<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Mon 16 Oct 23  to  Tue 17 Oct 23, announced Wed, 18 Oct 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item348">Cross-lists</a></li>
<li><a href="#item397">Replacements</a></li>
</ul>
<small>[ total of 680 entries:  <b>1-680</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed, 18 Oct 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10652" title="Abstract">arXiv:2310.10652</a> [<a href="/pdf/2310.10652" title="Download PDF">pdf</a>, <a href="/format/2310.10652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BRC-20: Hope or Hype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guangsheng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">BRC-20 (short for Bitcoin Request for Comment 20) token mania was a key
storyline in the middle of 2023. Setting it apart from conventional ERC-20
token standards on Ethereum, BRC-20 introduces non-fungibility to Bitcoin
through an editable field in each satoshi (0.00000001 Bitcoin, the smallest
unit), making them unique. In this paper, we pioneer the exploration of this
concept, covering its intricate mechanisms, features, and state-of-the-art
applications. By analyzing the multi-dimensional data spanning over months with
factual investigations, we conservatively comment that while BRC-20 expands
Bitcoin's functionality and applicability, it may still not match Ethereum's
abundance of decentralized applications and similar ecosystems.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10653" title="Abstract">arXiv:2310.10653</a> [<a href="/pdf/2310.10653" title="Download PDF">pdf</a>, <a href="/format/2310.10653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure and Trustworthy NFC-based Sensor Readout for Battery Packs in  Battery Management Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basic%2C+F">Fikret Basic</a>, 
<a href="/search/cs?searchtype=author&query=Gaertner%2C+M">Martin Gaertner</a>, 
<a href="/search/cs?searchtype=author&query=Steger%2C+C">Christian Steger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2308.09366">arXiv:2308.09366</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Journal of Radio Frequency Identification 2022, vol. 6, pages
  637-648
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Wireless Battery Management Systems (BMS) are increasingly being considered
for modern applications. The ever-increasing complexity and production costs of
BMS modules and wired connections resulted in a necessity for new ideas and
approaches. Despite this growing trend, there is a lack of generic solutions
focused on battery cells' sensor readout, where wireless communication allows
for a more flexible and cost-efficient sensor installation in battery packs.
Many wireless technologies, such as those that use the 2.4 GHz frequency band,
suffer from interference and other limitations. In this article, we present an
alternative approach to communication in BMS that relies on the use of Near
Field Communication (NFC) technology for battery sensor readouts. As an answer
to the rising concern over the counterfeited battery packs, we consider an
authentication schema for battery pack validation. We further consider security
measures for the processed and stored BMS status data. To show that a general
BMS application can make use of our design, we implement a BMS demonstrator
using the targeted components. We further test the demonstrator on the
technical and functional level, by also performing evaluation on its
performance, energy usage, and a security threat model.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10654" title="Abstract">arXiv:2310.10654</a> [<a href="/pdf/2310.10654" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identity Prove Limited Information Governance Policy against cyber  security persistent threats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kruti%2C+A">Antigoni Kruti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Identity Prove Limited (IDPL) is a long-founded online identity verification
software provider of citizens for Banking services. IDPL applies an information
governance based on the ISO/IEC 27001:2022 standard of security and within GDPR
to accomplish face verification. The company has a good reputation for
biometric authentication services that allow a secure, simple, sustainable
online access for financial services providers on delivering security
device-independent, ensuring reassurance and convenience to users. The company
should ensure a right person, a real person, authenticating in real-time. The
IDPL company must assume sustainable security models for the duration of
day-to-day operations does not involve human intervention. The IDPL Security
Operations Centre (ISOC) should continuously provide the optimum scale of
system performance, utilize security procedures against new threats, ensure the
optimum scale of system performance capabilities. The aim of information
governance policy is to declare and to demonstrate the performance of the
company on effectively and efficiently way in front of risk detection and
vulnerability mitigation. The scope of this policy involves all management
systems and stakeholders details, include unique identifiers of submitter and
receiver. The company has in-house systems focused on all potential risks to
client data and its information system assets.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10655" title="Abstract">arXiv:2310.10655</a> [<a href="/pdf/2310.10655" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Trustworthiness in ML-Based Network Intrusion Detection with  Uncertainty Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Talpini%2C+J">Jacopo Talpini</a>, 
<a href="/search/cs?searchtype=author&query=Sartori%2C+F">Fabio Sartori</a>, 
<a href="/search/cs?searchtype=author&query=Savi%2C+M">Marco Savi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The evolution of Internet and its related communication technologies have
consistently increased the risk of cyber-attacks. In this context, a crucial
role is played by Intrusion Detection Systems (IDSs), which are security
devices designed to identify and mitigate attacks to modern networks. In the
last decade, data-driven approaches based on Machine Learning (ML) have gained
more and more popularity for executing the classification tasks required by
IDSs. However, typical ML models adopted for this purpose do not properly take
into account the uncertainty associated with their own prediction. This poses
significant challenges, as they tend to produce misleadingly high
classification scores for both misclassified inputs and inputs belonging to
unknown classes (e.g. novel attacks), limiting the trustworthiness of existing
ML-based solutions. In this paper we argue that ML-based IDSs should always
provide accurate uncertainty quantification to avoid overconfident predictions.
In fact, an uncertainty-aware classification would be beneficial to enhance
closed-set classification performance, would make it possible to efficiently
carry out Active Learning, and would help recognize inputs of unknown classes
as truly unknowns (i.e., not belonging to any known class), unlocking open-set
classification capabilities and Out-of-Distribution (OoD) detection. To verify
it, we compare various ML-based methods for uncertainty quantification and for
OoD detection, either specifically designed for or tailored to the domain of
network intrusion detection, showing how a proper estimation of the model
uncertainty can be exploited to significantly enhance the trustworthiness of
ML-based IDSs. Our results also confirm that conventional ML-based approaches
to network intrusion detection (e.g. based on traditional feed-forward Neural
Networks) may not be appropriate and should be adopted with caution.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10656" title="Abstract">arXiv:2310.10656</a> [<a href="/pdf/2310.10656" title="Download PDF">pdf</a>, <a href="/format/2310.10656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VeriDIP: Verifying Ownership of Deep Neural Networks through Privacy  Leakage Fingerprints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+A">Aoting Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhigang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Renjie Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minhui Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deploying Machine Learning as a Service gives rise to model plagiarism,
leading to copyright infringement. Ownership testing techniques are designed to
identify model fingerprints for verifying plagiarism. However, previous works
often rely on overfitting or robustness features as fingerprints, lacking
theoretical guarantees and exhibiting under-performance on generalized models.
In this paper, we propose a novel ownership testing method called VeriDIP,
which verifies a DNN model's intellectual property. VeriDIP makes two major
contributions. (1) It utilizes membership inference attacks to estimate the
lower bound of privacy leakage, which reflects the fingerprint of a given
model. The privacy leakage fingerprints highlight the unique patterns through
which the models memorize sensitive training datasets. (2) We introduce a novel
approach using less private samples to enhance the performance of ownership
testing.
<br />Extensive experimental results confirm that VeriDIP is effective and
efficient in validating the ownership of deep learning models trained on both
image and tabular datasets. VeriDIP achieves comparable performance to
state-of-the-art methods on image datasets while significantly reducing
computation and communication costs. Enhanced VeriDIP demonstrates superior
verification performance on generalized deep learning models, particularly on
table-trained models. Additionally, VeriDIP exhibits similar effectiveness on
utility-preserving differentially private models compared to non-differentially
private baselines.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10657" title="Abstract">arXiv:2310.10657</a> [<a href="/pdf/2310.10657" title="Download PDF">pdf</a>, <a href="/format/2310.10657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Managing Networked IoT Assets Using Practical and Scalable Traffic  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pashamokhtari%2C+A">Arman Pashamokhtari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Internet has recently witnessed unprecedented growth of a class of
connected assets called the Internet of Things (IoT). Due to relatively
immature manufacturing processes and limited computing resources, IoTs have
inadequate device-level security measures, exposing the Internet to various
cyber risks. Prior research leveraged predictable patterns in IoT network
traffic to develop inference models. However, they fall short of expectations
in addressing practical challenges, preventing them from being deployed in
production settings. This thesis identifies four practical challenges and
develops techniques to address them which can help secure businesses and
protect user privacy against growing cyber threats.
<br />My first contribution balances prediction gains against computing costs of
traffic features for IoT traffic classification and monitoring. My second
contribution addresses the challenges of measurement costs and data quality. I
develop an inference method that uses stochastic and deterministic modeling to
predict IoT devices in home networks from opaque and coarse-grained IPFIX flow
data. Evaluations show that false positive rates can be reduced by 75% compared
to related work without significantly affecting true positives. My third
contribution focuses on the challenge of concept drifts by analyzing over six
million flow records collected from 12 real home networks. Finally, my fourth
contribution studies the resilience of machine learning models against
adversarial attacks with a specific focus on decision tree-based models.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10658" title="Abstract">arXiv:2310.10658</a> [<a href="/pdf/2310.10658" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Checking and Automating Confidentiality Theory in Isabelle/UTP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bailey%2C+L">Lex Bailey</a> (they/them), 
<a href="/search/cs?searchtype=author&query=Woodcock%2C+J">Jim Woodcock</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+S">Simon Foster</a>, 
<a href="/search/cs?searchtype=author&query=Metere%2C+R">Roberto Metere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The severity of recent vulnerabilities discovered on modern CPUs, e.g.,
Spectre [1], highlights how information leakage can have devas-tating effects
to the security of computer systems. At the same time, it suggests that
confidentiality should be promoted as a normal part of program verification, to
discover and mitigate such vulnerabili-ties early in development. The theory we
propose is primarily based on Bank's theory [2], a framework for reasoning
about confidentiali-ty properties formalised in the Unifying Theories of
Programming (UTP) [3]. We mechanised our encoding in the current
implementa-tion of UTP in the Isabelle theorem prover, Isabelle/UTP [4]. We
have identified some theoretical issues in Bank's original framework. Finally,
we demonstrate how our mechanisation can be used to for-mally verify of some of
the examples from Bank's work.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10659" title="Abstract">arXiv:2310.10659</a> [<a href="/pdf/2310.10659" title="Download PDF">pdf</a>, <a href="/format/2310.10659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdoor Attack through Machine Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingtian Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, the security issues of artificial intelligence have become
increasingly prominent due to the rapid development of deep learning research
and applications. Backdoor attack is an attack targeting the vulnerability of
deep learning models, where hidden backdoors are activated by triggers embedded
by the attacker, thereby outputting malicious predictions that may not align
with the intended output for a given input. In this work, we propose a novel
black-box backdoor attack based on machine unlearning. The attacker first
augments the training set with carefully designed samples, including poison and
mitigation data, to train a 'benign' model. Then, the attacker posts unlearning
requests for the mitigation samples to remove the impact of relevant data on
the model, gradually activating the hidden backdoor. Since backdoors are
implanted during the iterative unlearning process, it significantly increases
the computational overhead of existing defense methods for backdoor detection
or mitigation. To address this new security threat, we propose two methods for
detecting or mitigating such malicious unlearning requests. We conduct the
experiment in both naive unlearning and SISA settings. Experimental results
show that: 1) our attack can successfully implant backdoor into the model, and
sharding increases the difficulty of attack; 2) our detection algorithms are
effective in identifying the mitigation samples, while sharding reduces the
effectiveness of our detection algorithms.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10660" title="Abstract">arXiv:2310.10660</a> [<a href="/pdf/2310.10660" title="Download PDF">pdf</a>, <a href="/format/2310.10660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and Detection against Network Attacks in the Overlapping  Phenomenon of Behavior Attribute
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhanga%2C+Y">Yongzheng Zhanga</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peishuai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongbo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 26 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The proliferation of network attacks poses a significant threat. Researchers
propose datasets for network attacks to support research in related fields.
Then, many attack detection methods based on these datasets are proposed. These
detection methods, whether two-classification or multi-classification, belong
to single-label learning, i.e., only one label is given to each sample.
However, we discover that there is a noteworthy phenomenon of behavior
attribute overlap between attacks, The presentation of this phenomenon in a
dataset is that there are multiple samples with the same features but different
labels. In this paper, we verify the phenomenon in well-known
datasets(UNSW-NB15, CCCS-CIC-AndMal-2020) and re-label these data. In addition,
detecting network attacks in a multi-label manner can obtain more information,
providing support for tracing the attack source and building IDS. Therefore, we
propose a multi-label detection model based on deep learning, MLD-Model, in
which Wasserstein-Generative-Adversarial- Network-with-Gradient-Penalty
(WGAN-GP) with improved loss performs data enhancement to alleviate the class
imbalance problem, and Auto-Encoder (AE) performs classifier parameter
pre-training. Experimental results demonstrate that MLD-Model can achieve
excellent classification performance. It can achieve F1=80.06% in UNSW-NB15 and
F1=83.63% in CCCS-CIC-AndMal-2020. Especially, MLD-Model is 5.99%-7.97% higher
in F1 compared with the related single-label methods.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10661" title="Abstract">arXiv:2310.10661</a> [<a href="/pdf/2310.10661" title="Download PDF">pdf</a>, <a href="/format/2310.10661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TII-SSRC-23 Dataset: Typological Exploration of Diverse Traffic Patterns  for Intrusion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herzalla%2C+D">Dania Herzalla</a>, 
<a href="/search/cs?searchtype=author&query=Lunardi%2C+W+T">Willian T. Lunardi</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+M+A">Martin Andreoni Lopez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The effectiveness of network intrusion detection systems, predominantly based
on machine learning, are highly influenced by the dataset they are trained on.
Ensuring an accurate reflection of the multifaceted nature of benign and
malicious traffic in these datasets is essential for creating models capable of
recognizing and responding to a wide array of intrusion patterns. However,
existing datasets often fall short, lacking the necessary diversity and
alignment with the contemporary network environment, thereby limiting the
effectiveness of intrusion detection. This paper introduces TII-SSRC-23, a
novel and comprehensive dataset designed to overcome these challenges.
Comprising a diverse range of traffic types and subtypes, our dataset is a
robust and versatile tool for the research community. Additionally, we conduct
a feature importance analysis, providing vital insights into critical features
for intrusion detection tasks. Through extensive experimentation, we also
establish firm baselines for supervised and unsupervised intrusion detection
methodologies using our dataset, further contributing to the advancement and
adaptability of intrusion detection models in the rapidly changing landscape of
network security. Our dataset is available at
https://kaggle.com/datasets/daniaherzalla/tii-ssrc-23.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10662" title="Abstract">arXiv:2310.10662</a> [<a href="/pdf/2310.10662" title="Download PDF">pdf</a>, <a href="/format/2310.10662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Influence of Different Types of Probing on Adversarial  Decision-Making in a Deception Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sayed%2C+M+A">Md Abu Sayed</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A+I">Mohammad Ariful Islam Khan</a>, 
<a href="/search/cs?searchtype=author&query=Allsup%2C+B+A">Bryant A Allsup</a>, 
<a href="/search/cs?searchtype=author&query=Zamora%2C+J">Joshua Zamora</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+P">Palvi Aggarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Deception, which includes leading cyber-attackers astray with false
information, has shown to be an effective method of thwarting cyber-attacks.
There has been little investigation of the effect of probing action costs on
adversarial decision-making, despite earlier studies on deception in
cybersecurity focusing primarily on variables like network size and the
percentage of honeypots utilized in games. Understanding human decision-making
when prompted with choices of various costs is essential in many areas such as
in cyber security. In this paper, we will use a deception game (DG) to examine
different costs of probing on adversarial decisions. To achieve this we
utilized an IBLT model and a delayed feedback mechanism to mimic knowledge of
human actions. Our results were taken from an even split of deception and no
deception to compare each influence. It was concluded that probing was slightly
taken less as the cost of probing increased. The proportion of attacks stayed
relatively the same as the cost of probing increased. Although a constant cost
led to a slight decrease in attacks. Overall, our results concluded that the
different probing costs do not have an impact on the proportion of attacks
whereas it had a slightly noticeable impact on the proportion of probing.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10663" title="Abstract">arXiv:2310.10663</a> [<a href="/pdf/2310.10663" title="Download PDF">pdf</a>, <a href="/format/2310.10663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data privacy for Mobility as a Service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garroussi%2C+Z">Zineb Garroussi</a>, 
<a href="/search/cs?searchtype=author&query=Legrain%2C+A">Antoine Legrain</a>, 
<a href="/search/cs?searchtype=author&query=Gambs%2C+S">S&#xe9;bastien Gambs</a>, 
<a href="/search/cs?searchtype=author&query=Gautrais%2C+V">Vincent Gautrais</a>, 
<a href="/search/cs?searchtype=author&query=Sans%C3%B2%2C+B">Brunilde Sans&#xf2;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Mobility as a Service (MaaS) is revolutionizing the transportation industry
by offering convenient, efficient and integrated transportation solutions.
However, the extensive use of user data as well as the integration of multiple
service providers raises significant privacy concerns. The objective of this
survey paper is to provide a comprehensive analysis of the current state of
data privacy in MaaS, in particular by discussing the associated challenges,
existing solutions as well as potential future directions to ensure user
privacy while maintaining the benefits of MaaS systems for society.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10664" title="Abstract">arXiv:2310.10664</a> [<a href="/pdf/2310.10664" title="Download PDF">pdf</a>, <a href="/format/2310.10664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nebula: Self-Attention for Dynamic Malware Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trizna%2C+D">Dmitrijs Trizna</a>, 
<a href="/search/cs?searchtype=author&query=Demetrio%2C+L">Luca Demetrio</a>, 
<a href="/search/cs?searchtype=author&query=Biggio%2C+B">Battista Biggio</a>, 
<a href="/search/cs?searchtype=author&query=Roli%2C+F">Fabio Roli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures, 12 tables, preprint, in review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Dynamic analysis enables detecting Windows malware by executing programs in a
controlled environment, and storing their actions in log reports. Previous work
has started training machine learning models on such reports to perform either
malware detection or malware classification. However, most of the approaches
(i) have only considered convolutional and long-short term memory networks,
(ii) they have been built focusing only on APIs called at runtime, without
considering other relevant though heterogeneous sources of information like
network and file operations, and (iii) the code and pretrained models are
hardly available, hindering reproducibility of results in this research area.
In this work, we overcome these limitations by presenting Nebula, a versatile,
self-attention transformer-based neural architecture that can generalize across
different behavior representations and formats, combining heterogeneous
information from dynamic log reports. We show the efficacy of Nebula on three
distinct data collections from different dynamic analysis platforms, comparing
its performance with previous state-of-the-art models developed for malware
detection and classification tasks. We produce an extensive ablation study that
showcases how the components of Nebula influence its predictive performance,
while enabling it to outperform some competing approaches at very low false
positive rates. We conclude our work by inspecting the behavior of Nebula
through the application of explainability methods, which highlight that Nebula
correctly focuses more on portions of reports that contain malicious
activities. We release our code and models at github.com/dtrizna/nebula.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10665" title="Abstract">arXiv:2310.10665</a> [<a href="/pdf/2310.10665" title="Download PDF">pdf</a>, <a href="/format/2310.10665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Preservation in Artificial Intelligence and Extended Reality  (AI-XR) Metaverses: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alkaeed%2C+M">Mahdi Alkaeed</a>, 
<a href="/search/cs?searchtype=author&query=Qayyum%2C+A">Adnan Qayyum</a>, 
<a href="/search/cs?searchtype=author&query=Qadir%2C+J">Junaid Qadir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The metaverse is a nascent concept that envisions a virtual universe, a
collaborative space where individuals can interact, create, and participate in
a wide range of activities. Privacy in the metaverse is a critical concern as
the concept evolves and immersive virtual experiences become more prevalent.
The metaverse privacy problem refers to the challenges and concerns surrounding
the privacy of personal information and data within Virtual Reality (VR)
environments as the concept of a shared VR space becomes more accessible.
Metaverse will harness advancements from various technologies such as
Artificial Intelligence (AI), Extended Reality (XR), Mixed Reality (MR), and
5G/6G-based communication to provide personalized and immersive services to its
users. Moreover, to enable more personalized experiences, the metaverse relies
on the collection of fine-grained user data that leads to various privacy
issues. Therefore, before the potential of the metaverse can be fully realized,
privacy concerns related to personal information and data within VR
environments must be addressed. This includes safeguarding users' control over
their data, ensuring the security of their personal information, and protecting
in-world actions and interactions from unauthorized sharing. In this paper, we
explore various privacy challenges that future metaverses are expected to face,
given their reliance on AI for tracking users, creating XR and MR experiences,
and facilitating interactions. Moreover, we thoroughly analyze technical
solutions such as differential privacy, Homomorphic Encryption (HE), and
Federated Learning (FL) and discuss related sociotechnical issues regarding
privacy.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10666" title="Abstract">arXiv:2310.10666</a> [<a href="/pdf/2310.10666" title="Download PDF">pdf</a>, <a href="/format/2310.10666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Physical Causality from Measurements to Detect and Localize  False Data Injection Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shengyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dongyuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">False Data Injection Attack (FDIA) has become a growing concern in modern
cyber-physical power systems. Most existing FDIA detection techniques project
the raw measurement data into a high-dimensional latent space to separate
normal and attacked samples. These approaches focus more on the statistical
correlations of data values and are therefore susceptible to data distribution
drifts induced by changes in system operating points or changes in FDIA types
and strengths, especially for FDIA localization tasks. Causal inference, on the
other hand, extracts the causality behind the coordinated fluctuations of
different measurements. The causality patterns are determined by fundamental
physical laws such as Ohm's Law and Kirchhoff's Law. They are sensitive to the
violation of physical laws caused by FDIA, but tend to remain stable with the
drift of system operating points. Leveraging this advantage, this paper
proposes a joint FDIA detection and localization framework based on causal
inference and the Graph Attention Network (GAT) to identify the attacked system
nodes. The proposed framework consists of two levels. The lower level uses the
X-learner algorithm to estimate the causality strength between measurements and
generate Measurement Causality Graphs (MCGs). The upper level then applies a
GAT to identify the anomaly patterns in the MCGs. Since the extracted causality
patterns are intrinsically related to the measurements, it is easier for the
upper level to figure out the attacked nodes than the existing FDIA
localization approaches. The performance of the proposed framework is evaluated
on the IEEE 39-bus system. Experimental results show that the causality-based
FDIA detection and localization mechanism is highly interpretable and robust.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10667" title="Abstract">arXiv:2310.10667</a> [<a href="/pdf/2310.10667" title="Download PDF">pdf</a>, <a href="/format/2310.10667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Network Resilience through Machine Learning-powered Graph  Combinatorial Optimization: Applications in Cyber Defense and Information  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+D">Diksha Goel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With the burgeoning advancements of computing and network communication
technologies, network infrastructures and their application environments have
become increasingly complex. Due to the increased complexity, networks are more
prone to hardware faults and highly susceptible to cyber-attacks. Therefore,
for rapidly growing network-centric applications, network resilience is
essential to minimize the impact of attacks and to ensure that the network
provides an acceptable level of services during attacks, faults or disruptions.
In this regard, this thesis focuses on developing effective approaches for
enhancing network resilience. Existing approaches for enhancing network
resilience emphasize on determining bottleneck nodes and edges in the network
and designing proactive responses to safeguard the network against attacks.
However, existing solutions generally consider broader application domains and
possess limited applicability when applied to specific application areas such
as cyber defense and information diffusion, which are highly popular
application domains among cyber attackers.
<br />This thesis aims to design effective, efficient and scalable techniques for
discovering bottleneck nodes and edges in the network to enhance network
resilience in cyber defense and information diffusion application domains. We
first investigate a cyber defense graph optimization problem, i.e., hardening
active directory systems by discovering bottleneck edges in the network. We
then study the problem of identifying bottleneck structural hole spanner nodes,
which are crucial for information diffusion in the network. We transform both
problems into graph-combinatorial optimization problems and design machine
learning based approaches for discovering bottleneck points vital for enhancing
network resilience.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10669" title="Abstract">arXiv:2310.10669</a> [<a href="/pdf/2310.10669" title="Download PDF">pdf</a>, <a href="/format/2310.10669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased Watermark for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhengmian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lichang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xidong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yihan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The recent advancements in large language models (LLMs) have sparked a
growing apprehension regarding the potential misuse. One approach to mitigating
this risk is to incorporate watermarking techniques into LLMs, allowing for the
tracking and attribution of model outputs. This study examines a crucial aspect
of watermarking: how significantly watermarks impact the quality of
model-generated outputs. Previous studies have suggested a trade-off between
watermark strength and output quality. However, our research demonstrates that
it is possible to integrate watermarks without affecting the output probability
distribution with appropriate implementation. We refer to this type of
watermark as an unbiased watermark. This has significant implications for the
use of LLMs, as it becomes impossible for users to discern whether a service
provider has incorporated watermarks or not. Furthermore, the presence of
watermarks does not compromise the performance of the model in downstream
tasks, ensuring that the overall utility of the language model is preserved.
Our findings contribute to the ongoing discussion around responsible AI
development, suggesting that unbiased watermarks can serve as an effective
means of tracking and attributing model outputs without sacrificing output
quality.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10670" title="Abstract">arXiv:2310.10670</a> [<a href="/pdf/2310.10670" title="Download PDF">pdf</a>, <a href="/format/2310.10670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart OMVI: Obfuscated Malware Variant Identification using a novel  dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qamar%2C+S">Suleman Qamar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cybersecurity has become a significant issue in the digital era as a result
of the growth in everyday computer use. Cybercriminals now engage in more than
virus distribution and computer hacking. Cyberwarfare has developed as a result
because it has become a threat to a nation's survival. Malware analysis serves
as the first line of defence against an attack and is a significant component
of cybercrime. Every day, malware attacks target a large number of computer
users, businesses, and governmental agencies, causing billions of dollars in
losses. Malware may evade multiple AV software with a very minor, cunning tweak
made by its designers, despite the fact that security experts have a variety of
tools at their disposal to identify it. To address this challenge, a new
dataset called the Obfuscated Malware Dataset (OMD) has been developed. This
dataset comprises 40 distinct malware families having 21924 samples, and it
incorporates obfuscation techniques that mimic the strategies employed by
malware creators to make their malware variations different from the original
samples. The purpose of this dataset is to provide a more realistic and
representative environment for evaluating the effectiveness of malware analysis
techniques. Different conventional machine learning algorithms including but
not limited to Support Vector Machine (SVM), Random Forrest (RF), Extreme
Gradient Boosting (XGBOOST) etc are applied and contrasted. The results
demonstrated that XGBoost outperformed the other algorithms, achieving an
accuracy of f 82%, precision of 88%, recall of 80%, and an F1-Score of 83%.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10672" title="Abstract">arXiv:2310.10672</a> [<a href="/pdf/2310.10672" title="Download PDF">pdf</a>, <a href="/format/2310.10672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Quantum-Classical Machine Learning for Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masum%2C+A+K+M">Abu Kaisar Mohammad Masum</a>, 
<a href="/search/cs?searchtype=author&query=Maurya%2C+A">Anshul Maurya</a>, 
<a href="/search/cs?searchtype=author&query=Murthy%2C+D+S">Dhruthi Sridhar Murthy</a>, 
<a href="/search/cs?searchtype=author&query=Pratibha">Pratibha</a>, 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+N">Naveed Mahmud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, To Appear at IEEE ICMLA 2023, FL, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The collaboration between quantum computing and classical machine learning
offers potential advantages in natural language processing, particularly in the
sentiment analysis of human emotions and opinions expressed in large-scale
datasets. In this work, we propose a methodology for sentiment analysis using
hybrid quantum-classical machine learning algorithms. We investigate quantum
kernel approaches and variational quantum circuit-based classifiers and
integrate them with classical dimension reduction techniques such as PCA and
Haar wavelet transform. The proposed methodology is evaluated using two
distinct datasets, based on English and Bengali languages. Experimental results
show that after dimensionality reduction of the data, performance of the
quantum-based hybrid algorithms were consistent and better than classical
methods.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10673" title="Abstract">arXiv:2310.10673</a> [<a href="/pdf/2310.10673" title="Download PDF">pdf</a>, <a href="/ps/2310.10673" title="Download PostScript">ps</a>, <a href="/format/2310.10673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Emotion-Based Synthetic Consciousness: Using LLMs to Estimate  Emotion Probability Vectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinclair%2C+D">David Sinclair</a>, 
<a href="/search/cs?searchtype=author&query=Pye%2C+W">Willem Pye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Emotion descriptors derived from LLMs are likely to be used in governing robot behaviour. Vectorizing emotion descriptors provides a finer grained representation of state than current 'positive vs negative' situation assessments. Finer grained geometric representation of state will be necessary for future human robot interaction governance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper shows how LLMs (Large Language Models) may be used to estimate a
summary of the emotional state associated with piece of text. The summary of
emotional state is a dictionary of words used to describe emotion together with
the probability of the word appearing after a prompt comprising the original
text and an emotion eliciting tail. Through emotion analysis of Amazon product
reviews we demonstrate emotion descriptors can be mapped into a PCA type space.
It was hoped that text descriptions of actions to improve a current text
described state could also be elicited through a tail prompt. Experiment seemed
to indicate that this is not straightforward to make work. This failure put our
hoped for selection of action via choosing the best predict ed outcome via
comparing emotional responses out of reach for the moment.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10675" title="Abstract">arXiv:2310.10675</a> [<a href="/pdf/2310.10675" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creation Of A ChatBot Based On Natural Language Proccesing For Whatsapp
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jonatan%2C+V">Valderrama Jonatan</a>, 
<a href="/search/cs?searchtype=author&query=Igor%2C+A">Aguilar-Alonso Igor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the era of digital transformation, customer service is of paramount
importance to the success of organizations, and to meet the growing demand for
immediate responses and personalized assistance 24 hours a day, chatbots have
become a promising tool to solve these problems. Currently, there are many
companies that need to provide these solutions to their customers, which
motivates us to study this problem and offer a suitable solution. The objective
of this study is to develop a chatbot based on natural language processing to
improve customer satisfaction and improve the quality of service provided by
the company through WhatsApp. The solution focuses on creating a chatbot that
efficiently and effectively handles user queries. A literature review related
to existing chatbots has been conducted, analyzing methodological approaches,
artificial intelligence techniques and quality attributes used in the
implementation of chatbots. The results found highlight that chatbots based on
natural language processing enable fast and accurate responses, which improves
the efficiency of customer service, as chatbots contribute to customer
satisfaction by providing accurate answers and quick solutions to their queries
at any time. Some authors point out that artificial intelligence techniques,
such as machine learning, improve the learning and adaptability of chatbots as
user interactions occur, so a good choice of appropriate natural language
understanding technologies is essential for optimal chatbot performance. The
results of this study will provide a solid foundation for the design and
development of effective chatbots for customer service, ensuring a satisfactory
user experience and thus meeting the needs of the organization.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10676" title="Abstract">arXiv:2310.10676</a> [<a href="/pdf/2310.10676" title="Download PDF">pdf</a>, <a href="/format/2310.10676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application-layer Characterization and Traffic Analysis for Encrypted  QUIC Transport Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qianqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Chi-Jiun Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Quick UDP Internet Connection (QUIC) is an emerging end-to-end encrypted,
transport-layer protocol, which has been increasingly adopted by popular web
services to improve communication security and quality of experience (QoE)
towards end-users. However, this tendency makes the traffic analysis more
challenging, given the limited information in the QUIC packet header and full
encryption on the payload. To address this challenge, a novel rule-based
approach is proposed to estimate the application-level traffic attributes
without decrypting QUIC packets. Based on the size, timing, and direction
information, our proposed algorithm analyzes the associated network traffic to
infer the identity of each HTTP request and response pair, as well as the
multiplexing feature in each QUIC connection. The inferred HTTP attributes can
be used to evaluate the QoE of application-layer services and identify the
service categories for traffic classification in the encrypted QUIC
connections.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10677" title="Abstract">arXiv:2310.10677</a> [<a href="/pdf/2310.10677" title="Download PDF">pdf</a>, <a href="/format/2310.10677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs as Potential Brainstorming Partners for Math and Science Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Sophia Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the recent rise of widely successful deep learning models, there is
emerging interest among professionals in various math and science communities
to see and evaluate the state-of-the-art models' abilities to collaborate on
finding or solving problems that often require creativity and thus
brainstorming. While a significant chasm still exists between current
human-machine intellectual collaborations and the resolution of complex math
and science problems, such as the six unsolved Millennium Prize Problems, our
initial investigation into this matter reveals a promising step towards
bridging the divide. This is due to the recent advancements in Large Language
Models (LLMs). More specifically, we conduct comprehensive case studies to
explore both the capabilities and limitations of the current state-of-the-art
LLM, notably GPT-4, in collective brainstorming with humans.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10679" title="Abstract">arXiv:2310.10679</a> [<a href="/pdf/2310.10679" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large language models can replicate cross-cultural differences in  personality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niszczota%2C+P">Pawe&#x142; Niszczota</a>, 
<a href="/search/cs?searchtype=author&query=Janczak%2C+M">Mateusz Janczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure and 1 table in the manuscript (more figures and tables in the supplementary materials)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">We use a large-scale experiment (N=8000) to determine whether GPT-4 can
replicate cross-cultural differences in the Big Five, measured using the
Ten-Item Personality Inventory. We used the US and South Korea as the cultural
pair, given that prior research suggests substantial personality differences
between people from these two countries. We manipulated the target of the
simulation (US vs. Korean), the language of the inventory (English vs. Korean),
and the language model (GPT-4 vs. GPT-3.5). Our results show that GPT-4
replicated the cross-cultural differences for each factor. However, mean
ratings had an upward bias and exhibited lower variation than in the human
samples, as well as lower structural validity. Overall, we provide preliminary
evidence that LLMs can aid cross-cultural psychological research.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10683" title="Abstract">arXiv:2310.10683</a> [<a href="/pdf/2310.10683" title="Download PDF">pdf</a>, <a href="/format/2310.10683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuanshun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaojun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We study how to perform unlearning, i.e. forgetting undesirable
(mis)behaviors, on large language models (LLMs). We show at least three
scenarios of aligning LLMs with human preferences can benefit from unlearning:
(1) removing harmful responses, (2) erasing copyright-protected content as
requested, and (3) eliminating hallucinations. Unlearning, as an alignment
technique, has three advantages. (1) It only requires negative (e.g. harmful)
examples, which are much easier and cheaper to collect (e.g. via red teaming or
user reporting) than positive (e.g. helpful and often human-written) examples
required in RLHF (RL from human feedback). (2) It is computationally efficient.
(3) It is especially effective when we know which training samples cause the
misbehavior. To the best of our knowledge, our work is among the first to
explore LLM unlearning. We are also among the first to formulate the settings,
goals, and evaluations in LLM unlearning. We show that if practitioners only
have limited resources, and therefore the priority is to stop generating
undesirable outputs rather than to try to generate desirable outputs,
unlearning is particularly appealing. Despite only having negative samples, our
ablation study shows that unlearning can still achieve better alignment
performance than RLHF with just 2% of its computational time.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10685" title="Abstract">arXiv:2310.10685</a> [<a href="/pdf/2310.10685" title="Download PDF">pdf</a>, <a href="/format/2310.10685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PS-AAS: Portfolio Selection for Automated Algorithm Selection in  Black-Box Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kostovska%2C+A">Ana Kostovska</a>, 
<a href="/search/cs?searchtype=author&query=Cenikj%2C+G">Gjorgjina Cenikj</a>, 
<a href="/search/cs?searchtype=author&query=Vermetten%2C+D">Diederick Vermetten</a>, 
<a href="/search/cs?searchtype=author&query=Jankovic%2C+A">Anja Jankovic</a>, 
<a href="/search/cs?searchtype=author&query=Nikolikj%2C+A">Ana Nikolikj</a>, 
<a href="/search/cs?searchtype=author&query=Skvorc%2C+U">Urban Skvorc</a>, 
<a href="/search/cs?searchtype=author&query=Korosec%2C+P">Peter Korosec</a>, 
<a href="/search/cs?searchtype=author&query=Doerr%2C+C">Carola Doerr</a>, 
<a href="/search/cs?searchtype=author&query=Eftimov%2C+T">Tome Eftimov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proc. of International Conference on Automated Machine Learning (AutoML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The performance of automated algorithm selection (AAS) strongly depends on
the portfolio of algorithms to choose from. Selecting the portfolio is a
non-trivial task that requires balancing the trade-off between the higher
flexibility of large portfolios with the increased complexity of the AAS task.
In practice, probably the most common way to choose the algorithms for the
portfolio is a greedy selection of the algorithms that perform well in some
reference tasks of interest.
<br />We set out in this work to investigate alternative, data-driven portfolio
selection techniques. Our proposed method creates algorithm behavior
meta-representations, constructs a graph from a set of algorithms based on
their meta-representation similarity, and applies a graph algorithm to select a
final portfolio of diverse, representative, and non-redundant algorithms. We
evaluate two distinct meta-representation techniques (SHAP and performance2vec)
for selecting complementary portfolios from a total of 324 different variants
of CMA-ES for the task of optimizing the BBOB single-objective problems in
dimensionalities 5 and 30 with different cut-off budgets. We test two types of
portfolios: one related to overall algorithm behavior and the `personalized'
one (related to algorithm behavior per each problem separately). We observe
that the approach built on the performance2vec-based representations favors
small portfolios with negligible error in the AAS task relative to the virtual
best solver from the selected portfolio, whereas the portfolios built from the
SHAP-based representations gain from higher flexibility at the cost of
decreased performance of the AAS. Across most considered scenarios,
personalized portfolios yield comparable or slightly better performance than
the classical greedy approach. They outperform the full portfolio in all
scenarios.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10686" title="Abstract">arXiv:2310.10686</a> [<a href="/pdf/2310.10686" title="Download PDF">pdf</a>, <a href="/format/2310.10686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Tree-search Ability of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhuorui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yikang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Due to the limitation "The abstract field cannot be longer than 1,920 characters", the abstract here is shorter than that in the PDF file
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models have excelled in remarkable reasoning capabilities with
advanced prompting techniques, but they fall short on tasks that require
exploration, strategic foresight, and sequential decision-making. Recent works
propose to utilize external programs to define search logic, such that LLMs can
perform passive tree search to solve more challenging reasoning tasks. Though
impressive results have been achieved, there are several fundamental
limitations of these approaches. First, passive tree searches are not efficient
as they usually require multiple rounds of LLM API calls to solve one single
problem. Moreover, passive search methods are not flexible since they need
task-specific program designs. Then a natural question arises: can we maintain
the tree-search capability of LLMs without the aid of external programs, and
can still generate responses that clearly demonstrate the process of a
tree-structure search? To this end, we propose a new concept called autonomous
tree-search ability of LLM, which can automatically generate a response
containing search trajectories for the correct answer. Concretely, we perform
search trajectories using capable LLM API via a fixed system prompt, allowing
them to perform autonomous tree-search (ATS) right out of the box. Experiments
on 4 puzzle games demonstrate our method can achieve huge improvements. The
ATS-BFS method outperforms the Chain of Thought approach by achieving an
average accuracy improvement of 33%. Compared to Tree of Thoughts, it requires
65.6% or 47.7% less GPT-api cost to attain a comparable level of accuracy.
Moreover, we have collected data using the ATS prompt method and fine-tuned
LLaMA. This approach yield a greater improvement compared to the ones
fine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an
average of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10687" title="Abstract">arXiv:2310.10687</a> [<a href="/pdf/2310.10687" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Exploration Into Web Session Security- A Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habib%2C+M+I">Md. Imtiaz Habib</a>, 
<a href="/search/cs?searchtype=author&query=Maruf%2C+A+A">Abdullah Al Maruf</a>, 
<a href="/search/cs?searchtype=author&query=Nabil%2C+M+J+A">Md. Jobair Ahmed Nabil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 sections, survey article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The most common attacks against web sessions are reviewed in this paper, for
example, some attacks against web browsers' honest users attempting to create
session with trusted web browser application legally. We have assessed with
four different ways to judge the viability of a certain solution by reviewing
existing security solutions which prevent or halt the different attacks. Then
we have pointed out some guidelines that have been taken into account by the
designers of the proposals we reviewed. The guidelines we have identified will
be helpful for the creative solutions proceeding web security in a more
structured and holistic way.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10688" title="Abstract">arXiv:2310.10688</a> [<a href="/pdf/2310.10688" title="Download PDF">pdf</a>, <a href="/format/2310.10688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A decoder-only foundation model for time-series forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Abhimanyu Das</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+W">Weihao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+R">Rajat Sen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yichen Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Motivated by recent advances in large language models for Natural Language
Processing (NLP), we design a time-series foundation model for forecasting
whose out-of-the-box zero-shot performance on a variety of public datasets
comes close to the accuracy of state-of-the-art supervised forecasting models
for each individual dataset. Our model is based on pretraining a
patched-decoder style attention model on a large time-series corpus, and can
work well across different forecasting history lengths, prediction lengths and
temporal granularities.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10690" title="Abstract">arXiv:2310.10690</a> [<a href="/pdf/2310.10690" title="Download PDF">pdf</a>, <a href="/format/2310.10690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for In-Context Student Modeling: Synthesizing  Student&#x27;s Behavior in Visual Programming from One-Shot Observation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M+H">Manh Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tschiatschek%2C+S">Sebastian Tschiatschek</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+A">Adish Singla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Student modeling is central to many educational technologies as it enables
the prediction of future learning outcomes and targeted instructional
strategies. However, open-ended learning environments pose challenges for
accurately modeling students due to the diverse behaviors exhibited by students
and the absence of a well-defined set of learning skills. To approach these
challenges, we explore the application of Large Language Models (LLMs) for
in-context student modeling in open-ended learning environments. We introduce a
novel framework, LLM-SS, that leverages LLMs for synthesizing student's
behavior. More concretely, given a particular student's solving attempt on a
reference task as observation, the goal is to synthesize the student's attempt
on a target task. Our framework can be combined with different LLMs; moreover,
we fine-tune LLMs using domain-specific expertise to boost their understanding
of domain background and student behaviors. We evaluate several concrete
methods based on LLM-SS using the StudentSyn benchmark, an existing student's
attempt synthesis benchmark in visual programming. Experimental results show a
significant improvement compared to baseline methods included in the StudentSyn
benchmark. Furthermore, our method using the fine-tuned Llama2-70B model
improves noticeably compared to using the base model and becomes on par with
using the state-of-the-art GPT-4 model.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10691" title="Abstract">arXiv:2310.10691</a> [<a href="/pdf/2310.10691" title="Download PDF">pdf</a>, <a href="/format/2310.10691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing ML model accuracy for Digital VLSI circuits using diffusion  models: A study on synthetic data generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+P">Prasha Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Pawan Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+Z">Zia Abbas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, submitted to NeurIPS workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Generative AI has seen remarkable growth over the past few years, with
diffusion models being state-of-the-art for image generation. This study
investigates the use of diffusion models in generating artificial data
generation for electronic circuits for enhancing the accuracy of subsequent
machine learning models in tasks such as performance assessment, design, and
testing when training data is usually known to be very limited. We utilize
simulations in the HSPICE design environment with 22nm CMOS technology nodes to
obtain representative real training data for our proposed diffusion model. Our
results demonstrate the close resemblance of synthetic data using diffusion
model to real data. We validate the quality of generated data, and demonstrate
that data augmentation certainly effective in predictive analysis of VLSI
design for digital circuits.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10692" title="Abstract">arXiv:2310.10692</a> [<a href="/pdf/2310.10692" title="Download PDF">pdf</a>, <a href="/format/2310.10692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACES: generating diverse programming puzzles with autotelic language  models and semantic descriptors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pourcel%2C+J">Julien Pourcel</a>, 
<a href="/search/cs?searchtype=author&query=Colas%2C+C">C&#xe9;dric Colas</a>, 
<a href="/search/cs?searchtype=author&query=Oudeyer%2C+P">Pierre-Yves Oudeyer</a>, 
<a href="/search/cs?searchtype=author&query=Teodorescu%2C+L">Laetitia Teodorescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Finding and selecting new and interesting problems to solve is at the heart
of curiosity, science and innovation. We here study automated problem
generation in the context of the open-ended space of python programming
puzzles. Existing generative models often aim at modeling a reference
distribution without any explicit diversity optimization. Other methods
explicitly optimizing for diversity do so either in limited hand-coded
representation spaces or in uninterpretable learned embedding spaces that may
not align with human perceptions of interesting variations. With ACES
(Autotelic Code Exploration via Semantic descriptors), we introduce a new
autotelic generation method that leverages semantic descriptors produced by a
large language model (LLM) to directly optimize for interesting diversity, as
well as few-shot-based generation. Each puzzle is labeled along 10 dimensions,
each capturing a programming skill required to solve it. ACES generates and
pursues novel and feasible goals to explore that abstract semantic space,
slowly discovering a diversity of solvable programming puzzles in any given
run. Across a set of experiments, we show that ACES discovers a richer
diversity of puzzles than existing diversity-maximizing algorithms as measured
across a range of diversity metrics. We further study whether and in which
conditions this diversity can translate into the successful training of puzzle
solving models.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10693" title="Abstract">arXiv:2310.10693</a> [<a href="/pdf/2310.10693" title="Download PDF">pdf</a>, <a href="/format/2310.10693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Analysis of the iNaturalist Citizen Science Community
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+L">Yu Lu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiralerspong%2C+T">Thomas Jiralerspong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, citizen science has become a larger and larger part of the
scientific community. Its ability to crowd source data and expertise from
thousands of citizen scientists makes it invaluable. Despite the field's
growing popularity, the interactions and structure of citizen science projects
are still poorly understood and under analyzed. We use the iNaturalist citizen
science platform as a case study to analyze the structure of citizen science
projects. We frame the data from iNaturalist as a bipartite network and use
visualizations as well as established network science techniques to gain
insights into the structure and interactions between users in citizen science
projects. Finally, we propose a novel unique benchmark for network science
research by using the iNaturalist data to create a network which has an unusual
structure relative to other common benchmark networks. We demonstrate using a
link prediction task that this network can be used to gain novel insights into
a variety of network science methods.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10696" title="Abstract">arXiv:2310.10696</a> [<a href="/pdf/2310.10696" title="Download PDF">pdf</a>, <a href="/format/2310.10696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Collaborative Filtering to Popularity Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">An Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenchang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jingnan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-seng Chua</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Information Systems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In leading collaborative filtering (CF) models, representations of users and
items are prone to learn popularity bias in the training data as shortcuts. The
popularity shortcut tricks are good for in-distribution (ID) performance but
poorly generalized to out-of-distribution (OOD) data, i.e., when popularity
distribution of test data shifts w.r.t. the training one. To close the gap,
debiasing strategies try to assess the shortcut degrees and mitigate them from
the representations. However, there exist two deficiencies: (1) when measuring
the shortcut degrees, most strategies only use statistical metrics on a single
aspect (i.e., item frequency on item and user frequency on user aspect),
failing to accommodate the compositional degree of a user-item pair; (2) when
mitigating shortcuts, many strategies assume that the test distribution is
known in advance. This results in low-quality debiased representations. Worse
still, these strategies achieve OOD generalizability with a sacrifice on ID
performance. In this work, we present a simple yet effective debiasing
strategy, PopGo, which quantifies and reduces the interaction-wise popularity
shortcut without any assumptions on the test data. It first learns a shortcut
model, which yields a shortcut degree of a user-item pair based on their
popularity representations. Then, it trains the CF model by adjusting the
predictions with the interaction-wise shortcut degrees. By taking both causal-
and information-theoretical looks at PopGo, we can justify why it encourages
the CF model to capture the critical popularity-agnostic features while leaving
the spurious popularity-relevant patterns out. We use PopGo to debias two
high-performing CF models (MF, LightGCN) on four benchmark datasets. On both ID
and OOD test sets, PopGo achieves significant gains over the state-of-the-art
debiasing strategies (e.g., DICE, MACR).
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10698" title="Abstract">arXiv:2310.10698</a> [<a href="/pdf/2310.10698" title="Download PDF">pdf</a>, <a href="/format/2310.10698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Code Semantic and LLMs: Semantic Chain-of-Thought Prompting for  Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yingwei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanshan Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yutao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xiangke Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have showcased remarkable prowess in code
generation. However, automated code generation is still challenging since it
requires a high-level semantic mapping between natural language requirements
and codes. Most existing LLMs-based approaches for code generation rely on
decoder-only causal language models often treate codes merely as plain text
tokens \ie feeding the requirements as a prompt input, and outputing code as
flat sequence of tokens, potentially missing the rich semantic features
inherent in source code. To bridge this gap, this paper proposes the "Semantic
Chain-of-Thought" approach to intruduce semantic information of code, named
SeCoT. Our motivation is that the semantic information of the source code (\eg
data flow and control flow) describes more precise program execution behavior,
intention and function. By guiding LLM consider and integrate semantic
information, we can achieve a more granular understanding and representation of
code, enhancing code generation accuracy. Meanwhile, while traditional
techniques leveraging such semantic information require complex static or
dynamic code analysis to obtain features such as data flow and control flow,
SeCoT demonstrates that this process can be fully automated via the intrinsic
capabilities of LLMs (\ie in-context learning), while being generalizable and
applicable to challenging domains. While SeCoT can be applied with different
LLMs, this paper focuses on the powerful GPT-style models: ChatGPT(close-source
model) and WizardCoder(open-source model). The experimental study on three
popular DL benchmarks (\ie HumanEval, HumanEval-ET and MBPP) shows that SeCoT
can achieves state-of-the-art performance, greatly improving the potential for
large models and code generation.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10699" title="Abstract">arXiv:2310.10699</a> [<a href="/pdf/2310.10699" title="Download PDF">pdf</a>, <a href="/format/2310.10699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reusing Pretrained Models by Multi-linear Operators for Efficient  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yichun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lifeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Training large models from scratch usually costs a substantial amount of
resources. Towards this problem, recent studies such as bert2BERT and LiGO have
reused small pretrained models to initialize a large model (termed the ``target
model''), leading to a considerable acceleration in training. Despite the
successes of these previous studies, they grew pretrained models by mapping
partial weights only, ignoring potential correlations across the entire model.
As we show in this paper, there are inter- and intra-interactions among the
weights of both the pretrained and the target models. As a result, the partial
mapping may not capture the complete information and lead to inadequate growth.
In this paper, we propose a method that linearly correlates each weight of the
target model to all the weights of the pretrained model to further enhance
acceleration ability. We utilize multi-linear operators to reduce computational
and spacial complexity, enabling acceptable resource requirements. Experiments
demonstrate that our method can save 76\% computational costs on DeiT-base
transferred from DeiT-small, which outperforms bert2BERT by +12.0\% and LiGO by
+20.7\%, respectively.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10700" title="Abstract">arXiv:2310.10700</a> [<a href="/pdf/2310.10700" title="Download PDF">pdf</a>, <a href="/format/2310.10700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PELA: Learning Parameter-Efficient Models with Low-Rank Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yangyang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Applying a pre-trained large model to downstream tasks is prohibitive under
resource-constrained conditions. Recent dominant approaches for addressing
efficiency issues involve adding a few learnable parameters to the fixed
backbone model. This strategy, however, leads to more challenges in loading
large models for downstream fine-tuning with limited resources. In this paper,
we propose a novel method for increasing the parameter efficiency of
pre-trained models by introducing an intermediate pre-training stage. To this
end, we first employ low-rank approximation to compress the original large
model and then devise a feature distillation module and a weight perturbation
regularization module. These modules are specifically designed to enhance the
low-rank model. Concretely, we update only the low-rank model while freezing
the backbone parameters during pre-training. This allows for direct and
efficient utilization of the low-rank model for downstream tasks. The proposed
method achieves both efficiencies in terms of required parameters and
computation time while maintaining comparable results with minimal
modifications to the base architecture. Specifically, when applied to three
vision-only and one vision-language Transformer models, our approach often
demonstrates a $\sim$0.6 point decrease in performance while reducing the
original parameter size by 1/3 to 2/3.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10701" title="Abstract">arXiv:2310.10701</a> [<a href="/pdf/2310.10701" title="Download PDF">pdf</a>, <a href="/format/2310.10701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theory of Mind for Multi-Agent Collaboration via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+Y+Q">Yu Quan Chong</a>, 
<a href="/search/cs?searchtype=author&query=Stepputtis%2C+S">Simon Stepputtis</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+J">Joseph Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+D">Dana Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Michael Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Sycara%2C+K">Katia Sycara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 (Main Conference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While Large Language Models (LLMs) have demonstrated impressive
accomplishments in both reasoning and planning, their abilities in multi-agent
collaborations remains largely unexplored. This study evaluates LLM-based
agents in a multi-agent cooperative text game with Theory of Mind (ToM)
inference tasks, comparing their performance with Multi-Agent Reinforcement
Learning (MARL) and planning-based baselines. We observed evidence of emergent
collaborative behaviors and high-order Theory of Mind capabilities among
LLM-based agents. Our results reveal limitations in LLM-based agents' planning
optimization due to systematic failures in managing long-horizon contexts and
hallucination about the task state. We explore the use of explicit belief state
representations to mitigate these issues, finding that it enhances task
performance and the accuracy of ToM inferences for LLM-based agents.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10702" title="Abstract">arXiv:2310.10702</a> [<a href="/pdf/2310.10702" title="Download PDF">pdf</a>, <a href="/format/2310.10702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transparent Anomaly Detection via Concept-based Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sevyeri%2C+L+R">Laya Rafiee Sevyeri</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+I">Ivaxi Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Farahnak%2C+F">Farhood Farahnak</a>, 
<a href="/search/cs?searchtype=author&query=Enger%2C+S+A">Shirin Abbasinejad Enger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Advancements in deep learning techniques have given a boost to the
performance of anomaly detection. However, real-world and safety-critical
applications demand a level of transparency and reasoning beyond accuracy. The
task of anomaly detection (AD) focuses on finding whether a given sample
follows the learned distribution. Existing methods lack the ability to reason
with clear explanations for their outcomes. Hence to overcome this challenge,
we propose Transparent {A}nomaly Detection {C}oncept {E}xplanations (ACE). ACE
is able to provide human interpretable explanations in the form of concepts
along with anomaly prediction. To the best of our knowledge, this is the first
paper that proposes interpretable by-design anomaly detection. In addition to
promoting transparency in AD, it allows for effective human-model interaction.
Our proposed model shows either higher or comparable results to black-box
uninterpretable models. We validate the performance of ACE across three
realistic datasets - bird classification on CUB-200-2011, challenging
histopathology slide image classification on TIL-WSI-TCGA, and gender
classification on CelebA. We further demonstrate that our concept learning
paradigm can be seamlessly integrated with other classification-based AD
methods.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10704" title="Abstract">arXiv:2310.10704</a> [<a href="/pdf/2310.10704" title="Download PDF">pdf</a>, <a href="/format/2310.10704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Tokenization for Transcribed Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wullach%2C+T">Tomer Wullach</a>, 
<a href="/search/cs?searchtype=author&query=Chazan%2C+S+E">Shlomo E. Chazan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The challenges facing speech recognition systems, such as variations in
pronunciations, adverse audio conditions, and the scarcity of labeled data,
emphasize the necessity for a post-processing step that corrects recurring
errors. Previous research has shown the advantages of employing dedicated error
correction models, yet training such models requires large amounts of labeled
data which is not easily obtained. To overcome this limitation, synthetic
transcribed-like data is often utilized, however, bridging the distribution gap
between transcribed errors and synthetic noise is not trivial. In this paper,
we demonstrate that the performance of correction models can be significantly
increased by training solely using synthetic data. Specifically, we empirically
show that: (1) synthetic data generated using the error distribution derived
from a set of transcribed data outperforms the common approach of applying
random perturbations; (2) applying language-specific adjustments to the
vocabulary of a BPE tokenizer strike a balance between adapting to unseen
distributions and retaining knowledge of transcribed errors. We showcase the
benefits of these key observations, and evaluate our approach using multiple
languages, speech recognition systems and prominent speech recognition
datasets.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10705" title="Abstract">arXiv:2310.10705</a> [<a href="/pdf/2310.10705" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Techniques for Identifying the Defective Patterns in  Semiconductor Wafer Maps: A Survey, Empirical, and Experimental Evaluations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taha%2C+K">Kamal Taha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This survey paper offers a comprehensive review of methodologies utilizing
machine learning (ML) techniques for identifying wafer defects in semiconductor
manufacturing. Despite the growing body of research demonstrating the
effectiveness of ML in wafer defect identification, there is a noticeable
absence of comprehensive reviews on this subject. This survey attempts to fill
this void by amalgamating available literature and providing an in-depth
analysis of the advantages, limitations, and potential applications of various
ML algorithms in the realm of wafer defect detection. An innovative taxonomy of
methodologies that we present provides a detailed classification of algorithms
into more refined categories and techniques. This taxonomy follows a four-tier
structure, starting from broad methodology categories and ending with specific
sub-techniques. It aids researchers in comprehending the complex relationships
between different algorithms and their techniques. We employ a rigorous
empirical and experimental evaluation to rank these varying techniques. For the
empirical evaluation, we assess techniques based on a set of four criteria. The
experimental evaluation ranks the algorithms employing the same sub-techniques,
techniques, sub-categories, and categories. This integration of a multi-layered
taxonomy, empirical evaluations, and comparative experiments provides a
detailed and holistic understanding of ML techniques and algorithms for
identifying wafer defects. This approach guides researchers towards making more
informed decisions in their work. Additionally, the paper illuminates the
future prospects of ML techniques for wafer defect identification, underscoring
potential advancements and opportunities for further research in this field
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10706" title="Abstract">arXiv:2310.10706</a> [<a href="/pdf/2310.10706" title="Download PDF">pdf</a>, <a href="/format/2310.10706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Power of LLMs: Evaluating Human-AI text Co-Creation  through the Lens of News Headline Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zijian Ding</a>, 
<a href="/search/cs?searchtype=author&query=Smith-Renner%2C+A">Alison Smith-Renner</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tetreault%2C+J+R">Joel R. Tetreault</a>, 
<a href="/search/cs?searchtype=author&query=Jaimes%2C+A">Alejandro Jaimes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">To explore how humans can best leverage LLMs for writing and how interacting
with these models affects feelings of ownership and trust in the writing
process, we compared common human-AI interaction types (e.g., guiding system,
selecting from system outputs, post-editing outputs) in the context of
LLM-assisted news headline generation. While LLMs alone can generate
satisfactory news headlines, on average, human control is needed to fix
undesirable model outputs. Of the interaction methods, guiding and selecting
model output added the most benefit with the lowest cost (in time and effort).
Further, AI assistance did not harm participants' perception of control
compared to freeform editing.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10707" title="Abstract">arXiv:2310.10707</a> [<a href="/pdf/2310.10707" title="Download PDF">pdf</a>, <a href="/format/2310.10707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demonstrations Are All You Need: Advancing Offensive Content  Paraphrasing using In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Som%2C+A">Anirudh Som</a>, 
<a href="/search/cs?searchtype=author&query=Sikka%2C+K">Karan Sikka</a>, 
<a href="/search/cs?searchtype=author&query=Gent%2C+H">Helen Gent</a>, 
<a href="/search/cs?searchtype=author&query=Divakaran%2C+A">Ajay Divakaran</a>, 
<a href="/search/cs?searchtype=author&query=Kathol%2C+A">Andreas Kathol</a>, 
<a href="/search/cs?searchtype=author&query=Vergyri%2C+D">Dimitra Vergyri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Paraphrasing of offensive content is a better alternative to content removal
and helps improve civility in a communication environment. Supervised
paraphrasers; however, rely heavily on large quantities of labelled data to
help preserve meaning and intent. They also retain a large portion of the
offensiveness of the original content, which raises questions on their overall
usability. In this paper we aim to assist practitioners in developing usable
paraphrasers by exploring In-Context Learning (ICL) with large language models
(LLMs), i.e., using a limited number of input-label demonstration pairs to
guide the model in generating desired outputs for specific queries. Our study
focuses on key factors such as -- number and order of demonstrations, exclusion
of prompt instruction, and reduction in measured toxicity. We perform
principled evaluation on three datasets, including our proposed Context-Aware
Polite Paraphrase dataset, comprising of dialogue-style rude utterances, polite
paraphrases, and additional dialogue context. We evaluate our approach using
two closed source and one open source LLM. Our results reveal that ICL is
comparable to supervised methods in generation quality, while being
qualitatively better by 25% on human evaluation and attaining lower toxicity by
76%. Also, ICL-based paraphrasers only show a slight reduction in performance
even with just 10% training data.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10708" title="Abstract">arXiv:2310.10708</a> [<a href="/pdf/2310.10708" title="Download PDF">pdf</a>, <a href="/format/2310.10708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Natural Language Explanation of Deep Visual Neurons with Large  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenxu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Wei Qian</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yucheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huai%2C+M">Mengdi Huai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep neural networks have exhibited remarkable performance across a wide
range of real-world tasks. However, comprehending the underlying reasons for
their effectiveness remains a challenging problem. Interpreting deep neural
networks through examining neurons offers distinct advantages when it comes to
exploring the inner workings of neural networks. Previous research has
indicated that specific neurons within deep vision networks possess semantic
meaning and play pivotal roles in model performance. Nonetheless, the current
methods for generating neuron semantics heavily rely on human intervention,
which hampers their scalability and applicability. To address this limitation,
this paper proposes a novel post-hoc framework for generating semantic
explanations of neurons with large foundation models, without requiring human
intervention or prior knowledge. Our framework is designed to be compatible
with various model architectures and datasets, facilitating automated and
scalable neuron interpretation. Experiments are conducted with both qualitative
and quantitative analysis to verify the effectiveness of our proposed approach.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10735" title="Abstract">arXiv:2310.10735</a> [<a href="/pdf/2310.10735" title="Download PDF">pdf</a>, <a href="/format/2310.10735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Persona Consistent Dialogue Agents with Offline Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shea%2C+R">Ryan Shea</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Maintaining a consistent persona is a key quality for any open domain
dialogue system. Current state-of-the-art systems do this by training agents
with supervised learning or online reinforcement learning (RL). However,
systems trained with supervised learning often lack consistency as they are
never punished for uttering contradictions. Additional training with RL can
alleviate some of these issues, however the training process is expensive.
Instead, we propose an offline RL framework to improve the persona consistency
of dialogue systems. Our framework allows us to combine the advantages of
previous methods as we can inexpensively train our model on existing data as in
supervised learning, while punishing and rewarding specific utterances as in
RL. We also introduce a simple importance sampling method to reduce the
variance of importance weights in offline RL training which we call
Variance-Reducing MLE-Initialized (VaRMI) importance sampling. Our automatic
and human evaluations show that our framework improves both the persona
consistency and dialogue quality of a state-of-the-art social chatbot.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10737" title="Abstract">arXiv:2310.10737</a> [<a href="/pdf/2310.10737" title="Download PDF">pdf</a>, <a href="/ps/2310.10737" title="Download PostScript">ps</a>, <a href="/format/2310.10737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outperforming 5 LDPCs with GRAND over long, low rate codes -- making a  long story short
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+P">Peihong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Medard%2C+M">Muriel Medard</a>, 
<a href="/search/cs?searchtype=author&query=Galligan%2C+K">Kevin Galligan</a>, 
<a href="/search/cs?searchtype=author&query=Duffy%2C+K+R">Ken R. Duffy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2305.05777">arXiv:2305.05777</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We establish that a large and flexible class of long, high redundancy error
correcting codes can be efficiently and accurately decoded with guessing random
additive noise decoding (GRAND). Performance evaluation demonstrates that it is
possible to construct simple concatenated codes that outperform LDPC codes in
the 5G New Radio standard. The concatenated structure enables many desirable
features, including: low-complexity hardware-friendly encoding and decoding;
high levels of flexibility in length and rate through modularity; and high
levels of parallelism in decoding that enable low latency.
<br />Central to this is the development of a method through which any soft-input
GRAND algorithm can provide soft-output in the form of an accurate a posteriori
estimate of the likelihood that a decoding is correct or, in the case of list
decoding, the likelihood that each element of the list is correct. The key
distinguishing feature of the soft-output in comparison to other methods is the
provision of an estimate that the correct decoding has not been found, even
when providing a single decoding. That per-block soft-output can be converted
into accurate per-bit soft-output by a weighted sum that includes a term for
the soft-input. Crucially, implementing the method for generating soft-output
adds negligible additional computation and memory to the existing decoding
process, and using it results in a practical alternative to LDPC codes.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10744" title="Abstract">arXiv:2310.10744</a> [<a href="/pdf/2310.10744" title="Download PDF">pdf</a>, <a href="/format/2310.10744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Adversarial Label-Flipping Attack on Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xinglong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Dobbie%2C+G">Gillian Dobbie</a>, 
<a href="/search/cs?searchtype=author&query=Wicker%2C+J">J&#xf6;rg Wicker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning models are increasingly used in fields that require high
reliability such as cybersecurity. However, these models remain vulnerable to
various attacks, among which the adversarial label-flipping attack poses
significant threats. In label-flipping attacks, the adversary maliciously flips
a portion of training labels to compromise the machine learning model. This
paper raises significant concerns as these attacks can camouflage a highly
skewed dataset as an easily solvable classification problem, often misleading
machine learning practitioners into lower defenses and miscalculations of
potential risks. This concern amplifies in tabular data settings, where
identifying true labels requires expertise, allowing malicious label-flipping
attacks to easily slip under the radar. To demonstrate this risk is inherited
in the adversary's objective, we propose FALFA (Fast Adversarial Label-Flipping
Attack), a novel efficient attack for crafting adversarial labels. FALFA is
based on transforming the adversary's objective and employs linear programming
to reduce computational complexity. Using ten real-world tabular datasets, we
demonstrate FALFA's superior attack potential, highlighting the need for robust
defenses against such threats.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10745" title="Abstract">arXiv:2310.10745</a> [<a href="/pdf/2310.10745" title="Download PDF">pdf</a>, <a href="/format/2310.10745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mori-Zwanzig latent space Koopman closure for nonlinear autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Priyam Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+P+J">Peter J. Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Sipp%2C+D">Denis Sipp</a>, 
<a href="/search/cs?searchtype=author&query=Sayadi%2C+T">Taraneh Sayadi</a>, 
<a href="/search/cs?searchtype=author&query=Rigas%2C+G">Georgios Rigas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Fluid Dynamics (physics.flu-dyn); Machine Learning (stat.ML)

</div>
<p class="mathjax">The Koopman operator presents an attractive approach to achieve global
linearization of nonlinear systems, making it a valuable method for simplifying
the understanding of complex dynamics. While data-driven methodologies have
exhibited promise in approximating finite Koopman operators, they grapple with
various challenges, such as the judicious selection of observables,
dimensionality reduction, and the ability to predict complex system behaviours
accurately. This study presents a novel approach termed Mori-Zwanzig
autoencoder (MZ-AE) to robustly approximate the Koopman operator in
low-dimensional spaces. The proposed method leverages a nonlinear autoencoder
to extract key observables for approximating a finite invariant Koopman
subspace and integrates a non-Markovian correction mechanism using the
Mori-Zwanzig formalism. Consequently, this approach yields a closed
representation of dynamics within the latent manifold of the nonlinear
autoencoder, thereby enhancing the precision and stability of the Koopman
operator approximation. Demonstrations showcase the technique's ability to
capture regime transitions in the flow around a circular cylinder. It also
provided a low dimensional approximation for chaotic Kuramoto-Sivashinsky with
promising short-term predictability and robust long-term statistical
performance. By bridging the gap between data-driven techniques and the
mathematical foundations of Koopman theory, MZ-AE offers a promising avenue for
improved understanding and prediction of complex nonlinear dynamics.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10750" title="Abstract">arXiv:2310.10750</a> [<a href="/pdf/2310.10750" title="Download PDF">pdf</a>, <a href="/format/2310.10750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multifidelity Methods for Uncertainty Quantification of a Nonlocal Model  for Phase Changes in Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khodabakhshi%2C+P">Parisa Khodabakhshi</a>, 
<a href="/search/cs?searchtype=author&query=Burkovska%2C+O">Olena Burkovska</a>, 
<a href="/search/cs?searchtype=author&query=Willcox%2C+K">Karen Willcox</a>, 
<a href="/search/cs?searchtype=author&query=Gunzburger%2C+M">Max Gunzburger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This study is devoted to the construction of a multifidelity Monte Carlo
(MFMC) method for the uncertainty quantification of a nonlocal,
non-mass-conserving Cahn-Hilliard model for phase transitions with an obstacle
potential. We are interested in the estimation of the expected value of an
output of interest (OoI) that depends on the solution of the nonlocal
Cahn-Hilliard model. As opposed to its local counterpart, the nonlocal model
captures sharp interfaces without the need for significant mesh refinement.
However, the computational cost of the nonlocal Cahn-Hilliard model is higher
than that of its local counterpart with similar mesh refinement, inhibiting its
use for outer-loop applications such as uncertainty quantification. The MFMC
method augments the desired high-fidelity, high-cost OoI with a set of
lower-fidelity, lower-cost OoIs to alleviate the computational burden
associated with nonlocality. Most of the computational budget is allocated to
sampling the cheap surrogate models to achieve speedup, whereas the
high-fidelity model is sparsely sampled to maintain accuracy. For the
non-mass-conserving nonlocal Cahn-Hilliard model, the use of the MFMC method
results in, for a given computational budget, about one-order-of-magnitude
reduction in the mean-squared error of the expected value of the OoI relative
to that of the Monte Carlo method.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10755" title="Abstract">arXiv:2310.10755</a> [<a href="/pdf/2310.10755" title="Download PDF">pdf</a>, <a href="/format/2310.10755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IDRNet: Intervention-Driven Relation Network for Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhenchao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaowei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lingting Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Luchuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lequan Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPs 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Co-occurrent visual patterns suggest that pixel relation modeling facilitates
dense prediction tasks, which inspires the development of numerous context
modeling paradigms, \emph{e.g.}, multi-scale-driven and similarity-driven
context schemes. Despite the impressive results, these existing paradigms often
suffer from inadequate or ineffective contextual information aggregation due to
reliance on large amounts of predetermined priors. To alleviate the issues, we
propose a novel \textbf{I}ntervention-\textbf{D}riven \textbf{R}elation
\textbf{Net}work (\textbf{IDRNet}), which leverages a deletion diagnostics
procedure to guide the modeling of contextual relations among different pixels.
Specifically, we first group pixel-level representations into semantic-level
representations with the guidance of pseudo labels and further improve the
distinguishability of the grouped representations with a feature enhancement
module. Next, a deletion diagnostics procedure is conducted to model relations
of these semantic-level representations via perceiving the network outputs and
the extracted relations are utilized to guide the semantic-level
representations to interact with each other. Finally, the interacted
representations are utilized to augment original pixel-level representations
for final predictions. Extensive experiments are conducted to validate the
effectiveness of IDRNet quantitatively and qualitatively. Notably, our
intervention-driven context scheme brings consistent performance improvements
to state-of-the-art segmentation frameworks and achieves competitive results on
popular benchmark datasets, including ADE20K, COCO-Stuff, PASCAL-Context, LIP,
and Cityscapes. Code is available at
\url{https://github.com/SegmentationBLWX/sssegmentation}.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10760" title="Abstract">arXiv:2310.10760</a> [<a href="/pdf/2310.10760" title="Download PDF">pdf</a>, <a href="/format/2310.10760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards reducing hallucination in extracting information from financial  reports using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarmah%2C+B">Bhaskarjit Sarmah</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tianjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+D">Dhagash Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Pasquali%2C+S">Stefano Pasquali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages + references. Accepted for publication in Workshop on Generative AI at the 3rd International Conference on AI-ML Systems 2023, Bengaluru, India
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Portfolio Management (q-fin.PM); Statistical Finance (q-fin.ST); Applications (stat.AP)

</div>
<p class="mathjax">For a financial analyst, the question and answer (Q\&amp;A) segment of the
company financial report is a crucial piece of information for various analysis
and investment decisions. However, extracting valuable insights from the Q\&amp;A
section has posed considerable challenges as the conventional methods such as
detailed reading and note-taking lack scalability and are susceptible to human
errors, and Optical Character Recognition (OCR) and similar techniques
encounter difficulties in accurately processing unstructured transcript text,
often missing subtle linguistic nuances that drive investor decisions. Here, we
demonstrate the utilization of Large Language Models (LLMs) to efficiently and
rapidly extract information from earnings report transcripts while ensuring
high accuracy transforming the extraction process as well as reducing
hallucination by combining retrieval-augmented generation technique as well as
metadata. We evaluate the outcomes of various LLMs with and without using our
proposed approach based on various objective metrics for evaluating Q\&amp;A
systems, and empirically demonstrate superiority of our method.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10762" title="Abstract">arXiv:2310.10762</a> [<a href="/pdf/2310.10762" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring hyperelastic material model discovery for human brain cortex:  multivariate analysis vs. artificial neural network approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jixin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Filla%2C+N">Nicholas Filla</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Razavi%2C+M+J">Mir Jalil Razavi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianqiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traditional computational methods, such as the finite element analysis, have
provided valuable insights into uncovering the underlying mechanisms of brain
physical behaviors. However, precise predictions of brain physics require
effective constitutive models to represent the intricate mechanical properties
of brain tissue. In this study, we aimed to identify the most favorable
constitutive material model for human brain tissue. To achieve this, we applied
artificial neural network and multiple regression methods to a generalization
of widely accepted classic models, and compared the results obtained from these
two approaches. To evaluate the applicability and efficacy of the model, all
setups were kept consistent across both methods, except for the approach to
prevent potential overfitting. Our results demonstrate that artificial neural
networks are capable of automatically identifying accurate constitutive models
from given admissible estimators. Nonetheless, the five-term and two-term
neural network models trained under single-mode and multi-mode loading
scenarios, were found to be suboptimal and could be further simplified into
two-term and single-term, respectively, with higher accuracy using multiple
regression. Our findings highlight the importance of hyperparameters for the
artificial neural network and emphasize the necessity for detailed
cross-validations of regularization parameters to ensure optimal selection at a
global level in the development of material constitutive models. This study
validates the applicability and accuracy of artificial neural network to
automatically discover constitutive material models with proper regularization
as well as the benefits in model simplification without compromising accuracy
for traditional multivariable regression.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10765" title="Abstract">arXiv:2310.10765</a> [<a href="/pdf/2310.10765" title="Download PDF">pdf</a>, <a href="/format/2310.10765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiomedJourney: Counterfactual Biomedical Image Generation by  Instruction-Learning from Multimodal Patient Journeys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Usuyama%2C+N">Naoto Usuyama</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lungren%2C+M+P">Matthew P. Lungren</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+H">Hoifung Poon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Rapid progress has been made in instruction-learning for image editing with
natural-language instruction, as exemplified by InstructPix2Pix. In
biomedicine, such methods can be applied to counterfactual image generation,
which helps differentiate causal structure from spurious correlation and
facilitate robust image interpretation for disease progression modeling.
However, generic image-editing models are ill-suited for the biomedical domain,
and counterfactual biomedical image generation is largely underexplored. In
this paper, we present BiomedJourney, a novel method for counterfactual
biomedical image generation by instruction-learning from multimodal patient
journeys. Given a patient with two biomedical images taken at different time
points, we use GPT-4 to process the corresponding imaging reports and generate
a natural language description of disease progression. The resulting triples
(prior image, progression description, new image) are then used to train a
latent diffusion model for counterfactual biomedical image generation. Given
the relative scarcity of image time series data, we introduce a two-stage
curriculum that first pretrains the denoising network using the much more
abundant single image-report pairs (with dummy prior image), and then continues
training using the counterfactual triples. Experiments using the standard
MIMIC-CXR dataset demonstrate the promise of our method. In a comprehensive
battery of tests on counterfactual medical image generation, BiomedJourney
substantially outperforms prior state-of-the-art methods in instruction image
editing and medical image generation such as InstructPix2Pix and RoentGen. To
facilitate future study in counterfactual medical generation, we plan to
release our instruction-learning code and pretrained models.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10766" title="Abstract">arXiv:2310.10766</a> [<a href="/pdf/2310.10766" title="Download PDF">pdf</a>, <a href="/format/2310.10766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearly Optimal Approximation Rates for Deep Super ReLU Networks on  Sobolev Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yahong Yang</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+H">Haizhao Yang</a>, 
<a href="/search/math?searchtype=author&query=Xiang%2C+Y">Yang Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2305.08466">arXiv:2305.08466</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces deep super ReLU networks (DSRNs) as a method for
approximating functions in Sobolev spaces measured by Sobolev norms $W^{m,p}$
for $m\in\mathbb{N}$ with $m\ge 2$ and $1\le p\le +\infty$. Standard ReLU deep
neural networks (ReLU DNNs) cannot achieve this goal. DSRNs consist primarily
of ReLU DNNs, and several layers of the square of ReLU added at the end to
smooth the networks output. This approach retains the advantages of ReLU DNNs,
leading to the straightforward training. The paper also proves the optimality
of DSRNs by estimating the VC-dimension of higher-order derivatives of DNNs,
and obtains the generalization error in Sobolev spaces via an estimate of the
pseudo-dimension of higher-order derivatives of DNNs.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10767" title="Abstract">arXiv:2310.10767</a> [<a href="/pdf/2310.10767" title="Download PDF">pdf</a>, <a href="/ps/2310.10767" title="Download PostScript">ps</a>, <a href="/format/2310.10767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wide Neural Networks as Gaussian Processes: Lessons from Deep  Equilibrium Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tianxiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+X">Xiaokai Huo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hailiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hongyang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Neural networks with wide layers have attracted significant attention due to
their equivalence to Gaussian processes, enabling perfect fitting of training
data while maintaining generalization performance, known as benign overfitting.
However, existing results mainly focus on shallow or finite-depth networks,
necessitating a comprehensive analysis of wide neural networks with
infinite-depth layers, such as neural ordinary differential equations (ODEs)
and deep equilibrium models (DEQs). In this paper, we specifically investigate
the deep equilibrium model (DEQ), an infinite-depth neural network with shared
weight matrices across layers. Our analysis reveals that as the width of DEQ
layers approaches infinity, it converges to a Gaussian process, establishing
what is known as the Neural Network and Gaussian Process (NNGP) correspondence.
Remarkably, this convergence holds even when the limits of depth and width are
interchanged, which is not observed in typical infinite-depth Multilayer
Perceptron (MLP) networks. Furthermore, we demonstrate that the associated
Gaussian vector remains non-degenerate for any pairwise distinct input data,
ensuring a strictly positive smallest eigenvalue of the corresponding kernel
matrix using the NNGP kernel. These findings serve as fundamental elements for
studying the training and generalization of DEQs, laying the groundwork for
future research in this area.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10768" title="Abstract">arXiv:2310.10768</a> [<a href="/pdf/2310.10768" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security in Cryptocurrency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Medina%2C+C">Chelsea Medina</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+L">Lily Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Vargas%2C+D">Dissy Vargas</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+S">Sundar Krishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper discusses the mechanisms of cryptocurrency, the idea of using
security in the system, and the popularity of it. To begin, the authors provide
a background on cryptocurrency and how it works. The authors understand that
while most people may be familiar with the concept, they may not know how it
works. Next, the authors discuss the security of cryptocurrency in-depth within
the paper. The authors also provide examples of attacks on cryptocurrency
systems to show the vulnerabilities within the system. Lastly, the authors
discuss the popularity of the system to further express the need for security
in cryptocurrency.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10769" title="Abstract">arXiv:2310.10769</a> [<a href="/pdf/2310.10769" title="Download PDF">pdf</a>, <a href="/format/2310.10769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAMP: Learn A Motion Pattern for Few-Shot-Based Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruiqi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liangyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chunle Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://rq-wu.github.io/projects/LAMP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the impressive progress in diffusion-based text-to-image generation,
extending such powerful generative ability to text-to-video raises enormous
attention. Existing methods either require large-scale text-video pairs and a
large number of training resources or learn motions that are precisely aligned
with template videos. It is non-trivial to balance a trade-off between the
degree of generation freedom and the resource costs for video generation. In
our study, we present a few-shot-based tuning framework, LAMP, which enables
text-to-image diffusion model Learn A specific Motion Pattern with 8~16 videos
on a single GPU. Specifically, we design a first-frame-conditioned pipeline
that uses an off-the-shelf text-to-image model for content generation so that
our tuned video diffusion model mainly focuses on motion learning. The
well-developed text-to-image techniques can provide visually pleasing and
diverse content as generation conditions, which highly improves video quality
and generation freedom. To capture the features of temporal dimension, we
expand the pretrained 2D convolution layers of the T2I model to our novel
temporal-spatial motion learning layers and modify the attention blocks to the
temporal level. Additionally, we develop an effective inference trick,
shared-noise sampling, which can improve the stability of videos with
computational costs. Our method can also be flexibly applied to other tasks,
e.g. real-world image animation and video editing. Extensive experiments
demonstrate that LAMP can effectively learn the motion pattern on limited data
and generate high-quality videos. The code and models are available at
https://rq-wu.github.io/projects/LAMP.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10772" title="Abstract">arXiv:2310.10772</a> [<a href="/pdf/2310.10772" title="Download PDF">pdf</a>, <a href="/format/2310.10772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Lead Sheet Generation via Semantic Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Novack%2C+Z">Zachary Novack</a>, 
<a href="/search/cs?searchtype=author&query=Srivatsan%2C+N">Nikita Srivatsan</a>, 
<a href="/search/cs?searchtype=author&query=Berg-Kirkpatrick%2C+T">Taylor Berg-Kirkpatrick</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Lead sheets have become commonplace in generative music research, being used
as an initial compressed representation for downstream tasks like multitrack
music generation and automatic arrangement. Despite this, researchers have
often fallen back on deterministic reduction methods (such as the skyline
algorithm) to generate lead sheets when seeking paired lead sheets and full
scores, with little attention being paid toward the quality of the lead sheets
themselves and how they accurately reflect their orchestrated counterparts. To
address these issues, we propose the problem of conditional lead sheet
generation (i.e. generating a lead sheet given its full score version), and
show that this task can be formulated as an unsupervised music compression
task, where the lead sheet represents a compressed latent version of the score.
We introduce a novel model, called Lead-AE, that models the lead sheets as a
discrete subselection of the original sequence, using a differentiable top-k
operator to allow for controllable local sparsity constraints. Across both
automatic proxy tasks and direct human evaluations, we find that our method
improves upon the established deterministic baseline and produces coherent
reductions of large multitrack scores.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10773" title="Abstract">arXiv:2310.10773</a> [<a href="/pdf/2310.10773" title="Download PDF">pdf</a>, <a href="/format/2310.10773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gotta be SAFE: A New Framework for Molecular Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noutahi%2C+E">Emmanuel Noutahi</a>, 
<a href="/search/cs?searchtype=author&query=Gabellini%2C+C">Cristian Gabellini</a>, 
<a href="/search/cs?searchtype=author&query=Craig%2C+M">Michael Craig</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J+S+C">Jonathan S.C Lim</a>, 
<a href="/search/cs?searchtype=author&query=Tossou%2C+P">Prudencio Tossou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to a workshop at Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Traditional molecular string representations, such as SMILES, often pose
challenges for AI-driven molecular design due to their non-sequential depiction
of molecular substructures. To address this issue, we introduce Sequential
Attachment-based Fragment Embedding (SAFE), a novel line notation for chemical
structures. SAFE reimagines SMILES strings as an unordered sequence of
interconnected fragment blocks while maintaining full compatibility with
existing SMILES parsers. It streamlines complex generative tasks, including
scaffold decoration, fragment linking, polymer generation, and scaffold
hopping, while facilitating autoregressive generation for fragment-constrained
design, thereby eliminating the need for intricate decoding or graph-based
models. We demonstrate the effectiveness of SAFE by training an
87-million-parameter GPT2-like model on a dataset containing 1.1 billion SAFE
representations. Through extensive experimentation, we show that our SAFE-GPT
model exhibits versatile and robust optimization performance. SAFE opens up new
avenues for the rapid exploration of chemical space under various constraints,
promising breakthroughs in AI-driven molecular design.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10776" title="Abstract">arXiv:2310.10776</a> [<a href="/pdf/2310.10776" title="Download PDF">pdf</a>, <a href="/format/2310.10776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correcting model misspecification in physics-informed neural networks  (PINNs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zongren Zou</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xuhui Meng</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Data-driven discovery of governing equations in computational science has
emerged as a new paradigm for obtaining accurate physical models and as a
possible alternative to theoretical derivations. The recently developed
physics-informed neural networks (PINNs) have also been employed to learn
governing equations given data across diverse scientific disciplines. Despite
the effectiveness of PINNs for discovering governing equations, the physical
models encoded in PINNs may be misspecified in complex systems as some of the
physical processes may not be fully understood, leading to the poor accuracy of
PINN predictions. In this work, we present a general approach to correct the
misspecified physical models in PINNs for discovering governing equations,
given some sparse and/or noisy data. Specifically, we first encode the assumed
physical models, which may be misspecified, then employ other deep neural
networks (DNNs) to model the discrepancy between the imperfect models and the
observational data. Due to the expressivity of DNNs, the proposed method is
capable of reducing the computational errors caused by the model
misspecification and thus enables the applications of PINNs in complex systems
where the physical processes are not exactly known. Furthermore, we utilize the
Bayesian PINNs (B-PINNs) and/or ensemble PINNs to quantify uncertainties
arising from noisy and/or gappy data in the discovered governing equations. A
series of numerical examples including non-Newtonian channel and cavity flows
demonstrate that the added DNNs are capable of correcting the model
misspecification in PINNs and thus reduce the discrepancy between the physical
models and the observational data. We envision that the proposed approach will
extend the applications of PINNs for discovering governing equations in
problems where the physico-chemical or biological processes are not well
understood.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10777" title="Abstract">arXiv:2310.10777</a> [<a href="/pdf/2310.10777" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Spectrum Sensing Techniques in Cognitive Radio Systems Using  Time-Domain Symbol Cross-correlation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Temtam%2C+A">Ahmed Temtam</a>, 
<a href="/search/eess?searchtype=author&query=Popescu%2C+D">Dimitrie Popescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In order to enable spectrum sharing, spectrum sensing plays a crucial role in
wireless communication. The challenges in wireless spectrum require
collaboration among stakeholders to devise innovative solutions. This research
explores the use of a Cognitive Radio (CR) system that employs a Time-Domain
Symbol Cross-correlation (TDSC) based spectrum sensing algorithm. WiMAX and LTE
standards are utilized as case studies to demonstrate the efficacy of the TDSC
method. The study presents theoretical and simulation results and also suggests
future research to investigate the performance of the TDSC method in WiMAX and
LTE systems. Additionally, this study compares the spectrum sensing
capabilities of WiMAX and LTE.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10778" title="Abstract">arXiv:2310.10778</a> [<a href="/pdf/2310.10778" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is there a Trojan! : Literature survey and critical evaluation of the  latest ML based modern intrusion detection systems in IoT environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karanam%2C+V">Vishal Karanam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures, CIOS-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">IoT as a domain has grown so much in the last few years that it rivals that
of the mobile network environments in terms of data volumes as well as
cybersecurity threats. The confidentiality and privacy of data within IoT
environments have become very important areas of security research within the
last few years. More and more security experts are interested in designing
robust IDS systems to protect IoT environments as a supplement to the more
traditional security methods. Given that IoT devices are resource-constrained
and have a heterogeneous protocol stack, most traditional intrusion detection
approaches don't work well within these schematic boundaries. This has led
security researchers to innovate at the intersection of Machine Learning and
IDS to solve the shortcomings of non-learning based IDS systems in the IoT
ecosystem.
<br />Despite various ML algorithms already having high accuracy with IoT datasets,
we can see a lack of sufficient production grade models. This survey paper
details a comprehensive summary of the latest learning-based approaches used in
IoT intrusion detection systems, and conducts a thorough critical review of
these systems, potential pitfalls in ML pipelines, challenges from an ML
perspective, and discusses future research scope and recommendations.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10780" title="Abstract">arXiv:2310.10780</a> [<a href="/pdf/2310.10780" title="Download PDF">pdf</a>, <a href="/format/2310.10780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying Poisoning Backdoor Attacks from a Statistical Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xian%2C+X">Xun Xian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Ganghua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+J">Jayanth Srinivasa</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+A">Ashish Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+X">Xuan Bi</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Mingyi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jie Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The growing dependence on machine learning in real-world applications
emphasizes the importance of understanding and ensuring its safety. Backdoor
attacks pose a significant security risk due to their stealthy nature and
potentially serious consequences. Such attacks involve embedding triggers
within a learning model with the intention of causing malicious behavior when
an active trigger is present while maintaining regular functionality without
it. This paper evaluates the effectiveness of any backdoor attack incorporating
a constant trigger, by establishing tight lower and upper boundaries for the
performance of the compromised model on both clean and backdoor test data. The
developed theory answers a series of fundamental but previously underexplored
problems, including (1) what are the determining factors for a backdoor
attack's success, (2) what is the direction of the most effective backdoor
attack, and (3) when will a human-imperceptible trigger succeed. Our derived
understanding applies to both discriminative and generative models. We also
demonstrate the theory by conducting experiments using benchmark datasets and
state-of-the-art backdoor attack scenarios.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10781" title="Abstract">arXiv:2310.10781</a> [<a href="/pdf/2310.10781" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BanglaNLP at BLP-2023 Task 1: Benchmarking different Transformer Models  for Violence Inciting Text Detection in Bengali
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Saumajit Saha</a>, 
<a href="/search/cs?searchtype=author&query=Nanda%2C+A">Albert Nanda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents the system that we have developed while solving this
shared task on violence inciting text detection in Bangla. We explain both the
traditional and the recent approaches that we have used to make our models
learn. Our proposed system helps to classify if the given text contains any
threat. We studied the impact of data augmentation when there is a limited
dataset available. Our quantitative results show that finetuning a
multilingual-e5-base model performed the best in our task compared to other
transformer-based architectures. We obtained a macro F1 of 68.11\% in the test
set and our performance in this shared task is ranked at 23 in the leaderboard.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10783" title="Abstract">arXiv:2310.10783</a> [<a href="/pdf/2310.10783" title="Download PDF">pdf</a>, <a href="/format/2310.10783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Laplace-based strategies for Bayesian optimal experimental design with  nuisance uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartuska%2C+A">Arved Bartuska</a>, 
<a href="/search/math?searchtype=author&query=Espath%2C+L">Luis Espath</a>, 
<a href="/search/math?searchtype=author&query=Tempone%2C+R">Ra&#xfa;l Tempone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Finding the optimal design of experiments in the Bayesian setting typically
requires estimation and optimization of the expected information gain
functional. This functional consists of one outer and one inner integral,
separated by the logarithm function applied to the inner integral. When the
mathematical model of the experiment contains uncertainty about the parameters
of interest and nuisance uncertainty, (i.e., uncertainty about parameters that
affect the model but are not themselves of interest to the experimenter), two
inner integrals must be estimated. Thus, the already considerable computational
effort required to determine good approximations of the expected information
gain is increased further. The Laplace approximation has been applied
successfully in the context of experimental design in various ways, and we
propose two novel estimators featuring the Laplace approximation to alleviate
the computational burden of both inner integrals considerably. The first
estimator applies Laplace's method followed by a Laplace approximation,
introducing a bias. The second estimator uses two Laplace approximations as
importance sampling measures for Monte Carlo approximations of the inner
integrals. Both estimators use Monte Carlo approximation for the remaining
outer integral estimation. We provide three numerical examples demonstrating
the applicability and effectiveness of our proposed estimators.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10789" title="Abstract">arXiv:2310.10789</a> [<a href="/pdf/2310.10789" title="Download PDF">pdf</a>, <a href="/format/2310.10789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State Machine Frameworks for Website Fingerprinting Defenses: Maybe Not
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Witwer%2C+E">Ethan Witwer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Senior thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Tor is an anonymity network used by millions of people every day to evade
censorship and protect their browsing activity from privacy threats such as
mass surveillance. Unfortunately, Tor has been shown to be vulnerable to
website fingerprinting attacks, in which an adversary observes the connection
between a user and the Tor network and uses features of the encrypted traffic,
such as the timing and volume of packets, to identify the websites that are
being visited. In response, researchers have proposed a number of defenses
against website fingerprinting attacks, and a "circuit padding framework" has
been added to the Tor software which supports the implementation of defenses.
However, many proposed defenses are not supported by this framework, and no
defenses are currently present in Tor.
<br />As Arti, a reimplementation of Tor in Rust, is being developed, the issue
arises of whether a new state machine framework should be included or if
alternative models should instead be considered for future defense
implementation. We address this question by using an improved Rust-based state
machine framework, Maybenot, to implement three state-of-the-art website
fingerprinting defenses. Through our evaluation, we demonstrate the potential
of state machine frameworks to support effective defenses, and we highlight
important features that they should contain to do so. However, our evaluation
also raises uncertainty about the long-term feasibility of state machine
frameworks for defense implementation. We recommend enhancements to Maybenot
and substantial further evaluation, along with consideration of alternative
designs, before any decision is made regarding a mechanism for implementing
website fingerprinting defenses in Arti.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10790" title="Abstract">arXiv:2310.10790</a> [<a href="/pdf/2310.10790" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuromorphic Place Cells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhaoqi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Etienne-Cummings%2C+R">Ralph Etienne-Cummings</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, draft for Journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A neuromorphic SLAM system shows potential for more efficient implementation
than its traditional counterpart. We demonstrate a mixed-mode implementation
for spatial encoding neurons including theta cells, vector cells and place
cells. Together, they form a biologically plausible network that could
reproduce the localization functionality of place cells. Experimental results
validate the robustness of our model when suffering from variations of analog
circuits. We provide a foundation for implementing dynamic neuromorphic SLAM
systems and inspirations for the formation of spatial cells in biology.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10791" title="Abstract">arXiv:2310.10791</a> [<a href="/pdf/2310.10791" title="Download PDF">pdf</a>, <a href="/format/2310.10791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Tangent Kernels Motivate Graph Neural Networks with  Cross-Covariance Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalafi%2C+S">Shervin Khalafi</a>, 
<a href="/search/cs?searchtype=author&query=Sihag%2C+S">Saurabh Sihag</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Neural tangent kernels (NTKs) provide a theoretical regime to analyze the
learning and generalization behavior of over-parametrized neural networks. For
a supervised learning task, the association between the eigenvectors of the NTK
kernel and given data (a concept referred to as alignment in this paper) can
govern the rate of convergence of gradient descent, as well as generalization
to unseen data. Building upon this concept, we investigate NTKs and alignment
in the context of graph neural networks (GNNs), where our analysis reveals that
optimizing alignment translates to optimizing the graph representation or the
graph shift operator in a GNN. Our results further establish the theoretical
guarantees on the optimality of the alignment for a two-layer GNN and these
guarantees are characterized by the graph shift operator being a function of
the cross-covariance between the input and the output data. The theoretical
insights drawn from the analysis of NTKs are validated by our experiments
focused on a multi-variate time series prediction task for a publicly available
dataset. Specifically, they demonstrate that GNNs with cross-covariance as the
graph shift operator indeed outperform those that operate on the covariance
matrix from only the input data.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10802" title="Abstract">arXiv:2310.10802</a> [<a href="/pdf/2310.10802" title="Download PDF">pdf</a>, <a href="/ps/2310.10802" title="Download PostScript">ps</a>, <a href="/format/2310.10802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three Quantum Programming Language Parser Implementations for the Web
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Edwards%2C+M">Marcus Edwards</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">IBM has developed a quantum assembly (QASM) language particular to gate model
quantum computing since 2017 [CBSG17]. Version 3.0 which adds timing, pulse
control, and gate modifiers is currently undergoing finalization in 2023
[CJA+21]. In a similar vein, Pakin of Los Alamos National Laboratory published
a quantum macro assembler (QMASM) for D-Wave quantum annealers in 2016 [Pak16].
This assembler specifically targets quantum annealers like D-Wave's. A
comparable technology that targets continuous-variable (CV) quantum computing
is the Blackbird language developed by Xanadu since 2018 [KIQ+19]. We implement
parsers for each of these languages in TypeScript with a singular approach. In
the cases of Blackbird and QMASM these are the first parser implementations
that are web compatible and so bring these languages to a new audience and to
new runtimes. This makes the parsing and execution of QMASM, QASM and Blackbird
possible in web and mobile environments that don't have access to heavy compile
toolchains, enabling adoption and scientific research.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10803" title="Abstract">arXiv:2310.10803</a> [<a href="/pdf/2310.10803" title="Download PDF">pdf</a>, <a href="/format/2310.10803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SD-HuBERT: Self-Distillation Induces Syllabic Organization in HuBERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+C+J">Cheol Jun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+A">Abdelrahman Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shang-Wen Li</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+A+W">Alan W Black</a>, 
<a href="/search/cs?searchtype=author&query=Anumanchipalli%2C+G+K">Gopala K. Anumanchipalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Data-driven unit discovery in self-supervised learning (SSL) of speech has
embarked on a new era of spoken language processing. Yet, the discovered units
often remain in phonetic space, limiting the utility of SSL representations.
Here, we demonstrate that a syllabic organization emerges in learning
sentence-level representation of speech. In particular, we adopt
"self-distillation" objective to fine-tune the pretrained HuBERT with an
aggregator token that summarizes the entire sentence. Without any supervision,
the resulting model draws definite boundaries in speech, and the
representations across frames show salient syllabic structures. We demonstrate
that this emergent structure largely corresponds to the ground truth syllables.
Furthermore, we propose a new benchmark task, Spoken Speech ABX, for evaluating
sentence-level representation of speech. When compared to previous models, our
model outperforms in both unsupervised syllable discovery and learning
sentence-level representation. Together, we demonstrate that the
self-distillation of HuBERT gives rise to syllabic organization without relying
on external labels or modalities, and potentially provides novel data-driven
units for spoken language modeling.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10808" title="Abstract">arXiv:2310.10808</a> [<a href="/pdf/2310.10808" title="Download PDF">pdf</a>, <a href="/format/2310.10808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> If the Sources Could Talk: Evaluating Large Language Models for Research  Assistance in History
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia%2C+G+G">Giselle Gonzalez Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Weilbach%2C+C">Christian Weilbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Will be published at CHR2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent advent of powerful Large-Language Models (LLM) provides a new
conversational form of inquiry into historical memory (or, training data, in
this case). We show that by augmenting such LLMs with vector embeddings from
highly specialized academic sources, a conversational methodology can be made
accessible to historians and other researchers in the Humanities. Concretely,
we evaluate and demonstrate how LLMs have the ability of assisting researchers
while they examine a customized corpora of different types of documents,
including, but not exclusive to: (1). primary sources, (2). secondary sources
written by experts, and (3). the combination of these two. Compared to
established search interfaces for digital catalogues, such as metadata and
full-text search, we evaluate the richer conversational style of LLMs on the
performance of two main types of tasks: (1). question-answering, and (2).
extraction and organization of data. We demonstrate that LLMs semantic
retrieval and reasoning abilities on problem-specific tasks can be applied to
large textual archives that have not been part of the its training data.
Therefore, LLMs can be augmented with sources relevant to specific research
projects, and can be queried privately by researchers.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10810" title="Abstract">arXiv:2310.10810</a> [<a href="/pdf/2310.10810" title="Download PDF">pdf</a>, <a href="/format/2310.10810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Multi-Agent Reinforcement Learning via Adversarial  Regularization: Theoretical Foundation and Stable Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bukharin%2C+A">Alexander Bukharin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhehui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+S">Simiao Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tuo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-Agent Reinforcement Learning (MARL) has shown promising results across
several domains. Despite this promise, MARL policies often lack robustness and
are therefore sensitive to small changes in their environment. This presents a
serious concern for the real world deployment of MARL algorithms, where the
testing environment may slightly differ from the training environment. In this
work we show that we can gain robustness by controlling a policy's Lipschitz
constant, and under mild conditions, establish the existence of a Lipschitz and
close-to-optimal policy. Based on these insights, we propose a new robust MARL
framework, ERNIE, that promotes the Lipschitz continuity of the policies with
respect to the state observations and actions by adversarial regularization.
The ERNIE framework provides robustness against noisy observations, changing
transition dynamics, and malicious actions of agents. However, ERNIE's
adversarial regularization may introduce some training instability. To reduce
this instability, we reformulate adversarial regularization as a Stackelberg
game. We demonstrate the effectiveness of the proposed framework with extensive
experiments in traffic light control and particle environments. In addition, we
extend ERNIE to mean-field MARL with a formulation based on distributionally
robust optimization that outperforms its non-robust counterpart and is of
independent interest. Our code is available at
https://github.com/abukharin3/ERNIE.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10815" title="Abstract">arXiv:2310.10815</a> [<a href="/pdf/2310.10815" title="Download PDF">pdf</a>, <a href="/ps/2310.10815" title="Download PostScript">ps</a>, <a href="/format/2310.10815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streaming Algorithms for Graph k-Matching with Optimal or Near-Optimal  Update Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianer Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kanj%2C+I">Iyad Kanj</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Ge Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present streaming algorithms for the graph $k$-matching problem in both
the insert-only and dynamic models. Our algorithms, with space complexity
matching the best upper bounds, have optimal or near-optimal update time,
significantly improving on previous results. More specifically, for the
insert-only streaming model, we present a one-pass algorithm with optimal space
complexity $O(k^2)$ and optimal update time $O(1)$, that with high probability
computes a maximum weighted $k$-matching of a given weighted graph. The update
time of our algorithm significantly improves the previous upper bound of
$O(\log k)$, which was derived only for $k$-matching on unweighted graphs. For
the dynamic streaming model, we present a one-pass algorithm that with high
probability computes a maximum weighted $k$-matching in $O(Wk^2 \cdot
\mbox{polylog}(n)$ space and with $O(\mbox{polylog}(n))$ update time, where $W$
is the number of distinct edge weights. Again the update time of our algorithm
improves the previous upper bound of $O(k^2 \cdot \mbox{polylog}(n))$. This
algorithm, when applied to unweighted graphs, gives a streaming algorithm on
the dynamic model whose space and update time complexities are both
near-optimal. Our results also imply a streaming approximation algorithm for
maximum weighted $k$-matching whose space complexity matches the best known
upper bound with a significantly improved update time.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10817" title="Abstract">arXiv:2310.10817</a> [<a href="/pdf/2310.10817" title="Download PDF">pdf</a>, <a href="/format/2310.10817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Documentation Usage via Page-view Log Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nam%2C+D">Daye Nam</a>, 
<a href="/search/cs?searchtype=author&query=Macvean%2C+A">Andrew Macvean</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+B">Brad Myers</a>, 
<a href="/search/cs?searchtype=author&query=Vasilescu%2C+B">Bogdan Vasilescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Almost no modern software system is written from scratch, and developers are
required to effectively learn to use third-party libraries or software
services. Thus, many practitioners and researchers have looked for ways to
create effective documentation that supports developers' learning. However, few
efforts have focused on how people actually use the documentation. In this
paper, we report on an exploratory, multi-phase, mixed methods empirical study
of documentation page-view logs from four cloud-based industrial services. By
analyzing page-view logs for over 100,000 users, we find diverse patterns of
documentation page visits. Moreover, we show statistically that which
documentation pages people visit often correlates with user characteristics
such as past experience with the specific product, on the one hand, and with
future adoption of the API on the other hand. We discuss the implications of
these results on documentation design and propose documentation page-view log
analysis as a feasible technique for design audits of documentation, from ones
written for software developers to ones designed to support end users (e.g.,
Adobe Photoshop).
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10818" title="Abstract">arXiv:2310.10818</a> [<a href="/pdf/2310.10818" title="Download PDF">pdf</a>, <a href="/format/2310.10818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware transfer across tasks using hybrid model-based  successor feature reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malekzadeh%2C+P">Parvin Malekzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+M">Ming Hou</a>, 
<a href="/search/cs?searchtype=author&query=Plataniotis%2C+K+N">Konstantinos N. Plataniotis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neurocomputing 530 (2023): 165-187
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Sample efficiency is central to developing practical reinforcement learning
(RL) for complex and large-scale decision-making problems. The ability to
transfer and generalize knowledge gained from previous experiences to
downstream tasks can significantly improve sample efficiency. Recent research
indicates that successor feature (SF) RL algorithms enable knowledge
generalization between tasks with different rewards but identical transition
dynamics. It has recently been hypothesized that combining model-based (MB)
methods with SF algorithms can alleviate the limitation of fixed transition
dynamics. Furthermore, uncertainty-aware exploration is widely recognized as
another appealing approach for improving sample efficiency. Putting together
two ideas of hybrid model-based successor feature (MB-SF) and uncertainty leads
to an approach to the problem of sample efficient uncertainty-aware knowledge
transfer across tasks with different transition dynamics or/and reward
functions. In this paper, the uncertainty of the value of each action is
approximated by a Kalman filter (KF)-based multiple-model adaptive estimation.
This KF-based framework treats the parameters of a model as random variables.
To the best of our knowledge, this is the first attempt at formulating a hybrid
MB-SF algorithm capable of generalizing knowledge across large or continuous
state space tasks with various transition dynamics while requiring less
computation at decision time than MB methods. The number of samples required to
learn the tasks was compared to recent SF and MB baselines. The results show
that our algorithm generalizes its knowledge across different transition
dynamics, learns downstream tasks with significantly fewer samples than
starting from scratch, and outperforms existing approaches.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10821" title="Abstract">arXiv:2310.10821</a> [<a href="/pdf/2310.10821" title="Download PDF">pdf</a>, <a href="/format/2310.10821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Get-A-Sense: Designing Spatial Context Awareness for Mobile AR  Environment Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiqin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ganj%2C+A">Ashkan Ganj</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tian Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Physical environment understanding is vital in delivering immersive and
interactive mobile augmented reality (AR) user experiences. Recently, we have
witnessed a transition in the design of environment understanding systems, from
visual data focused to centering on the concept of spatial context, including
user, device, and environment information. Even though spatial context can
benefit the environment understanding tasks, e.g., we demonstrate in a case
study that lighting estimation performance can be improved by as much as 59%,
not all environment understanding systems support spatial context. Furthermore,
even for the environment understanding systems that support spatial context,
not all useful spatial context has been leveraged; and the design and
implementation can differ vastly. In this paper, we advocate for the design of
a spatial context-aware and shared environment understanding system that can
effectively support multiple tasks simultaneously. Fundamentally, there are
many practical challenges in designing such a unified environment understanding
system. We discuss the challenges in the context of three open questions, (i)
how to fully leverage user mobility, (ii) how to design a unified data model,
and (iii) finally how to build a shared system for multiple tasks.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10822" title="Abstract">arXiv:2310.10822</a> [<a href="/pdf/2310.10822" title="Download PDF">pdf</a>, <a href="/format/2310.10822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision and Language Navigation in the Real World via Online Visual  Language Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengguang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+T">Hieu T. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Amato%2C+C">Christopher Amato</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+L+L+S">Lawson L.S. Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Systems and Control (eess.SY)

</div>
<p class="mathjax">Navigating in unseen environments is crucial for mobile robots. Enhancing
them with the ability to follow instructions in natural language will further
improve navigation efficiency in unseen cases. However, state-of-the-art (SOTA)
vision-and-language navigation (VLN) methods are mainly evaluated in
simulation, neglecting the complex and noisy real world. Directly transferring
SOTA navigation policies trained in simulation to the real world is challenging
due to the visual domain gap and the absence of prior knowledge about unseen
environments. In this work, we propose a novel navigation framework to address
the VLN task in the real world. Utilizing the powerful foundation models, the
proposed framework includes four key components: (1) an LLMs-based instruction
parser that converts the language instruction into a sequence of pre-defined
macro-action descriptions, (2) an online visual-language mapper that builds a
real-time visual-language map to maintain a spatial and semantic understanding
of the unseen environment, (3) a language indexing-based localizer that grounds
each macro-action description into a waypoint location on the map, and (4) a
DD-PPO-based local controller that predicts the action. We evaluate the
proposed pipeline on an Interbotix LoCoBot WX250 in an unseen lab environment.
Without any fine-tuning, our pipeline significantly outperforms the SOTA VLN
baseline in the real world.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10826" title="Abstract">arXiv:2310.10826</a> [<a href="/pdf/2310.10826" title="Download PDF">pdf</a>, <a href="/format/2310.10826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanism Design for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duetting%2C+P">Paul Duetting</a>, 
<a href="/search/cs?searchtype=author&query=Mirrokni%2C+V">Vahab Mirrokni</a>, 
<a href="/search/cs?searchtype=author&query=Leme%2C+R+P">Renato Paes Leme</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haifeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+S">Song Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">We investigate auction mechanisms to support the emerging format of
AI-generated content. We in particular study how to aggregate several LLMs in
an incentive compatible manner. In this problem, the preferences of each agent
over stochastically generated contents are described/encoded as an LLM. A key
motivation is to design an auction format for AI-generated ad creatives to
combine inputs from different advertisers. We argue that this problem, while
generally falling under the umbrella of mechanism design, has several unique
features. We propose a general formalism -- the token auction model -- for
studying this problem. A key feature of this model is that it acts on a
token-by-token basis and lets LLM agents influence generated contents through
single dimensional bids.
<br />We first explore a robust auction design approach, in which all we assume is
that agent preferences entail partial orders over outcome distributions. We
formulate two natural incentive properties, and show that these are equivalent
to a monotonicity condition on distribution aggregation. We also show that for
such aggregation functions, it is possible to design a second-price auction,
despite the absence of bidder valuation functions. We then move to designing
concrete aggregation functions by focusing on specific valuation forms based on
KL-divergence, a commonly used loss function in LLM. The welfare-maximizing
aggregation rules turn out to be the weighted (log-space) convex combination of
the target distributions from all participants. We conclude with experimental
results in support of the token auction formulation.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10828" title="Abstract">arXiv:2310.10828</a> [<a href="/pdf/2310.10828" title="Download PDF">pdf</a>, <a href="/ps/2310.10828" title="Download PostScript">ps</a>, <a href="/format/2310.10828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness and Approximation of Discrete-time Mean-field Games under  Discounted Cost Criterion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ayd%C4%B1n%2C+U">U&#x11f;ur Ayd&#x131;n</a>, 
<a href="/search/eess?searchtype=author&query=Saldi%2C+N">Naci Saldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we investigate the robustness of stationary mean-field
equilibria in the presence of model uncertainties, specifically focusing on
infinite-horizon discounted cost functions. To achieve this, we initially
establish convergence conditions for value iteration-based algorithms in
mean-field games. Subsequently, utilizing these results, we demonstrate that
the mean-field equilibrium obtained through this value iteration algorithm
remains robust even in the face of system dynamics misspecifications. We then
apply these robustness findings to the finite model approximation problem in
mean-field games, showing that if the state space quantization is fine enough,
the mean-field equilibrium for the finite model closely approximates the
nominal one.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10830" title="Abstract">arXiv:2310.10830</a> [<a href="/pdf/2310.10830" title="Download PDF">pdf</a>, <a href="/format/2310.10830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fake News in Sheep&#x27;s Clothing: Robust Fake News Detection Against  LLM-Empowered Style Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaying Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hooi%2C+B">Bryan Hooi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">It is commonly perceived that online fake news and reliable news exhibit
stark differences in writing styles, such as the use of sensationalist versus
objective language. However, we emphasize that style-related features can also
be exploited for style-based attacks. Notably, the rise of powerful Large
Language Models (LLMs) has enabled malicious users to mimic the style of
trustworthy news outlets at minimal cost. Our analysis reveals that
LLM-camouflaged fake news content leads to substantial performance degradation
of state-of-the-art text-based detectors (up to 38% decrease in F1 Score),
posing a significant challenge for automated detection in online ecosystems. To
address this, we introduce SheepDog, a style-agnostic fake news detector robust
to news writing styles. SheepDog achieves this adaptability through
LLM-empowered news reframing, which customizes each article to match different
writing styles using style-oriented reframing prompts. By employing
style-agnostic training, SheepDog enhances its resilience to stylistic
variations by maximizing prediction consistency across these diverse
reframings. Furthermore, SheepDog extracts content-focused veracity
attributions from LLMs, where the news content is evaluated against a set of
fact-checking rationales. These attributions provide supplementary information
and potential interpretability that assist veracity prediction. On three
benchmark datasets, empirical results show that SheepDog consistently yields
significant improvements over competitive baselines and enhances robustness
against LLM-empowered style attacks.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10831" title="Abstract">arXiv:2310.10831</a> [<a href="/pdf/2310.10831" title="Download PDF">pdf</a>, <a href="/format/2310.10831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Data-Driven Surrogates of Dynamical Systems for Forward  Propagation of Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=De%2C+S">Saibal De</a>, 
<a href="/search/math?searchtype=author&query=Jones%2C+R+E">Reese E. Jones</a>, 
<a href="/search/math?searchtype=author&query=Kolla%2C+H">Hemanth Kolla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Stochastic collocation (SC) is a well-known non-intrusive method of
constructing surrogate models for uncertainty quantification. In dynamical
systems, SC is especially suited for full-field uncertainty propagation that
characterizes the distributions of the high-dimensional primary solution fields
of a model with stochastic input parameters. However, due to the highly
nonlinear nature of the parameter-to-solution map in even the simplest
dynamical systems, the constructed SC surrogates are often inaccurate. This
work presents an alternative approach, where we apply the SC approximation over
the dynamics of the model, rather than the solution. By combining the
data-driven sparse identification of nonlinear dynamics (SINDy) framework with
SC, we construct dynamics surrogates and integrate them through time to
construct the surrogate solutions. We demonstrate that the SC-over-dynamics
framework leads to smaller errors, both in terms of the approximated system
trajectories as well as the model state distributions, when compared against
full-field SC applied to the solutions directly. We present numerical evidence
of this improvement using three test problems: a chaotic ordinary differential
equation, and two partial differential equations from solid mechanics.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10833" title="Abstract">arXiv:2310.10833</a> [<a href="/pdf/2310.10833" title="Download PDF">pdf</a>, <a href="/format/2310.10833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proper Laplacian Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomez%2C+D">Diego Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Bowling%2C+M">Michael Bowling</a>, 
<a href="/search/cs?searchtype=author&query=Machado%2C+M+C">Marlos C. Machado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The ability to learn good representations of states is essential for solving
large reinforcement learning problems, where exploration, generalization, and
transfer are particularly challenging. The Laplacian representation is a
promising approach to address these problems by inducing intrinsic rewards for
temporally-extended action discovery and reward shaping, and informative state
encoding. To obtain the Laplacian representation one needs to compute the
eigensystem of the graph Laplacian, which is often approximated through
optimization objectives compatible with deep learning approaches. These
approximations, however, depend on hyperparameters that are impossible to tune
efficiently, converge to arbitrary rotations of the desired eigenvectors, and
are unable to accurately recover the corresponding eigenvalues. In this paper
we introduce a theoretically sound objective and corresponding optimization
algorithm for approximating the Laplacian representation. Our approach
naturally recovers both the true eigenvectors and eigenvalues while eliminating
the hyperparameter dependence of previous approximations. We provide
theoretical guarantees for our method and we show that those results translate
empirically into robust learning across multiple environments.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10836" title="Abstract">arXiv:2310.10836</a> [<a href="/pdf/2310.10836" title="Download PDF">pdf</a>, <a href="/format/2310.10836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian processes based data augmentation and expected signature for  time series classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romito%2C+M">Marco Romito</a>, 
<a href="/search/cs?searchtype=author&query=Triggiano%2C+F">Francesco Triggiano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The signature is a fundamental object that describes paths (that is,
continuous functions from an interval to a Euclidean space). Likewise, the
expected signature provides a statistical description of the law of stochastic
processes. We propose a feature extraction model for time series built upon the
expected signature. This is computed through a Gaussian processes based data
augmentation. One of the main features is that an optimal feature extraction is
learnt through the supervised task that uses the model.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10837" title="Abstract">arXiv:2310.10837</a> [<a href="/pdf/2310.10837" title="Download PDF">pdf</a>, <a href="/format/2310.10837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating Two-Layer Feedforward Networks for Efficient Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Csord%C3%A1s%2C+R">R&#xf3;bert Csord&#xe1;s</a>, 
<a href="/search/cs?searchtype=author&query=Irie%2C+K">Kazuki Irie</a>, 
<a href="/search/cs?searchtype=author&query=Schmidhuber%2C+J">J&#xfc;rgen Schmidhuber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">How to reduce compute and memory requirements of neural networks (NNs)
without sacrificing performance? Many recent works use sparse Mixtures of
Experts (MoEs) to build resource-efficient large language models (LMs). Here we
introduce several novel perspectives on MoEs, presenting a general framework
that unifies various methods to approximate two-layer NNs (e.g., feedforward
blocks of Transformers), including product-key memories (PKMs). Leveraging
insights from this framework, we propose methods to improve both MoEs and PKMs.
Unlike prior work that compares MoEs with dense baselines under the
compute-equal condition, our evaluation condition is parameter-equal, which is
crucial to properly evaluate LMs. We show that our MoEs are competitive with
the dense Transformer-XL on both the WikiText-103 and enwiki8 datasets at two
different scales, while being much more resource efficient. This demonstrates
that MoEs are relevant not only to extremely large LMs but also to any-scale
resource-efficient LMs. Our code is public.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10839" title="Abstract">arXiv:2310.10839</a> [<a href="/pdf/2310.10839" title="Download PDF">pdf</a>, <a href="/format/2310.10839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision Cone Control Barrier Functions: Experimental Validation on  UGVs for Kinematic Obstacle Avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+B+G">Bhavya Giri Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Tayal%2C+M">Manan Tayal</a>, 
<a href="/search/cs?searchtype=author&query=Rajgopal%2C+K">Karthik Rajgopal</a>, 
<a href="/search/cs?searchtype=author&query=Jagtap%2C+P">Pushpak Jagtap</a>, 
<a href="/search/cs?searchtype=author&query=Kolathaya%2C+S">Shishir Kolathaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures, Submitted at American Control Conference (ACC), 2024. arXiv admin note: substantial text overlap with <a href="/abs/2209.11524">arXiv:2209.11524</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">Autonomy advances have enabled robots in diverse environments and close human
interaction, necessitating controllers with formal safety guarantees. This
paper introduces an experimental platform designed for the validation and
demonstration of a novel class of Control Barrier Functions (CBFs) tailored for
Unmanned Ground Vehicles (UGVs) to proactively prevent collisions with
kinematic obstacles by integrating the concept of collision cones. While
existing CBF formulations excel with static obstacles, extensions to
torque/acceleration-controlled unicycle and bicycle models have seen limited
success. Conventional CBF applications in nonholonomic UGV models have
demonstrated control conservatism, particularly in scenarios where
steering/thrust control was deemed infeasible. Drawing inspiration from
collision cones in path planning, we present a pioneering CBF formulation
ensuring theoretical safety guarantees for both unicycle and bicycle models.
The core premise revolves around aligning the obstacle's velocity away from the
vehicle, establishing a constraint to perpetually avoid vectors directed
towards it. This control methodology is rigorously validated through
simulations and experimental verification on the Copernicus mobile robot
(Unicycle Model) and FOCAS-Car (Bicycle Model).
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10841" title="Abstract">arXiv:2310.10841</a> [<a href="/pdf/2310.10841" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Machine Learning-based Algorithm for Automated Detection of  Frequency-based Events in Recorded Time Series of Sensor Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Medghalchi%2C+B">Bahareh Medghalchi</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+A">Andreas Vogel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">Automated event detection has emerged as one of the fundamental practices to
monitor the behavior of technical systems by means of sensor data. In the
automotive industry, these methods are in high demand for tracing events in
time series data. For assessing the active vehicle safety systems, a diverse
range of driving scenarios is conducted. These scenarios involve the recording
of the vehicle's behavior using external sensors, enabling the evaluation of
operational performance. In such setting, automated detection methods not only
accelerate but also standardize and objectify the evaluation by avoiding
subjective, human-based appraisals in the data inspection. This work proposes a
novel event detection method that allows to identify frequency-based events in
time series data. To this aim, the time series data is mapped to
representations in the time-frequency domain, known as scalograms. After
filtering scalograms to enhance relevant parts of the signal, an object
detection model is trained to detect the desired event objects in the
scalograms. For the analysis of unseen time series data, events can be detected
in their scalograms with the trained object detection model and are thereafter
mapped back to the time series data to mark the corresponding time interval.
The algorithm, evaluated on unseen datasets, achieves a precision rate of 0.97
in event detection, providing sharp time interval boundaries whose accurate
indication by human visual inspection is challenging. Incorporating this method
into the vehicle development process enhances the accuracy and reliability of
event detection, which holds major importance for rapid testing analysis.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10844" title="Abstract">arXiv:2310.10844</a> [<a href="/pdf/2310.10844" title="Download PDF">pdf</a>, <a href="/format/2310.10844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey of Vulnerabilities in Large Language Models Revealed by  Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shayegani%2C+E">Erfan Shayegani</a>, 
<a href="/search/cs?searchtype=author&query=Mamun%2C+M+A+A">Md Abdullah Al Mamun</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zaree%2C+P">Pedram Zaree</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yue Dong</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Ghazaleh%2C+N">Nael Abu-Ghazaleh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) are swiftly advancing in architecture and
capability, and as they integrate more deeply into complex systems, the urgency
to scrutinize their security properties grows. This paper surveys research in
the emerging interdisciplinary field of adversarial attacks on LLMs, a subfield
of trustworthy ML, combining the perspectives of Natural Language Processing
and Security. Prior work has shown that even safety-aligned LLMs (via
instruction tuning and reinforcement learning through human feedback) can be
susceptible to adversarial attacks, which exploit weaknesses and mislead AI
systems, as evidenced by the prevalence of `jailbreak' attacks on models like
ChatGPT and Bard. In this survey, we first provide an overview of large
language models, describe their safety alignment, and categorize existing
research based on various learning structures: textual-only attacks,
multi-modal attacks, and additional attack methods specifically targeting
complex systems, such as federated learning or multi-agent systems. We also
offer comprehensive remarks on works that focus on the fundamental sources of
vulnerabilities and potential defenses. To make this field more accessible to
newcomers, we present a systematic review of existing works, a structured
typology of adversarial attack concepts, and additional resources, including
slides for presentations on related topics at the 62nd Annual Meeting of the
Association for Computational Linguistics (ACL'24).
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10845" title="Abstract">arXiv:2310.10845</a> [<a href="/pdf/2310.10845" title="Download PDF">pdf</a>, <a href="/format/2310.10845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoTFormer: More Tokens With Attention Make Up For Less Depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohtashami%2C+A">Amirkeivan Mohtashami</a>, 
<a href="/search/cs?searchtype=author&query=Pagliardini%2C+M">Matteo Pagliardini</a>, 
<a href="/search/cs?searchtype=author&query=Jaggi%2C+M">Martin Jaggi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The race to continually develop ever larger and deeper foundational models is
underway. However, techniques like the Chain-of-Thought (CoT) method continue
to play a pivotal role in achieving optimal downstream performance. In this
work, we establish an approximate parallel between using chain-of-thought and
employing a deeper transformer. Building on this insight, we introduce
CoTFormer, a transformer variant that employs an implicit CoT-like mechanism to
achieve capacity comparable to a deeper model. Our empirical findings
demonstrate the effectiveness of CoTFormers, as they significantly outperform
larger standard transformers.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10851" title="Abstract">arXiv:2310.10851</a> [<a href="/pdf/2310.10851" title="Download PDF">pdf</a>, <a href="/format/2310.10851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking China&#x27;s cross-strait bot networks against Taiwan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+C+S">Charity S. Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+L+H+X">Lynnette Hui Xian Ng</a>, 
<a href="/search/cs?searchtype=author&query=Carley%2C+K+M">Kathleen M. Carley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages with 5 figures. Published in Conference Proceedings for Social, Cultural, and Behavioral Modeling (SBP-BRiMS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">The cross-strait relationship between China and Taiwan is marked by
increasing hostility around potential reunification. We analyze an unattributed
bot network and how repeater bots engaged in an influence campaign against
Taiwan following US House Speaker Nancy Pelosi's visit to Taiwan in 2022. We
examine the message amplification tactics employed by four key bot
sub-communities, the widespread dissemination of information across multiple
platforms through URLs, and the potential targeted audiences of this bot
network. We find that URL link sharing reveals circumvention around YouTube
suspensions, in addition to the potential effectiveness of algorithmic bot
connectivity to appear less bot-like, and detail a sequence of coordination
within a sub-community for message amplification. We additionally find the
narratives and targeted audience potentially shifting after account activity
discrepancies, demonstrating how dynamic these bot networks can operate.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10853" title="Abstract">arXiv:2310.10853</a> [<a href="/pdf/2310.10853" title="Download PDF">pdf</a>, <a href="/format/2310.10853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manta Ray Inspired Flapping-Wing Blimp
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nojima-Schmunk%2C+K">Kentaro Nojima-Schmunk</a>, 
<a href="/search/cs?searchtype=author&query=Turzak%2C+D">David Turzak</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kevin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+A">Andrew Vu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">James Yang</a>, 
<a href="/search/cs?searchtype=author&query=Motukuri%2C+S">Sreeauditya Motukuri</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+N">Ningshi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Shishika%2C+D">Daigo Shishika</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages + 1 reference page. 11 figures. Submitted to International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Lighter-than-air vehicles or blimps, are an evolving platform in robotics
with several beneficial properties such as energy efficiency, collision
resistance, and ability to work in close proximity to human users. While
existing blimp designs have mainly used propeller-based propulsion, we focus
our attention to an alternate locomotion method, flapping wings. Specifically,
this paper introduces a flapping-wing blimp inspired by manta rays, in contrast
to existing research on flapping-wing vehicles that draw inspiration from
insects or birds. We present the overall design and control scheme of the blimp
as well as the analysis on how the wing performs. The effects of wing shape and
flapping characteristics on the thrust generation are studied experimentally.
We also demonstrate that the flapping-wing blimp has a significant range
advantage over a propeller-based system.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10856" title="Abstract">arXiv:2310.10856</a> [<a href="/pdf/2310.10856" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Optimization of Traffic Signal Control and Vehicle Routing in  Signalized Road Networks using Multi-Agent Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Peng%2C+X">Xianyue Peng</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+H">Hang Gao</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+G">Gengyue Han</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Michael Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Urban traffic congestion is a critical predicament that plagues modern road
networks. To alleviate this issue and enhance traffic efficiency, traffic
signal control and vehicle routing have proven to be effective measures. In
this paper, we propose a joint optimization approach for traffic signal control
and vehicle routing in signalized road networks. The objective is to enhance
network performance by simultaneously controlling signal timings and route
choices using Multi-Agent Deep Reinforcement Learning (MADRL). Signal control
agents (SAs) are employed to establish signal timings at intersections, whereas
vehicle routing agents (RAs) are responsible for selecting vehicle routes. By
establishing relevance between agents and enabling them to share observations
and rewards, interaction and cooperation among agents are fostered, which
enhances individual training. The Multi-Agent Advantage Actor-Critic algorithm
is used to handle multi-agent environments, and Deep Neural Network (DNN)
structures are designed to facilitate the algorithm's convergence. Notably, our
work is the first to utilize MADRL in determining the optimal joint policy for
signal control and vehicle routing. Numerical experiments conducted on the
modified Sioux network demonstrate that our integration of signal control and
vehicle routing outperforms controlling signal timings or vehicles' routes
alone in enhancing traffic efficiency.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10858" title="Abstract">arXiv:2310.10858</a> [<a href="/pdf/2310.10858" title="Download PDF">pdf</a>, <a href="/format/2310.10858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Shared Information Displays for Agents of Varying Strategic  Sophistication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hartline%2C+J">Jason Hartline</a>, 
<a href="/search/cs?searchtype=author&query=Hullman%2C+J">Jessica Hullman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 11 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Data-driven predictions are often perceived as inaccurate in hindsight due to
behavioral responses. We consider the role of interface design choices on how
individuals respond to predictions presented on a shared information display in
a strategic setting. We introduce a novel staged experimental design to
investigate the effects of interface design features, such as the visualization
of prediction uncertainty and prediction error, within a repeated congestion
game. In this game, participants assume the role of taxi drivers and use a
shared information display to decide where to search for their next ride. Our
experimental design endows agents with varying level-$k$ depths of thinking,
allowing some agents to possess greater sophistication in anticipating the
decisions of others using the same information display. Through several large
pre-registered experiments, we identify trade-offs between displays that are
optimal for individual decisions and those that best serve the collective
social welfare of the system. Additionally, we note that the influence of
display characteristics varies based on an agent's strategic sophistication. We
observe that design choices promoting individual-level decision-making can lead
to suboptimal system outcomes, as manifested by a lower realization of
potential social welfare. However, this decline in social welfare is offset by
a slight reduction in distribution shift, narrowing the gap between predicted
and realized system outcomes. This may enhance the perceived reliability and
trustworthiness of the information display post hoc. Our findings pave the way
for new research questions concerning the design of effective prediction
interfaces in strategic environments.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10861" title="Abstract">arXiv:2310.10861</a> [<a href="/pdf/2310.10861" title="Download PDF">pdf</a>, <a href="/format/2310.10861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoybeanNet: Transformer-Based Convolutional Neural Network for Soybean  Pod Counting from Unmanned Aerial Vehicle (UAV) Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiajia Li</a>, 
<a href="/search/cs?searchtype=author&query=Magar%2C+R+T">Raju Thada Magar</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Feng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dechun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+W">Weichao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaojian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Soybeans are a critical source of food, protein and oil, and thus have
received extensive research aimed at enhancing their yield, refining
cultivation practices, and advancing soybean breeding techniques. Within this
context, soybean pod counting plays an essential role in understanding and
optimizing production. Despite recent advancements, the development of a robust
pod-counting algorithm capable of performing effectively in real-field
conditions remains a significant challenge This paper presents a pioneering
work of accurate soybean pod counting utilizing unmanned aerial vehicle (UAV)
images captured from actual soybean fields in Michigan, USA. Specifically, this
paper presents SoybeanNet, a novel point-based counting network that harnesses
powerful transformer backbones for simultaneous soybean pod counting and
localization with high accuracy. In addition, a new dataset of UAV-acquired
images for soybean pod counting was created and open-sourced, consisting of 113
drone images with more than 260k manually annotated soybean pods captured under
natural lighting conditions. Through comprehensive evaluations, SoybeanNet
demonstrated superior performance over five state-of-the-art approaches when
tested on the collected images. Remarkably, SoybeanNet achieved a counting
accuracy of $84.51\%$ when tested on the testing dataset, attesting to its
efficacy in real-world scenarios. The publication also provides both the source
code (\url{https://github.com/JiajiaLi04/Soybean-Pod-Counting-from-UAV-Images})
and the labeled soybean dataset
(\url{https://www.kaggle.com/datasets/jiajiali/uav-based-soybean-pod-images}),
offering a valuable resource for future research endeavors in soybean pod
counting and related fields.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10862" title="Abstract">arXiv:2310.10862</a> [<a href="/pdf/2310.10862" title="Download PDF">pdf</a>, <a href="/format/2310.10862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Invisible Map: Visual-Inertial SLAM with Fiducial Markers for  Smartphone-based Indoor Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruvolo%2C+P">Paul Ruvolo</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+A">Ayush Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+R">Rucha Dave</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Richard Li</a>, 
<a href="/search/cs?searchtype=author&query=Mazza%2C+D">Duncan Mazza</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xierui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Siddique%2C+R">Raiyan Siddique</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+K">Krishna Suresh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present a system for creating building-scale, easily navigable 3D maps
using mainstream smartphones. In our approach, we formulate the 3D-mapping
problem as an instance of Graph SLAM and infer the position of both building
landmarks (fiducial markers) and navigable paths through the environment (phone
poses). Our results demonstrate the system's ability to create accurate 3D
maps. Further, we highlight the importance of careful selection of mapping
hyperparameters and provide a novel technique for tuning these hyperparameters
to adapt our algorithm to new environments.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10863" title="Abstract">arXiv:2310.10863</a> [<a href="/pdf/2310.10863" title="Download PDF">pdf</a>, <a href="/format/2310.10863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greedy Perspectives: Multi-Drone View Planning for Collaborative  Coverage in Cluttered Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suresh%2C+K">Krishna Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Rauniyar%2C+A">Aditya Rauniyar</a>, 
<a href="/search/cs?searchtype=author&query=Corah%2C+M">Micah Corah</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA'24; 7 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deployment of teams of aerial robots could enable large-scale filming of
dynamic groups of people (actors) in complex environments for novel
applications in areas such as team sports and cinematography. Toward this end,
methods for submodular maximization via sequential greedy planning can be used
for scalable optimization of camera views across teams of robots but face
challenges with efficient coordination in cluttered environments. Obstacles can
produce occlusions and increase chances of inter-robot collision which can
violate requirements for near-optimality guarantees. To coordinate teams of
aerial robots in filming groups of people in dense environments, a more general
view-planning approach is required. We explore how collision and occlusion
impact performance in filming applications through the development of a
multi-robot multi-actor view planner with an occlusion-aware objective for
filming groups of people and compare with a greedy formation planner. To
evaluate performance, we plan in five test environments with complex
multiple-actor behaviors. Compared with a formation planner, our sequential
planner generates 14% greater view reward over the actors for three scenarios
and comparable performance to formation planning on two others. We also observe
near identical performance of sequential planning both with and without
inter-robot collision constraints. Overall, we demonstrate effective
coordination of teams of aerial robots for filming groups that may split,
merge, or spread apart and in environments cluttered with obstacles that may
cause collisions or occlusions.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10865" title="Abstract">arXiv:2310.10865</a> [<a href="/pdf/2310.10865" title="Download PDF">pdf</a>, <a href="/format/2310.10865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Will the Prince Get True Love&#x27;s Kiss? On the Model Sensitivity to Gender  Perturbation over Fairytale Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chance%2C+C">Christina Chance</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Da Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dakuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent studies show that traditional fairytales are rife with harmful gender
biases. To help mitigate these gender biases in fairytales, this work aims to
assess learned biases of language models by evaluating their robustness against
gender perturbations. Specifically, we focus on Question Answering (QA) tasks
in fairytales. Using counterfactual data augmentation to the FairytaleQA
dataset, we evaluate model robustness against swapped gender character
information, and then mitigate learned biases by introducing counterfactual
gender stereotypes during training time. We additionally introduce a novel
approach that utilizes the massive vocabulary of language models to support
text genres beyond fairytales. Our experimental results suggest that models are
sensitive to gender perturbations, with significant performance drops compared
to the original testing set. However, when first fine-tuned on a counterfactual
training dataset, models are less sensitive to the later introduced anti-gender
stereotyped text.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10866" title="Abstract">arXiv:2310.10866</a> [<a href="/pdf/2310.10866" title="Download PDF">pdf</a>, <a href="/ps/2310.10866" title="Download PostScript">ps</a>, <a href="/format/2310.10866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The linear elasticity system under singular forces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Allendes%2C+A">Alejandro Allendes</a>, 
<a href="/search/math?searchtype=author&query=Campa%C3%B1a%2C+G">Gilberto Campa&#xf1;a</a>, 
<a href="/search/math?searchtype=author&query=Ot%C3%A1rola%2C+E">Enrique Ot&#xe1;rola</a>, 
<a href="/search/math?searchtype=author&query=Salgado%2C+A+J">Abner J. Salgado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study the linear elasticity system subject to singular forces. We show
existence and uniqueness of solutions in two frameworks: weighted Sobolev
spaces, where the weight belongs to the Muckenhoupt class $A_2$; and standard
Sobolev spaces where the integrability index is less than $d/(d-1)$; $d$ is the
spatial dimension. We propose a standard finite element scheme and provide
optimal error estimates in the $\mathbf{L}^2$--norm. By proving well posedness,
we clarify some issues concerning the study of generalized mixed problems in
Banach spaces.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10869" title="Abstract">arXiv:2310.10869</a> [<a href="/pdf/2310.10869" title="Download PDF">pdf</a>, <a href="/format/2310.10869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation properties of slice-matching operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+S">Shiying Li</a>, 
<a href="/search/math?searchtype=author&query=Moosmueller%2C+C">Caroline Moosmueller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Iterative slice-matching procedures are efficient schemes for transferring a
source measure to a target measure, especially in high dimensions. These
schemes have been successfully used in applications such as color transfer and
shape retrieval, and are guaranteed to converge under regularity assumptions.
In this paper, we explore approximation properties related to a single step of
such iterative schemes by examining an associated slice-matching operator,
depending on a source measure, a target measure, and slicing directions. In
particular, we demonstrate an invariance property with respect to the source
measure, an equivariance property with respect to the target measure, and
Lipschitz continuity concerning the slicing directions. We furthermore
establish error bounds corresponding to approximating the target measure by one
step of the slice-matching scheme and characterize situations in which the
slice-matching operator recovers the optimal transport map between two
measures. We also investigate connections to affine registration problems with
respect to (sliced) Wasserstein distances. These connections can be also be
viewed as extensions to the invariance and equivariance properties of the
slice-matching operator and illustrate the extent to which slice-matching
schemes incorporate affine effects.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10872" title="Abstract">arXiv:2310.10872</a> [<a href="/pdf/2310.10872" title="Download PDF">pdf</a>, <a href="/format/2310.10872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Sparse Tensor Decompositions via Chapel and C++/MPI  Interoperability without Intermediate I/O
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anderson%2C+S+I+G">S. Isaac Geronimo Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Dunlavy%2C+D+M">Daniel M. Dunlavy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We extend an existing approach for efficient use of shared mapped memory
across Chapel and C++ for graph data stored as 1-D arrays to sparse tensor data
stored using a combination of 2-D and 1-D arrays. We describe the specific
extensions that provide use of shared mapped memory tensor data for a
particular C++ tensor decomposition tool called GentenMPI. We then demonstrate
our approach on several real-world datasets, providing timing results that
illustrate minimal overhead incurred using this approach. Finally, we extend
our work to improve memory usage and provide convenient random access to sparse
shared mapped memory tensor elements in Chapel, while still being capable of
leveraging high performance implementations of tensor algorithms in C++.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10873" title="Abstract">arXiv:2310.10873</a> [<a href="/pdf/2310.10873" title="Download PDF">pdf</a>, <a href="/format/2310.10873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IDEAL: Influence-Driven Selective Annotations Empower In-Context  Learners in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaokun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling-Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiale Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In-context learning is a promising paradigm that utilizes in-context examples
as prompts for the predictions of large language models. These prompts are
crucial for achieving strong performance. However, since the prompts need to be
sampled from a large volume of annotated examples, finding the right prompt may
result in high annotation costs. To address this challenge, this paper
introduces an influence-driven selective annotation method that aims to
minimize annotation costs while improving the quality of in-context examples.
The essence of our method is to select a pivotal subset from a large-scale
unlabeled data pool to annotate for the subsequent sampling of prompts.
Specifically, a directed graph is first constructed to represent unlabeled
data. Afterward, the influence of candidate unlabeled subsets is quantified
with a diffusion process. A simple yet effective greedy algorithm for unlabeled
data selection is lastly introduced. It iteratively selects the data if it
provides a maximum marginal gain with respect to quantified influence. Compared
with previous efforts on selective annotations, our influence-driven method
works in an end-to-end manner, avoids an intractable explicit balance between
data diversity and representativeness, and enjoys theoretical support.
Experiments confirm the superiority of the proposed method on various
benchmarks, achieving better performance under lower time consumption during
subset selection. The project page is available at
https://skzhang1.github.io/IDEAL/.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10874" title="Abstract">arXiv:2310.10874</a> [<a href="/pdf/2310.10874" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Religious Affiliation in the Twenty-First Century: A Machine Learning  Perspective on the World Value Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jafarigol%2C+E">Elaheh Jafarigol</a>, 
<a href="/search/cs?searchtype=author&query=Keely%2C+W">William Keely</a>, 
<a href="/search/cs?searchtype=author&query=Hartog%2C+T">Tess Hartog</a>, 
<a href="/search/cs?searchtype=author&query=Welborn%2C+T">Tom Welborn</a>, 
<a href="/search/cs?searchtype=author&query=Hekmatpour%2C+P">Peyman Hekmatpour</a>, 
<a href="/search/cs?searchtype=author&query=Trafalis%2C+T+B">Theodore B. Trafalis</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Society, pp.1-17 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This paper is a quantitative analysis of the data collected globally by the
World Value Survey. The data is used to study the trajectories of change in
individuals' religious beliefs, values, and behaviors in societies. Utilizing
random forest, we aim to identify the key factors of religiosity and classify
respondents of the survey as religious and non religious using country level
data. We use resampling techniques to balance the data and improve imbalanced
learning performance metrics. The results of the variable importance analysis
suggest that Age and Income are the most important variables in the majority of
countries. The results are discussed with fundamental sociological theories
regarding religion and human behavior. This study is an application of machine
learning in identifying the underlying patterns in the data of 30 countries
participating in the World Value Survey. The results from variable importance
analysis and classification of imbalanced data provide valuable insights
beneficial to theoreticians and researchers of social sciences.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10875" title="Abstract">arXiv:2310.10875</a> [<a href="/pdf/2310.10875" title="Download PDF">pdf</a>, <a href="/format/2310.10875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Filling the Holes on 3D Heritage Object Surface based on Automatic  Segmentation Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+S">Sinh Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+S+T">Son Thanh Le</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M+K">Minh Khai Tran</a>, 
<a href="/search/cs?searchtype=author&query=Sach%2C+L+T">Le Thanh Sach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures, 37 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">Reconstructing and processing the 3D objects are popular activities in the
research field of computer graphics, image processing and computer vision. The
3D objects are processed based on the methods like geometric modeling, a branch
of applied mathematics and computational geometry, or the machine learning
algorithms based on image processing. The computation of geometrical objects
includes processing the curves and surfaces, subdivision, simplification,
meshing, holes filling, reconstructing, and refining the 3D surface objects on
both point cloud data and triangular mesh. While the machine learning methods
are developed using deep learning models. With the support of 3D laser scan
devices and Lidar techniques, the obtained dataset is close to original shape
of the real objects. Besides, the photography and its application based on the
modern techniques in recent years help us collect data and process the 3D
models more precise. This article proposes an improved method for filling holes
on the 3D object surface based on an automatic segmentation. Instead of filling
the hole directly as the existing methods, we now subdivide the hole before
filling it. The hole is first determined and segmented automatically based on
computation of its local curvature. It is then filled on each part of the hole
to match its local curvature shape. The method can work on both 3D point cloud
surfaces and triangular mesh surface. Comparing to the state of the art
methods, our proposed method obtained higher accuracy of the reconstructed 3D
objects.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10878" title="Abstract">arXiv:2310.10878</a> [<a href="/pdf/2310.10878" title="Download PDF">pdf</a>, <a href="/format/2310.10878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eco-Driving Control of Connected and Automated Vehicles using Neural  Network based Rollout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paugh%2C+J">Jacob Paugh</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhaoxuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shobhit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Canova%2C+M">Marcello Canova</a>, 
<a href="/search/cs?searchtype=author&query=Stockar%2C+S">Stephanie Stockar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Connected and autonomous vehicles have the potential to minimize energy
consumption by optimizing the vehicle velocity and powertrain dynamics with
Vehicle-to-Everything info en route. Existing deterministic and stochastic
methods created to solve the eco-driving problem generally suffer from high
computational and memory requirements, which makes online implementation
challenging.
<br />This work proposes a hierarchical multi-horizon optimization framework
implemented via a neural network. The neural network learns a full-route value
function to account for the variability in route information and is then used
to approximate the terminal cost in a receding horizon optimization.
Simulations over real-world routes demonstrate that the proposed approach
achieves comparable performance to a stochastic optimization solution obtained
via reinforcement learning, while requiring no sophisticated training paradigm
and negligible on-board memory.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10879" title="Abstract">arXiv:2310.10879</a> [<a href="/pdf/2310.10879" title="Download PDF">pdf</a>, <a href="/format/2310.10879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLoad: Enhancing Neural Network Training with Efficient Sequential Data  Handling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruschel%2C+R">Raphael Ruschel</a>, 
<a href="/search/cs?searchtype=author&query=Iftekhar%2C+A+S+M">A. S. M. Iftekhar</a>, 
<a href="/search/cs?searchtype=author&query=Manjunath%2C+B+S">B. S. Manjunath</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Suya You</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The increasing complexity of modern deep neural network models and the
expanding sizes of datasets necessitate the development of optimized and
scalable training methods. In this white paper, we addressed the challenge of
efficiently training neural network models using sequences of varying sizes. To
address this challenge, we propose a novel training scheme that enables
efficient distributed data-parallel training on sequences of different sizes
with minimal overhead. By using this scheme we were able to reduce the padding
amount by more than 100$x$ while not deleting a single frame, resulting in an
overall increased performance on both training time and Recall in our
experiments.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10886" title="Abstract">arXiv:2310.10886</a> [<a href="/pdf/2310.10886" title="Download PDF">pdf</a>, <a href="/format/2310.10886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Calysto Scheme Project
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blank%2C+D+S">Douglas S. Blank</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+J+B">James B. Marshall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at The 2023 Scheme and Functional Programming Workshop (<a href="/abs/cs/0101200">arXiv:cs/0101200</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Calysto Scheme is written in Scheme in Continuation-Passing Style, and
converted through a series of correctness-preserving program transformations
into Python. It has support for standard Scheme functionality, including
call/cc, as well as syntactic extensions, a nondeterministic operator for
automatic backtracking, and many extensions to allow Python interoperation.
Because of its Python foundation, it can take advantage of modern Python
libraries, including those for machine learning and other pedagogical contexts.
Although Calysto Scheme was developed with educational purposes in mind, it has
proven to be generally useful due to its simplicity and ease of installation.
It has been integrated into the Jupyter Notebook ecosystem and used in the
classroom to teach introductory Programming Languages with some interesting and
unique twists.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10887" title="Abstract">arXiv:2310.10887</a> [<a href="/pdf/2310.10887" title="Download PDF">pdf</a>, <a href="/format/2310.10887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Stackage Repository: An Exploratory Study of its Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leger%2C+P">Paul Leger</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+F">Felipe Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Sep%C3%BAlveda%2C+N">Nicol&#xe1;s Sep&#xfa;lveda</a>, 
<a href="/search/cs?searchtype=author&query=Figueroa%2C+I">Ismael Figueroa</a>, 
<a href="/search/cs?searchtype=author&query=Cardozo%2C+N">Nicol&#xe1;s Cardozo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Context. Package repositories for a programming language are increasingly
common. A repository can keep a register of the evolution of its packages. In
the programming language Haskell, with its defining characteristic monads, we
can find the Stackage repository, which is a curated repository for stable
Haskell packages in the Hackage repository. Despite the widespread use of
Stackage in its industrial target, we are not aware of much empirical research
about how this repository has evolved, including the use of monads. Objective.
This paper conducts empirical research about the evolution of Stackage
considering monad packages through 22 Long-Term Support releases during the
period 2014-2023. Focusing on five research questions, this evolution is
analyzed in terms of packages with their dependencies and imports; including
the most used monad packages. To the best of our knowledge, this is the first
large-scale analysis of the evolution of the Stackage repository regarding
packages used and monads. Method. We define six research questions regarding
the repository's evolution, and analyze them on 51,716 packages (17.05 GB)
spread over 22 releases. For each package, we parse its cabal file and source
code to extract the data, which is analyzed in terms of dependencies and
imports using Pandas scripts. Results. From the methodology we get different
findings. For example, there are packages that depend on other packages whose
versions are not available in a particular release of Stackage; opening a
potential stability issue. The mtl and transformers are on the top 10 packages
most used/imported across releases of the Stackage evolution. We discussed
these findings with Stackage maintainers, which allowed us to refine the
research questions.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10898" title="Abstract">arXiv:2310.10898</a> [<a href="/pdf/2310.10898" title="Download PDF">pdf</a>, <a href="/format/2310.10898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Modularity Maximization in Approximation, Heuristic, and Graph  Neural Network Algorithms for Community Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aref%2C+S">Samin Aref</a>, 
<a href="/search/cs?searchtype=author&query=Mostajabdaveh%2C+M">Mahdi Mostajabdaveh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is an extended version of <a href="/abs/2302.14698">arXiv:2302.14698</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Community detection, a fundamental problem in computational sciences, finds
applications in various domains. Heuristics are often employed to detect
communities through maximizing an objective function, modularity, over
partitions of network nodes. Our research delves into the performance of
different modularity maximization algorithms in achieving optimal partitions.
We use 104 networks, comprising real-world instances from diverse contexts and
synthetic graphs with modular structures. We analyze ten inexact
modularity-based algorithms against an exact baseline which is an exact integer
programming method that globally optimizes modularity. The ten algorithms
analyzed include eight heuristics, two variations of a graph neural network
algorithm, and several variations of the Bayan approximation algorithm. Our
analysis uncovers substantial dissimilarities between the partitions obtained
by most commonly used modularity-based methods and any optimal partition of the
networks, as indicated by both adjusted and reduced mutual information metrics.
Importantly, our results show that near-optimal partitions are often
disproportionately dissimilar to any optimal partition. Taken together, our
analysis points to a crucial limitation of the commonly used unguaranteed
modularity-based methods for discovering communities: they rarely produce an
optimal partition or a partition resembling an optimal partition even on
networks with modular structures. If modularity is to be used for detecting
communities, approximate optimization algorithms are recommendable for a more
methodologically sound usage of modularity within its applicability limits.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10899" title="Abstract">arXiv:2310.10899</a> [<a href="/pdf/2310.10899" title="Download PDF">pdf</a>, <a href="/format/2310.10899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instilling Inductive Biases with Subnetworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Enyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lepori%2C+M+A">Michael A. Lepori</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the recent success of artificial neural networks on a variety of
tasks, we have little knowledge or control over the exact solutions these
models implement. Instilling inductive biases -- preferences for some solutions
over others -- into these models is one promising path toward understanding and
controlling their behavior. Much work has been done to study the inherent
inductive biases of models and instill different inductive biases through
hand-designed architectures or carefully curated training regimens. In this
work, we explore a more mechanistic approach: Subtask Induction. Our method
discovers a functional subnetwork that implements a particular subtask within a
trained model and uses it to instill inductive biases towards solutions
utilizing that subtask. Subtask Induction is flexible and efficient, and we
demonstrate its effectiveness with two experiments. First, we show that Subtask
Induction significantly reduces the amount of training data required for a
model to adopt a specific, generalizable solution to a modular arithmetic task.
Second, we demonstrate that Subtask Induction successfully induces a human-like
shape bias while increasing data efficiency for convolutional and
transformer-based image classification models.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10902" title="Abstract">arXiv:2310.10902</a> [<a href="/pdf/2310.10902" title="Download PDF">pdf</a>, <a href="/format/2310.10902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reuse Kernels or Activations? A Flexible Dataflow for Low-latency  Spectral CNN Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yue Niu</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+R">Rajgopal Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Ajitesh Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+V">Viktor Prasanna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures Accepted to ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA) 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Spectral-domain CNNs have been shown to be more efficient than traditional
spatial CNNs in terms of reducing computation complexity. However they come
with a `kernel explosion' problem that, even after compression (pruning),
imposes a high memory burden and off-chip bandwidth requirement for kernel
access. This creates a performance gap between the potential acceleration
offered by compression and actual FPGA implementation performance, especially
for low-latency CNN inference. In this paper, we develop a principled approach
to overcoming this performance gap and designing a low-latency, low-bandwidth,
spectral sparse CNN accelerator on FPGAs. First, we analyze the
bandwidth-storage tradeoff of sparse convolutional layers and locate
communication bottlenecks. We then develop a dataflow for flexibly optimizing
data reuse in different layers to minimize off-chip communication. Finally, we
propose a novel scheduling algorithm to optimally schedule the on-chip memory
access of multiple sparse kernels and minimize read conflicts. On a
state-of-the-art FPGA platform, our design reduces data transfers by 42\% with
DSP utilization up to 90\% and achieves inference latency of 9 ms for VGG16,
compared to the baseline state-of-the-art latency of 68 ms.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10903" title="Abstract">arXiv:2310.10903</a> [<a href="/pdf/2310.10903" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent AI-Assisted Discourse: Case Study of a Second Language Writer  Authoring with ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacob%2C+S">Sharin Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Tate%2C+T">Tamara Tate</a>, 
<a href="/search/cs?searchtype=author&query=Warschauer%2C+M">Mark Warschauer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The rapid proliferation of ChatGPT has incited debates regarding its impact
on human writing. Amid concerns about declining writing standards, this study
investigates the role of ChatGPT in facilitating academic writing, especially
among language learners. Using a case study approach, this study examines the
experiences of Kailing, a doctoral student, who integrates ChatGPT throughout
their academic writing process. The study employs activity theory as a lens for
understanding writing with generative AI tools and data analyzed includes
semi-structured interviews, writing samples, and GPT logs. Results indicate
that Kailing effectively collaborates with ChatGPT across various writing
stages while preserving her distinct authorial voice and agency. This
underscores the potential of AI tools such as ChatGPT to enhance academic
writing for language learners without overshadowing individual authenticity.
This case study offers a critical exploration of how ChatGPT is utilized in the
academic writing process and the preservation of a student's authentic voice
when engaging with the tool.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10908" title="Abstract">arXiv:2310.10908</a> [<a href="/pdf/2310.10908" title="Download PDF">pdf</a>, <a href="/format/2310.10908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Mixture-of-Experts: Can Dense Pre-trained Transformers Benefit  from Emergent Modular Structures?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zihan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zeyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Incorporating modular designs into neural networks demonstrates superior
out-of-generalization, learning efficiency, etc. Existing modular neural
networks are generally $\textit{explicit}$ because their modular architectures
are pre-defined, and individual modules are expected to implement distinct
functions. Conversely, recent works reveal that there exist $\textit{implicit}$
modular structures in standard pre-trained transformers, namely
$\textit{Emergent Modularity}$. They indicate that such modular structures
exhibit during the early pre-training phase and are totally spontaneous.
However, most transformers are still treated as monolithic models with their
modular natures underutilized. Therefore, given the excellent properties of
explicit modular architecture, we explore $\textit{whether and how dense
pre-trained transformers can benefit from emergent modular structures.}$ To
study this question, we construct \textbf{E}mergent
$\textbf{M}$ixture-$\textbf{o}$f-$\textbf{E}$xperts (EMoE). Without introducing
additional parameters, EMoE can be seen as the modular counterpart of the
original model and can be effortlessly incorporated into downstream tuning.
Extensive experiments (we tune 1785 models) on various downstream tasks (vision
and language) and models (22M to1.5B) demonstrate that EMoE effectively boosts
in-domain and out-of-domain generalization abilities. Further analysis and
ablation study suggest that EMoE mitigates negative knowledge transfer and is
robust to various configurations. Code is available at
\url{https://github.com/qiuzh20/EMoE}
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10909" title="Abstract">arXiv:2310.10909</a> [<a href="/pdf/2310.10909" title="Download PDF">pdf</a>, <a href="/format/2310.10909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogenous Memory Augmented Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zihan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuicheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">It has been shown that semi-parametric methods, which combine standard neural
networks with non-parametric components such as external memory modules and
data retrieval, are particularly helpful in data scarcity and
out-of-distribution (OOD) scenarios. However, existing semi-parametric methods
mostly depend on independent raw data points - this strategy is difficult to
scale up due to both high computational costs and the incapacity of current
attention mechanisms with a large number of tokens. In this paper, we introduce
a novel heterogeneous memory augmentation approach for neural networks which,
by introducing learnable memory tokens with attention mechanism, can
effectively boost performance without huge computational overhead. Our
general-purpose method can be seamlessly combined with various backbones (MLP,
CNN, GNN, and Transformer) in a plug-and-play manner. We extensively evaluate
our approach on various image and graph-based tasks under both in-distribution
(ID) and OOD conditions and show its competitive performance against
task-specific state-of-the-art methods. Code is available at
\url{https://github.com/qiuzh20/HMA}.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10910" title="Abstract">arXiv:2310.10910</a> [<a href="/pdf/2310.10910" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning in the Quantum Age: Quantum vs. Classical Support  Vector Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tasar%2C+D+E">Davut Emre Tasar</a>, 
<a href="/search/cs?searchtype=author&query=Koruyan%2C+K">Kutan Koruyan</a>, 
<a href="/search/cs?searchtype=author&query=Tasar%2C+C+O">Ceren Ocal Tasar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages, in Turkish language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This work endeavors to juxtapose the efficacy of machine learning algorithms
within classical and quantum computational paradigms. Particularly, by
emphasizing on Support Vector Machines (SVM), we scrutinize the classification
prowess of classical SVM and Quantum Support Vector Machines (QSVM) operational
on quantum hardware over the Iris dataset. The methodology embraced
encapsulates an extensive array of experiments orchestrated through the Qiskit
library, alongside hyperparameter optimization. The findings unveil that in
particular scenarios, QSVMs extend a level of accuracy that can vie with
classical SVMs, albeit the execution times are presently protracted. Moreover,
we underscore that augmenting quantum computational capacity and the magnitude
of parallelism can markedly ameliorate the performance of quantum machine
learning algorithms. This inquiry furnishes invaluable insights regarding the
extant scenario and future potentiality of machine learning applications in the
quantum epoch. Colab: https://t.ly/QKuz0
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10912" title="Abstract">arXiv:2310.10912</a> [<a href="/pdf/2310.10912" title="Download PDF">pdf</a>, <a href="/format/2310.10912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Training-free Open-world Segmentation via Image Prompting  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lv Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng-Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Hao-Ke Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The realm of computer vision has witnessed a paradigm shift with the advent
of foundational models, mirroring the transformative influence of large
language models in the domain of natural language processing. This paper delves
into the exploration of open-world segmentation, presenting a novel approach
called Image Prompt Segmentation (IPSeg) that harnesses the power of vision
foundational models. At the heart of IPSeg lies the principle of a
training-free paradigm, which capitalizes on image prompting techniques. IPSeg
utilizes a single image containing a subjective visual concept as a flexible
prompt to query vision foundation models like DINOv2 and Stable Diffusion. Our
approach extracts robust features for the prompt image and input image, then
matches the input representations to the prompt representations via a novel
feature interaction module to generate point prompts highlighting target
objects in the input image. The generated point prompts are further utilized to
guide the Segment Anything Model to segment the target object in the input
image. The proposed method stands out by eliminating the need for exhaustive
training sessions, thereby offering a more efficient and scalable solution.
Experiments on COCO, PASCAL VOC, and other datasets demonstrate IPSeg's
efficacy for flexible open-world segmentation using intuitive image prompts.
This work pioneers tapping foundation models for open-world understanding
through visual concepts conveyed in images.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10917" title="Abstract">arXiv:2310.10917</a> [<a href="/pdf/2310.10917" title="Download PDF">pdf</a>, <a href="/ps/2310.10917" title="Download PostScript">ps</a>, <a href="/format/2310.10917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Performance of Near-Field ISAC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Boqun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+C">Chongjun Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2308.16352">arXiv:2308.16352</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The technical trends for the next-generation wireless network significantly
extend the near-field region, necessitating a reevaluation for the performance
of integrated sensing and communications (ISAC) to account for the effects
introduced by the near field. In this paper, a near-field ISAC framework is
proposed with a more accurate channel model than the three conventional models
(TCMs): uniform plane wave, uniform spherical wave, and non-uniform spherical
wave. Based on the proposed model, sensing and communication (S\&amp;C) performance
in both downlink and uplink scenarios are analyzed. For the downlink case,
three different designs are investigated: the sensing-centric (S-C) design, the
communications-centric (C-C) design, and the Pareto optimal design. For the
uplink case, the S-C design, the C-C design and the time-sharing strategy are
considered. Within each design, sensing rates (SRs) and communication rates
(CRs) are derived. To gain further insights, high signal-to-noise ratio slopes
and rate scaling laws concerning the number of antennas are also examined.
Finally, the attainable SR-CR regions of the near-field ISAC are characterized.
Numerical results reveal that 1) as the number of antennas grows, the SRs and
CRs of the proposed model converges to constants, while those of the TCMs
increase unboundedly; 2) ISAC achieves a more extensive rate region than the
conventional frequency-division S\&amp;C in both downlink and uplink cases.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10920" title="Abstract">arXiv:2310.10920</a> [<a href="/pdf/2310.10920" title="Download PDF">pdf</a>, <a href="/format/2310.10920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NuclearQA: A Human-Made Benchmark for Language Models for the Nuclear  Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acharya%2C+A">Anurag Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Munikoti%2C+S">Sai Munikoti</a>, 
<a href="/search/cs?searchtype=author&query=Hellinger%2C+A">Aaron Hellinger</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S">Sara Smith</a>, 
<a href="/search/cs?searchtype=author&query=Wagle%2C+S">Sridevi Wagle</a>, 
<a href="/search/cs?searchtype=author&query=Horawalavithana%2C+S">Sameera Horawalavithana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As LLMs have become increasingly popular, they have been used in almost every
field. But as the application for LLMs expands from generic fields to narrow,
focused science domains, there exists an ever-increasing gap in ways to
evaluate their efficacy in those fields. For the benchmarks that do exist, a
lot of them focus on questions that don't require proper understanding of the
subject in question. In this paper, we present NuclearQA, a human-made
benchmark of 100 questions to evaluate language models in the nuclear domain,
consisting of a varying collection of questions that have been specifically
designed by experts to test the abilities of language models. We detail our
approach and show how the mix of several types of questions makes our benchmark
uniquely capable of evaluating models in the nuclear domain. We also present
our own evaluation metric for assessing LLM's performances due to the
limitations of existing ones. Our experiments on state-of-the-art models
suggest that even the best LLMs perform less than satisfactorily on our
benchmark, demonstrating the scientific knowledge gap of existing LLMs.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10921" title="Abstract">arXiv:2310.10921</a> [<a href="/pdf/2310.10921" title="Download PDF">pdf</a>, <a href="/format/2310.10921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Software Tooling for Improving Software Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cooper%2C+N">Nathan Cooper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Software has eaten the world with many of the necessities and quality of life
services people use requiring software. Therefore, tools that improve the
software development experience can have a significant impact on the world such
as generating code and test cases, detecting bugs, question and answering,
etc., The success of Deep Learning (DL) over the past decade has shown huge
advancements in automation across many domains, including Software Development
processes. One of the main reasons behind this success is the availability of
large datasets such as open-source code available through GitHub or image
datasets of mobile Graphical User Interfaces (GUIs) with RICO and ReDRAW to be
trained on. Therefore, the central research question my dissertation explores
is: In what ways can the software development process be improved through
leveraging DL techniques on the vast amounts of unstructured software
engineering artifacts?
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10922" title="Abstract">arXiv:2310.10922</a> [<a href="/pdf/2310.10922" title="Download PDF">pdf</a>, <a href="/format/2310.10922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial HuBERT: Self-supervised Spatial Speech Representation Learning  for a Single Talker from Multi-channel Audio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dimitriadis%2C+A">Antoni Dimitriadis</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Siqi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Sethu%2C+V">Vidhyasaharan Sethu</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+B">Beena Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Self-supervised learning has been used to leverage unlabelled data, improving
accuracy and generalisation of speech systems through the training of
representation models. While many recent works have sought to produce effective
representations across a variety of acoustic domains, languages, modalities and
even simultaneous speakers, these studies have all been limited to
single-channel audio recordings. This paper presents Spatial HuBERT, a
self-supervised speech representation model that learns both acoustic and
spatial information pertaining to a single speaker in a potentially noisy
environment by using multi-channel audio inputs. Spatial HuBERT learns
representations that outperform state-of-the-art single-channel speech
representations on a variety of spatial downstream tasks, particularly in
reverberant and noisy environments. We also demonstrate the utility of the
representations learned by Spatial HuBERT on a speech localisation downstream
task. Along with this paper, we publicly release a new dataset of 100 000
simulated first-order ambisonics room impulse responses.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10925" title="Abstract">arXiv:2310.10925</a> [<a href="/pdf/2310.10925" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path Following Control of Automated Vehicle Considering Model  Uncertainties External Disturbances and Parametric Varying
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shen%2C+D">Dan Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Automated Vehicle Path Following Control (PFC) is an advanced control system
that can regulate the vehicle into a collision-free region in the presence of
other objects on the road. Common collision avoidance functions, such as
forward collision warning and automatic emergency braking, have recently been
developed and equipped on production vehicles. However, it is impossible to
develop a perfectly precise vehicle model when the vehicle is driving. Most
PFCs did not consider uncertainties in the vehicle model, external
disturbances, and parameter variations at the same time. To address the issues
associated with this important feature and function in autonomous driving, a
new vehicle PFC is proposed using a robust model predictive control (MPC)
design technique based on matrix inequality and the theoretical approach of the
hybrid $\&amp;$ switched system. The proposed methodology requires a combination of
continuous and discrete states, e.g. regulating the continuous states of the AV
(e.g., velocity and yaw angle) and discrete switching of the control strategy
that affects the dynamic behaviors of the AV under different driving speeds.
Firstly, considering bounded model uncertainties, and norm-bounded external
disturbances, the system states and control matrices are modified.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10928" title="Abstract">arXiv:2310.10928</a> [<a href="/pdf/2310.10928" title="Download PDF">pdf</a>, <a href="/ps/2310.10928" title="Download PostScript">ps</a>, <a href="/format/2310.10928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Audio Data to Facilitate Depression Risk Assessment in Primary  Health Care
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levinson%2C+A+V">Adam Valen Levinson</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+A">Abhay Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Man%2C+R+H+C">Roger Ho Chun Man</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R+K">Roy Ka-Wei Lee</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+K">Koustuv Saha</a>, 
<a href="/search/cs?searchtype=author&query=Parekh%2C+N">Nimay Parekh</a>, 
<a href="/search/cs?searchtype=author&query=Altice%2C+F+L">Frederick L. Altice</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+L+Y">Lam Yin Cheung</a>, 
<a href="/search/cs?searchtype=author&query=De+Choudhury%2C+M">Munmun De Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Navin Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Telehealth is a valuable tool for primary health care (PHC), where depression
is a common condition. PHC is the first point of contact for most people with
depression, but about 25% of diagnoses made by PHC physicians are inaccurate.
Many other barriers also hinder depression detection and treatment in PHC.
Artificial intelligence (AI) may help reduce depression misdiagnosis in PHC and
improve overall diagnosis and treatment outcomes. Telehealth consultations
often have video issues, such as poor connectivity or dropped calls. Audio-only
telehealth is often more practical for lower-income patients who may lack
stable internet connections. Thus, our study focused on using audio data to
predict depression risk. The objectives were to: 1) Collect audio data from 24
people (12 with depression and 12 without mental health or major health
condition diagnoses); 2) Build a machine learning model to predict depression
risk. TPOT, an autoML tool, was used to select the best machine learning
algorithm, which was the K-nearest neighbors classifier. The selected model had
high performance in classifying depression risk (Precision: 0.98, Recall: 0.93,
F1-Score: 0.96). These findings may lead to a range of tools to help screen for
and treat depression. By developing tools to detect depression risk, patients
can be routed to AI-driven chatbots for initial screenings. Partnerships with a
range of stakeholders are crucial to implementing these solutions. Moreover,
ethical considerations, especially around data privacy and potential biases in
AI models, need to be at the forefront of any AI-driven intervention in mental
health care.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10930" title="Abstract">arXiv:2310.10930</a> [<a href="/pdf/2310.10930" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Transformer Architecture for Natural Language Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moon%2C+W">Woohyeon Moon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taeyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+B">Bumgeun Park</a>, 
<a href="/search/cs?searchtype=author&query=Har%2C+D">Dongsoo Har</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformer is a state-of-the-art model in the field of natural language
processing (NLP). Current NLP models primarily increase the number of
transformers to improve processing performance. However, this technique
requires a lot of training resources such as computing capacity. In this paper,
a novel structure of Transformer is proposed. It is featured by full layer
normalization, weighted residual connection, positional encoding exploiting
reinforcement learning, and zero masked self-attention. The proposed
Transformer model, which is called Enhanced Transformer, is validated by the
bilingual evaluation understudy (BLEU) score obtained with the Multi30k
translation dataset. As a result, the Enhanced Transformer achieves 202.96%
higher BLEU score as compared to the original transformer with the translation
dataset.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10931" title="Abstract">arXiv:2310.10931</a> [<a href="/pdf/2310.10931" title="Download PDF">pdf</a>, <a href="/format/2310.10931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Structure: a Structural Benchmark Dataset for SLAM Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanbiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces a new benchmark dataset, Open-Structure, for evaluating
visual odometry and SLAM methods, which directly equips point and line
measurements, correspondences, structural associations, and co-visibility
factor graphs instead of providing raw images. Based on the proposed benchmark
dataset, these 2D or 3D data can be directly input to different stages of SLAM
pipelines to avoid the impact of the data preprocessing modules in ablation
experiments. First, we propose a dataset generator for real-world and simulated
scenarios. In real-world scenes, it maintains the same observations and
occlusions as actual feature extraction results. Those generated simulation
sequences enhance the dataset's diversity by introducing various carefully
designed trajectories and observations. Second, a SLAM baseline is proposed
using our dataset to evaluate widely used modules in camera pose tracking,
parametrization, and optimization modules. By evaluating these state-of-the-art
algorithms across different scenarios, we discern each module's strengths and
weaknesses within the camera tracking and optimization process. Our dataset and
baseline are available at \url{https://github.com/yanyan-li/Open-Structure}.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10935" title="Abstract">arXiv:2310.10935</a> [<a href="/pdf/2310.10935" title="Download PDF">pdf</a>, <a href="/format/2310.10935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intent Detection and Slot Filling for Home Assistants: Dataset and  Analysis for Bangla and Sylheti
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakib%2C+F+A">Fardin Ahsan Sakib</a>, 
<a href="/search/cs?searchtype=author&query=Karim%2C+A+H+M+R">A H M Rezaul Karim</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S+H">Saadat Hasan Khan</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+M">Md Mushfiqur Rahman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the First Workshop on Bangla Language Processing, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As voice assistants cement their place in our technologically advanced
society, there remains a need to cater to the diverse linguistic landscape,
including colloquial forms of low-resource languages. Our study introduces the
first-ever comprehensive dataset for intent detection and slot filling in
formal Bangla, colloquial Bangla, and Sylheti languages, totaling 984 samples
across 10 unique intents. Our analysis reveals the robustness of large language
models for tackling downstream tasks with inadequate data. The GPT-3.5 model
achieves an impressive F1 score of 0.94 in intent detection and 0.51 in slot
filling for colloquial Bangla.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10939" title="Abstract">arXiv:2310.10939</a> [<a href="/pdf/2310.10939" title="Download PDF">pdf</a>, <a href="/format/2310.10939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Simple Spectral Clustering in Theory and Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macgregor%2C+P">Peter Macgregor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Spectral clustering is a popular and effective algorithm designed to find $k$
clusters in a graph $G$. In the classical spectral clustering algorithm, the
vertices of $G$ are embedded into $\mathbb{R}^k$ using $k$ eigenvectors of the
graph Laplacian matrix. However, computing this embedding is computationally
expensive and dominates the running time of the algorithm. In this paper, we
present a simple spectral clustering algorithm based on a vertex embedding with
$O(\log(k))$ vectors computed by the power method. The vertex embedding is
computed in nearly-linear time with respect to the size of the graph, and the
algorithm provably recovers the ground truth clusters under natural assumptions
on the input graph. We evaluate the new algorithm on several synthetic and
real-world datasets, finding that it is significantly faster than alternative
clustering algorithms, while producing results with approximately the same
clustering accuracy.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10941" title="Abstract">arXiv:2310.10941</a> [<a href="/pdf/2310.10941" title="Download PDF">pdf</a>, <a href="/format/2310.10941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MASON-NLP at eRisk 2023: Deep Learning-Based Detection of Depression  Symptoms from Social Media Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakib%2C+F+A">Fardin Ahsan Sakib</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+A+A">Ahnaf Atef Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Uzuner%2C+O">Ozlem Uzuner</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Working Notes of CLEF (2023): 18-21
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Depression is a mental health disorder that has a profound impact on people's
lives. Recent research suggests that signs of depression can be detected in the
way individuals communicate, both through spoken words and written texts. In
particular, social media posts are a rich and convenient text source that we
may examine for depressive symptoms. The Beck Depression Inventory (BDI)
Questionnaire, which is frequently used to gauge the severity of depression, is
one instrument that can aid in this study. We can narrow our study to only
those symptoms since each BDI question is linked to a particular depressive
symptom. It's important to remember that not everyone with depression exhibits
all symptoms at once, but rather a combination of them. Therefore, it is
extremely useful to be able to determine if a sentence or a piece of
user-generated content is pertinent to a certain condition. With this in mind,
the eRisk 2023 Task 1 was designed to do exactly that: assess the relevance of
different sentences to the symptoms of depression as outlined in the BDI
questionnaire. This report is all about how our team, Mason-NLP, participated
in this subtask, which involved identifying sentences related to different
depression symptoms. We used a deep learning approach that incorporated
MentalBERT, RoBERTa, and LSTM. Despite our efforts, the evaluation results were
lower than expected, underscoring the challenges inherent in ranking sentences
from an extensive dataset about depression, which necessitates both appropriate
methodological choices and significant computational resources. We anticipate
that future iterations of this shared task will yield improved results as our
understanding and techniques evolve.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10942" title="Abstract">arXiv:2310.10942</a> [<a href="/pdf/2310.10942" title="Download PDF">pdf</a>, <a href="/format/2310.10942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unanswerable Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanyang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+F">Fangkai Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Teaching Visual Question Answering (VQA) models to abstain from unanswerable
questions is indispensable for building a trustworthy AI system. Existing
studies, though have explored various aspects of VQA, yet marginally ignored
this particular attribute. This paper aims to bridge the research gap by
contributing a comprehensive dataset, called UNK-VQA. The dataset is
specifically designed to address the challenge of questions that can be
unanswerable. To this end, we first augment the existing data via deliberate
perturbations on either the image or question. In specific, we carefully ensure
that the question-image semantics remain close to the original unperturbed
distribution. By means of this, the identification of unanswerable questions
becomes challenging, setting our dataset apart from others that involve mere
image replacement. We then extensively evaluate the zero- and few-shot
performance of several emerging multi-modal large models and discover
significant limitations of them when applied to our dataset. Additionally, we
also propose a straightforward method to tackle these unanswerable questions.
This dataset, we believe, will serve as a valuable benchmark for enhancing the
abstention capability of VQA models, thereby leading to increased
trustworthiness of AI systems.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10943" title="Abstract">arXiv:2310.10943</a> [<a href="/pdf/2310.10943" title="Download PDF">pdf</a>, <a href="/format/2310.10943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reaching the Limit in Autonomous Racing: Optimal Control versus  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yunlong Song</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+A">Angel Romero</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+M">Matthias Mueller</a>, 
<a href="/search/cs?searchtype=author&query=Koltun%2C+V">Vladlen Koltun</a>, 
<a href="/search/cs?searchtype=author&query=Scaramuzza%2C+D">Davide Scaramuzza</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Science Robotics, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A central question in robotics is how to design a control system for an agile
mobile robot. This paper studies this question systematically, focusing on a
challenging setting: autonomous drone racing. We show that a neural network
controller trained with reinforcement learning (RL) outperformed optimal
control (OC) methods in this setting. We then investigated which fundamental
factors have contributed to the success of RL or have limited OC. Our study
indicates that the fundamental advantage of RL over OC is not that it optimizes
its objective better but that it optimizes a better objective. OC decomposes
the problem into planning and control with an explicit intermediate
representation, such as a trajectory, that serves as an interface. This
decomposition limits the range of behaviors that can be expressed by the
controller, leading to inferior control performance when facing unmodeled
effects. In contrast, RL can directly optimize a task-level objective and can
leverage domain randomization to cope with model uncertainty, allowing the
discovery of more robust control responses. Our findings allowed us to push an
agile drone to its maximum performance, achieving a peak acceleration greater
than 12 times the gravitational acceleration and a peak velocity of 108
kilometers per hour. Our policy achieved superhuman control within minutes of
training on a standard workstation. This work presents a milestone in agile
robotics and sheds light on the role of RL and OC in robot control.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10944" title="Abstract">arXiv:2310.10944</a> [<a href="/pdf/2310.10944" title="Download PDF">pdf</a>, <a href="/format/2310.10944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEQ: Trainable Equivalent Transformation for Quantization of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wenhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiyang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+K">Kaokao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haihao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As large language models (LLMs) become more prevalent, there is a growing
need for new and improved quantization methods that can meet the
computationalast layer demands of these modern architectures while maintaining
the accuracy. In this paper, we present TEQ, a trainable equivalent
transformation that preserves the FP32 precision of the model output while
taking advantage of low-precision quantization, especially 3 and 4 bits
weight-only quantization. The training process is lightweight, requiring only
1K steps and fewer than 0.1 percent of the original model's trainable
parameters. Furthermore, the transformation does not add any computational
overhead during inference. Our results are on-par with the state-of-the-art
(SOTA) methods on typical LLMs. Our approach can be combined with other methods
to achieve even better performance. The code is available at
https://github.com/intel/neural-compressor.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10946" title="Abstract">arXiv:2310.10946</a> [<a href="/pdf/2310.10946" title="Download PDF">pdf</a>, <a href="/ps/2310.10946" title="Download PostScript">ps</a>, <a href="/format/2310.10946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-point Feedback of Bandit Convex Optimization with Hard Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hikima%2C+Y">Yasunari Hikima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper studies bandit convex optimization with constraints, where the
learner aims to generate a sequence of decisions under partial information of
loss functions such that the cumulative loss is reduced as well as the
cumulative constraint violation is simultaneously reduced. We adopt the
cumulative \textit{hard} constraint violation as the metric of constraint
violation, which is defined by $\sum_{t=1}^{T} \max\{g_t(\boldsymbol{x}_t),
0\}$. Owing to the maximum operator, a strictly feasible solution cannot cancel
out the effects of violated constraints compared to the conventional metric
known as \textit{long-term} constraints violation. We present a penalty-based
proximal gradient descent method that attains a sub-linear growth of both
regret and cumulative hard constraint violation, in which the gradient is
estimated with a two-point function evaluation. Precisely, our algorithm
attains $O(d^2T^{\max\{c,1-c\}})$ regret bounds and $O(d^2T^{1-\frac{c}{2}})$
cumulative hard constraint violation bounds for convex loss functions and
time-varying constraints, where $d$ is the dimensionality of the feasible
region and $c\in[\frac{1}{2}, 1)$ is a user-determined parameter. We also
extend the result for the case where the loss functions are strongly convex and
show that both regret and constraint violation bounds can be further reduced.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10948" title="Abstract">arXiv:2310.10948</a> [<a href="/pdf/2310.10948" title="Download PDF">pdf</a>, <a href="/format/2310.10948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combat Urban Congestion via Collaboration: Heterogeneous GNN-based MARL  for Coordinated Platooning and Traffic Signal Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xianyue Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H+M">H. Michael Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Over the years, reinforcement learning has emerged as a popular approach to
develop signal control and vehicle platooning strategies either independently
or in a hierarchical way. However, jointly controlling both in real-time to
alleviate traffic congestion presents new challenges, such as the inherent
physical and behavioral heterogeneity between signal control and platooning, as
well as coordination between them. This paper proposes an innovative solution
to tackle these challenges based on heterogeneous graph multi-agent
reinforcement learning and traffic theories. Our approach involves: 1)
designing platoon and signal control as distinct reinforcement learning agents
with their own set of observations, actions, and reward functions to optimize
traffic flow; 2) designing coordination by incorporating graph neural networks
within multi-agent reinforcement learning to facilitate seamless information
exchange among agents on a regional scale. We evaluate our approach through
SUMO simulation, which shows a convergent result in terms of various
transportation metrics and better performance over sole signal or platooning
control.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10949" title="Abstract">arXiv:2310.10949</a> [<a href="/pdf/2310.10949" title="Download PDF">pdf</a>, <a href="/format/2310.10949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network-aware EV charging and discharging in unbalanced distribution  grids: A distributed, robust approach against communication failures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nimalsiri%2C+N">Nanduni Nimalsiri</a>, 
<a href="/search/eess?searchtype=author&query=Ratnam%2C+E">Elizabeth Ratnam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted for presentation at the 2023 IEEE International Conference on Energy Technologies for Future Grids (ETFG) and will be published on the IEEE Xplore after presentation. This work was supported by the Australian Research Council under Grant DP220101035
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a distributed optimization-based algorithm for electric
vehicle (EV) charging and discharging, incorporating EV customer economics and
distribution network constraints enforced on an unbalanced distribution grid.
Building on a consensus-based alternating direction method of multipliers
(ADMM), the algorithm is designed such that EVs coordinate by means of
exchanging limited information with their neighboring EVs in a connected
communication network. Specifically, an iterative routine is executed, whereby
EVs cooperatively determine their charge-discharge profiles that maintain the
distribution grid voltages and transformer core temperatures within safe
operating limits. Importantly, the algorithm is robust against communication
failures potentially arising in real-world implementations. Numerical
simulations are conducted to verify the efficacy of the proposed EV charging
algorithm in terms of network-aware operation and communication-failure
tolerant operation.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10953" title="Abstract">arXiv:2310.10953</a> [<a href="/pdf/2310.10953" title="Download PDF">pdf</a>, <a href="/format/2310.10953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Local Graph Limits Perspective on Sampling-Based GNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alimohammadi%2C+Y">Yeganeh Alimohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+L">Luana Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Saberi%2C+A">Amin Saberi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a theoretical framework for training Graph Neural Networks (GNNs)
on large input graphs via training on small, fixed-size sampled subgraphs. This
framework is applicable to a wide range of models, including popular
sampling-based GNNs, such as GraphSAGE and FastGCN. Leveraging the theory of
graph local limits, we prove that, under mild assumptions, parameters learned
from training sampling-based GNNs on small samples of a large input graph are
within an $\epsilon$-neighborhood of the outcome of training the same
architecture on the whole graph. We derive bounds on the number of samples, the
size of the graph, and the training steps required as a function of $\epsilon$.
Our results give a novel theoretical understanding for using sampling in
training GNNs. They also suggest that by training GNNs on small samples of the
input graph, practitioners can identify and select the best models,
hyperparameters, and sampling algorithms more efficiently. We empirically
illustrate our results on a node classification task on large citation graphs,
observing that sampling-based GNNs trained on local subgraphs 12$\times$
smaller than the original graph achieve comparable performance to those trained
on the input graph.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10954" title="Abstract">arXiv:2310.10954</a> [<a href="/pdf/2310.10954" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of a fault free Inverter Circuit using Minimum number of cells &amp;  related Kink Energy Calculation in Quantum dot Cellular Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakrabarty%2C+R">Ratna Chakrabarty</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Angshuman Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proc. of 2013 International Conference on Computation and Communication Advancement (IC3A), Kalyani, India, 2013
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Hardware Architecture (cs.AR); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Quantum dot Cellular Automata (QCA) is the most promising nanotechnology in
the field of microelectronics and VLSI systems. QCA-based circuits require less
power with a high switching speed of operation compared to CMOS technology. QCA
inverter is one of the basic building blocks of QCA circuit design. The
conventional QCA inverter design requires many cells. In this paper, we design
the QCA inverter circuit using a lesser number of cells. We showed the kink
energy calculation for the QCA-implemented inverters as well as the
polarization of the circuits.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10955" title="Abstract">arXiv:2310.10955</a> [<a href="/pdf/2310.10955" title="Download PDF">pdf</a>, <a href="/format/2310.10955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A State-Vector Framework for Dataset Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahak%2C+E">Esmat Sahak</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zining Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Rudzicz%2C+F">Frank Rudzicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The impressive success of recent deep neural network (DNN)-based systems is
significantly influenced by the high-quality datasets used in training.
However, the effects of the datasets, especially how they interact with each
other, remain underexplored. We propose a state-vector framework to enable
rigorous studies in this direction. This framework uses idealized probing test
results as the bases of a vector space. This framework allows us to quantify
the effects of both standalone and interacting datasets. We show that the
significant effects of some commonly-used language understanding datasets are
characteristic and are concentrated on a few linguistic dimensions.
Additionally, we observe some ``spill-over'' effects: the datasets could impact
the models along dimensions that may seem unrelated to the intended tasks. Our
state-vector framework paves the way for a systematic understanding of the
dataset effects, a crucial component in responsible and robust model
development.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10956" title="Abstract">arXiv:2310.10956</a> [<a href="/pdf/2310.10956" title="Download PDF">pdf</a>, <a href="/format/2310.10956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing the optimal keyboard through a geometric analysis of the  English language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deschamps%2C+J">Jules Deschamps</a>, 
<a href="/search/cs?searchtype=author&query=Hubert%2C+Q">Quentin Hubert</a>, 
<a href="/search/cs?searchtype=author&query=Ryckelynck%2C+L">Lucas Ryckelynck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In the context of a group project for the course COMSW4995 002 - Geometric
Data Analysis, we bring our attention to the design of fast-typing keyboards.
Leveraging some geometric tools in an optimization framework allowed us to
propose novel keyboard layouts that offer a faster typing.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10958" title="Abstract">arXiv:2310.10958</a> [<a href="/pdf/2310.10958" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Deep Neural Network Training Efficiency and Performance  through Linear Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+H">Hejie Ying</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mengmeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yaohong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shungen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zimin Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep neural networks (DNN) have achieved remarkable success in various
fields, including computer vision and natural language processing. However,
training an effective DNN model still poses challenges. This paper aims to
propose a method to optimize the training effectiveness of DNN, with the goal
of improving model performance. Firstly, based on the observation that the DNN
parameters change in certain laws during training process, the potential of
parameter prediction for improving model training efficiency and performance is
discovered. Secondly, considering the magnitude of DNN model parameters,
hardware limitations and characteristics of Stochastic Gradient Descent (SGD)
for noise tolerance, a Parameter Linear Prediction (PLP) method is exploit to
perform DNN parameter prediction. Finally, validations are carried out on some
representative backbones. Experiment results show that compare to the normal
training ways, under the same training conditions and epochs, by employing
proposed PLP method, the optimal model is able to obtain average about 1%
accuracy improvement and 0.01 top-1/top-5 error reduction for Vgg16, Resnet18
and GoogLeNet based on CIFAR-100 dataset, which shown the effectiveness of the
proposed method on different DNN structures, and validated its capacity in
enhancing DNN training efficiency and performance.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10959" title="Abstract">arXiv:2310.10959</a> [<a href="/pdf/2310.10959" title="Download PDF">pdf</a>, <a href="/format/2310.10959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Origami-inspired Bi-directional Actuator with Orthogonal Actuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Athar%2C+S">Sheeraz Athar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M+Y">Michael Yu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Origami offers a promising alternative for designing innovative soft robotic
actuators. While features of origami, such as bi-directional motion and
structural anisotropy, haven't been extensively explored in the past, this
letter presents a novel design inspired by origami tubes for a bi-directional
actuator. This actuator is capable of moving in two orthogonal directions and
has separate channels throughout its body to control each movement. We
introduce a bottom-up design methodology that can also be adapted for other
complex movements. The actuator was manufactured using popular 3D printing
techniques. To enhance its durability, we experimented with different 3D
printing technologies and materials. The actuator's strength was further
improved using silicon spin coating, and we compared the performance of coated,
uncoated, and silicon-only specimens. The material model was empirically
derived by testing specimens on a universal testing machine (UTM). Lastly, we
suggest potential applications for these actuators, such as in quadruped
robots.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10961" title="Abstract">arXiv:2310.10961</a> [<a href="/pdf/2310.10961" title="Download PDF">pdf</a>, <a href="/format/2310.10961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stealthy Terrain-Aware Multi-Agent Active Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakshi%2C+N+A">Nikhil Angad Bakshi</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jeff Schneider</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 28 figures, for demo video see: <a href="https://youtu.be/Fs1lv4y6Nq8">this https URL</a> , accepted for presentation in Conference on Robot Learning 2023, Atlanta, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Stealthy multi-agent active search is the problem of making efficient
sequential data-collection decisions to identify an unknown number of sparsely
located targets while adapting to new sensing information and concealing the
search agents' location from the targets. This problem is applicable to
reconnaissance tasks wherein the safety of the search agents can be compromised
as the targets may be adversarial. Prior work usually focuses either on
adversarial search, where the risk of revealing the agents' location to the
targets is ignored or evasion strategies where efficient search is ignored. We
present the Stealthy Terrain-Aware Reconnaissance (STAR) algorithm, a
multi-objective parallelized Thompson sampling-based algorithm that relies on a
strong topographical prior to reason over changing visibility risk over the
course of the search. The STAR algorithm outperforms existing state-of-the-art
multi-agent active search methods on both rate of recovery of targets as well
as minimising risk even when subject to noisy observations, communication
failures and an unknown number of targets.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10962" title="Abstract">arXiv:2310.10962</a> [<a href="/pdf/2310.10962" title="Download PDF">pdf</a>, <a href="/format/2310.10962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Aware Contrastive Sentence Representation Learning with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Liying Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaodonghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Soh%2C+D+W">De Wen Soh</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Lidong Bing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Contrastive learning has been proven to be effective in learning better
sentence representations. However, to train a contrastive learning model, large
numbers of labeled sentences are required to construct positive and negative
pairs explicitly, such as those in natural language inference (NLI) datasets.
Unfortunately, acquiring sufficient high-quality labeled data can be both
time-consuming and resource-intensive, leading researchers to focus on
developing methods for learning unsupervised sentence representations. As there
is no clear relationship between these unstructured randomly-sampled sentences,
building positive and negative pairs over them is tricky and problematic. To
tackle these challenges, in this paper, we propose SemCSR, a semantic-aware
contrastive sentence representation framework. By leveraging the generation and
evaluation capabilities of large language models (LLMs), we can automatically
construct a high-quality NLI-style corpus without any human annotation, and
further incorporate the generated sentence pairs into learning a contrastive
sentence representation model. Extensive experiments and comprehensive analyses
demonstrate the effectiveness of our proposed framework for learning a better
sentence representation with LLMs.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10963" title="Abstract">arXiv:2310.10963</a> [<a href="/pdf/2310.10963" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MRI brain tumor segmentation using informative feature vectors and  kernel dictionary learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mousavi%2C+S+M">Seyedeh Mahya Mousavi</a>, 
<a href="/search/cs?searchtype=author&query=Mostafavi%2C+M">Mohammad Mostafavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper presents a method based on a kernel dictionary learning algorithm
for segmenting brain tumor regions in magnetic resonance images (MRI). A set of
first-order and second-order statistical feature vectors are extracted from
patches of size 3 * 3 around pixels in the brain MRI scans. These feature
vectors are utilized to train two kernel dictionaries separately for healthy
and tumorous tissues. To enhance the efficiency of the dictionaries and reduce
training time, a correlation-based sample selection technique is developed to
identify the most informative and discriminative subset of feature vectors.
This technique aims to improve the performance of the dictionaries by selecting
a subset of feature vectors that provide valuable information for the
segmentation task. Subsequently, a linear classifier is utilized to distinguish
between healthy and unhealthy pixels based on the learned dictionaries. The
results demonstrate that the proposed method outperforms other existing methods
in terms of segmentation accuracy and significantly reduces both the time and
memory required, resulting in a remarkably fast training process.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10964" title="Abstract">arXiv:2310.10964</a> [<a href="/pdf/2310.10964" title="Download PDF">pdf</a>, <a href="/format/2310.10964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral-Efficiency and Energy-Efficiency of Variable-Length XP-HARQ
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiahui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yaru Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanghua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shaodan Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A variable-length cross-packet hybrid automatic repeat request (VL-XP-HARQ)
is proposed to boost the spectral efficiency (SE) and the energy efficiency
(EE) of communications. The SE is firstly derived in terms of the outage
probabilities, with which the SE is proved to be upper bounded by the ergodic
capacity (EC). Moreover, to facilitate the maximization of the SE, the
asymptotic outage probability is obtained at high signal-to-noise ratio (SNR),
with which the SE is maximized by properly choosing the number of new
information bits while guaranteeing outage requirement. By applying
Dinkelbach's transform, the fractional objective function is transformed into a
subtraction form, which can be decomposed into multiple sub-problems through
alternating optimization. By noticing that the asymptotic outage probability is
a convex function, each sub-problem can be easily relaxed to a convex problem
by adopting successive convex approximation (SCA). Besides, the EE of
VL-XP-HARQ is also investigated. An upper bound of the EE is found and proved
to be attainable. Furthermore, by aiming at maximizing the EE via power
allocation while confining outage within a certain constraint, the methods to
the maximization of SE are invoked to solve the similar fractional problem.
Finally, numerical results are presented for verification.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10967" title="Abstract">arXiv:2310.10967</a> [<a href="/pdf/2310.10967" title="Download PDF">pdf</a>, <a href="/format/2310.10967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EXMODD: An EXplanatory Multimodal Open-Domain Dialogue dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Pinren Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The need for high-quality data has been a key issue hindering the research of
dialogue tasks. Recent studies try to build datasets through manual, web
crawling, and large pre-trained models. However, man-made data is expensive and
data collected from the internet often includes generic responses, meaningless
statements, and toxic dialogues. Automatic data generation through large models
is a cost-effective method, but for open-domain multimodal dialogue tasks,
there are still three drawbacks: 1) There is currently no open-source large
model that can accept multimodal input; 2) The content generated by the model
lacks interpretability; 3) The generated data is usually difficult to quality
control and require extensive resource to collect. To alleviate the significant
human and resource expenditure in data collection, we propose a Multimodal Data
Construction Framework (MDCF). MDCF designs proper prompts to spur the
large-scale pre-trained language model to generate well-formed and satisfactory
content. Additionally, MDCF also automatically provides explanation for a given
image and its corresponding dialogue, which can provide a certain degree of
interpretability and facilitate manual follow-up quality inspection. Based on
this, we release an Explanatory Multimodal Open-Domain dialogue dataset
(EXMODD). Experiments indicate a positive correlation between the model's
ability to generate accurate understandings and high-quality responses. Our
code and data can be found at https://github.com/poplpr/EXMODD.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10970" title="Abstract">arXiv:2310.10970</a> [<a href="/pdf/2310.10970" title="Download PDF">pdf</a>, <a href="/format/2310.10970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SD-PINN: Deep Learning based Spatially Dependent PDEs Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruixian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gerstoft%2C+P">Peter Gerstoft</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The physics-informed neural network (PINN) is capable of recovering partial
differential equation (PDE) coefficients that remain constant throughout the
spatial domain directly from physical measurements. In this work, we propose a
spatially dependent physics-informed neural network (SD-PINN), which enables
the recovery of coefficients in spatially-dependent PDEs using a single neural
network, eliminating the requirement for domain-specific physical expertise.
The proposed method exhibits robustness to noise owing to the incorporation of
physical constraints. It can also incorporate the low-rank assumption of the
spatial variation for the PDE coefficients to recover the coefficients at
locations without available measurements.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10971" title="Abstract">arXiv:2310.10971</a> [<a href="/pdf/2310.10971" title="Download PDF">pdf</a>, <a href="/format/2310.10971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fifty%2C+C">Christopher Fifty</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+D">Dennis Duan</a>, 
<a href="/search/cs?searchtype=author&query=Junkins%2C+R+G">Ronald G. Junkins</a>, 
<a href="/search/cs?searchtype=author&query=Amid%2C+E">Ehsan Amid</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A9%2C+C">Christopher R&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Thrun%2C+S">Sebastian Thrun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Large Language Models like ChatGPT demonstrate a remarkable capacity to learn
new concepts during inference without any fine-tuning. However, visual models
trained to detect new objects during inference have been unable to replicate
this ability, and instead either perform poorly or require meta-training and/or
fine-tuning on similar objects. In this work, we propose a meta-learning
algorithm that emulates Large Language Models by learning new visual concepts
during inference without fine-tuning. Our approach leverages a frozen
pre-trained feature extractor, and analogous to in-context learning, recasts
meta-learning as sequence modeling over datapoints with known labels and a test
datapoint with an unknown label. On 8 out of 11 meta-learning benchmarks, our
approach -- without meta-training or fine-tuning -- exceeds or matches the
state-of-the-art algorithm, P&gt;M&gt;F, which is meta-trained on these benchmarks.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10975" title="Abstract">arXiv:2310.10975</a> [<a href="/pdf/2310.10975" title="Download PDF">pdf</a>, <a href="/format/2310.10975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NICE: Improving Panoptic Narrative Detection and Segmentation with  Cascading Collaborative Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiayi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yilong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoshuai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages. 9 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Panoptic Narrative Detection (PND) and Segmentation (PNS) are two challenging
tasks that involve identifying and locating multiple targets in an image
according to a long narrative description. In this paper, we propose a unified
and effective framework called NICE that can jointly learn these two panoptic
narrative recognition tasks. Existing visual grounding tasks use a two-branch
paradigm, but applying this directly to PND and PNS can result in prediction
conflict due to their intrinsic many-to-many alignment property. To address
this, we introduce two cascading modules based on the barycenter of the mask,
which are Coordinate Guided Aggregation (CGA) and Barycenter Driven
Localization (BDL), responsible for segmentation and detection, respectively.
By linking PNS and PND in series with the barycenter of segmentation as the
anchor, our approach naturally aligns the two tasks and allows them to
complement each other for improved performance. Specifically, CGA provides the
barycenter as a reference for detection, reducing BDL's reliance on a large
number of candidate boxes. BDL leverages its excellent properties to
distinguish different instances, which improves the performance of CGA for
segmentation. Extensive experiments demonstrate that NICE surpasses all
existing methods by a large margin, achieving 4.1% for PND and 2.9% for PNS
over the state-of-the-art. These results validate the effectiveness of our
proposed collaborative learning strategy. The project of this work is made
publicly available at https://github.com/Mr-Neko/NICE.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10977" title="Abstract">arXiv:2310.10977</a> [<a href="/pdf/2310.10977" title="Download PDF">pdf</a>, <a href="/format/2310.10977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A positivity-preserving numerical method for a thin liquid film on a  vertical cylindrical fiber
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kim%2C+B">Bohyun Kim</a>, 
<a href="/search/math?searchtype=author&query=Ji%2C+H">Hangjie Ji</a>, 
<a href="/search/math?searchtype=author&query=Bertozzi%2C+A+L">Andrea L. Bertozzi</a>, 
<a href="/search/math?searchtype=author&query=Sadeghpour%2C+A">Abolfazl Sadeghpour</a>, 
<a href="/search/math?searchtype=author&query=Ju%2C+Y+S">Y. Sungtaek Ju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">When a thin liquid film flows down on a vertical fiber, one can observe the
complex and captivating interfacial dynamics of an unsteady flow. Such dynamics
are applicable in various fluid experiments due to their high surface
area-to-volume ratio. Recent studies verified that when the flow undergoes
regime transitions, the magnitude of the film thickness changes dramatically,
making numerical simulations challenging. In this paper, we present a
computationally efficient numerical method that can maintain the positivity of
the film thickness as well as conserve the volume of the fluid under the coarse
mesh setting. A series of comparisons to laboratory experiments and previously
proposed numerical methods supports the validity of our numerical method. We
also prove that our method is second-order consistent in space and satisfies
the entropy estimate.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10980" title="Abstract">arXiv:2310.10980</a> [<a href="/pdf/2310.10980" title="Download PDF">pdf</a>, <a href="/format/2310.10980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of potential flow networks: Variations in transport time with  $discrete$, $continuous$, and $selfish$ operation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kurian%2C+V">Varghese Kurian</a>, 
<a href="/search/eess?searchtype=author&query=Narasimhan%2C+S">Sridharakumar Narasimhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In potential flow networks, the equilibrium flow rates are usually not
proportional to the demands and flow control elements are required to regulate
the flow. The control elements can broadly be classified into two types -
discrete and continuous. Discrete control elements can have only two
operational states: fully open or fully closed. On the other hand, continuous
control elements may be operated in any intermediate position in addition to
the fully open and fully closed states. Naturally, with their increased
flexibility, continuous control elements can provide better network
performance, but $to~what~extent$?
<br />We consider a class of branched networks with a single source and multiple
sinks. The potential drop across edges ($\Delta H$) is assumed to be
proportional to the $n^{th}$ power of flow rate ($Q$), i.e., $\Delta H=kQ^n$ ,
($n&gt;=1$). We define $\textbf{R}$ as the ratio of minimal operational times
required to transport a given quantum of material with either type of control
element and show that $1\leq \textbf{R}\leq m^{\left(1-1/n\right)}$, where $m$
is the maximum depth of the network. The results point to the role of network
topology in the variations in operational time. Further analysis reveals that
the selfish operation of a network with continuous control valves has the same
bounds on the price of anarchy.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10981" title="Abstract">arXiv:2310.10981</a> [<a href="/pdf/2310.10981" title="Download PDF">pdf</a>, <a href="/format/2310.10981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instructive Dialogue Summarization with Query Aggregations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept to EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Conventional dialogue summarization methods directly generate summaries and
do not consider user's specific interests. This poses challenges in cases where
the users are more focused on particular topics or aspects. With the
advancement of instruction-finetuned language models, we introduce
instruction-tuning to dialogues to expand the capability set of dialogue
summarization models. To overcome the scarcity of instructive dialogue
summarization data, we propose a three-step approach to synthesize high-quality
query-based summarization triples. This process involves summary-anchored query
generation, query filtering, and query-based summary generation. By training a
unified model called InstructDS (Instructive Dialogue Summarization) on three
summarization datasets with multi-purpose instructive triples, we expand the
capability of dialogue summarization models. We evaluate our method on four
datasets, including dialogue summarization and dialogue reading comprehension.
Experimental results show that our approach outperforms the state-of-the-art
models and even models with larger sizes. Additionally, our model exhibits
higher generalizability and faithfulness, as confirmed by human subjective
evaluations.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10982" title="Abstract">arXiv:2310.10982</a> [<a href="/pdf/2310.10982" title="Download PDF">pdf</a>, <a href="/format/2310.10982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SICNav: Safe and Interactive Crowd Navigation using Model Predictive  Control and Bilevel Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samavi%2C+S">Sepehr Samavi</a>, 
<a href="/search/cs?searchtype=author&query=Shkurti%2C+F">Florian Shkurti</a>, 
<a href="/search/cs?searchtype=author&query=Schoellig%2C+A+P">Angela P. Schoellig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently under review for IEEE Transactions on Robotics (T-RO)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robots need to predict and react to human motions to navigate through a crowd
without collisions. Many existing methods decouple prediction from planning,
which does not account for the interaction between robot and human motions and
can lead to the robot getting stuck. We propose SICNav, a Model Predictive
Control (MPC) method that jointly solves for robot motion and predicted crowd
motion in closed-loop. We model each human in the crowd to be following an
Optimal Reciprocal Collision Avoidance (ORCA) scheme and embed that model as a
constraint in the robot's local planner, resulting in a bilevel nonlinear MPC
optimization problem. We use a KKT-reformulation to cast the bilevel problem as
a single level and use a nonlinear solver to optimize. Our MPC method can
influence pedestrian motion while explicitly satisfying safety constraints in a
single-robot multi-human environment. We analyze the performance of SICNav in a
simulation environment to demonstrate safe robot motion that can influence the
surrounding humans. We also validate the trajectory forecasting performance of
ORCA on a human trajectory dataset.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10984" title="Abstract">arXiv:2310.10984</a> [<a href="/pdf/2310.10984" title="Download PDF">pdf</a>, <a href="/ps/2310.10984" title="Download PostScript">ps</a>, <a href="/format/2310.10984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent class analysis with weighted responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qing%2C+H">Huan Qing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The latent class model has been proposed as a powerful tool for cluster
analysis of categorical data in various fields such as social, psychological,
behavioral, and biological sciences. However, one important limitation of the
latent class model is that it is only suitable for data with binary responses,
making it fail to model real-world data with continuous or negative responses.
In many applications, ignoring the weights throws out a lot of potentially
valuable information contained in the weights. To address this limitation, we
propose a novel generative model, the weighted latent class model (WLCM). Our
model allows data's response matrix to be generated from an arbitrary
distribution with a latent class structure. In comparison to the latent class
model, our WLCM is more realistic and more general. To our knowledge, our WLCM
is the first model for latent class analysis with weighted responses. We
investigate the identifiability of the model and propose an efficient algorithm
for estimating the latent classes and other model parameters. We show that the
proposed algorithm enjoys consistent estimation. The performance of the
proposed algorithm is investigated using both computer-generated and real-world
weighted response data.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10985" title="Abstract">arXiv:2310.10985</a> [<a href="/pdf/2310.10985" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational synthesis of locomoting soft robots by topology  optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+H">Hiroki Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Gholami%2C+F">Farzad Gholami</a>, 
<a href="/search/cs?searchtype=author&query=Montgomery%2C+S+M">S. Macrae Montgomery</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+M">Masato Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+L">Liang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Yuhn%2C+C">Changyoung Yuhn</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yuki Sato</a>, 
<a href="/search/cs?searchtype=author&query=Kawamoto%2C+A">Atsushi Kawamoto</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H+J">H. Jerry Qi</a>, 
<a href="/search/cs?searchtype=author&query=Nomura%2C+T">Tsuyoshi Nomura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 total pages (19 pages, 3 supplementary pages), 4 Figures, 4 Supplementary figures. 1 Supplementary table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Biological organisms have acquired sophisticated body shapes for walking or
climbing through million-year evolutionary processes. In contrast, the
components of locomoting soft robots, such as legs and arms, are designed in
trial-and-error loops guided by a priori knowledge and experience, which leaves
considerable room for improvement. Here, we present optimized soft robots that
performed a specific locomotion task without any a priori assumptions or
knowledge of the layout and shapes of the limbs by fully exploiting the
computational capabilities for topology optimization. The only requirements
introduced were a design domain and a periodically acting pneumatic actuator.
The freeform shape of a soft body was derived from iterative updates in a
gradient-based topology optimization that incorporated complex physical
phenomena, such as large deformations, contacts, material viscosity, and
fluid-structure interactions, in transient problems. The locomotion tasks
included a horizontal movement on flat ground (walking) and a vertical movement
between two walls (climbing). Without any human intervention, optimized soft
robots have limbs and exhibit locomotion similar to those of biological
organisms. Linkage-like structures were formed for the climbing task to assign
different movements to multiple legs with limited degrees of freedom in the
actuator. We fabricated the optimized design using 3D printing and confirmed
the performance of these robots. This study presents a new and efficient
strategy for designing soft robots and other bioinspired systems, suggesting
that a purely mathematical process can produce shapes reminiscent of nature's
long-term evolution.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10987" title="Abstract">arXiv:2310.10987</a> [<a href="/pdf/2310.10987" title="Download PDF">pdf</a>, <a href="/format/2310.10987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Do Students Drop Out? University Dropout Prediction and Associated  Factor Analysis Using Machine Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sean Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+E">Eliot Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Samuel Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Graduation and dropout rates have always been a serious consideration for
educational institutions and students. High dropout rates negatively impact
both the lives of individual students and institutions. To address this
problem, this study examined university dropout prediction using academic,
demographic, socioeconomic, and macroeconomic data types. Additionally, we
performed associated factor analysis to analyze which type of data would be
most influential on the performance of machine learning models in predicting
graduation and dropout status. These features were used to train four binary
classifiers to determine if students would graduate or drop out. The overall
performance of the classifiers in predicting dropout status had an average
ROC-AUC score of 0.935. The data type most influential to the model performance
was found to be academic data, with the average ROC-AUC score dropping from
0.935 to 0.811 when excluding all academic-related features from the data set.
Preliminary results indicate that a correlation does exist between data types
and dropout status.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10988" title="Abstract">arXiv:2310.10988</a> [<a href="/pdf/2310.10988" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HCI in e-Government and e-Democracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tianmu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This chapter introduces the application of HCI design processes and design
principles in e-government and e-democracy. We elaborate on HCI design
processes and six HCI design principles in the context of e-government and
e-democracy, including citizen-centered design, usability, accessibility,
access to information, transaction efficiency, and security and privacy. Then,
we present two cases to demonstrate the value of applying the HCI processes and
design principles in developing and deploying e-government and e-democracy.
Finally, we highlight the challenges faced by e-government and e-democracy as
well as the future trends. In conclusion, HCI can help the success of
e-government and e-democracy and their future growth.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10989" title="Abstract">arXiv:2310.10989</a> [<a href="/pdf/2310.10989" title="Download PDF">pdf</a>, <a href="/ps/2310.10989" title="Download PostScript">ps</a>, <a href="/format/2310.10989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WGoM: A novel model for categorical data with weighted responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qing%2C+H">Huan Qing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The Graded of Membership (GoM) model is a powerful tool for inferring latent
classes in categorical data, which enables subjects to belong to multiple
latent classes. However, its application is limited to categorical data with
nonnegative integer responses, making it inappropriate for datasets with
continuous or negative responses. To address this limitation, this paper
proposes a novel model named the Weighted Grade of Membership (WGoM) model.
Compared with GoM, our WGoM relaxes GoM's distribution constraint on the
generation of a response matrix and it is more general than GoM. We then
propose an algorithm to estimate the latent mixed memberships and the other
WGoM parameters. We derive the error bounds of the estimated parameters and
show that the algorithm is statistically consistent. The algorithmic
performance is validated in both synthetic and real-world datasets. The results
demonstrate that our algorithm is accurate and efficient, indicating its high
potential for practical applications. This paper makes a valuable contribution
to the literature by introducing a novel model that extends the applicability
of the GoM model and provides a more flexible framework for analyzing
categorical data with weighted responses.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10990" title="Abstract">arXiv:2310.10990</a> [<a href="/pdf/2310.10990" title="Download PDF">pdf</a>, <a href="/format/2310.10990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A second-order exponential integration constraint energy minimizing  generalized multiscale method for parabolic problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Poveda%2C+L+A">Leonardo A. Poveda</a>, 
<a href="/search/math?searchtype=author&query=Galvis%2C+J">Juan Galvis</a>, 
<a href="/search/math?searchtype=author&query=Chung%2C+E">Eric Chung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper investigates an efficient exponential integrator generalized
multiscale finite element method for solving a class of time-evolving partial
differential equations in bounded domains. The proposed method first performs
the spatial discretization of the model problem using constraint energy
minimizing generalized multiscale finite element method (CEM-GMsFEM). This
approach consists of two stages. First, the auxiliary space is constructed by
solving local spectral problems, where the basis functions corresponding to
small eigenvalues are captured. The multiscale basis functions are obtained in
the second stage using the auxiliary space by solving local energy minimization
problems over the oversampling domains. The basis functions have exponential
decay outside the corresponding local oversampling regions. We shall consider
the first and second-order explicit exponential Runge-Kutta approach for
temporal discretization and to build a fully discrete numerical solution. The
exponential integration strategy for the time variable allows us to take full
advantage of the CEM-GMsFEM as it enables larger time steps due to its
stability properties. We derive the error estimates in the energy norm under
the regularity assumption. Finally, we will provide some numerical experiments
to sustain the efficiency of the proposed method.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10992" title="Abstract">arXiv:2310.10992</a> [<a href="/pdf/2310.10992" title="Download PDF">pdf</a>, <a href="/format/2310.10992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A High Fidelity and Low Complexity Neural Audio Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenzhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yupeng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yuyong Kang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+D">Dan Su</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+S">Shidong Shang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio coding is an essential module in the real-time communication system.
Neural audio codecs can compress audio samples with a low bitrate due to the
strong modeling and generative capabilities of deep neural networks. To address
the poor high-frequency expression and high computational cost and storage
consumption, we proposed an integrated framework that utilizes a neural network
to model wide-band components and adopts traditional signal processing to
compress high-band components according to psychological hearing knowledge.
Inspired by auditory perception theory, a perception-based loss function is
designed to improve harmonic modeling. Besides, generative adversarial network
(GAN) compression is proposed for the first time for neural audio codecs. Our
method is superior to prior advanced neural codecs across subjective and
objective metrics and allows real-time inference on desktop and mobile.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10996" title="Abstract">arXiv:2310.10996</a> [<a href="/pdf/2310.10996" title="Download PDF">pdf</a>, <a href="/format/2310.10996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClarifyGPT: Empowering LLM-based Code Generation with Intention  Clarification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+F">Fangwen Mu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhuohao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Binquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenxue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shichao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">We introduce a novel framework named ClarifyGPT, which aims to enhance code
generation by empowering LLMs with the ability to identify ambiguous
requirements and ask targeted clarifying questions. In particular, ClarifyGPT
first detects whether a given requirement is ambiguous by performing a code
consistency check. If it is ambiguous, ClarifyGPT prompts an LLM to generate
targeted clarifying questions. After receiving question responses, ClarifyGPT
refines the ambiguous requirement and inputs it into the same LLM to generate a
final code solution. To evaluate our ClarifyGPT, we first conduct a human
evaluation involving ten participants who use ClarifyGPT for code generation on
two publicly available benchmarks: MBPP-sanitized and MBPP-ET. The results show
that ClarifyGPT elevates the performance (Pass@1) of GPT-4 from 70.96% to
80.80% on MBPP-sanitized. Furthermore, to perform large-scale automated
evaluations of ClarifyGPT across different LLMs and benchmarks without
requiring user participation, we introduce a high-fidelity simulation method to
simulate user responses. The automated evaluation results also demonstrate that
ClarifyGPT can significantly enhance code generation performance compared to
the baselines. In particular, ClarifyGPT improves the average performance of
GPT-4 and ChatGPT across four benchmarks from 68.02% to 75.75% and from 58.55%
to 67.22%, respectively. We believe that ClarifyGPT can effectively facilitate
the practical application of LLMs in real-world development environments.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10997" title="Abstract">arXiv:2310.10997</a> [<a href="/pdf/2310.10997" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Dispatch of Microgrids Community Using Risk-Sensitive  Reinforcement Learning with Monotonously Improved Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Z">Ziqing Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+X">Xiang Gao</a>, 
<a href="/search/eess?searchtype=author&query=Bu%2C+S">Siqi Bu</a>, 
<a href="/search/eess?searchtype=author&query=Chan%2C+K+W">Ka Wing Chan</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+B">Bin Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+S">Shiwei Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The integration of individual microgrids (MGs) into Microgrid Clusters (MGCs)
significantly improves the reliability and flexibility of energy supply,
through resource sharing and ensuring backup during outages. The dispatch of
MGCs is the key challenge to be tackled to ensure their secure and economic
operation. Currently, there is a lack of optimization method that can achieve a
trade-off among top-priority requirements of MGCs' dispatch, including fast
computation speed, optimality, multiple objectives, and risk mitigation against
uncertainty. In this paper, a novel Multi-Objective, Risk-Sensitive, and Online
Trust Region Policy Optimization (RS-TRPO) Algorithm is proposed to tackle this
problem. First, a dispatch paradigm for autonomous MGs in the MGC is proposed,
enabling them sequentially implement their self-dispatch to mitigate potential
conflicts. This dispatch paradigm is then formulated as a Markov Game model,
which is finally solved by the RS-TRPO algorithm. This online algorithm enables
MGs to spontaneously search for the Pareto Frontier considering multiple
objectives and risk mitigation. The outstanding computational performance of
this algorithm is demonstrated in comparison with mathematical programming
methods and heuristic algorithms in a modified IEEE 30-Bus Test System
integrated with four autonomous MGs.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10998" title="Abstract">arXiv:2310.10998</a> [<a href="/pdf/2310.10998" title="Download PDF">pdf</a>, <a href="/format/2310.10998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Scalable Graph Neural Network Inference with Node-Adaptive  Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinyi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junliang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yingxia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2211.00495">arXiv:2211.00495</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph neural networks (GNNs) have exhibited exceptional efficacy in a diverse
array of applications. However, the sheer size of large-scale graphs presents a
significant challenge to real-time inference with GNNs. Although existing
Scalable GNNs leverage linear propagation to preprocess the features and
accelerate the training and inference procedure, these methods still suffer
from scalability issues when making inferences on unseen nodes, as the feature
preprocessing requires the graph to be known and fixed. To further accelerate
Scalable GNNs inference in this inductive setting, we propose an online
propagation framework and two novel node-adaptive propagation methods that can
customize the optimal propagation depth for each node based on its topological
information and thereby avoid redundant feature propagation. The trade-off
between accuracy and latency can be flexibly managed through simple
hyper-parameters to accommodate various latency constraints. Moreover, to
compensate for the inference accuracy loss caused by the potential early
termination of propagation, we further propose Inception Distillation to
exploit the multi-scale receptive field information within graphs. The rigorous
and comprehensive experimental study on public datasets with varying scales and
characteristics demonstrates that the proposed inference acceleration framework
outperforms existing state-of-the-art graph inference acceleration methods in
terms of accuracy and efficiency. Particularly, the superiority of our approach
is notable on datasets with larger scales, yielding a 75x inference speedup on
the largest Ogbn-products dataset.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11000" title="Abstract">arXiv:2310.11000</a> [<a href="/pdf/2310.11000" title="Download PDF">pdf</a>, <a href="/format/2310.11000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mid-Band 5G: A Measurement Study in Europe and US
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fezeu%2C+R+A+K">Rostand A. K. Fezeu</a>, 
<a href="/search/cs?searchtype=author&query=Carpenter%2C+J">Jason Carpenter</a>, 
<a href="/search/cs?searchtype=author&query=Fiandrino%2C+C">Claudio Fiandrino</a>, 
<a href="/search/cs?searchtype=author&query=Ramadan%2C+E">Eman Ramadan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Widmer%2C+J">Joerg Widmer</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+F">Feng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhi-Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 36 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Fifth Generation (5G) mobile networks mark a significant shift from previous
generations of networks. By introducing a flexible design, 5G networks support
highly diverse application requirements. Currently, the landscape of previous
measurement studies does not shed light on 5G network configuration and the
inherent implications to application performance. In this paper, we precisely
fill this gap and report our in-depth multi-country measurement study on 5G
deployed at mid-bands. This is the common playground for U.S. and European
carriers. Our findings reveal key aspects on how carriers configure their
network, including spectrum utilization, frame configuration, resource
allocation and their implication on the application performance.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11001" title="Abstract">arXiv:2310.11001</a> [<a href="/pdf/2310.11001" title="Download PDF">pdf</a>, <a href="/format/2310.11001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially-resolved hyperlocal weather prediction and anomaly detection  using IoT sensor networks and machine learning techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A+B">Anita B. Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Rajesh%2C+R">Rohit Rajesh</a>, 
<a href="/search/cs?searchtype=author&query=Arul%2C+N">Nitin Arul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Modelling Simulation &amp; Intelligent Computing, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Accurate and timely hyperlocal weather predictions are essential for various
applications, ranging from agriculture to disaster management. In this paper,
we propose a novel approach that combines hyperlocal weather prediction and
anomaly detection using IoT sensor networks and advanced machine learning
techniques. Our approach leverages data from multiple spatially-distributed yet
relatively close locations and IoT sensors to create high-resolution weather
models capable of predicting short-term, localized weather conditions such as
temperature, pressure, and humidity. By monitoring changes in weather
parameters across these locations, our system is able to enhance the spatial
resolution of predictions and effectively detect anomalies in real-time.
Additionally, our system employs unsupervised learning algorithms to identify
unusual weather patterns, providing timely alerts. Our findings indicate that
this system has the potential to enhance decision-making.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11003" title="Abstract">arXiv:2310.11003</a> [<a href="/pdf/2310.11003" title="Download PDF">pdf</a>, <a href="/format/2310.11003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correction Focused Language Model Training for Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yingyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kalinli%2C+O">Ozlem Kalinli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Language models (LMs) have been commonly adopted to boost the performance of
automatic speech recognition (ASR) particularly in domain adaptation tasks.
Conventional way of LM training treats all the words in corpora equally,
resulting in suboptimal improvements in ASR performance. In this work, we
introduce a novel correction focused LM training approach which aims to
prioritize ASR fallible words. The word-level ASR fallibility score,
representing the likelihood of ASR mis-recognition, is defined and shaped as a
prior word distribution to guide the LM training. To enable correction focused
training with text-only corpora, large language models (LLMs) are employed as
fallibility score predictors and text generators through multi-task
fine-tuning. Experimental results for domain adaptation tasks demonstrate the
effectiveness of our proposed method. Compared with conventional LMs,
correction focused training achieves up to relatively 5.5% word error rate
(WER) reduction in sufficient text scenarios. In insufficient text scenarios,
LM training with LLM-generated text achieves up to relatively 13% WER
reduction, while correction focused training further obtains up to relatively
6% WER reduction.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11005" title="Abstract">arXiv:2310.11005</a> [<a href="/pdf/2310.11005" title="Download PDF">pdf</a>, <a href="/ps/2310.11005" title="Download PostScript">ps</a>, <a href="/format/2310.11005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Private Discrete Distribution Estimation with One-bit  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Seung-Hyun Nam</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+V+Y+F">Vincent Y. F. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Si-Hyeon Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, and 1 page of supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We consider a private discrete distribution estimation problem with one-bit
communication constraint. The privacy constraints are imposed with respect to
the local differential privacy and the maximal leakage. The estimation error is
quantified by the worst-case mean squared error. We completely characterize the
first-order asymptotics of this privacy-utility trade-off under the one-bit
communication constraint for both types of privacy constraints by using ideas
from local asymptotic normality and the resolution of a block design mechanism.
These results demonstrate the optimal dependence of the privacy-utility
trade-off under the one-bit communication constraint in terms of the parameters
of the privacy constraint and the size of the alphabet of the discrete
distribution.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11009" title="Abstract">arXiv:2310.11009</a> [<a href="/pdf/2310.11009" title="Download PDF">pdf</a>, <a href="/format/2310.11009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Pairwise Encodings for Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shomer%2C+H">Harry Shomer</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haitao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Link prediction is a common task on graph-structured data that has seen
applications in a variety of domains. Classically, hand-crafted heuristics were
used for this task. Heuristic measures are chosen such that they correlate well
with the underlying factors related to link formation. In recent years, a new
class of methods has emerged that combines the advantages of message-passing
neural networks (MPNN) and heuristics methods. These methods perform
predictions by using the output of an MPNN in conjunction with a "pairwise
encoding" that captures the relationship between nodes in the candidate link.
They have been shown to achieve strong performance on numerous datasets.
However, current pairwise encodings often contain a strong inductive bias,
using the same underlying factors to classify all links. This limits the
ability of existing methods to learn how to properly classify a variety of
different links that may form from different factors. To address this
limitation, we propose a new method, LPFormer, which attempts to adaptively
learn the pairwise encodings for each link. LPFormer models the link factors
via an attention module that learns the pairwise encoding that exists between
nodes by modeling multiple factors integral to link prediction. Extensive
experiments demonstrate that LPFormer can achieve SOTA performance on numerous
datasets while maintaining efficiency.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11011" title="Abstract">arXiv:2310.11011</a> [<a href="/pdf/2310.11011" title="Download PDF">pdf</a>, <a href="/format/2310.11011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Identifiable Causal Representations to Controllable Counterfactual  Generation: A Survey on Causal Generative Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Komanduri%2C+A">Aneesh Komanduri</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongkai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep generative models have shown tremendous success in data density
estimation and data generation from finite samples. While these models have
shown impressive performance by learning correlations among features in the
data, some fundamental shortcomings are their lack of explainability, the
tendency to induce spurious correlations, and poor out-of-distribution
extrapolation. In an effort to remedy such challenges, one can incorporate the
theory of causality in deep generative modeling. Structural causal models
(SCMs) describe data-generating processes and model complex causal
relationships and mechanisms among variables in a system. Thus, SCMs can
naturally be combined with deep generative models. Causal models offer several
beneficial properties to deep generative models, such as distribution shift
robustness, fairness, and interoperability. We provide a technical survey on
causal generative modeling categorized into causal representation learning and
controllable counterfactual generation methods. We focus on fundamental theory,
formulations, drawbacks, datasets, metrics, and applications of causal
generative models in fairness, privacy, out-of-distribution generalization, and
precision medicine. We also discuss open problems and fruitful research
directions for future work in the field.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11015" title="Abstract">arXiv:2310.11015</a> [<a href="/pdf/2310.11015" title="Download PDF">pdf</a>, <a href="/format/2310.11015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pure Exploration in Asynchronous Federated Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chenyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lianghui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huazheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We study the federated pure exploration problem of multi-armed bandits and
linear bandits, where $M$ agents cooperatively identify the best arm via
communicating with the central server. To enhance the robustness against
latency and unavailability of agents that are common in practice, we propose
the first federated asynchronous multi-armed bandit and linear bandit
algorithms for pure exploration with fixed confidence. Our theoretical analysis
shows the proposed algorithms achieve near-optimal sample complexities and
efficient communication costs in a fully asynchronous environment. Moreover,
experimental results based on synthetic and real-world data empirically
elucidate the effectiveness and communication cost-efficiency of the proposed
algorithms.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11016" title="Abstract">arXiv:2310.11016</a> [<a href="/pdf/2310.11016" title="Download PDF">pdf</a>, <a href="/format/2310.11016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reading Order Matters: Information Extraction from Visually-rich  Documents by Token Path Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Ya Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Y">Yi Tu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinyang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huijia Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a long paper in the main conference of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advances in multimodal pre-trained models have significantly improved
information extraction from visually-rich documents (VrDs), in which named
entity recognition (NER) is treated as a sequence-labeling task of predicting
the BIO entity tags for tokens, following the typical setting of NLP. However,
BIO-tagging scheme relies on the correct order of model inputs, which is not
guaranteed in real-world NER on scanned VrDs where text are recognized and
arranged by OCR systems. Such reading order issue hinders the accurate marking
of entities by BIO-tagging scheme, making it impossible for sequence-labeling
methods to predict correct named entities. To address the reading order issue,
we introduce Token Path Prediction (TPP), a simple prediction head to predict
entity mentions as token sequences within documents. Alternative to token
classification, TPP models the document layout as a complete directed graph of
tokens, and predicts token paths within the graph as entities. For better
evaluation of VrD-NER systems, we also propose two revised benchmark datasets
of NER on scanned documents which can reflect real-world scenarios. Experiment
results demonstrate the effectiveness of our method, and suggest its potential
to be a universal solution to various information extraction tasks on
documents.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11019" title="Abstract">arXiv:2310.11019</a> [<a href="/pdf/2310.11019" title="Download PDF">pdf</a>, <a href="/format/2310.11019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical simulation of time fractional Kudryashov Sinelshchikov  equation describing the pressure waves in a mixture of liquid and gas bubbles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Das%2C+G">Gayatri Das</a>, 
<a href="/search/math?searchtype=author&query=Ray%2C+S+S">S. Saha Ray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.07375">arXiv:2310.07375</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">This article is concerned with an approximate analytical solution for the
time fractional Kudryashov Sinelshchikov equation by using the reproducing
kernel Hilbert space method. The main tools of this method are reproducing
kernel theory, some important Hilbert spaces, the normal basis,
orthogonalisation process, and homogenization. The effectiveness of reproduc
ing kernel Hilbert space method is presented through the tables and graphs.
These computa tional results indicate that this method is highly accurate and
efficient for the time fractional Kudryashov Sinelshchikov equation. Also, it
is demonstrated that the approximate solution uniformly converges to exact
solution by using reproducing kernel Hilbert space method.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11022" title="Abstract">arXiv:2310.11022</a> [<a href="/pdf/2310.11022" title="Download PDF">pdf</a>, <a href="/format/2310.11022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compatible Transformer for Irregularly Sampled Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Juntong Peng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the IEEE International Conference on Data Mining (ICDM) 2023 as short paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">To analyze multivariate time series, most previous methods assume regular
subsampling of time series, where the interval between adjacent measurements
and the number of samples remain unchanged. Practically, data collection
systems could produce irregularly sampled time series due to sensor failures
and interventions. However, existing methods designed for regularly sampled
multivariate time series cannot directly handle irregularity owing to
misalignment along both temporal and variate dimensions. To fill this gap, we
propose Compatible Transformer (CoFormer), a transformer-based encoder to
achieve comprehensive temporal-interaction feature learning for each individual
sample in irregular multivariate time series. In CoFormer, we view each sample
as a unique variate-time point and leverage intra-variate/inter-variate
attentions to learn sample-wise temporal/interaction features based on
intra-variate/inter-variate neighbors. With CoFormer as the core, we can
analyze irregularly sampled multivariate time series for many downstream tasks,
including classification and prediction. We conduct extensive experiments on 3
real-world datasets and validate that the proposed CoFormer significantly and
consistently outperforms existing methods.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11025" title="Abstract">arXiv:2310.11025</a> [<a href="/pdf/2310.11025" title="Download PDF">pdf</a>, <a href="/format/2310.11025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SignGT: Signed Attention-based Graph Transformer for Graph  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinsong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gaichao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hopcroft%2C+J+E">John E. Hopcroft</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kun He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to a conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The emerging graph Transformers have achieved impressive performance for
graph representation learning over graph neural networks (GNNs). In this work,
we regard the self-attention mechanism, the core module of graph Transformers,
as a two-step aggregation operation on a fully connected graph. Due to the
property of generating positive attention values, the self-attention mechanism
is equal to conducting a smooth operation on all nodes, preserving the
low-frequency information. However, only capturing the low-frequency
information is inefficient in learning complex relations of nodes on diverse
graphs, such as heterophily graphs where the high-frequency information is
crucial. To this end, we propose a Signed Attention-based Graph Transformer
(SignGT) to adaptively capture various frequency information from the graphs.
Specifically, SignGT develops a new signed self-attention mechanism (SignSA)
that produces signed attention values according to the semantic relevance of
node pairs. Hence, the diverse frequency information between different node
pairs could be carefully preserved. Besides, SignGT proposes a structure-aware
feed-forward network (SFFN) that introduces the neighborhood bias to preserve
the local topology information. In this way, SignGT could learn informative
node representations from both long-range dependencies and local topology
information. Extensive empirical results on both node-level and graph-level
tasks indicate the superiority of SignGT against state-of-the-art graph
Transformers as well as advanced GNNs.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11026" title="Abstract">arXiv:2310.11026</a> [<a href="/pdf/2310.11026" title="Download PDF">pdf</a>, <a href="/format/2310.11026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Automatic Evaluation Methods based on a Decoder-based LLM for  Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasahara%2C+T">Tomohito Kasahara</a>, 
<a href="/search/cs?searchtype=author&query=Kawahara%2C+D">Daisuke Kawahara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IJCNLP-AACL 2023 SRW
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automatic evaluation of text generation is essential for improving the
accuracy of generation tasks. In light of the current trend towards
increasingly larger decoder-based language models, we investigate automatic
evaluation methods based on such models for text generation. This paper
compares various methods, including tuning with encoder-based models and large
language models under equal conditions, on two different tasks, machine
translation evaluation and semantic textual similarity, in two languages,
Japanese and English. Experimental results show that compared to the tuned
encoder-based models, the tuned decoder-based models perform poorly. The
analysis of the causes for this suggests that the decoder-based models focus on
surface word sequences and do not capture meaning. It is also revealed that
in-context learning of very large decoder-based models such as ChatGPT makes it
difficult to identify fine-grained semantic differences.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11028" title="Abstract">arXiv:2310.11028</a> [<a href="/pdf/2310.11028" title="Download PDF">pdf</a>, <a href="/format/2310.11028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Compression via Randomized Low Rank and Low Precision  Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+R">Rajarshi Saha</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+V">Varun Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Pilanci%2C+M">Mert Pilanci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">Matrices are exceptionally useful in various fields of study as they provide
a convenient framework to organize and manipulate data in a structured manner.
However, modern matrices can involve billions of elements, making their storage
and processing quite demanding in terms of computational resources and memory
usage. Although prohibitively large, such matrices are often approximately low
rank. We propose an algorithm that exploits this structure to obtain a low rank
decomposition of any matrix $\mathbf{A}$ as $\mathbf{A} \approx
\mathbf{L}\mathbf{R}$, where $\mathbf{L}$ and $\mathbf{R}$ are the low rank
factors. The total number of elements in $\mathbf{L}$ and $\mathbf{R}$ can be
significantly less than that in $\mathbf{A}$. Furthermore, the entries of
$\mathbf{L}$ and $\mathbf{R}$ are quantized to low precision formats $--$
compressing $\mathbf{A}$ by giving us a low rank and low precision
factorization. Our algorithm first computes an approximate basis of the range
space of $\mathbf{A}$ by randomly sketching its columns, followed by a
quantization of the vectors constituting this basis. It then computes
approximate projections of the columns of $\mathbf{A}$ onto this quantized
basis. We derive upper bounds on the approximation error of our algorithm, and
analyze the impact of target rank and quantization bit-budget. The tradeoff
between compression ratio and approximation accuracy allows for flexibility in
choosing these parameters based on specific application requirements. We
empirically demonstrate the efficacy of our algorithm in image compression,
nearest neighbor classification of image and text embeddings, and compressing
the layers of LlaMa-$7$b. Our results illustrate that we can achieve
compression ratios as aggressive as one bit per matrix coordinate, all while
surpassing or maintaining the performance of traditional compression
techniques.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11029" title="Abstract">arXiv:2310.11029</a> [<a href="/pdf/2310.11029" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Core Building Blocks: Next Gen Geo Spatial GPT Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+A">Ashley Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Dube%2C+S">Swaraj Dube</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper proposes MapGPT which is a novel approach that integrates the
capabilities of language models, specifically large language models (LLMs),
with spatial data processing techniques. This paper introduces MapGPT, which
aims to bridge the gap between natural language understanding and spatial data
analysis by highlighting the relevant core building blocks. By combining the
strengths of LLMs and geospatial analysis, MapGPT enables more accurate and
contextually aware responses to location-based queries. The proposed
methodology highlights building LLMs on spatial and textual data, utilizing
tokenization and vector representations specific to spatial information. The
paper also explores the challenges associated with generating spatial vector
representations. Furthermore, the study discusses the potential of
computational capabilities within MapGPT, allowing users to perform geospatial
computations and obtain visualized outputs. Overall, this research paper
presents the building blocks and methodology of MapGPT, highlighting its
potential to enhance spatial data understanding and generation in natural
language processing applications.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11031" title="Abstract">arXiv:2310.11031</a> [<a href="/pdf/2310.11031" title="Download PDF">pdf</a>, <a href="/format/2310.11031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization Using Large Pretrained Models with  Mixture-of-Adapters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyuseong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+W">Wooseok Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+H">Jin Hyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jaewoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning a robust vision model despite large distribution shift is essential
for model deployment in real-world settings. Especially, domain generalization
(DG) algorithm aims to maintain the performance of a trained model on different
distributions which were not seen during training. One of the most effective
methods has been leveraging the already learned rich knowledge of large
pretrained models. However, naively fine-tuning large models to DG tasks is
often practically infeasible due to memory limitations, extensive time
requirements for training, and the risk of learned knowledge deterioration.
Recently, parameter-efficient fine-tuning (PEFT) methods have been proposed to
reduce the high computational cost during training and efficiently adapt large
models to downstream tasks. In this work, for the first time, we find that the
use of adapters in PEFT methods not only reduce high computational cost during
training but also serve as an effective regularizer for DG tasks. Surprisingly,
a naive adapter implementation for large models achieve superior performance on
common datasets. However, in situations of large distribution shifts,
additional factors such as optimal amount of regularization due to the strength
of distribution shifts should be considered for a sophisticated adapter
implementation. To address this, we propose a mixture-of-expert based adapter
fine-tuning method, dubbed as mixture-of-adapters (MoA). Specifically, we
employ multiple adapters that have varying capacities, and by using learnable
routers, we allocate each token to a proper adapter. By using both PEFT and MoA
methods, we effectively alleviate the performance deterioration caused by
distribution shifts and achieve state-of-the-art performance on diverse DG
benchmarks.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11033" title="Abstract">arXiv:2310.11033</a> [<a href="/pdf/2310.11033" title="Download PDF">pdf</a>, <a href="/format/2310.11033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slicenet: a Simple and Scalable Flow-Level Simulator for Network Slice  Provisioning and Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=KumarSkandPriya%2C+V">Viswanath KumarSkandPriya</a> (1), 
<a href="/search/cs?searchtype=author&query=Dandoush%2C+A">Abdulhalim Dandoush</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Diaz%2C+G">Gladys Diaz</a> (3) ((1) Esme research lab, Campus Paris Sud, France, (2) University of Doha for Science and Technology, Doha, Qatar, (3) Universite Sorbonne Paris Nord - L2TI, 93430 Villateneuse, France)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Network slicing plays a crucial role in the progression of 5G and beyond,
facilitating dedicated logical networks to meet diverse and specific service
requirements. The principle of End-to-End (E2E) slice includes not only a
service chain of physical or virtual functions for the radio and core of 5G/6G
networks but also the full path to the application servers that might be
running at some edge computing or at central cloud. Nonetheless, the
development and optimization of E2E network slice management systems
necessitate a reliable simulation tool for evaluating different aspects at
large-scale network topologies such as resource allocation and function
placement models. This paper introduces Slicenet, a mininetlike simulator
crafted for E2E network slicing experimentation at the flow level. Slicenet
aims at facilitating the investigation of a wide range of slice optimization
techniques, delivering measurable, reproducible results without the need for
physical resources or complex integration tools. It provides a well-defined
process for conducting experiments, which includes the creation and
implementation of policies for various components such as edge and central
cloud resources, network functions of multiple slices of different
characteristics. Furthermore, Slicenet effortlessly produces meaningful
visualizations from simulation results, aiding in comprehensive understanding.
Utilizing Slicenet, service providers can derive invaluable insights into
resource optimization, capacity planning, Quality of Service (QoS) assessment,
cost optimization, performance comparison, risk mitigation, and Service Level
Agreement (SLA) compliance, thereby fortifying network resource management and
slice orchestration.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11035" title="Abstract">arXiv:2310.11035</a> [<a href="/pdf/2310.11035" title="Download PDF">pdf</a>, <a href="/format/2310.11035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lyricist-Singer Entropy Affects Lyric-Lyricist Classification  Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morita%2C+M">Mitsuki Morita</a>, 
<a href="/search/cs?searchtype=author&query=Kikuchi%2C+M">Masato Kikuchi</a>, 
<a href="/search/cs?searchtype=author&query=Ozono%2C+T">Tadachika Ozono</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 10th International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Although lyrics represent an essential component of music, few music
information processing studies have been conducted on the characteristics of
lyricists. Because these characteristics may be valuable for musical
applications, such as recommendations, they warrant further study. We
considered a potential method that extracts features representing the
characteristics of lyricists from lyrics. Because these features must be
identified prior to extraction, we focused on lyricists with easily
identifiable features. We believe that it is desirable for singers to perform
unique songs that share certain characteristics specific to the singer.
Accordingly, we hypothesized that lyricists account for the unique
characteristics of the singers they write lyrics for. In other words,
lyric-lyricist classification performance or the ease of capturing the features
of a lyricist from the lyrics may depend on the variety of singers. In this
study, we observed a relationship between lyricist-singer entropy or the
variety of singers associated with a single lyricist and lyric-lyricist
classification performance. As an example, the lyricist-singer entropy is
minimal when the lyricist writes lyrics for only one singer. In our
experiments, we grouped lyricists among five groups in terms of lyricist-singer
entropy and assessed the lyric-lyricist classification performance within each
group. Consequently, the best F1 score was obtained for the group with the
lowest lyricist-singer entropy. Our results suggest that further analyses of
the features contributing to lyric-lyricist classification performance on the
lowest lyricist-singer entropy group may improve the feature extraction task
for lyricists.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11037" title="Abstract">arXiv:2310.11037</a> [<a href="/pdf/2310.11037" title="Download PDF">pdf</a>, <a href="/ps/2310.11037" title="Download PostScript">ps</a>, <a href="/format/2310.11037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling for Remote Estimation of the Wiener Process over an Unreliable  Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiayu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shroff%2C+N+B">Ness B. Shroff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Sigmetrics, will appear in ACM POMACS journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we study a sampling problem where a source takes samples from
a Wiener process and transmits them through a wireless channel to a remote
estimator. Due to channel fading, interference, and potential collisions, the
packet transmissions are unreliable and could take random time durations. Our
objective is to devise an optimal causal sampling policy that minimizes the
long-term average mean square estimation error. This optimal sampling problem
is a recursive optimal stopping problem, which is generally quite difficult to
solve. However, we prove that the optimal sampling strategy is, in fact, a
simple threshold policy where a new sample is taken whenever the instantaneous
estimation error exceeds a threshold. This threshold remains a constant value
that does not vary over time. By exploring the structure properties of the
recursive optimal stopping problem, a low-complexity iterative algorithm is
developed to compute the optimal threshold. This work generalizes previous
research by incorporating both transmission errors and random transmission
times into remote estimation. Numerical simulations are provided to compare our
optimal policy with the zero-wait and age-optimal policies.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11042" title="Abstract">arXiv:2310.11042</a> [<a href="/pdf/2310.11042" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagrammatic Modelling of Causality and Causal Relations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Fedaghi%2C+S">Sabah Al-Fedaghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 Pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">It has been stated that the notion of cause and effect is one object of study
that sciences and engineering revolve around. Lately, in software engineering,
diagrammatic causal inference methods (e.g., Pearl s model) have gained
popularity (e.g., analyzing causes and effects of change in software
requirement development). This paper concerns diagrammatical (graphic) models
of causal relationships. Specifically, we experiment with using the conceptual
language of thinging machines (TMs) as a tool in this context. This would
benefit works on causal relationships in requirements engineering, enhance our
understanding of the TM modeling, and contribute to the study of the
philosophical notion of causality. To specify the causality in a system s
description is to constrain the system s behavior and thus exclude some
possible chronologies of events. The notion of causality has been studied based
on tools to express causal questions in diagrammatic and algebraic forms.
Causal models deploy diagrammatic models, structural equations, and
counterfactual and interventional logic. Diagrammatic models serve as a
language for representing what we know about the world. The research
methodology in the paper focuses on converting causal graphs into TM models and
contrasts the two types of representation. The results show that the TM
depiction of causality is more complete and therefore can provide a foundation
for causal graphs.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11044" title="Abstract">arXiv:2310.11044</a> [<a href="/pdf/2310.11044" title="Download PDF">pdf</a>, <a href="/ps/2310.11044" title="Download PostScript">ps</a>, <a href="/format/2310.11044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tutorial on Near-Field XL-MIMO Communications Towards 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haiquan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Changsheng You</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhenjun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng-Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xiaohu You</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Extremely large-scale multiple-input multiple-output (XL-MIMO) is a promising
technology for the sixth-generation (6G) mobile communication networks. By
significantly boosting the antenna number or size to at least an order of
magnitude beyond current massive MIMO systems, XL-MIMO is expected to
unprecedentedly enhance the spectral efficiency and spatial resolution for
wireless communication. The evolution from massive MIMO to XL-MIMO is not
simply an increase in the array size, but faces new design challenges, in terms
of near-field channel modelling, performance analysis, channel estimation, and
practical implementation. In this article, we give a comprehensive tutorial
overview on near-field XL-MIMO communications, aiming to provide useful
guidance for tackling the above challenges. First, the basic near-field
modelling for XL-MIMO is established, by considering the new characteristics of
non-uniform spherical wave (NUSW) and spatial non-stationarity. Next, based on
the near-field modelling, the performance analysis of XL-MIMO is presented,
including the near-field signal-to-noise ratio (SNR) scaling laws, beam
focusing pattern, achievable rate, and degrees-of-freedom (DoF). Furthermore,
various XL-MIMO design issues such as near-field beam codebook, beam training,
channel estimation, and delay alignment modulation (DAM) transmission are
elaborated. Finally, we point out promising directions to inspire future
research on near-field XL-MIMO communications.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11046" title="Abstract">arXiv:2310.11046</a> [<a href="/pdf/2310.11046" title="Download PDF">pdf</a>, <a href="/format/2310.11046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Graph Condensation with Structure-based Neural Tangent Kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wenqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiatong Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapid development of Internet technology has given rise to a vast amount
of graph-structured data. Graph Neural Networks (GNNs), as an effective method
for various graph mining tasks, incurs substantial computational resource costs
when dealing with large-scale graph data. A data-centric manner solution is
proposed to condense the large graph dataset into a smaller one without
sacrificing the predictive performance of GNNs. However, existing efforts
condense graph-structured data through a computational intensive bi-level
optimization architecture also suffer from massive computation costs. In this
paper, we propose reforming the graph condensation problem as a Kernel Ridge
Regression (KRR) task instead of iteratively training GNNs in the inner loop of
bi-level optimization. More specifically, We propose a novel dataset
condensation framework (GC-SNTK) for graph-structured data, where a
Structure-based Neural Tangent Kernel (SNTK) is developed to capture the
topology of graph and serves as the kernel function in KRR paradigm.
Comprehensive experiments demonstrate the effectiveness of our proposed model
in accelerating graph condensation while maintaining high prediction
performance.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11047" title="Abstract">arXiv:2310.11047</a> [<a href="/pdf/2310.11047" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Gamified Auditory-Verbal Training for Hearing-Challenged  Children at Intermediate and Advanced Rehabilitation Stages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yan Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Danni Chang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+L">Lei Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Auditory-verbal training is essential for children with hearing challenges,
and the gamification approach has become a promising direction for improving
the rehabilitation experience and effect. However, the specific influence of
the gamified training approach on participants at different rehabilitation
stages has not been empirically studied. This paper is thusly intended to
investigate the research questions: Do the training performances of children at
advanced rehabilitation stage differ before and after using the gamified
training system? Do the training performances of children at intermediate
rehabilitation stage differ before and after using the gamified training
system? Do children enjoy the gamified training approach? For the purpose, a
digital gamified auditory-verbal training system was originally developed, and
a series of user experiments were organized. Particularly, 31
hearing-challenged children aging between three-six years old at an
auditory-verbal rehabilitation center were recruited to take the training, and
six professional therapists were also invited to assist with the experiments
and attend the interviews. Based on the training performance observation and
interviews with participants, their parents and the therapists, it can be found
that generally the gamified training approach can effectively facilitate the
training experience, and help with the basic auditory memory and expression
capabilities. Regarding the specific influence, the gamified way can better
improve the basic auditory-verbal performance of children at the intermediate
stage, since they focus more on the ease of learning and adaption to the
training system. These findings and conclusions can provide insights for the
further exploration and application of the gamification approach in children's
auditory-verbal rehabilitation.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11048" title="Abstract">arXiv:2310.11048</a> [<a href="/pdf/2310.11048" title="Download PDF">pdf</a>, <a href="/format/2310.11048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Contrastive Learning via Distributionally Robust  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junkang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiancan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wentao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study reveals the inherent tolerance of contrastive learning (CL)
towards sampling bias, wherein negative samples may encompass similar semantics
(\eg labels). However, existing theories fall short in providing explanations
for this phenomenon. We bridge this research gap by analyzing CL through the
lens of distributionally robust optimization (DRO), yielding several key
insights: (1) CL essentially conducts DRO over the negative sampling
distribution, thus enabling robust performance across a variety of potential
distributions and demonstrating robustness to sampling bias; (2) The design of
the temperature $\tau$ is not merely heuristic but acts as a Lagrange
Coefficient, regulating the size of the potential distribution set; (3) A
theoretical connection is established between DRO and mutual information, thus
presenting fresh evidence for ``InfoNCE as an estimate of MI'' and a new
estimation approach for $\phi$-divergence-based generalized mutual information.
We also identify CL's potential shortcomings, including over-conservatism and
sensitivity to outliers, and introduce a novel Adjusted InfoNCE loss (ADNCE) to
mitigate these issues. It refines potential distribution, improving performance
and accelerating convergence. Extensive experiments on various domains (image,
sentence, and graphs) validate the effectiveness of the proposal. The code is
available at \url{https://github.com/junkangwu/ADNCE}.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11049" title="Abstract">arXiv:2310.11049</a> [<a href="/pdf/2310.11049" title="Download PDF">pdf</a>, <a href="/format/2310.11049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonet at SemEval-2023 Task 6: Methodologies for Legal Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nigam%2C+S+K">Shubham Kumar Nigam</a>, 
<a href="/search/cs?searchtype=author&query=Deroy%2C+A">Aniket Deroy</a>, 
<a href="/search/cs?searchtype=author&query=Shallum%2C+N">Noel Shallum</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A+K">Ayush Kumar Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+A">Anup Roy</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S+K">Shubham Kumar Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+A">Arnab Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Saptarshi Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+K">Kripabandhu Ghosh</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> https://aclanthology.org/2023.semeval-1.180
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper describes our submission to the SemEval-2023 for Task 6 on
LegalEval: Understanding Legal Texts. Our submission concentrated on three
subtasks: Legal Named Entity Recognition (L-NER) for Task-B, Legal Judgment
Prediction (LJP) for Task-C1, and Court Judgment Prediction with Explanation
(CJPE) for Task-C2. We conducted various experiments on these subtasks and
presented the results in detail, including data statistics and methodology. It
is worth noting that legal tasks, such as those tackled in this research, have
been gaining importance due to the increasing need to automate legal analysis
and support. Our team obtained competitive rankings of 15$^{th}$, 11$^{th}$,
and 1$^{st}$ in Task-B, Task-C1, and Task-C2, respectively, as reported on the
leaderboard.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11052" title="Abstract">arXiv:2310.11052</a> [<a href="/pdf/2310.11052" title="Download PDF">pdf</a>, <a href="/format/2310.11052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Threats Posed by SMS Origin Spoofing to IoT Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsunoda%2C+A">Akaki Tsunoda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The short message service (SMS) is a service for exchanging texts via mobile
networks that has been developed not only as a means of text communication
between subscribers but also as a means to remotely manage Internet of Things
(IoT) devices. However, the originating number of an SMS can be spoofed. If IoT
devices authenticate administrators based on the originating number of an SMS,
the authentication is bypassed via SMS origin spoofing. Consequently, IoT
devices are at risk of accepting commands from attackers and performing
unauthorized actions. Accordingly, in this study, the specifications of major
cellular IoT gateways were evaluated by focusing on remote management via SMS,
and the authentication bypass hypothesis was verified. The results showed that
25 of the 32 targeted products supported SMS-based remote management, and 20
implemented authentication based on the originating number of the SMS.
Furthermore, by spoofing the originating number of the SMS, one product was
demonstrated to be remotely exploitable through authentication bypassing. Thus,
this study revealed the threats posed by SMS origin spoofing to IoT devices and
proved that SMS origin spoofing not only threatens text communication between
people but also puts machine communication at risk.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11053" title="Abstract">arXiv:2310.11053</a> [<a href="/pdf/2310.11053" title="Download PDF">pdf</a>, <a href="/format/2310.11053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denevil: Towards Deciphering and Navigating the Ethical Values of Large  Language Models via Instruction Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shitong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ning Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Large Language Models (LLMs) have made unprecedented breakthroughs, yet their
increasing integration into everyday life might raise societal risks due to
generated unethical content. Despite extensive study on specific issues like
bias, the intrinsic values of LLMs remain largely unexplored from a moral
philosophy perspective. This work delves into ethical values utilizing Moral
Foundation Theory. Moving beyond conventional discriminative evaluations with
poor reliability, we propose DeNEVIL, a novel prompt generation algorithm
tailored to dynamically exploit LLMs' value vulnerabilities and elicit the
violation of ethics in a generative manner, revealing their underlying value
inclinations. On such a basis, we construct MoralPrompt, a high-quality dataset
comprising 2,397 prompts covering 500+ value principles, and then benchmark the
intrinsic values across a spectrum of LLMs. We discovered that most models are
essentially misaligned, necessitating further ethical value alignment. In
response, we develop VILMO, an in-context alignment method that substantially
enhances the value compliance of LLM outputs by learning to generate
appropriate value instructions, outperforming existing competitors. Our methods
are suitable for black-box and open-source models, offering a promising initial
step in studying the ethical values of LLMs.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11059" title="Abstract">arXiv:2310.11059</a> [<a href="/pdf/2310.11059" title="Download PDF">pdf</a>, <a href="/format/2310.11059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Feature Selection via Transfer Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonetti%2C+P">Paolo Bonetti</a>, 
<a href="/search/cs?searchtype=author&query=Metelli%2C+A+M">Alberto Maria Metelli</a>, 
<a href="/search/cs?searchtype=author&query=Restelli%2C+M">Marcello Restelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning algorithms are designed to capture complex relationships
between features. In this context, the high dimensionality of data often
results in poor model performance, with the risk of overfitting. Feature
selection, the process of selecting a subset of relevant and non-redundant
features, is, therefore, an essential step to mitigate these issues. However,
classical feature selection approaches do not inspect the causal relationship
between selected features and target, which can lead to misleading results in
real-world applications. Causal discovery, instead, aims to identify causal
relationships between features with observational data. In this paper, we
propose a novel methodology at the intersection between feature selection and
causal discovery, focusing on time series. We introduce a new causal feature
selection approach that relies on the forward and backward feature selection
procedures and leverages transfer entropy to estimate the causal flow of
information from the features to the target in time series. Our approach
enables the selection of features not only in terms of mere model performance
but also captures the causal information flow. In this context, we provide
theoretical guarantees on the regression and classification errors for both the
exact and the finite-sample cases. Finally, we present numerical validations on
synthetic and real-world regression problems, showing results competitive
w.r.t. the considered baselines.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11060" title="Abstract">arXiv:2310.11060</a> [<a href="/pdf/2310.11060" title="Download PDF">pdf</a>, <a href="/format/2310.11060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally Differentially Private Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zening Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rong-Hua Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+M">Meihao Liao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+F">Fusheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph embedding has been demonstrated to be a powerful tool for learning
latent representations for nodes in a graph. However, despite its superior
performance in various graph-based machine learning tasks, learning over graphs
can raise significant privacy concerns when graph data involves sensitive
information. To address this, in this paper, we investigate the problem of
developing graph embedding algorithms that satisfy local differential privacy
(LDP). We propose LDP-GE, a novel privacy-preserving graph embedding framework,
to protect the privacy of node data. Specifically, we propose an LDP mechanism
to obfuscate node data and adopt personalized PageRank as the proximity measure
to learn node representations. Then, we theoretically analyze the privacy
guarantees and utility of the LDP-GE framework. Extensive experiments conducted
over several real-world graph datasets demonstrate that LDP-GE achieves
favorable privacy-utility trade-offs and significantly outperforms existing
approaches in both node classification and link prediction tasks.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11062" title="Abstract">arXiv:2310.11062</a> [<a href="/pdf/2310.11062" title="Download PDF">pdf</a>, <a href="/format/2310.11062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NP-RDMA: Using Commodity RDMA without Pinning Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huijun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bojie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xingtong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xizheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geron%2C+A">Amit Geron</a>, 
<a href="/search/cs?searchtype=author&query=Rabinovitch%2C+S">Shamir Rabinovitch</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haifeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+H">Han Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingbin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K">Kun Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Remote Direct Memory Access (RDMA) has been haunted by the need of pinning
down memory regions. Pinning limits the memory utilization because it impedes
on-demand paging and swapping. It also increases the initialization latency of
large memory applications from seconds to minutes. To remove memory pining,
existing approaches often require special hardware which supports page fault,
and still have inferior performance. We propose NP-RDMA, which removes memory
pinning during memory registration and enables dynamic page fault handling with
commodity RDMA NICs. NP-RDMA does not require NICs to support page fault.
Instead, by monitoring local memory paging and swapping with MMU-notifier,
combining with IOMMU/SMMU-based address mapping, NP-RDMA efficiently detects
and handles page fault in the software with near-zero additional latency to
non-page-fault RDMA verbs. We implement an LD_PRELOAD library (with a modified
kernel module), which is fully compatible with existing RDMA applications.
Experiments show that NP-RDMA adds only 0.1{\sim}2 {\mu}s latency under
non-page-fault scenarios. Moreover, NP-RDMA adds only 3.5{\sim}5.7 {\mu}s and
60 {\mu}s under minor or major page faults, respectively, which is 500x faster
than ODP which uses advanced NICs that support page fault. With non-pinned
memory, Spark initialization is 20x faster and the physical memory usage
reduces by 86% with only 5.4% slowdown. Enterprise storage can expand to 5x
capacity with SSDs while the average latency is only 10% higher. To the best of
our knowledge, NP-RDMA is the first efficient and application-transparent
software approach to remove memory pinning using commodity RDMA NICs.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11069" title="Abstract">arXiv:2310.11069</a> [<a href="/pdf/2310.11069" title="Download PDF">pdf</a>, <a href="/format/2310.11069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Waheed%2C+A">Abdul Waheed</a>, 
<a href="/search/cs?searchtype=author&query=Talafha%2C+B">Bashar Talafha</a>, 
<a href="/search/cs?searchtype=author&query=Suvellin%2C+P">Peter Suvellin</a>, 
<a href="/search/cs?searchtype=author&query=Elmadney%2C+A">Abdelrahman Elmadney</a>, 
<a href="/search/cs?searchtype=author&query=Abdul-Mageed%2C+M">Muhammad Abdul-Mageed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ArabicNLP conference co-located with EMNLP'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Arabic is a complex language with many varieties and dialects spoken by over
450 millions all around the world. Due to the linguistic diversity and
variations, it is challenging to build a robust and generalized ASR system for
Arabic. In this work, we address this gap by developing and demoing a system,
dubbed VoxArabica, for dialect identification (DID) as well as automatic speech
recognition (ASR) of Arabic. We train a wide range of models such as HuBERT
(DID), Whisper, and XLS-R (ASR) in a supervised setting for Arabic DID and ASR
tasks. Our DID models are trained to identify 17 different dialects in addition
to MSA. We finetune our ASR models on MSA, Egyptian, Moroccan, and mixed data.
Additionally, for the remaining dialects in ASR, we provide the option to
choose various models such as Whisper and MMS in a zero-shot setting. We
integrate these models into a single web interface with diverse features such
as audio recording, file upload, model selection, and the option to raise flags
for incorrect outputs. Overall, we believe VoxArabica will be useful for a wide
range of audiences concerned with Arabic research. Our system is currently
running at https://cdce-206-12-100-168.ngrok.io/.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11075" title="Abstract">arXiv:2310.11075</a> [<a href="/pdf/2310.11075" title="Download PDF">pdf</a>, <a href="/format/2310.11075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sim-to-Real Transfer of Adaptive Control Parameters for AUV  Stabilization under Current Disturbance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaffre%2C+T">Thomas Chaffre</a>, 
<a href="/search/cs?searchtype=author&query=Wheare%2C+J">Jonathan Wheare</a>, 
<a href="/search/cs?searchtype=author&query=Lammas%2C+A">Andrew Lammas</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+P">Paulo Santos</a>, 
<a href="/search/cs?searchtype=author&query=Chenadec%2C+G+L">Gilles Le Chenadec</a>, 
<a href="/search/cs?searchtype=author&query=Sammut%2C+K">Karl Sammut</a>, 
<a href="/search/cs?searchtype=author&query=Clement%2C+B">Benoit Clement</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Learning-based adaptive control methods hold the premise of enabling
autonomous agents to reduce the effect of process variations with minimal human
intervention. However, its application to autonomous underwater vehicles (AUVs)
has so far been restricted due to 1) unknown dynamics under the form of sea
current disturbance that we can not model properly nor measure due to limited
sensor capability and 2) the nonlinearity of AUVs tasks where the controller
response at some operating points must be overly conservative in order to
satisfy the specification at other operating points. Deep Reinforcement
Learning (DRL) can alleviates these limitations by training general-purpose
neural network policies, but applications of DRL algorithms to AUVs have been
restricted to simulated environments, due to their inherent high sample
complexity and distribution shift problem. This paper presents a novel
approach, merging the Maximum Entropy Deep Reinforcement Learning framework
with a classic model-based control architecture, to formulate an adaptive
controller. Within this framework, we introduce a Sim-to-Real transfer strategy
comprising the following components: a bio-inspired experience replay
mechanism, an enhanced domain randomisation technique, and an evaluation
protocol executed on a physical platform. Our experimental assessments
demonstrate that this method effectively learns proficient policies from
suboptimal simulated models of the AUV, resulting in control performance 3
times higher when transferred to a real-world vehicle, compared to its
model-based nonadaptive but optimal counterpart.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11077" title="Abstract">arXiv:2310.11077</a> [<a href="/pdf/2310.11077" title="Download PDF">pdf</a>, <a href="/format/2310.11077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> United We Stand: Using Epoch-wise Agreement of Ensembles to Combat  Overfit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stern%2C+U">Uri Stern</a>, 
<a href="/search/cs?searchtype=author&query=Shwartz%2C+D">Daniel Shwartz</a>, 
<a href="/search/cs?searchtype=author&query=Weinshall%2C+D">Daphna Weinshall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep neural networks have become the method of choice for solving many image
classification tasks, largely because they can fit very complex functions
defined over raw images. The downside of such powerful learners is the danger
of overfitting the training set, leading to poor generalization, which is
usually avoided by regularization and "early stopping" of the training. In this
paper, we propose a new deep network ensemble classifier that is very effective
against overfit. We begin with the theoretical analysis of a regression model,
whose predictions - that the variance among classifiers increases when overfit
occurs - is demonstrated empirically in deep networks in common use. Guided by
these results, we construct a new ensemble-based prediction method designed to
combat overfit, where the prediction is determined by the most consensual
prediction throughout the training. On multiple image and text classification
datasets, we show that when regular ensembles suffer from overfit, our method
eliminates the harmful reduction in generalization due to overfit, and often
even surpasses the performance obtained by early stopping. Our method is easy
to implement, and can be integrated with any training scheme and architecture,
without additional prior knowledge beyond the training set. Accordingly, it is
a practical and useful tool to overcome overfit.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11079" title="Abstract">arXiv:2310.11079</a> [<a href="/pdf/2310.11079" title="Download PDF">pdf</a>, <a href="/format/2310.11079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Red Teaming: Gender Bias Provocation and Mitigation in  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hsuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Cheng-Chu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Farn%2C+H">Hua Farn</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S+H">Shachi H Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Sahay%2C+S">Saurav Sahay</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shang-Tse Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, researchers have made considerable improvements in dialogue systems
with the progress of large language models (LLMs) such as ChatGPT and GPT-4.
These LLM-based chatbots encode the potential biases while retaining
disparities that can harm humans during interactions. The traditional biases
investigation methods often rely on human-written test cases. However, these
test cases are usually expensive and limited. In this work, we propose a
first-of-its-kind method that automatically generates test cases to detect
LLMs' potential gender bias. We apply our method to three well-known LLMs and
find that the generated test cases effectively identify the presence of biases.
To address the biases identified, we propose a mitigation strategy that uses
the generated test cases as demonstrations for in-context learning to
circumvent the need for parameter fine-tuning. The experimental results show
that LLMs generate fairer responses with the proposed approach.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11080" title="Abstract">arXiv:2310.11080</a> [<a href="/pdf/2310.11080" title="Download PDF">pdf</a>, <a href="/format/2310.11080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On General Capacity-Distortion Formulas of Integrated Sensing and  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Oechtering%2C+T">Tobias Oechtering</a>, 
<a href="/search/cs?searchtype=author&query=Skoglund%2C+M">Mikael Skoglund</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuan Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The integrated sensing and communication (ISAC) problem with general state
and channel distributions is investigated. General formulas of the
capacity-distortion tradeoff for the ISAC problem under maximal and average
distortion constraints are provided. The results cover some existing
communication models such as the general point-to-point channel and
Gel'fand-Pinsker channel. More details including memoryless states and
channels, mixed states and channels, and rate-limited CSI at one side are
considered. Numerical results focus on writing-on-dirty paper model and channel
with ergodic/non-ergodic fading.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11081" title="Abstract">arXiv:2310.11081</a> [<a href="/pdf/2310.11081" title="Download PDF">pdf</a>, <a href="/format/2310.11081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding writing style in social media with a supervised  contrastively pre-trained transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huertas-Tato%2C+J">Javier Huertas-Tato</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+A">Alejandro Martin</a>, 
<a href="/search/cs?searchtype=author&query=Camacho%2C+D">David Camacho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Online Social Networks serve as fertile ground for harmful behavior, ranging
from hate speech to the dissemination of disinformation. Malicious actors now
have unprecedented freedom to misbehave, leading to severe societal unrest and
dire consequences, as exemplified by events such as the Capitol assault during
the US presidential election and the Antivaxx movement during the COVID-19
pandemic. Understanding online language has become more pressing than ever.
While existing works predominantly focus on content analysis, we aim to shift
the focus towards understanding harmful behaviors by relating content to their
respective authors. Numerous novel approaches attempt to learn the stylistic
features of authors in texts, but many of these approaches are constrained by
small datasets or sub-optimal training losses. To overcome these limitations,
we introduce the Style Transformer for Authorship Representations (STAR),
trained on a large corpus derived from public sources of 4.5 x 10^6 authored
texts involving 70k heterogeneous authors. Our model leverages Supervised
Contrastive Loss to teach the model to minimize the distance between texts
authored by the same individual. This author pretext pre-training task yields
competitive performance at zero-shot with PAN challenges on attribution and
clustering. Additionally, we attain promising results on PAN verification
challenges using a single dense layer, with our model serving as an embedding
encoder. Finally, we present results from our test partition on Reddit. Using a
support base of 8 documents of 512 tokens, we can discern authors from sets of
up to 1616 authors with at least 80\% accuracy. We share our pre-trained model
at huggingface (https://huggingface.co/AIDA-UPM/star) and our code is available
at (https://github.com/jahuerta92/star)
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11082" title="Abstract">arXiv:2310.11082</a> [<a href="/pdf/2310.11082" title="Download PDF">pdf</a>, <a href="/format/2310.11082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-omics Sampling-based Graph Transformer for Synthetic Lethality  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xusheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qiong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Huailiang Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Synthetic lethality (SL) prediction is used to identify if the co-mutation of
two genes results in cell death. The prevalent strategy is to abstract SL
prediction as an edge classification task on gene nodes within SL data and
achieve it through graph neural networks (GNNs). However, GNNs suffer from
limitations in their message passing mechanisms, including over-smoothing and
over-squashing issues. Moreover, harnessing the information of non-SL gene
relationships within large-scale multi-omics data to facilitate SL prediction
poses a non-trivial challenge. To tackle these issues, we propose a new
multi-omics sampling-based graph transformer for SL prediction (MSGT-SL).
Concretely, we introduce a shallow multi-view GNN to acquire local structural
patterns from both SL and multi-omics data. Further, we input gene features
that encode multi-view information into the standard self-attention to capture
long-range dependencies. Notably, starting with batch genes from SL data, we
adopt parallel random walk sampling across multiple omics gene graphs
encompassing them. Such sampling effectively and modestly incorporates genes
from omics in a structure-aware manner before using self-attention. We showcase
the effectiveness of MSGT-SL on real-world SL tasks, demonstrating the
empirical benefits gained from the graph transformer and multi-omics data.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11083" title="Abstract">arXiv:2310.11083</a> [<a href="/pdf/2310.11083" title="Download PDF">pdf</a>, <a href="/format/2310.11083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSG: Curriculum Representation Learning for Signed Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kaiqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Pengqian Han</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xianda Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Signed graphs are valuable for modeling complex relationships with positive
and negative connections, and Signed Graph Neural Networks (SGNNs) have become
crucial tools for their analysis. However, prior to our work, no specific
training plan existed for SGNNs, and the conventional random sampling approach
did not address varying learning difficulties within the graph's structure. We
proposed a curriculum-based training approach, where samples progress from easy
to complex, inspired by human learning. To measure learning difficulty, we
introduced a lightweight mechanism and created the Curriculum representation
learning framework for Signed Graphs (CSG). This framework optimizes the order
in which samples are presented to the SGNN model. Empirical validation across
six real-world datasets showed impressive results, enhancing SGNN model
accuracy by up to 23.7% in link sign prediction (AUC) and significantly
improving stability with an up to 8.4 reduction in the standard deviation of
AUC scores.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11085" title="Abstract">arXiv:2310.11085</a> [<a href="/pdf/2310.11085" title="Download PDF">pdf</a>, <a href="/format/2310.11085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Few-Shot Relation Extraction via Pre-Trained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ozyurt%2C+Y">Yilmazcan Ozyurt</a>, 
<a href="/search/cs?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Relation extraction aims at inferring structured human knowledge from textual
documents. State-of-the-art methods based on language models commonly have two
limitations: (1) they require named entities to be either given as input or
infer them, which introduces additional noise, and (2) they require human
annotations of documents. As a remedy, we present a novel framework for
in-context few-shot relation extraction via pre-trained language models. To the
best of our knowledge, we are the first to reformulate the relation extraction
task as a tailored in-context few-shot learning paradigm. Thereby, we achieve
crucial benefits in that we eliminate the need for both named entity
recognition and human annotation of documents. Unlike existing methods based on
fine-tuning, our framework is flexible in that it can be easily updated for a
new set of relations without re-training. We evaluate our framework using
DocRED, the largest publicly available dataset for document-level relation
extraction, and demonstrate that our framework achieves state-of-the-art
performance. Finally, our framework allows us to identify missing annotations,
and we thus show that our framework actually performs much better than the
original labels from the development set of DocRED.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11087" title="Abstract">arXiv:2310.11087</a> [<a href="/pdf/2310.11087" title="Download PDF">pdf</a>, <a href="/format/2310.11087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Pyramid biLSTM: Using Smartphone Sensors for Transportation Mode  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qinrui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">The widespread utilization of smartphones has provided extensive availability
to Inertial Measurement Units, providing a wide range of sensory data that can
be advantageous for the detection of transportation modes. The objective of
this study is to propose a novel end-to-end approach to effectively explore a
reduced amount of sensory data collected from a smartphone to achieve accurate
mode detection in common daily traveling activities. Our approach, called
Feature Pyramid biLSTM (FPbiLSTM), is characterized by its ability to reduce
the number of sensors required and processing demands, resulting in a more
efficient modeling process without sacrificing the quality of the outcomes than
the other current models. FPbiLSTM extends an existing CNN biLSTM model with
the Feature Pyramid Network, leveraging the advantages of both shallow layer
richness and deeper layer feature resilience for capturing temporal moving
patterns in various transportation modes. It exhibits an excellent performance
by employing the data collected from only three out of seven sensors, i.e.
accelerometers, gyroscopes, and magnetometers, in the 2018 Sussex-Huawei
Locomotion (SHL) challenge dataset, attaining a noteworthy accuracy of 95.1%
and an F1-score of 94.7% in detecting eight different transportation modes.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11088" title="Abstract">arXiv:2310.11088</a> [<a href="/pdf/2310.11088" title="Download PDF">pdf</a>, <a href="/format/2310.11088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MeKB-Rec: Personal Knowledge Graph Learning for Cross-Domain  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xin Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Z">Zifei Shan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qian Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">It is a long-standing challenge in modern recommender systems to effectively
make recommendations for new users, namely the cold-start problem. Cross-Domain
Recommendation (CDR) has been proposed to address this challenge, but current
ways to represent users' interests across systems are still severely limited.
We introduce Personal Knowledge Graph (PKG) as a domain-invariant interest
representation, and propose a novel CDR paradigm named MeKB-Rec. We first link
users and entities in a knowledge base to construct a PKG of users' interests,
named MeKB. Then we learn a semantic representation of MeKB for the
cross-domain recommendation. To efficiently utilize limited training data in
CDR, MeKB-Rec employs Pretrained Language Models to inject world knowledge into
understanding users' interests. Beyond most existing systems, our approach
builds a semantic mapping across domains which breaks the requirement for
in-domain user behaviors, enabling zero-shot recommendations for new users in a
low-resource domain. We experiment MeKB-Rec on well-established public CDR
datasets, and demonstrate that the new formulation % is more powerful than
previous approaches, achieves a new state-of-the-art that significantly
improves HR@10 and NDCG@10 metrics over best previous approaches by 24\%--91\%,
with a 105\% improvement for HR@10 of zero-shot users with no behavior in the
target domain. We deploy MeKB-Rec in WeiXin recommendation scenarios and
achieve significant gains in core online metrics. MeKB-Rec is now serving
hundreds of millions of users in real-world products.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11092" title="Abstract">arXiv:2310.11092</a> [<a href="/pdf/2310.11092" title="Download PDF">pdf</a>, <a href="/format/2310.11092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DORec: Decomposed Object Reconstruction Utilizing 2D Self-Supervised  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sicheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Sihui Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+R">Rong Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yiyi Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Decomposing a target object from a complex background while reconstructing is
challenging. Most approaches acquire the perception for object instances
through the use of manual labels, but the annotation procedure is costly. The
recent advancements in 2D self-supervised learning have brought new prospects
to object-aware representation, yet it remains unclear how to leverage such
noisy 2D features for clean decomposition. In this paper, we propose a
Decomposed Object Reconstruction (DORec) network based on neural implicit
representations. Our key idea is to transfer 2D self-supervised features into
masks of two levels of granularity to supervise the decomposition, including a
binary mask to indicate the foreground regions and a K-cluster mask to indicate
the semantically similar regions. These two masks are complementary to each
other and lead to robust decomposition. Experimental results show the
superiority of DORec in segmenting and reconstructing the foreground object on
various datasets.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11093" title="Abstract">arXiv:2310.11093</a> [<a href="/pdf/2310.11093" title="Download PDF">pdf</a>, <a href="/format/2310.11093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SODA: Robust Training of Test-Time Data Adaptors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zige Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yonggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+L">Long Lan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenjing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Adapting models deployed to test distributions can mitigate the performance
degradation caused by distribution shifts. However, privacy concerns may render
model parameters inaccessible. One promising approach involves utilizing
zeroth-order optimization (ZOO) to train a data adaptor to adapt the test data
to fit the deployed models. Nevertheless, the data adaptor trained with ZOO
typically brings restricted improvements due to the potential corruption of
data features caused by the data adaptor. To address this issue, we revisit ZOO
in the context of test-time data adaptation. We find that the issue directly
stems from the unreliable estimation of the gradients used to optimize the data
adaptor, which is inherently due to the unreliable nature of the pseudo-labels
assigned to the test data. Based on this observation, we propose
pseudo-label-robust data adaptation (SODA) to improve the performance of data
adaptation. Specifically, SODA leverages high-confidence predicted labels as
reliable labels to optimize the data adaptor with ZOO for label prediction. For
data with low-confidence predictions, SODA encourages the adaptor to preserve
data information to mitigate data corruption. Empirical results indicate that
SODA can significantly enhance the performance of deployed models in the
presence of distribution shifts without requiring access to model parameters.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11094" title="Abstract">arXiv:2310.11094</a> [<a href="/pdf/2310.11094" title="Download PDF">pdf</a>, <a href="/format/2310.11094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relearning Forgotten Knowledge: on Forgetting, Overfit and Training-Free  Ensembles of DNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stern%2C+U">Uri Stern</a>, 
<a href="/search/cs?searchtype=author&query=Weinshall%2C+D">Daphna Weinshall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The infrequent occurrence of overfit in deep neural networks is perplexing.
On the one hand, theory predicts that as models get larger they should
eventually become too specialized for a specific training set, with ensuing
decrease in generalization. In contrast, empirical results in image
classification indicate that increasing the training time of deep models or
using bigger models almost never hurts generalization. Is it because the way we
measure overfit is too limited? Here, we introduce a novel score for
quantifying overfit, which monitors the forgetting rate of deep models on
validation data. Presumably, this score indicates that even while
generalization improves overall, there are certain regions of the data space
where it deteriorates. When thus measured, we show that overfit can occur with
and without a decrease in validation accuracy, and may be more common than
previously appreciated. This observation may help to clarify the aforementioned
confusing picture. We use our observations to construct a new ensemble method,
based solely on the training history of a single network, which provides
significant improvement in performance without any additional cost in training
time. An extensive empirical evaluation with modern deep models shows our
method's utility on multiple datasets, neural networks architectures and
training schemes, both when training from scratch and when using pre-trained
networks in transfer learning. Notably, our method outperforms comparable
methods while being easier to implement and use, and further improves the
performance of competitive networks on Imagenet by 1\%.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11096" title="Abstract">arXiv:2310.11096</a> [<a href="/pdf/2310.11096" title="Download PDF">pdf</a>, <a href="/format/2310.11096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse-DySta: Sparsity-Aware Dynamic and Static Scheduling for Sparse  Multi-DNN Workloads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hongxiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Venieris%2C+S+I">Stylianos I. Venieris</a>, 
<a href="/search/cs?searchtype=author&query=Kouris%2C+A">Alexandros Kouris</a>, 
<a href="/search/cs?searchtype=author&query=Lane%2C+N+D">Nicholas D. Lane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted by MICRO'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Running multiple deep neural networks (DNNs) in parallel has become an
emerging workload in both edge devices, such as mobile phones where multiple
tasks serve a single user for daily activities, and data centers, where various
requests are raised from millions of users, as seen with large language models.
To reduce the costly computational and memory requirements of these workloads,
various efficient sparsification approaches have been introduced, resulting in
widespread sparsity across different types of DNN models. In this context,
there is an emerging need for scheduling sparse multi-DNN workloads, a problem
that is largely unexplored in previous literature. This paper systematically
analyses the use-cases of multiple sparse DNNs and investigates the
opportunities for optimizations. Based on these findings, we propose Dysta, a
novel bi-level dynamic and static scheduler that utilizes both static sparsity
patterns and dynamic sparsity information for the sparse multi-DNN scheduling.
Both static and dynamic components of Dysta are jointly designed at the
software and hardware levels, respectively, to improve and refine the
scheduling approach. To facilitate future progress in the study of this class
of workloads, we construct a public benchmark that contains sparse multi-DNN
workloads across different deployment scenarios, spanning from mobile phones
and AR/VR wearables to data centers. A comprehensive evaluation on the sparse
multi-DNN benchmark demonstrates that our proposed approach outperforms the
state-of-the-art methods with up to 10% decrease in latency constraint
violation rate and nearly 4X reduction in average normalized turnaround time.
Our artifacts and code are publicly available at:
https://github.com/SamsungLabs/Sparse-Multi-DNN-Scheduling.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11097" title="Abstract">arXiv:2310.11097</a> [<a href="/pdf/2310.11097" title="Download PDF">pdf</a>, <a href="/format/2310.11097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimenting AI Technologies for Disinformation Combat: the IDMO  Project
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canale%2C+L">Lorenzo Canale</a>, 
<a href="/search/cs?searchtype=author&query=Messina%2C+A">Alberto Messina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The Italian Digital Media Observatory (IDMO) project, part of a European
initiative, focuses on countering disinformation and fake news. This report
outlines contributions from Rai-CRITS to the project, including: (i) the
creation of novel datasets for testing technologies (ii) development of an
automatic model for categorizing Pagella Politica verdicts to facilitate
broader analysis (iii) creation of an automatic model for recognizing textual
entailment with exceptional accuracy on the FEVER dataset (iv) assessment using
GPT-4 to identify textual entailmen (v) a game to raise awareness about fake
news at national events.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11099" title="Abstract">arXiv:2310.11099</a> [<a href="/pdf/2310.11099" title="Download PDF">pdf</a>, <a href="/format/2310.11099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Local Patterns of Child Pornography Consumption in France  using Tor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koebe%2C+T">Till Koebe</a>, 
<a href="/search/cs?searchtype=author&query=del+Villar%2C+Z">Zinnya del Villar</a>, 
<a href="/search/cs?searchtype=author&query=Nutakki%2C+B">Brahmani Nutakki</a>, 
<a href="/search/cs?searchtype=author&query=Sagimbayeva%2C+N">Nursulu Sagimbayeva</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+I">Ingmar Weber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Child pornography represents a severe form of exploitation and victimization
of children, leaving the victims with emotional and physical trauma. In this
study, we aim to analyze local patterns of child pornography consumption in 20
metropolitan regions of France using fine-grained mobile traffic data of Tor
network-related web services. We conservatively estimate that approx. 3.3 % of
Tor mobile download traffic observed in France is linked to the consumption of
child sexual abuse materials by correlating it with local-level temporal porn
consumption patterns. This compares to 16.9 % of what we estimate to be the
global share of child pornographic content on Tor. In line with existing
literature on the link between sexual child abuse and the consumption of
image-based content thereof, we observe a positive and statistically
significant effect of our child pornography consumption estimates on the
reported number of victims of sexual violence and vice versa across 1341 French
communes, which validates our findings, after controlling for a set of spatial
and non-spatial features including socio-demographic characteristics, voting
behaviour, nearby points of interest and Google Trends queries. While this is a
first, exploratory attempt to look at child pornography from a spatial
epidemiological angle, we believe this research provides public health
officials with valuable information to prioritize target areas for public
awareness campaigns and hopefully inform future paths of research in that area.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11102" title="Abstract">arXiv:2310.11102</a> [<a href="/pdf/2310.11102" title="Download PDF">pdf</a>, <a href="/format/2310.11102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HGCVAE: Integrating Generative and Contrastive Learning for  Heterogeneous Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yulan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhirui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+S">Sheng Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative self-supervised learning (SSL) has exhibited significant potential
and garnered increasing interest in graph learning. In this study, we aim to
explore the problem of generative SSL in the context of heterogeneous graph
learning (HGL). The previous SSL approaches for heterogeneous graphs have
primarily relied on contrastive learning, necessitating the design of complex
views to capture heterogeneity. However, existing generative SSL methods have
not fully leveraged the capabilities of generative models to address the
challenges of HGL. In this paper, we present HGCVAE, a novel contrastive
variational graph auto-encoder that liberates HGL from the burden of intricate
heterogeneity capturing. Instead of focusing on complicated heterogeneity,
HGCVAE harnesses the full potential of generative SSL. HGCVAE innovatively
consolidates contrastive learning with generative SSL, introducing several key
innovations. Firstly, we employ a progressive mechanism to generate
high-quality hard negative samples for contrastive learning, utilizing the
power of variational inference. Additionally, we present a dynamic mask
strategy to ensure effective and stable learning. Moreover, we propose an
enhanced scaled cosine error as the criterion for better attribute
reconstruction. As an initial step in combining generative and contrastive SSL,
HGCVAE achieves remarkable results compared to various state-of-the-art
baselines, confirming its superiority.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11103" title="Abstract">arXiv:2310.11103</a> [<a href="/pdf/2310.11103" title="Download PDF">pdf</a>, <a href="/format/2310.11103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Motion-Copying via Homomorphic Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Takanashi%2C+H">Haruki Takanashi</a>, 
<a href="/search/eess?searchtype=author&query=Teranishi%2C+K">Kaoru Teranishi</a>, 
<a href="/search/eess?searchtype=author&query=Kogiso%2C+K">Kiminao Kogiso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This study aims to develop an encrypted motion-copying system using
homomorphic encryption for secure motion preservation and reproduction. A novel
concept of encrypted motion-copying systems is introduced, realizing the
preservation, edition, and reproduction of the motion over encrypted data. The
developed motion-copying system uses the conventional encrypted four-channel
bilateral control system with robotic arms to save the leader's motion by a
human operator in the ciphertext in a memory. The follower's control system
reproduces the motion using the encrypted data loaded from the secure memory.
Additionally, the developed system enables us to directly edit the motion data
preserved in the memory without decryption using homomorphic operation.
Finally, this study demonstrates the effectiveness of the developed encrypted
motion-copying system in free motion, object contact, and spatial scaling
scenarios.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11105" title="Abstract">arXiv:2310.11105</a> [<a href="/pdf/2310.11105" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizability of CNN Architectures for Face Morph Presentation Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=HmaSalah%2C+S+R">Sherko R. HmaSalah</a>, 
<a href="/search/cs?searchtype=author&query=Asaad%2C+A">Aras Asaad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic border control systems are wide spread in modern airports
worldwide. Morphing attacks on face biometrics is a serious threat that
undermines the security and reliability of face recognition systems deployed in
airports and border controls. Therefore, developing a robust Machine Learning
(ML) system is necessary to prevent criminals crossing borders with fake
identifications especially since it has been shown that security officers
cannot detect morphs better than machines. In this study, we investigate the
generalization power of Convolutional Neural Network (CNN) architectures
against morphing attacks. The investigation utilizes 5 distinct CNNs namely
ShuffleNet, DenseNet201, VGG16, EffecientNet-B0 and InceptionResNet-v2. Each
CNN architecture represents a well-known family of CNN models in terms of
number of parameters, architectural design and performance across various
computer vision applications. To ensure robust evaluation, we employ 4
different datasets (Utrecht, London, Defacto and KurdFace) that contain a
diverse range of digital face images which cover variations in ethnicity,
gender, age, lighting condition and camera setting. One of the fundamental
concepts of ML system design is the ability to generalize effectively to
previously unseen data, hence not only we evaluate the performance of CNN
models within individual datasets but also explore their performance across
combined datasets and investigating each dataset in testing phase only.
Experimental results on more than 8 thousand images (genuine and morph) from
the 4 datasets show that InceptionResNet-v2 generalizes better to unseen data
and outperforms the other 4 CNN models.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11106" title="Abstract">arXiv:2310.11106</a> [<a href="/pdf/2310.11106" title="Download PDF">pdf</a>, <a href="/format/2310.11106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Structure-guided Network for Tooth Alignment in 2D Photograph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dou%2C+Y">Yulong Dou</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+L">Lanzhuju Mei</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhiming Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Orthodontics focuses on rectifying misaligned teeth (i.e., malocclusions),
affecting both masticatory function and aesthetics. However, orthodontic
treatment often involves complex, lengthy procedures. As such, generating a 2D
photograph depicting aligned teeth prior to orthodontic treatment is crucial
for effective dentist-patient communication and, more importantly, for
encouraging patients to accept orthodontic intervention. In this paper, we
propose a 3D structure-guided tooth alignment network that takes 2D photographs
as input (e.g., photos captured by smartphones) and aligns the teeth within the
2D image space to generate an orthodontic comparison photograph featuring
aesthetically pleasing, aligned teeth. Notably, while the process operates
within a 2D image space, our method employs 3D intra-oral scanning models
collected in clinics to learn about orthodontic treatment, i.e., projecting the
pre- and post-orthodontic 3D tooth structures onto 2D tooth contours, followed
by a diffusion model to learn the mapping relationship. Ultimately, the aligned
tooth contours are leveraged to guide the generation of a 2D photograph with
aesthetically pleasing, aligned teeth and realistic textures. We evaluate our
network on various facial photographs, demonstrating its exceptional
performance and strong applicability within the orthodontic industry.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11110" title="Abstract">arXiv:2310.11110</a> [<a href="/pdf/2310.11110" title="Download PDF">pdf</a>, <a href="/format/2310.11110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimally Informed Linear Discriminant Analysis: training an LDA model  with unlabelled data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heintz%2C+N">Nicolas Heintz</a>, 
<a href="/search/cs?searchtype=author&query=Francart%2C+T">Tom Francart</a>, 
<a href="/search/cs?searchtype=author&query=Bertrand%2C+A">Alexander Bertrand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Linear Discriminant Analysis (LDA) is one of the oldest and most popular
linear methods for supervised classification problems. In this paper, we
demonstrate that it is possible to compute the exact projection vector from LDA
models based on unlabelled data, if some minimal prior information is
available. More precisely, we show that only one of the following three pieces
of information is actually sufficient to compute the LDA projection vector if
only unlabelled data are available: (1) the class average of one of the two
classes, (2) the difference between both class averages (up to a scaling), or
(3) the class covariance matrices (up to a scaling). These theoretical results
are validated in numerical experiments, demonstrating that this minimally
informed Linear Discriminant Analysis (MILDA) model closely matches the
performance of a supervised LDA model. Furthermore, we show that the MILDA
projection vector can be computed in a closed form with a computational cost
comparable to LDA and is able to quickly adapt to non-stationary data, making
it well-suited to use as an adaptive classifier.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11113" title="Abstract">arXiv:2310.11113</a> [<a href="/pdf/2310.11113" title="Download PDF">pdf</a>, <a href="/format/2310.11113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Sentiment Analysis for Software Engineering in the Era of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Ting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Irsan%2C+I+C">Ivana Clairine Irsan</a>, 
<a href="/search/cs?searchtype=author&query=Thung%2C+F">Ferdian Thung</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software development is an inherently collaborative process, where various
stakeholders frequently express their opinions and emotions across diverse
platforms. Recognizing the sentiments conveyed in these interactions is crucial
for the effective development and ongoing maintenance of software systems. For
instance, app developers can harness sentiment analysis of app users' reviews
to enhance the quality of their app. Over the years, many tools have been
proposed to aid in sentiment analysis, but accurately identifying the
sentiments expressed in software engineering datasets remains challenging.
<br />Recent advances have showcased the potential of fine-tuned pre-trained
language models in handling software engineering datasets, albeit they grapple
with the shortage of labeled data. With the emergence of large language models
(LLMs), it is pertinent to investigate how these models perform in the context
of sentiment analysis for software engineering. In this work, we undertake a
comprehensive empirical study using five established software engineering
datasets. We assess the performance of three open-source LLMs in both zero-shot
and few-shot scenarios. Additionally, we draw comparisons between fine-tuned
pre-trained smaller language models and LLMs employing prompts.
<br />Our experimental findings demonstrate that LLMs exhibit state-of-the-art
performance on datasets marked by limited training data and imbalanced
distributions. LLMs can also achieve excellent performance under a zero-shot
setting. However, when ample training data is available, or the dataset
exhibits a more balanced distribution, fine-tuned smaller language models can
still achieve superior results.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11116" title="Abstract">arXiv:2310.11116</a> [<a href="/pdf/2310.11116" title="Download PDF">pdf</a>, <a href="/format/2310.11116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Platform Social Dynamics: An Analysis of ChatGPT and COVID-19  Vaccine Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alipour%2C+S">Shayan Alipour</a>, 
<a href="/search/cs?searchtype=author&query=Galeazzi%2C+A">Alessandro Galeazzi</a>, 
<a href="/search/cs?searchtype=author&query=Sangiorgio%2C+E">Emanuele Sangiorgio</a>, 
<a href="/search/cs?searchtype=author&query=Avalle%2C+M">Michele Avalle</a>, 
<a href="/search/cs?searchtype=author&query=Bojic%2C+L">Ljubisa Bojic</a>, 
<a href="/search/cs?searchtype=author&query=Cinelli%2C+M">Matteo Cinelli</a>, 
<a href="/search/cs?searchtype=author&query=Quattrociocchi%2C+W">Walter Quattrociocchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The role of social media in information dissemination and agenda-setting has
significantly expanded in recent years. By offering real-time interactions,
online platforms have become invaluable tools for studying societal responses
to significant events as they unfold. However, online reactions to external
developments are influenced by various factors, including the nature of the
event and the online environment. This study examines the dynamics of public
discourse on digital platforms to shed light on this issue. We analyzed over 12
million posts and news articles related to two significant events: the release
of ChatGPT in 2022 and the global discussions about COVID-19 vaccines in 2021.
Data was collected from multiple platforms, including Twitter, Facebook,
Instagram, Reddit, YouTube, and GDELT. We employed topic modeling techniques to
uncover the distinct thematic emphases on each platform, which reflect their
specific features and target audiences. Additionally, sentiment analysis
revealed various public perceptions regarding the topics studied. Lastly, we
compared the evolution of engagement across platforms, unveiling unique
patterns for the same topic. Notably, discussions about COVID-19 vaccines
spread more rapidly due to the immediacy of the subject, while discussions
about ChatGPT, despite its technological importance, propagated more gradually.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11117" title="Abstract">arXiv:2310.11117</a> [<a href="/pdf/2310.11117" title="Download PDF">pdf</a>, <a href="/format/2310.11117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USDC: Unified Static and Dynamic Compression for Visual Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Huan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Chao Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jianchao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+P">Peng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiyuan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chengru Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was actually finished in 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Visual Transformers have achieved great success in almost all vision tasks,
such as classification, detection, and so on. However, the model complexity and
the inference speed of the visual transformers hinder their deployments in
industrial products. Various model compression techniques focus on directly
compressing the visual transformers into a smaller one while maintaining the
model performance, however, the performance drops dramatically when the
compression ratio is large. Furthermore, several dynamic network techniques
have also been applied to dynamically compress the visual transformers to
obtain input-adaptive efficient sub-structures during the inference stage,
which can achieve a better trade-off between the compression ratio and the
model performance. The upper bound of memory of dynamic models is not reduced
in the practical deployment since the whole original visual transformer model
and the additional control gating modules should be loaded onto devices
together for inference. To alleviate two disadvantages of two categories of
methods, we propose to unify the static compression and dynamic compression
techniques jointly to obtain an input-adaptive compressed model, which can
further better balance the total compression ratios and the model performances.
Moreover, in practical deployment, the batch sizes of the training and
inference stage are usually different, which will cause the model inference
performance to be worse than the model training performance, which is not
touched by all previous dynamic network papers. We propose a sub-group gates
augmentation technique to solve this performance drop problem. Extensive
experiments demonstrate the superiority of our method on various baseline
visual transformers such as DeiT, T2T-ViT, and so on.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11124" title="Abstract">arXiv:2310.11124</a> [<a href="/pdf/2310.11124" title="Download PDF">pdf</a>, <a href="/format/2310.11124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maintaining App Services in Disrupted Cities: A Crisis and Resilience  Evaluation Tool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=W%C3%BCrsching%2C+L">Leon W&#xfc;rsching</a>, 
<a href="/search/cs?searchtype=author&query=Hollick%2C+M">Matthias Hollick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 4 figures, source code available at <a href="https://github.com/seemoo-lab/caret">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Disaster scenarios can disconnect entire cities from the core network (CN),
isolating base stations (BSs) and disrupting the Internet connection of app
services for many users. Such a disruption is particularly disastrous when it
affects critical app services such as communication, information, and
navigation. Deploying local app servers at the network edge can solve this
issue but leaves mobile network operators (MNOs) faced with design decisions
regarding the criticality of traffic flows, the BS topology, and the app server
deployment. We present the Crisis and Resilience Evaluation Tool (CARET) for
crisis-mode radio access networks RANs, enabling MNOs to make informed
decisions about a city's RAN configuration based on real-world data of the
NetMob23 dataset.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11130" title="Abstract">arXiv:2310.11130</a> [<a href="/pdf/2310.11130" title="Download PDF">pdf</a>, <a href="/format/2310.11130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Expressivity of ReLU Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ergen%2C+E">Ekin Ergen</a>, 
<a href="/search/cs?searchtype=author&query=Grillo%2C+M">Moritz Grillo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We study the expressivity of ReLU neural networks in the setting of a binary
classification problem from a topological perspective. Recently, empirical
studies showed that neural networks operate by changing topology, transforming
a topologically complicated data set into a topologically simpler one as it
passes through the layers. This topological simplification has been measured by
Betti numbers, which are algebraic invariants of a topological space. We use
the same measure to establish lower and upper bounds on the topological
simplification a ReLU neural network can achieve with a given architecture. We
therefore contribute to a better understanding of the expressivity of ReLU
neural networks in the context of binary classification problems by shedding
light on their ability to capture the underlying topological structure of the
data. In particular the results show that deep ReLU neural networks are
exponentially more powerful than shallow ones in terms of topological
simplification. This provides a mathematically rigorous explanation why deeper
networks are better equipped to handle complex and topologically rich datasets.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11131" title="Abstract">arXiv:2310.11131</a> [<a href="/pdf/2310.11131" title="Download PDF">pdf</a>, <a href="/format/2310.11131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FROST: Towards Energy-efficient AI-on-5G Platforms -- A GPU Power  Capping Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mavromatis%2C+I">Ioannis Mavromatis</a>, 
<a href="/search/cs?searchtype=author&query=De+Feo%2C+S">Stefano De Feo</a>, 
<a href="/search/cs?searchtype=author&query=Carnelli%2C+P">Pietro Carnelli</a>, 
<a href="/search/cs?searchtype=author&query=Piechocki%2C+R+J">Robert J. Piechocki</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Aftab Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE CSCN 2023, Munich, Germany
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The Open Radio Access Network (O-RAN) is a burgeoning market with projected
growth in the upcoming years. RAN has the highest CAPEX impact on the network
and, most importantly, consumes 73% of its total energy. That makes it an ideal
target for optimisation through the integration of Machine Learning (ML).
However, the energy consumption of ML is frequently overlooked in such
ecosystems. Our work addresses this critical aspect by presenting FROST -
Flexible Reconfiguration method with Online System Tuning - a solution for
energy-aware ML pipelines that adhere to O-RAN's specifications and principles.
FROST is capable of profiling the energy consumption of an ML pipeline and
optimising the hardware accordingly, thereby limiting the power draw. Our
findings indicate that FROST can achieve energy savings of up to 26.4% without
compromising the model's accuracy or introducing significant time delays.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11132" title="Abstract">arXiv:2310.11132</a> [<a href="/pdf/2310.11132" title="Download PDF">pdf</a>, <a href="/format/2310.11132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-parametric Conditional Independence Testing for Mixed  Continuous-Categorical Variables: A Novel Method and Numerical Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popescu%2C+O">Oana-Iuliana Popescu</a>, 
<a href="/search/cs?searchtype=author&query=Gerhardus%2C+A">Andreas Gerhardus</a>, 
<a href="/search/cs?searchtype=author&query=Runge%2C+J">Jakob Runge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Conditional independence testing (CIT) is a common task in machine learning,
e.g., for variable selection, and a main component of constraint-based causal
discovery. While most current CIT approaches assume that all variables are
numerical or all variables are categorical, many real-world applications
involve mixed-type datasets that include numerical and categorical variables.
Non-parametric CIT can be conducted using conditional mutual information (CMI)
estimators combined with a local permutation scheme. Recently, two novel CMI
estimators for mixed-type datasets based on k-nearest-neighbors (k-NN) have
been proposed. As with any k-NN method, these estimators rely on the definition
of a distance metric. One approach computes distances by a one-hot encoding of
the categorical variables, essentially treating categorical variables as
discrete-numerical, while the other expresses CMI by entropy terms where the
categorical variables appear as conditions only. In this work, we study these
estimators and propose a variation of the former approach that does not treat
categorical variables as numeric. Our numerical experiments show that our
variant detects dependencies more robustly across different data distributions
and preprocessing types.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11133" title="Abstract">arXiv:2310.11133</a> [<a href="/pdf/2310.11133" title="Download PDF">pdf</a>, <a href="/format/2310.11133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Invariants for Polynomial Programs by Semidefinite  Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiuye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Bai Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+N">Naijun Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhi%2C+L">Lihong Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhihong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 4 figures, in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Constraint-solving-based program invariant synthesis involves taking a
parametric template, encoding the invariant conditions, and attempting to solve
the constraints to obtain a valid assignment of parameters. The challenge lies
in that the resulting constraints are often non-convex and lack efficient
solvers. Consequently, existing works mostly rely on heuristic algorithms or
general-purpose solvers, leading to a trade-off between completeness and
efficiency.
<br />In this paper, we propose two novel approaches to synthesize invariants for
polynomial programs using semidefinite programming (SDP). For basic
semialgebraic templates, we apply techniques from robust optimization to
construct a hierarchy of SDP relaxations. These relaxations induce a series of
sub-level sets that under-approximate the set of valid parameter assignments.
Under a certain non-degenerate assumption, we present a weak completeness
result that the synthesized sets include almost all valid assignments.
Furthermore, we discuss several extensions to improve the efficiency and
expressiveness of the algorithm. We also identify a subclass of basic
semialgebraic templates, called masked templates, for which the non-degenerate
assumption is violated. Regarding masked templates, we present a
substitution-based method to strengthen the invariant conditions. The
strengthened constraints again admit a hierarchy of SDP approximations. Both of
our approaches have been implemented, and empirical results demonstrate that
they outperform the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11136" title="Abstract">arXiv:2310.11136</a> [<a href="/pdf/2310.11136" title="Download PDF">pdf</a>, <a href="/ps/2310.11136" title="Download PostScript">ps</a>, <a href="/format/2310.11136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equational Anti-Unification over Absorption Theories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayala-Rincon%2C+M">Mauricio Ayala-Rincon</a>, 
<a href="/search/cs?searchtype=author&query=Cerna%2C+D+M">David M. Cerna</a>, 
<a href="/search/cs?searchtype=author&query=Barragan%2C+A+F+G">Andres Felipe Gonzalez Barragan</a>, 
<a href="/search/cs?searchtype=author&query=Kutsia%2C+T">Temur Kutsia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 18 main text, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Interest in anti-unification, the dual problem of unification, is on the rise
due to applications within the field of software analysis and related areas.
For example, anti-unification-based techniques have found uses within clone
detection and automatic program repair methods. While syntactic forms of
anti-unification are enough for many applications, some aspects of software
analysis methods are more appropriately modeled by reasoning modulo an
equational theory. Thus, extending existing anti-unification methods to deal
with important equational theories is the natural step forward. This paper
considers anti-unification modulo pure absorption theories, i.e., some
operators are associated with a special constant satisfying the axiom
$f(x,\varepsilon_f) \approx f(\varepsilon_f,x) \approx \varepsilon_f$. We
provide a sound and complete rule-based algorithm for such theories.
Furthermore, we show that anti-unification modulo absorption is infinitary.
Despite this, our algorithm terminates and produces a finitary algorithmic
representation of the minimal complete set of solutions. We also show that the
linear variant is finitary.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11138" title="Abstract">arXiv:2310.11138</a> [<a href="/pdf/2310.11138" title="Download PDF">pdf</a>, <a href="/format/2310.11138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keep Various Trajectories: Promoting Exploration of Ensemble Policies in  Continuous Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qiang He</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinwen Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The combination of deep reinforcement learning (DRL) with ensemble methods
has been proved to be highly effective in addressing complex sequential
decision-making problems. This success can be primarily attributed to the
utilization of multiple models, which enhances both the robustness of the
policy and the accuracy of value function estimation. However, there has been
limited analysis of the empirical success of current ensemble RL methods thus
far. Our new analysis reveals that the sample efficiency of previous ensemble
DRL algorithms may be limited by sub-policies that are not as diverse as they
could be. Motivated by these findings, our study introduces a new ensemble RL
algorithm, termed \textbf{T}rajectories-awar\textbf{E} \textbf{E}nsemble
exploratio\textbf{N} (TEEN). The primary goal of TEEN is to maximize the
expected return while promoting more diverse trajectories. Through extensive
experiments, we demonstrate that TEEN not only enhances the sample diversity of
the ensemble policy compared to using sub-policies alone but also improves the
performance over ensemble RL algorithms. On average, TEEN outperforms the
baseline ensemble DRL algorithms by 41\% in performance on the tested
representative environments.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11140" title="Abstract">arXiv:2310.11140</a> [<a href="/pdf/2310.11140" title="Download PDF">pdf</a>, <a href="/format/2310.11140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moving from ISAD(G) to a CIDOC CRM-based Linked Data Model in the  Portuguese Archives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koch%2C+I">In&#xea;s Koch</a>, 
<a href="/search/cs?searchtype=author&query=Lopes%2C+C+T">Carla Teixeira Lopes</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+C">Cristina Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In\^es Koch, Carla Teixeira Lopes, and Cristina Ribeiro. 2023. Moving from ISAD(G) to a CIDOC CRM-based Linked Data Model in the Portuguese Archives. J. Comput. Cult. Herit. Just Accepted (September 2023). <a href="https://doi.org/10.1145/3605910">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Archives are facing numerous challenges. On the one hand, archival assets are
evolving to encompass digitized documents and increasing quantities of
born-digital information in diverse formats. On the other hand, the audience is
changing along with how it wishes to access archival material. Moreover, the
interoperability requirements of cultural heritage repositories are growing. In
this context, the Portuguese Archives started an ambitious program aiming to
evolve its data model, migrate existing records, and build a new archival
management system appropriate to both archival tasks and public access. The
overall goal is to have a fine-grained and flexible description, more
machine-actionable than the current one. This work describes ArchOnto, a linked
open data model for archives, and rules for its automatic population from
existing records. ArchOnto adopts a semantic web approach and encompasses the
CIDOC Conceptual Reference Model and additional ontologies, envisioning
interoperability with datasets curated by multiple communities of practice.
Existing ISAD(G)-conforming descriptions are being migrated to the new model
using the direct mappings provided here. We used a sample of 25 records
associated with different description levels to validate the completeness and
conformity of ArchOnto to existing data. This work is in progress and is
original in several respects: (1) it is one of the first approaches to use
CIDOC CRM in the context of archives, identifying problems and questions that
emerged during the process and pinpointing possible solutions; (2) it addresses
the balance in the model between the migration of existing records and the
construction of new ones by archive professionals; and (3) it adopts an open
world view on linking archival data to global information sources.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11141" title="Abstract">arXiv:2310.11141</a> [<a href="/pdf/2310.11141" title="Download PDF">pdf</a>, <a href="/format/2310.11141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-form Simultaneous Speech Translation: Thesis Proposal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pol%C3%A1k%2C+P">Peter Pol&#xe1;k</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCNLP-AACL SRW 2023 - camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Simultaneous speech translation (SST) aims to provide real-time translation
of spoken language, even before the speaker finishes their sentence.
Traditionally, SST has been addressed primarily by cascaded systems that
decompose the task into subtasks, including speech recognition, segmentation,
and machine translation. However, the advent of deep learning has sparked
significant interest in end-to-end (E2E) systems. Nevertheless, a major
limitation of most approaches to E2E SST reported in the current literature is
that they assume that the source speech is pre-segmented into sentences, which
is a significant obstacle for practical, real-world applications. This thesis
proposal addresses end-to-end simultaneous speech translation, particularly in
the long-form setting, i.e., without pre-segmentation. We present a survey of
the latest advancements in E2E SST, assess the primary obstacles in SST and its
relevance to long-form scenarios, and suggest approaches to tackle these
challenges.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11142" title="Abstract">arXiv:2310.11142</a> [<a href="/pdf/2310.11142" title="Download PDF">pdf</a>, <a href="/format/2310.11142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kou%2C+S">Siqi Kou</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+L">Lei Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dequan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhijie Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models have impressive image generation capability, but low-quality
generations still exist, and their identification remains challenging due to
the lack of a proper sample-wise metric. To address this, we propose BayesDiff,
a pixel-wise uncertainty estimator for generations from diffusion models based
on Bayesian inference. In particular, we derive a novel uncertainty iteration
principle to characterize the uncertainty dynamics in diffusion, and leverage
the last-layer Laplace approximation for efficient Bayesian inference. The
estimated pixel-wise uncertainty can not only be aggregated into a sample-wise
metric to filter out low-fidelity images but also aids in augmenting successful
generations and rectifying artifacts in failed generations in text-to-image
tasks. Extensive experiments demonstrate the efficacy of BayesDiff and its
promise for practical applications.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11146" title="Abstract">arXiv:2310.11146</a> [<a href="/pdf/2310.11146" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Quo Vadis of the Relationship between Language and Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leivada%2C+E">Evelina Leivada</a>, 
<a href="/search/cs?searchtype=author&query=Dentella%2C+V">Vittoria Dentella</a>, 
<a href="/search/cs?searchtype=author&query=Murphy%2C+E">Elliot Murphy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the field of Artificial (General) Intelligence (AI), the several recent
advancements in Natural language processing (NLP) activities relying on Large
Language Models (LLMs) have come to encourage the adoption of LLMs as
scientific models of language. While the terminology employed for the
characterization of LLMs favors their embracing as such, it is not clear that
they are in a place to offer insights into the target system they seek to
represent. After identifying the most important theoretical and empirical risks
brought about by the adoption of scientific models that lack transparency, we
discuss LLMs relating them to every scientific model's fundamental components:
the object, the medium, the meaning and the user. We conclude that, at their
current stage of development, LLMs hardly offer any explanations for language,
and then we provide an outlook for more informative future research directions
on this topic.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11153" title="Abstract">arXiv:2310.11153</a> [<a href="/pdf/2310.11153" title="Download PDF">pdf</a>, <a href="/format/2310.11153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Pre-Training Using Masked Autoencoders for ECG Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+G+N">Ganesh Neelakanta Iyer</a>, 
<a href="/search/cs?searchtype=author&query=Nag%2C+A">Avishek Nag</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+D">Deepu John</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Biomedical Circuits and Systems (BIOCAS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Unsupervised learning methods have become increasingly important in deep
learning due to their demonstrated large utilization of datasets and higher
accuracy in computer vision and natural language processing tasks. There is a
growing trend to extend unsupervised learning methods to other domains, which
helps to utilize a large amount of unlabelled data. This paper proposes an
unsupervised pre-training technique based on masked autoencoder (MAE) for
electrocardiogram (ECG) signals. In addition, we propose a task-specific
fine-tuning to form a complete framework for ECG analysis. The framework is
high-level, universal, and not individually adapted to specific model
architectures or tasks. Experiments are conducted using various model
architectures and large-scale datasets, resulting in an accuracy of 94.39% on
the MITDB dataset for ECG arrhythmia classification task. The result shows a
better performance for the classification of previously unseen data for the
proposed approach compared to fully supervised methods.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11154" title="Abstract">arXiv:2310.11154</a> [<a href="/pdf/2310.11154" title="Download PDF">pdf</a>, <a href="/format/2310.11154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal discovery using dynamically requested knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kitson%2C+N+K">Neville K Kitson</a>, 
<a href="/search/cs?searchtype=author&query=Constantinou%2C+A+C">Anthony C Constantinou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Causal Bayesian Networks (CBNs) are an important tool for reasoning under
uncertainty in complex real-world systems. Determining the graphical structure
of a CBN remains a key challenge and is undertaken either by eliciting it from
humans, using machine learning to learn it from data, or using a combination of
these two approaches. In the latter case, human knowledge is generally provided
to the algorithm before it starts, but here we investigate a novel approach
where the structure learning algorithm itself dynamically identifies and
requests knowledge for relationships that the algorithm identifies as uncertain
during structure learning. We integrate this approach into the Tabu structure
learning algorithm and show that it offers considerable gains in structural
accuracy, which are generally larger than those offered by existing approaches
for integrating knowledge. We suggest that a variant which requests only arc
orientation information may be particularly useful where the practitioner has
little preexisting knowledge of the causal relationships. As well as offering
improved accuracy, the approach can use human expertise more effectively and
contributes to making the structure learning process more transparent.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11158" title="Abstract">arXiv:2310.11158</a> [<a href="/pdf/2310.11158" title="Download PDF">pdf</a>, <a href="/format/2310.11158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing the Creativity of Large Language Models: Can models produce  divergent semantic association?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Honghua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Nai Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models possess remarkable capacity for processing language,
but it remains unclear whether these models can further generate creative
content. The present study aims to investigate the creative thinking of large
language models through a cognitive perspective. We utilize the divergent
association task (DAT), an objective measurement of creativity that asks models
to generate unrelated words and calculates the semantic distance between them.
We compare the results across different models and decoding strategies. Our
findings indicate that: (1) When using the greedy search strategy, GPT-4
outperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level.
(2) Stochastic sampling and temperature scaling are effective to obtain higher
DAT scores for models except GPT-4, but face a trade-off between creativity and
stability. These results imply that advanced large language models have
divergent semantic associations, which is a fundamental process underlying
creativity.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11160" title="Abstract">arXiv:2310.11160</a> [<a href="/pdf/2310.11160" title="Download PDF">pdf</a>, <a href="/format/2310.11160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Content-based Features from Multiple Acoustic Models for  Singing Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xueyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yicheng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haopeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zihao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+L">Lexiao Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Liumeng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhizheng Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Singing voice conversion (SVC) is a technique to enable an arbitrary singer
to sing an arbitrary song. To achieve that, it is important to obtain
speaker-agnostic representations from source audio, which is a challenging
task. A common solution is to extract content-based features (e.g., PPGs) from
a pretrained acoustic model. However, the choices for acoustic models are vast
and varied. It is yet to be explored what characteristics of content features
from different acoustic models are, and whether integrating multiple content
features can help each other. Motivated by that, this study investigates three
distinct content features, sourcing from WeNet, Whisper, and ContentVec,
respectively. We explore their complementary roles in intelligibility, prosody,
and conversion similarity for SVC. By integrating the multiple content features
with a diffusion-based SVC model, our SVC system achieves superior conversion
performance on both objective and subjective evaluation in comparison to a
single source of content features. Our demo page and code can be available
https://www.zhangxueyao.com/data/MultipleContentsSVC/index.html.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11161" title="Abstract">arXiv:2310.11161</a> [<a href="/pdf/2310.11161" title="Download PDF">pdf</a>, <a href="/format/2310.11161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate prediction of international trade flows: Leveraging knowledge  graphs and their embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rincon-Yanez%2C+D">Diego Rincon-Yanez</a>, 
<a href="/search/cs?searchtype=author&query=Ounoughi%2C+C">Chahinez Ounoughi</a>, 
<a href="/search/cs?searchtype=author&query=Sellami%2C+B">Bassem Sellami</a>, 
<a href="/search/cs?searchtype=author&query=Kalvet%2C+T">Tarmo Kalvet</a>, 
<a href="/search/cs?searchtype=author&query=Tiits%2C+M">Marek Tiits</a>, 
<a href="/search/cs?searchtype=author&query=Senatore%2C+S">Sabrina Senatore</a>, 
<a href="/search/cs?searchtype=author&query=Yahia%2C+S+B">Sadok Ben Yahia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on Journal of King Saud University Computer and Information Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">Knowledge representation (KR) is vital in designing symbolic notations to
represent real-world facts and facilitate automated decision-making tasks.
Knowledge graphs (KGs) have emerged so far as a popular form of KR, offering a
contextual and human-like representation of knowledge. In international
economics, KGs have proven valuable in capturing complex interactions between
commodities, companies, and countries. By putting the gravity model, which is a
common economic framework, into the process of building KGs, important factors
that affect trade relationships can be taken into account, making it possible
to predict international trade patterns. This paper proposes an approach that
leverages Knowledge Graph embeddings for modeling international trade, focusing
on link prediction using embeddings. Thus, valuable insights are offered to
policymakers, businesses, and economists, enabling them to anticipate the
effects of changes in the international trade system. Moreover, the integration
of traditional machine learning methods with KG embeddings, such as decision
trees and graph neural networks are also explored. The research findings
demonstrate the potential for improving prediction accuracy and provide
insights into embedding explainability in knowledge representation. The paper
also presents a comprehensive analysis of the influence of embedding methods on
other intelligent algorithms.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11163" title="Abstract">arXiv:2310.11163</a> [<a href="/pdf/2310.11163" title="Download PDF">pdf</a>, <a href="/format/2310.11163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMTLab: An Open-Source Platform for Building, Evaluating, and Diagnosing  Interactive Machine Translation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhirui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruize Gao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yichao Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lemao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gouping Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present IMTLab, an open-source end-to-end interactive machine translation
(IMT) system platform that enables researchers to quickly build IMT systems
with state-of-the-art models, perform an end-to-end evaluation, and diagnose
the weakness of systems. IMTLab treats the whole interactive translation
process as a task-oriented dialogue with a human-in-the-loop setting, in which
human interventions can be explicitly incorporated to produce high-quality,
error-free translations. To this end, a general communication interface is
designed to support the flexible IMT architectures and user policies. Based on
the proposed design, we construct a simulated and real interactive environment
to achieve end-to-end evaluation and leverage the framework to systematically
evaluate previous IMT systems. Our simulated and manual experiments show that
the prefix-constrained decoding approach still gains the lowest editing cost in
the end-to-end evaluation, while BiTIIMT achieves comparable editing cost with
a better interactive experience.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11165" title="Abstract">arXiv:2310.11165</a> [<a href="/pdf/2310.11165" title="Download PDF">pdf</a>, <a href="/format/2310.11165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Serenade: A Model for Human-in-the-loop Automatic Chord Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koops%2C+H+V">Hendrik Vincent Koops</a>, 
<a href="/search/cs?searchtype=author&query=Micchi%2C+G">Gianluca Micchi</a>, 
<a href="/search/cs?searchtype=author&query=Manco%2C+I">Ilaria Manco</a>, 
<a href="/search/cs?searchtype=author&query=Quinton%2C+E">Elio Quinton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MMRP23. 7 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Computational harmony analysis is important for MIR tasks such as automatic
segmentation, corpus analysis and automatic chord label estimation. However,
recent research into the ambiguous nature of musical harmony, causing limited
inter-rater agreement, has made apparent that there is a glass ceiling for
common metrics such as accuracy. Commonly, these issues are addressed either in
the training data itself by creating majority-rule annotations or during the
training phase by learning soft targets. We propose a novel alternative
approach in which a human and an autoregressive model together co-create a
harmonic annotation for an audio track. After automatically generating harmony
predictions, a human sparsely annotates parts with low model confidence and the
model then adjusts its predictions following human guidance. We evaluate our
model on a dataset of popular music and we show that, with this
human-in-the-loop approach, harmonic analysis performance improves over a
model-only approach. The human contribution is amplified by the second,
constrained prediction of the model.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11166" title="Abstract">arXiv:2310.11166</a> [<a href="/pdf/2310.11166" title="Download PDF">pdf</a>, <a href="/format/2310.11166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text  Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quoc-Nam Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+T+C">Thang Chau Phan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duc-Vu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+K">Kiet Van Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP'2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">English and Chinese, known as resource-rich languages, have witnessed the
strong development of transformer-based language models for natural language
processing tasks. Although Vietnam has approximately 100M people speaking
Vietnamese, several pre-trained models, e.g., PhoBERT, ViBERT, and vELECTRA,
performed well on general Vietnamese NLP tasks, including POS tagging and named
entity recognition. These pre-trained language models are still limited to
Vietnamese social media tasks. In this paper, we present the first monolingual
pre-trained language model for Vietnamese social media texts, ViSoBERT, which
is pre-trained on a large-scale corpus of high-quality and diverse Vietnamese
social media texts using XLM-R architecture. Moreover, we explored our
pre-trained model on five important natural language downstream tasks on
Vietnamese social media texts: emotion recognition, hate speech detection,
sentiment analysis, spam reviews detection, and hate speech spans detection.
Our experiments demonstrate that ViSoBERT, with far fewer parameters, surpasses
the previous state-of-the-art models on multiple Vietnamese social media tasks.
Our ViSoBERT model is
available\footnote{\url{https://huggingface.co/uitnlp/visobert}} only for
research purposes.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11169" title="Abstract">arXiv:2310.11169</a> [<a href="/pdf/2310.11169" title="Download PDF">pdf</a>, <a href="/format/2310.11169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MST-GAT: A Multimodal Spatial-Temporal Graph Attention Network for Time  Series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Chaoyue Ding</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shiliang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jing Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Information Fusion 2023 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multimodal time series (MTS) anomaly detection is crucial for maintaining the
safety and stability of working devices (e.g., water treatment system and
spacecraft), whose data are characterized by multivariate time series with
diverse modalities. Although recent deep learning methods show great potential
in anomaly detection, they do not explicitly capture spatial-temporal
relationships between univariate time series of different modalities, resulting
in more false negatives and false positives. In this paper, we propose a
multimodal spatial-temporal graph attention network (MST-GAT) to tackle this
problem. MST-GAT first employs a multimodal graph attention network (M-GAT) and
a temporal convolution network to capture the spatial-temporal correlation in
multimodal time series. Specifically, M-GAT uses a multi-head attention module
and two relational attention modules (i.e., intra- and inter-modal attention)
to model modal correlations explicitly. Furthermore, MST-GAT optimizes the
reconstruction and prediction modules simultaneously. Experimental results on
four multimodal benchmarks demonstrate that MST-GAT outperforms the
state-of-the-art baselines. Further analysis indicates that MST-GAT strengthens
the interpretability of detected anomalies by locating the most anomalous
univariate time series.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11171" title="Abstract">arXiv:2310.11171</a> [<a href="/pdf/2310.11171" title="Download PDF">pdf</a>, <a href="/format/2310.11171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Testing Behavior by Gamifying IntelliJ
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Straubinger%2C+P">Philipp Straubinger</a>, 
<a href="/search/cs?searchtype=author&query=Fraser%2C+G">Gordon Fraser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Testing is an important aspect of software development, but unfortunately, it
is often neglected. While test quality analyses such as code coverage or
mutation analysis inform developers about the quality of their tests, such
reports are viewed only sporadically during continuous integration or code
review, if they are considered at all, and their impact on the developers'
testing behavior therefore tends to be negligible. To actually influence
developer behavior, it may rather be necessary to motivate developers directly
within their programming environment, while they are coding. We introduce
IntelliGame, a gamified plugin for the popular IntelliJ Java Integrated
Development Environment, which rewards developers for positive testing behavior
using a multi-level achievement system: A total of 27 different achievements,
each with incremental levels, provide affirming feedback when developers
exhibit commendable testing behavior, and provide an incentive to further
continue and improve this behavior. A controlled experiment with 49
participants given a Java programming task reveals substantial differences in
the testing behavior triggered by IntelliGame: Incentivized developers write
more tests, achieve higher coverage and mutation scores, run their tests more
often, and achieve functionality earlier.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11173" title="Abstract">arXiv:2310.11173</a> [<a href="/pdf/2310.11173" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Extraction and Distillation from Large-Scale Image-Text  Colonoscopy Records Leveraging Large Language and Vision Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaoyuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+P">Peiyao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Manning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhijian Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quanlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pinghong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The development of artificial intelligence systems for colonoscopy analysis
often necessitates expert-annotated image datasets. However, limitations in
dataset size and diversity impede model performance and generalisation.
Image-text colonoscopy records from routine clinical practice, comprising
millions of images and text reports, serve as a valuable data source, though
annotating them is labour-intensive. Here we leverage recent advancements in
large language and vision models and propose EndoKED, a data mining paradigm
for deep knowledge extraction and distillation. EndoKED automates the
transformation of raw colonoscopy records into image datasets with pixel-level
annotation. We validate EndoKED using multi-centre datasets of raw colonoscopy
records (~1 million images), demonstrating its superior performance in training
polyp detection and segmentation models. Furthermore, the EndoKED pre-trained
vision backbone enables data-efficient and generalisable learning for optical
biopsy, achieving expert-level performance in both retrospective and
prospective validation.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11176" title="Abstract">arXiv:2310.11176</a> [<a href="/pdf/2310.11176" title="Download PDF">pdf</a>, <a href="/format/2310.11176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Behavior and User Experience in Online Museum Virtual Tours
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shikhri%2C+R">Roman Shikhri</a>, 
<a href="/search/cs?searchtype=author&query=Poretski%2C+L">Lev Poretski</a>, 
<a href="/search/cs?searchtype=author&query=Lanir%2C+J">Joel Lanir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The disruption to tourism and travel caused by the COVID-related health
crisis highlighted the potential of virtual tourism to provide a universally
accessible way to engage in cultural experiences. 360-degree virtual tours,
showing a realistic representation of the physical location, enable virtual
tourists to experience cultural heritage sites and engage with their
collections from the comfort and safety of their home. However, there is no
clear standard for the design of such tours and the experience of visitors may
vary widely from platform to platform. We first conducted a comprehensive
analysis of 40 existing virtual tours, constructing a descriptive framework for
understanding the key components and characteristics of virtual tours. Next, we
conducted a remote usability study to gain deeper insights into the actual
experiences and challenges faced by VT users. Our investigation revealed a
significant disparity between users' mental models of virtual tours and the
actual system behavior. We discuss these issues and provide concrete
recommendations for the creation of better, user-friendly 360-degree virtual
tours.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11178" title="Abstract">arXiv:2310.11178</a> [<a href="/pdf/2310.11178" title="Download PDF">pdf</a>, <a href="/format/2310.11178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FocDepthFormer: Transformer with LSTM for Depth Estimation from Focus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xueyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Fengze Han</a>, 
<a href="/search/cs?searchtype=author&query=Fayjie%2C+A">Abdur Fayjie</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+D">Dong Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 18 figures, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Depth estimation from focal stacks is a fundamental computer vision problem
that aims to infer depth from focus/defocus cues in the image stacks. Most
existing methods tackle this problem by applying convolutional neural networks
(CNNs) with 2D or 3D convolutions over a set of fixed stack images to learn
features across images and stacks. Their performance is restricted due to the
local properties of the CNNs, and they are constrained to process a fixed
number of stacks consistent in train and inference, limiting the generalization
to the arbitrary length of stacks. To handle the above limitations, we develop
a novel Transformer-based network, FocDepthFormer, composed mainly of a
Transformer with an LSTM module and a CNN decoder. The self-attention in
Transformer enables learning more informative features via an implicit
non-local cross reference. The LSTM module is learned to integrate the
representations across the stack with arbitrary images. To directly capture the
low-level features of various degrees of focus/defocus, we propose to use
multi-scale convolutional kernels in an early-stage encoder. Benefiting from
the design with LSTM, our FocDepthFormer can be pre-trained with abundant
monocular RGB depth estimation data for visual pattern capturing, alleviating
the demand for the hard-to-collect focal stack data. Extensive experiments on
various focal stack benchmark datasets show that our model outperforms the
state-of-the-art models on multiple metrics.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11182" title="Abstract">arXiv:2310.11182</a> [<a href="/pdf/2310.11182" title="Download PDF">pdf</a>, <a href="/ps/2310.11182" title="Download PostScript">ps</a>, <a href="/format/2310.11182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effectiveness of Creating Conversational Agent Personalities  Through Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span>  (Eric)
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Heng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Degachi%2C+C">Chadha Degachi</a>, 
<a href="/search/cs?searchtype=author&query=Gen%C3%A7%2C+U">U&#x11f;ur Gen&#xe7;</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasegaran%2C+S">Senthil Chandrasegaran</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+H">Himanshu Verma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 table, PGAI CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this work, we report on the effectiveness of our efforts to tailor the
personality and conversational style of a conversational agent based on GPT-3.5
and GPT-4 through prompts. We use three personality dimensions with two levels
each to create eight conversational agents archetypes. Ten conversations were
collected per chatbot, of ten exchanges each, generating 1600 exchanges across
GPT-3.5 and GPT-4. Using Linguistic Inquiry and Word Count (LIWC) analysis, we
compared the eight agents on language elements including clout, authenticity,
and emotion. Four language cues were significantly distinguishing in GPT-3.5,
while twelve were distinguishing in GPT-4. With thirteen out of a total
nineteen cues in LIWC appearing as significantly distinguishing, our results
suggest possible novel prompting approaches may be needed to better suit the
creation and evaluation of persistent conversational agent personalities or
language styles.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11184" title="Abstract">arXiv:2310.11184</a> [<a href="/pdf/2310.11184" title="Download PDF">pdf</a>, <a href="/format/2310.11184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Multi-Object Render-and-Compare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Langer%2C+F">Florian Langer</a>, 
<a href="/search/cs?searchtype=author&query=Budvytis%2C+I">Ignas Budvytis</a>, 
<a href="/search/cs?searchtype=author&query=Cipolla%2C+R">Roberto Cipolla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing 3D shape and pose of static objects from a single image is an
essential task for various industries, including robotics, augmented reality,
and digital content creation. This can be done by directly predicting 3D shape
in various representations or by retrieving CAD models from a database and
predicting their alignments. Directly predicting 3D shapes often produces
unrealistic, overly smoothed or tessellated shapes. Retrieving CAD models
ensures realistic shapes but requires robust and accurate alignment. Learning
to directly predict CAD model poses from image features is challenging and
inaccurate. Works, such as ROCA, compute poses from predicted normalised object
coordinates which can be more accurate but are susceptible to systematic
failure. SPARC demonstrates that following a ''render-and-compare'' approach
where a network iteratively improves upon its own predictions achieves accurate
alignments. Nevertheless, it performs individual CAD alignment for every object
detected in an image. This approach is slow when applied to many objects as the
time complexity increases linearly with the number of objects and can not learn
inter-object relations. Introducing a new network architecture Multi-SPARC we
learn to perform CAD model alignments for multiple detected objects jointly.
Compared to other single-view methods we achieve state-of-the-art performance
on the challenging real-world dataset ScanNet. By improving the instance
alignment accuracy from 31.8% to 40.3% we perform similar to state-of-the-art
multi-view methods.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11186" title="Abstract">arXiv:2310.11186</a> [<a href="/pdf/2310.11186" title="Download PDF">pdf</a>, <a href="/format/2310.11186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Visualizing Large Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuchen Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Most existing graph visualization methods based on dimension reduction are
limited to relatively small graphs due to performance issues. In this work, we
propose a novel dimension reduction method for graph visualization, called
t-Distributed Stochastic Graph Neighbor Embedding (t-SGNE). t-SGNE is
specifically designed to visualize cluster structures in the graph. As a
variant of the standard t-SNE method, t-SGNE avoids the time-consuming
computations of pairwise similarity. Instead, it uses the neighbor structures
of the graph to reduce the time complexity from quadratic to linear, thus
supporting larger graphs. In addition, to suit t-SGNE, we combined Laplacian
Eigenmaps with the shortest path algorithm in graphs to form the graph
embedding algorithm ShortestPath Laplacian Eigenmaps Embedding (SPLEE).
Performing SPLEE to obtain a high-dimensional embedding of the large-scale
graph and then using t-SGNE to reduce its dimension for visualization, we are
able to visualize graphs with up to 300K nodes and 1M edges within 5 minutes
and achieve approximately 10% improvement in visualization quality. Codes and
data are available at
https://github.com/Charlie-XIAO/embedding-visualization-test.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11187" title="Abstract">arXiv:2310.11187</a> [<a href="/pdf/2310.11187" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Databases for comparative syntactic research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ivani%2C+J+K">Jessica K. Ivani</a>, 
<a href="/search/cs?searchtype=author&query=Bickel%2C+B">Balthasar Bickel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Recent years have witnessed a steep increase in linguistic databases
capturing syntactic variation. We survey and describe 21 publicly available
morpho-syntactic databases, focusing on such properties as data structure, user
interface, documentation, formats, and overall user friendliness. We
demonstrate that all the surveyed databases can be fruitfully categorized along
two dimensions: units of description and the design principle. Units of
description refer to the type of the data the database represents (languages,
constructions, or expressions). The design principles capture the internal
logic of the database. We identify three primary design principles, which vary
in their descriptive power, granularity, and complexity: monocategorization,
multicategorization, and structural decomposition. We describe how these design
principles are implemented in concrete databases and discuss their advantages
and limitations. Finally, we outline essential desiderata for future modern
databases in linguistics.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11188" title="Abstract">arXiv:2310.11188</a> [<a href="/pdf/2310.11188" title="Download PDF">pdf</a>, <a href="/format/2310.11188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Modified EXP3 and Its Adaptive Variant in Adversarial Bandits with  Multi-User Delayed Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yandi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianxiong Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of "A Modified EXP3 in Adversarial Bandits with Multi-User Delayed Feedback" published in COCOON 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">For the adversarial multi-armed bandit problem with delayed feedback, we
consider that the delayed feedback results are from multiple users and are
unrestricted on internal distribution. As the player picks an arm, feedback
from multiple users may not be received instantly yet after an arbitrary delay
of time which is unknown to the player in advance. For different users in a
round, the delays in feedback have no latent correlation. Thus, we formulate an
adversarial multi-armed bandit problem with multi-user delayed feedback and
design a modified EXP3 algorithm named MUD-EXP3, which makes a decision at each
round by considering the importance-weighted estimator of the received feedback
from different users. On the premise of known terminal round index $T$, the
number of users $M$, the number of arms $N$, and upper bound of delay
$d_{max}$, we prove a regret of
$\mathcal{O}(\sqrt{TM^2\ln{N}(N\mathrm{e}+4d_{max})})$. Furthermore, for the
more common case of unknown $T$, an adaptive algorithm named AMUD-EXP3 is
proposed with a sublinear regret with respect to $T$. Finally, extensive
experiments are conducted to indicate the correctness and effectiveness of our
algorithms.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11191" title="Abstract">arXiv:2310.11191</a> [<a href="/pdf/2310.11191" title="Download PDF">pdf</a>, <a href="/format/2310.11191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical Text Simplification: Optimizing for Readability with  Unlikelihood Training and Reranked Beam Search Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flores%2C+L+J+Y">Lorenzo Jaime Yu Flores</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Kejian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chheang%2C+S">Sophie Chheang</a>, 
<a href="/search/cs?searchtype=author&query=Cohan%2C+A">Arman Cohan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text simplification has emerged as an increasingly useful application of AI
for bridging the communication gap in specialized fields such as medicine,
where the lexicon is often dominated by technical jargon and complex
constructs. Despite notable progress, methods in medical simplification
sometimes result in the generated text having lower quality and diversity. In
this work, we explore ways to further improve the readability of text
simplification in the medical domain. We propose (1) a new unlikelihood loss
that encourages generation of simpler terms and (2) a reranked beam search
decoding method that optimizes for simplicity, which achieve better performance
on readability metrics on three datasets. This study's findings offer promising
avenues for improving text simplification in the medical field.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11198" title="Abstract">arXiv:2310.11198</a> [<a href="/pdf/2310.11198" title="Download PDF">pdf</a>, <a href="/format/2310.11198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EEG motor imagery decoding: A framework for comparative analysis with  channel attention mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wimpff%2C+M">Martin Wimpff</a>, 
<a href="/search/cs?searchtype=author&query=Gizzi%2C+L">Leonardo Gizzi</a>, 
<a href="/search/cs?searchtype=author&query=Zerfowski%2C+J">Jan Zerfowski</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures, submitted to: Journal of Neural Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The objective of this study is to investigate the application of various
channel attention mechanisms within the domain of brain-computer interface
(BCI) for motor imagery decoding. Channel attention mechanisms can be seen as a
powerful evolution of spatial filters traditionally used for motor imagery
decoding. This study systematically compares such mechanisms by integrating
them into a lightweight architecture framework to evaluate their impact. We
carefully construct a straightforward and lightweight baseline architecture
designed to seamlessly integrate different channel attention mechanisms. This
approach is contrary to previous works which only investigate one attention
mechanism and usually build a very complex, sometimes nested architecture. Our
framework allows us to evaluate and compare the impact of different attention
mechanisms under the same circumstances. The easy integration of different
channel attention mechanisms as well as the low computational complexity
enables us to conduct a wide range of experiments on three datasets to
thoroughly assess the effectiveness of the baseline model and the attention
mechanisms. Our experiments demonstrate the strength and generalizability of
our architecture framework as well as how channel attention mechanisms can
improve the performance while maintaining the small memory footprint and low
computational complexity of our baseline architecture. Our architecture
emphasizes simplicity, offering easy integration of channel attention
mechanisms, while maintaining a high degree of generalizability across
datasets, making it a versatile and efficient solution for EEG motor imagery
decoding within brain-computer interfaces.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11203" title="Abstract">arXiv:2310.11203</a> [<a href="/pdf/2310.11203" title="Download PDF">pdf</a>, <a href="/format/2310.11203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning with Nonvacuous Generalisation Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jobic%2C+P">Pierre Jobic</a>, 
<a href="/search/cs?searchtype=author&query=Haddouche%2C+M">Maxime Haddouche</a>, 
<a href="/search/cs?searchtype=author&query=Guedj%2C+B">Benjamin Guedj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We introduce a novel strategy to train randomised predictors in federated
learning, where each node of the network aims at preserving its privacy by
releasing a local predictor but keeping secret its training dataset with
respect to the other nodes. We then build a global randomised predictor which
inherits the properties of the local private predictors in the sense of a
PAC-Bayesian generalisation bound. We consider the synchronous case where all
nodes share the same training objective (derived from a generalisation bound),
and the asynchronous case where each node may have its own personalised
training objective. We show through a series of numerical experiments that our
approach achieves a comparable predictive performance to that of the batch
approach where all datasets are shared across nodes. Moreover the predictors
are supported by numerically nonvacuous generalisation bounds while preserving
privacy for each node. We explicitly compute the increment on predictive
performance and generalisation bounds between batch and federated settings,
highlighting the price to pay to preserve privacy.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11204" title="Abstract">arXiv:2310.11204</a> [<a href="/pdf/2310.11204" title="Download PDF">pdf</a>, <a href="/ps/2310.11204" title="Download PostScript">ps</a>, <a href="/format/2310.11204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Video Deepfake Detection: A DCT-Based Approach with  Patch-Level Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guarnera%2C+L">Luca Guarnera</a> (1), 
<a href="/search/cs?searchtype=author&query=Manganello%2C+S">Salvatore Manganello</a> (1), 
<a href="/search/cs?searchtype=author&query=Battiato%2C+S">Sebastiano Battiato</a> (1) ((1) University of Catania)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The term deepfake refers to all those multimedia contents that were
synthetically altered or created from scratch through the use of generative
models. This phenomenon has become widespread due to the use of increasingly
accurate and efficient architectures capable of rendering manipulated content
indistinguishable from real content. In order to fight the illicit use of this
powerful technology, it has become necessary to develop algorithms able to
distinguish synthetic content from real ones. In this study, a new algorithm
for the detection of deepfakes in digital videos is presented, focusing on the
main goal of creating a fast and explainable method from a forensic
perspective. To achieve this goal, the I-frames were extracted in order to
provide faster computation and analysis than approaches described in
literature. In addition, to identify the most discriminating regions within
individual video frames, the entire frame, background, face, eyes, nose, mouth,
and face frame were analyzed separately. From the Discrete Cosine Transform
(DCT), the Beta components were extracted from the AC coefficients and used as
input to standard classifiers (e.g., k-NN, SVM, and others) in order to
identify those frequencies most discriminative for solving the task in
question. Experimental results obtained on the Faceforensics++ and Celeb-DF
(v2) datasets show that the eye and mouth regions are those most discriminative
and able to determine the nature of the video with greater reliability than the
analysis of the whole frame. The method proposed in this study is analytical,
fast and does not require much computational power.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11206" title="Abstract">arXiv:2310.11206</a> [<a href="/pdf/2310.11206" title="Download PDF">pdf</a>, <a href="/format/2310.11206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QoS-aware Scheduling in 5G Wireless Base Stations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasad%2C+R">Reshma Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Sunny%2C+A">Albert Sunny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 28 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">5G and beyond networks are expected to support flows with varied
\emph{Quality-of-Service (QoS)} requirements under unpredictable traffic
conditions. Consequently, designing policies ensuring optimal system
utilization in such networks is challenging. Given this, we formulate a
long-term time-averaged scheduling problem that minimizes a weighted function
of packets dropped by the 5G wireless base station. We then present two
policies for this problem. The first is a delay-guaranteed near-optimal policy,
and the second is a delay-guaranteed sub-optimal policy that provides flow
isolation. We perform extensive simulations to understand the performance of
these policies. Further, we study these policies in the presence of a
closed-loop flow rate-control mechanism.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11207" title="Abstract">arXiv:2310.11207</a> [<a href="/pdf/2310.11207" title="Download PDF">pdf</a>, <a href="/format/2310.11207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Explain Themselves? A Study of LLM-Generated  Self-Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shiyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mamidanna%2C+S">Siddarth Mamidanna</a>, 
<a href="/search/cs?searchtype=author&query=Jangam%2C+S">Shreedhar Jangam</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yilun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gilpin%2C+L+H">Leilani H. Gilpin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) such as ChatGPT have demonstrated superior
performance on a variety of natural language processing (NLP) tasks including
sentiment analysis, mathematical reasoning and summarization. Furthermore,
since these models are instruction-tuned on human conversations to produce
"helpful" responses, they can and often will produce explanations along with
the response, which we call self-explanations. For example, when analyzing the
sentiment of a movie review, the model may output not only the positivity of
the sentiment, but also an explanation (e.g., by listing the sentiment-laden
words such as "fantastic" and "memorable" in the review). How good are these
automatically generated self-explanations? In this paper, we investigate this
question on the task of sentiment analysis and for feature attribution
explanation, one of the most commonly studied settings in the interpretability
literature (for pre-ChatGPT models). Specifically, we study different ways to
elicit the self-explanations, evaluate their faithfulness on a set of
evaluation metrics, and compare them to traditional explanation methods such as
occlusion or LIME saliency maps. Through an extensive set of experiments, we
find that ChatGPT's self-explanations perform on par with traditional ones, but
are quite different from them according to various agreement metrics, meanwhile
being much cheaper to produce (as they are generated along with the
prediction). In addition, we identified several interesting characteristics of
them, which prompt us to rethink many current model interpretability practices
in the era of ChatGPT(-like) LLMs.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11210" title="Abstract">arXiv:2310.11210</a> [<a href="/pdf/2310.11210" title="Download PDF">pdf</a>, <a href="/format/2310.11210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Comprehensive Representations with Richer Self for  Text-to-Image Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuanglin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Neng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinhui Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Text-to-image person re-identification (TIReID) retrieves pedestrian images
of the same identity based on a query text. However, existing methods for
TIReID typically treat it as a one-to-one image-text matching problem, only
focusing on the relationship between image-text pairs within a view. The
many-to-many matching between image-text pairs across views under the same
identity is not taken into account, which is one of the main reasons for the
poor performance of existing methods. To this end, we propose a simple yet
effective framework, called LCR$^2$S, for modeling many-to-many correspondences
of the same identity by learning comprehensive representations for both
modalities from a novel perspective. We construct a support set for each image
(text) by using other images (texts) under the same identity and design a
multi-head attentional fusion module to fuse the image (text) and its support
set. The resulting enriched image and text features fuse information from
multiple views, which are aligned to train a "richer" TIReID model with
many-to-many correspondences. Since the support set is unavailable during
inference, we propose to distill the knowledge learned by the "richer" model
into a lightweight model for inference with a single image/text as input. The
lightweight model focuses on semantic association and reasoning of multi-view
information, which can generate a comprehensive representation containing
multi-view information with only a single-view input to perform accurate
text-to-image retrieval during inference. In particular, we use the intra-modal
features and inter-modal semantic relations of the "richer" model to supervise
the lightweight model to inherit its powerful capability. Extensive experiments
demonstrate the effectiveness of LCR$^2$S, and it also achieves new
state-of-the-art performance on three popular TIReID datasets.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11211" title="Abstract">arXiv:2310.11211</a> [<a href="/pdf/2310.11211" title="Download PDF">pdf</a>, <a href="/format/2310.11211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Fairness Surrogate Functions in Algorithmic Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanke Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhicong Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">It has been observed that machine learning algorithms exhibit biased
predictions against certain population groups. To mitigate such bias while
achieving comparable accuracy, a promising approach is to introduce surrogate
functions of the concerned fairness definition and solve a constrained
optimization problem. However, an intriguing issue in previous work is that
such fairness surrogate functions may yield unfair results. In this work, in
order to deeply understand this issue, taking a widely used fairness
definition, demographic parity as an example, we both theoretically and
empirically show that there is a surrogate-fairness gap between the fairness
definition and the fairness surrogate function. The "gap" directly determines
whether a surrogate function is an appropriate substitute for a fairness
definition. Also, the theoretical analysis and experimental results about the
"gap" motivate us that the unbounded surrogate functions will be affected by
the points far from the decision boundary, which is the large margin points
issue investigated in this paper. To address it, we propose the general sigmoid
surrogate with a rigorous and reliable fairness guarantee. Interestingly, the
theory also provides insights into two important issues that deal with the
large margin points as well as obtaining a more balanced dataset are beneficial
to fairness. Furthermore, we elaborate a novel and general algorithm called
Balanced Surrogate, which iteratively reduces the "gap" to improve fairness.
Finally, we provide empirical evidence showing that our methods achieve better
fairness performance in three real-world datasets.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11217" title="Abstract">arXiv:2310.11217</a> [<a href="/pdf/2310.11217" title="Download PDF">pdf</a>, <a href="/ps/2310.11217" title="Download PostScript">ps</a>, <a href="/format/2310.11217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innovative Methods for Non-Destructive Inspection of Handwritten  Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breci%2C+E">Eleonora Breci</a> (1), 
<a href="/search/cs?searchtype=author&query=Guarnera%2C+L">Luca Guarnera</a> (1), 
<a href="/search/cs?searchtype=author&query=Battiato%2C+S">Sebastiano Battiato</a> (1) ((1) University of Catania)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Handwritten document analysis is an area of forensic science, with the goal
of establishing authorship of documents through examination of inherent
characteristics. Law enforcement agencies use standard protocols based on
manual processing of handwritten documents. This method is time-consuming, is
often subjective in its evaluation, and is not replicable. To overcome these
limitations, in this paper we present a framework capable of extracting and
analyzing intrinsic measures of manuscript documents related to text line
heights, space between words, and character sizes using image processing and
deep learning techniques. The final feature vector for each document involved
consists of the mean and standard deviation for every type of measure
collected. By quantifying the Euclidean distance between the feature vectors of
the documents to be compared, authorship can be discerned. We also proposed a
new and challenging dataset consisting of 362 handwritten manuscripts written
on paper and digital devices by 124 different people. Our study pioneered the
comparison between traditionally handwritten documents and those produced with
digital tools (e.g., tablets). Experimental results demonstrate the ability of
our method to objectively determine authorship in different writing media,
outperforming the state of the art.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11220" title="Abstract">arXiv:2310.11220</a> [<a href="/pdf/2310.11220" title="Download PDF">pdf</a>, <a href="/format/2310.11220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+Y">Yeonsu Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+Y">Yohan Jo</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Edward Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While large language models (LLMs) have made considerable advancements in
understanding and generating unstructured text, their application in structured
data remains underexplored. Particularly, using LLMs for complex reasoning
tasks on knowledge graphs (KGs) remains largely untouched. To address this, we
propose KG-GPT, a multi-purpose framework leveraging LLMs for tasks employing
KGs. KG-GPT comprises three steps: Sentence Segmentation, Graph Retrieval, and
Inference, each aimed at partitioning sentences, retrieving relevant graph
components, and deriving logical conclusions, respectively. We evaluate KG-GPT
using KG-based fact verification and KGQA benchmarks, with the model showing
competitive and robust performance, even outperforming several fully-supervised
models. Our work, therefore, marks a significant step in unifying structured
and unstructured data processing within the realm of LLMs.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11222" title="Abstract">arXiv:2310.11222</a> [<a href="/pdf/2310.11222" title="Download PDF">pdf</a>, <a href="/format/2310.11222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Node Vector Distance Computations using Laplacian Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coscia%2C+M">Michele Coscia</a>, 
<a href="/search/cs?searchtype=author&query=Devriendt%2C+K">Karel Devriendt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Complex networks are a useful tool to investigate various phenomena in social
science, economics, and logistics. Node Vector Distance (NVD) is an emerging
set of techniques allowing us to estimate the distance and correlation between
variables defined on the nodes of a network. One drawback of NVD is its high
computational complexity. Here we show that a subset of NVD techniques, the
ones calculating the Generalized Euclidean measure on networks, can be
efficiently tackled with Laplacian solvers. In experiments, we show that this
provides a significant runtime speedup with negligible approximation errors,
which opens the possibility to scale the techniques to large networks.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11225" title="Abstract">arXiv:2310.11225</a> [<a href="/pdf/2310.11225" title="Download PDF">pdf</a>, <a href="/ps/2310.11225" title="Download PostScript">ps</a>, <a href="/format/2310.11225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse grid approximation of the stochastic Landau-Lifshitz-Gilbert  equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=An%2C+X">Xin An</a>, 
<a href="/search/math?searchtype=author&query=Dick%2C+J">Josef Dick</a>, 
<a href="/search/math?searchtype=author&query=Feischl%2C+M">Michael Feischl</a>, 
<a href="/search/math?searchtype=author&query=Scaglioni%2C+A">Andrea Scaglioni</a>, 
<a href="/search/math?searchtype=author&query=Tran%2C+T">Thanh Tran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We show convergence rates for a sparse grid approximation of the distribution
of solutions of the stochastic Landau-Lifshitz-Gilbert equation. Beyond being a
frequently studied equation in engineering and physics, the stochastic
Landau-Lifshitz-Gilbert equation poses many interesting challenges that do not
appear simultaneously in previous works on uncertainty quantification: The
equation is strongly nonlinear, time-dependent, and has a non-convex side
constraint. Moreover, the parametrization of the stochastic noise features
countably many unbounded parameters and low regularity compared to other
elliptic and parabolic problems studied in uncertainty quantification. We use a
novel technique to establish uniform holomorphic regularity of the
parameter-to-solution map based on a Gronwall-type estimate combined with
previously known methods that use the implicit function theorem. We demonstrate
numerically the feasibility of the stochastic collocation method and show a
clear advantage of a multi-level stochastic collocation scheme for the
stochastic Landau-Lifshitz-Gilbert equation.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11227" title="Abstract">arXiv:2310.11227</a> [<a href="/pdf/2310.11227" title="Download PDF">pdf</a>, <a href="/format/2310.11227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RealBehavior: A Framework for Faithfully Characterizing Foundation  Models&#x27; Human-like Behavior Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zhiheng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Songyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zichu Fei</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jingting Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reports of human-like behaviors in foundation models are growing, with
psychological theories providing enduring tools to investigate these behaviors.
However, current research tends to directly apply these human-oriented tools
without verifying the faithfulness of their outcomes. In this paper, we
introduce a framework, RealBehavior, which is designed to characterize the
humanoid behaviors of models faithfully. Beyond simply measuring behaviors, our
framework assesses the faithfulness of results based on reproducibility,
internal and external consistency, and generalizability. Our findings suggest
that a simple application of psychological tools cannot faithfully characterize
all human-like behaviors. Moreover, we discuss the impacts of aligning models
with human and social values, arguing for the necessity of diversifying
alignment objectives to prevent the creation of models with restricted
characteristics.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11232" title="Abstract">arXiv:2310.11232</a> [<a href="/pdf/2310.11232" title="Download PDF">pdf</a>, <a href="/ps/2310.11232" title="Download PostScript">ps</a>, <a href="/format/2310.11232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Sample Better
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albergo%2C+M+S">Michael S. Albergo</a>, 
<a href="/search/cs?searchtype=author&query=Vanden-Eijnden%2C+E">Eric Vanden-Eijnden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Les Houches 2022 Summer School on Statistical Physics and Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">These lecture notes provide an introduction to recent advances in generative
modeling methods based on the dynamical transportation of measures, by means of
which samples from a simple base measure are mapped to samples from a target
measure of interest. Special emphasis is put on the applications of these
methods to Monte-Carlo (MC) sampling techniques, such as importance sampling
and Markov Chain Monte-Carlo (MCMC) schemes. In this context, it is shown how
the maps can be learned variationally using data generated by MC sampling, and
how they can in turn be used to improve such sampling in a positive feedback
loop.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11234" title="Abstract">arXiv:2310.11234</a> [<a href="/pdf/2310.11234" title="Download PDF">pdf</a>, <a href="/format/2310.11234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imaging of nonlinear materials via the Monotonicity Principle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mottola%2C+V">Vincenzo Mottola</a>, 
<a href="/search/math?searchtype=author&query=Esposito%2C+A+C">Antonio Corbo Esposito</a>, 
<a href="/search/math?searchtype=author&query=Piscitelli%2C+G">Gianpaolo Piscitelli</a>, 
<a href="/search/math?searchtype=author&query=Tamburrino%2C+A">Antonello Tamburrino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The topic of inverse problems, related to Maxwell's equations, in the
presence of nonlinear materials is quite new in literature. The lack of
contributions in this area can be ascribed to the significant challenges that
such problems pose. Retrieving the spatial behaviour of some unknown physical
property, starting from boundary measurements, is a nonlinear and highly
ill-posed problem even in the presence of linear materials. And the complexity
exponentially grows when the focus is on nonlinear material properties.
Recently, the Monotonicity Principle has been extended to nonlinear materials
under very general assumptions. Starting from the theoretical background given
by this extension, we develop a first real-time inversion method for the
inverse obstacle problem in the presence of nonlinear materials. The
Monotonicity Principle is the foundation of a class of non-iterative algorithms
for tomography of linear materials. It has been successfully applied to various
problems, governed by different PDEs. In the linear case, MP based inversion
methods ensure excellent performances and compatibility with real-time
applications. We focus on problems governed by elliptical PDEs and, as an
example of application, we treat the Magnetostatic Permeability Tomography
problem, in which the aim is to retrieve the spatial behaviour of magnetic
permeability through boundary measurements in DC operations. In this paper, we
provide some preliminary results giving the foundation of our method and
extended numerical examples.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11237" title="Abstract">arXiv:2310.11237</a> [<a href="/pdf/2310.11237" title="Download PDF">pdf</a>, <a href="/format/2310.11237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Watermarking LLMs with Weight Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Botian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Ke Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Findings of EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Abuse of large language models reveals high risks as large language models
are being deployed at an astonishing speed. It is important to protect the
model weights to avoid malicious usage that violates licenses of open-source
large language models. This paper proposes a novel watermarking strategy that
plants watermarks in the quantization process of large language models without
pre-defined triggers during inference. The watermark works when the model is
used in the fp32 mode and remains hidden when the model is quantized to int8,
in this way, the users can only inference the model without further supervised
fine-tuning of the model. We successfully plant the watermark into open-source
large language model weights including GPT-Neo and LLaMA. We hope our proposed
method can provide a potential direction for protecting model weights in the
era of large language model applications.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11239" title="Abstract">arXiv:2310.11239</a> [<a href="/pdf/2310.11239" title="Download PDF">pdf</a>, <a href="/format/2310.11239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR-based 4D Occupancy Completion and Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Moonjun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Q">Qi Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Scene completion and forecasting are two popular perception problems in
research for mobile agents like autonomous vehicles. Existing approaches treat
the two problems in isolation, resulting in a separate perception of the two
aspects. In this paper, we introduce a novel LiDAR perception task of Occupancy
Completion and Forecasting (OCF) in the context of autonomous driving to unify
these aspects into a cohesive framework. This task requires new algorithms to
address three challenges altogether: (1) sparse-to-dense reconstruction, (2)
partial-to-complete hallucination, and (3) 3D-to-4D prediction. To enable
supervision and evaluation, we curate a large-scale dataset termed OCFBench
from public autonomous driving datasets. We analyze the performance of closely
related existing baseline models and our own ones on our dataset. We envision
that this research will inspire and call for further investigation in this
evolving and crucial area of 4D perception. Our code for data curation and
baseline implementation is available at https://github.com/ai4ce/Occ4cast.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11241" title="Abstract">arXiv:2310.11241</a> [<a href="/pdf/2310.11241" title="Download PDF">pdf</a>, <a href="/format/2310.11241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Humanising robot-assisted navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Falqueto%2C+P">Placido Falqueto</a>, 
<a href="/search/cs?searchtype=author&query=Antonucci%2C+A">Alessandro Antonucci</a>, 
<a href="/search/cs?searchtype=author&query=Palopoli%2C+L">Luigi Palopoli</a>, 
<a href="/search/cs?searchtype=author&query=Fontanelli%2C+D">Daniele Fontanelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures. To be published in Intelligent Service Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robot-assisted navigation is a perfect example of a class of applications
requiring flexible control approaches. When the human is reliable, the robot
should concede space to their initiative. When the human makes inappropriate
choices the robot controller should kick-in guiding them towards safer paths.
Shared authority control is a way to achieve this behaviour by deciding online
how much of the authority should be given to the human and how much should be
retained by the robot. An open problem is how to evaluate the appropriateness
of the human's choices. One possible way is to consider the deviation from an
ideal path computed by the robot. This choice is certainly safe and efficient,
but it emphasises the importance of the robot's decision and relegates the
human to a secondary role. In this paper, we propose a different paradigm: a
human's behaviour is correct if, at every time, it bears a close resemblance to
what other humans do in similar situations. This idea is implemented through
the combination of machine learning and adaptive control. The map of the
environment is decomposed into a grid. In each cell, we classify the possible
motions that the human executes. We use a neural network classifier to classify
the current motion, and the probability score is used as a hyperparameter in
the control to vary the amount of intervention. The experiments collected for
the paper show the feasibility of the idea. A qualitative evaluation, done by
surveying the users after they have tested the robot, shows that the
participants preferred our control method over a state-of-the-art visco-elastic
control.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11244" title="Abstract">arXiv:2310.11244</a> [<a href="/pdf/2310.11244" title="Download PDF">pdf</a>, <a href="/format/2310.11244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entity Matching using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peeters%2C+R">Ralph Peeters</a>, 
<a href="/search/cs?searchtype=author&query=Bizer%2C+C">Christian Bizer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Entity Matching is the task of deciding whether two entity descriptions refer
to the same real-world entity. Entity Matching is a central step in most data
integration pipelines and an enabler for many e-commerce applications which
require to match products offers from different vendors. State-of-the-art
entity matching methods often rely on pre-trained language models (PLMs) such
as BERT or RoBERTa. Two major drawbacks of these models for entity matching are
that (i) the models require significant amounts of task-specific training data
and (ii) the fine-tuned models are not robust concerning out-of-distribution
entities. In this paper, we investigate using large language models (LLMs) for
entity matching as a less domain-specific training data reliant and more robust
alternative to PLM-based matchers. Our study covers hosted LLMs, such as GPT3.5
and GPT4, as well as open source LLMs based on Llama2 which can be run locally.
We evaluate these models in a zero-shot scenario as well as a scenario where
task-specific training data is available. We compare different prompt designs
as well as the prompt sensitivity of the models in the zero-shot scenario. We
investigate (i) the selection of in-context demonstrations, (ii) the generation
of matching rules, as well as (iii) fine-tuning GPT3.5 in the second scenario
using the same pool of training data across the different approaches. Our
experiments show that GPT4 without any task-specific training data outperforms
fine-tuned PLMs (RoBERTa and Ditto) on three out of five benchmark datasets
reaching F1 scores around 90%. The experiments with in-context learning and
rule generation show that all models beside of GPT4 benefit from these
techniques (on average 5.9% and 2.2% F1), while GPT4 does not need such
additional guidance in most cases...
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11246" title="Abstract">arXiv:2310.11246</a> [<a href="/pdf/2310.11246" title="Download PDF">pdf</a>, <a href="/format/2310.11246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query2Triple: Unified Query Encoding for Answering Diverse Complex  Queries over Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yao Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shizhu He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cunguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Li Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Complex Query Answering (CQA) is a challenge task of Knowledge Graph (KG).
Due to the incompleteness of KGs, query embedding (QE) methods have been
proposed to encode queries and entities into the same embedding space, and
treat logical operators as neural set operators to obtain answers. However,
these methods train KG embeddings and neural set operators concurrently on both
simple (one-hop) and complex (multi-hop and logical) queries, which causes
performance degradation on simple queries and low training efficiency. In this
paper, we propose Query to Triple (Q2T), a novel approach that decouples the
training for simple and complex queries. Q2T divides the training into two
stages: (1) Pre-training a neural link predictor on simple queries to predict
tail entities based on the head entity and relation. (2) Training a query
encoder on complex queries to encode diverse complex queries into a unified
triple form that can be efficiently solved by the pretrained neural link
predictor. Our proposed Q2T is not only efficient to train, but also modular,
thus easily adaptable to various neural link predictors that have been studied
well. Extensive experiments demonstrate that, even without explicit modeling
for neural set operators, Q2T still achieves state-of-the-art performance on
diverse complex queries over three public benchmarks.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11248" title="Abstract">arXiv:2310.11248</a> [<a href="/pdf/2310.11248" title="Download PDF">pdf</a>, <a href="/format/2310.11248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yangruibo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zijian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+W+U">Wasi Uddin Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hantian Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Ming Tan</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+N">Nihal Jain</a>, 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+M+K">Murali Krishna Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Nallapati%2C+R">Ramesh Nallapati</a>, 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+P">Parminder Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+D">Dan Roth</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+B">Bing Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at NeurIPS 2023 (Datasets and Benchmarks Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Code completion models have made significant progress in recent years, yet
current popular evaluation datasets, such as HumanEval and MBPP, predominantly
focus on code completion tasks within a single file. This over-simplified
setting falls short of representing the real-world software development
scenario where repositories span multiple files with numerous cross-file
dependencies, and accessing and understanding cross-file context is often
required to complete the code correctly.
<br />To fill in this gap, we propose CrossCodeEval, a diverse and multilingual
code completion benchmark that necessitates an in-depth cross-file contextual
understanding to complete the code accurately. CrossCodeEval is built on a
diverse set of real-world, open-sourced, permissively-licensed repositories in
four popular programming languages: Python, Java, TypeScript, and C#. To create
examples that strictly require cross-file context for accurate completion, we
propose a straightforward yet efficient static-analysis-based approach to
pinpoint the use of cross-file context within the current file.
<br />Extensive experiments on state-of-the-art code language models like CodeGen
and StarCoder demonstrate that CrossCodeEval is extremely challenging when the
relevant cross-file context is absent, and we see clear improvements when
adding these context into the prompt. However, despite such improvements, the
pinnacle of performance remains notably unattained even with the
highest-performing model, indicating that CrossCodeEval is also capable of
assessing model's capability in leveraging extensive context to make better
code completion. Finally, we benchmarked various methods in retrieving
cross-file context, and show that CrossCodeEval can also be used to measure the
capability of code retrievers.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11249" title="Abstract">arXiv:2310.11249</a> [<a href="/pdf/2310.11249" title="Download PDF">pdf</a>, <a href="/format/2310.11249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Model for Automatic Evolving of Industrial  Data-Centric R&amp;D Cycle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P">Peng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zeqi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; General Finance (q-fin.GN)

</div>
<p class="mathjax">In the wake of relentless digital transformation, data-driven solutions are
emerging as powerful tools to address multifarious industrial tasks such as
forecasting, anomaly detection, planning, and even complex decision-making.
Although data-centric R&amp;D has been pivotal in harnessing these solutions, it
often comes with significant costs in terms of human, computational, and time
resources. This paper delves into the potential of large language models (LLMs)
to expedite the evolution cycle of data-centric R&amp;D. Assessing the foundational
elements of data-centric R&amp;D, including heterogeneous task-related data,
multi-facet domain knowledge, and diverse computing-functional tools, we
explore how well LLMs can understand domain-specific requirements, generate
professional ideas, utilize domain-specific tools to conduct experiments,
interpret results, and incorporate knowledge from past endeavors to tackle new
challenges. We take quantitative investment research as a typical example of
industrial data-centric R&amp;D scenario and verified our proposed framework upon
our full-stack open-sourced quantitative research platform Qlib and obtained
promising results which shed light on our vision of automatic evolving of
industrial data-centric R&amp;D cycle.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11252" title="Abstract">arXiv:2310.11252</a> [<a href="/pdf/2310.11252" title="Download PDF">pdf</a>, <a href="/format/2310.11252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing the Unwritten: Visual Investigation of Beam Search Trees to  Address Language Model Prompting Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spinner%2C+T">Thilo Spinner</a>, 
<a href="/search/cs?searchtype=author&query=Kehlbeck%2C+R">Rebecca Kehlbeck</a>, 
<a href="/search/cs?searchtype=author&query=Sevastjanova%2C+R">Rita Sevastjanova</a>, 
<a href="/search/cs?searchtype=author&query=St%C3%A4hle%2C+T">Tobias St&#xe4;hle</a>, 
<a href="/search/cs?searchtype=author&query=Keim%2C+D+A">Daniel A. Keim</a>, 
<a href="/search/cs?searchtype=author&query=Deussen%2C+O">Oliver Deussen</a>, 
<a href="/search/cs?searchtype=author&query=Spitz%2C+A">Andreas Spitz</a>, 
<a href="/search/cs?searchtype=author&query=El-Assady%2C+M">Mennatallah El-Assady</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages paper, 2 pages references, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The growing popularity of generative language models has amplified interest
in interactive methods to guide model outputs. Prompt refinement is considered
one of the most effective means to influence output among these methods. We
identify several challenges associated with prompting large language models,
categorized into data- and model-specific, linguistic, and socio-linguistic
challenges. A comprehensive examination of model outputs, including runner-up
candidates and their corresponding probabilities, is needed to address these
issues. The beam search tree, the prevalent algorithm to sample model outputs,
can inherently supply this information. Consequently, we introduce an
interactive visual method for investigating the beam search tree, facilitating
analysis of the decisions made by the model during generation. We
quantitatively show the value of exposing the beam search tree and present five
detailed analysis scenarios addressing the identified challenges. Our
methodology validates existing results and offers additional insights.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11257" title="Abstract">arXiv:2310.11257</a> [<a href="/pdf/2310.11257" title="Download PDF">pdf</a>, <a href="/format/2310.11257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An empirical study of automatic wildlife detection using drone thermal  imaging and object detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Miao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+T">Tan Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Palaparthi%2C+M">Manas Palaparthi</a>, 
<a href="/search/cs?searchtype=author&query=Howell%2C+L">Lachlan Howell</a>, 
<a href="/search/cs?searchtype=author&query=Bonti%2C+A">Alessio Bonti</a>, 
<a href="/search/cs?searchtype=author&query=Abdelrazek%2C+M">Mohamed Abdelrazek</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+T">Duc Thanh Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Robotics (cs.RO)

</div>
<p class="mathjax">Artificial intelligence has the potential to make valuable contributions to
wildlife management through cost-effective methods for the collection and
interpretation of wildlife data. Recent advances in remotely piloted aircraft
systems (RPAS or ``drones'') and thermal imaging technology have created new
approaches to collect wildlife data. These emerging technologies could provide
promising alternatives to standard labourious field techniques as well as cover
much larger areas. In this study, we conduct a comprehensive review and
empirical study of drone-based wildlife detection. Specifically, we collect a
realistic dataset of drone-derived wildlife thermal detections. Wildlife
detections, including arboreal (for instance, koalas, phascolarctos cinereus)
and ground dwelling species in our collected data are annotated via bounding
boxes by experts. We then benchmark state-of-the-art object detection
algorithms on our collected dataset. We use these experimental results to
identify issues and discuss future directions in automatic animal monitoring
using drones.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11258" title="Abstract">arXiv:2310.11258</a> [<a href="/pdf/2310.11258" title="Download PDF">pdf</a>, <a href="/format/2310.11258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Weak Supervision To Generate Indonesian Conservation Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fransiska%2C+M">Mega Fransiska</a>, 
<a href="/search/cs?searchtype=author&query=Pitaloka%2C+D">Diah Pitaloka</a>, 
<a href="/search/cs?searchtype=author&query=Saripudin">Saripudin</a>, 
<a href="/search/cs?searchtype=author&query=Putra%2C+S">Satrio Putra</a>, 
<a href="/search/cs?searchtype=author&query=Sutawika%2C+L">Lintang Sutawika</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Weak supervision has emerged as a promising approach for rapid and
large-scale dataset creation in response to the increasing demand for
accelerated NLP development. By leveraging labeling functions, weak supervision
allows practitioners to generate datasets quickly by creating learned label
models that produce soft-labeled datasets. This paper aims to show how such an
approach can be utilized to build an Indonesian NLP dataset from conservation
news text. We construct two types of datasets: multi-class classification and
sentiment classification. We then provide baseline experiments using various
pretrained language models. These baseline results demonstrate test
performances of 59.79% accuracy and 55.72% F1-score for sentiment
classification, 66.87% F1-score-macro, 71.5% F1-score-micro, and 83.67% ROC-AUC
for multi-class classification. Additionally, we release the datasets and
labeling functions used in this work for further research and exploration.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11266" title="Abstract">arXiv:2310.11266</a> [<a href="/pdf/2310.11266" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emulating Human Cognitive Processes for Expert-Level Medical  Question-Answering with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+K">Khushboo Verma</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+M">Marina Moore</a>, 
<a href="/search/cs?searchtype=author&query=Wottrich%2C+S">Stephanie Wottrich</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+K+R">Karla Robles L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+N">Nishant Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+Z">Zeel Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Aagamjit Singh</a>, 
<a href="/search/cs?searchtype=author&query=Unroe%2C+B">Bradford Unroe</a>, 
<a href="/search/cs?searchtype=author&query=Basheer%2C+S">Salah Basheer</a>, 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+N">Nitish Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+P">Prinka Arora</a>, 
<a href="/search/cs?searchtype=author&query=Kaur%2C+H">Harmanjeet Kaur</a>, 
<a href="/search/cs?searchtype=author&query=Kaur%2C+T">Tanupreet Kaur</a>, 
<a href="/search/cs?searchtype=author&query=Hood%2C+T">Tevon Hood</a>, 
<a href="/search/cs?searchtype=author&query=Marquez%2C+A">Anahi Marquez</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+T">Tushar Varshney</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+N">Nanfu Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ramani%2C+A">Azaan Ramani</a>, 
<a href="/search/cs?searchtype=author&query=Ishwara%2C+P">Pawanraj Ishwara</a>, 
<a href="/search/cs?searchtype=author&query=Saeed%2C+M">Maimoona Saeed</a>, 
<a href="/search/cs?searchtype=author&query=Pe%C3%B1a%2C+T+L+V">Tatiana L&#xf3;pez Velarde Pe&#xf1;a</a>, 
<a href="/search/cs?searchtype=author&query=Barksdale%2C+B">Bryan Barksdale</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+S">Sushovan Guha</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Satwant Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In response to the pressing need for advanced clinical problem-solving tools
in healthcare, we introduce BooksMed, a novel framework based on a Large
Language Model (LLM). BooksMed uniquely emulates human cognitive processes to
deliver evidence-based and reliable responses, utilizing the GRADE (Grading of
Recommendations, Assessment, Development, and Evaluations) framework to
effectively quantify evidence strength. For clinical decision-making to be
appropriately assessed, an evaluation metric that is clinically aligned and
validated is required. As a solution, we present ExpertMedQA, a multispecialty
clinical benchmark comprised of open-ended, expert-level clinical questions,
and validated by a diverse group of medical professionals. By demanding an
in-depth understanding and critical appraisal of up-to-date clinical
literature, ExpertMedQA rigorously evaluates LLM performance. BooksMed
outperforms existing state-of-the-art models Med-PaLM 2, Almanac, and ChatGPT
in a variety of medical scenarios. Therefore, a framework that mimics human
cognitive stages could be a useful tool for providing reliable and
evidence-based responses to clinical inquiries.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11270" title="Abstract">arXiv:2310.11270</a> [<a href="/pdf/2310.11270" title="Download PDF">pdf</a>, <a href="/format/2310.11270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks for Recommendation: Reproducibility, Graph  Topology, and Node Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malitesta%2C+D">Daniele Malitesta</a>, 
<a href="/search/cs?searchtype=author&query=Pomo%2C+C">Claudio Pomo</a>, 
<a href="/search/cs?searchtype=author&query=Di+Noia%2C+T">Tommaso Di Noia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Graph neural networks (GNNs) have gained prominence in recommendation systems
in recent years. By representing the user-item matrix as a bipartite and
undirected graph, GNNs have demonstrated their potential to capture short- and
long-distance user-item interactions, thereby learning more accurate preference
patterns than traditional recommendation approaches. In contrast to previous
tutorials on the same topic, this tutorial aims to present and examine three
key aspects that characterize GNNs for recommendation: (i) the reproducibility
of state-of-the-art approaches, (ii) the potential impact of graph topological
characteristics on the performance of these models, and (iii) strategies for
learning node representations when training features from scratch or utilizing
pre-trained embeddings as additional item information (e.g., multimodal
features). The goal is to provide three novel theoretical and practical
perspectives on the field, currently subject to debate in graph learning but
long been overlooked in the context of recommendation systems.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11271" title="Abstract">arXiv:2310.11271</a> [<a href="/pdf/2310.11271" title="Download PDF">pdf</a>, <a href="/format/2310.11271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error analysis for hybrid finite element/neural network discretizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kapustsin%2C+U">Uladzislau Kapustsin</a>, 
<a href="/search/math?searchtype=author&query=Kaya%2C+U">Utku Kaya</a>, 
<a href="/search/math?searchtype=author&query=Richter%2C+T">Thomas Richter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We describe and analyze a hybrid finite element/neural network method for
predicting solutions of partial differential equations. The methodology is
designed for obtaining fine scale fluctuations from neural networks in a local
manner. The network is capable of locally correcting a coarse finite element
solution towards a fine solution taking the source term and the coarse
approximation as input. Key observation is the dependency between quality of
predictions and the size of training set which consists of different source
terms and corresponding fine &amp; coarse solutions. We provide the a priori error
analysis of the method together with the stability analysis of the neural
network. The numerical experiments confirm the capability of the network
predicting fine finite element solutions. We also illustrate the generalization
of the method to problems where test and training domains differ from each
other.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11275" title="Abstract">arXiv:2310.11275</a> [<a href="/pdf/2310.11275" title="Download PDF">pdf</a>, <a href="/format/2310.11275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xMEN: A Modular Toolkit for Cross-Lingual Medical Entity Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borchert%2C+F">Florian Borchert</a>, 
<a href="/search/cs?searchtype=author&query=Llorca%2C+I">Ignacio Llorca</a>, 
<a href="/search/cs?searchtype=author&query=Roller%2C+R">Roland Roller</a>, 
<a href="/search/cs?searchtype=author&query=Arnrich%2C+B">Bert Arnrich</a>, 
<a href="/search/cs?searchtype=author&query=Schapranow%2C+M">Matthieu-P. Schapranow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Objective: To improve performance of medical entity normalization across many
languages, especially when fewer language resources are available compared to
English.
<br />Materials and Methods: We introduce xMEN, a modular system for cross-lingual
medical entity normalization, which performs well in both low- and
high-resource scenarios. When synonyms in the target language are scarce for a
given terminology, we leverage English aliases via cross-lingual candidate
generation. For candidate ranking, we incorporate a trainable cross-encoder
model if annotations for the target task are available. We also evaluate
cross-encoders trained in a weakly supervised manner based on
machine-translated datasets from a high resource domain. Our system is publicly
available as an extensible Python toolkit.
<br />Results: xMEN improves the state-of-the-art performance across a wide range
of multilingual benchmark datasets. Weakly supervised cross-encoders are
effective when no training data is available for the target task. Through the
compatibility of xMEN with the BigBIO framework, it can be easily used with
existing and prospective datasets.
<br />Discussion: Our experiments show the importance of balancing the output of
general-purpose candidate generators with subsequent trainable re-rankers,
which we achieve through a rank regularization term in the loss function of the
cross-encoder. However, error analysis reveals that multi-word expressions and
other complex entities are still challenging.
<br />Conclusion: xMEN exhibits strong performance for medical entity normalization
in multiple languages, even when no labeled data and few terminology aliases
for the target language are available. Its configuration system and evaluation
modules enable reproducible benchmarks. Models and code are available online at
the following URL: https://github.com/hpi-dhc/xmen
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11281" title="Abstract">arXiv:2310.11281</a> [<a href="/pdf/2310.11281" title="Download PDF">pdf</a>, <a href="/format/2310.11281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervision meets kernel graph neural models: From architecture to  augmentations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dan%2C+J">Jiawang Dan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruofan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baokun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Changhua Meng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tengfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ningtao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xing Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph representation learning has now become the de facto standard when
handling graph-structured data, with the framework of message-passing graph
neural networks (MPNN) being the most prevailing algorithmic tool. Despite its
popularity, the family of MPNNs suffers from several drawbacks such as
transparency and expressivity. Recently, the idea of designing neural models on
graphs using the theory of graph kernels has emerged as a more transparent as
well as sometimes more expressive alternative to MPNNs known as kernel graph
neural networks (KGNNs). Developments on KGNNs are currently a nascent field of
research, leaving several challenges from algorithmic design and adaptation to
other learning paradigms such as self-supervised learning. In this paper, we
improve the design and learning of KGNNs. Firstly, we extend the algorithmic
formulation of KGNNs by allowing a more flexible graph-level similarity
definition that encompasses former proposals like random walk graph kernel, as
well as providing a smoother optimization objective that alleviates the need of
introducing combinatorial learning procedures. Secondly, we enhance KGNNs
through the lens of self-supervision via developing a novel
structure-preserving graph data augmentation method called latent graph
augmentation (LGA). Finally, we perform extensive empirical evaluations to
demonstrate the efficacy of our proposed mechanisms. Experimental results over
benchmark datasets suggest that our proposed model achieves competitive
performance that is comparable to or sometimes outperforming state-of-the-art
graph representation learning frameworks with or without self-supervision on
graph classification tasks. Comparisons against other previously established
graph data augmentation methods verify that the proposed LGA augmentation
scheme captures better semantics of graph-level invariance.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11282" title="Abstract">arXiv:2310.11282</a> [<a href="/pdf/2310.11282" title="Download PDF">pdf</a>, <a href="/format/2310.11282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChapGTP, ILLC&#x27;s Attempt at Raising a BabyLM: Improving Data Efficiency  by Automatic Task Formation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jumelet%2C+J">Jaap Jumelet</a>, 
<a href="/search/cs?searchtype=author&query=Hanna%2C+M">Michael Hanna</a>, 
<a href="/search/cs?searchtype=author&query=de+Heer+Kloots%2C+M">Marianne de Heer Kloots</a>, 
<a href="/search/cs?searchtype=author&query=Langedijk%2C+A">Anna Langedijk</a>, 
<a href="/search/cs?searchtype=author&query=Pouw%2C+C">Charlotte Pouw</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Wal%2C+O">Oskar van der Wal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Part of the BabyLM challenge at CoNLL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present the submission of the ILLC at the University of Amsterdam to the
BabyLM challenge (Warstadt et al., 2023), in the strict-small track. Our final
model, ChapGTP, is a masked language model that was trained for 200 epochs,
aided by a novel data augmentation technique called Automatic Task Formation.
We discuss in detail the performance of this model on the three evaluation
suites: BLiMP, (Super)GLUE, and MSGS. Furthermore, we present a wide range of
methods that were ultimately not included in the model, but may serve as
inspiration for training LMs in low-resource settings.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11283" title="Abstract">arXiv:2310.11283</a> [<a href="/pdf/2310.11283" title="Download PDF">pdf</a>, <a href="/format/2310.11283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separator Theorem and Algorithms for Planar Hyperbolic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kisfaludi-Bak%2C+S">S&#xe1;ndor Kisfaludi-Bak</a>, 
<a href="/search/cs?searchtype=author&query=Masa%C5%99%C3%ADkov%C3%A1%2C+J">Jana Masa&#x159;&#xed;kov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=van+Leeuwen%2C+E+J">Erik Jan van Leeuwen</a>, 
<a href="/search/cs?searchtype=author&query=Walczak%2C+B">Bartosz Walczak</a>, 
<a href="/search/cs?searchtype=author&query=W%C4%99grzycki%2C+K">Karol W&#x119;grzycki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG); Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The hyperbolicity of a graph, informally, measures how close a graph is
(metrically) to a tree. Hence, it is intuitively similar to treewidth, but the
measures are formally incomparable. Motivated by the broad study of algorithms
and separators on planar graphs and their relation to treewidth, we initiate
the study of planar graphs of bounded hyperbolicity.
<br />Our main technical contribution is a novel balanced separator theorem for
planar $\delta$-hyperbolic graphs that is substantially stronger than the
classic planar separator theorem. For any fixed $\delta \geq 0$, we can find
balanced separator that induces either a single geodesic (shortest) path or a
single geodesic cycle in the graph.
<br />An important advantage of our separator is that the union of our separator
(vertex set $Z$) with any subset of the connected components of $G - Z$ induces
again a planar $\delta$-hyperbolic graph, which would not be guaranteed with an
arbitrary separator. Our construction runs in near-linear time and guarantees
that size of separator is $\mathrm{poly}(\delta) \cdot \log n$. As an
application of our separator theorem and its strong properties, we obtain two
novel approximation schemes on planar $\delta$-hyperbolic graphs. We prove that
Maximum Independent Set and the Traveling Salesperson problem have a
near-linear time FPTAS for any constant $\delta$, running in $n\,
\mathrm{polylog}(n) \cdot 2^{\mathcal{O}(\delta^2)} \cdot
\varepsilon^{-\mathcal{O}(\delta)}$ time.
<br />We also show that our approximation scheme for Maximum Independent Set has
essentially the best possible running time under the Exponential Time
Hypothesis (ETH). This immediately follows from our third contribution: we
prove that Maximum Independent Set has no $n^{o(\delta)}$-time algorithm on
planar $\delta$-hyperbolic graphs, unless ETH fails.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11284" title="Abstract">arXiv:2310.11284</a> [<a href="/pdf/2310.11284" title="Download PDF">pdf</a>, <a href="/format/2310.11284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised 3D Scene Flow Estimation and Motion Prediction using  Local Rigidity Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extension of our CVPR 2022 paper (RigidFlow: Self-Supervised Scene Flow Learning on Point Clouds by Local Rigidity Prior)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this article, we investigate self-supervised 3D scene flow estimation and
class-agnostic motion prediction on point clouds. A realistic scene can be well
modeled as a collection of rigidly moving parts, therefore its scene flow can
be represented as a combination of the rigid motion of these individual parts.
Building upon this observation, we propose to generate pseudo scene flow labels
for self-supervised learning through piecewise rigid motion estimation, in
which the source point cloud is decomposed into local regions and each region
is treated as rigid. By rigidly aligning each region with its potential
counterpart in the target point cloud, we obtain a region-specific rigid
transformation to generate its pseudo flow labels. To mitigate the impact of
potential outliers on label generation, when solving the rigid registration for
each region, we alternately perform three steps: establishing point
correspondences, measuring the confidence for the correspondences, and updating
the rigid transformation based on the correspondences and their confidence. As
a result, confident correspondences will dominate label generation and a
validity mask will be derived for the generated pseudo labels. By using the
pseudo labels together with their validity mask for supervision, models can be
trained in a self-supervised manner. Extensive experiments on FlyingThings3D
and KITTI datasets demonstrate that our method achieves new state-of-the-art
performance in self-supervised scene flow learning, without any ground truth
scene flow for supervision, even performing better than some supervised
counterparts. Additionally, our method is further extended to class-agnostic
motion prediction and significantly outperforms previous state-of-the-art
self-supervised methods on nuScenes dataset.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11285" title="Abstract">arXiv:2310.11285</a> [<a href="/pdf/2310.11285" title="Download PDF">pdf</a>, <a href="/ps/2310.11285" title="Download PostScript">ps</a>, <a href="/format/2310.11285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of optimal optimum distance flag codes by MRD codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuangqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shuhui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+L">Lijun Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Optimum distance flag codes (ODFCs), as special flag codes, have received a
lot of attention due to its application in random network coding. In 2021,
Alonso-Gonz\'{a}lez et al. constructed optimal $(n,\mathcal{A})$-ODFC for
$\mathcal {A}\subseteq \{1,2,\ldots,k,n-k,\ldots,n-1\}$ with $k\in \mathcal A$
and $k|n$. In this paper, we introduce a new construction of $(n,\mathcal
A)_q$-ODFCs by maximum rank-metric codes. It is proved that there is an
$(n,\mathcal{A})$-ODFC of size $\frac{q^n-q^{k+r}}{q^k-1}+1$ for any
$\mathcal{A}\subseteq\{1,2,\ldots,k,n-k,\ldots,n-1\}$ with $\mathcal A\cap
\{k,n-k\}\neq\emptyset$, where $r\equiv n\pmod k$ and $0\leq r&lt;k$. Furthermore,
when $k&gt;\frac{q^r-1}{q-1}$, this $(n,\mathcal A)_q$-ODFC is optimal. Specially,
when $r=0$, Alonso-Gonz\'{a}lez et al.'s result is also obtained.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11287" title="Abstract">arXiv:2310.11287</a> [<a href="/pdf/2310.11287" title="Download PDF">pdf</a>, <a href="/format/2310.11287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Impact of Humanitarian Aid on Food Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cerd%C3%A0-Bautista%2C+J">Jordi Cerd&#xe0;-Bautista</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%A1rraga%2C+J+M">Jos&#xe9; Mar&#xed;a T&#xe1;rraga</a>, 
<a href="/search/cs?searchtype=author&query=Sitokonstantinou%2C+V">Vasileios Sitokonstantinou</a>, 
<a href="/search/cs?searchtype=author&query=Camps-Valls%2C+G">Gustau Camps-Valls</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the face of climate change-induced droughts, vulnerable regions encounter
severe threats to food security, demanding urgent humanitarian assistance. This
paper introduces a causal inference framework for the Horn of Africa, aiming to
assess the impact of cash-based interventions on food crises. Our contributions
encompass identifying causal relationships within the food security system,
harmonizing a comprehensive database, and estimating the causal effect of
humanitarian interventions on malnutrition. Our results revealed no significant
effects, likely due to limited sample size, suboptimal data quality, and an
imperfect causal graph resulting from our limited understanding of
multidisciplinary systems like food security. This underscores the need to
enhance data collection and refine causal models with domain experts for more
effective future interventions and policies, improving transparency and
accountability in humanitarian aid.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11288" title="Abstract">arXiv:2310.11288</a> [<a href="/pdf/2310.11288" title="Download PDF">pdf</a>, <a href="/format/2310.11288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enriching Diagrams with Algebraic Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villoria%2C+A">Alejandro Villoria</a>, 
<a href="/search/cs?searchtype=author&query=Basold%2C+H">Henning Basold</a>, 
<a href="/search/cs?searchtype=author&query=Laarman%2C+A">Alfons Laarman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 appendix pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">In this paper, we extend diagrammatic reasoning in monoidal categories with
algebraic operations and equations. We achieve this by considering monoidal
categories that are enriched in the category of Eilenberg-Moore algebras for a
monad. Under the condition that this monad is monoidal and affine, we construct
an adjunction between symmetric monoidal categories and symmetric monoidal
categories enriched over algebras for the monad. This allows us to devise an
extension, and its semantics, of the ZX-calculus with probabilistic choices by
freely enriching over convex algebras, which are the algebras of the finite
distribution monad. We show how this construction can be used for diagrammatic
reasoning of noise in quantum systems.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11290" title="Abstract">arXiv:2310.11290</a> [<a href="/pdf/2310.11290" title="Download PDF">pdf</a>, <a href="/format/2310.11290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signal Temporal Logic-Guided Model Predictive Control for Robust Bipedal  Locomotion Resilient to Runtime External Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhaoyuan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Rongming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yates%2C+W">William Yates</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yipu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Ye Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This study investigates formal-method-based trajectory optimization (TO) for
bipedal locomotion, focusing on scenarios where the robot encounters external
perturbations at unforeseen times. Our key research question centers around the
assurance of task specification correctness and the maximization of
specification robustness for a bipedal robot in the presence of external
perturbations.
<br />Our contribution includes the design of an optimization-based task and motion
planning framework that generates optimal control sequences with formal
guarantees of external perturbation recovery. As a core component of the
framework, a model predictive controller (MPC) encodes signal temporal logic
(STL)-based task specifications as a cost function. In particular, we
investigate challenging scenarios where the robot is subjected to lateral
perturbations that increase the risk of failure due to leg self-collision. To
address this, we synthesize agile and safe crossed-leg maneuvers to enhance
locomotion stability.
<br />This work marks the first study to incorporate formal guarantees offered by
STL into a TO for perturbation recovery of bipedal locomotion. We demonstrate
the efficacy of the framework via perturbation experiments in simulations.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11291" title="Abstract">arXiv:2310.11291</a> [<a href="/pdf/2310.11291" title="Download PDF">pdf</a>, <a href="/format/2310.11291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Automatic Learning Rate Schedule Algorithm for Achieving Faster  Convergence and Steeper Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chiwun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The delta-bar-delta algorithm is recognized as a learning rate adaptation
technique that enhances the convergence speed of the training process in
optimization by dynamically scheduling the learning rate based on the
difference between the current and previous weight updates. While this
algorithm has demonstrated strong competitiveness in full data optimization
when compared to other state-of-the-art algorithms like Adam and SGD, it may
encounter convergence issues in mini-batch optimization scenarios due to the
presence of noisy gradients.
<br />In this study, we thoroughly investigate the convergence behavior of the
delta-bar-delta algorithm in real-world neural network optimization. To address
any potential convergence challenges, we propose a novel approach called RDBD
(Regrettable Delta-Bar-Delta). Our approach allows for prompt correction of
biased learning rate adjustments and ensures the convergence of the
optimization process. Furthermore, we demonstrate that RDBD can be seamlessly
integrated with any optimization algorithm and significantly improve the
convergence speed.
<br />By conducting extensive experiments and evaluations, we validate the
effectiveness and efficiency of our proposed RDBD approach. The results
showcase its capability to overcome convergence issues in mini-batch
optimization and its potential to enhance the convergence speed of various
optimization algorithms. This research contributes to the advancement of
optimization techniques in neural network training, providing practitioners
with a reliable automatic learning rate scheduler for achieving faster
convergence and improved optimization outcomes.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11292" title="Abstract">arXiv:2310.11292</a> [<a href="/pdf/2310.11292" title="Download PDF">pdf</a>, <a href="/format/2310.11292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two subspace methods for frequency sparse graph signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Emmrich%2C+T">Tarek Emmrich</a>, 
<a href="/search/math?searchtype=author&query=Juhnke-Kubitzke%2C+M">Martina Juhnke-Kubitzke</a>, 
<a href="/search/math?searchtype=author&query=Kunis%2C+S">Stefan Kunis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study signals that are sparse in graph spectral domain and develop
explicit algorithms to reconstruct the support set as well as partial
components from samples on few vertices of the graph. The number of required
samples is independent of the total size of the graph and takes only local
properties of the graph into account. Our results rely on an operator based
framework for subspace methods and become effective when the spectral
eigenfunctions are zero-free or linear independent on small sets of the
vertices. The latter has recently been adressed using algebraic methods by the
first author.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11294" title="Abstract">arXiv:2310.11294</a> [<a href="/pdf/2310.11294" title="Download PDF">pdf</a>, <a href="/format/2310.11294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Reward Distribution in Federated Byzantine Agreement Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ndolo%2C+C">Charmaine Ndolo</a>, 
<a href="/search/cs?searchtype=author&query=Florian%2C+M">Martin Florian</a>, 
<a href="/search/cs?searchtype=author&query=Tschorsch%2C+F">Florian Tschorsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Federated Byzantine Agreement Systems (FBASs) offer a solution to consensus
in permissionless systems by adapting the well-studied Byzantine agreement
model to permissionless consensus. Unlike its counterparts in the context of
permissionless consensus, the FBAS system model does not offer validating nodes
protocol-level incentives although they are entrusted with safeguarding and
ensuring the functionality of the system. Multiple studies have reported on the
small number of active validators in these systems leading to some concerns
about their resilience. To this end, this paper studies how rewards can be
distributed in FBASs and presents a fair reward distribution function for
FBASs. The challenge is that, on the one hand, consensus in an FBAS is found
jointly between all nodes and, on the other hand, nodes do not all contribute
equally to this process. We draw on game-theoretic methods to quantify these
contributions bearing the overall health of the FBAS in mind and present a fair
reward distribution function which we evaluate based on a set of identified
properties.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11295" title="Abstract">arXiv:2310.11295</a> [<a href="/pdf/2310.11295" title="Download PDF">pdf</a>, <a href="/format/2310.11295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CorrTalk: Correlation Between Hierarchical Speech and Facial Activity  Variances for 3D Animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhaojie Chu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kailing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xiaofen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yilin Lan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+B">Bolun Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangmin Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">Speech-driven 3D facial animation is a challenging cross-modal task that has
attracted growing research interest. During speaking activities, the mouth
displays strong motions, while the other facial regions typically demonstrate
comparatively weak activity levels. Existing approaches often simplify the
process by directly mapping single-level speech features to the entire facial
animation, which overlook the differences in facial activity intensity leading
to overly smoothed facial movements. In this study, we propose a novel
framework, CorrTalk, which effectively establishes the temporal correlation
between hierarchical speech features and facial activities of different
intensities across distinct regions. A novel facial activity intensity metric
is defined to distinguish between strong and weak facial activity, obtained by
computing the short-time Fourier transform of facial vertex displacements.
Based on the variances in facial activity, we propose a dual-branch decoding
framework to synchronously synthesize strong and weak facial activity, which
guarantees wider intensity facial animation synthesis. Furthermore, a weighted
hierarchical feature encoder is proposed to establish temporal correlation
between hierarchical speech features and facial activity at different
intensities, which ensures lip-sync and plausible facial expressions. Extensive
qualitatively and quantitatively experiments as well as a user study indicate
that our CorrTalk outperforms existing state-of-the-art methods. The source
code and supplementary video are publicly available at:
https://zjchu.github.io/projects/CorrTalk/
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11301" title="Abstract">arXiv:2310.11301</a> [<a href="/pdf/2310.11301" title="Download PDF">pdf</a>, <a href="/format/2310.11301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source Code Comprehension: A Contemporary Definition and Conceptual  Model for Empirical Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wyrich%2C+M">Marvin Wyrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submission under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Be it in debugging, testing, code review or, more recently, pair programming
with AI assistance: in all these activities, software engineers need to
understand source code. Accordingly, plenty of research is taking place in the
field to find out, for example, what makes code easy to understand and which
tools can best support developers in their comprehension process. And while any
code comprehension researcher certainly has a rough idea of what they mean when
they mention a developer having a good understanding of a piece of code, to
date, the research community has not managed to define source code
comprehension as a concept. Instead, in primary research on code comprehension,
an implicit definition by task prevails, i.e., code comprehension is what the
experimental tasks measure. This approach has two negative consequences. First,
it makes it difficult to conduct secondary research. Currently, each code
comprehension primary study uses different comprehension tasks and measures,
and thus it is not clear whether different studies intend to measure the same
construct. Second, authors of a primary study run into the difficulty of
justifying their design decisions without a definition of what they attempt to
measure. An operationalization of an insufficiently described construct occurs,
which poses a threat to construct validity.
<br />The task of defining code comprehension considering the theory of the past
fifty years is not an easy one. Nor is it a task that every author of a primary
study must accomplish on their own. Therefore, this paper constitutes a
reference work that defines source code comprehension and presents a conceptual
framework in which researchers can anchor their empirical code comprehension
research.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11303" title="Abstract">arXiv:2310.11303</a> [<a href="/pdf/2310.11303" title="Download PDF">pdf</a>, <a href="/format/2310.11303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for  Zero-Shot Commonsense Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haochen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tianqing Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Baixuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenxuan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Zero-shot commonsense Question-Answering (QA) requires models to reason about
general situations beyond specific benchmarks. State-of-the-art approaches
fine-tune language models on QA pairs constructed from CommonSense Knowledge
Bases (CSKBs) to equip the models with more commonsense knowledge in a QA
context. However, current QA synthesis protocols may introduce noise from the
CSKBs and generate ungrammatical questions and false negative options, which
impede the model's ability to generalize. To address these issues, we propose
QADYNAMICS, a training dynamics-driven framework for QA diagnostics and
refinement. Our approach analyzes the training dynamics of each QA pair at both
the question level and option level, discarding machine-detectable artifacts by
removing uninformative QA pairs and mislabeled or false-negative options.
Extensive experiments demonstrate the effectiveness of our approach, which
outperforms all baselines while using only 33% of the synthetic data, even
including LLMs such as ChatGPT. Moreover, expert evaluations confirm that our
framework significantly improves the quality of QA synthesis. Our codes and
model checkpoints are available at
https://github.com/HKUST-KnowComp/QaDynamics.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11305" title="Abstract">arXiv:2310.11305</a> [<a href="/pdf/2310.11305" title="Download PDF">pdf</a>, <a href="/format/2310.11305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiniZero: Comparative Analysis of AlphaZero and MuZero on Go, Othello,  and Atari Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Ti-Rong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guei%2C+H">Hung Guei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Po-Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Pei-Chiun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T+H">Ting Han Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shih%2C+C">Chung-Chin Shih</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yun-Jui Tsai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents MiniZero, a zero-knowledge learning framework that
supports four state-of-the-art algorithms, including AlphaZero, MuZero, Gumbel
AlphaZero, and Gumbel MuZero. While these algorithms have demonstrated
super-human performance in many games, it remains unclear which among them is
most suitable or efficient for specific tasks. Through MiniZero, we
systematically evaluate the performance of each algorithm in two board games,
9x9 Go and 8x8 Othello, as well as 57 Atari games. Our empirical findings are
summarized as follows. For two board games, using more simulations generally
results in higher performance. However, the choice of AlphaZero and MuZero may
differ based on game properties. For Atari games, both MuZero and Gumbel MuZero
are worth considering. Since each game has unique characteristics, different
algorithms and simulations yield varying results. In addition, we introduce an
approach, called progressive simulation, which progressively increases the
simulation budget during training to allocate computation more efficiently. Our
empirical results demonstrate that progressive simulation achieves
significantly superior performance in two board games. By making our framework
and trained models publicly available, this paper contributes a benchmark for
future research on zero-knowledge learning algorithms, assisting researchers in
algorithm selection and comparison against these zero-knowledge learning
baselines.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11307" title="Abstract">arXiv:2310.11307</a> [<a href="/pdf/2310.11307" title="Download PDF">pdf</a>, <a href="/format/2310.11307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi Self-supervised Pre-fine-tuned Transformer Fusion for Better  Intelligent Transportation Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Juwu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiangtao Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Intelligent transportation system combines advanced information technology to
provide intelligent services such as monitoring, detection, and early warning
for modern transportation. Intelligent transportation detection is the
cornerstone of many intelligent traffic services by identifying task targets
through object detection methods. However existing detection methods in
intelligent transportation are limited by two aspects. First, there is a
difference between the model knowledge pre-trained on large-scale datasets and
the knowledge required for target task. Second, most detection models follow
the pattern of single-source learning, which limits the learning ability. To
address these problems, we propose a Multi Self-supervised Pre-fine-tuned
Transformer Fusion (MSPTF) network, consisting of two steps: unsupervised
pre-fine-tune domain knowledge learning and multi-model fusion target task
learning. In the first step, we introduced self-supervised learning methods
into transformer model pre-fine-tune which could reduce data costs and
alleviate the knowledge gap between pre-trained model and target task. In the
second step, we take feature information differences between different model
architectures and different pre-fine-tune tasks into account and propose
Multi-model Semantic Consistency Cross-attention Fusion (MSCCF) network to
combine different transformer model features by considering channel semantic
consistency and feature vector semantic consistency, which obtain more complete
and proper fusion features for detection task. We experimented the proposed
method on vehicle recognition dataset and road disease detection dataset and
achieved 1.1%, 5.5%, 4.2% improvement compared with baseline and 0.7%, 1.8%,
1.7% compared with sota, which proved the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11309" title="Abstract">arXiv:2310.11309</a> [<a href="/pdf/2310.11309" title="Download PDF">pdf</a>, <a href="/ps/2310.11309" title="Download PostScript">ps</a>, <a href="/format/2310.11309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Surfaces Aided High-Mobility Communications: Opportunities  and Design Issues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Communications Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Intelligent reflecting/refracting surface (IRS) is envisioned as a promising
technology to reconfigure wireless propagation environment for enhancing the
communication performance, by smartly controlling the signal
reflection/refraction with a large number of tunable passive elements. In
particular, the application of IRS in high-mobility scenarios can convert
wireless channels from fast fading to slow fading, thus achieving more reliable
communications. In this paper, we first provide an overview of the new
applications and opportunities of IRS in high-mobility communications. Next, we
present two practical strategies for deploying IRS to aid high-mobility
communications, namely, roadside IRS versus vehicle-side IRS, and compare their
different channel characteristics, handover requirements, and deployment costs.
Then, the main issues in designing IRS-aided high-mobility communications,
including node discovery, mode switching, beam alignment/tracking, handover,
and multiuser scheduling are discussed for both IRS deployment strategies.
Moreover, numerical results are presented to demonstrate the potential
performance gains of IRSs in vehicular communications. Finally, new research
directions are pointed out for future work.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11311" title="Abstract">arXiv:2310.11311</a> [<a href="/pdf/2310.11311" title="Download PDF">pdf</a>, <a href="/format/2310.11311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elucidating The Design Space of Classifier-Guided Diffusion Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiajun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tianyang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiacheng Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Guidance in conditional diffusion generation is of great importance for
sample quality and controllability. However, existing guidance schemes are to
be desired. On one hand, mainstream methods such as classifier guidance and
classifier-free guidance both require extra training with labeled data, which
is time-consuming and unable to adapt to new conditions. On the other hand,
training-free methods such as universal guidance, though more flexible, have
yet to demonstrate comparable performance. In this work, through a
comprehensive investigation into the design space, we show that it is possible
to achieve significant performance improvements over existing guidance schemes
by leveraging off-the-shelf classifiers in a training-free fashion, enjoying
the best of both worlds. Employing calibration as a general guideline, we
propose several pre-conditioning techniques to better exploit pretrained
off-the-shelf classifiers for guiding diffusion generation. Extensive
experiments on ImageNet validate our proposed method, showing that
state-of-the-art diffusion models (DDPM, EDM, DiT) can be further improved (up
to 20%) using off-the-shelf classifiers with barely any extra computational
cost. With the proliferation of publicly available pretrained classifiers, our
proposed approach has great potential and can be readily scaled up to
text-to-image generation tasks. The code is available at
https://github.com/AlexMaOLS/EluCD/tree/main.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11316" title="Abstract">arXiv:2310.11316</a> [<a href="/pdf/2310.11316" title="Download PDF">pdf</a>, <a href="/format/2310.11316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MonoSKD: General Distillation Framework for Monocular 3D Object  Detection via Spearman Correlation Coefficient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Monocular 3D object detection is an inherently ill-posed problem, as it is
challenging to predict accurate 3D localization from a single image. Existing
monocular 3D detection knowledge distillation methods usually project the LiDAR
onto the image plane and train the teacher network accordingly. Transferring
LiDAR-based model knowledge to RGB-based models is more complex, so a general
distillation strategy is needed. To alleviate cross-modal prob-lem, we propose
MonoSKD, a novel Knowledge Distillation framework for Monocular 3D detection
based on Spearman correlation coefficient, to learn the relative correlation
between cross-modal features. Considering the large gap between these features,
strict alignment of features may mislead the training, so we propose a looser
Spearman loss. Furthermore, by selecting appropriate distillation locations and
removing redundant modules, our scheme saves more GPU resources and trains
faster than existing methods. Extensive experiments are performed to verify the
effectiveness of our framework on the challenging KITTI 3D object detection
benchmark. Our method achieves state-of-the-art performance until submission
with no additional inference computational cost. Our codes are available at
https://github.com/Senwang98/MonoSKD
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11318" title="Abstract">arXiv:2310.11318</a> [<a href="/pdf/2310.11318" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilising a Large Language Model to Annotate Subject Metadata: A Case  Study in an Australian National Research Data Catalogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mingfang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiuzhen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In support of open and reproducible research, there has been a rapidly
increasing number of datasets made available for research. As the availability
of datasets increases, it becomes more important to have quality metadata for
discovering and reusing them. Yet, it is a common issue that datasets often
lack quality metadata due to limited resources for data curation. Meanwhile,
technologies such as artificial intelligence and large language models (LLMs)
are progressing rapidly. Recently, systems based on these technologies, such as
ChatGPT, have demonstrated promising capabilities for certain data curation
tasks. This paper proposes to leverage LLMs for cost-effective annotation of
subject metadata through the LLM-based in-context learning. Our method employs
GPT-3.5 with prompts designed for annotating subject metadata, demonstrating
promising performance in automatic metadata annotation. However, models based
on in-context learning cannot acquire discipline-specific rules, resulting in
lower performance in several categories. This limitation arises from the
limited contextual information available for subject inference. To the best of
our knowledge, we are introducing, for the first time, an in-context learning
method that harnesses large language models for automated subject metadata
annotation.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11324" title="Abstract">arXiv:2310.11324</a> [<a href="/pdf/2310.11324" title="Download PDF">pdf</a>, <a href="/format/2310.11324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Language Models&#x27; Sensitivity to Spurious Features in Prompt  Design or: How I learned to start worrying about prompt formatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sclar%2C+M">Melanie Sclar</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkov%2C+Y">Yulia Tsvetkov</a>, 
<a href="/search/cs?searchtype=author&query=Suhr%2C+A">Alane Suhr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As large language models (LLMs) are adopted as a fundamental component of
language technologies, it is crucial to accurately characterize their
performance. Because choices in prompt design can strongly influence model
behavior, this design process is critical in effectively using any modern
pre-trained generative language model. In this work, we focus on LLM
sensitivity to a quintessential class of meaning-preserving design choices:
prompt formatting. We find that several widely used open-source LLMs are
extremely sensitive to subtle changes in prompt formatting in few-shot
settings, with performance differences of up to 76 accuracy points when
evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model
size, the number of few-shot examples, or performing instruction tuning. Our
analysis suggests that work evaluating LLMs with prompting-based methods would
benefit from reporting a range of performance across plausible prompt formats,
instead of the currently-standard practice of reporting performance on a single
format. We also show that format performance only weakly correlates between
models, which puts into question the methodological validity of comparing
models with an arbitrarily chosen, fixed prompt format. To facilitate
systematic analysis we propose FormatSpread, an algorithm that rapidly
evaluates a sampled set of plausible prompt formats for a given task, and
reports the interval of expected performance without accessing model weights.
Furthermore, we present a suite of analyses that characterize the nature of
this sensitivity, including exploring the influence of particular atomic
perturbations and the internal representation of particular formats.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11325" title="Abstract">arXiv:2310.11325</a> [<a href="/pdf/2310.11325" title="Download PDF">pdf</a>, <a href="/format/2310.11325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of Malicious DNS-over-HTTPS Traffic: An Anomaly Detection  Approach using Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monroy%2C+S+S">Sergio Salinas Monroy</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A+K">Aman Kumar Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Wahlstedt%2C+G">Garrett Wahlstedt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">To maintain the privacy of users' web browsing history, popular browsers
encrypt their DNS traffic using the DNS-over-HTTPS (DoH) protocol.
Unfortunately, encrypting DNS packets prevents many existing intrusion
detection systems from using plaintext domain names to detect malicious
traffic. In this paper, we design an autoencoder that is capable of detecting
malicious DNS traffic by only observing the encrypted DoH traffic. Compared to
previous works, the proposed autoencoder looks for anomalies in DoH traffic,
and thus can detect malicious traffic that has not been previously observed,
i.e., zero-day attacks. We run extensive experiments to evaluate the
performance of our proposed autoencoder and compare it to that of other anomaly
detection algorithms, namely, local outlier factor, one-class support vector
machine, isolation forest, and variational autoencoders. We find that our
proposed autoencoder achieves the highest detection performance, with a median
F-1 score of 99\% over several types of malicious traffic.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11326" title="Abstract">arXiv:2310.11326</a> [<a href="/pdf/2310.11326" title="Download PDF">pdf</a>, <a href="/format/2310.11326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Channel Estimation by Exploiting Dual Timescales  for Delay-Doppler Alignment Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhiqiang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+F">Fuxi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zaichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">For integrated sensing and communication (ISAC) systems, the channel
information essential for communication and sensing tasks fluctuates across
different timescales. Specifically, wireless sensing primarily focuses on
acquiring path state information (PSI) (e.g., delay, angle, and Doppler) of
individual multi-path components to sense the environment, which usually
evolves much more slowly than the composite channel state information (CSI)
required for communications. Typically, the CSI is approximately unchanged
during the channel coherence time, which characterizes the statistical
properties of wireless communication channels. However, this concept is less
appropriate for describing that for wireless sensing. To this end, in this
paper, we introduce a new timescale to study the variation of the PSI from a
channel geometric perspective, termed path invariant time, during which the PSI
largely remains constant. Our analysis indicates that the path invariant time
considerably exceeds the channel coherence time. Thus, capitalizing on these
dual timescales of the wireless channel, in this paper, we propose a novel ISAC
framework exploiting the recently proposed delay-Doppler alignment modulation
(DDAM) technique. Different from most existing studies on DDAM that assume the
availability of perfect PSI, in this work, we propose a novel algorithm, termed
as adaptive simultaneously orthogonal matching pursuit with support refinement
(ASOMP-SR), for joint environment sensing and PSI estimation. We also analyze
the performance of DDAM with imperfectly sensed PSI.Simulation results unveil
that the proposed DDAM-based ISAC can achieve superior spectral efficiency and
a reduced peak-to-average power ratio (PAPR) compared to standard orthogonal
frequency division multiplexing (OFDM).
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11331" title="Abstract">arXiv:2310.11331</a> [<a href="/pdf/2310.11331" title="Download PDF">pdf</a>, <a href="/ps/2310.11331" title="Download PostScript">ps</a>, <a href="/format/2310.11331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streamlining Sleepy Consensus: Total-Order Broadcast with Single-Vote  Decisions in the Sleepy Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Amato%2C+F">Francesco D&#x27;Amato</a>, 
<a href="/search/cs?searchtype=author&query=Zanolini%2C+L">Luca Zanolini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Over the past years, distributed consensus research has shifted its focus
towards addressing challenges in large-scale, permissionless systems, such as
blockchains. This shift is characterized by the need to accommodate dynamic
participation, contrasting the traditional approach of a static set of
continuously online participants. Works like Bitcoin and the Sleepy Model have
set the stage for this developing framework.
<br />Notable contributions from Momose and Ren (CCS 2022) and subsequent works
have introduced Total-Order Broadcast protocols leveraging Graded Agreement
primitives and supporting dynamic participation, though often requiring
multiple rounds of voting per decision -- a potential bottleneck for real-world
large-scale systems.
<br />Addressing this, our paper presents a novel Total-Order Broadcast protocol in
the Sleepy Model resilient to up to 1/2 adversarial participants, requiring
just a single round of voting per decision. This work paves the way to more
practical Total-Order Broadcast protocols to be implemented in real-world
systems where a large number of participants are involved simultaneously and
their participation level might fluctuate over time.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11332" title="Abstract">arXiv:2310.11332</a> [<a href="/pdf/2310.11332" title="Download PDF">pdf</a>, <a href="/format/2310.11332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering High-Quality Process Models Despite Data Scarcity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adams%2C+J+N">Jan Niklas Adams</a>, 
<a href="/search/cs?searchtype=author&query=Peeperkorn%2C+J">Jari Peeperkorn</a>, 
<a href="/search/cs?searchtype=author&query=Brockhoff%2C+T">Tobias Brockhoff</a>, 
<a href="/search/cs?searchtype=author&query=Terrier%2C+I">Isabelle Terrier</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6hner%2C+H">Heiko G&#xf6;hner</a>, 
<a href="/search/cs?searchtype=author&query=Uysal%2C+M+S">Merih Seran Uysal</a>, 
<a href="/search/cs?searchtype=author&query=Broucke%2C+S+v">Seppe vanden Broucke</a>, 
<a href="/search/cs?searchtype=author&query=De+Weerdt%2C+J">Jochen De Weerdt</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Aalst%2C+W+M+P">Wil M.P. van der Aalst</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Process discovery algorithms learn process models from executed activity
sequences, describing concurrency, causality, and conflict. Concurrent
activities require observing multiple permutations, increasing data
requirements, especially for processes with concurrent subprocesses such as
hierarchical, composite, or distributed processes. While process discovery
algorithms traditionally use sequences of activities as input, recently
introduced object-centric process discovery algorithms can use graphs of
activities as input, encoding partial orders between activities. As such, they
contain the concurrency information of many sequences in a single graph. In
this paper, we address the research question of reducing process discovery data
requirements when using object-centric event logs for process discovery. We
classify different real-life processes according to the control-flow complexity
within and between subprocesses and introduce an evaluation framework to assess
process discovery algorithm quality of traditional and object-centric process
discovery based on the sample size. We complement this with a large-scale
production process case study. Our results show reduced data requirements,
enabling the discovery of large, concurrent processes such as manufacturing
with little data, previously infeasible with traditional process discovery. Our
findings suggest that object-centric process mining could revolutionize process
discovery in various sectors, including manufacturing and supply chains.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11333" title="Abstract">arXiv:2310.11333</a> [<a href="/pdf/2310.11333" title="Download PDF">pdf</a>, <a href="/format/2310.11333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Key Point-based Orientation Estimation of Strawberries for Robotic Fruit  Picking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%C3%ABdec%2C+J+L">Justin Le Lou&#xeb;dec</a>, 
<a href="/search/cs?searchtype=author&query=Cielniak%2C+G">Grzegorz Cielniak</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Vision Systems. ICVS 2023. Lecture Notes in Computer
  Science, vol 14253
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Selective robotic harvesting is a promising technological solution to address
labour shortages which are affecting modern agriculture in many parts of the
world. For an accurate and efficient picking process, a robotic harvester
requires the precise location and orientation of the fruit to effectively plan
the trajectory of the end effector. The current methods for estimating fruit
orientation employ either complete 3D information which typically requires
registration from multiple views or rely on fully-supervised learning
techniques, which require difficult-to-obtain manual annotation of the
reference orientation. In this paper, we introduce a novel key-point-based
fruit orientation estimation method allowing for the prediction of 3D
orientation from 2D images directly. The proposed technique can work without
full 3D orientation annotations but can also exploit such information for
improved accuracy. We evaluate our work on two separate datasets of strawberry
images obtained from real-world data collection scenarios. Our proposed method
achieves state-of-the-art performance with an average error as low as
$8^{\circ}$, improving predictions by $\sim30\%$ compared to previous work
presented in~\cite{wagner2021efficient}. Furthermore, our method is suited for
real-time robotic applications with fast inference times of $\sim30$ms.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11334" title="Abstract">arXiv:2310.11334</a> [<a href="/pdf/2310.11334" title="Download PDF">pdf</a>, <a href="/format/2310.11334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent-Specific Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Triantafyllou%2C+S">Stelios Triantafyllou</a>, 
<a href="/search/cs?searchtype=author&query=Sukovic%2C+A">Aleksa Sukovic</a>, 
<a href="/search/cs?searchtype=author&query=Mandal%2C+D">Debmalya Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Radanovic%2C+G">Goran Radanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Establishing causal relationships between actions and outcomes is fundamental
for accountable multi-agent decision-making. However, interpreting and
quantifying agents' contributions to such relationships pose significant
challenges. These challenges are particularly prominent in the context of
multi-agent sequential decision-making, where the causal effect of an agent's
action on the outcome depends on how the other agents respond to that action.
In this paper, our objective is to present a systematic approach for
attributing the causal effects of agents' actions to the influence they exert
on other agents. Focusing on multi-agent Markov decision processes, we
introduce agent-specific effects (ASE), a novel causal quantity that measures
the effect of an agent's action on the outcome that propagates through other
agents. We then turn to the counterfactual counterpart of ASE (cf-ASE), provide
a sufficient set of conditions for identifying cf-ASE, and propose a practical
sampling-based algorithm for estimating it. Finally, we experimentally evaluate
the utility of cf-ASE through a simulation-based testbed, which includes a
sepsis management environment.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11335" title="Abstract">arXiv:2310.11335</a> [<a href="/pdf/2310.11335" title="Download PDF">pdf</a>, <a href="/format/2310.11335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-ergodicity in reinforcement learning: robustness via ergodicity  transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baumann%2C+D">Dominik Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Noorani%2C+E">Erfaun Noorani</a>, 
<a href="/search/cs?searchtype=author&query=Price%2C+J">James Price</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+O">Ole Peters</a>, 
<a href="/search/cs?searchtype=author&query=Connaughton%2C+C">Colm Connaughton</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6n%2C+T+B">Thomas B. Sch&#xf6;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Envisioned application areas for reinforcement learning (RL) include
autonomous driving, precision agriculture, and finance, which all require RL
agents to make decisions in the real world. A significant challenge hindering
the adoption of RL methods in these domains is the non-robustness of
conventional algorithms. In this paper, we argue that a fundamental issue
contributing to this lack of robustness lies in the focus on the expected value
of the return as the sole "correct" optimization objective. The expected value
is the average over the statistical ensemble of infinitely many trajectories.
For non-ergodic returns, this average differs from the average over a single
but infinitely long trajectory. Consequently, optimizing the expected value can
lead to policies that yield exceptionally high returns with probability zero
but almost surely result in catastrophic outcomes. This problem can be
circumvented by transforming the time series of collected returns into one with
ergodic increments. This transformation enables learning robust policies by
optimizing the long-term return for individual agents rather than the average
across infinitely many trajectories. We propose an algorithm for learning
ergodicity transformations from data and demonstrate its effectiveness in an
instructive, non-ergodic environment and on standard RL benchmarks.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11341" title="Abstract">arXiv:2310.11341</a> [<a href="/pdf/2310.11341" title="Download PDF">pdf</a>, <a href="/format/2310.11341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Cognitive Architecture: Incorporating Biases and Multi-Memory  Systems for Lifelong Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gowda%2C+S">Shruthi Gowda</a>, 
<a href="/search/cs?searchtype=author&query=Zonooz%2C+B">Bahram Zonooz</a>, 
<a href="/search/cs?searchtype=author&query=Arani%2C+E">Elahe Arani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Transactions on Machine Learning Research (TMLR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Artificial neural networks (ANNs) exhibit a narrow scope of expertise on
stationary independent data. However, the data in the real world is continuous
and dynamic, and ANNs must adapt to novel scenarios while also retaining the
learned knowledge to become lifelong learners. The ability of humans to excel
at these tasks can be attributed to multiple factors ranging from cognitive
computational structures, cognitive biases, and the multi-memory systems in the
brain. We incorporate key concepts from each of these to design a novel
framework, Dual Cognitive Architecture (DUCA), which includes multiple
sub-systems, implicit and explicit knowledge representation dichotomy,
inductive bias, and a multi-memory system. The inductive bias learner within
DUCA is instrumental in encoding shape information, effectively countering the
tendency of ANNs to learn local textures. Simultaneously, the inclusion of a
semantic memory submodule facilitates the gradual consolidation of knowledge,
replicating the dynamics observed in fast and slow learning systems,
reminiscent of the principles underpinning the complementary learning system in
human cognition. DUCA shows improvement across different settings and datasets,
and it also exhibits reduced task recency bias, without the need for extra
information. To further test the versatility of lifelong learning methods on a
challenging distribution shift, we introduce a novel domain-incremental dataset
DN4IL. In addition to improving performance on existing benchmarks, DUCA also
demonstrates superior performance on this complex dataset.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11344" title="Abstract">arXiv:2310.11344</a> [<a href="/pdf/2310.11344" title="Download PDF">pdf</a>, <a href="/format/2310.11344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The effect of stemming and lemmatization on Portuguese fake news text  classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Freitas+Santos%2C+L">Lucca de Freitas Santos</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+M+V">Murilo Varges da Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the popularization of the internet, smartphones and social media,
information is being spread quickly and easily way, which implies bigger
traffic of information in the world, but there is a problem that is harming
society with the dissemination of fake news. With a bigger flow of information,
some people are trying to disseminate deceptive information and fake news. The
automatic detection of fake news is a challenging task because to obtain a good
result is necessary to deal with linguistics problems, especially when we are
dealing with languages that not have been comprehensively studied yet, besides
that, some techniques can help to reach a good result when we are dealing with
text data, although, the motivation of detecting this deceptive information it
is in the fact that the people need to know which information is true and
trustful and which one is not. In this work, we present the effect the
pre-processing methods such as lemmatization and stemming have on fake news
classification, for that we designed some classifier models applying different
pre-processing techniques. The results show that the pre-processing step is
important to obtain betters results, the stemming and lemmatization techniques
are interesting methods and need to be more studied to develop techniques
focused on the Portuguese language so we can reach better results.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11346" title="Abstract">arXiv:2310.11346</a> [<a href="/pdf/2310.11346" title="Download PDF">pdf</a>, <a href="/format/2310.11346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generalizable Multi-Camera 3D Object Detection via Perspective  Debiasing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Q">Qing Lian</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dalong Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingcong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting objects in 3D space using multiple cameras, known as Multi-Camera
3D Object Detection (MC3D-Det), has gained prominence with the advent of
bird's-eye view (BEV) approaches. However, these methods often struggle when
faced with unfamiliar testing environments due to the lack of diverse training
data encompassing various viewpoints and environments. To address this, we
propose a novel method that aligns 3D detection with 2D camera plane results,
ensuring consistent and accurate detections. Our framework, anchored in
perspective debiasing, helps the learning of features resilient to domain
shifts. In our approach, we render diverse view maps from BEV features and
rectify the perspective bias of these maps, leveraging implicit foreground
volumes to bridge the camera and BEV planes. This two-step process promotes the
learning of perspective- and context-independent features, crucial for accurate
object detection across varying viewpoints, camera parameters and environment
conditions. Notably, our model-agnostic approach preserves the original network
structure without incurring additional inference costs, facilitating seamless
integration across various models and simplifying deployment. Furthermore, we
also show our approach achieves satisfactory results in real data when trained
only with virtual datasets, eliminating the need for real scene annotations.
Experimental results on both Domain Generalization (DG) and Unsupervised Domain
Adaptation (UDA) clearly demonstrate its effectiveness. Our code will be
released.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11349" title="Abstract">arXiv:2310.11349</a> [<a href="/pdf/2310.11349" title="Download PDF">pdf</a>, <a href="/ps/2310.11349" title="Download PostScript">ps</a>, <a href="/format/2310.11349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A robust and high precision algorithm for elastic scattering problems  from cornered domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yao%2C+J">Jianan Yao</a>, 
<a href="/search/math?searchtype=author&query=Xie%2C+B">Baoling Xie</a>, 
<a href="/search/math?searchtype=author&query=Lai%2C+J">Jun Lai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Navier equation is the governing equation of elastic waves, and computing
its solution accurately and rapidly has a wide range of applications in
geophysical exploration, materials science, etc. In this paper, we focus on the
efficient and high-precision numerical algorithm for the time harmonic elastic
wave scattering problems from cornered domains via the boundary integral
equations in two dimensions. The approach is based on the combination of
Nystr\"om discretization, analytical singular integrals and kernel-splitting
method, which results in a high-order solver for smooth boundaries. It is then
combined with the recursively compressed inverse preconditioning (RCIP) method
to solve elastic scattering problems from cornered domains. Numerical
experiments demonstrate that the proposed approach achieves high accuracy, with
stabilized errors close to machine precision in various geometric
configurations. The algorithm is further applied to investigate the asymptotic
behavior of density functions associated with boundary integral operators near
corners, and the numerical results are highly consistent with the theoretical
formulas.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11354" title="Abstract">arXiv:2310.11354</a> [<a href="/pdf/2310.11354" title="Download PDF">pdf</a>, <a href="/format/2310.11354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning by Teaching: Key Challenges and Design Implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Debban%C3%A9%2C+A">Amy Debban&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+J">Ken Jen Lee</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+J">Jarvis Tse</a>, 
<a href="/search/cs?searchtype=author&query=Law%2C+E">Edith Law</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 figures, ACM CSCW 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. ACM Hum.-Comput. Interact. 7, CSCW1, Article 68 (April
  2023), 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Benefits of learning by teaching (LbT) have been highlighted by previous
studies from a pedagogical lens, as well as through computer-supported systems.
However, the challenges that university students face in technology-mediated
LbT$\unicode{x2013}$whether it be teaching oneself, teaching a peer, or
teaching an agent$\unicode{x2013}$are not well understood. Furthermore, there
is a gap in knowledge on the challenges that students encounter throughout the
process of teaching (content selection, preparation, teaching, receiving and
giving feedback, and reflection) despite its importance to the design of LbT
platforms. Thus, we conducted a study with 24 university students where they
taught content they had not fully grasped, without guidance, and participated
in a semi-structured interview. Results demonstrate that participants
encountered the following challenges: psychological barriers relating to self
and others, and lack of know-how. Furthermore, we illuminate design
implications required to overcome these challenges and benefit from LbT without
requiring prior training in pedagogy.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11360" title="Abstract">arXiv:2310.11360</a> [<a href="/pdf/2310.11360" title="Download PDF">pdf</a>, <a href="/format/2310.11360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Neural Machine Translation with Semantic Units
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Langlin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shuhao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuocheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Conventional neural machine translation (NMT) models typically use subwords
and words as the basic units for model input and comprehension. However,
complete words and phrases composed of several tokens are often the fundamental
units for expressing semantics, referred to as semantic units. To address this
issue, we propose a method Semantic Units for Machine Translation (SU4MT) which
models the integral meanings of semantic units within a sentence, and then
leverages them to provide a new perspective for understanding the sentence.
Specifically, we first propose Word Pair Encoding (WPE), a phrase extraction
method to help identify the boundaries of semantic units. Next, we design an
Attentive Semantic Fusion (ASF) layer to integrate the semantics of multiple
subwords into a single vector: the semantic unit representation. Lastly, the
semantic-unit-level sentence representation is concatenated to the token-level
one, and they are combined as the input of encoder. Experimental results
demonstrate that our method effectively models and leverages
semantic-unit-level information and outperforms the strong baselines. The code
is available at https://github.com/ictnlp/SU4MT.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11361" title="Abstract">arXiv:2310.11361</a> [<a href="/pdf/2310.11361" title="Download PDF">pdf</a>, <a href="/format/2310.11361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained FoV Radiated Power as a Figure of Merit of Phased Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ruiz%2C+A+A">Alejandro Ant&#xf3;n Ruiz</a>, 
<a href="/search/eess?searchtype=author&query=Hosseinzadegan%2C+S">Samar Hosseinzadegan</a>, 
<a href="/search/eess?searchtype=author&query=Kvarnstrand%2C+J">John Kvarnstrand</a>, 
<a href="/search/eess?searchtype=author&query=Arvidsson%2C+K">Klas Arvidsson</a>, 
<a href="/search/eess?searchtype=author&query=Glazunov%2C+A+A">Andr&#xe9;s Alay&#xf3;n Glazunov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we propose quantifying the radiated power of phased arrays or,
in general, directive antennas, by the Constrained-View Radiated Power (CVRP).
The constrained view shall be interpreted here as the Field-of-View (FoV) of an
antenna that defines a region in space where focusing the radiated power is
highly desired. In the limiting cases, we have that CVRP equals the Total
Radiated Power (TRP) when the FoV covers the whole sphere, while, if the FoV
reduces to a single point in space, the CVRP equals the Equivalent Isotropic
Radiated Power (EIRP). We further present an analysis based on measured
radiation patterns of a 16-element, linearly polarized, millimeter-Wave
(mmWave), planar phased array antenna operating at 28 GHz. We compare the
results to two ideal planar array antennas with the same number of Huygens and
cosine elements. The evaluated figure of merit is computed for different
scanning angles, as well as for different malfunctions of antenna elements,
both for the real and simulated arrays. The results show that the introduced
figure of merit could be potentially used for the detection of malfunctioning
elements in antenna arrays as well as to characterize the impact of scan loss.
Furthermore, CVRP is useful to straightforwardly and significantly characterize
the performance of a directive antenna in terms of the power radiated towards a
specific region in space.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11363" title="Abstract">arXiv:2310.11363</a> [<a href="/pdf/2310.11363" title="Download PDF">pdf</a>, <a href="/format/2310.11363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangling the Linguistic Competence of Privacy-Preserving BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arnold%2C+S">Stefan Arnold</a>, 
<a href="/search/cs?searchtype=author&query=Kemmerzell%2C+N">Nils Kemmerzell</a>, 
<a href="/search/cs?searchtype=author&query=Schreiner%2C+A">Annika Schreiner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Differential Privacy (DP) has been tailored to address the unique challenges
of text-to-text privatization. However, text-to-text privatization is known for
degrading the performance of language models when trained on perturbed text.
Employing a series of interpretation techniques on the internal representations
extracted from BERT trained on perturbed pre-text, we intend to disentangle at
the linguistic level the distortion induced by differential privacy.
Experimental results from a representational similarity analysis indicate that
the overall similarity of internal representations is substantially reduced.
Using probing tasks to unpack this dissimilarity, we find evidence that
text-to-text privatization affects the linguistic competence across several
formalisms, encoding localized properties of words while falling short at
encoding the contextual relationships between spans of words.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11364" title="Abstract">arXiv:2310.11364</a> [<a href="/pdf/2310.11364" title="Download PDF">pdf</a>, <a href="/format/2310.11364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Fidelity Noise Reduction with Differentiable Signal Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steinmetz%2C+C+J">Christian J. Steinmetz</a>, 
<a href="/search/cs?searchtype=author&query=Walther%2C+T">Thomas Walther</a>, 
<a href="/search/cs?searchtype=author&query=Reiss%2C+J+D">Joshua D. Reiss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the 155th Convention of the Audio Engineering Society
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Noise reduction techniques based on deep learning have demonstrated
impressive performance in enhancing the overall quality of recorded speech.
While these approaches are highly performant, their application in audio
engineering can be limited due to a number of factors. These include operation
only on speech without support for music, lack of real-time capability, lack of
interpretable control parameters, operation at lower sample rates, and a
tendency to introduce artifacts. On the other hand, signal processing-based
noise reduction algorithms offer fine-grained control and operation on a broad
range of content, however, they often require manual operation to achieve the
best results. To address the limitations of both approaches, in this work we
introduce a method that leverages a signal processing-based denoiser that when
combined with a neural network controller, enables fully automatic and
high-fidelity noise reduction on both speech and music signals. We evaluate our
proposed method with objective metrics and a perceptual listening test. Our
evaluation reveals that speech enhancement models can be extended to music,
however training the model to remove only stationary noise is critical.
Furthermore, our proposed approach achieves performance on par with the deep
learning models, while being significantly more efficient and introducing fewer
artifacts in some cases. Listening examples are available online at
https://tape.it/research/denoiser .
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11365" title="Abstract">arXiv:2310.11365</a> [<a href="/pdf/2310.11365" title="Download PDF">pdf</a>, <a href="/format/2310.11365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monte-Carlo/Moments micro-macro Parareal method for unimodal and bimodal  scalar McKean-Vlasov SDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bossuyt%2C+I">Ignace Bossuyt</a>, 
<a href="/search/math?searchtype=author&query=Vandewalle%2C+S">Stefan Vandewalle</a>, 
<a href="/search/math?searchtype=author&query=Samaey%2C+G">Giovanni Samaey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph); Computation (stat.CO)

</div>
<p class="mathjax">We propose a micro-macro parallel-in-time Parareal method for scalar
McKean-Vlasov stochastic differential equations (SDEs). In the algorithm, the
fine Parareal propagator is a Monte Carlo simulation of an ensemble of
particles, while an approximate ordinary differential equation (ODE)
description of the mean and the variance of the particle distribution is used
as a coarse Parareal propagator to achieve speedup. We analyse the convergence
behaviour of our method for a linear problem and provide numerical experiments
indicating the parallel weak scaling of the algorithm on a set of examples. We
show that convergence typically takes place in a low number of iterations,
depending on the quality of the ODE predictor. For bimodal SDEs, we avoid
quality deterioration of the coarse predictor (compared to unimodal SDEs)
through the usage of multiple ODEs, each describing the mean and variance of
the particle distribution in locally unimodal regions of the phase space. The
benefit of the proposed algorithm can be viewed through two lenses: (i) through
the parallel-in-time lens, speedup is obtained through the use of a very cheap
coarse integrator (an ODE moment model), and (ii) through the moment models
lens, accuracy is iteratively gained through the use of parallel machinery as a
corrector. In contrast to the isolated use of a moment model, the proposed
method (iteratively) converges to the true distribution generated by the SDE.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11366" title="Abstract">arXiv:2310.11366</a> [<a href="/pdf/2310.11366" title="Download PDF">pdf</a>, <a href="/format/2310.11366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lie Group Decompositions for Equivariant Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mironenco%2C+M">Mircea Mironenco</a>, 
<a href="/search/cs?searchtype=author&query=Forr%C3%A9%2C+P">Patrick Forr&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Invariance and equivariance to geometrical transformations have proven to be
very useful inductive biases when training (convolutional) neural network
models, especially in the low-data regime. Much work has focused on the case
where the symmetry group employed is compact or abelian, or both. Recent work
has explored enlarging the class of transformations used to the case of Lie
groups, principally through the use of their Lie algebra, as well as the group
exponential and logarithm maps. The applicability of such methods to larger
transformation groups is limited by the fact that depending on the group of
interest $G$, the exponential map may not be surjective. Further limitations
are encountered when $G$ is neither compact nor abelian. Using the structure
and geometry of Lie groups and their homogeneous spaces, we present a framework
by which it is possible to work with such groups primarily focusing on the Lie
groups $G = \text{GL}^{+}(n, \mathbb{R})$ and $G = \text{SL}(n, \mathbb{R})$,
as well as their representation as affine transformations $\mathbb{R}^{n}
\rtimes G$. Invariant integration as well as a global parametrization is
realized by decomposing the `larger` groups into subgroups and submanifolds
which can be handled individually. Under this framework, we show how
convolution kernels can be parametrized to build models equivariant with
respect to affine transformations. We evaluate the robustness and
out-of-distribution generalisation capability of our model on the standard
affine-invariant benchmark classification task, where we outperform all
previous equivariant models as well as all Capsule Network proposals.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11367" title="Abstract">arXiv:2310.11367</a> [<a href="/pdf/2310.11367" title="Download PDF">pdf</a>, <a href="/format/2310.11367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the Characterization of Terminal Cut Functions: a Condition for  Laminar Families
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zihan Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">We study the following characterization problem. Given a set $T$ of terminals
and a $(2^{|T|}-2)$-dimensional vector $\pi$ whose coordinates are indexed by
proper subsets of $T$, is there a graph $G$ that contains $T$, such that for
all subsets $\emptyset\subsetneq S\subsetneq T$, $\pi_S$ equals the value of
the min-cut in $G$ separating $S$ from $T\setminus S$? The only known necessary
conditions are submodularity and a special class of linear inequalities given
by Chaudhuri, Subrahmanyam, Wagner and Zaroliagis.
<br />Our main result is a new class of linear inequalities concerning laminar
families, that generalize all previous ones. Using our new class of
inequalities, we can generalize Karger's approximate min-cut counting result to
graphs with terminals.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11368" title="Abstract">arXiv:2310.11368</a> [<a href="/pdf/2310.11368" title="Download PDF">pdf</a>, <a href="/format/2310.11368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VECHR: A Dataset for Explainable and Robust Classification of  Vulnerability Type in the European Court of Human Rights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shanshan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Staufer%2C+L">Leon Staufer</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+S+T+Y+S">Santosh T.Y.S.S</a>, 
<a href="/search/cs?searchtype=author&query=Ichim%2C+O">Oana Ichim</a>, 
<a href="/search/cs?searchtype=author&query=Heri%2C+C">Corina Heri</a>, 
<a href="/search/cs?searchtype=author&query=Grabmair%2C+M">Matthias Grabmair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recognizing vulnerability is crucial for understanding and implementing
targeted support to empower individuals in need. This is especially important
at the European Court of Human Rights (ECtHR), where the court adapts
Convention standards to meet actual individual needs and thus ensures effective
human rights protection. However, the concept of vulnerability remains elusive
at the ECtHR and no prior NLP research has dealt with it. To enable future
research in this area, we present VECHR, a novel expert-annotated multi-label
dataset comprising of vulnerability type classification and explanation
rationale. We benchmark the performance of state-of-the-art models on VECHR
from both prediction and explainability perspectives. Our results demonstrate
the challenging nature of the task with lower prediction performance and
limited agreement between models and experts. Further, we analyze the
robustness of these models in dealing with out-of-domain (OOD) data and observe
overall limited performance. Our dataset poses unique challenges offering
significant room for improvement regarding performance, explainability, and
robustness.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11370" title="Abstract">arXiv:2310.11370</a> [<a href="/pdf/2310.11370" title="Download PDF">pdf</a>, <a href="/format/2310.11370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Operator Situation Awareness when Working with AI Recommender  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+D+K">Divya K. Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Lilly%2C+J+M">J. Mason Lilly</a>, 
<a href="/search/cs?searchtype=author&query=Feigh%2C+K+M">Karen M. Feigh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 12 figures, submitted to Springer's "Cognition, Technology, and Work" journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">AI recommender systems are sought for decision support by providing
suggestions to operators responsible for making final decisions. However, these
systems are typically considered black boxes, and are often presented without
any context or insight into the underlying algorithm. As a result, recommender
systems can lead to miscalibrated user reliance and decreased situation
awareness. Recent work has focused on improving the transparency of recommender
systems in various ways such as improving the recommender's analysis and
visualization of the figures of merit, providing explanations for the
recommender's decision, as well as improving user training or calibrating user
trust. In this paper, we introduce an alternative transparency technique of
structuring the order in which contextual information and the recommender's
decision are shown to the human operator. This technique is designed to improve
the operator's situation awareness and therefore the shared situation awareness
between the operator and the recommender system. This paper presents the
results of a two-phase between-subjects study in which participants and a
recommender system jointly make a high-stakes decision. We varied the amount of
contextual information the participant had, the assessment technique of the
figures of merit, and the reliability of the recommender system. We found that
providing contextual information upfront improves the team's shared situation
awareness by improving the human decision maker's initial and final judgment,
as well as their ability to discern the recommender's error boundary.
Additionally, this technique accurately calibrated the human operator's trust
in the recommender. This work proposes and validates a way to provide
model-agnostic transparency into AI systems that can support the human decision
maker and lead to improved team performance.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11372" title="Abstract">arXiv:2310.11372</a> [<a href="/pdf/2310.11372" title="Download PDF">pdf</a>, <a href="/format/2310.11372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Force and Contact Estimation for a Soft-Bubble Visuotactile Sensor  Using FEM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jing-Chen Peng</a> (1), 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shaoxiong Yao</a> (1), 
<a href="/search/cs?searchtype=author&query=Hauser%2C+K">Kris Hauser</a> (1) ((1) Department of Computer Science at the University of Illinois at Urbana-Champaign, Urbana, Illinois, USA.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Soft-bubble tactile sensors have the potential to capture dense contact and
force information across a large contact surface. However, it is difficult to
extract contact forces directly from observing the bubble surface because local
contacts change the global surface shape significantly due to membrane
mechanics and air pressure. This paper presents a model-based method of
reconstructing dense contact forces from the bubble sensor's internal RGBD
camera and air pressure sensor. We present a finite element model of the force
response of the bubble sensor that uses a linear plane stress approximation
that only requires calibrating 3 variables. Our method is shown to reconstruct
normal and shear forces significantly more accurately than the
state-of-the-art, with comparable accuracy for detecting the contact patch, and
with very little calibration data.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11373" title="Abstract">arXiv:2310.11373</a> [<a href="/pdf/2310.11373" title="Download PDF">pdf</a>, <a href="/format/2310.11373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Layer Blockchain Sharding Protocol Leveraging Safety and Liveness  for Enhanced Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yibin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jingyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%BCdder%2C+B">Boris D&#xfc;dder</a>, 
<a href="/search/cs?searchtype=author&query=Slaats%2C+T">Tijs Slaats</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yongluan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted to Network and Distributed System Security (NDSS) Symposium 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Network and Distributed System Security (NDSS) Symposium 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Sharding is essential for improving blockchain scalability. Existing
protocols overlook diverse adversarial attacks, limiting transaction
throughput. This paper presents Reticulum, a groundbreaking sharding protocol
addressing this issue, boosting blockchain scalability.
<br />Reticulum employs a two-phase approach, adapting transaction throughput based
on runtime adversarial attacks. It comprises "control" and "process" shards in
two layers. Process shards contain at least one trustworthy node, while control
shards have a majority of trusted nodes. In the first phase, transactions are
written to blocks and voted on by nodes in process shards. Unanimously accepted
blocks are confirmed. In the second phase, blocks without unanimous acceptance
are voted on by control shards. Blocks are accepted if the majority votes in
favor, eliminating first-phase opponents and silent voters. Reticulum uses
unanimous voting in the first phase, involving fewer nodes, enabling more
parallel process shards. Control shards finalize decisions and resolve
disputes.
<br />Experiments confirm Reticulum's innovative design, providing high transaction
throughput and robustness against various network attacks, outperforming
existing sharding protocols for blockchain networks.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11374" title="Abstract">arXiv:2310.11374</a> [<a href="/pdf/2310.11374" title="Download PDF">pdf</a>, <a href="/format/2310.11374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DialogueLLM: Context and Emotion Knowledge-Tuned LLaMA Models for  Emotion Recognition in Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yazhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+P">Prayag Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiuchi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jing Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) and their variants have shown extraordinary
efficacy across numerous downstream natural language processing (NLP) tasks,
which has presented a new vision for the development of NLP. Despite their
remarkable performance in natural language generating (NLG), LLMs lack a
distinct focus on the emotion understanding domain. As a result, using LLMs for
emotion recognition may lead to suboptimal and inadequate precision. Another
limitation of LLMs is that they are typical trained without leveraging
multi-modal information. To overcome these limitations, we propose DialogueLLM,
a context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA
models with 13,638 multi-modal (i.e., texts and videos) emotional dialogues.
The visual information is considered as the supplementary knowledge to
construct high-quality instructions. We offer a comprehensive evaluation of our
proposed model on three benchmarking emotion recognition in conversations (ERC)
datasets and compare the results against the SOTA baselines and other SOTA
LLMs. Additionally, DialogueLLM-7B can be easily trained using LoRA on a 40GB
A100 GPU in 5 hours, facilitating reproducibility for other researchers.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11377" title="Abstract">arXiv:2310.11377</a> [<a href="/pdf/2310.11377" title="Download PDF">pdf</a>, <a href="/format/2310.11377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Algorithms for Generalized Mean Densest Subgraph Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenglin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Ping Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hanyu Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2106.00909">arXiv:2106.00909</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">The densest subgraph of a large graph usually refers to some subgraph with
the highest average degree, which has been extended to the family of $p$-means
dense subgraph objectives by~\citet{veldt2021generalized}. The $p$-mean densest
subgraph problem seeks a subgraph with the highest average $p$-th-power degree,
whereas the standard densest subgraph problem seeks a subgraph with a simple
highest average degree. It was shown that the standard peeling algorithm can
perform arbitrarily poorly on generalized objective when $p&gt;1$ but uncertain
when $0&lt;p&lt;1$. In this paper, we are the first to show that a standard peeling
algorithm can still yield $2^{1/p}$-approximation for the case $0&lt;p &lt; 1$.
(Veldt 2021) proposed a new generalized peeling algorithm (GENPEEL), which for
$p \geq 1$ has an approximation guarantee ratio $(p+1)^{1/p}$, and time
complexity $O(mn)$, where $m$ and $n$ denote the number of edges and nodes in
graph respectively. In terms of algorithmic contributions, we propose a new and
faster generalized peeling algorithm (called GENPEEL++ in this paper), which
for $p \in [1, +\infty)$ has an approximation guarantee ratio $(2(p+1))^{1/p}$,
and time complexity $O(m(\log n))$, where $m$ and $n$ denote the number of
edges and nodes in graph, respectively. This approximation ratio converges to 1
as $p \rightarrow \infty$.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11379" title="Abstract">arXiv:2310.11379</a> [<a href="/pdf/2310.11379" title="Download PDF">pdf</a>, <a href="/format/2310.11379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Wake-Up Word Detection by Two-stage Multi-resolution Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+F">Fernando L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Luque%2C+J">Jordi Luque</a>, 
<a href="/search/cs?searchtype=author&query=Segura%2C+C">Carlos Segura</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+P">Pablo G&#xf3;mez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Voice-based interfaces rely on a wake-up word mechanism to initiate
communication with devices. However, achieving a robust, energy-efficient, and
fast detection remains a challenge. This paper addresses these real production
needs by enhancing data with temporal alignments and using detection based on
two phases with multi-resolution. It employs two models: a lightweight
on-device model for real-time processing of the audio stream and a verification
model on the server-side, which is an ensemble of heterogeneous architectures
that refine detection. This scheme allows the optimization of two operating
points. To protect privacy, audio features are sent to the cloud instead of raw
audio. The study investigated different parametric configurations for feature
extraction to select one for on-device detection and another for the
verification model. Furthermore, thirteen different audio classifiers were
compared in terms of performance and inference time. The proposed ensemble
outperforms our stronger classifier in every noise condition.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11385" title="Abstract">arXiv:2310.11385</a> [<a href="/pdf/2310.11385" title="Download PDF">pdf</a>, <a href="/format/2310.11385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A voxel-level approach to brain age prediction: A method to assess  regional brain aging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gianchandani%2C+N">Neha Gianchandani</a>, 
<a href="/search/cs?searchtype=author&query=Dibaji%2C+M">Mahsa Dibaji</a>, 
<a href="/search/cs?searchtype=author&query=Ospel%2C+J">Johanna Ospel</a>, 
<a href="/search/cs?searchtype=author&query=Vega%2C+F">Fernando Vega</a>, 
<a href="/search/cs?searchtype=author&query=Bento%2C+M">Mariana Bento</a>, 
<a href="/search/cs?searchtype=author&query=MacDonald%2C+M+E">M. Ethan MacDonald</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+R">Roberto Souza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, submitted to MELBA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Brain aging is a regional phenomenon, a facet that remains relatively
under-explored within the realm of brain age prediction research using machine
learning methods. Voxel-level predictions can provide localized brain age
estimates that can provide granular insights into the regional aging processes.
This is essential to understand the differences in aging trajectories in
healthy versus diseased subjects. In this work, a deep learning-based multitask
model is proposed for voxel-level brain age prediction from T1-weighted
magnetic resonance images. The proposed model outperforms the models existing
in the literature and yields valuable clinical insights when applied to both
healthy and diseased populations. Regional analysis is performed on the
voxel-level brain age predictions to understand aging trajectories of known
anatomical regions in the brain and show that there exist disparities in
regional aging trajectories of healthy subjects compared to ones with
underlying neurological disorders such as Dementia and more specifically,
Alzheimer's disease. Our code is available at
https://github.com/nehagianchandani/Voxel-level-brain-age-prediction.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11386" title="Abstract">arXiv:2310.11386</a> [<a href="/pdf/2310.11386" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Operationalizing Social Bonding in Human-Robot Dyads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+I">Imran Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">With momentum increasing in the use of social robots as long-term assistive
and collaborative partners, humans developing social bonds with these
artificial agents appears to be inevitable. In human-human dyads, social
bonding plays a powerful role in regulating behaviours, emotions, and even
health. If this is to extend to human-robot dyads, the phenomenology of such
relationships (including their emergence and stability) must be better
understood. In this paper, we discuss potential approaches towards
operationalizing the phenomenon of social bonding between human-robot dyads. We
will discuss a number of biobehavioural proxies of social bonding, moving away
from existing approaches that use subjective, psychological measures, and
instead grounding our approach in some of the evolutionary, neurobiological and
physiological correlates of social bond formation in natural systems: (a)
reductions in physiological stress (the ''social buffering'' phenomenon), (b)
narrowing of spatial proximity between dyads, and (c) inter-dyad behavioural
synchrony. We provide relevant evolutionary support for each proposed
component, with suggestions and considerations for how they can be recorded in
(real-time) human-robot interaction scenarios. With this, we aim to inspire
more robust operationalisation of ''social bonding'' between human and
artificial (robotic) agents.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11389" title="Abstract">arXiv:2310.11389</a> [<a href="/pdf/2310.11389" title="Download PDF">pdf</a>, <a href="/ps/2310.11389" title="Download PostScript">ps</a>, <a href="/format/2310.11389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VaR\ and CVaR Estimation in a Markov Cost Process: Lower and Upper  Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhat%2C+S">Sanjay Bhat</a>, 
<a href="/search/cs?searchtype=author&query=A.%2C+P+L">Prashanth L.A.</a>, 
<a href="/search/cs?searchtype=author&query=Thoppe%2C+G">Gugan Thoppe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We tackle the problem of estimating the Value-at-Risk (VaR) and the
Conditional Value-at-Risk (CVaR) of the infinite-horizon discounted cost within
a Markov cost process. First, we derive a minimax lower bound of
$\Omega(1/\sqrt{n})$ that holds both in an expected and in a probabilistic
sense. Then, using a finite-horizon truncation scheme, we derive an upper bound
for the error in CVaR estimation, which matches our lower bound up to constant
factors. Finally, we discuss an extension of our estimation scheme that covers
more general risk measures satisfying a certain continuity criterion, e.g.,
spectral risk measures, utility-based shortfall risk. To the best of our
knowledge, our work is the first to provide lower and upper bounds on the
estimation error for any risk measure within Markovian settings. We remark that
our lower bounds also extend to the infinite-horizon discounted costs' mean.
Even in that case, our result $\Omega(1/\sqrt{n}) $ improves upon the existing
result $\Omega(1/n)$[13].
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11392" title="Abstract">arXiv:2310.11392</a> [<a href="/pdf/2310.11392" title="Download PDF">pdf</a>, <a href="/format/2310.11392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Satellite Images Captions Generation Using Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yingxu He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiqi Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Automatic image captioning is a promising technique for conveying visual
information using natural language. It can benefit various tasks in satellite
remote sensing, such as environmental monitoring, resource management, disaster
management, etc. However, one of the main challenges in this domain is the lack
of large-scale image-caption datasets, as they require a lot of human expertise
and effort to create. Recent research on large language models (LLMs) has
demonstrated their impressive performance in natural language understanding and
generation tasks. Nonetheless, most of them cannot handle images (GPT-3.5,
Falcon, Claude, etc.), while conventional captioning models pre-trained on
general ground-view images often fail to produce detailed and accurate captions
for aerial images (BLIP, GIT, CM3, CM3Leon, etc.). To address this problem, we
propose a novel approach: Automatic Remote Sensing Image Captioning (ARSIC) to
automatically collect captions for remote sensing images by guiding LLMs to
describe their object annotations. We also present a benchmark model that
adapts the pre-trained generative image2text model (GIT) to generate
high-quality captions for remote-sensing images. Our evaluation demonstrates
the effectiveness of our approach for collecting captions for remote sensing
images.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11397" title="Abstract">arXiv:2310.11397</a> [<a href="/pdf/2310.11397" title="Download PDF">pdf</a>, <a href="/format/2310.11397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Last One Standing: A Comparative Analysis of Security and Privacy of  Soft Prompt Tuning, LoRA, and In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+R">Rui Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Salem%2C+A">Ahmed Salem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) are powerful tools for natural language
processing, enabling novel applications and user experiences. However, to
achieve optimal performance, LLMs often require adaptation with private data,
which poses privacy and security challenges. Several techniques have been
proposed to adapt LLMs with private data, such as Low-Rank Adaptation (LoRA),
Soft Prompt Tuning (SPT), and In-Context Learning (ICL), but their comparative
privacy and security properties have not been systematically investigated. In
this work, we fill this gap by evaluating the robustness of LoRA, SPT, and ICL
against three types of well-established attacks: membership inference, which
exposes data leakage (privacy); backdoor, which injects malicious behavior
(security); and model stealing, which can violate intellectual property
(privacy and security). Our results show that there is no silver bullet for
privacy and security in LLM adaptation and each technique has different
strengths and weaknesses.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11398" title="Abstract">arXiv:2310.11398</a> [<a href="/pdf/2310.11398" title="Download PDF">pdf</a>, <a href="/format/2310.11398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Attention: Enhancing QKV Calculation in Self-Attention Mechanism  with Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of deep learning, the self-attention mechanism has substantiated
its pivotal role across a myriad of tasks, encompassing natural language
processing and computer vision. Despite achieving success across diverse
applications, the traditional self-attention mechanism primarily leverages
linear transformations for the computation of query, key, and value (QKV),
which may not invariably be the optimal choice under specific circumstances.
This paper probes into a novel methodology for QKV computation-implementing a
specially-designed neural network structure for the calculation. Utilizing a
modified Marian model, we conducted experiments on the IWSLT 2017
German-English translation task dataset and juxtaposed our method with the
conventional approach. The experimental results unveil a significant
enhancement in BLEU scores with our method. Furthermore, our approach also
manifested superiority when training the Roberta model with the Wikitext-103
dataset, reflecting a notable reduction in model perplexity compared to its
original counterpart. These experimental outcomes not only validate the
efficacy of our method but also reveal the immense potential in optimizing the
self-attention mechanism through neural network-based QKV computation, paving
the way for future research and practical applications. The source code and
implementation details for our proposed method can be accessed at
https://github.com/ocislyjrti/NeuralAttention.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11401" title="Abstract">arXiv:2310.11401</a> [<a href="/pdf/2310.11401" title="Download PDF">pdf</a>, <a href="/format/2310.11401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Group Fairness in Online Settings Using Oblique Decision  Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S+B+R">Somnath Basu Roy Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Monath%2C+N">Nicholas Monath</a>, 
<a href="/search/cs?searchtype=author&query=Beirami%2C+A">Ahmad Beirami</a>, 
<a href="/search/cs?searchtype=author&query=Kidambi%2C+R">Rahul Kidambi</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Avinava Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A">Amr Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Chaturvedi%2C+S">Snigdha Chaturvedi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Fairness, especially group fairness, is an important consideration in the
context of machine learning systems. The most commonly adopted group
fairness-enhancing techniques are in-processing methods that rely on a mixture
of a fairness objective (e.g., demographic parity) and a task-specific
objective (e.g., cross-entropy) during the training process. However, when data
arrives in an online fashion -- one instance at a time -- optimizing such
fairness objectives poses several challenges. In particular, group fairness
objectives are defined using expectations of predictions across different
demographic groups. In the online setting, where the algorithm has access to a
single instance at a time, estimating the group fairness objective requires
additional storage and significantly more computation (e.g., forward/backward
passes) than the task-specific objective at every time step. In this paper, we
propose Aranyani, an ensemble of oblique decision trees, to make fair decisions
in online settings. The hierarchical tree structure of Aranyani enables
parameter isolation and allows us to efficiently compute the fairness gradients
using aggregate statistics of previous decisions, eliminating the need for
additional storage and forward/backward passes. We also present an efficient
framework to train Aranyani and theoretically analyze several of its
properties. We conduct empirical evaluations on 5 publicly available benchmarks
(including vision and language datasets) to show that Aranyani achieves a
better accuracy-fairness trade-off compared to baseline approaches.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11405" title="Abstract">arXiv:2310.11405</a> [<a href="/pdf/2310.11405" title="Download PDF">pdf</a>, <a href="/format/2310.11405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Coherence-based Predictors for Dense Query Performance Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vlachou%2C+M">Maria Vlachou</a>, 
<a href="/search/cs?searchtype=author&query=Macdonald%2C+C">Craig Macdonald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Query Performance Prediction (QPP) estimates the effectiveness of a search
engine's results in response to a query without relevance judgments.
Traditionally, post-retrieval predictors have focused upon either the
distribution of the retrieval scores, or the coherence of the top-ranked
documents using traditional bag-of-words index representations. More recently,
BERT-based models using dense embedded document representations have been used
to create new predictors, but mostly applied to predict the performance of
rankings created by BM25. Instead, we aim to predict the effectiveness of
rankings created by single-representation dense retrieval models (ANCE &amp;
TCT-ColBERT). Therefore, we propose a number of variants of existing
unsupervised coherence-based predictors that employ neural embedding
representations. In our experiments on the TREC Deep Learning Track datasets,
we demonstrate improved accuracy upon dense retrieval (up to 92% compared to
sparse variants for TCT-ColBERT and 188% for ANCE). Going deeper, we select the
most representative and best performing predictors to study the importance of
differences among predictors and query types on query performance. Using
existing distribution-based evaluation QPP measures and a particular type of
linear mixed models, we find that query types further significantly influence
query performance (and are up to 35% responsible for the unstable performance
of QPP predictors), and that this sensitivity is unique to dense retrieval
models. Our approach introduces a new setting for obtaining richer information
on query differences in dense QPP that can explain potential unstable
performance of existing predictors and outlines the unique characteristics of
different query types on dense retrieval models.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11406" title="Abstract">arXiv:2310.11406</a> [<a href="/pdf/2310.11406" title="Download PDF">pdf</a>, <a href="/format/2310.11406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GreenNFV: Energy-Efficient Network Function Virtualization with Service  Level Agreement Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nine%2C+M+S+Q+Z">MD S Q Zulkar Nine</a>, 
<a href="/search/cs?searchtype=author&query=Kosar%2C+T">Tevfik Kosar</a>, 
<a href="/search/cs?searchtype=author&query=Bulut%2C+F">Fatih Bulut</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jinho Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Network Function Virtualization (NFV) platforms consume significant energy,
introducing high operational costs in edge and data centers. This paper
presents a novel framework called GreenNFV that optimizes resource usage for
network function chains using deep reinforcement learning. GreenNFV optimizes
resource parameters such as CPU sharing ratio, CPU frequency scaling,
last-level cache (LLC) allocation, DMA buffer size, and packet batch size.
GreenNFV learns the resource scheduling model from the benchmark experiments
and takes Service Level Agreements (SLAs) into account to optimize resource
usage models based on the different throughput and energy consumption
requirements. Our evaluation shows that GreenNFV models achieve high transfer
throughput and low energy consumption while satisfying various SLA constraints.
Specifically, GreenNFV with Throughput SLA can achieve $4.4\times$ higher
throughput and $1.5\times$ better energy efficiency over the baseline settings,
whereas GreenNFV with Energy SLA can achieve $3\times$ higher throughput while
reducing energy consumption by 50%.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11407" title="Abstract">arXiv:2310.11407</a> [<a href="/pdf/2310.11407" title="Download PDF">pdf</a>, <a href="/format/2310.11407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group-blind optimal transport to group parity and its constrained  variants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Quan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Marecek%2C+J">Jakub Marecek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Fairness holds a pivotal role in the realm of machine learning, particularly
when it comes to addressing groups categorised by sensitive attributes, e.g.,
gender, race. Prevailing algorithms in fair learning predominantly hinge on
accessibility or estimations of these sensitive attributes, at least in the
training process. We design a single group-blind projection map that aligns the
feature distributions of both groups in the source data, achieving
(demographic) group parity, without requiring values of the protected attribute
for individual samples in the computation of the map, as well as its use.
Instead, our approach utilises the feature distributions of the privileged and
unprivileged groups in a boarder population and the essential assumption that
the source data are unbiased representation of the population. We present
numerical results on synthetic data and real data.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11409" title="Abstract">arXiv:2310.11409</a> [<a href="/pdf/2310.11409" title="Download PDF">pdf</a>, <a href="/format/2310.11409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating LLMs for Privilege-Escalation Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Happe%2C+A">Andreas Happe</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+A">Aaron Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Cito%2C+J">J&#xfc;rgen Cito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Penetration testing, an essential component of cybersecurity, allows
organizations to proactively identify and remediate vulnerabilities in their
systems, thus bolstering their defense mechanisms against potential
cyberattacks. One recent advancement in the realm of penetration testing is the
utilization of Language Models (LLMs). We explore the intersection of LLMs and
penetration testing to gain insight into their capabilities and challenges in
the context of privilige escalation. We create an automated Linux
privilege-escalation benchmark utilizing local virtual machines. We introduce
an LLM-guided privilege-escalation tool designed for evaluating different LLMs
and prompt strategies against our benchmark. We analyze the impact of different
prompt designs, the benefits of in-context learning, and the advantages of
offering high-level guidance to LLMs. We discuss challenging areas for LLMs,
including maintaining focus during testing, coping with errors, and finally
comparing them with both stochastic parrots as well as with human hackers.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11417" title="Abstract">arXiv:2310.11417</a> [<a href="/pdf/2310.11417" title="Download PDF">pdf</a>, <a href="/format/2310.11417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VcT: Visual change Transformer for Remote Sensing Image Change Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zitian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xixi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing visual change detectors usually adopt CNNs or Transformers for
feature representation learning and focus on learning effective representation
for the changed regions between images. Although good performance can be
obtained by enhancing the features of the change regions, however, these works
are still limited mainly due to the ignorance of mining the unchanged
background context information. It is known that one main challenge for change
detection is how to obtain the consistent representations for two images
involving different variations, such as spatial variation, sunlight intensity,
etc. In this work, we demonstrate that carefully mining the common background
information provides an important cue to learn the consistent representations
for the two images which thus obviously facilitates the visual change detection
problem. Based on this observation, we propose a novel Visual change
Transformer (VcT) model for visual change detection problem. To be specific, a
shared backbone network is first used to extract the feature maps for the given
image pair. Then, each pixel of feature map is regarded as a graph node and the
graph neural network is proposed to model the structured information for coarse
change map prediction. Top-K reliable tokens can be mined from the map and
refined by using the clustering algorithm. Then, these reliable tokens are
enhanced by first utilizing self/cross-attention schemes and then interacting
with original features via an anchor-primary attention learning module.
Finally, the prediction head is proposed to get a more accurate change map.
Extensive experiments on multiple benchmark datasets validated the
effectiveness of our proposed VcT model.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11420" title="Abstract">arXiv:2310.11420</a> [<a href="/pdf/2310.11420" title="Download PDF">pdf</a>, <a href="/format/2310.11420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Map Relations for Unsupervised Non-Rigid Shape Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Dongliang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Roetzer%2C+P">Paul Roetzer</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+F">Florian Bernard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3DV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We propose a novel unsupervised learning approach for non-rigid 3D shape
matching. Our approach improves upon recent state-of-the art deep functional
map methods and can be applied to a broad range of different challenging
scenarios. Previous deep functional map methods mainly focus on feature
extraction and aim exclusively at obtaining more expressive features for
functional map computation. However, the importance of the functional map
computation itself is often neglected and the relationship between the
functional map and point-wise map is underexplored. In this paper, we
systematically investigate the coupling relationship between the functional map
from the functional map solver and the point-wise map based on feature
similarity. To this end, we propose a self-adaptive functional map solver to
adjust the functional map regularisation for different shape matching
scenarios, together with a vertex-wise contrastive loss to obtain more
discriminative features. Using different challenging datasets (including
non-isometry, topological noise and partiality), we demonstrate that our method
substantially outperforms previous state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11426" title="Abstract">arXiv:2310.11426</a> [<a href="/pdf/2310.11426" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Underwater and Surface Aquatic Locomotion of Soft Biomimetic Robot Based  on Bending Rolled Dielectric Elastomer Actuators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+J">Juntian Qu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xiang Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">All-around, real-time navigation and sensing across the water environments by
miniature soft robotics are promising, for their merits of small size, high
agility and good compliance to the unstructured surroundings. In this paper, we
propose and demonstrate a mantas-like soft aquatic robot which propels itself
by flapping-fins using rolled dielectric elastomer actuators (DEAs) with
bending motions. This robot exhibits fast-moving capabilities of swimming at
57mm/s or 1.25 body length per second (BL/s), skating on water surface at 64
mm/s (1.36 BL/s) and vertical ascending at 38mm/s (0.82 BL/s) at 1300 V, 17 Hz
of the power supply. These results show the feasibility of adopting rolled DEAs
for mesoscale aquatic robots with high motion performance in various
water-related scenarios.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11428" title="Abstract">arXiv:2310.11428</a> [<a href="/pdf/2310.11428" title="Download PDF">pdf</a>, <a href="/format/2310.11428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning  and Autoregression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Block%2C+A">Adam Block</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+D+J">Dylan J. Foster</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+A">Akshay Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Simchowitz%2C+M">Max Simchowitz</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cyril Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">This work studies training instabilities of behavior cloning with deep neural
networks. We observe that minibatch SGD updates to the policy network during
training result in sharp oscillations in long-horizon rewards, despite
negligibly affecting the behavior cloning loss. We empirically disentangle the
statistical and computational causes of these oscillations, and find them to
stem from the chaotic propagation of minibatch SGD noise through unstable
closed-loop dynamics. While SGD noise is benign in the single-step action
prediction objective, it results in catastrophic error accumulation over long
horizons, an effect we term gradient variance amplification (GVA). We show that
many standard mitigation techniques do not alleviate GVA, but find an
exponential moving average (EMA) of iterates to be surprisingly effective at
doing so. We illustrate the generality of this phenomenon by showing the
existence of GVA and its amelioration by EMA in both continuous control and
autoregressive language generation. Finally, we provide theoretical vignettes
that highlight the benefits of EMA in alleviating GVA and shed light on the
extent to which classical convex models can help in understanding the benefits
of iterate averaging in deep learning.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11430" title="Abstract">arXiv:2310.11430</a> [<a href="/pdf/2310.11430" title="Download PDF">pdf</a>, <a href="/format/2310.11430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Translation Hypothesis Ensembling with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farinhas%2C+A">Ant&#xf3;nio Farinhas</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza%2C+J+G+C">Jos&#xe9; G. C. de Souza</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+A+F+T">Andr&#xe9; F. T. Martins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (main conference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) are becoming a one-fits-many solution, but they
sometimes hallucinate or produce unreliable output. In this paper, we
investigate how hypothesis ensembling can improve the quality of the generated
text for the specific problem of LLM-based machine translation. We experiment
with several techniques for ensembling hypotheses produced by LLMs such as
ChatGPT, LLaMA, and Alpaca. We provide a comprehensive study along multiple
dimensions, including the method to generate hypotheses (multiple prompts,
temperature-based sampling, and beam search) and the strategy to produce the
final translation (instruction-based, quality-based reranking, and minimum
Bayes risk (MBR) decoding). Our results show that MBR decoding is a very
effective method, that translation quality can be improved using a small number
of samples, and that instruction tuning has a strong impact on the relation
between the diversity of the hypotheses and the sampling temperature.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11436" title="Abstract">arXiv:2310.11436</a> [<a href="/pdf/2310.11436" title="Download PDF">pdf</a>, <a href="/format/2310.11436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sadness, Anger, or Anxiety: Twitter Users&#x27; Emotional Responses to  Toxicity in Public Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aleksandric%2C+A">Ana Aleksandric</a>, 
<a href="/search/cs?searchtype=author&query=Pankaj%2C+H">Hanani Pankaj</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+G+M">Gabriela Mustata Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Nilizadeh%2C+S">Shirin Nilizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Cyberbullying and online harassment have serious negative psychological and
emotional consequences for the victims, such as decreased life satisfaction,
suicidal ideation, self-harming behaviors, depression, anxiety, and others.
Most of the prior works assessed people's emotional responses via
questionnaires, while social media platforms contain data that could provide
valuable insights into users' emotions in real online discussions. Therefore,
this data-driven study investigates the effect of toxicity on Twitter users'
emotions and other factors associated with expressing anger, anxiety, and
sadness in terms of account identifiability, activity, conversation structure,
and conversation topic. To achieve this goal, we identified toxic replies in
the large dataset consisting of 79,799 random Twitter conversations and
obtained the emotions expressed in these conversations. Then, we performed
propensity score matching and analyzed causal associations between toxicity and
users' emotions. In general, we found that users receiving toxic replies are
more likely to express emotions of anger, sadness, and anxiety compared to
users who did not receive toxic replies. Finally, analysis results indicate
that the conversation topic and users' account characteristics are likely to
affect their emotional responses to toxicity. Our findings provide a better
understanding of toxic replies' consequences on users' emotional states, which
can potentially lead to developing personalized moderation methods that will
help users emotionally cope with toxicity on social media.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11439" title="Abstract">arXiv:2310.11439</a> [<a href="/pdf/2310.11439" title="Download PDF">pdf</a>, <a href="/format/2310.11439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding deep neural networks through the lens of their  non-linearity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouniot%2C+Q">Quentin Bouniot</a>, 
<a href="/search/cs?searchtype=author&query=Redko%2C+I">Ievgen Redko</a>, 
<a href="/search/cs?searchtype=author&query=Mallasto%2C+A">Anton Mallasto</a>, 
<a href="/search/cs?searchtype=author&query=Laclau%2C+C">Charlotte Laclau</a>, 
<a href="/search/cs?searchtype=author&query=Arndt%2C+K">Karol Arndt</a>, 
<a href="/search/cs?searchtype=author&query=Struckmeier%2C+O">Oliver Struckmeier</a>, 
<a href="/search/cs?searchtype=author&query=Heinonen%2C+M">Markus Heinonen</a>, 
<a href="/search/cs?searchtype=author&query=Kyrki%2C+V">Ville Kyrki</a>, 
<a href="/search/cs?searchtype=author&query=Kaski%2C+S">Samuel Kaski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">The remarkable success of deep neural networks (DNN) is often attributed to
their high expressive power and their ability to approximate functions of
arbitrary complexity. Indeed, DNNs are highly non-linear models, and activation
functions introduced into them are largely responsible for this. While many
works studied the expressive power of DNNs through the lens of their
approximation capabilities, quantifying the non-linearity of DNNs or of
individual activation functions remains an open problem. In this paper, we
propose the first theoretically sound solution to track non-linearity
propagation in deep neural networks with a specific focus on computer vision
applications. Our proposed affinity score allows us to gain insights into the
inner workings of a wide range of different architectures and learning
paradigms. We provide extensive experimental results that highlight the
practical utility of the proposed affinity score and its potential for
long-reaching applications.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11440" title="Abstract">arXiv:2310.11440</a> [<a href="/pdf/2310.11440" title="Download PDF">pdf</a>, <a href="/format/2310.11440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EvalCrafter: Benchmarking and Evaluating Large Video Generation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaofang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuebo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+R">Raymond Chan</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The vision and language generative models have been overgrown in recent
years. For video generation, various open-sourced models and public-available
services are released for generating high-visual quality videos. However, these
methods often use a few academic metrics, for example, FVD or IS, to evaluate
the performance. We argue that it is hard to judge the large conditional
generative models from the simple metrics since these models are often trained
on very large datasets with multi-aspect abilities. Thus, we propose a new
framework and pipeline to exhaustively evaluate the performance of the
generated videos. To achieve this, we first conduct a new prompt list for
text-to-video generation by analyzing the real-world prompt list with the help
of the large language model. Then, we evaluate the state-of-the-art video
generative models on our carefully designed benchmarks, in terms of visual
qualities, content qualities, motion qualities, and text-caption alignment with
around 18 objective metrics. To obtain the final leaderboard of the models, we
also fit a series of coefficients to align the objective metrics to the users'
opinions. Based on the proposed opinion alignment method, our final score shows
a higher correlation than simply averaging the metrics, showing the
effectiveness of the proposed evaluation method.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11441" title="Abstract">arXiv:2310.11441</a> [<a href="/pdf/2310.11441" title="Download PDF">pdf</a>, <a href="/format/2310.11441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xueyan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We present Set-of-Mark (SoM), a new visual prompting method, to unleash the
visual grounding abilities of large multimodal models (LMMs), such as GPT-4V.
As illustrated in Fig. 1 (right), we employ off-the-shelf interactive
segmentation models, such as SAM, to partition an image into regions at
different levels of granularity, and overlay these regions with a set of marks
e.g., alphanumerics, masks, boxes. Using the marked image as input, GPT-4V can
answer the questions that require visual grounding. We perform a comprehensive
empirical study to validate the effectiveness of SoM on a wide range of
fine-grained vision and multimodal tasks. For example, our experiments show
that GPT-4V with SoM outperforms the state-of-the-art fully-finetuned referring
segmentation model on RefCOCOg in a zero-shot setting.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11442" title="Abstract">arXiv:2310.11442</a> [<a href="/pdf/2310.11442" title="Download PDF">pdf</a>, <a href="/format/2310.11442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trusted Provenance of Automated, Collaborative and Adaptive Data  Processing Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stage%2C+L">Ludwig Stage</a>, 
<a href="/search/cs?searchtype=author&query=Karastoyanova%2C+D">Dimka Karastoyanova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">To benefit from the abundance of data and the insights it brings data
processing pipelines are being used in many areas of research and development
in both industry and academia. One approach to automating data processing
pipelines is the workflow technology, as it also supports collaborative,
trial-and-error experimentation with the pipeline architecture in different
application domains. In addition to the necessary flexibility that such
pipelines need to possess, in collaborative settings cross-organisational
interactions are plagued by lack of trust. While capturing provenance
information related to the pipeline execution and the processed data is a first
step towards enabling trusted collaborations, the current solutions do not
allow for provenance of the change in the processing pipelines, where the
subject of change can be made on any aspect of the workflow implementing the
pipeline and on the data used while the pipeline is being executed. Therefore
in this work we provide a solution architecture and a proof of concept
implementation of a service, called Provenance Holder, which enable provenance
of collaborative, adaptive data processing pipelines in a trusted manner. We
also contribute a definition of a set of properties of such a service and
identify future research directions.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11446" title="Abstract">arXiv:2310.11446</a> [<a href="/pdf/2310.11446" title="Download PDF">pdf</a>, <a href="/format/2310.11446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Invariants to Watermark Large Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pierre%2C+F">Fernandez Pierre</a>, 
<a href="/search/cs?searchtype=author&query=Guillaume%2C+C">Couairon Guillaume</a>, 
<a href="/search/cs?searchtype=author&query=Teddy%2C+F">Furon Teddy</a>, 
<a href="/search/cs?searchtype=author&query=Matthijs%2C+D">Douze Matthijs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The rapid growth of transformer-based models increases the concerns about
their integrity and ownership insurance. Watermarking addresses this issue by
embedding a unique identifier into the model, while preserving its performance.
However, most existing approaches require to optimize the weights to imprint
the watermark signal, which is not suitable at scale due to the computational
cost. This paper explores watermarks with virtually no computational cost,
applicable to a non-blind white-box setting (assuming access to both the
original and watermarked networks). They generate functionally equivalent
copies by leveraging the models' invariance, via operations like dimension
permutations or scaling/unscaling. This enables to watermark models without any
change in their outputs and remains stealthy. Experiments demonstrate the
effectiveness of the approach and its robustness against various model
transformations (fine-tuning, quantization, pruning), making it a practical
solution to protect the integrity of large models.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11447" title="Abstract">arXiv:2310.11447</a> [<a href="/pdf/2310.11447" title="Download PDF">pdf</a>, <a href="/ps/2310.11447" title="Download PostScript">ps</a>, <a href="/format/2310.11447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nondango is NP-Complete
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruangwises%2C+S">Suthee Ruangwises</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Nondango is a pencil puzzle consisting of a rectangular grid partitioned into
regions, with some cells containing a white circle. The player has to color
some circles black such that every region contains exactly one black circle,
and there are no three consecutive circles (horizontally, vertically, or
diagonally) with the same color. In this paper, we prove that deciding the
solvability of a given Nondango puzzle is NP-complete.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11448" title="Abstract">arXiv:2310.11448</a> [<a href="/pdf/2310.11448" title="Download PDF">pdf</a>, <a href="/format/2310.11448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4K4D: Real-Time 4D View Synthesis at 4K Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Sida Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haotong Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+G">Guangzhao He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiaming Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Hujun Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaowei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://zju3dv.github.io/4k4d">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper targets high-fidelity and real-time view synthesis of dynamic 3D
scenes at 4K resolution. Recently, some methods on dynamic view synthesis have
shown impressive rendering quality. However, their speed is still limited when
rendering high-resolution images. To overcome this problem, we propose 4K4D, a
4D point cloud representation that supports hardware rasterization and enables
unprecedented rendering speed. Our representation is built on a 4D feature grid
so that the points are naturally regularized and can be robustly optimized. In
addition, we design a novel hybrid appearance model that significantly boosts
the rendering quality while preserving efficiency. Moreover, we develop a
differentiable depth peeling algorithm to effectively learn the proposed model
from RGB videos. Experiments show that our representation can be rendered at
over 400 FPS on the DNA-Rendering dataset at 1080p resolution and 80 FPS on the
ENeRF-Outdoor dataset at 4K resolution using an RTX 4090 GPU, which is 30x
faster than previous methods and achieves the state-of-the-art rendering
quality. We will release the code for reproducibility.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11449" title="Abstract">arXiv:2310.11449</a> [<a href="/pdf/2310.11449" title="Download PDF">pdf</a>, <a href="/format/2310.11449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DELIFFAS: Deformable Light Fields for Fast Avatar Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+Y">Youngjoong Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fuchs%2C+H">Henry Fuchs</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+M">Marc Habermann</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Generating controllable and photorealistic digital human avatars is a
long-standing and important problem in Vision and Graphics. Recent methods have
shown great progress in terms of either photorealism or inference speed while
the combination of the two desired properties still remains unsolved. To this
end, we propose a novel method, called DELIFFAS, which parameterizes the
appearance of the human as a surface light field that is attached to a
controllable and deforming human mesh model. At the core, we represent the
light field around the human with a deformable two-surface parameterization,
which enables fast and accurate inference of the human appearance. This allows
perceptual supervision on the full image compared to previous approaches that
could only supervise individual pixels or small patches due to their slow
runtime. Our carefully designed human representation and supervision strategy
leads to state-of-the-art synthesis results and inference time. The video
results and code are available at
https://vcai.mpi-inf.mpg.de/projects/DELIFFAS.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11450" title="Abstract">arXiv:2310.11450</a> [<a href="/pdf/2310.11450" title="Download PDF">pdf</a>, <a href="/format/2310.11450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining Deep Neural Networks for Bearing Fault Detection with  Vibration Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Decker%2C+T">Thomas Decker</a>, 
<a href="/search/cs?searchtype=author&query=Lebacher%2C+M">Michael Lebacher</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE 21st International Conference on Industrial Informatics (INDIN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Concept-based explanation methods, such as Concept Activation Vectors, are
potent means to quantify how abstract or high-level characteristics of input
data influence the predictions of complex deep neural networks. However,
applying them to industrial prediction problems is challenging as it is not
immediately clear how to define and access appropriate concepts for individual
use cases and specific data types. In this work, we investigate how to leverage
established concept-based explanation techniques in the context of bearing
fault detection with deep neural networks trained on vibration signals. Since
bearings are prevalent in almost every rotating equipment, ensuring the
reliability of intransparent fault detection models is crucial to prevent
costly repairs and downtimes of industrial machinery. Our evaluations
demonstrate that explaining opaque models in terms of vibration concepts
enables human-comprehensible and intuitive insights about their inner workings,
but the underlying assumptions need to be carefully validated first.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11451" title="Abstract">arXiv:2310.11451</a> [<a href="/pdf/2310.11451" title="Download PDF">pdf</a>, <a href="/format/2310.11451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from  a Parametric Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Ming Zhong</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+C">Chenxin An</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengcheng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) inherently encode a wealth of knowledge within
their parameters through pre-training on extensive corpora. While prior
research has delved into operations on these parameters to manipulate the
underlying implicit knowledge (encompassing detection, editing, and merging),
there remains an ambiguous understanding regarding their transferability across
models with varying scales. In this paper, we seek to empirically investigate
knowledge transfer from larger to smaller models through a parametric
perspective. To achieve this, we employ sensitivity-based techniques to extract
and align knowledge-specific parameters between different LLMs. Moreover, the
LoRA module is used as the intermediary mechanism for injecting the extracted
knowledge into smaller models. Evaluations across four benchmarks validate the
efficacy of our proposed method. Our findings highlight the critical factors
contributing to the process of parametric knowledge transfer, underscoring the
transferability of model parameters across LLMs of different scales. We release
code and data at \url{https://github.com/maszhongming/ParaKnowTransfer}.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11453" title="Abstract">arXiv:2310.11453</a> [<a href="/pdf/2310.11453" title="Download PDF">pdf</a>, <a href="/format/2310.11453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BitNet: Scaling 1-bit Transformers for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shuming Ma</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Li Dong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaohan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huaijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lingxiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The increasing size of large language models has posed challenges for
deployment and raised concerns about environmental impact due to high energy
consumption. In this work, we introduce BitNet, a scalable and stable 1-bit
Transformer architecture designed for large language models. Specifically, we
introduce BitLinear as a drop-in replacement of the nn.Linear layer in order to
train 1-bit weights from scratch. Experimental results on language modeling
show that BitNet achieves competitive performance while substantially reducing
memory footprint and energy consumption, compared to state-of-the-art 8-bit
quantization methods and FP16 Transformer baselines. Furthermore, BitNet
exhibits a scaling law akin to full-precision Transformers, suggesting its
potential for effective scaling to even larger language models while
maintaining efficiency and performance benefits.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11454" title="Abstract">arXiv:2310.11454</a> [<a href="/pdf/2310.11454" title="Download PDF">pdf</a>, <a href="/format/2310.11454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VeRA: Vector-based Random Matrix Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kopiczko%2C+D+J">Dawid Jan Kopiczko</a>, 
<a href="/search/cs?searchtype=author&query=Blankevoort%2C+T">Tijmen Blankevoort</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki Markus Asano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Low-rank adapation (LoRA) is a popular method that reduces the number of
trainable parameters when finetuning large language models, but still faces
acute storage challenges when scaling to even larger models or deploying
numerous per-user or per-task adapted models. In this work, we present
Vector-based Random Matrix Adaptation (VeRA), which reduces the number of
trainable parameters by 10x compared to LoRA, yet maintains the same
performance. It achieves this by using a single pair of low-rank matrices
shared across all layers and learning small scaling vectors instead. We
demonstrate its effectiveness on the GLUE and E2E benchmarks, and show its
application in instruction-following with just 1.4M parameters using the Llama2
7B model.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed, 18 Oct 23</h3>
<dl>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1312.7832" title="Abstract">arXiv:1312.7832</a> (cross-list from math.LO) [<a href="/pdf/1312.7832" title="Download PDF">pdf</a>, <a href="/ps/1312.7832" title="Download PostScript">ps</a>, <a href="/format/1312.7832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defining implication relation for classical logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fu%2C+L">Li Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages; 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In classical logic, "P implies Q" is equivalent to "not-P or Q". It is well
known that the equivalence is problematic. Actually, from "P implies Q", "not-P
or Q" can be inferred ("Implication-to-disjunction" is valid), while from
"not-P or Q", "P implies Q" cannot be inferred in general
("Disjunction-to-implication" is not generally valid), so the equivalence
between them is invalid in general. This work aims to remove exactly the
incorrect Disjunction-to-implication from classical logic (CL). The paper
proposes a logical system (IRL) with the expected properties: (1) CL is simply
obtained by adding Disjunction-to-implication to IRL, and (2)
Disjunction-to-implication is independent of IRL (either
Disjunction-to-implication or its negation cannot be derived in IRL) in the
general case. In other words, IRL is just the system obtained by exactly
removing Disjunction-to-implication from CL.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10695" title="Abstract">arXiv:2310.10695</a> (cross-list from physics.comp-ph) [<a href="/pdf/2310.10695" title="Download PDF">pdf</a>, <a href="/format/2310.10695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Score-Based Models for Generating Stable Structures with  Adaptive Crystal Cells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sultanov%2C+A">Arsen Sultanov</a>, 
<a href="/search/physics?searchtype=author&query=Crivello%2C+J">Jean-Claude Crivello</a>, 
<a href="/search/physics?searchtype=author&query=Rebafka%2C+T">Tabea Rebafka</a>, 
<a href="/search/physics?searchtype=author&query=Sokolovska%2C+N">Nataliya Sokolovska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The discovery of new functional and stable materials is a big challenge due
to its complexity. This work aims at the generation of new crystal structures
with desired properties, such as chemical stability and specified chemical
composition, by using machine learning generative models. Compared to the
generation of molecules, crystal structures pose new difficulties arising from
the periodic nature of the crystal and from the specific symmetry constraints
related to the space group. In this work, score-based probabilistic models
based on annealed Langevin dynamics, which have shown excellent performance in
various applications, are adapted to the task of crystal generation. The
novelty of the presented approach resides in the fact that the lattice of the
crystal cell is not fixed. During the training of the model, the lattice is
learned from the available data, whereas during the sampling of a new chemical
structure, two denoising processes are used in parallel to generate the lattice
along the generation of the atomic positions. A multigraph crystal
representation is introduced that respects symmetry constraints, yielding
computational advantages and a better quality of the sampled structures. We
show that our model is capable of generating new candidate structures in any
chosen chemical system and crystal group without any additional training. To
illustrate the functionality of the proposed method, a comparison of our model
to other recent generative models, based on descriptor-based metrics, is
provided.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10717" title="Abstract">arXiv:2310.10717</a> (cross-list from astro-ph.CO) [<a href="/pdf/2310.10717" title="Download PDF">pdf</a>, <a href="/format/2310.10717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A representation learning approach to probe for dynamical dark energy in  matter power spectra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Piras%2C+D">Davide Piras</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lombriser%2C+L">Lucas Lombriser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present DE-VAE, a variational autoencoder (VAE) architecture to search for
a compressed representation of dynamical dark energy (DE) models in
observational studies of the cosmic large-scale structure. DE-VAE is trained on
matter power spectra boosts generated at wavenumbers $k\in(0.01-2.5) \
h/\rm{Mpc}$ and at four redshift values $z\in(0.1,0.48,0.78,1.5)$ for the most
typical dynamical DE parametrization with two extra parameters describing an
evolving DE equation of state. The boosts are compressed to a lower-dimensional
representation, which is concatenated with standard cold dark matter (CDM)
parameters and then mapped back to reconstructed boosts; both the compression
and the reconstruction components are parametrized as neural networks.
Remarkably, we find that a single latent parameter is sufficient to predict 95%
(99%) of DE power spectra generated over a broad range of cosmological
parameters within $1\sigma$ ($2\sigma$) of a Gaussian error which includes
cosmic variance, shot noise and systematic effects for a Stage IV-like survey.
This single parameter shows a high mutual information with the two DE
parameters, and these three variables can be linked together with an explicit
equation through symbolic regression. Considering a model with two latent
variables only marginally improves the accuracy of the predictions, and adding
a third latent variable has no significant impact on the model's performance.
We discuss how the DE-VAE architecture can be extended from a proof of concept
to a general framework to be employed in the search for a common
lower-dimensional parametrization of a wide range of beyond-$\Lambda$CDM models
and for different cosmological datasets. Such a framework could then both
inform the development of cosmological surveys by targeting optimal probes, and
provide theoretical insight into the common phenomenological aspects of
beyond-$\Lambda$CDM models.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10732" title="Abstract">arXiv:2310.10732</a> (cross-list from physics.chem-ph) [<a href="/pdf/2310.10732" title="Download PDF">pdf</a>, <a href="/format/2310.10732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Fu%2C+X">Xiang Fu</a>, 
<a href="/search/physics?searchtype=author&query=Xie%2C+T">Tian Xie</a>, 
<a href="/search/physics?searchtype=author&query=Rosen%2C+A+S">Andrew S. Rosen</a>, 
<a href="/search/physics?searchtype=author&query=Jaakkola%2C+T">Tommi Jaakkola</a>, 
<a href="/search/physics?searchtype=author&query=Smith%2C+J">Jake Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Metal-organic frameworks (MOFs) are of immense interest in applications such
as gas storage and carbon capture due to their exceptional porosity and tunable
chemistry. Their modular nature has enabled the use of template-based methods
to generate hypothetical MOFs by combining molecular building blocks in
accordance with known network topologies. However, the ability of these methods
to identify top-performing MOFs is often hindered by the limited diversity of
the resulting chemical space. In this work, we propose MOFDiff: a
coarse-grained (CG) diffusion model that generates CG MOF structures through a
denoising diffusion process over the coordinates and identities of the building
blocks. The all-atom MOF structure is then determined through a novel assembly
algorithm. Equivariant graph neural networks are used for the diffusion model
to respect the permutational and roto-translational symmetries. We
comprehensively evaluate our model's capability to generate valid and novel MOF
structures and its effectiveness in designing outstanding MOF materials for
carbon capture applications with molecular simulations.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10756" title="Abstract">arXiv:2310.10756</a> (cross-list from eess.IV) [<a href="/pdf/2310.10756" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Conditional Shape Models for 3D cardiac image segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jacob%2C+A+J">Athira J Jacob</a>, 
<a href="/search/eess?searchtype=author&query=Sharma%2C+P">Puneet Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Ruckert%2C+D">Daniel Ruckert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented as oral presentation at Statistical Atlases and Computational Modeling of the Heart (STACOM) workshop at MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Delineation of anatomical structures is often the first step of many medical
image analysis workflows. While convolutional neural networks achieve high
performance, these do not incorporate anatomical shape information. We
introduce a novel segmentation algorithm that uses Deep Conditional Shape
models (DCSMs) as a core component. Using deep implicit shape representations,
the algorithm learns a modality-agnostic shape model that can generate the
signed distance functions for any anatomy of interest. To fit the generated
shape to the image, the shape model is conditioned on anatomic landmarks that
can be automatically detected or provided by the user. Finally, we add a
modality-dependent, lightweight refinement network to capture any fine details
not represented by the implicit function. The proposed DCSM framework is
evaluated on the problem of cardiac left ventricle (LV) segmentation from
multiple 3D modalities (contrast-enhanced CT, non-contrasted CT, 3D
echocardiography-3DE). We demonstrate that the automatic DCSM outperforms the
baseline for non-contrasted CT without the local refinement, and with the
refinement for contrasted CT and 3DE, especially with significant improvement
in the Hausdorff distance. The semi-automatic DCSM with user-input landmarks,
while only trained on contrasted CT, achieves greater than 92% Dice for all
modalities. Both automatic DCSM with refinement and semi-automatic DCSM achieve
equivalent or better performance compared to inter-user variability for these
modalities.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10758" title="Abstract">arXiv:2310.10758</a> (cross-list from math.ST) [<a href="/pdf/2310.10758" title="Download PDF">pdf</a>, <a href="/ps/2310.10758" title="Download PostScript">ps</a>, <a href="/format/2310.10758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Barriers to Affine-equivariant Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Z">Zihao Chen</a>, 
<a href="/search/math?searchtype=author&query=Cherapanamjeri%2C+Y">Yeshwanth Cherapanamjeri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
<p class="mathjax">We investigate the quantitative performance of affine-equivariant estimators
for robust mean estimation. As a natural stability requirement, the
construction of such affine-equivariant estimators has been extensively studied
in the statistics literature. We quantitatively evaluate these estimators under
two outlier models which have been the subject of much recent work: the
heavy-tailed and adversarial corruption settings. We establish lower bounds
which show that affine-equivariance induces a strict degradation in recovery
error with quantitative rates degrading by a factor of $\sqrt{d}$ in both
settings. We find that classical estimators such as the Tukey median (Tukey
'75) and Stahel-Donoho estimator (Stahel '81 and Donoho '82) are either
quantitatively sub-optimal even within the class of affine-equivariant
estimators or lack any quantitative guarantees. On the other hand, recent
estimators with strong quantitative guarantees are not affine-equivariant or
require additional distributional assumptions to achieve it. We remedy this by
constructing a new affine-equivariant estimator which nearly matches our lower
bound. Our estimator is based on a novel notion of a high-dimensional median
which may be of independent interest. Notably, our results are applicable more
broadly to any estimator whose performance is evaluated in the Mahalanobis norm
which, for affine-equivariant estimators, corresponds to an evaluation in
Euclidean norm on isotropic distributions.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10785" title="Abstract">arXiv:2310.10785</a> (cross-list from math.LO) [<a href="/pdf/2310.10785" title="Download PDF">pdf</a>, <a href="/format/2310.10785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cyclic Proofs for iGL via Corecursion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sierra-Miranda%2C+B">Borja Sierra-Miranda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Daniyar Shamkanov proved that three distinct systems of sequent calculi for
GL are equivalent. These systems consist in one with finite proofs, another
with ill-founded proofs and the last one with cyclic proofs. The main tool used
for proving the equivalence is corecursion. In this project, we prove the
equivalence between a finitary sequent calculus for iGL and a cyclic calculus,
using also coinductive methods.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10788" title="Abstract">arXiv:2310.10788</a> (cross-list from eess.AS) [<a href="/pdf/2310.10788" title="Download PDF">pdf</a>, <a href="/format/2310.10788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Models of Speech Infer Universal Articulatory Kinematics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cho%2C+C+J">Cheol Jun Cho</a>, 
<a href="/search/eess?searchtype=author&query=Mohamed%2C+A">Abdelrahman Mohamed</a>, 
<a href="/search/eess?searchtype=author&query=Black%2C+A+W">Alan W Black</a>, 
<a href="/search/eess?searchtype=author&query=Anumanchipalli%2C+G+K">Gopala K. Anumanchipalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Self-Supervised Learning (SSL) based models of speech have shown remarkable
performance on a range of downstream tasks. These state-of-the-art models have
remained blackboxes, but many recent studies have begun "probing" models like
HuBERT, to correlate their internal representations to different aspects of
speech. In this paper, we show "inference of articulatory kinematics" as
fundamental property of SSL models, i.e., the ability of these models to
transform acoustics into the causal articulatory dynamics underlying the speech
signal. We also show that this abstraction is largely overlapping across the
language of the data used to train the model, with preference to the language
with similar phonological system. Furthermore, we show that with simple affine
transformations, Acoustic-to-Articulatory inversion (AAI) is transferrable
across speakers, even across genders, languages, and dialects, showing the
generalizability of this property. Together, these results shed new light on
the internals of SSL models that are critical to their superior performance,
and open up new avenues into language-agnostic universal models for speech
engineering, that are interpretable and grounded in speech science.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10797" title="Abstract">arXiv:2310.10797</a> (cross-list from q-fin.RM) [<a href="/pdf/2310.10797" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and managing blockchain protocol risks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Nathan%2C+A">Alex Nathan</a>, 
<a href="/search/q-fin?searchtype=author&query=Kaponis%2C+D">Dimosthenis Kaponis</a>, 
<a href="/search/q-fin?searchtype=author&query=Lustgarten%2C+S">Saul Lustgarten</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Risk Management in Financial Institutions 16.4 (2023):
  337-353
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Risk Management (q-fin.RM)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">This paper addresses the issue of blockchain protocol risks, a foundational
category of risks affecting Distributed Ledger Technology (DLT) which underpins
digital assets, smart contracts, and decentralised applications. It presents a
comprehensive risk management framework developed in collaboration with
financial institutions, blockchain development teams and regulators that
applies a traditional risk management taxonomy to address certain overlooked
blockchain protocol risks. The approach offers a structured way to identify,
measure, monitor and report blockchain protocol risks. The paper provides
real-world use cases to demonstrate the practicality and implementation of the
proposed framework. The findings of this work contribute to the evolving
understanding of blockchain protocol risks and provide valuable insights on how
these risks affect the adoption of DLT by financial institutions.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10806" title="Abstract">arXiv:2310.10806</a> (cross-list from eess.IV) [<a href="/pdf/2310.10806" title="Download PDF">pdf</a>, <a href="/format/2310.10806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Neural Network Model for Diabetic Retinopathy Feature  Extraction and Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Subramanian%2C+S">Sharan Subramanian</a>, 
<a href="/search/eess?searchtype=author&query=Gilpin%2C+L+H">Leilani H. Gilpin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 tables, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The application of Artificial Intelligence in the medical market brings up
increasing concerns but aids in more timely diagnosis of silent progressing
diseases like Diabetic Retinopathy. In order to diagnose Diabetic Retinopathy
(DR), ophthalmologists use color fundus images, or pictures of the back of the
retina, to identify small distinct features through a difficult and
time-consuming process. Our work creates a novel CNN model and identifies the
severity of DR through fundus image input. We classified 4 known DR features,
including micro-aneurysms, cotton wools, exudates, and hemorrhages, through
convolutional layers and were able to provide an accurate diagnostic without
additional user input. The proposed model is more interpretable and robust to
overfitting. We present initial results with a sensitivity of 97% and an
accuracy of 71%. Our contribution is an interpretable model with similar
accuracy to more complex models. With that, our model advances the field of DR
detection and proves to be a key step towards AI-focused medical diagnosis.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10807" title="Abstract">arXiv:2310.10807</a> (cross-list from stat.ML) [<a href="/pdf/2310.10807" title="Download PDF">pdf</a>, <a href="/format/2310.10807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularization properties of adversarially-trained linear regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ribeiro%2C+A+H">Ant&#xf4;nio H. Ribeiro</a>, 
<a href="/search/stat?searchtype=author&query=Zachariah%2C+D">Dave Zachariah</a>, 
<a href="/search/stat?searchtype=author&query=Bach%2C+F">Francis Bach</a>, 
<a href="/search/stat?searchtype=author&query=Sch%C3%B6n%2C+T+B">Thomas B. Sch&#xf6;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted (spotlight) NeurIPS 2023; A preliminary version of this work titled: "Surprises in adversarially-trained linear regression" was made available under a different identifier: <a href="/abs/2205.12695">arXiv:2205.12695</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">State-of-the-art machine learning models can be vulnerable to very small
input perturbations that are adversarially constructed. Adversarial training is
an effective approach to defend against it. Formulated as a min-max problem, it
searches for the best solution when the training data were corrupted by the
worst-case attacks. Linear models are among the simple models where
vulnerabilities can be observed and are the focus of our study. In this case,
adversarial training leads to a convex optimization problem which can be
formulated as the minimization of a finite sum. We provide a comparative
analysis between the solution of adversarial training in linear regression and
other regularization methods. Our main findings are that: (A) Adversarial
training yields the minimum-norm interpolating solution in the
overparameterized regime (more parameters than data), as long as the maximum
disturbance radius is smaller than a threshold. And, conversely, the
minimum-norm interpolator is the solution to adversarial training with a given
radius. (B) Adversarial training can be equivalent to parameter shrinking
methods (ridge regression and Lasso). This happens in the underparametrized
region, for an appropriate choice of adversarial radius and zero-mean
symmetrically distributed covariates. (C) For $\ell_\infty$-adversarial
training -- as in square-root Lasso -- the choice of adversarial radius for
optimal bounds does not depend on the additive noise variance. We confirm our
theoretical findings with numerical examples.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10835" title="Abstract">arXiv:2310.10835</a> (cross-list from eess.IV) [<a href="/pdf/2310.10835" title="Download PDF">pdf</a>, <a href="/format/2310.10835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Probabilistic Imaging using Score-Based Generative Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yu Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zihui Wu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yifan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+B+T">Berthy T. Feng</a>, 
<a href="/search/eess?searchtype=author&query=Bouman%2C+K+L">Katherine L. Bouman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Estimating high-quality images while also quantifying their uncertainty are
two desired features in an image reconstruction algorithm for solving ill-posed
inverse problems. In this paper, we propose plug-and-play Monte Carlo (PMC) as
a principled framework for characterizing the space of possible solutions to a
general inverse problem. PMC is able to incorporate expressive score-based
generative priors for high-quality image reconstruction while also performing
uncertainty quantification via posterior sampling. In particular, we introduce
two PMC algorithms which can be viewed as the sampling analogues of the
traditional plug-and-play priors (PnP) and regularization by denoising (RED)
algorithms. We also establish a theoretical analysis for characterizing the
convergence of the PMC algorithms. Our analysis provides non-asymptotic
stationarity guarantees for both algorithms, even in the presence of
non-log-concave likelihoods and imperfect score networks. We demonstrate the
performance of the PMC algorithms on multiple representative inverse problems
with both linear and nonlinear forward models. Experimental results show that
PMC significantly improves reconstruction quality and enables high-fidelity
uncertainty quantification.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10843" title="Abstract">arXiv:2310.10843</a> (cross-list from stat.ML) [<a href="/pdf/2310.10843" title="Download PDF">pdf</a>, <a href="/format/2310.10843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Classification by Density Estimation Using Gaussian  Mixture Model and Masked Autoregressive Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ghojogh%2C+B">Benyamin Ghojogh</a>, 
<a href="/search/stat?searchtype=author&query=Toutounchian%2C+M+A">Milad Amir Toutounchian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Density estimation, which estimates the distribution of data, is an important
category of probabilistic machine learning. A family of density estimators is
mixture models, such as Gaussian Mixture Model (GMM) by expectation
maximization. Another family of density estimators is the generative models
which generate data from input latent variables. One of the generative models
is the Masked Autoregressive Flow (MAF) which makes use of normalizing flows
and autoregressive networks. In this paper, we use the density estimators for
classification, although they are often used for estimating the distribution of
data. We model the likelihood of classes of data by density estimation,
specifically using GMM and MAF. The proposed classifiers outperform simpler
classifiers such as linear discriminant analysis which model the likelihood
using only a single Gaussian distribution. This work opens the research door
for proposing other probabilistic classifiers based on joint density
estimation.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10893" title="Abstract">arXiv:2310.10893</a> (cross-list from q-bio.QM) [<a href="/pdf/2310.10893" title="Download PDF">pdf</a>, <a href="/format/2310.10893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning Framework for Cost-Effective TCR-Epitope Binding  Affinity Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+P">Pengfei Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Bang%2C+S">Seojin Bang</a>, 
<a href="/search/q-bio?searchtype=author&query=Lee%2C+H">Heewook Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, this paper has been accepted for publication in the proceedings of the IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">T cell receptors (TCRs) are critical components of adaptive immune systems,
responsible for responding to threats by recognizing epitope sequences
presented on host cell surface. Computational prediction of binding affinity
between TCRs and epitope sequences using machine/deep learning has attracted
intense attention recently. However, its success is hindered by the lack of
large collections of annotated TCR-epitope pairs. Annotating their binding
affinity requires expensive and time-consuming wet-lab evaluation. To reduce
annotation cost, we present ActiveTCR, a framework that incorporates active
learning and TCR-epitope binding affinity prediction models. Starting with a
small set of labeled training pairs, ActiveTCR iteratively searches for
unlabeled TCR-epitope pairs that are ''worth'' for annotation. It aims to
maximize performance gains while minimizing the cost of annotation. We compared
four query strategies with a random sampling baseline and demonstrated that
ActiveTCR reduces annotation costs by approximately 40%. Furthermore, we showed
that providing ground truth labels of TCR-epitope pairs to query strategies can
help identify and reduce more than 40% redundancy among already annotated pairs
without compromising model performance, enabling users to train equally
powerful prediction models with less training data. Our work is the first
systematic investigation of data optimization for TCR-epitope binding affinity
prediction.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10900" title="Abstract">arXiv:2310.10900</a> (cross-list from math.ST) [<a href="/pdf/2310.10900" title="Download PDF">pdf</a>, <a href="/ps/2310.10900" title="Download PostScript">ps</a>, <a href="/format/2310.10900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability of Sequential Lateration and of Stress Minimization in the  Presence of Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arias-Castro%2C+E">Ery Arias-Castro</a>, 
<a href="/search/math?searchtype=author&query=Chau%2C+P+A">Phong Alain Chau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2207.07218">arXiv:2207.07218</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Networking and Internet Architecture (cs.NI); Probability (math.PR)

</div>
<p class="mathjax">Sequential lateration is a class of methods for multidimensional scaling
where a suitable subset of nodes is first embedded by some method, e.g., a
clique embedded by classical scaling, and then the remaining nodes are
recursively embedded by lateration. A graph is a lateration graph when it can
be embedded by such a procedure. We provide a stability result for a particular
variant of sequential lateration. We do so in a setting where the
dissimilarities represent noisy Euclidean distances between nodes in a
geometric lateration graph. We then deduce, as a corollary, a perturbation
bound for stress minimization. To argue that our setting applies broadly, we
show that a (large) random geometric graph is a lateration graph with high
probability under mild condition. This extends a previous result of Aspnes et
al (2006).
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10907" title="Abstract">arXiv:2310.10907</a> (cross-list from stat.ML) [<a href="/pdf/2310.10907" title="Download PDF">pdf</a>, <a href="/format/2310.10907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surrogate Active Subspaces for Jump-Discontinuous Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wycoff%2C+N">Nathan Wycoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> comments very welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Surrogate modeling and active subspaces have emerged as powerful paradigms in
computational science and engineering. Porting such techniques to computational
models in the social sciences brings into sharp relief their limitations in
dealing with discontinuous simulators, such as Agent-Based Models, which have
discrete outputs. Nevertheless, prior applied work has shown that surrogate
estimates of active subspaces for such estimators can yield interesting
results. But given that active subspaces are defined by way of gradients, it is
not clear what quantity is being estimated when this methodology is applied to
a discontinuous simulator. We begin this article by showing some pathologies
that can arise when conducting such an analysis. This motivates an extension of
active subspaces to discontinuous functions, clarifying what is actually being
estimated in such analyses. We also conduct numerical experiments on synthetic
test functions to compare Gaussian process estimates of active subspaces on
continuous and discontinuous functions. Finally, we deploy our methodology on
Flee, an agent-based model of refugee movement, yielding novel insights into
which parameters of the simulation are most important across 8 displacement
crises in Africa and the Middle East.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10951" title="Abstract">arXiv:2310.10951</a> (cross-list from eess.IV) [<a href="/pdf/2310.10951" title="Download PDF">pdf</a>, <a href="/format/2310.10951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusionU-Net: U-Net with Enhanced Skip Connection for Pathology Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zongyi Li</a>, 
<a href="/search/eess?searchtype=author&query=Lyu%2C+H">Hongbing Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In recent years, U-Net and its variants have been widely used in pathology
image segmentation tasks. One of the key designs of U-Net is the use of skip
connections between the encoder and decoder, which helps to recover detailed
information after upsampling. While most variations of U-Net adopt the original
skip connection design, there is semantic gap between the encoder and decoder
that can negatively impact model performance. Therefore, it is important to
reduce this semantic gap before conducting skip connection. To address this
issue, we propose a new segmentation network called FusionU-Net, which is based
on U-Net structure and incorporates a fusion module to exchange information
between different skip connections to reduce semantic gaps. Unlike the other
fusion modules in existing networks, ours is based on a two-round fusion design
that fully considers the local relevance between adjacent encoder layer outputs
and the need for bi-directional information exchange across multiple layers. We
conducted extensive experiments on multiple pathology image datasets to
evaluate our model and found that FusionU-Net achieves better performance
compared to other competing methods. We argue our fusion module is more
effective than the designs of existing networks, and it could be easily
embedded into other networks to further enhance the model performance.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10952" title="Abstract">arXiv:2310.10952</a> (cross-list from stat.ML) [<a href="/pdf/2310.10952" title="Download PDF">pdf</a>, <a href="/format/2310.10952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restricted Tweedie Stochastic Block Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jian%2C+J">Jie Jian</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+M">Mu Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Sang%2C+P">Peijun Sang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP); Computation (stat.CO)

</div>
<p class="mathjax">The stochastic block model (SBM) is a widely used framework for community
detection in networks, where the network structure is typically represented by
an adjacency matrix. However, conventional SBMs are not directly applicable to
an adjacency matrix that consists of non-negative zero-inflated continuous edge
weights. To model the international trading network, where edge weights
represent trading values between countries, we propose an innovative SBM based
on a restricted Tweedie distribution. Additionally, we incorporate nodal
information, such as the geographical distance between countries, and account
for its dynamic effect on edge weights. Notably, we show that given a
sufficiently large number of nodes, estimating this covariate effect becomes
independent of community labels of each node when computing the maximum
likelihood estimator of parameters in our model. This result enables the
development of an efficient two-step algorithm that separates the estimation of
covariate effects from other parameters. We demonstrate the effectiveness of
our proposed method through extensive simulation studies and an application to
real-world international trading data.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10957" title="Abstract">arXiv:2310.10957</a> (cross-list from eess.IV) [<a href="/pdf/2310.10957" title="Download PDF">pdf</a>, <a href="/format/2310.10957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical Image Segmentation via Sparse Coding Decoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zeng%2C+L">Long Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+K">Kaigui Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Transformers have achieved significant success in medical image segmentation,
owing to its capability to capture long-range dependencies. Previous works
incorporate convolutional layers into the encoder module of transformers,
thereby enhancing their ability to learn local relationships among pixels.
However, transformers may suffer from limited generalization capabilities and
reduced robustness, attributed to the insufficient spatial recovery ability of
their decoders. To address this issue, A convolution sparse vector coding based
decoder is proposed , namely CAScaded multi-layer Convolutional Sparse vector
Coding DEcoder (CASCSCDE), which represents features extracted by the encoder
using sparse vectors. To prove the effectiveness of our CASCSCDE, The
widely-used TransUNet model is chosen for the demonstration purpose, and the
CASCSCDE is incorporated with TransUNet to establish the TransCASCSCDE
architecture. Our experiments demonstrate that TransUNet with CASCSCDE
significantly enhances performance on the Synapse benchmark, obtaining up to
3.15\% and 1.16\% improvements in DICE and mIoU scores, respectively. CASCSCDE
opens new ways for constructing decoders based on convolutional sparse vector
coding.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10965" title="Abstract">arXiv:2310.10965</a> (cross-list from math.DS) [<a href="/pdf/2310.10965" title="Download PDF">pdf</a>, <a href="/ps/2310.10965" title="Download PostScript">ps</a>, <a href="/format/2310.10965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The neural network models with delays for solving absolute value  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yu%2C+D">Dongmei Yu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+G">Gehao Zhang</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+C">Cairong Chen</a>, 
<a href="/search/math?searchtype=author&query=Han%2C+D">Deren Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">An inverse-free neural network model with mixed delays is proposed for
solving the absolute value equation (AVE) $Ax -|x| - b =0$, which includes an
inverse-free neural network model with discrete delay as a special case. By
using the Lyapunov-Krasovskii theory and the linear matrix inequality (LMI)
method, the developed neural network models are proved to be exponentially
convergent to the solution of the AVE. Compared with the existing neural
network models for solving the AVE, the proposed models feature the ability of
solving a class of AVE with $\|A^{-1}\|&gt;1$. Numerical simulations are given to
show the effectiveness of the two delayed neural network models.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10976" title="Abstract">arXiv:2310.10976</a> (cross-list from stat.ME) [<a href="/pdf/2310.10976" title="Download PDF">pdf</a>, <a href="/format/2310.10976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact nonlinear state estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chipilski%2C+H+G">Hristo G. Chipilski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Dynamical Systems (math.DS); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">The majority of data assimilation (DA) methods in the geosciences are based
on Gaussian assumptions. While these assumptions facilitate efficient
algorithms, they cause analysis biases and subsequent forecast degradations.
Non-parametric, particle-based DA algorithms have superior accuracy, but their
application to high-dimensional models still poses operational challenges.
Drawing inspiration from recent advances in the field of generative artificial
intelligence (AI), this article introduces a new nonlinear estimation theory
which attempts to bridge the existing gap in DA methodology. Specifically, a
Conjugate Transform Filter (CTF) is derived and shown to generalize the
celebrated Kalman filter to arbitrarily non-Gaussian distributions. The new
filter has several desirable properties, such as its ability to preserve
statistical relationships in the prior state and convergence to highly accurate
observations. An ensemble approximation of the new theory (ECTF) is also
presented and validated using idealized statistical experiments that feature
bounded quantities with non-Gaussian distributions, a prevalent challenge in
Earth system models. Results from these experiments indicate that the greatest
benefits from ECTF occur when observation errors are small relative to the
forecast uncertainty and when state variables exhibit strong nonlinear
dependencies. Ultimately, the new filtering theory offers exciting avenues for
improving conventional DA algorithms through their principled integration with
AI techniques.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11014" title="Abstract">arXiv:2310.11014</a> (cross-list from physics.optics) [<a href="/pdf/2310.11014" title="Download PDF">pdf</a>, <a href="/format/2310.11014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperspectral In-Memory Computing with Optical Frequency Combs and  Programmable Optical Memories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Latifpour%2C+M+H">Mostafa Honari Latifpour</a>, 
<a href="/search/physics?searchtype=author&query=Park%2C+B+J">Byoung Jun Park</a>, 
<a href="/search/physics?searchtype=author&query=Yamamoto%2C+Y">Yoshihisa Yamamoto</a>, 
<a href="/search/physics?searchtype=author&query=Suh%2C+M">Myoung-Gyun Suh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">The rapid advancements in machine learning across numerous industries have
amplified the demand for extensive matrix-vector multiplication operations,
thereby challenging the capacities of traditional von Neumann computing
architectures. To address this, researchers are currently exploring
alternatives such as in-memory computing systems to develop faster and more
energy-efficient hardware. In particular, there is renewed interest in
computing systems based on optics, which could potentially handle matrix-vector
multiplication in a more energy-efficient way. Despite promising initial
results, developing a highly parallel, programmable, and scalable optical
computing system capable of rivaling electronic computing hardware still
remains elusive. In this context, we propose a hyperspectral in-memory
computing architecture that integrates space multiplexing with frequency
multiplexing of optical frequency combs and uses spatial light modulators as a
programmable optical memory, thereby boosting the computational throughput and
the energy efficiency. We have experimentally demonstrated multiply-accumulate
operations with higher than 4-bit precision in both matrix-vector and
matrix-matrix multiplications, which suggests the system's potential for a wide
variety of deep learning and optimization tasks. This system exhibits
extraordinary modularity, scalability, and programmability, effectively
transcending the traditional limitations of optics-based computing
architectures. Our approach demonstrates the potential to scale beyond peta
operations per second, marking a significant step towards achieving
high-throughput energy-efficient optical computing.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11021" title="Abstract">arXiv:2310.11021</a> (cross-list from quant-ph) [<a href="/pdf/2310.11021" title="Download PDF">pdf</a>, <a href="/format/2310.11021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic quantum circuit compilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fang%2C+K">Kun Fang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+M">Munan Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shi%2C+R">Ruqi Shi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Y">Yinan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 32 figures; comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Quantum computing has shown tremendous promise in addressing complex
computational problems, yet its practical realization is hindered by the
limited availability of qubits for computation. Recent advancements in quantum
hardware have introduced mid-circuit measurements and resets, enabling the
reuse of measured qubits and significantly reducing the qubit requirements for
executing quantum algorithms. In this work, we present a systematic study of
dynamic quantum circuit compilation, a process that transforms static quantum
circuits into their dynamic equivalents with a reduced qubit count through
qubit-reuse. We establish the first general framework for optimizing the
dynamic circuit compilation via graph manipulation. In particular, we
completely characterize the optimal quantum circuit compilation using binary
integer programming, provide efficient algorithms for determining whether a
given quantum circuit can be reduced to a smaller circuit and present heuristic
algorithms for devising dynamic compilation schemes in general. Furthermore, we
conduct a thorough analysis of quantum circuits with practical relevance,
offering optimal compilations for well-known quantum algorithms in quantum
computation, ansatz circuits utilized in quantum machine learning, and
measurement-based quantum computation crucial for quantum networking. We also
perform a comparative analysis against state-of-the-art approaches,
demonstrating the superior performance of our methods in both structured and
random quantum circuits. Our framework lays a rigorous foundation for
comprehending dynamic quantum circuit compilation via qubit-reuse, bridging the
gap between theoretical quantum algorithms and their physical implementation on
quantum computers with limited resources.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11036" title="Abstract">arXiv:2310.11036</a> (cross-list from eess.SP) [<a href="/pdf/2310.11036" title="Download PDF">pdf</a>, <a href="/format/2310.11036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radio Map Estimation in the Real-World: Empirical Validation and  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shrestha%2C+R">Raju Shrestha</a>, 
<a href="/search/eess?searchtype=author&query=Ha%2C+T+N">Tien Ngoc Ha</a>, 
<a href="/search/eess?searchtype=author&query=Viet%2C+P+Q">Pham Q. Viet</a>, 
<a href="/search/eess?searchtype=author&query=Romero%2C+D">Daniel Romero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in IEEE CAMA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Radio maps quantify received signal strength or other magnitudes of the radio
frequency environment at every point of a geographical region. These maps play
a vital role in a large number of applications such as wireless network
planning, spectrum management, and optimization of communication systems.
However, empirical validation of the large number of existing radio map
estimators is highly limited. To fill this gap, a large data set of
measurements has been collected with an autonomous unmanned aerial vehicle
(UAV) and a representative subset of these estimators were evaluated on this
data. The performance-complexity trade-off and the impact of fast fading are
extensively investigated. Although sophisticated estimators based on deep
neural networks (DNNs) exhibit the best performance, they are seen to require
large volumes of training data to offer a substantial advantage relative to
more traditional schemes. A novel algorithm that blends both kinds of
estimators is seen to enjoy the benefits of both, thereby suggesting the
potential of exploring this research direction further.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11040" title="Abstract">arXiv:2310.11040</a> (cross-list from eess.IV) [<a href="/pdf/2310.11040" title="Download PDF">pdf</a>, <a href="/format/2310.11040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-Learning Semantic-aware Unsupervised Segmentation for Pathological  Image Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+S">Shi Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, published in Medical Image Computing and Computer Assisted Intervention (MICCAI) 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Medical Image Computing and
  Computer-Assisted Intervention, pp. 537-547. Cham: Springer Nature
  Switzerland, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The registration of pathological images plays an important role in medical
applications. Despite its significance, most researchers in this field
primarily focus on the registration of normal tissue into normal tissue. The
negative impact of focal tissue, such as the loss of spatial correspondence
information and the abnormal distortion of tissue, are rarely considered. In
this paper, we propose GIRNet, a novel unsupervised approach for pathological
image registration by incorporating segmentation and inpainting through the
principles of Generation, Inpainting, and Registration (GIR). The registration,
segmentation, and inpainting modules are trained simultaneously in a
co-learning manner so that the segmentation of the focal area and the
registration of inpainted pairs can improve collaboratively. Overall, the
registration of pathological images is achieved in a completely unsupervised
learning framework. Experimental results on multiple datasets, including
Magnetic Resonance Imaging (MRI) of T1 sequences, demonstrate the efficacy of
our proposed method. Our results show that our method can accurately achieve
the registration of pathological images and identify lesions even in
challenging imaging modalities. Our unsupervised approach offers a promising
solution for the efficient and cost-effective registration of pathological
images. Our code is available at
https://github.com/brain-intelligence-lab/GIRNet.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11043" title="Abstract">arXiv:2310.11043</a> (cross-list from eess.SP) [<a href="/pdf/2310.11043" title="Download PDF">pdf</a>, <a href="/format/2310.11043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spoofing Attack Detection in the Physical Layer with Robustness to User  Movement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Romero%2C+D">Daniel Romero</a>, 
<a href="/search/eess?searchtype=author&query=Ha%2C+T+N">Tien Ngoc Ha</a>, 
<a href="/search/eess?searchtype=author&query=Gerstoft%2C+P">Peter Gerstoft</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WCNC. arXiv admin note: text overlap with <a href="/abs/2211.04269">arXiv:2211.04269</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In a spoofing attack, an attacker impersonates a legitimate user to access or
modify data belonging to the latter. Typical approaches for spoofing detection
in the physical layer declare an attack when a change is observed in certain
channel features, such as the received signal strength (RSS) measured by
spatially distributed receivers. However, since channels change over time, for
example due to user movement, such approaches are impractical. To sidestep this
limitation, this paper proposes a scheme that combines the decisions of a
position-change detector based on a deep neural network to distinguish spoofing
from movement. Building upon community detection on graphs, the sequence of
received frames is partitioned into subsequences to detect concurrent
transmissions from distinct locations. The scheme can be easily deployed in
practice since it just involves collecting a small dataset of measurements at a
few tens of locations that need not even be computed or recorded. The scheme is
evaluated on real data collected for this purpose.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11050" title="Abstract">arXiv:2310.11050</a> (cross-list from eess.IV) [<a href="/pdf/2310.11050" title="Download PDF">pdf</a>, <a href="/format/2310.11050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $k$-$t$ CLAIR: Self-Consistency Guided Multi-Prior Learning for Dynamic  Parallel MR Image Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Liping Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Weitian Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 4 tables. CMRxRecon Challenge, MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Cardiac magnetic resonance imaging (CMR) has been widely used in clinical
practice for the medical diagnosis of cardiac diseases. However, the long
acquisition time hinders its development in real-time applications. Here, we
propose a novel self-consistency guided multi-prior learning framework named
$k$-$t$ CLAIR to exploit spatiotemporal correlations from highly undersampled
data for accelerated dynamic parallel MRI reconstruction. The $k$-$t$ CLAIR
progressively reconstructs faithful images by leveraging multiple complementary
priors learned in the $x$-$t$, $x$-$f$, and $k$-$t$ domains in an iterative
fashion, as dynamic MRI exhibits high spatiotemporal redundancy. Additionally,
$k$-$t$ CLAIR incorporates calibration information for prior learning,
resulting in a more consistent reconstruction. Experimental results on cardiac
cine and T1W/T2W images demonstrate that $k$-$t$ CLAIR achieves high-quality
dynamic MR reconstruction in terms of both quantitative and qualitative
performance.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11063" title="Abstract">arXiv:2310.11063</a> (cross-list from physics.med-ph) [<a href="/pdf/2310.11063" title="Download PDF">pdf</a>, <a href="/ps/2310.11063" title="Download PostScript">ps</a>, <a href="/format/2310.11063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Overview of Current and Emerging Biomaterials Technology for  Continuous Glucose Monitoring (CGM) Devices -- Current state and future  perspectives of the leading technologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Momy%2C+U+H">Umme Hafsa Momy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages,Review paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In the world today, diabetic complications are a major factor in the
disease's high mortality rate. Diabetes mellitus has been a major source of
concern for decades due to its global prevalence and the resulting rising costs
to individuals, governments, and healthcare systems on both a social and
economic level. The complex interplay between nutrition, exercise, stress,
medicine, sickness, and hormonal changes makes controlling diabetes difficult.
Even though there is currently no cure for diabetes, the condition may be
managed with careful attention to blood glucose levels and the use of
appropriate medications. Blood sugar levels should be monitored on a regular
basis, which requires a glucometer and a fingertip and is becoming the standard
in diabetes control technologies. For the convenience of diabetic patients, the
use of a CGM device for monitoring glucose levels has become the preferred
method. For diabetes therapy at the point of care, replacing finger-prick
glucometers can be done anywhere they are currently on the market. As a result,
it has sparked a lot of interest in a variety of glucose sensing mechanisms,
particularly non-invasive or marginally glucose sensing mechanisms that focus
on subcutaneously implantable electrochemical sugar sensors that work more
reliably and last longer.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11065" title="Abstract">arXiv:2310.11065</a> (cross-list from stat.ML) [<a href="/pdf/2310.11065" title="Download PDF">pdf</a>, <a href="/format/2310.11065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resampling Stochastic Gradient Descent Cheaply for Efficient Uncertainty  Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lam%2C+H">Henry Lam</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Z">Zitong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Stochastic gradient descent (SGD) or stochastic approximation has been widely
used in model training and stochastic optimization. While there is a huge
literature on analyzing its convergence, inference on the obtained solutions
from SGD has only been recently studied, yet is important due to the growing
need for uncertainty quantification. We investigate two computationally cheap
resampling-based methods to construct confidence intervals for SGD solutions.
One uses multiple, but few, SGDs in parallel via resampling with replacement
from the data, and another operates this in an online fashion. Our methods can
be regarded as enhancements of established bootstrap schemes to substantially
reduce the computation effort in terms of resampling requirements, while at the
same time bypassing the intricate mixing conditions in existing batching
methods. We achieve these via a recent so-called cheap bootstrap idea and
Berry-Esseen-type bound for SGD.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11104" title="Abstract">arXiv:2310.11104</a> (cross-list from math.OC) [<a href="/pdf/2310.11104" title="Download PDF">pdf</a>, <a href="/ps/2310.11104" title="Download PostScript">ps</a>, <a href="/format/2310.11104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Lipschitz Constant Computation of ReLU-FNNs: Upper Bound  Computation with Exactness Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ebihara%2C+Y">Yoshio Ebihara</a>, 
<a href="/search/math?searchtype=author&query=Dai%2C+X">Xin Dai</a>, 
<a href="/search/math?searchtype=author&query=Magron%2C+V">Victor Magron</a>, 
<a href="/search/math?searchtype=author&query=Peaucelle%2C+D">Dimitri Peaucelle</a>, 
<a href="/search/math?searchtype=author&query=Tarbouriech%2C+S">Sophie Tarbouriech</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper is concerned with the computation of the local Lipschitz constant
of feedforward neural networks (FNNs) with activation functions being rectified
linear units (ReLUs). The local Lipschitz constant of an FNN for a target input
is a reasonable measure for its quantitative evaluation of the reliability. By
following a standard procedure using multipliers that capture the behavior of
ReLUs,we first reduce the upper bound computation problem of the local
Lipschitz constant into a semidefinite programming problem (SDP). Here we newly
introduce copositive multipliers to capture the ReLU behavior accurately. Then,
by considering the dual of the SDP for the upper bound computation, we second
derive a viable test to conclude the exactness of the computed upper bound.
However, these SDPs are intractable for practical FNNs with hundreds of ReLUs.
To address this issue, we further propose a method to construct a reduced order
model whose input-output property is identical to the original FNN over a
neighborhood of the target input. We finally illustrate the effectiveness of
the model reduction and exactness verification methods with numerical examples
of practical FNNs.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11112" title="Abstract">arXiv:2310.11112</a> (cross-list from eess.IV) [<a href="/pdf/2310.11112" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Super resolution of histopathological frozen sections via deep learning  preserving tissue structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yoshai%2C+E">Elad Yoshai</a>, 
<a href="/search/eess?searchtype=author&query=Goldinger%2C+G">Gil Goldinger</a>, 
<a href="/search/eess?searchtype=author&query=Haifler%2C+M">Miki Haifler</a>, 
<a href="/search/eess?searchtype=author&query=Shaked%2C+N+T">Natan T. Shaked</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Histopathology plays a pivotal role in medical diagnostics. In contrast to
preparing permanent sections for histopathology, a time-consuming process,
preparing frozen sections is significantly faster and can be performed during
surgery, where the sample scanning time should be optimized. Super-resolution
techniques allow imaging the sample in lower magnification and sparing scanning
time. In this paper, we present a new approach to super resolution for
histopathological frozen sections, with focus on achieving better distortion
measures, rather than pursuing photorealistic images that may compromise
critical diagnostic information. Our deep-learning architecture focuses on
learning the error between interpolated images and real images, thereby it
generates high-resolution images while preserving critical image details,
reducing the risk of diagnostic misinterpretation. This is done by leveraging
the loss functions in the frequency domain, assigning higher weights to the
reconstruction of complex, high-frequency components. In comparison to existing
methods, we obtained significant improvements in terms of Structural Similarity
Index (SSIM) and Peak Signal-to-Noise Ratio (PSNR), as well as indicated
details that lost in the low-resolution frozen-section images, affecting the
pathologist's clinical decisions. Our approach has a great potential in
providing more-rapid frozen-section imaging, with less scanning, while
preserving the high resolution in the imaged sample.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11122" title="Abstract">arXiv:2310.11122</a> (cross-list from stat.ML) [<a href="/pdf/2310.11122" title="Download PDF">pdf</a>, <a href="/format/2310.11122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensitivity-Aware Amortized Bayesian Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Elsem%C3%BCller%2C+L">Lasse Elsem&#xfc;ller</a>, 
<a href="/search/stat?searchtype=author&query=Olischl%C3%A4ger%2C+H">Hans Olischl&#xe4;ger</a>, 
<a href="/search/stat?searchtype=author&query=Schmitt%2C+M">Marvin Schmitt</a>, 
<a href="/search/stat?searchtype=author&query=B%C3%BCrkner%2C+P">Paul-Christian B&#xfc;rkner</a>, 
<a href="/search/stat?searchtype=author&query=K%C3%B6the%2C+U">Ullrich K&#xf6;the</a>, 
<a href="/search/stat?searchtype=author&query=Radev%2C+S+T">Stefan T.Radev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Bayesian inference is a powerful framework for making probabilistic
inferences and decisions under uncertainty. Fundamental choices in modern
Bayesian workflows concern the specification of the likelihood function and
prior distributions, the posterior approximator, and the data. Each choice can
significantly influence model-based inference and subsequent decisions, thereby
necessitating sensitivity analysis. In this work, we propose a multifaceted
approach to integrate sensitivity analyses into amortized Bayesian inference
(ABI, i.e., simulation-based inference with neural networks). First, we utilize
weight sharing to encode the structural similarities between alternative
likelihood and prior specifications in the training process with minimal
computational overhead. Second, we leverage the rapid inference of neural
networks to assess sensitivity to various data perturbations or pre-processing
procedures. In contrast to most other Bayesian approaches, both steps
circumvent the costly bottleneck of refitting the model(s) for each choice of
likelihood, prior, or dataset. Finally, we propose to use neural network
ensembles to evaluate variation in results induced by unreliable approximation
on unseen data. We demonstrate the effectiveness of our method in applied
modeling problems, ranging from the estimation of disease outbreak dynamics and
global warming thresholds to the comparison of human decision-making models.
Our experiments showcase how our approach enables practitioners to effectively
unveil hidden relationships between modeling choices and inferential
conclusions.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11143" title="Abstract">arXiv:2310.11143</a> (cross-list from stat.ML) [<a href="/pdf/2310.11143" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new high-resolution indoor radon map for Germany using a machine  learning based probabilistic exposure model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Petermann%2C+E">Eric Petermann</a>, 
<a href="/search/stat?searchtype=author&query=Bossew%2C+P">Peter Bossew</a>, 
<a href="/search/stat?searchtype=author&query=Kemski%2C+J">Joachim Kemski</a>, 
<a href="/search/stat?searchtype=author&query=Gruber%2C+V">Valeria Gruber</a>, 
<a href="/search/stat?searchtype=author&query=Suhr%2C+N">Nils Suhr</a>, 
<a href="/search/stat?searchtype=author&query=Hoffmann%2C+B">Bernd Hoffmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Radon is a carcinogenic, radioactive gas that can accumulate indoors. Indoor
radon exposure at the national scale is usually estimated on the basis of
extensive measurement campaigns. However, characteristics of the sample often
differ from the characteristics of the population due to the large number of
relevant factors such as the availability of geogenic radon or floor level.
Furthermore, the sample size usually does not allow exposure estimation with
high spatial resolution. We propose a model-based approach that allows a more
realistic estimation of indoor radon distribution with a higher spatial
resolution than a purely data-based approach. We applied a two-stage modelling
approach: 1) a quantile regression forest using environmental and building data
as predictors was applied to estimate the probability distribution function of
indoor radon for each floor level of each residential building in Germany; (2)
a probabilistic Monte Carlo sampling technique enabled the combination and
population weighting of floor-level predictions. In this way, the uncertainty
of the individual predictions is effectively propagated into the estimate of
variability at the aggregated level. The results give an arithmetic mean of 63
Bq/m3, a geometric mean of 41 Bq/m3 and a 95 %ile of 180 Bq/m3. The exceedance
probability for 100 Bq/m3 and 300 Bq/m3 are 12.5 % (10.5 million people) and
2.2 % (1.9 million people), respectively. In large cities, individual indoor
radon exposure is generally lower than in rural areas, which is a due to the
different distribution of the population on floor levels. The advantages of our
approach are 1) an accurate exposure estimation even if the survey was not
fully representative with respect to the main controlling factors, and 2) an
estimate of the exposure distribution with a much higher spatial resolution
than basic descriptive statistics.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11147" title="Abstract">arXiv:2310.11147</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2310.11147" title="Download PDF">pdf</a>, <a href="/format/2310.11147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering wall-shear stress dynamics from neural-network enhanced fluid  flow measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lagemann%2C+E">Esther Lagemann</a>, 
<a href="/search/physics?searchtype=author&query=Brunton%2C+S+L">Steven L. Brunton</a>, 
<a href="/search/physics?searchtype=author&query=Lagemann%2C+C">Christian Lagemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1911.01780">arXiv:1911.01780</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Friction drag from a turbulent fluid moving past or inside an object plays a
crucial role in domains as diverse as transportation, public utility
infrastructure, energy technology, and human health. As a direct measure of the
shear-induced friction forces, an accurate prediction of the wall-shear stress
can contribute to sustainability, conservation of resources, and carbon
neutrality in civil aviation as well as enhanced medical treatment of vascular
diseases and cancer. Despite such importance for our modern society, we still
lack adequate experimental methods to capture the instantaneous wall-shear
stress dynamics. In this contribution, we present a holistic approach that
derives velocity and wall-shear stress fields with impressive spatial and
temporal resolution from flow measurements using a deep optical flow estimator
with physical knowledge. The validity and physical correctness of the derived
flow quantities is demonstrated with synthetic and real-world experimental data
covering a range of relevant fluid flows.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11167" title="Abstract">arXiv:2310.11167</a> (cross-list from math.CO) [<a href="/pdf/2310.11167" title="Download PDF">pdf</a>, <a href="/format/2310.11167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reuniting $&#x3c7;$-boundedness with polynomial $&#x3c7;$-boundedness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chudnovsky%2C+M">Maria Chudnovsky</a>, 
<a href="/search/math?searchtype=author&query=Cook%2C+L">Linda Cook</a>, 
<a href="/search/math?searchtype=author&query=Davies%2C+J">James Davies</a>, 
<a href="/search/math?searchtype=author&query=Oum%2C+S">Sang-il Oum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A class $\mathcal F$ of graphs is $\chi$-bounded if there is a function $f$
such that $\chi(H)\le f(\omega(H))$ for all induced subgraphs $H$ of a graph in
$\mathcal F$. If $f$ can be chosen to be a polynomial, we say that $\mathcal F$
is polynomially $\chi$-bounded. Esperet proposed a conjecture that every
$\chi$-bounded class of graphs is polynomially $\chi$-bounded. This conjecture
has been disproved; it has been shown that there are classes of graphs that are
$\chi$-bounded but not polynomially $\chi$-bounded. Nevertheless, inspired by
Esperet's conjecture, we introduce Pollyanna classes of graphs. A class
$\mathcal C$ of graphs is Pollyanna if $\mathcal C\cap \mathcal F$ is
polynomially $\chi$-bounded for every $\chi$-bounded class $\mathcal F$ of
graphs. We prove that several classes of graphs are Pollyanna and also present
some proper classes of graphs that are not Pollyanna.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11230" title="Abstract">arXiv:2310.11230</a> (cross-list from eess.AS) [<a href="/pdf/2310.11230" title="Download PDF">pdf</a>, <a href="/format/2310.11230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zipformer: A faster and better encoder for automatic speech recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+Z">Zengwei Yao</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+L">Liyong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaoyu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+W">Wei Kang</a>, 
<a href="/search/eess?searchtype=author&query=Kuang%2C+F">Fangjun Kuang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Z">Zengrui Jin</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+L">Long Lin</a>, 
<a href="/search/eess?searchtype=author&query=Povey%2C+D">Daniel Povey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Conformer has become the most popular encoder model for automatic speech
recognition (ASR). It adds convolution modules to a transformer to learn both
local and global dependencies. In this work we describe a faster, more
memory-efficient, and better-performing transformer, called Zipformer. Modeling
changes include: 1) a U-Net-like encoder structure where middle stacks operate
at lower frame rates; 2) reorganized block structure with more modules, within
which we re-use attention weights for efficiency; 3) a modified form of
LayerNorm called BiasNorm allows us to retain some length information; 4) new
activation functions SwooshR and SwooshL work better than Swish. We also
propose a new optimizer, called ScaledAdam, which scales the update by each
tensor's current scale to keep the relative change about the same, and also
explictly learns the parameter scale. It achieves faster convergence and better
performance than Adam. Extensive experiments on LibriSpeech, Aishell-1, and
WenetSpeech datasets demonstrate the effectiveness of our proposed Zipformer
over other state-of-the-art ASR models. Our code is publicly available at
https://github.com/k2-fsa/icefall.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11254" title="Abstract">arXiv:2310.11254</a> (cross-list from math.CO) [<a href="/pdf/2310.11254" title="Download PDF">pdf</a>, <a href="/ps/2310.11254" title="Download PostScript">ps</a>, <a href="/format/2310.11254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triangulations Admit Dominating Sets of Size $2n/7$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Christiansen%2C+A+B+G">Aleksander B. G. Christiansen</a>, 
<a href="/search/math?searchtype=author&query=Rotenberg%2C+E">Eva Rotenberg</a>, 
<a href="/search/math?searchtype=author&query=Rutschmann%2C+D">Daniel Rutschmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We show that every planar triangulation on $n&gt;10$ vertices has a dominating
set of size $n/7=n/3.5$. This approaches the $n/4$ bound conjectured by
Matheson and Tarjan [MT'96], and improves significantly on the previous best
bound of $17n/53\approx n/3.117$ by \v{S}pacapan [\v{S}'20].
<br />From our proof it follows that every 3-connected $n$-vertex
near-triangulation (except for 3 sporadic examples) has a dominating set of
size $n/3.5$. On the other hand, for 3-connected near-triangulations, we show a
lower bound of $3(n-1)/11\approx n/3.666$, demonstrating that the conjecture by
Matheson and Tarjan [MT'96] cannot be strengthened to 3-connected
near-triangulations.
<br />Our proof uses a penalty function that, aside from the number of vertices,
penalises vertices of degree 2 and specific constellations of neighbours of
degree 3 along the boundary of the outer face. To facilitate induction, we not
only consider near-triangulations, but a wider class of graphs (skeletal
triangulations), allowing us to delete vertices more freely. Our main technical
contribution is a set of attachments, that are small graphs we inductively
attach to our graph, in order both to remember whether existing vertices are
already dominated, and that serve as a tool in a divide and conquer approach.
Along with a well-chosen potential function, we thus both remove and add
vertices during the induction proof.
<br />We complement our proof with a constructive algorithm that returns a
dominating set of size $\le 2n/7$. Our algorithm has a quadratic running time.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11256" title="Abstract">arXiv:2310.11256</a> (cross-list from stat.ML) [<a href="/pdf/2310.11256" title="Download PDF">pdf</a>, <a href="/format/2310.11256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gromov-Wassertein-like Distances in the Gaussian Mixture Models Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Salmona%2C+A">Antoine Salmona</a>, 
<a href="/search/stat?searchtype=author&query=Delon%2C+J">Julie Delon</a>, 
<a href="/search/stat?searchtype=author&query=Desolneux%2C+A">Agn&#xe8;s Desolneux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we introduce two Gromov-Wasserstein-type distances on the set
of Gaussian mixture models. The first one takes the form of a
Gromov-Wasserstein distance between two discrete distributionson the space of
Gaussian measures. This distance can be used as an alternative to
Gromov-Wasserstein for applications which only require to evaluate how far the
distributions are from each other but does not allow to derive directly an
optimal transportation plan between clouds of points. To design a way to define
such a transportation plan, we introduce another distance between measures
living in incomparable spaces that turns out to be closely related to
Gromov-Wasserstein. When restricting the set of admissible transportation
couplings to be themselves Gaussian mixture models in this latter, this defines
another distance between Gaussian mixture models that can be used as another
alternative to Gromov-Wasserstein and which allows to derive an optimal
assignment between points. Finally, we design a transportation plan associated
with the first distance by analogy with the second, and we illustrate their
practical uses on medium-to-large scale problems such as shape matching and
hyperspectral image color transfer.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11265" title="Abstract">arXiv:2310.11265</a> (cross-list from eess.IV) [<a href="/pdf/2310.11265" title="Download PDF">pdf</a>, <a href="/format/2310.11265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Compression using only Attention based Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luka%2C+N">Natacha Luka</a>, 
<a href="/search/eess?searchtype=author&query=Negrel%2C+R">Romain Negrel</a>, 
<a href="/search/eess?searchtype=author&query=Picard%2C+D">David Picard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In recent research, Learned Image Compression has gained prominence for its
capacity to outperform traditional handcrafted pipelines, especially at low
bit-rates. While existing methods incorporate convolutional priors with
occasional attention blocks to address long-range dependencies, recent advances
in computer vision advocate for a transformative shift towards fully
transformer-based architectures grounded in the attention mechanism. This paper
investigates the feasibility of image compression exclusively using attention
layers within our novel model, QPressFormer. We introduce the concept of
learned image queries to aggregate patch information via cross-attention,
followed by quantization and coding techniques. Through extensive evaluations,
our work demonstrates competitive performance achieved by convolution-free
architectures across the popular Kodak, DIV2K, and CLIC datasets.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11276" title="Abstract">arXiv:2310.11276</a> (cross-list from eess.IV) [<a href="/pdf/2310.11276" title="Download PDF">pdf</a>, <a href="/format/2310.11276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Super-Resolution Using a Grouped Residual in Residual Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ashoori%2C+M">MohammadHossein Ashoori</a>, 
<a href="/search/eess?searchtype=author&query=Amini%2C+A">Arash Amini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Super-resolution (SR) is the technique of increasing the nominal resolution
of image / video content accompanied with quality improvement. Video
super-resolution (VSR) can be considered as the generalization of single image
super-resolution (SISR). This generalization should be such that more detail is
created in the output using adjacent input frames. In this paper, we propose a
grouped residual in residual network (GRRN) for VSR. By adjusting the
hyperparameters of the proposed structure, we train three networks with
different numbers of parameters and compare their quantitative and qualitative
results with the existing methods. Although based on some quantitative
criteria, GRRN does not provide better results than the existing methods, in
terms of the quality of the output image it has acceptable performance.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11277" title="Abstract">arXiv:2310.11277</a> (cross-list from math.CO) [<a href="/pdf/2310.11277" title="Download PDF">pdf</a>, <a href="/ps/2310.11277" title="Download PostScript">ps</a>, <a href="/format/2310.11277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trimming forests is hard (unless they are made of stars)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gishboliner%2C+L">Lior Gishboliner</a>, 
<a href="/search/math?searchtype=author&query=Levanzov%2C+Y">Yevgeny Levanzov</a>, 
<a href="/search/math?searchtype=author&query=Shapira%2C+A">Asaf Shapira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Graph modification problems ask for the minimal number of vertex/edge
additions/deletions needed to make a graph satisfy some predetermined property.
A (meta) problem of this type, which was raised by Yannakakis in 1981, asks to
determine for which properties ${\mathcal P}$, it is NP-hard to compute the
smallest number of edge deletions needed to make a graph satisfy ${\mathcal
P}$. Despite being extensively studied in the past 40 years, this problem is
still wide open. In fact, it is open even when ${\mathcal P}$ is the property
of being $H$-free, for some fixed graph $H$. In this case we use
$\text{rem}_{H}(G)$ to denote the smallest number of edge deletions needed to
turn $G$ into an $H$-free graph.
<br />Alon, Sudakov and Shapira [Annals of Math. 2009] proved that if $H$ is not
bipartite, then computing $\text{rem}_{H}(G)$ is NP-hard. They left open the
problem of classifying the bipartite graphs $H$ for which computing
$\text{rem}_{H}(G)$ is NP-hard. In this paper we resolve this problem when $H$
is a forest, showing that computing $\text{rem}_{H}(G)$ is polynomial-time
solvable if $H$ is a star forest and NP-hard otherwise. Our main innovation in
this work lies in introducing a new graph theoretic approach for Yannakakis's
problem, which differs significantly from all prior works on this subject. In
particular, we prove new results concerning an old and famous conjecture of
Erd\H{o}s and S\'os, which are of independent interest.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11320" title="Abstract">arXiv:2310.11320</a> (cross-list from eess.IV) [<a href="/pdf/2310.11320" title="Download PDF">pdf</a>, <a href="/format/2310.11320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generic Semi-Supervised Framework for Volumetric Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Volume-wise labeling in 3D medical images is a time-consuming task that
requires expertise. As a result, there is growing interest in using
semi-supervised learning (SSL) techniques to train models with limited labeled
data. However, the challenges and practical applications extend beyond SSL to
settings such as unsupervised domain adaptation (UDA) and semi-supervised
domain generalization (SemiDG). This work aims to develop a generic SSL
framework that can handle all three settings. We identify two main obstacles to
achieving this goal in the existing SSL framework: 1) the weakness of capturing
distribution-invariant features; and 2) the tendency for unlabeled data to be
overwhelmed by labeled data, leading to over-fitting to the labeled data during
training. To address these issues, we propose an Aggregating &amp; Decoupling
framework. The aggregating part consists of a Diffusion encoder that constructs
a common knowledge set by extracting distribution-invariant features from
aggregated information from multiple distributions/domains. The decoupling part
consists of three decoders that decouple the training process with labeled and
unlabeled data, thus avoiding over-fitting to labeled data, specific domains
and classes. We evaluate our proposed framework on four benchmark datasets for
SSL, Class-imbalanced SSL, UDA and SemiDG. The results showcase notable
improvements compared to state-of-the-art methods across all four settings,
indicating the potential of our framework to tackle more challenging SSL
scenarios. Code and models are available at:
https://github.com/xmed-lab/GenericSSL.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11340" title="Abstract">arXiv:2310.11340</a> (cross-list from stat.ML) [<a href="/pdf/2310.11340" title="Download PDF">pdf</a>, <a href="/format/2310.11340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextualized Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lengerich%2C+B">Benjamin Lengerich</a>, 
<a href="/search/stat?searchtype=author&query=Ellington%2C+C+N">Caleb N. Ellington</a>, 
<a href="/search/stat?searchtype=author&query=Rubbi%2C+A">Andrea Rubbi</a>, 
<a href="/search/stat?searchtype=author&query=Kellis%2C+M">Manolis Kellis</a>, 
<a href="/search/stat?searchtype=author&query=Xing%2C+E+P">Eric P. Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We examine Contextualized Machine Learning (ML), a paradigm for learning
heterogeneous and context-dependent effects. Contextualized ML estimates
heterogeneous functions by applying deep learning to the meta-relationship
between contextual information and context-specific parametric models. This is
a form of varying-coefficient modeling that unifies existing frameworks
including cluster analysis and cohort modeling by introducing two reusable
concepts: a context encoder which translates sample context into model
parameters, and sample-specific model which operates on sample predictors. We
review the process of developing contextualized models, nonparametric inference
from contextualized models, and identifiability conditions of contextualized
models. Finally, we present the open-source PyTorch package ContextualizedML.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11394" title="Abstract">arXiv:2310.11394</a> (cross-list from quant-ph) [<a href="/pdf/2310.11394" title="Download PDF">pdf</a>, <a href="/format/2310.11394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Financial Modeling on NISQ Hardware: Random Walks using  Approximate Quantum Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Widdows%2C+D">Dominic Widdows</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Quantum computers are expected to contribute more efficient and accurate ways
of modeling economic processes. Quantum hardware is currently available at a
relatively small scale, but effective algorithms are limited by the number of
logic gates that can be used, before noise from gate inaccuracies tends to
dominate results. Some theoretical algorithms that have been proposed and
studied for years do not perform well yet on quantum hardware in practice. This
encourages the development of suitable alternative algorithms that play similar
roles in limited contexts.
<br />This paper implements this strategy in the case of quantum counting, which is
used as a component for keeping track of position in a quantum walk, which is
used as a model for simulating asset prices over time. We introduce quantum
approximate counting circuits that use far fewer 2-qubit entangling gates than
traditional quantum counting that relies on binary positional encoding. The
robustness of these circuits to noise is demonstrated.
<br />While this paper is mainly about robust simplified quantum circuit designs,
we compare some aspects of the results with price change distributions from
stock indices, and compare the behavior of circuits with and without
mid-measurement to trends in the housing market.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11404" title="Abstract">arXiv:2310.11404</a> (cross-list from math.OC) [<a href="/pdf/2310.11404" title="Download PDF">pdf</a>, <a href="/ps/2310.11404" title="Download PostScript">ps</a>, <a href="/format/2310.11404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesis of constrained robust feedback policies and model predictive  control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gramlich%2C+D">Dennis Gramlich</a>, 
<a href="/search/math?searchtype=author&query=Scherer%2C+C+W">Carsten W. Scherer</a>, 
<a href="/search/math?searchtype=author&query=H%C3%A4ring%2C+H">Hannah H&#xe4;ring</a>, 
<a href="/search/math?searchtype=author&query=Ebenbauer%2C+C">Christian Ebenbauer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of a contribution to be submitted to the European Control Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this work, we develop a method based on robust control techniques to
synthesize robust time-varying state-feedback policies for finite, infinite,
and receding horizon control problems subject to convex quadratic state and
input constraints. To ensure constraint satisfaction of our policy, we employ
(initial state)-to-peak gain techniques. Based on this idea, we formulate
linear matrix inequality conditions, which are simultaneously convex in the
parameters of an affine control policy, a Lyapunov function along the
trajectory and multiplier variables for the uncertainties in a time-varying
linear fractional transformation model. In our experiments this approach is
less conservative than standard tube-based robust model predictive control
methods.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11414" title="Abstract">arXiv:2310.11414</a> (cross-list from math.OC) [<a href="/pdf/2310.11414" title="Download PDF">pdf</a>, <a href="/format/2310.11414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of Fossil Fuel Consumption under Grid Energy Supply by Wind  Energy and Auxiliary Batteries Using Fossil Fuel for Energy Supply
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, a class of systems in which auxiliary batteries fed by fossil
fuel generation and wind farms work together to supply power to the grid are
modeled and strategies are solved to minimize the consumption of fossil fuels
while still allowing the total energy to satisfy the energy demand of the grid.
The wind resource is modeled using stochastic differential equations and the
grid energy demand is also stochastically modeled using stochastic differential
equations. The two stochastic models are well calibrated using wind resource
data from historical wind farms and historical grid energy demand data.
Finally, dynamic programming is used to solve this optimization problem.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11416" title="Abstract">arXiv:2310.11416</a> (cross-list from math.OC) [<a href="/pdf/2310.11416" title="Download PDF">pdf</a>, <a href="/ps/2310.11416" title="Download PostScript">ps</a>, <a href="/format/2310.11416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Block Backstepping for Isotachic Hyperbolic PDEs and Multilayer  Timoshenko Beams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+G">Guangwei Chen</a>, 
<a href="/search/math?searchtype=author&query=Vazquez%2C+R">Rafael Vazquez</a>, 
<a href="/search/math?searchtype=author&query=Qiao%2C+J">Junfei Qiao</a>, 
<a href="/search/math?searchtype=author&query=Krstic%2C+M">Miroslav Krstic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we investigate the rapid stabilization of N-layer Timoshenko
composite beams with anti-damping and anti-stiffness at the uncontrolled
boundaries. The problem of stabilization for a two-layer composite beam has
been previously studied by transforming the model into a 1-D hyperbolic
PIDE-ODE form and then applying backstepping to this new system. In principle
this approach is generalizable to any number of layers. However, when some of
the layers have the same physical properties (as e.g. in lamination of repeated
layers), the approach leads to isotachic hyperbolic PDEs (i.e. where some
states have the same transport speed). This particular yet physical and
interesting case has not received much attention beyond a few remarks in the
early hyperbolic design. Thus, this work starts by extending the theory of
backstepping control of (m + n) hyperbolic PIDEs and m ODEs to blocks of
isotachic states, leading to a block backstepping design. Then, returning to
multilayer Timoshenko beams, the Riemann transformation is used to transform
the states of N-layer Timoshenko beams into a 1-D hyperbolic PIDE-ODE system.
The block backstepping method is then applied to this model, obtaining
closed-loop stability of the origin in the L2 sense. An arbitrarily rapid
convergence rate can be obtained by adjusting control parameters. Finally,
numerical simulations are presented corroborating the theoretical developments.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11431" title="Abstract">arXiv:2310.11431</a> (cross-list from stat.ML) [<a href="/pdf/2310.11431" title="Download PDF">pdf</a>, <a href="/format/2310.11431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Interpretable Visual Features in Artificial and Biological  Neural Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Klindt%2C+D">David Klindt</a>, 
<a href="/search/stat?searchtype=author&query=Sanborn%2C+S">Sophia Sanborn</a>, 
<a href="/search/stat?searchtype=author&query=Acosta%2C+F">Francisco Acosta</a>, 
<a href="/search/stat?searchtype=author&query=Poitevin%2C+F">Fr&#xe9;d&#xe9;ric Poitevin</a>, 
<a href="/search/stat?searchtype=author&query=Miolane%2C+N">Nina Miolane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Single neurons in neural networks are often ``interpretable'' in that they
represent individual, intuitively meaningful features. However, many neurons
exhibit $\textit{mixed selectivity}$, i.e., they represent multiple unrelated
features. A recent hypothesis proposes that features in deep networks may be
represented in $\textit{superposition}$, i.e., on non-orthogonal axes by
multiple neurons, since the number of possible interpretable features in
natural data is generally larger than the number of neurons in a given network.
Accordingly, we should be able to find meaningful directions in activation
space that are not aligned with individual neurons. Here, we propose (1) an
automated method for quantifying visual interpretability that is validated
against a large database of human psychophysics judgments of neuron
interpretability, and (2) an approach for finding meaningful directions in
network activation space. We leverage these methods to discover directions in
convolutional neural networks that are more intuitively meaningful than
individual neurons, as we confirm and investigate in a series of analyses.
Moreover, we apply the same method to two recent datasets of visual neural
responses in the brain and find that our conclusions largely transfer to real
neural data, suggesting that superposition might be deployed by the brain. This
also provides a link with disentanglement and raises fundamental questions
about robust, efficient and factorized representations in both artificial and
biological neural systems.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11445" title="Abstract">arXiv:2310.11445</a> (cross-list from quant-ph) [<a href="/pdf/2310.11445" title="Download PDF">pdf</a>, <a href="/ps/2310.11445" title="Download PostScript">ps</a>, <a href="/format/2310.11445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Quantum Sampling for Non-Logconcave Distributions and  Estimating Partition Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ozgul%2C+G">Guneykan Ozgul</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+X">Xiantao Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mahdavi%2C+M">Mehrdad Mahdavi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+C">Chunhao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">We present quantum algorithms for sampling from non-logconcave probability
distributions in the form of $\pi(x) \propto \exp(-\beta f(x))$. Here, $f$ can
be written as a finite sum $f(x):= \frac{1}{N}\sum_{k=1}^N f_k(x)$. Our
approach is based on quantum simulated annealing on slowly varying Markov
chains derived from unadjusted Langevin algorithms, removing the necessity for
function evaluations which can be computationally expensive for large data sets
in mixture modeling and multi-stable systems. We also incorporate a stochastic
gradient oracle that implements the quantum walk operators inexactly by only
using mini-batch gradients. As a result, our stochastic gradient based
algorithm only accesses small subsets of data points in implementing the
quantum walk. One challenge of quantizing the resulting Markov chains is that
they do not satisfy the detailed balance condition in general. Consequently,
the mixing time of the algorithm cannot be expressed in terms of the spectral
gap of the transition density, making the quantum algorithms nontrivial to
analyze. To overcome these challenges, we first build a hypothetical Markov
chain that is reversible, and also converges to the target distribution. Then,
we quantified the distance between our algorithm's output and the target
distribution by using this hypothetical chain as a bridge to establish the
total complexity. Our quantum algorithms exhibit polynomial speedups in terms
of both dimension and precision dependencies when compared to the best-known
classical algorithms.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed, 18 Oct 23</h3>
<dl>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1804.09133" title="Abstract">arXiv:1804.09133</a> (replaced) [<a href="/pdf/1804.09133" title="Download PDF">pdf</a>, <a href="/format/1804.09133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Native Ads CTR Prediction by Large Scale Event Embedding and  Recurrent Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parsana%2C+M">Mehul Parsana</a>, 
<a href="/search/cs?searchtype=author&query=Poola%2C+K">Krishna Poola</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yajun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiguang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1907.04585" title="Abstract">arXiv:1907.04585</a> (replaced) [<a href="/pdf/1907.04585" title="Download PDF">pdf</a>, <a href="/format/1907.04585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quasi-polynomial time approximation schemes for the Maximum Weight  Independent Set Problem in H-free graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chudnovsky%2C+M">Maria Chudnovsky</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Marcin Pilipczuk</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Micha&#x142; Pilipczuk</a>, 
<a href="/search/cs?searchtype=author&query=Thomass%C3%A9%2C+S">St&#xe9;phan Thomass&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: added results on subexponential algorithms, v3: revision after reviewers' remarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.08410" title="Abstract">arXiv:2002.08410</a> (replaced) [<a href="/pdf/2002.08410" title="Download PDF">pdf</a>, <a href="/format/2002.08410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Mixture Reduction with Composite Transportation Divergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Q">Qiong Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+A+G">Archer Gong Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+J">Jiahua Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.05845" title="Abstract">arXiv:2011.05845</a> (replaced) [<a href="/pdf/2011.05845" title="Download PDF">pdf</a>, <a href="/ps/2011.05845" title="Download PostScript">ps</a>, <a href="/format/2011.05845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a general matrix-valued unbalanced optimal transport problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+B">Bowen Li</a>, 
<a href="/search/math?searchtype=author&query=Zou%2C+J">Jun Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For readability, it is split into two parts; the second part for numerics is in <a href="/abs/2310.09420">arXiv:2310.09420</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.07724" title="Abstract">arXiv:2102.07724</a> (replaced) [<a href="/pdf/2102.07724" title="Download PDF">pdf</a>, <a href="/format/2102.07724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locality and Centrality: The Variety ZG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amarilli%2C+A">Antoine Amarilli</a>, 
<a href="/search/cs?searchtype=author&query=Paperman%2C+C">Charles Paperman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.08634" title="Abstract">arXiv:2104.08634</a> (replaced) [<a href="/pdf/2104.08634" title="Download PDF">pdf</a>, <a href="/format/2104.08634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARES: Accurate, Autonomous, Near Real-time 3D Reconstruction using  Drones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+F">Fawad Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+C">Christina Shin</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+R">Rajrup Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=D%27Ambrosio%2C+J">John D&#x27;Ambrosio</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+E">Eugene Chai</a>, 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+K">Karthik Sundaresan</a>, 
<a href="/search/cs?searchtype=author&query=Govindan%2C+R">Ramesh Govindan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.01331" title="Abstract">arXiv:2105.01331</a> (replaced) [<a href="/pdf/2105.01331" title="Download PDF">pdf</a>, <a href="/format/2105.01331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLM-17m: A Large-Scale Dataset for Black Lives Matter Topic Detection on  Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kemik%2C+H">Hasan Kemik</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zate%C5%9F%2C+N">Nusret &#xd6;zate&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=Asgari-Chenaghlu%2C+M">Meysam Asgari-Chenaghlu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Cambria%2C+E">Erik Cambria</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.01382" title="Abstract">arXiv:2106.01382</a> (replaced) [<a href="/pdf/2106.01382" title="Download PDF">pdf</a>, <a href="/format/2106.01382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Undecidability of Non-Triviality and Finiteness to Undecidability  of Learnability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caro%2C+M+C">Matthias C. Caro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages (main body) + 11 pages (references and appendix); 1 figure; Close to published version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Approximate Reasoning 163, 109057 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Machine Learning (cs.LG); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.06483" title="Abstract">arXiv:2106.06483</a> (replaced) [<a href="/pdf/2106.06483" title="Download PDF">pdf</a>, <a href="/ps/2106.06483" title="Download PostScript">ps</a>, <a href="/format/2106.06483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Model Selection in Contextual Bandits with Many Classes via  Offline Oracles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+S+K">Sanath Kumar Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Propp%2C+A+M">Adrienne Margaret Propp</a>, 
<a href="/search/cs?searchtype=author&query=Athey%2C+S">Susan Athey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.02565" title="Abstract">arXiv:2107.02565</a> (replaced) [<a href="/pdf/2107.02565" title="Download PDF">pdf</a>, <a href="/format/2107.02565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prioritized training on points that are learnable, worth learning, and  not yet learned (workshop version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mindermann%2C+S">S&#xf6;ren Mindermann</a>, 
<a href="/search/cs?searchtype=author&query=Razzak%2C+M">Muhammed Razzak</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Winnie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kirsch%2C+A">Andreas Kirsch</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Mrinank Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Morisot%2C+A">Adrien Morisot</a>, 
<a href="/search/cs?searchtype=author&query=Gomez%2C+A+N">Aidan N. Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Farquhar%2C+S">Sebastian Farquhar</a>, 
<a href="/search/cs?searchtype=author&query=Brauner%2C+J">Jan Brauner</a>, 
<a href="/search/cs?searchtype=author&query=Gal%2C+Y">Yarin Gal</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICML 2021 Workshop on Subset Selection in Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.12978" title="Abstract">arXiv:2108.12978</a> (replaced) [<a href="/pdf/2108.12978" title="Download PDF">pdf</a>, <a href="/format/2108.12978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Multi-Task Learning: Formulation and Applications to Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+V">Virginia Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TMLR. Transactions on Machine Learning Research (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.07101" title="Abstract">arXiv:2109.07101</a> (replaced) [<a href="/pdf/2109.07101" title="Download PDF">pdf</a>, <a href="/format/2109.07101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delay-aware Robust Control for Safe Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalaria%2C+D">Dvij Kalaria</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dolan%2C+J+M">John M. Dolan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IV 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.12989" title="Abstract">arXiv:2109.12989</a> (replaced) [<a href="/pdf/2109.12989" title="Download PDF">pdf</a>, <a href="/format/2109.12989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperQB: A QBF-Based Bounded Model Checker for Hyperproperties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsu%2C+T">Tzu-Han Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Bonakdarpour%2C+B">Borzoo Bonakdarpour</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+C">C&#xe9;sar S&#xe1;nchez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.02355" title="Abstract">arXiv:2111.02355</a> (replaced) [<a href="/pdf/2111.02355" title="Download PDF">pdf</a>, <a href="/format/2111.02355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theoretical Analysis on Independence-driven Importance Weighting for  Covariate-shift Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zheyan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.04543" title="Abstract">arXiv:2111.04543</a> (replaced) [<a href="/pdf/2111.04543" title="Download PDF">pdf</a>, <a href="/ps/2111.04543" title="Download PostScript">ps</a>, <a href="/format/2111.04543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Treewidth versus clique number. II. Tree-independence number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dallard%2C+C">Cl&#xe9;ment Dallard</a>, 
<a href="/search/math?searchtype=author&query=Milani%C4%8D%2C+M">Martin Milani&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=%C5%A0torgel%2C+K">Kenny &#x160;torgel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages; abstract has been shortened due to arXiv requirements. A previous version of this arXiv post has been reorganized into two parts; this is the first of the two parts (the second one is <a href="/abs/2206.15092">arXiv:2206.15092</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.01536" title="Abstract">arXiv:2203.01536</a> (replaced) [<a href="/pdf/2203.01536" title="Download PDF">pdf</a>, <a href="/format/2203.01536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent Advances in Vision Transformer: A Survey and Outlook of Recent  Work
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+K">Khawar Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added AAAI 2022 methods and working on ICLR 2022 methods and ICML 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03149" title="Abstract">arXiv:2203.03149</a> (replaced) [<a href="/pdf/2203.03149" title="Download PDF">pdf</a>, <a href="/format/2203.03149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIDO: Deep Inertial Quadrotor Dynamical Odometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kunyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chenxing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinghang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Teng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures, accepted by IROS 2022 with RA-L
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16482" title="Abstract">arXiv:2203.16482</a> (replaced) [<a href="/pdf/2203.16482" title="Download PDF">pdf</a>, <a href="/format/2203.16482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RFNet-4D++: Joint Object Reconstruction and Flow Estimation from 4D  Point Clouds with Cross-Attention Spatio-Temporal Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Tuan-Anh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+T">Duc Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+B">Binh-Son Hua</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quang-Hieu Pham</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Sai-Kit Yeung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TPAMI journal extension of ECCV 2022 <a href="/abs/2203.16482">arXiv:2203.16482</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.17168" title="Abstract">arXiv:2203.17168</a> (replaced) [<a href="/pdf/2203.17168" title="Download PDF">pdf</a>, <a href="/ps/2203.17168" title="Download PostScript">ps</a>, <a href="/format/2203.17168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower bounds for uniform read-once threshold formulae in the randomized  decision tree model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leonardos%2C+N">Nikos Leonardos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added a remark
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.03046" title="Abstract">arXiv:2204.03046</a> (replaced) [<a href="/pdf/2204.03046" title="Download PDF">pdf</a>, <a href="/format/2204.03046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertical Allocation-based Fair Exposure Amortizing in Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhichao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04793" title="Abstract">arXiv:2204.04793</a> (replaced) [<a href="/pdf/2204.04793" title="Download PDF">pdf</a>, <a href="/format/2204.04793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fake news detection using parallel BERT deep neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farokhian%2C+M">Mahmood Farokhian</a>, 
<a href="/search/cs?searchtype=author&query=Rafe%2C+V">Vahid Rafe</a>, 
<a href="/search/cs?searchtype=author&query=Veisi%2C+H">Hadi Veisi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Multimed Tools Appl (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.07481" title="Abstract">arXiv:2204.07481</a> (replaced) [<a href="/pdf/2204.07481" title="Download PDF">pdf</a>, <a href="/format/2204.07481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Equivalence in Digital Twins of Intelligent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Nan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bahsoon%2C+R">Rami Bahsoon</a>, 
<a href="/search/cs?searchtype=author&query=Tziritas%2C+N">Nikos Tziritas</a>, 
<a href="/search/cs?searchtype=author&query=Theodoropoulos%2C+G">Georgios Theodoropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 16 figures. Under review. Submitted to ACM Transactions on Modeling and Computer Simulation (TOMACS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.10027" title="Abstract">arXiv:2205.10027</a> (replaced) [<a href="/pdf/2205.10027" title="Download PDF">pdf</a>, <a href="/format/2205.10027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pISTA: preconditioned Iterative Soft Thresholding Algorithm for  Graphical Lasso
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shalom%2C+G">Gal Shalom</a>, 
<a href="/search/math?searchtype=author&query=Treister%2C+E">Eran Treister</a>, 
<a href="/search/math?searchtype=author&query=Yavneh%2C+I">Irad Yavneh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Software (cs.MS)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02346" title="Abstract">arXiv:2206.02346</a> (replaced) [<a href="/pdf/2206.02346" title="Download PDF">pdf</a>, <a href="/format/2206.02346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence and sample complexity of natural policy gradient primal-dual  methods for constrained MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ding%2C+D">Dongsheng Ding</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+K">Kaiqing Zhang</a>, 
<a href="/search/math?searchtype=author&query=Duan%2C+J">Jiali Duan</a>, 
<a href="/search/math?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>, 
<a href="/search/math?searchtype=author&query=Jovanovi%C4%87%2C+M+R">Mihailo R. Jovanovi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 72 pages, 4 figures, 2 tables; revised sample complexity and computational experiments, and added zero constraint violation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05833" title="Abstract">arXiv:2206.05833</a> (replaced) [<a href="/pdf/2206.05833" title="Download PDF">pdf</a>, <a href="/format/2206.05833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COLD Fusion: Calibrated and Ordinal Latent Distribution Fusion for  Uncertainty-Aware Multimodal Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tellamekala%2C+M+K">Mani Kumar Tellamekala</a>, 
<a href="/search/cs?searchtype=author&query=Amiriparian%2C+S">Shahin Amiriparian</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn W. Schuller</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+E">Elisabeth Andr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Giesbrecht%2C+T">Timo Giesbrecht</a>, 
<a href="/search/cs?searchtype=author&query=Valstar%2C+M">Michel Valstar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.06299" title="Abstract">arXiv:2206.06299</a> (replaced) [<a href="/pdf/2206.06299" title="Download PDF">pdf</a>, <a href="/format/2206.06299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An adversarially robust data-market for spatial, crowd-sourced data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kharman%2C+A+M">Aida Manzano Kharman</a>, 
<a href="/search/cs?searchtype=author&query=Jursitzky%2C+C">Christian Jursitzky</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Quan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ferraro%2C+P">Pietro Ferraro</a>, 
<a href="/search/cs?searchtype=author&query=Marecek%2C+J">Jakub Marecek</a>, 
<a href="/search/cs?searchtype=author&query=Pinson%2C+P">Pierre Pinson</a>, 
<a href="/search/cs?searchtype=author&query=Shorten%2C+R">Robert Shorten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07940" title="Abstract">arXiv:2206.07940</a> (replaced) [<a href="/e-print/2206.07940" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROFHIT: Probabilistic Robust Forecasting for Hierarchical Time-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamarthi%2C+H">Harshavardhan Kamarthi</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingkai Kong</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez%2C+A">Alexander Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+B+A">B. Aditya Prakash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted a new version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09818" title="Abstract">arXiv:2206.09818</a> (replaced) [<a href="/pdf/2206.09818" title="Download PDF">pdf</a>, <a href="/format/2206.09818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSM-DTA: Breaking the Barriers of Data Scarcity in Drug-Target Affinity  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Pei%2C+Q">Qizhi Pei</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+L">Lijun Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhu%2C+J">Jinhua Zhu</a>, 
<a href="/search/q-bio?searchtype=author&query=Xia%2C+Y">Yingce Xia</a>, 
<a href="/search/q-bio?searchtype=author&query=Xie%2C+S">Shufang Xie</a>, 
<a href="/search/q-bio?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+H">Haiguang Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+T">Tie-Yan Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Briefings in Bioinformatics 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10745" title="Abstract">arXiv:2206.10745</a> (replaced) [<a href="/pdf/2206.10745" title="Download PDF">pdf</a>, <a href="/format/2206.10745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Derivative-Informed Neural Operator: An Efficient Framework for  High-Dimensional Parametric Derivative Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=O%27Leary-Roseberry%2C+T">Thomas O&#x27;Leary-Roseberry</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/math?searchtype=author&query=Villa%2C+U">Umberto Villa</a>, 
<a href="/search/math?searchtype=author&query=Ghattas%2C+O">Omar Ghattas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.07173" title="Abstract">arXiv:2207.07173</a> (replaced) [<a href="/pdf/2207.07173" title="Download PDF">pdf</a>, <a href="/format/2207.07173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Image Clustering with Contrastive Learning and Multi-scale Graph  Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuankun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Dong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chang-Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+J">Jian-Huang Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Pattern Recognition journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08610" title="Abstract">arXiv:2207.08610</a> (replaced) [<a href="/pdf/2207.08610" title="Download PDF">pdf</a>, <a href="/format/2207.08610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid and robust synchronization via weak synaptic coupling Extended  arXiv version
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+J+G">Jin Gyu Lee</a>, 
<a href="/search/eess?searchtype=author&query=Sepulchre%2C+R">Rodolphe Sepulchre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.12547" title="Abstract">arXiv:2207.12547</a> (replaced) [<a href="/pdf/2207.12547" title="Download PDF">pdf</a>, <a href="/format/2207.12547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The BUTTER Zone: An Empirical Study of Training Dynamics in Fully  Connected Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tripp%2C+C+E">Charles Edison Tripp</a>, 
<a href="/search/cs?searchtype=author&query=Perr-Sauer%2C+J">Jordan Perr-Sauer</a>, 
<a href="/search/cs?searchtype=author&query=Hayne%2C+L">Lucas Hayne</a>, 
<a href="/search/cs?searchtype=author&query=Lunacek%2C+M">Monte Lunacek</a>, 
<a href="/search/cs?searchtype=author&query=Gafur%2C+J">Jamil Gafur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13559" title="Abstract">arXiv:2207.13559</a> (replaced) [<a href="/pdf/2207.13559" title="Download PDF">pdf</a>, <a href="/format/2207.13559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balanced Encoding of Near-Zero Correlation for an AES Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungkwang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeong-Nyeo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 25 figures, submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01387" title="Abstract">arXiv:2209.01387</a> (replaced) [<a href="/pdf/2209.01387" title="Download PDF">pdf</a>, <a href="/ps/2209.01387" title="Download PostScript">ps</a>, <a href="/format/2209.01387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential Privacy on Dynamic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Ke Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02397" title="Abstract">arXiv:2209.02397</a> (replaced) [<a href="/pdf/2209.02397" title="Download PDF">pdf</a>, <a href="/format/2209.02397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Scene-Text Synthesis Engine Achieved Through Learning from Decomposed  Real-World Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhengmi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Miyazaki%2C+T">Tomo Miyazaki</a>, 
<a href="/search/cs?searchtype=author&query=Omachi%2C+S">Shinichiro Omachi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03737" title="Abstract">arXiv:2209.03737</a> (replaced) [<a href="/pdf/2209.03737" title="Download PDF">pdf</a>, <a href="/format/2209.03737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CGAN-ECT: Tomography Image Reconstruction from Electrical Capacitance  Measurements Using CGANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deabes%2C+W">Wael Deabes</a>, 
<a href="/search/eess?searchtype=author&query=Abdel-Hakim%2C+A+E">Alaa E. Abdel-Hakim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09483" title="Abstract">arXiv:2209.09483</a> (replaced) [<a href="/pdf/2209.09483" title="Download PDF">pdf</a>, <a href="/format/2209.09483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Unit: Interpretable Edge Enhancement and Suppression Learning  for 3D Point Cloud Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiu%2C+H">Haoyi Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weimin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kyoung-Sook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shinohara%2C+T">Takayuki Shinohara</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Q">Qiong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Matsuoka%2C+M">Masashi Matsuoka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurocomputing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11524" title="Abstract">arXiv:2209.11524</a> (replaced) [<a href="/pdf/2209.11524" title="Download PDF">pdf</a>, <a href="/format/2209.11524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control Barrier Functions in UGVs for Kinematic Obstacle Avoidance: A  Collision Cone Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thontepu%2C+P">Phani Thontepu</a>, 
<a href="/search/cs?searchtype=author&query=Goswami%2C+B+G">Bhavya Giri Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Tayal%2C+M">Manan Tayal</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+N">Neelaksh Singh</a>, 
<a href="/search/cs?searchtype=author&query=I%2C+S+P">Shyamsundar P I</a>, 
<a href="/search/cs?searchtype=author&query=G%2C+S+S+M">Shyam Sundar M G</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+S">Suresh Sundaram</a>, 
<a href="/search/cs?searchtype=author&query=Katewa%2C+V">Vaibhav Katewa</a>, 
<a href="/search/cs?searchtype=author&query=Kolathaya%2C+S">Shishir Kolathaya</a> (Robert Bosch Center for Cyber-Physical Systems (RBCCPS), Indian Institute of Science (IISc), Bengaluru)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, For supplement video follow <a href="https://youtu.be/Dme7Wm9y6es.">this https URL</a> *The first and second authors have contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05521" title="Abstract">arXiv:2210.05521</a> (replaced) [<a href="/pdf/2210.05521" title="Download PDF">pdf</a>, <a href="/format/2210.05521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Inverted Index Is a Robust Accelerator for Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shitao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhicheng Dou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jing Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11443" title="Abstract">arXiv:2210.11443</a> (replaced) [<a href="/pdf/2210.11443" title="Download PDF">pdf</a>, <a href="/format/2210.11443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Snapshot of Algebraic Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kileel%2C+J">Joe Kileel</a>, 
<a href="/search/math?searchtype=author&query=Kohn%2C+K">Kathl&#xe9;n Kohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: incorporated referees' suggestions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01607" title="Abstract">arXiv:2211.01607</a> (replaced) [<a href="/pdf/2211.01607" title="Download PDF">pdf</a>, <a href="/format/2211.01607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImageCAS: A Large-Scale Dataset and Benchmark for Coronary Artery  Segmentation based on Computed Tomography Angiography Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zeng%2C+A">An Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Chunbiao Wu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+M">Meiping Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zhuang%2C+J">Jian Zhuang</a>, 
<a href="/search/eess?searchtype=author&query=Bi%2C+S">Shanshan Bi</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+D">Dan Pan</a>, 
<a href="/search/eess?searchtype=author&query=Ullah%2C+N">Najeeb Ullah</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+K+N">Kaleem Nawaz Khan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Tianchen Wang</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+G">Guisen Lin</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+X">Xiaowei Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 12 figures, 4 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computerized Medical Imaging and Graphics, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03100" title="Abstract">arXiv:2211.03100</a> (replaced) [<a href="/pdf/2211.03100" title="Download PDF">pdf</a>, <a href="/format/2211.03100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting User-specific Future Activities using LSTM-based Multi-label  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Irbaz%2C+M+S">Mohammad Sabik Irbaz</a>, 
<a href="/search/cs?searchtype=author&query=Sakib%2C+F+A">Fardin Ahsan Sakib</a>, 
<a href="/search/cs?searchtype=author&query=Lota%2C+L+N">Lutfun Nahar Lota</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Proceedings of the 4th International Conference on Activity and Behavior Computing 2022 (ABC 2022) Reference: <a href="https://abc-research.github.io/challenge2022/results/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03363" title="Abstract">arXiv:2211.03363</a> (replaced) [<a href="/pdf/2211.03363" title="Download PDF">pdf</a>, <a href="/format/2211.03363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Over-The-Air Clustered Wireless Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madhan-Sohini%2C+A">Ayush Madhan-Sohini</a>, 
<a href="/search/cs?searchtype=author&query=Dominic%2C+D">Divin Dominic</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+N">Nazreen Shah</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+R">Ranjitha Prasad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE GlobeCom 2023, ELNextGen Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05412" title="Abstract">arXiv:2211.05412</a> (replaced) [<a href="/pdf/2211.05412" title="Download PDF">pdf</a>, <a href="/format/2211.05412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Desire Backpropagation: A Lightweight Training Algorithm for Multi-Layer  Spiking Neural Networks based on Spike-Timing-Dependent Plasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gerlinghoff%2C+D">Daniel Gerlinghoff</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+R+S+M">Rick Siow Mong Goh</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+W">Weng-Fai Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11990" title="Abstract">arXiv:2211.11990</a> (replaced) [<a href="/pdf/2211.11990" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiME and AGVis: A Distributed Messaging Environment and Geographical  Visualizer for Large-scale Power System Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Parsly%2C+N">Nicholas Parsly</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jinning Wang</a>, 
<a href="/search/eess?searchtype=author&query=West%2C+N">Nick West</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Q">Qiwei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+H">Hantao Cui</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+F">Fangxing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13543" title="Abstract">arXiv:2211.13543</a> (replaced) [<a href="/pdf/2211.13543" title="Download PDF">pdf</a>, <a href="/format/2211.13543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impure Simplicial Complexes: Complete Axiomatization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Randrianomentsoa%2C+R">Rojo Randrianomentsoa</a>, 
<a href="/search/cs?searchtype=author&query=van+Ditmarsch%2C+H">Hans van Ditmarsch</a>, 
<a href="/search/cs?searchtype=author&query=Kuznets%2C+R">Roman Kuznets</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14420" title="Abstract">arXiv:2211.14420</a> (replaced) [<a href="/e-print/2211.14420" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Photo Rater: Photographs Auto-Selector with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wentao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+C">Charlie Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Claire Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The authors discovered issues in the code that produced figures 8 and 9
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.17148" title="Abstract">arXiv:2211.17148</a> (replaced) [<a href="/pdf/2211.17148" title="Download PDF">pdf</a>, <a href="/format/2211.17148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConvLab-3: A Flexible Dialogue System Toolkit Based on a Unified Data  Format
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Geishauser%2C+C">Christian Geishauser</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsien-chin Lin</a>, 
<a href="/search/cs?searchtype=author&query=van+Niekerk%2C+C">Carel van Niekerk</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Baolin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Heck%2C+M">Michael Heck</a>, 
<a href="/search/cs?searchtype=author&query=Lubis%2C+N">Nurul Lubis</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+D">Dazhen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaochen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1i%C4%87%2C+M">Milica Ga&#x161;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02083" title="Abstract">arXiv:2212.02083</a> (replaced) [<a href="/pdf/2212.02083" title="Download PDF">pdf</a>, <a href="/format/2212.02083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Overlooked Structure of Stochastic Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zeke Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qian-Yuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingming Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Ping Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. 20 pages, 16 figures, 17 Tables; Key Words: Deep Learning, Stochastic Gradient, Optimization. arXiv admin note: text overlap with <a href="/abs/2201.13011">arXiv:2201.13011</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06312" title="Abstract">arXiv:2212.06312</a> (replaced) [<a href="/pdf/2212.06312" title="Download PDF">pdf</a>, <a href="/format/2212.06312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy learning for many outcomes of interest: Combining optimal policy  trees with multi-objective Bayesian optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rehill%2C+P">Patrick Rehill</a>, 
<a href="/search/cs?searchtype=author&query=Biddle%2C+N">Nicholas Biddle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Econometrics (econ.EM)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07055" title="Abstract">arXiv:2212.07055</a> (replaced) [<a href="/pdf/2212.07055" title="Download PDF">pdf</a>, <a href="/format/2212.07055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Most Important Person-guided Dual-branch Cross-Patch Attention for Group  Affect Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hongxia Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Ming-Xian Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tzu-Jui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hung-Jen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hou-I Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+H">Hong-Han Shuai</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wen-Huang Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07489" title="Abstract">arXiv:2212.07489</a> (replaced) [<a href="/pdf/2212.07489" title="Download PDF">pdf</a>, <a href="/format/2212.07489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMACv2: An Improved Benchmark for Cooperative Multi-Agent Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ellis%2C+B">Benjamin Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+J">Jonathan Cook</a>, 
<a href="/search/cs?searchtype=author&query=Moalla%2C+S">Skander Moalla</a>, 
<a href="/search/cs?searchtype=author&query=Samvelyan%2C+M">Mikayel Samvelyan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingfei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+A">Anuj Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+J+N">Jakob N. Foerster</a>, 
<a href="/search/cs?searchtype=author&query=Whiteson%2C+S">Shimon Whiteson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10230" title="Abstract">arXiv:2212.10230</a> (replaced) [<a href="/pdf/2212.10230" title="Download PDF">pdf</a>, <a href="/format/2212.10230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study of the Robustness for LiDAR-based 3D Object  Detectors against Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yixuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 14 figures. Accepted by IJCV
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11580" title="Abstract">arXiv:2212.11580</a> (replaced) [<a href="/pdf/2212.11580" title="Download PDF">pdf</a>, <a href="/ps/2212.11580" title="Download PostScript">ps</a>, <a href="/format/2212.11580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theory of Conversion Relations for Prefixed Units of Measure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Widemann%2C+B+T+y">Baltasar Tranc&#xf3;n y Widemann</a>, 
<a href="/search/cs?searchtype=author&query=Lepper%2C+M">Markus Lepper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12897" title="Abstract">arXiv:2212.12897</a> (replaced) [<a href="/pdf/2212.12897" title="Download PDF">pdf</a>, <a href="/format/2212.12897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal regularized hypothesis testing in statistical inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kretschmann%2C+R">Remo Kretschmann</a>, 
<a href="/search/math?searchtype=author&query=Wachsmuth%2C+D">Daniel Wachsmuth</a>, 
<a href="/search/math?searchtype=author&query=Werner%2C+F">Frank Werner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00434" title="Abstract">arXiv:2301.00434</a> (replaced) [<a href="/pdf/2301.00434" title="Download PDF">pdf</a>, <a href="/ps/2301.00434" title="Download PostScript">ps</a>, <a href="/format/2301.00434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cops and robbers pebbling in graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Clarke%2C+N">Nancy Clarke</a>, 
<a href="/search/math?searchtype=author&query=Forkin%2C+J">Joshua Forkin</a>, 
<a href="/search/math?searchtype=author&query=Hurlbert%2C+G">Glenn Hurlbert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02136" title="Abstract">arXiv:2301.02136</a> (replaced) [<a href="/pdf/2301.02136" title="Download PDF">pdf</a>, <a href="/format/2301.02136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Transforms for Signals on Simplicial Complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saito%2C+N">Naoki Saito</a>, 
<a href="/search/cs?searchtype=author&query=Schonsheck%2C+S+C">Stefan C. Schonsheck</a>, 
<a href="/search/cs?searchtype=author&query=Shvarts%2C+E">Eugene Shvarts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 Pages, Comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Signal Processing (eess.SP); Combinatorics (math.CO); Numerical Analysis (math.NA); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04900" title="Abstract">arXiv:2301.04900</a> (replaced) [<a href="/pdf/2301.04900" title="Download PDF">pdf</a>, <a href="/format/2301.04900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How accurate are neural approximations of complex network dynamics?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Vasiliauskaite%2C+V">Vaiva Vasiliauskaite</a>, 
<a href="/search/cond-mat?searchtype=author&query=Antulov-Fantulin%2C+N">Nino Antulov-Fantulin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05065" title="Abstract">arXiv:2301.05065</a> (replaced) [<a href="/pdf/2301.05065" title="Download PDF">pdf</a>, <a href="/format/2301.05065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Building General Foundation Models for Language, Vision, and  Vision-Language Understanding Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinsong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05856" title="Abstract">arXiv:2301.05856</a> (replaced) [<a href="/pdf/2301.05856" title="Download PDF">pdf</a>, <a href="/format/2301.05856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EARL: An Elliptical Distribution aided Adaptive Rotation Label  Assignment for Oriented Object Detection in Remote Sensing Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Jian Guan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Mingjie Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youtian Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+G">Guangjun He</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+P">Pengming Feng</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Geoscience and Remote Sensing, vol. 61, pp.
  1-15, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06341" title="Abstract">arXiv:2301.06341</a> (replaced) [<a href="/pdf/2301.06341" title="Download PDF">pdf</a>, <a href="/format/2301.06341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An architectural technical debt index based on machine learning and  architectural smells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sas%2C+D">Darius Sas</a>, 
<a href="/search/cs?searchtype=author&query=Avgeriou%2C+P">Paris Avgeriou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper submitted to IEEE Transactions on Software Engineering in May 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09749" title="Abstract">arXiv:2301.09749</a> (replaced) [<a href="/pdf/2301.09749" title="Download PDF">pdf</a>, <a href="/format/2301.09749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-Efficient Visual-Audio Representation with Intuitive Fine-tuning  for Voice-Controlled Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+P">Peixin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuijing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tianchen Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+N">Neeloy Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Kaiwen Hong</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Conference on Robot Learning (CoRL), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11916" title="Abstract">arXiv:2301.11916</a> (replaced) [<a href="/pdf/2301.11916" title="Download PDF">pdf</a>, <a href="/format/2301.11916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Are Latent Variable Models: Explaining and Finding  Good Demonstrations for In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wanrong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Saxon%2C+M">Michael Saxon</a>, 
<a href="/search/cs?searchtype=author&query=Steyvers%2C+M">Mark Steyvers</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code at: <a href="https://github.com/WANGXinyiLinda/concept-based-demonstration-selection">this https URL</a> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12892" title="Abstract">arXiv:2301.12892</a> (replaced) [<a href="/pdf/2301.12892" title="Download PDF">pdf</a>, <a href="/format/2301.12892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying and maximizing the information flux in recurrent neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Metzner%2C+C">Claus Metzner</a>, 
<a href="/search/q-bio?searchtype=author&query=Yamakou%2C+M+E">Marius E. Yamakou</a>, 
<a href="/search/q-bio?searchtype=author&query=Voelkl%2C+D">Dennis Voelkl</a>, 
<a href="/search/q-bio?searchtype=author&query=Schilling%2C+A">Achim Schilling</a>, 
<a href="/search/q-bio?searchtype=author&query=Krauss%2C+P">Patrick Krauss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00926" title="Abstract">arXiv:2302.00926</a> (replaced) [<a href="/pdf/2302.00926" title="Download PDF">pdf</a>, <a href="/format/2302.00926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPCIPI: A pre-trained deep learning model for predicting cross-immunity  between drifted strains of Influenza A/H3N2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yiming Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuotian Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qian He</a>, 
<a href="/search/cs?searchtype=author&query=Tulu%2C+T+W">Thomas Wetere Tulu</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+H+K">Kei Hang Katie Chan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+S">Sen Pei</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhanwei Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiao-Ke Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X+F">Xiao Fan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01068" title="Abstract">arXiv:2302.01068</a> (replaced) [<a href="/pdf/2302.01068" title="Download PDF">pdf</a>, <a href="/format/2302.01068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedLAP-DP: Federated Learning by Sharing Differentially Private Loss  Approximations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui-Po Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dingfan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kerkouche%2C+R">Raouf Kerkouche</a>, 
<a href="/search/cs?searchtype=author&query=Fritz%2C+M">Mario Fritz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02978" title="Abstract">arXiv:2302.02978</a> (replaced) [<a href="/pdf/2302.02978" title="Download PDF">pdf</a>, <a href="/format/2302.02978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuG: A Multimodal Classification Benchmark on Game Data with Tabular,  Textual, and Visual Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiaying Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yongchen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shifan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Y">Yuanzhe Xi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Findings of the Association for Computational Linguistics:
  EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03246" title="Abstract">arXiv:2302.03246</a> (replaced) [<a href="/pdf/2302.03246" title="Download PDF">pdf</a>, <a href="/format/2302.03246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDANs: Temporal Causal Discovery from Autocorrelated and Non-Stationary  Time Series Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdous%2C+M+H">Muhammad Hasan Ferdous</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+U">Uzma Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Gani%2C+M+O">Md Osman Gani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03397" title="Abstract">arXiv:2302.03397</a> (replaced) [<a href="/pdf/2302.03397" title="Download PDF">pdf</a>, <a href="/format/2302.03397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AniPixel: Towards Animatable Pixel-Aligned Human Avatar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jinlong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Z">Zhi Hou</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MM'23, code will be released at <a href="https://github.com/loong8888/AniPixel">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03764" title="Abstract">arXiv:2302.03764</a> (replaced) [<a href="/pdf/2302.03764" title="Download PDF">pdf</a>, <a href="/format/2302.03764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketchy: Memory-efficient Adaptive Regularization with Frequent  Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Feinberg%2C+V">Vladimir Feinberg</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+X">Xinyi Chen</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+Y+J">Y. Jennifer Sun</a>, 
<a href="/search/stat?searchtype=author&query=Anil%2C+R">Rohan Anil</a>, 
<a href="/search/stat?searchtype=author&query=Hazan%2C+E">Elad Hazan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures, 7 tables, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04264" title="Abstract">arXiv:2302.04264</a> (replaced) [<a href="/pdf/2302.04264" title="Download PDF">pdf</a>, <a href="/format/2302.04264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nerfstudio: A Modular Framework for Neural Radiance Field Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tancik%2C+M">Matthew Tancik</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+E">Ethan Weber</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+E">Evonne Ng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruilong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+B">Brent Yi</a>, 
<a href="/search/cs?searchtype=author&query=Kerr%2C+J">Justin Kerr</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Terrance Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kristoffersen%2C+A">Alexander Kristoffersen</a>, 
<a href="/search/cs?searchtype=author&query=Austin%2C+J">Jake Austin</a>, 
<a href="/search/cs?searchtype=author&query=Salahi%2C+K">Kamyar Salahi</a>, 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+A">Abhik Ahuja</a>, 
<a href="/search/cs?searchtype=author&query=McAllister%2C+D">David McAllister</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+A">Angjoo Kanazawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page at <a href="https://nerf.studio">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04867" title="Abstract">arXiv:2302.04867</a> (replaced) [<a href="/pdf/2302.04867" title="Download PDF">pdf</a>, <a href="/format/2302.04867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniPC: A Unified Predictor-Corrector Framework for Fast Sampling of  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenliang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lujia Bai</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+Y">Yongming Rao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023. Project page: <a href="https://unipc.ivg-research.xyz">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05290" title="Abstract">arXiv:2302.05290</a> (replaced) [<a href="/pdf/2302.05290" title="Download PDF">pdf</a>, <a href="/format/2302.05290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Removing Structured Noise with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stevens%2C+T+S+W">Tristan S.W. Stevens</a>, 
<a href="/search/cs?searchtype=author&query=van+Gorp%2C+H">Hans van Gorp</a>, 
<a href="/search/cs?searchtype=author&query=Meral%2C+F+C">Faik C. Meral</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Junseob Shin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jason Yu</a>, 
<a href="/search/cs?searchtype=author&query=Robert%2C+J">Jean-Luc Robert</a>, 
<a href="/search/cs?searchtype=author&query=van+Sloun%2C+R+J+G">Ruud J.G. van Sloun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05372" title="Abstract">arXiv:2302.05372</a> (replaced) [<a href="/pdf/2302.05372" title="Download PDF">pdf</a>, <a href="/ps/2302.05372" title="Download PostScript">ps</a>, <a href="/format/2302.05372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Minimax Optimality of Model-based Robust Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clavier%2C+P">Pierre Clavier</a>, 
<a href="/search/cs?searchtype=author&query=Pennec%2C+E+L">Erwan Le Pennec</a>, 
<a href="/search/cs?searchtype=author&query=Geist%2C+M">Matthieu Geist</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08002" title="Abstract">arXiv:2302.08002</a> (replaced) [<a href="/pdf/2302.08002" title="Download PDF">pdf</a>, <a href="/ps/2302.08002" title="Download PostScript">ps</a>, <a href="/format/2302.08002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Enhanced Realized GARCH
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/econ?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/econ?searchtype=author&query=Tran%2C+M">Minh-Ngoc Tran</a>, 
<a href="/search/econ?searchtype=author&query=Kohn%2C+R">Robert Kohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11713" title="Abstract">arXiv:2302.11713</a> (replaced) [<a href="/pdf/2302.11713" title="Download PDF">pdf</a>, <a href="/format/2302.11713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Pre-trained Vision and Language Models Answer Visual  Information-Seeking Questions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hexiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+Y">Yi Luan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haitian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Changpinyo%2C+S">Soravit Changpinyo</a>, 
<a href="/search/cs?searchtype=author&query=Ritter%2C+A">Alan Ritter</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Ming-Wei Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (main conference); Our dataset and evaluation is available at <a href="https://open-vision-language.github.io/infoseek/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12769" title="Abstract">arXiv:2302.12769</a> (replaced) [<a href="/pdf/2302.12769" title="Download PDF">pdf</a>, <a href="/format/2302.12769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic maps on bistable vibration energy harvesters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Norenberg%2C+J+P">Jo&#xe3;o Pedro Norenberg</a>, 
<a href="/search/math?searchtype=author&query=Cunha%2C+A">Americo Cunha Jr</a>, 
<a href="/search/math?searchtype=author&query=da+Silva%2C+S">Samuel da Silva</a>, 
<a href="/search/math?searchtype=author&query=Varoto%2C+P+S">Paulo Sergio Varoto</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Nonlinear Dynamics 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Computational Engineering, Finance, and Science (cs.CE); Chaotic Dynamics (nlin.CD); Classical Physics (physics.class-ph); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13137" title="Abstract">arXiv:2302.13137</a> (replaced) [<a href="/pdf/2302.13137" title="Download PDF">pdf</a>, <a href="/format/2302.13137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Human-Centered Safe Robot Reinforcement Learning Framework with  Interactive Behaviors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shangding Gu</a>, 
<a href="/search/cs?searchtype=author&query=Kshirsagar%2C+A">Alap Kshirsagar</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13959" title="Abstract">arXiv:2302.13959</a> (replaced) [<a href="/pdf/2302.13959" title="Download PDF">pdf</a>, <a href="/format/2302.13959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make Every Example Count: On the Stability and Utility of Self-Influence  for Learning from Noisy NLP Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bejan%2C+I">Irina Bejan</a>, 
<a href="/search/cs?searchtype=author&query=Sokolov%2C+A">Artem Sokolov</a>, 
<a href="/search/cs?searchtype=author&query=Filippova%2C+K">Katja Filippova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01592" title="Abstract">arXiv:2303.01592</a> (replaced) [<a href="/pdf/2303.01592" title="Download PDF">pdf</a>, <a href="/format/2303.01592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint cortical registration of geometry and function using  semi-supervised learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/eess?searchtype=author&query=Tuckute%2C+G">Greta Tuckute</a>, 
<a href="/search/eess?searchtype=author&query=Fedorenko%2C+E">Evelina Fedorenko</a>, 
<a href="/search/eess?searchtype=author&query=Edlow%2C+B+L">Brian L. Edlow</a>, 
<a href="/search/eess?searchtype=author&query=Fischl%2C+B">Bruce Fischl</a>, 
<a href="/search/eess?searchtype=author&query=Dalca%2C+A+V">Adrian V. Dalca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> B. Fischl and A. V. Dalca are co-senior authors with equal contribution. This work has been published in MIDL 2023 (<a href="https://openreview.net/forum?id=n9v_BuIcY7G">this https URL</a>) Medical Imaging with Deep Learning, Nashville, TN, Jul. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02317" title="Abstract">arXiv:2303.02317</a> (replaced) [<a href="/pdf/2303.02317" title="Download PDF">pdf</a>, <a href="/format/2303.02317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast American Option Pricing using Nonlinear Stencils
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+Z">Zafar Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Browne%2C+R">Reilly Browne</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+R">Rezaul Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+R">Rathish Das</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yushen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yimin Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Data Structures and Algorithms (cs.DS); Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02863" title="Abstract">arXiv:2303.02863</a> (replaced) [<a href="/pdf/2303.02863" title="Download PDF">pdf</a>, <a href="/ps/2303.02863" title="Download PostScript">ps</a>, <a href="/format/2303.02863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on the Proposed Law for Improving the Transparency of Political  Advertising in the European Union
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruohonen%2C+J">Jukka Ruohonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A working paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03271" title="Abstract">arXiv:2303.03271</a> (replaced) [<a href="/pdf/2303.03271" title="Download PDF">pdf</a>, <a href="/ps/2303.03271" title="Download PostScript">ps</a>, <a href="/format/2303.03271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fibrational Tale of Operational Logical Relations: Pure, Effectful and  Differential
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dagnino%2C+F">Francesco Dagnino</a>, 
<a href="/search/cs?searchtype=author&query=Gavazzo%2C+F">Francesco Gavazzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04238" title="Abstract">arXiv:2303.04238</a> (replaced) [<a href="/pdf/2303.04238" title="Download PDF">pdf</a>, <a href="/format/2303.04238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patch of Invisibility: Naturalistic Physical Black-Box Adversarial  Attacks on Object Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lapid%2C+R">Raz Lapid</a>, 
<a href="/search/cs?searchtype=author&query=Mizrahi%2C+E">Eylon Mizrahi</a>, 
<a href="/search/cs?searchtype=author&query=Sipper%2C+M">Moshe Sipper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04614" title="Abstract">arXiv:2303.04614</a> (replaced) [<a href="/pdf/2303.04614" title="Download PDF">pdf</a>, <a href="/format/2303.04614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Densely Connected $G$-invariant Deep Neural Networks with Signed  Permutation Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+D">Devanshu Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Ostrowski%2C+J">James Ostrowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 2 figures, 4 tables. For associated code repository see <a href="https://github.com/dagrawa2/gdnn_code">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04693" title="Abstract">arXiv:2303.04693</a> (replaced) [<a href="/pdf/2303.04693" title="Download PDF">pdf</a>, <a href="/format/2303.04693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A path in regression Random Forest looking for spatial dependence: a  taxonomy and a systematic review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Patelli%2C+L">Luca Patelli</a>, 
<a href="/search/stat?searchtype=author&query=Cameletti%2C+M">Michela Cameletti</a>, 
<a href="/search/stat?searchtype=author&query=Golini%2C+N">Natalia Golini</a>, 
<a href="/search/stat?searchtype=author&query=Ignaccolo%2C+R">Rosaria Ignaccolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09447" title="Abstract">arXiv:2303.09447</a> (replaced) [<a href="/pdf/2303.09447" title="Download PDF">pdf</a>, <a href="/format/2303.09447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steering Prototypes with Prompt-tuning for Rehearsal-free Continual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Long Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Di Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Metaxas%2C+D+N">Dimitris N. Metaxas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09767" title="Abstract">arXiv:2303.09767</a> (replaced) [<a href="/pdf/2303.09767" title="Download PDF">pdf</a>, <a href="/format/2303.09767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> It Is All About Data: A Survey on the Effects of Data on Adversarial  Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+P">Peiyu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Tegegn%2C+M">Michael Tegegn</a>, 
<a href="/search/cs?searchtype=author&query=Sarin%2C+J+S">Jaskeerat Singh Sarin</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+S">Shubhraneel Pal</a>, 
<a href="/search/cs?searchtype=author&query=Rubin%2C+J">Julia Rubin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM Computing Surveys, 40 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09806" title="Abstract">arXiv:2303.09806</a> (replaced) [<a href="/pdf/2303.09806" title="Download PDF">pdf</a>, <a href="/format/2303.09806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DexRepNet: Learning Dexterous Robotic Grasping Network with Geometric  and Spatial Hand-Object Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingtao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhengnan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoming Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gaofeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Lin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10019" title="Abstract">arXiv:2303.10019</a> (replaced) [<a href="/pdf/2303.10019" title="Download PDF">pdf</a>, <a href="/format/2303.10019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multivariate Probabilistic CRPS Learning with an Application to  Day-Ahead Electricity Prices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Berrisch%2C+J">Jonathan Berrisch</a>, 
<a href="/search/stat?searchtype=author&query=Ziel%2C+F">Florian Ziel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Computational Finance (q-fin.CP); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10031" title="Abstract">arXiv:2303.10031</a> (replaced) [<a href="/pdf/2303.10031" title="Download PDF">pdf</a>, <a href="/format/2303.10031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Dissipativity Analysis of Linear Parameter-Varying Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Verhoek%2C+C">Chris Verhoek</a>, 
<a href="/search/eess?searchtype=author&query=Berberich%2C+J">Julian Berberich</a>, 
<a href="/search/eess?searchtype=author&query=Haesaert%2C+S">Sofie Haesaert</a>, 
<a href="/search/eess?searchtype=author&query=Allg%C3%B6wer%2C+F">Frank Allg&#xf6;wer</a>, 
<a href="/search/eess?searchtype=author&query=T%C3%B3th%2C+R">Roland T&#xf3;th</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11088" title="Abstract">arXiv:2303.11088</a> (replaced) [<a href="/pdf/2303.11088" title="Download PDF">pdf</a>, <a href="/format/2303.11088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking scalability of stream processing frameworks deployed as  microservices in the cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henning%2C+S">S&#xf6;ren Henning</a>, 
<a href="/search/cs?searchtype=author&query=Hasselbring%2C+W">Wilhelm Hasselbring</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11332" title="Abstract">arXiv:2303.11332</a> (replaced) [<a href="/pdf/2303.11332" title="Download PDF">pdf</a>, <a href="/format/2303.11332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Video-based Person Re-Identification: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+K">Khawar Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11435" title="Abstract">arXiv:2303.11435</a> (replaced) [<a href="/pdf/2303.11435" title="Download PDF">pdf</a>, <a href="/format/2303.11435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inversion by Direct Iteration: An Alternative to Denoising Diffusion for  Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Delbracio%2C+M">Mauricio Delbracio</a>, 
<a href="/search/eess?searchtype=author&query=Milanfar%2C+P">Peyman Milanfar</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (TMLR), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11632" title="Abstract">arXiv:2303.11632</a> (replaced) [<a href="/e-print/2303.11632" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Embarrassingly Simple Approach for Wafer Feature Extraction and  Defect Pattern Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shukla%2C+N">Nitish Shukla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> study is not relevant
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13780" title="Abstract">arXiv:2303.13780</a> (replaced) [<a href="/pdf/2303.13780" title="Download PDF">pdf</a>, <a href="/format/2303.13780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Making the Most of ChatGPT for Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Keqin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Q">Qihuang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuebo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+Y">Yuanxin Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13827" title="Abstract">arXiv:2303.13827</a> (replaced) [<a href="/e-print/2303.13827" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Mixed-Type Wafer Defect Pattern Recognition Using Compact  Deformable Convolutional Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shukla%2C+N">Nitish Shukla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Study is not relevant
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15938" title="Abstract">arXiv:2303.15938</a> (replaced) [<a href="/pdf/2303.15938" title="Download PDF">pdf</a>, <a href="/format/2303.15938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> fRegGAN with K-space Loss Regularization for Medical Image Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Baltruschat%2C+I+M">Ivo M. Baltruschat</a>, 
<a href="/search/eess?searchtype=author&query=Kreis%2C+F">Felix Kreis</a>, 
<a href="/search/eess?searchtype=author&query=Hoelscher%2C+A">Alexander Hoelscher</a>, 
<a href="/search/eess?searchtype=author&query=Dohmen%2C+M">Melanie Dohmen</a>, 
<a href="/search/eess?searchtype=author&query=Lenga%2C+M">Matthias Lenga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16913" title="Abstract">arXiv:2303.16913</a> (replaced) [<a href="/pdf/2303.16913" title="Download PDF">pdf</a>, <a href="/format/2303.16913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Reconfigurable Intelligent Surfaces for Short Transmissions:  How Detailed Configurations can be Afforded?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Enqvist%2C+A">Anders Enqvist</a>, 
<a href="/search/cs?searchtype=author&query=Demir%2C+%C3%96+T">&#xd6;zlem Tu&#x11f;fe Demir</a>, 
<a href="/search/cs?searchtype=author&query=Cavdar%2C+C">Cicek Cavdar</a>, 
<a href="/search/cs?searchtype=author&query=Bj%C3%B6rnson%2C+E">Emil Bj&#xf6;rnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures. This article has been accepted for publication in IEEE Transactions on Wireless Communications. This is the author's version which has not been fully edited and content may change prior to final publication. arXiv admin note: text overlap with <a href="/abs/2303.16625">arXiv:2303.16625</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17262" title="Abstract">arXiv:2303.17262</a> (replaced) [<a href="/pdf/2303.17262" title="Download PDF">pdf</a>, <a href="/format/2303.17262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ontology in Hybrid Intelligence: a concise literature review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pileggi%2C+S+F">Salvatore F. Pileggi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17806" title="Abstract">arXiv:2303.17806</a> (replaced) [<a href="/pdf/2303.17806" title="Download PDF">pdf</a>, <a href="/format/2303.17806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Microfacet Fields for Inverse Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mai%2C+A">Alexander Mai</a>, 
<a href="/search/cs?searchtype=author&query=Verbin%2C+D">Dor Verbin</a>, 
<a href="/search/cs?searchtype=author&query=Kuester%2C+F">Falko Kuester</a>, 
<a href="/search/cs?searchtype=author&query=Fridovich-Keil%2C+S">Sara Fridovich-Keil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://half-potato.gitlab.io/posts/nmf/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00157" title="Abstract">arXiv:2304.00157</a> (replaced) [<a href="/pdf/2304.00157" title="Download PDF">pdf</a>, <a href="/format/2304.00157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Perception of Transparent Objects: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiaqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+G">Guanqun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiankang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+T">Thanh-Toan Do</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shan Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 11 figures, Accepted by IEEE Transactions on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01492" title="Abstract">arXiv:2304.01492</a> (replaced) [<a href="/pdf/2304.01492" title="Download PDF">pdf</a>, <a href="/format/2304.01492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Contrastive Transfer Framework with Propagation Structure for  Boosting Low-Resource Rumor Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongzhan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jing Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingfei Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extension of the first contrastive approach for low-resource rumor detection (<a href="/abs/2204.08143">arXiv:2204.08143</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02742" title="Abstract">arXiv:2304.02742</a> (replaced) [<a href="/pdf/2304.02742" title="Download PDF">pdf</a>, <a href="/format/2304.02742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Medical Image Translation via Frequency-Guided Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yunxiang Li</a>, 
<a href="/search/eess?searchtype=author&query=Shao%2C+H">Hua-Chieh Shao</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+X">Xiao Liang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+L">Liyuan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+R">Ruiqi Li</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+S">Steve Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">You Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02806" title="Abstract">arXiv:2304.02806</a> (replaced) [<a href="/pdf/2304.02806" title="Download PDF">pdf</a>, <a href="/format/2304.02806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Mixture of Experts: Learning on Large-Scale Graphs with Explicit  Diversity Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haotao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Ziyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yuning You</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yan Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gaowen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+J">Jayanth Srinivasa</a>, 
<a href="/search/cs?searchtype=author&query=Kompella%2C+R+R">Ramana Rao Kompella</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03286" title="Abstract">arXiv:2304.03286</a> (replaced) [<a href="/pdf/2304.03286" title="Download PDF">pdf</a>, <a href="/format/2304.03286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Information in a model of Resource Gathering Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sowinski%2C+D+R">Damian R Sowinski</a>, 
<a href="/search/cond-mat?searchtype=author&query=Carroll-Nellenback%2C+J">Jonathan Carroll-Nellenback</a>, 
<a href="/search/cond-mat?searchtype=author&query=Markwick%2C+R+N">Robert N Markwick</a>, 
<a href="/search/cond-mat?searchtype=author&query=Pi%C3%B1ero%2C+J">Jordi Pi&#xf1;ero</a>, 
<a href="/search/cond-mat?searchtype=author&query=Gleiser%2C+M">Marcelo Gleiser</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kolchinsky%2C+A">Artemy Kolchinsky</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ghoshal%2C+G">Gourab Ghoshal</a>, 
<a href="/search/cond-mat?searchtype=author&query=Frank%2C+A">Adam Frank</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, 5 appendices
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PRX Life 1, 023003 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Information Theory (cs.IT); Cellular Automata and Lattice Gases (nlin.CG); Biological Physics (physics.bio-ph); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04250" title="Abstract">arXiv:2304.04250</a> (replaced) [<a href="/pdf/2304.04250" title="Download PDF">pdf</a>, <a href="/format/2304.04250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Editable User Profiles for Controllable Text Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mysore%2C+S">Sheshera Mysore</a>, 
<a href="/search/cs?searchtype=author&query=Jasim%2C+M">Mahmood Jasim</a>, 
<a href="/search/cs?searchtype=author&query=McCallum%2C+A">Andrew McCallum</a>, 
<a href="/search/cs?searchtype=author&query=Zamani%2C+H">Hamed Zamani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGIR-2023 paper with extended results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07187" title="Abstract">arXiv:2304.07187</a> (replaced) [<a href="/pdf/2304.07187" title="Download PDF">pdf</a>, <a href="/ps/2304.07187" title="Download PostScript">ps</a>, <a href="/format/2304.07187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Proof that Coarse Correlated Equilibrium Implies Nash Equilibrium in  Two-Player Zero-Sum Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MacQueen%2C+R">Revan MacQueen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12206" title="Abstract">arXiv:2304.12206</a> (replaced) [<a href="/pdf/2304.12206" title="Download PDF">pdf</a>, <a href="/format/2304.12206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAXQA: Generating Cross-lingual Question Answering Examples at Training  Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bryan Li</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Chris Callison-Burch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13013" title="Abstract">arXiv:2304.13013</a> (replaced) [<a href="/pdf/2304.13013" title="Download PDF">pdf</a>, <a href="/format/2304.13013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable and low-precision training for large-scale vision-language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wortsman%2C+M">Mitchell Wortsman</a>, 
<a href="/search/cs?searchtype=author&query=Dettmers%2C+T">Tim Dettmers</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Morcos%2C+A">Ari Morcos</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Ali Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+L">Ludwig Schmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13734" title="Abstract">arXiv:2304.13734</a> (replaced) [<a href="/pdf/2304.13734" title="Download PDF">pdf</a>, <a href="/format/2304.13734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Internal State of an LLM Knows When It&#x27;s Lying
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azaria%2C+A">Amos Azaria</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+T">Tom Mitchell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13785" title="Abstract">arXiv:2304.13785</a> (replaced) [<a href="/pdf/2304.13785" title="Download PDF">pdf</a>, <a href="/format/2304.13785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customized Segment Anything Model for Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaidong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report, 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.15000" title="Abstract">arXiv:2304.15000</a> (replaced) [<a href="/pdf/2304.15000" title="Download PDF">pdf</a>, <a href="/format/2304.15000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Control Machine: The Limits of Control Flow in Quantum  Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Charles Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Villanyi%2C+A">Agnes Villanyi</a>, 
<a href="/search/cs?searchtype=author&query=Carbin%2C+M">Michael Carbin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures. v3: added examples and improved organization of paper. v2: switched LaTeX template, improved descriptive text and added more discussion of implications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Hardware Architecture (cs.AR); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00447" title="Abstract">arXiv:2305.00447</a> (replaced) [<a href="/pdf/2305.00447" title="Download PDF">pdf</a>, <a href="/format/2305.00447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TALLRec: An Effective and Efficient Tuning Framework to Align Large  Language Model with Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+K">Keqin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jizhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RecSys '23: Proceedings of the 17th ACM Conference on Recommender Systems; September 2023 Pages; 1007-1014
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01261" title="Abstract">arXiv:2305.01261</a> (replaced) [<a href="/pdf/2305.01261" title="Download PDF">pdf</a>, <a href="/format/2305.01261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exactly Optimal and Communication-Efficient Private Estimation via Block  Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyun-Young Park</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Seung-Hyun Nam</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Si-Hyeon Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 1 figure, and 1 table. A short version of this manuscript was presented at 2023 IEEE International Symposium on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04134" title="Abstract">arXiv:2305.04134</a> (replaced) [<a href="/e-print/2305.04134" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Neuropsychology: Are Large Language Models Developing  Executive Functions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vazquez%2C+H+C">Hernan Ceferino Vazquez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The article on ArXiv is a translation of the original Spanish work. Upon review, we realized that crucial nuances and details were lost or misrepresented in the translation, affecting the results and conclusions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05249" title="Abstract">arXiv:2305.05249</a> (replaced) [<a href="/pdf/2305.05249" title="Download PDF">pdf</a>, <a href="/format/2305.05249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Quantum Integer Factorization Performance: A Scalable  Evaluation Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lee%2C+J">Junseo Lee</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bae%2C+K">Kibum Bae</a>, 
<a href="/search/quant-ph?searchtype=author&query=Song%2C+C">Chang-Nyoung Song</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jung%2C+H">Hyunchul Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05285" title="Abstract">arXiv:2305.05285</a> (replaced) [<a href="/pdf/2305.05285" title="Download PDF">pdf</a>, <a href="/format/2305.05285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Day-After-Tomorrow: On the Performance of Radio Fingerprinting over  Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alhazbi%2C+S">Saeif Alhazbi</a>, 
<a href="/search/cs?searchtype=author&query=Sciancalepore%2C+S">Savio Sciancalepore</a>, 
<a href="/search/cs?searchtype=author&query=Oligeri%2C+G">Gabriele Oligeri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05465" title="Abstract">arXiv:2305.05465</a> (replaced) [<a href="/pdf/2305.05465" title="Download PDF">pdf</a>, <a href="/format/2305.05465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The emergence of clusters in self-attention dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geshkovski%2C+B">Borjan Geshkovski</a>, 
<a href="/search/cs?searchtype=author&query=Letrouit%2C+C">Cyril Letrouit</a>, 
<a href="/search/cs?searchtype=author&query=Polyanskiy%2C+Y">Yury Polyanskiy</a>, 
<a href="/search/cs?searchtype=author&query=Rigollet%2C+P">Philippe Rigollet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Analysis of PDEs (math.AP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06547" title="Abstract">arXiv:2305.06547</a> (replaced) [<a href="/pdf/2305.06547" title="Download PDF">pdf</a>, <a href="/format/2305.06547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Lyapunov Control for Discrete-Time Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junlin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+A">Andrew Clark</a>, 
<a href="/search/cs?searchtype=author&query=Kantaros%2C+Y">Yiannis Kantaros</a>, 
<a href="/search/cs?searchtype=author&query=Vorobeychik%2C+Y">Yevgeniy Vorobeychik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07089" title="Abstract">arXiv:2305.07089</a> (replaced) [<a href="/pdf/2305.07089" title="Download PDF">pdf</a>, <a href="/format/2305.07089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchically Coherent Multivariate Mixture Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Olivares%2C+K+G">Kin G. Olivares</a>, 
<a href="/search/stat?searchtype=author&query=Luo%2C+D">David Luo</a>, 
<a href="/search/stat?searchtype=author&query=Challu%2C+C">Cristian Challu</a>, 
<a href="/search/stat?searchtype=author&query=La+Vattiata%2C+S">Stefania La Vattiata</a>, 
<a href="/search/stat?searchtype=author&query=Mergenthaler%2C+M">Max Mergenthaler</a>, 
<a href="/search/stat?searchtype=author&query=Dubrawski%2C+A">Artur Dubrawski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07440" title="Abstract">arXiv:2305.07440</a> (replaced) [<a href="/pdf/2305.07440" title="Download PDF">pdf</a>, <a href="/format/2305.07440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Memory Mapping Using Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sazanovich%2C+M">Mikita Sazanovich</a>, 
<a href="/search/cs?searchtype=author&query=Ilbeyi%2C+B">Berkin Ilbeyi</a>, 
<a href="/search/cs?searchtype=author&query=Phothilimthana%2C+P+M">Phitchaya Mangpo Phothilimthana</a>, 
<a href="/search/cs?searchtype=author&query=Purohit%2C+M">Manish Purohit</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+H+Y">Han Yang Tay</a>, 
<a href="/search/cs?searchtype=author&query=V%C5%A9%2C+N">Ng&#xe2;n V&#x169;</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miaosen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Paduraru%2C+C">Cosmin Paduraru</a>, 
<a href="/search/cs?searchtype=author&query=Leurent%2C+E">Edouard Leurent</a>, 
<a href="/search/cs?searchtype=author&query=Zhernov%2C+A">Anton Zhernov</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Po-Sen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Schrittwieser%2C+J">Julian Schrittwieser</a>, 
<a href="/search/cs?searchtype=author&query=Hubert%2C+T">Thomas Hubert</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+R">Robert Tung</a>, 
<a href="/search/cs?searchtype=author&query=Kurylowicz%2C+P">Paula Kurylowicz</a>, 
<a href="/search/cs?searchtype=author&query=Milan%2C+K">Kieran Milan</a>, 
<a href="/search/cs?searchtype=author&query=Vinyals%2C+O">Oriol Vinyals</a>, 
<a href="/search/cs?searchtype=author&query=Mankowitz%2C+D+J">Daniel J. Mankowitz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07609" title="Abstract">arXiv:2305.07609</a> (replaced) [<a href="/pdf/2305.07609" title="Download PDF">pdf</a>, <a href="/format/2305.07609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large  Language Model Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jizhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+K">Keqin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Recsys 2023 (Short)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07845" title="Abstract">arXiv:2305.07845</a> (replaced) [<a href="/pdf/2305.07845" title="Download PDF">pdf</a>, <a href="/format/2305.07845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Improving Model Averaging in Federated Learning on  Heterogeneous Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tailin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zehong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+D+H+K">Danny H.K. Tsang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09652" title="Abstract">arXiv:2305.09652</a> (replaced) [<a href="/pdf/2305.09652" title="Download PDF">pdf</a>, <a href="/format/2305.09652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Interpreter Understands Your Meaning: End-to-end Spoken Language  Understanding Aided by Speech Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mutian He</a>, 
<a href="/search/cs?searchtype=author&query=Garner%2C+P+N">Philip N. Garner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures; accepted by Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10120" title="Abstract">arXiv:2305.10120</a> (replaced) [<a href="/pdf/2305.10120" title="Download PDF">pdf</a>, <a href="/format/2305.10120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selective Amnesia: A Continual Learning Approach to Forgetting in Deep  Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heng%2C+A">Alvin Heng</a>, 
<a href="/search/cs?searchtype=author&query=Soh%2C+H">Harold Soh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10277" title="Abstract">arXiv:2305.10277</a> (replaced) [<a href="/pdf/2305.10277" title="Download PDF">pdf</a>, <a href="/ps/2305.10277" title="Download PostScript">ps</a>, <a href="/format/2305.10277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quadratic Lower bounds on the Approximate Stabilizer Rank: A  Probabilistic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Mehraban%2C+S">Saeed Mehraban</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tahmasbi%2C+M">Mehrdad Tahmasbi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10664" title="Abstract">arXiv:2305.10664</a> (replaced) [<a href="/pdf/2305.10664" title="Download PDF">pdf</a>, <a href="/format/2305.10664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Posterior Inference on Shallow Infinitely Wide Bayesian Neural Networks  under Weights with Unbounded Variance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lor%C3%ADa%2C+J">Jorge Lor&#xed;a</a>, 
<a href="/search/stat?searchtype=author&query=Bhadra%2C+A">Anindya Bhadra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10819" title="Abstract">arXiv:2305.10819</a> (replaced) [<a href="/pdf/2305.10819" title="Download PDF">pdf</a>, <a href="/format/2305.10819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLEME: Debiasing Multi-reference Evaluation for Grammatical Error  Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jingheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qingyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangning Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shirong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Ying Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as an EMNLP 2023 main paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11171" title="Abstract">arXiv:2305.11171</a> (replaced) [<a href="/pdf/2305.11171" title="Download PDF">pdf</a>, <a href="/format/2305.11171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrueTeacher: Learning Factual Consistency Evaluation with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gekhman%2C+Z">Zorik Gekhman</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+J">Jonathan Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+R">Roee Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Elkind%2C+C">Chen Elkind</a>, 
<a href="/search/cs?searchtype=author&query=Szpektor%2C+I">Idan Szpektor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a long paper in EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11490" title="Abstract">arXiv:2305.11490</a> (replaced) [<a href="/pdf/2305.11490" title="Download PDF">pdf</a>, <a href="/format/2305.11490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Suhyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+J">Won Jun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jinho Chang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12532" title="Abstract">arXiv:2305.12532</a> (replaced) [<a href="/pdf/2305.12532" title="Download PDF">pdf</a>, <a href="/format/2305.12532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Simplification of Medical Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joseph%2C+S">Sebastian Joseph</a>, 
<a href="/search/cs?searchtype=author&query=Kazanas%2C+K">Kathryn Kazanas</a>, 
<a href="/search/cs?searchtype=author&query=Reina%2C+K">Keziah Reina</a>, 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+V+J">Vishnesh J. Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+B+C">Byron C. Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J+J">Junyi Jessy Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version will be in EMNLP 2023 main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12553" title="Abstract">arXiv:2305.12553</a> (replaced) [<a href="/pdf/2305.12553" title="Download PDF">pdf</a>, <a href="/format/2305.12553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markov $&#x3b1;$-Potential Games: Equilibrium Approximation and Regret  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+C">Chinmay Maheshwari</a>, 
<a href="/search/cs?searchtype=author&query=Sastry%2C+S">Shankar Sastry</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Manxi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12785" title="Abstract">arXiv:2305.12785</a> (replaced) [<a href="/pdf/2305.12785" title="Download PDF">pdf</a>, <a href="/format/2305.12785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MacLaSa: Multi-Aspect Controllable Text Generation via Efficient  Sampling from Compact Latent Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hanxing Ding</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zihao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12961" title="Abstract">arXiv:2305.12961</a> (replaced) [<a href="/pdf/2305.12961" title="Download PDF">pdf</a>, <a href="/format/2305.12961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Meta Label Correction for Coping with Label Corruption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taraday%2C+M+K">Mitchell Keren Taraday</a>, 
<a href="/search/cs?searchtype=author&query=Baskin%2C+C">Chaim Baskin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13035" title="Abstract">arXiv:2305.13035</a> (replaced) [<a href="/pdf/2305.13035" title="Download PDF">pdf</a>, <a href="/format/2305.13035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alabdulmohsin%2C+I">Ibrahim Alabdulmohsin</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaohua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+A">Alexander Kolesnikov</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+L">Lucas Beyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, 9 tables. Version 2: Layout fixes
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Conference on Neural Information Processing Systems (NeurIPS
  2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13303" title="Abstract">arXiv:2305.13303</a> (replaced) [<a href="/pdf/2305.13303" title="Download PDF">pdf</a>, <a href="/format/2305.13303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Unsupervised Recognition of Semantic Differences in Related  Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vamvas%2C+J">Jannis Vamvas</a>, 
<a href="/search/cs?searchtype=author&query=Sennrich%2C+R">Rico Sennrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13812" title="Abstract">arXiv:2305.13812</a> (replaced) [<a href="/pdf/2305.13812" title="Download PDF">pdf</a>, <a href="/format/2305.13812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for  Improved Vision-Language Compositionality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+H">Harman Singh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengchuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengjiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wenhan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jingfei Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (main)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14014" title="Abstract">arXiv:2305.14014</a> (replaced) [<a href="/pdf/2305.14014" title="Download PDF">pdf</a>, <a href="/format/2305.14014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP4STR: A Simple Baseline for Scene Text Recognition with Pre-trained  Vision-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Linchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+R">Ruijie Quan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14260" title="Abstract">arXiv:2305.14260</a> (replaced) [<a href="/pdf/2305.14260" title="Download PDF">pdf</a>, <a href="/format/2305.14260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R2H: Building Multimodal Navigation Helpers that Respond to Help  Requests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yue Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jing Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kaizhi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X+E">Xin Eric Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14324" title="Abstract">arXiv:2305.14324</a> (replaced) [<a href="/pdf/2305.14324" title="Download PDF">pdf</a>, <a href="/format/2305.14324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ties Matter: Meta-Evaluating Modern Metrics with Pairwise Accuracy and  Tie Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deutsch%2C+D">Daniel Deutsch</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+G">George Foster</a>, 
<a href="/search/cs?searchtype=author&query=Freitag%2C+M">Markus Freitag</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14342" title="Abstract">arXiv:2305.14342</a> (replaced) [<a href="/pdf/2305.14342" title="Download PDF">pdf</a>, <a href="/format/2305.14342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sophia: A Scalable Stochastic Second-order Optimizer for Language Model  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+D">David Hall</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Percy Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengyu Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15040" title="Abstract">arXiv:2305.15040</a> (replaced) [<a href="/pdf/2305.15040" title="Download PDF">pdf</a>, <a href="/format/2305.15040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning for Natural Language Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perlitz%2C+Y">Yotam Perlitz</a>, 
<a href="/search/cs?searchtype=author&query=Gera%2C+A">Ariel Gera</a>, 
<a href="/search/cs?searchtype=author&query=Shmueli-Scheuer%2C+M">Michal Shmueli-Scheuer</a>, 
<a href="/search/cs?searchtype=author&query=Sheinwald%2C+D">Dafna Sheinwald</a>, 
<a href="/search/cs?searchtype=author&query=Slonim%2C+N">Noam Slonim</a>, 
<a href="/search/cs?searchtype=author&query=Ein-Dor%2C+L">Liat Ein-Dor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP2023 as a long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16014" title="Abstract">arXiv:2305.16014</a> (replaced) [<a href="/pdf/2305.16014" title="Download PDF">pdf</a>, <a href="/format/2305.16014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How many samples are needed to leverage smoothness?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cabannes%2C+V">Vivien Cabannes</a>, 
<a href="/search/stat?searchtype=author&query=Vigogna%2C+S">Stefano Vigogna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 13 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16283" title="Abstract">arXiv:2305.16283</a> (replaced) [<a href="/pdf/2305.16283" title="Download PDF">pdf</a>, <a href="/format/2305.16283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangyao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96rnek%2C+E+P">Evin P&#x131;nar &#xd6;rnek</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shun-Cheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+Y">Yan Di</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16309" title="Abstract">arXiv:2305.16309</a> (replaced) [<a href="/pdf/2305.16309" title="Download PDF">pdf</a>, <a href="/format/2305.16309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitating Task and Motion Planning with Visuomotor Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalal%2C+M">Murtaza Dalal</a>, 
<a href="/search/cs?searchtype=author&query=Mandlekar%2C+A">Ajay Mandlekar</a>, 
<a href="/search/cs?searchtype=author&query=Garrett%2C+C">Caelan Garrett</a>, 
<a href="/search/cs?searchtype=author&query=Handa%2C+A">Ankur Handa</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+D">Dieter Fox</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Robot Learning (CoRL) 2023. 8 pages, 5 figures, 2 tables; 11 pages appendix (10 additional figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17671" title="Abstract">arXiv:2305.17671</a> (replaced) [<a href="/pdf/2305.17671" title="Download PDF">pdf</a>, <a href="/format/2305.17671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear-Time--Branching-Time Spectroscopy Accounting for Silent Steps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bisping%2C+B">Benjamin Bisping</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+D+N">David N. Jansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18533" title="Abstract">arXiv:2305.18533</a> (replaced) [<a href="/pdf/2305.18533" title="Download PDF">pdf</a>, <a href="/format/2305.18533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pandemic Culture Wars: Partisan Differences in the Moral Language of  COVID-19 Discussions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Ashwin Rao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Siyi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S+N">Sze-Yuh Nina Wang</a>, 
<a href="/search/cs?searchtype=author&query=Morstatter%2C+F">Fred Morstatter</a>, 
<a href="/search/cs?searchtype=author&query=Lerman%2C+K">Kristina Lerman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18642" title="Abstract">arXiv:2305.18642</a> (replaced) [<a href="/pdf/2305.18642" title="Download PDF">pdf</a>, <a href="/ps/2305.18642" title="Download PostScript">ps</a>, <a href="/format/2305.18642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal approximation of infinite-dimensional holomorphic functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adcock%2C+B">Ben Adcock</a>, 
<a href="/search/math?searchtype=author&query=Dexter%2C+N">Nick Dexter</a>, 
<a href="/search/math?searchtype=author&query=Moraga%2C+S">Sebastian Moraga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19130" title="Abstract">arXiv:2305.19130</a> (replaced) [<a href="/pdf/2305.19130" title="Download PDF">pdf</a>, <a href="/ps/2305.19130" title="Download PostScript">ps</a>, <a href="/format/2305.19130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptation of Tongue Ultrasound-Based Silent Speech Interfaces Using  Spatial Transformer Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=T%C3%B3th%2C+L">L&#xe1;szl&#xf3; T&#xf3;th</a>, 
<a href="/search/cs?searchtype=author&query=Shandiz%2C+A+H">Amin Honarmandi Shandiz</a>, 
<a href="/search/cs?searchtype=author&query=Gosztolya%2C+G">G&#xe1;bor Gosztolya</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%A1bor%2C+C+T">Csap&#xf3; Tam&#xe1;s G&#xe1;bor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 3 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> the Proceedings of Interspeech 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19555" title="Abstract">arXiv:2305.19555</a> (replaced) [<a href="/pdf/2305.19555" title="Download PDF">pdf</a>, <a href="/ps/2305.19555" title="Download PostScript">ps</a>, <a href="/format/2305.19555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Are Not Strong Abstract Reasoners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gendron%2C+G">Ga&#xeb;l Gendron</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Q">Qiming Bao</a>, 
<a href="/search/cs?searchtype=author&query=Witbrock%2C+M">Michael Witbrock</a>, 
<a href="/search/cs?searchtype=author&query=Dobbie%2C+G">Gillian Dobbie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 13 pages for the main paper and 33 pages for the supplement, 35 figures. V2: performed additional experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19880" title="Abstract">arXiv:2305.19880</a> (replaced) [<a href="/pdf/2305.19880" title="Download PDF">pdf</a>, <a href="/format/2305.19880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability and convergence of in time approximations of hyperbolic  elastodynamics via stepwise minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=%C4%8Ce%C5%A1%C3%ADk%2C+A">Anton&#xed;n &#x10c;e&#x161;&#xed;k</a>, 
<a href="/search/math?searchtype=author&query=Schwarzacher%2C+S">Sebastian Schwarzacher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00600" title="Abstract">arXiv:2306.00600</a> (replaced) [<a href="/pdf/2306.00600" title="Download PDF">pdf</a>, <a href="/format/2306.00600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rotating Features for Object Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B6we%2C+S">Sindy L&#xf6;we</a>, 
<a href="/search/cs?searchtype=author&query=Lippe%2C+P">Phillip Lippe</a>, 
<a href="/search/cs?searchtype=author&query=Locatello%2C+F">Francesco Locatello</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Oral presentation at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02256" title="Abstract">arXiv:2306.02256</a> (replaced) [<a href="/pdf/2306.02256" title="Download PDF">pdf</a>, <a href="/format/2306.02256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less is More: Revisiting the Gaussian Mechanism for Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tianxi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at USENIX Security '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02602" title="Abstract">arXiv:2306.02602</a> (replaced) [<a href="/pdf/2306.02602" title="Download PDF">pdf</a>, <a href="/format/2306.02602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReContrast: Domain-Specific Anomaly Detection via Contrastive  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jia Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shuai Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+L">Lize Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weihang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huiqi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03955" title="Abstract">arXiv:2306.03955</a> (replaced) [<a href="/pdf/2306.03955" title="Download PDF">pdf</a>, <a href="/format/2306.03955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel quadrature with randomly pivoted Cholesky
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Epperly%2C+E+N">Ethan N. Epperly</a>, 
<a href="/search/math?searchtype=author&query=Moreno%2C+E">Elvira Moreno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures; NeurIPS 2023 (spotlight), camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04265" title="Abstract">arXiv:2306.04265</a> (replaced) [<a href="/pdf/2306.04265" title="Download PDF">pdf</a>, <a href="/format/2306.04265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Permutation Equivariant Graph Framelets for Heterophilous Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ruigang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Han Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+X">Xiaosheng Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04607" title="Abstract">arXiv:2306.04607</a> (replaced) [<a href="/pdf/2306.04607" title="Download PDF">pdf</a>, <a href="/format/2306.04607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+D">Dit-Yan Yeung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://kaichen1998.github.io/projects/geodiffusion/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04810" title="Abstract">arXiv:2306.04810</a> (replaced) [<a href="/pdf/2306.04810" title="Download PDF">pdf</a>, <a href="/format/2306.04810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlative Information Maximization: A Biologically Plausible Approach  to Supervised Deep Neural Networks without Weight Symmetry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bozkurt%2C+B">Bariscan Bozkurt</a>, 
<a href="/search/cs?searchtype=author&query=Pehlevan%2C+C">Cengiz Pehlevan</a>, 
<a href="/search/cs?searchtype=author&query=Erdogan%2C+A+T">Alper T Erdogan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05726" title="Abstract">arXiv:2306.05726</a> (replaced) [<a href="/pdf/2306.05726" title="Download PDF">pdf</a>, <a href="/format/2306.05726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iteratively Refined Behavior Regularization for Offline Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaohan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chenjun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06081" title="Abstract">arXiv:2306.06081</a> (replaced) [<a href="/pdf/2306.06081" title="Download PDF">pdf</a>, <a href="/format/2306.06081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARSO: Blending Adversarial Training and Purification Improves  Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ballarin%2C+E">Emanuele Ballarin</a>, 
<a href="/search/cs?searchtype=author&query=Ansuini%2C+A">Alessio Ansuini</a>, 
<a href="/search/cs?searchtype=author&query=Bortolussi%2C+L">Luca Bortolussi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 1 figure, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06330" title="Abstract">arXiv:2306.06330</a> (replaced) [<a href="/pdf/2306.06330" title="Download PDF">pdf</a>, <a href="/format/2306.06330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Drifting with 3 Minutes of Data via Learned Tire Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Djeumou%2C+F">Franck Djeumou</a>, 
<a href="/search/eess?searchtype=author&query=Goh%2C+J+Y+M">Jonathan Y.M. Goh</a>, 
<a href="/search/eess?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>, 
<a href="/search/eess?searchtype=author&query=Balachandran%2C+A">Avinash Balachandran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final Submission at ICRA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07092" title="Abstract">arXiv:2306.07092</a> (replaced) [<a href="/pdf/2306.07092" title="Download PDF">pdf</a>, <a href="/format/2306.07092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning Legged Locomotion Controllers via Safe Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Widmer%2C+D">Daniel Widmer</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongho Kang</a>, 
<a href="/search/cs?searchtype=author&query=Sukhija%2C+B">Bhavya Sukhija</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCbotter%2C+J">Jonas H&#xfc;botter</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/cs?searchtype=author&query=Coros%2C+S">Stelian Coros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted to the 2023 Conference on Robot Learning (CoRL 2023.) The supplementary video is available in <a href="https://youtu.be/zDBouUgegrU">this https URL</a> and the code implementation is available in <a href="https://github.com/lasgroup/gosafeopt">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09896" title="Abstract">arXiv:2306.09896</a> (replaced) [<a href="/pdf/2306.09896" title="Download PDF">pdf</a>, <a href="/format/2306.09896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Self-Repair a Silver Bullet for Code Generation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olausson%2C+T+X">Theo X. Olausson</a>, 
<a href="/search/cs?searchtype=author&query=Inala%2C+J+P">Jeevana Priya Inala</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Solar-Lezama%2C+A">Armando Solar-Lezama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added experiments for HumanEval (dataset) and Code Llama (model)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10070" title="Abstract">arXiv:2306.10070</a> (replaced) [<a href="/pdf/2306.10070" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opportunities and Challenges for ChatGPT and Large Language Models in  Biomedicine and Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Shubo Tian</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Q">Qiao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yeganova%2C+L">Lana Yeganova</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+P">Po-Ting Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qingqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiuying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W">Won Kim</a>, 
<a href="/search/cs?searchtype=author&query=Comeau%2C+D+C">Donald C. Comeau</a>, 
<a href="/search/cs?searchtype=author&query=Islamaj%2C+R">Rezarta Islamaj</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+A">Aadit Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhiyong Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10081" title="Abstract">arXiv:2306.10081</a> (replaced) [<a href="/pdf/2306.10081" title="Download PDF">pdf</a>, <a href="/format/2306.10081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizer&#x27;s Information Criterion: Dissecting and Correcting Bias in  Data-Driven Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iyengar%2C+G">Garud Iyengar</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+H">Henry Lam</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10190" title="Abstract">arXiv:2306.10190</a> (replaced) [<a href="/pdf/2306.10190" title="Download PDF">pdf</a>, <a href="/format/2306.10190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALP: Action-Aware Embodied Learning for Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xinran Liang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+A">Anthony Han</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wilson Yan</a>, 
<a href="/search/cs?searchtype=author&query=Raghunathan%2C+A">Aditi Raghunathan</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project website available at <a href="https://xinranliang.github.io/alp/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14079" title="Abstract">arXiv:2306.14079</a> (replaced) [<a href="/pdf/2306.14079" title="Download PDF">pdf</a>, <a href="/format/2306.14079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fighting Uncertainty with Gradients: Offline Reinforcement Learning via  Diffusion Score Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suh%2C+H+J+T">H.J. Terry Suh</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+G">Glen Chou</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hongkai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lujie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Tedrake%2C+R">Russ Tedrake</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Glen Chou, Hongkai Dai, and Lujie Yang contributed equally to this work. Accepted to CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14872" title="Abstract">arXiv:2306.14872</a> (replaced) [<a href="/pdf/2306.14872" title="Download PDF">pdf</a>, <a href="/format/2306.14872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-Aware Approaches for Balancing Performance and Theoretical  Guarantees in Linear Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuwei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Bayati%2C+M">Mohsen Bayati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15010" title="Abstract">arXiv:2306.15010</a> (replaced) [<a href="/pdf/2306.15010" title="Download PDF">pdf</a>, <a href="/format/2306.15010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient High-Resolution Template Matching with Vector Quantized  Nearest Neighbour Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ankit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Sintorn%2C+I">Ida-Maria Sintorn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15724" title="Abstract">arXiv:2306.15724</a> (replaced) [<a href="/pdf/2306.15724" title="Download PDF">pdf</a>, <a href="/format/2306.15724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REFLECT: Summarizing Robot Experiences for Failure Explanation and  Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zeyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bahety%2C+A">Arpit Bahety</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shuran Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Robot Learning (CoRL) 2023; Project website: <a href="https://robot-reflect.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16979" title="Abstract">arXiv:2306.16979</a> (replaced) [<a href="/pdf/2306.16979" title="Download PDF">pdf</a>, <a href="/format/2306.16979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defending Black-box Classifiers by Bayesian Boundary Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Diao%2C+Y">Yunfeng Diao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2203.04713">arXiv:2203.04713</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17181" title="Abstract">arXiv:2306.17181</a> (replaced) [<a href="/pdf/2306.17181" title="Download PDF">pdf</a>, <a href="/format/2306.17181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Text Embedding Space Generation Using Generative  Adversarial Networks for Text Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jun-Min Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+T">Tae-Bin Ha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NEJLT accpeted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01998" title="Abstract">arXiv:2307.01998</a> (replaced) [<a href="/pdf/2307.01998" title="Download PDF">pdf</a>, <a href="/format/2307.01998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Neural Architecture Search: Challenges, Solutions, and  Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guihong Li</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D">Duc Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+K">Kartikeya Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Ming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Marculescu%2C+R">Radu Marculescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02688" title="Abstract">arXiv:2307.02688</a> (replaced) [<a href="/pdf/2307.02688" title="Download PDF">pdf</a>, <a href="/ps/2307.02688" title="Download PostScript">ps</a>, <a href="/format/2307.02688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epistemic systems and Flagg and Friedman&#x27;s translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Inou%C3%A9%2C+T">Takao Inou&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02932" title="Abstract">arXiv:2307.02932</a> (replaced) [<a href="/pdf/2307.02932" title="Download PDF">pdf</a>, <a href="/format/2307.02932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When No-Rejection Learning is Consistent for Regression with Rejection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaocheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chunlin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanzhao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05793" title="Abstract">arXiv:2307.05793</a> (replaced) [<a href="/pdf/2307.05793" title="Download PDF">pdf</a>, <a href="/format/2307.05793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grid Cell-Inspired Fragmentation and Recall for Efficient Map Building
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jaedong Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Z">Zhang-Wei Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Eric Chen</a>, 
<a href="/search/cs?searchtype=author&query=Boopathy%2C+A">Akhilan Boopathy</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Fiete%2C+I">Ila Fiete</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07707" title="Abstract">arXiv:2307.07707</a> (replaced) [<a href="/pdf/2307.07707" title="Download PDF">pdf</a>, <a href="/format/2307.07707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Element Operations for Curved Simplex Meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shi%2C+A">Andrew Shi</a>, 
<a href="/search/math?searchtype=author&query=Persson%2C+P">Per-Olof Persson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> final version accepted at IJNME, 21 pages, 18 figures,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08137" title="Abstract">arXiv:2307.08137</a> (replaced) [<a href="/pdf/2307.08137" title="Download PDF">pdf</a>, <a href="/format/2307.08137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Euclidean lattices: theory and applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fukshansky%2C+L">Lenny Fukshansky</a>, 
<a href="/search/math?searchtype=author&query=Hollanti%2C+C">Camilla Hollanti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Communications in Mathematics 31 (2023), no. 2, 251--263
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Information Theory (cs.IT); Metric Geometry (math.MG)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08523" title="Abstract">arXiv:2307.08523</a> (replaced) [<a href="/pdf/2307.08523" title="Download PDF">pdf</a>, <a href="/ps/2307.08523" title="Download PostScript">ps</a>, <a href="/format/2307.08523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generic bidirectional typing for dependent type theories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Felicissimo%2C+T">Thiago Felicissimo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09052" title="Abstract">arXiv:2307.09052</a> (replaced) [<a href="/pdf/2307.09052" title="Download PDF">pdf</a>, <a href="/format/2307.09052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connections between Operator-splitting Methods and Deep Neural Networks  with Applications in Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+X">Xue-Cheng Tai</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+R">Raymond Chan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10236" title="Abstract">arXiv:2307.10236</a> (replaced) [<a href="/pdf/2307.10236" title="Download PDF">pdf</a>, <a href="/format/2307.10236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look Before You Leap: An Exploratory Study of Uncertainty Measurement  for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiayang Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shengming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Juefei-Xu%2C+F">Felix Juefei-Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14494" title="Abstract">arXiv:2307.14494</a> (replaced) [<a href="/pdf/2307.14494" title="Download PDF">pdf</a>, <a href="/format/2307.14494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding roots of complex analytic functions via generalized colleague  matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+H">Hanwen Zhang</a>, 
<a href="/search/math?searchtype=author&query=Rokhlin%2C+V">Vladimir Rokhlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16189" title="Abstract">arXiv:2307.16189</a> (replaced) [<a href="/pdf/2307.16189" title="Download PDF">pdf</a>, <a href="/format/2307.16189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Optimization: A Novel Approach to Counter Numerical Instability  in 16-bit Neural Network Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Juyoung Yun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16894" title="Abstract">arXiv:2307.16894</a> (replaced) [<a href="/pdf/2307.16894" title="Download PDF">pdf</a>, <a href="/format/2307.16894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A reduced order model for geometrically parameterized two-scale  simulations of elasto-plastic microstructures under large deformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Theron Guo</a>, 
<a href="/search/cs?searchtype=author&query=Roko%C5%A1%2C+O">Ond&#x159;ej Roko&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Veroy%2C+K">Karen Veroy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Methods in Applied Mechanics and Engineering 418 (2024):
  116467
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00619" title="Abstract">arXiv:2308.00619</a> (replaced) [<a href="/pdf/2308.00619" title="Download PDF">pdf</a>, <a href="/format/2308.00619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quantum algorithm for track reconstruction in the LHCb vertex detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Nicotra%2C+D">Davide Nicotra</a>, 
<a href="/search/quant-ph?searchtype=author&query=Martinez%2C+M+L">Miriam Lucio Martinez</a>, 
<a href="/search/quant-ph?searchtype=author&query=de+Vries%2C+J+A">Jacco Andreas de Vries</a>, 
<a href="/search/quant-ph?searchtype=author&query=Merk%2C+M">Marcel Merk</a>, 
<a href="/search/quant-ph?searchtype=author&query=Driessens%2C+K">Kurt Driessens</a>, 
<a href="/search/quant-ph?searchtype=author&query=Westra%2C+R+L">Ronald Leonard Westra</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dibenedetto%2C+D">Domenica Dibenedetto</a>, 
<a href="/search/quant-ph?searchtype=author&query=P%C3%A9rez%2C+D+H+C">Daniel Hugo C&#xe1;mpora P&#xe9;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); High Energy Physics - Experiment (hep-ex)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01263" title="Abstract">arXiv:2308.01263</a> (replaced) [<a href="/pdf/2308.01263" title="Download PDF">pdf</a>, <a href="/format/2308.01263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%C3%B6ttger%2C+P">Paul R&#xf6;ttger</a>, 
<a href="/search/cs?searchtype=author&query=Kirk%2C+H+R">Hannah Rose Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Vidgen%2C+B">Bertie Vidgen</a>, 
<a href="/search/cs?searchtype=author&query=Attanasio%2C+G">Giuseppe Attanasio</a>, 
<a href="/search/cs?searchtype=author&query=Bianchi%2C+F">Federico Bianchi</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+D">Dirk Hovy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2 prepared for conference submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08857" title="Abstract">arXiv:2308.08857</a> (replaced) [<a href="/pdf/2308.08857" title="Download PDF">pdf</a>, <a href="/format/2308.08857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D-IF: Uncertainty-aware Human Digitization via Implicit Distribution  Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xueting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yihao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yuliang Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhaoxin Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09793" title="Abstract">arXiv:2308.09793</a> (replaced) [<a href="/pdf/2308.09793" title="Download PDF">pdf</a>, <a href="/format/2308.09793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Modular Architecture for Science Factories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vescovi%2C+R">Rafael Vescovi</a>, 
<a href="/search/cs?searchtype=author&query=Ginsburg%2C+T">Tobias Ginsburg</a>, 
<a href="/search/cs?searchtype=author&query=Hippe%2C+K">Kyle Hippe</a>, 
<a href="/search/cs?searchtype=author&query=Ozgulbas%2C+D">Doga Ozgulbas</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+C">Casey Stone</a>, 
<a href="/search/cs?searchtype=author&query=Stroka%2C+A">Abraham Stroka</a>, 
<a href="/search/cs?searchtype=author&query=Butler%2C+R">Rory Butler</a>, 
<a href="/search/cs?searchtype=author&query=Blaiszik%2C+B">Ben Blaiszik</a>, 
<a href="/search/cs?searchtype=author&query=Brettin%2C+T">Tom Brettin</a>, 
<a href="/search/cs?searchtype=author&query=Chard%2C+K">Kyle Chard</a>, 
<a href="/search/cs?searchtype=author&query=Hereld%2C+M">Mark Hereld</a>, 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+A">Arvind Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+R">Rick Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Vriza%2C+A">Aikaterini Vriza</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingteng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+I">Ian Foster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09904" title="Abstract">arXiv:2308.09904</a> (replaced) [<a href="/pdf/2308.09904" title="Download PDF">pdf</a>, <a href="/format/2308.09904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAH! RecSys-Assistant-Human: A Human-Centered Recommendation Framework  with LLM Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yubo Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haonan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hansu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ning Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10335" title="Abstract">arXiv:2308.10335</a> (replaced) [<a href="/pdf/2308.10335" title="Download PDF">pdf</a>, <a href="/format/2308.10335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT replace StackOverflow? A Study on Robustness and Reliability  of Large Language Model Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Li Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10875" title="Abstract">arXiv:2308.10875</a> (replaced) [<a href="/e-print/2308.10875" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metaheuristic Algorithms in Artificial Intelligence with Applications to  Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+E+H">Elvis Han Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C+J">Culsome Junwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+W+K">Weng Kee Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision, unpublished manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10989" title="Abstract">arXiv:2308.10989</a> (replaced) [<a href="/pdf/2308.10989" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental demonstration of an integrated on-chip p-bit core utilizing  stochastic Magnetic Tunnel Junctions and 2D-MoS2 FETs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Daniel%2C+J">John Daniel</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+Z">Zheng Sun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+X">Xuejian Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tan%2C+Y">Yuanqiu Tan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Dilley%2C+N">Neil Dilley</a>, 
<a href="/search/cond-mat?searchtype=author&query=Chen%2C+Z">Zhihong Chen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Appenzeller%2C+J">Joerg Appenzeller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11890" title="Abstract">arXiv:2308.11890</a> (replaced) [<a href="/pdf/2308.11890" title="Download PDF">pdf</a>, <a href="/format/2308.11890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape-conditioned 3D Molecule Generation via Equivariant Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Parthasarathy%2C+S">Srinivasan Parthasarathy</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xia Ning</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13877" title="Abstract">arXiv:2308.13877</a> (replaced) [<a href="/pdf/2308.13877" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of machine Learning to improve the efficiency and range of  microbial biosynthesis: a review of state-of-art techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Bhalla%2C+A">Akshay Bhalla</a>, 
<a href="/search/q-bio?searchtype=author&query=Rajendran%2C+S">Suraj Rajendran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Subcellular Processes (q-bio.SC)</span>; Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15452" title="Abstract">arXiv:2308.15452</a> (replaced) [<a href="/pdf/2308.15452" title="Download PDF">pdf</a>, <a href="/format/2308.15452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Do Program-of-Thoughts Work for Reasoning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+Z">Zhen Bi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yinuo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shumin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guozhou Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16470" title="Abstract">arXiv:2308.16470</a> (replaced) [<a href="/pdf/2308.16470" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-adaptive Message Passing Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Kup-Sze Choi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version rectifies the numerical inaccuracies of Table 3 and 4 in the printed version (<a href="https://doi.org/10.1016/j.neunet.2023.04.038">this https URL</a>). See our corrigendum at <a href="https://doi.org/10.1016/j.neunet.2023.09.026">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Networks, vol. 164, pp. 439-454, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01289" title="Abstract">arXiv:2309.01289</a> (replaced) [<a href="/pdf/2309.01289" title="Download PDF">pdf</a>, <a href="/format/2309.01289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting  in Continual Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakman%2C+Y+F">Yavuz Faruk Bakman</a>, 
<a href="/search/cs?searchtype=author&query=Yaldiz%2C+D+N">Duygu Nur Yaldiz</a>, 
<a href="/search/cs?searchtype=author&query=Ezzeldin%2C+Y+H">Yahya H. Ezzeldin</a>, 
<a href="/search/cs?searchtype=author&query=Avestimehr%2C+S">Salman Avestimehr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02072" title="Abstract">arXiv:2309.02072</a> (replaced) [<a href="/pdf/2309.02072" title="Download PDF">pdf</a>, <a href="/format/2309.02072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepVol: A Pre-Trained Universal Asset Volatility Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/econ?searchtype=author&query=Tran%2C+M">Minh-Ngoc Tran</a>, 
<a href="/search/econ?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/econ?searchtype=author&query=Gerlach%2C+R">Richard Gerlach</a>, 
<a href="/search/econ?searchtype=author&query=Kohn%2C+R">Robert Kohn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Artificial Intelligence (cs.AI); Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04965" title="Abstract">arXiv:2309.04965</a> (replaced) [<a href="/pdf/2309.04965" title="Download PDF">pdf</a>, <a href="/format/2309.04965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prefix-diffusion: A Lightweight Diffusion Model for Diverse Image  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guisheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhengcong Fei</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haiyan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiangyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanqing Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages,4 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05197" title="Abstract">arXiv:2309.05197</a> (replaced) [<a href="/pdf/2309.05197" title="Download PDF">pdf</a>, <a href="/format/2309.05197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Sequential Acquisition Policies for Robot-Assisted Feeding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+P">Priya Sundaresan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05211" title="Abstract">arXiv:2309.05211</a> (replaced) [<a href="/pdf/2309.05211" title="Download PDF">pdf</a>, <a href="/format/2309.05211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Quaternion Higher-Order Singular Value Decomposition: Models and  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ya%2C+H">Hanxin Ya</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yuning Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07810" title="Abstract">arXiv:2309.07810</a> (replaced) [<a href="/pdf/2309.07810" title="Download PDF">pdf</a>, <a href="/format/2309.07810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectrum-Aware Adjustment: A New Debiasing Framework with Applications  to Principal Component Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yufan Li</a>, 
<a href="/search/math?searchtype=author&query=Sur%2C+P">Pragya Sur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08157" title="Abstract">arXiv:2309.08157</a> (replaced) [<a href="/pdf/2309.08157" title="Download PDF">pdf</a>, <a href="/format/2309.08157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RVAE-EM: Generative speech dereverberation based on recurrent  variational auto-encoder and convolutive transfer function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+P">Pengyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaofei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08586" title="Abstract">arXiv:2309.08586</a> (replaced) [<a href="/pdf/2309.08586" title="Download PDF">pdf</a>, <a href="/format/2309.08586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Replacing softmax with ReLU in Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wortsman%2C+M">Mitchell Wortsman</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Gilmer%2C+J">Justin Gilmer</a>, 
<a href="/search/cs?searchtype=author&query=Kornblith%2C+S">Simon Kornblith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09623" title="Abstract">arXiv:2309.09623</a> (replaced) [<a href="/pdf/2309.09623" title="Download PDF">pdf</a>, <a href="/format/2309.09623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumTrans: A Novel Open-Source Dataset for Humming Melody Transcription  and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shansong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xu Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dian Li</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10066" title="Abstract">arXiv:2309.10066</a> (replaced) [<a href="/pdf/2309.10066" title="Download PDF">pdf</a>, <a href="/format/2309.10066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Personalized Impression Generation for PET Reports Using Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tie%2C+X">Xin Tie</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+M">Muheon Shin</a>, 
<a href="/search/cs?searchtype=author&query=Pirasteh%2C+A">Ali Pirasteh</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+N">Nevein Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Huemann%2C+Z">Zachary Huemann</a>, 
<a href="/search/cs?searchtype=author&query=Castellino%2C+S+M">Sharon M. Castellino</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+K+M">Kara M. Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Garrett%2C+J">John Garrett</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Junjie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S+Y">Steve Y. Cho</a>, 
<a href="/search/cs?searchtype=author&query=Bradshaw%2C+T+J">Tyler J. Bradshaw</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages in total. 6 figures and 3 tables in the main body. The manuscript has been submitted to a journal for potential publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10150" title="Abstract">arXiv:2309.10150</a> (replaced) [<a href="/pdf/2309.10150" title="Download PDF">pdf</a>, <a href="/format/2309.10150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Transformer: Scalable Offline Reinforcement Learning via  Autoregressive Q-Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chebotar%2C+Y">Yevgen Chebotar</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Q">Quan Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Irpan%2C+A">Alex Irpan</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aviral Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianhe Yu</a>, 
<a href="/search/cs?searchtype=author&query=Herzog%2C+A">Alexander Herzog</a>, 
<a href="/search/cs?searchtype=author&query=Pertsch%2C+K">Karl Pertsch</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+K">Keerthana Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Ibarz%2C+J">Julian Ibarz</a>, 
<a href="/search/cs?searchtype=author&query=Nachum%2C+O">Ofir Nachum</a>, 
<a href="/search/cs?searchtype=author&query=Sontakke%2C+S">Sumedh Sontakke</a>, 
<a href="/search/cs?searchtype=author&query=Salazar%2C+G">Grecia Salazar</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+H+T">Huong T Tran</a>, 
<a href="/search/cs?searchtype=author&query=Peralta%2C+J">Jodilyn Peralta</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Clayton Tan</a>, 
<a href="/search/cs?searchtype=author&query=Manjunath%2C+D">Deeksha Manjunath</a>, 
<a href="/search/cs?searchtype=author&query=Singht%2C+J">Jaspiar Singht</a>, 
<a href="/search/cs?searchtype=author&query=Zitkovich%2C+B">Brianna Zitkovich</a>, 
<a href="/search/cs?searchtype=author&query=Jackson%2C+T">Tomas Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+K">Kanishka Rao</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See website at <a href="https://qtransformer.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10491" title="Abstract">arXiv:2309.10491</a> (replaced) [<a href="/pdf/2309.10491" title="Download PDF">pdf</a>, <a href="/format/2309.10491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCPT: Darkness Clue-Prompted Tracking in Nighttime UAVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiawen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huayi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shihao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengming Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12053" title="Abstract">arXiv:2309.12053</a> (replaced) [<a href="/pdf/2309.12053" title="Download PDF">pdf</a>, <a href="/format/2309.12053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AceGPT, Localizing Large Language Models in Arabic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xuening Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dingjie Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhihong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Alharthi%2C+A">Abdulmohsen Alharthi</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bang An</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Juncai He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziche Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianquan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruoyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinchao Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/FreedomIntelligence/AceGPT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12128" title="Abstract">arXiv:2309.12128</a> (replaced) [<a href="/pdf/2309.12128" title="Download PDF">pdf</a>, <a href="/format/2309.12128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence and Recovery Guarantees of Unsupervised Neural Networks for  Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buskulic%2C+N">Nathan Buskulic</a>, 
<a href="/search/cs?searchtype=author&query=Fadili%2C+J">Jalal Fadili</a>, 
<a href="/search/cs?searchtype=author&query=Qu%C3%A9au%2C+Y">Yvain Qu&#xe9;au</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12871" title="Abstract">arXiv:2309.12871</a> (replaced) [<a href="/pdf/2309.12871" title="Download PDF">pdf</a>, <a href="/format/2309.12871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnglE-optimized Text Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianming Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update llama results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14030" title="Abstract">arXiv:2309.14030</a> (replaced) [<a href="/pdf/2309.14030" title="Download PDF">pdf</a>, <a href="/format/2309.14030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeWave: Discrete EEG Waves Encoding for Brain Dynamics to Text  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yiqun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jinzhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Teng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14080" title="Abstract">arXiv:2309.14080</a> (replaced) [<a href="/pdf/2309.14080" title="Download PDF">pdf</a>, <a href="/format/2309.14080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and Detection of Pathological Voice using Glottal Source  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kadiri%2C+S+R">Sudarsana Reddy Kadiri</a>, 
<a href="/search/eess?searchtype=author&query=Alku%2C+P">Paavo Alku</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Copyright 2020 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Journal of Selected Topics in Signal Processing, Vol. 14, No.
  2, pp. 367-379, February 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14107" title="Abstract">arXiv:2309.14107</a> (replaced) [<a href="/pdf/2309.14107" title="Download PDF">pdf</a>, <a href="/format/2309.14107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wav2vec-based Detection and Severity Level Classification of Dysarthria  from Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Javanmardi%2C+F">Farhad Javanmardi</a>, 
<a href="/search/eess?searchtype=author&query=Tirronen%2C+S">Saska Tirronen</a>, 
<a href="/search/eess?searchtype=author&query=Kodali%2C+M">Manila Kodali</a>, 
<a href="/search/eess?searchtype=author&query=Kadiri%2C+S+R">Sudarsana Reddy Kadiri</a>, 
<a href="/search/eess?searchtype=author&query=Alku%2C+P">Paavo Alku</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in Proc. ICASSP, Rhodes Island, Greece, June 4-10, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14322" title="Abstract">arXiv:2309.14322</a> (replaced) [<a href="/pdf/2309.14322" title="Download PDF">pdf</a>, <a href="/format/2309.14322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small-scale proxies for large-scale Transformer training instabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wortsman%2C+M">Mitchell Wortsman</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P+J">Peter J. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lechao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Everett%2C+K">Katie Everett</a>, 
<a href="/search/cs?searchtype=author&query=Alemi%2C+A">Alex Alemi</a>, 
<a href="/search/cs?searchtype=author&query=Adlam%2C+B">Ben Adlam</a>, 
<a href="/search/cs?searchtype=author&query=Co-Reyes%2C+J+D">John D. Co-Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Gur%2C+I">Izzeddin Gur</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Novak%2C+R">Roman Novak</a>, 
<a href="/search/cs?searchtype=author&query=Pennington%2C+J">Jeffrey Pennington</a>, 
<a href="/search/cs?searchtype=author&query=Sohl-dickstein%2C+J">Jascha Sohl-dickstein</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kelvin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Gilmer%2C+J">Justin Gilmer</a>, 
<a href="/search/cs?searchtype=author&query=Kornblith%2C+S">Simon Kornblith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15714" title="Abstract">arXiv:2309.15714</a> (replaced) [<a href="/pdf/2309.15714" title="Download PDF">pdf</a>, <a href="/format/2309.15714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating LLM, EEG, and Eye-Tracking Biomarker Analysis for Word-Level  Neural State Classification in Semantic Inference Reading Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qin Li</a>, 
<a href="/search/cs?searchtype=author&query=Nahata%2C+S">Sujal Nahata</a>, 
<a href="/search/cs?searchtype=author&query=Jamal%2C+T">Tasnia Jamal</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shih-kuen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cauwenberghs%2C+G">Gert Cauwenberghs</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+T">Tzyy-Ping Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15816" title="Abstract">arXiv:2309.15816</a> (replaced) [<a href="/pdf/2309.15816" title="Download PDF">pdf</a>, <a href="/ps/2309.15816" title="Download PostScript">ps</a>, <a href="/format/2309.15816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orbit closures, stabilizer limits and intermediate $G$-varieties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adsul%2C+B">Bharat Adsul</a>, 
<a href="/search/math?searchtype=author&query=Sohoni%2C+M">Milind Sohoni</a>, 
<a href="/search/math?searchtype=author&query=Subrahmanyam%2C+K+V">K V Subrahmanyam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Representation Theory (math.RT)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15818" title="Abstract">arXiv:2309.15818</a> (replaced) [<a href="/pdf/2309.15818" title="Download PDF">pdf</a>, <a href="/format/2309.15818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D+J">David Junhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+Z">Jay Zhangjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+L">Lingmin Ran</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuchao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Difei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page is <a href="https://showlab.github.io/Show-1">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16039" title="Abstract">arXiv:2309.16039</a> (replaced) [<a href="/pdf/2309.16039" title="Download PDF">pdf</a>, <a href="/format/2309.16039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Long-Context Scaling of Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wenhan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Molybog%2C+I">Igor Molybog</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hejia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bhargava%2C+P">Prajjwal Bhargava</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Rui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+L">Louis Martin</a>, 
<a href="/search/cs?searchtype=author&query=Rungta%2C+R">Rashi Rungta</a>, 
<a href="/search/cs?searchtype=author&query=Sankararaman%2C+K+A">Karthik Abinav Sankararaman</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+B">Barlas Oguz</a>, 
<a href="/search/cs?searchtype=author&query=Khabsa%2C+M">Madian Khabsa</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Han Fang</a>, 
<a href="/search/cs?searchtype=author&query=Mehdad%2C+Y">Yashar Mehdad</a>, 
<a href="/search/cs?searchtype=author&query=Narang%2C+S">Sharan Narang</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+K">Kshitiz Malik</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+A">Angela Fan</a>, 
<a href="/search/cs?searchtype=author&query=Bhosale%2C+S">Shruti Bhosale</a>, 
<a href="/search/cs?searchtype=author&query=Edunov%2C+S">Sergey Edunov</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Mike Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sinong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hao Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16646" title="Abstract">arXiv:2309.16646</a> (replaced) [<a href="/pdf/2309.16646" title="Download PDF">pdf</a>, <a href="/format/2309.16646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Equivariance in State-of-the-Art Supervised Depth and Normal  Predictors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yuanyi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Bhattad%2C+A">Anand Bhattad</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Forsyth%2C+D">David Forsyth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16705" title="Abstract">arXiv:2309.16705</a> (replaced) [<a href="/pdf/2309.16705" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Analysis Of Google Bard And GPT-Vision: Experiments In Visual  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noever%2C+D">David Noever</a>, 
<a href="/search/cs?searchtype=author&query=Noever%2C+S+E+M">Samantha Elizabeth Miller Noever</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00091" title="Abstract">arXiv:2310.00091</a> (replaced) [<a href="/pdf/2310.00091" title="Download PDF">pdf</a>, <a href="/format/2310.00091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automated Accessibility Report Generation for Mobile Apps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Swearngin%2C+A">Amanda Swearngin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jason Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gomez%2C+E">Esteban Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Coughenour%2C+J">Jen Coughenour</a>, 
<a href="/search/cs?searchtype=author&query=Stukenborg%2C+R">Rachel Stukenborg</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+B">Bhavya Garg</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+G">Greg Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Hilliard%2C+A">Adriana Hilliard</a>, 
<a href="/search/cs?searchtype=author&query=Bigham%2C+J+P">Jeffrey P. Bigham</a>, 
<a href="/search/cs?searchtype=author&query=Nichols%2C+J">Jeffrey Nichols</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01015" title="Abstract">arXiv:2310.01015</a> (replaced) [<a href="/pdf/2310.01015" title="Download PDF">pdf</a>, <a href="/format/2310.01015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ETGraph: A Pioneering Dataset Bridging Ethereum and Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shengliang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bingqiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bingsheng He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01152" title="Abstract">arXiv:2310.01152</a> (replaced) [<a href="/pdf/2310.01152" title="Download PDF">pdf</a>, <a href="/format/2310.01152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model-Powered Smart Contract Vulnerability Detection: New  Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sihao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiansheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=%C4%B0lhan%2C+F">Fatih &#x130;lhan</a>, 
<a href="/search/cs?searchtype=author&query=Tekin%2C+S+F">Selim Furkan Tekin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Ling Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Trust, Privacy and Security in
  Intelligent Systems, and Applications 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01342" title="Abstract">arXiv:2310.01342</a> (replaced) [<a href="/pdf/2310.01342" title="Download PDF">pdf</a>, <a href="/format/2310.01342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-field Integrated Sensing and Communication: Opportunities and  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cong%2C+J">Jiayi Cong</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Changsheng You</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiapeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Beixiong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yi Gong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is submitted to IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01415" title="Abstract">arXiv:2310.01415</a> (replaced) [<a href="/pdf/2310.01415" title="Download PDF">pdf</a>, <a href="/format/2310.01415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-Driver: Learning to Drive with GPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiageng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yuxi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://pointscoder.github.io/projects/gpt_driver/index.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01541" title="Abstract">arXiv:2310.01541</a> (replaced) [<a href="/pdf/2310.01541" title="Download PDF">pdf</a>, <a href="/format/2310.01541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restoring the Discontinuous Heat Equation Source Using Sparse Boundary  Data and Dynamic Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+G">Guang Lin</a>, 
<a href="/search/math?searchtype=author&query=Ou%2C+N">Na Ou</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zecheng Zhang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zhidong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01552" title="Abstract">arXiv:2310.01552</a> (replaced) [<a href="/pdf/2310.01552" title="Download PDF">pdf</a>, <a href="/format/2310.01552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Ancillary Services: From Grid Codes to Transfer Function-Based  Converter Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=H%C3%A4berle%2C+V">Verena H&#xe4;berle</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Linbin Huang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+X">Xiuqiang He</a>, 
<a href="/search/eess?searchtype=author&query=Prieto-Araujo%2C+E">Eduardo Prieto-Araujo</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01596" title="Abstract">arXiv:2310.01596</a> (replaced) [<a href="/pdf/2310.01596" title="Download PDF">pdf</a>, <a href="/format/2310.01596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImagenHub: Standardizing the evaluation of conditional image generation  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ku%2C+M">Max Ku</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianle Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xingyu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+W">Wenwen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02523" title="Abstract">arXiv:2310.02523</a> (replaced) [<a href="/pdf/2310.02523" title="Download PDF">pdf</a>, <a href="/format/2310.02523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spatio-Temporal Attention-Based Method for Detecting Student Classroom  Behaviors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02554" title="Abstract">arXiv:2310.02554</a> (replaced) [<a href="/pdf/2310.02554" title="Download PDF">pdf</a>, <a href="/format/2310.02554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> zkFL: Zero-Knowledge Proof-based Gradient Aggregation for Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhipeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Nanqing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiahao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Knottenbelt%2C+W">William Knottenbelt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02569" title="Abstract">arXiv:2310.02569</a> (replaced) [<a href="/pdf/2310.02569" title="Download PDF">pdf</a>, <a href="/format/2310.02569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReForm-Eval: Evaluating Large Vision Language Models via Unified  Re-Formulation of Task-Oriented Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zejun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengfei Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Binhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chengxing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhihao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingjing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhongyu Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 11 figures, 24 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03708" title="Abstract">arXiv:2310.03708</a> (replaced) [<a href="/pdf/2310.03708" title="Download PDF">pdf</a>, <a href="/format/2310.03708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond One-Preference-for-All: Multi-Objective Direct Preference  Optimization for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanhui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiangyu Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04633" title="Abstract">arXiv:2310.04633</a> (replaced) [<a href="/pdf/2310.04633" title="Download PDF">pdf</a>, <a href="/format/2310.04633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased and Robust: External Attention-enhanced Graph Contrastive  Learning for Cross-domain Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinhua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+H">Houping Yue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zizheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liancheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, accepted by ICDM 2023 (workshop-GML4Rec)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04706" title="Abstract">arXiv:2310.04706</a> (replaced) [<a href="/e-print/2310.04706" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Imitation Learning with Variational Counterfactual Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bowei He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zexu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chen Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version has some errors and mistakes, especially theoretically. After a careful assessment, we think we need a long time to fix them, including revising the theory derivation in Sec. 3.2 and 4.3. and conducting some supplementary experiments to help validate the applicability of our method
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04780" title="Abstract">arXiv:2310.04780</a> (replaced) [<a href="/pdf/2310.04780" title="Download PDF">pdf</a>, <a href="/format/2310.04780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPMix: Label-Preserving Data Augmentation Method for Training Robust  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhenglin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+X">Xianan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Na Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+X">Xiaomei Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Biao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04809" title="Abstract">arXiv:2310.04809</a> (replaced) [<a href="/pdf/2310.04809" title="Download PDF">pdf</a>, <a href="/format/2310.04809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging LLVM&#x27;s ScalarEvolution for Symbolic Data Cache Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Touzeau%2C+V">Valentin Touzeau</a>, 
<a href="/search/cs?searchtype=author&query=Reineke%2C+J">Jan Reineke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of RTSS 2023 paper including definitions and proofs omitted in the conference version due to space constraints
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04986" title="Abstract">arXiv:2310.04986</a> (replaced) [<a href="/pdf/2310.04986" title="Download PDF">pdf</a>, <a href="/format/2310.04986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new economic and financial theory of money
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Glinsky%2C+M+E">Michael E. Glinsky</a>, 
<a href="/search/econ?searchtype=author&query=Sievert%2C+S">Sharon Sievert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 35 figures, 158 equations, to be submitted to Journal of Economic Affairs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI); Classical Physics (physics.class-ph)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05136" title="Abstract">arXiv:2310.05136</a> (replaced) [<a href="/pdf/2310.05136" title="Download PDF">pdf</a>, <a href="/format/2310.05136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructDET: Diversifying Referring Object Detection with Generalized  Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dang%2C+R">Ronghao Dang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiangyan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haodong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chongjian Ge</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lin Song</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Lijun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengju Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yibing Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages (include Appendix) Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05392" title="Abstract">arXiv:2310.05392</a> (replaced) [<a href="/pdf/2310.05392" title="Download PDF">pdf</a>, <a href="/format/2310.05392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Full-Convolutional Siamese Tracker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunfeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xueyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuoyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ye Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05647" title="Abstract">arXiv:2310.05647</a> (replaced) [<a href="/pdf/2310.05647" title="Download PDF">pdf</a>, <a href="/format/2310.05647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Manifold Structured Data Priors for Improved MR  Fingerprinting Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+Y">Yuping Ji</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Y">Yue Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures, will submit to IEEE Transactions on Medical Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05677" title="Abstract">arXiv:2310.05677</a> (replaced) [<a href="/pdf/2310.05677" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of stock molecular system and popularization of Density  Functional Theory in stock market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huajian Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiajian Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 1 table, 18 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05958" title="Abstract">arXiv:2310.05958</a> (replaced) [<a href="/pdf/2310.05958" title="Download PDF">pdf</a>, <a href="/format/2310.05958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimising T-count is NP-hard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=van+de+Wetering%2C+J">John van de Wetering</a>, 
<a href="/search/quant-ph?searchtype=author&query=Amy%2C+M">Matt Amy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages. v2: added proof of hardness of Toffoli optimisation, and improved upper bound of NP^NQP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06434" title="Abstract">arXiv:2310.06434</a> (replaced) [<a href="/pdf/2310.06434" title="Download PDF">pdf</a>, <a href="/format/2310.06434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whispering LLaMA: A Cross-Modal Generative Error Correction Framework  for Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radhakrishnan%2C+S">Srijith Radhakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C+H">Chao-Han Huck Yang</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S+A">Sumeer Ahmad Khan</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Rohit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Kiani%2C+N+A">Narsis A. Kiani</a>, 
<a href="/search/cs?searchtype=author&query=Gomez-Cabrero%2C+D">David Gomez-Cabrero</a>, 
<a href="/search/cs?searchtype=author&query=Tegner%2C+J+N">Jesper N. Tegner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 as main paper. 10 pages. Revised math notations. GitHub: <a href="https://github.com/Srijith-rkr/Whispering-LLaMA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06763" title="Abstract">arXiv:2310.06763</a> (replaced) [<a href="/pdf/2310.06763" title="Download PDF">pdf</a>, <a href="/format/2310.06763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FABind: Fast and Accurate Protein-Ligand Binding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+Q">Qizhi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kaiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lijun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yingce Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shufang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kun He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tie-Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Neural Information Processing Systems 2023 (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07184" title="Abstract">arXiv:2310.07184</a> (replaced) [<a href="/pdf/2310.07184" title="Download PDF">pdf</a>, <a href="/format/2310.07184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroInspect: Interpretable Neuron-based Debugging Framework through  Class-conditional Visualizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+Y">Yeong-Joon Ju</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Ji-Hoon Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07276" title="Abstract">arXiv:2310.07276</a> (replaced) [<a href="/pdf/2310.07276" title="Download PDF">pdf</a>, <a href="/format/2310.07276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioT5: Enriching Cross-modal Integration in Biology with Chemical  Knowledge and Natural Language Associations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+Q">Qizhi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kehan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kaiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lijun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yingce Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Empirical Methods in Natural Language Processing 2023 (EMNLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07577" title="Abstract">arXiv:2310.07577</a> (replaced) [<a href="/pdf/2310.07577" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of resource availability and conformity effect on sustainability  of common-pool resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Tu%2C+C">Chengyi Tu</a>, 
<a href="/search/econ?searchtype=author&query=Chen%2C+R">Renfei Chen</a>, 
<a href="/search/econ?searchtype=author&query=Fan%2C+Y">Ying Fan</a>, 
<a href="/search/econ?searchtype=author&query=Pan%2C+X">Xuwei Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07838" title="Abstract">arXiv:2310.07838</a> (replaced) [<a href="/pdf/2310.07838" title="Download PDF">pdf</a>, <a href="/format/2310.07838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the Fundamental Limits of Knowledge Transfer over Finite Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qingyue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 2 figures; related works polished
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08008" title="Abstract">arXiv:2310.08008</a> (replaced) [<a href="/pdf/2310.08008" title="Download PDF">pdf</a>, <a href="/format/2310.08008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects of Human Adversarial and Affable Samples on BERT  Generalizability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elangovan%2C+A">Aparna Elangovan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiayuan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Verspoor%2C+K">Karin Verspoor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at EMNLP Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08327" title="Abstract">arXiv:2310.08327</a> (replaced) [<a href="/pdf/2310.08327" title="Download PDF">pdf</a>, <a href="/format/2310.08327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Z3-Noodler: An Automata-based String Solver (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu-Fang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chocholat%C3%BD%2C+D">David Chocholat&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Havlena%2C+V">Vojt&#x11b;ch Havlena</a>, 
<a href="/search/cs?searchtype=author&query=Hol%C3%ADk%2C+L">Luk&#xe1;&#x161; Hol&#xed;k</a>, 
<a href="/search/cs?searchtype=author&query=Leng%C3%A1l%2C+O">Ond&#x159;ej Leng&#xe1;l</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%AD%C4%8D%2C+J">Juraj S&#xed;&#x10d;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08659" title="Abstract">arXiv:2310.08659</a> (replaced) [<a href="/pdf/2310.08659" title="Download PDF">pdf</a>, <a href="/format/2310.08659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengcheng He</a>, 
<a href="/search/cs?searchtype=author&query=Karampatziakis%2C+N">Nikos Karampatziakis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tuo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08738" title="Abstract">arXiv:2310.08738</a> (replaced) [<a href="/pdf/2310.08738" title="Download PDF">pdf</a>, <a href="/format/2310.08738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Splicing Up Your Predictions with RNA Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fradkin%2C+P">Philip Fradkin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+B">Brendan Frey</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+L+J">Leo J. Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08754" title="Abstract">arXiv:2310.08754</a> (replaced) [<a href="/pdf/2310.08754" title="Download PDF">pdf</a>, <a href="/format/2310.08754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tokenizer Choice For LLM Training: Negligible or Crucial?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+M">Mehdi Ali</a>, 
<a href="/search/cs?searchtype=author&query=Fromm%2C+M">Michael Fromm</a>, 
<a href="/search/cs?searchtype=author&query=Thellmann%2C+K">Klaudia Thellmann</a>, 
<a href="/search/cs?searchtype=author&query=Rutmann%2C+R">Richard Rutmann</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCbbering%2C+M">Max L&#xfc;bbering</a>, 
<a href="/search/cs?searchtype=author&query=Leveling%2C+J">Johannes Leveling</a>, 
<a href="/search/cs?searchtype=author&query=Klug%2C+K">Katrin Klug</a>, 
<a href="/search/cs?searchtype=author&query=Ebert%2C+J">Jan Ebert</a>, 
<a href="/search/cs?searchtype=author&query=Doll%2C+N">Niclas Doll</a>, 
<a href="/search/cs?searchtype=author&query=Buschhoff%2C+J+S">Jasper Schulze Buschhoff</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+C">Charvi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+A+A">Alexander Arno Weber</a>, 
<a href="/search/cs?searchtype=author&query=Jurkschat%2C+L">Lena Jurkschat</a>, 
<a href="/search/cs?searchtype=author&query=Abdelwahab%2C+H">Hammam Abdelwahab</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+C">Chelsea John</a>, 
<a href="/search/cs?searchtype=author&query=Suarez%2C+P+O">Pedro Ortiz Suarez</a>, 
<a href="/search/cs?searchtype=author&query=Ostendorff%2C+M">Malte Ostendorff</a>, 
<a href="/search/cs?searchtype=author&query=Weinbach%2C+S">Samuel Weinbach</a>, 
<a href="/search/cs?searchtype=author&query=Sifa%2C+R">Rafet Sifa</a>, 
<a href="/search/cs?searchtype=author&query=Kesselheim%2C+S">Stefan Kesselheim</a>, 
<a href="/search/cs?searchtype=author&query=Flores-Herr%2C+N">Nicolas Flores-Herr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08864" title="Abstract">arXiv:2310.08864</a> (replaced) [<a href="/pdf/2310.08864" title="Download PDF">pdf</a>, <a href="/format/2310.08864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open X-Embodiment: Robotic Learning Datasets and RT-X Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Open+X-Embodiment+Collaboration">Open X-Embodiment Collaboration</a>, 
<a href="/search/cs?searchtype=author&query=Padalkar%2C+A">Abhishek Padalkar</a>, 
<a href="/search/cs?searchtype=author&query=Pooley%2C+A">Acorn Pooley</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Ajinkya Jain</a>, 
<a href="/search/cs?searchtype=author&query=Bewley%2C+A">Alex Bewley</a>, 
<a href="/search/cs?searchtype=author&query=Herzog%2C+A">Alex Herzog</a>, 
<a href="/search/cs?searchtype=author&query=Irpan%2C+A">Alex Irpan</a>, 
<a href="/search/cs?searchtype=author&query=Khazatsky%2C+A">Alexander Khazatsky</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+A">Anant Rai</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anikait Singh</a>, 
<a href="/search/cs?searchtype=author&query=Brohan%2C+A">Anthony Brohan</a>, 
<a href="/search/cs?searchtype=author&query=Raffin%2C+A">Antonin Raffin</a>, 
<a href="/search/cs?searchtype=author&query=Wahid%2C+A">Ayzaan Wahid</a>, 
<a href="/search/cs?searchtype=author&query=Burgess-Limerick%2C+B">Ben Burgess-Limerick</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Beomjoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Charles Xu</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+C">Cheng Chi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chenguang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Christine Chan</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chuer Pan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chuyuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Devin%2C+C">Coline Devin</a>, 
<a href="/search/cs?searchtype=author&query=Driess%2C+D">Danny Driess</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhruv Shah</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCchler%2C+D">Dieter B&#xfc;chler</a>, 
<a href="/search/cs?searchtype=author&query=Kalashnikov%2C+D">Dmitry Kalashnikov</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Johns%2C+E">Edward Johns</a>, 
<a href="/search/cs?searchtype=author&query=Ceola%2C+F">Federico Ceola</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Stulp%2C+F">Freek Stulp</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Gaoyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sukhatme%2C+G+S">Gaurav S. Sukhatme</a>, 
<a href="/search/cs?searchtype=author&query=Salhotra%2C+G">Gautam Salhotra</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Ge Yan</a>, 
<a href="/search/cs?searchtype=author&query=Schiavi%2C+G">Giulio Schiavi</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+G">Gregory Kahn</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hao-Shu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haochen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Amor%2C+H+B">Heni Ben Amor</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+H+I">Henrik I Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Furuta%2C+H">Hiroki Furuta</a>, 
<a href="/search/cs?searchtype=author&query=Walke%2C+H">Homer Walke</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hongjie Fang</a>, 
<a href="/search/cs?searchtype=author&query=Mordatch%2C+I">Igor Mordatch</a>, 
<a href="/search/cs?searchtype=author&query=Radosavovic%2C+I">Ilija Radosavovic</a>,  et al. (124 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08868" title="Abstract">arXiv:2310.08868</a> (replaced) [<a href="/pdf/2310.08868" title="Download PDF">pdf</a>, <a href="/format/2310.08868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeCoNet: A Heterosexual Contact Network Growth Model for Human  Papillomavirus Disease Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Piraveenan%2C+M">Mahendra Piraveenan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08872" title="Abstract">arXiv:2310.08872</a> (replaced) [<a href="/pdf/2310.08872" title="Download PDF">pdf</a>, <a href="/format/2310.08872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R&amp;B: Region and Boundary Aware Zero-shot Grounded Text-to-image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jiayu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Henglei Lv</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under review. Project page: <a href="https://sagileo.github.io/Region-and-Boundary">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08915" title="Abstract">arXiv:2310.08915</a> (replaced) [<a href="/pdf/2310.08915" title="Download PDF">pdf</a>, <a href="/format/2310.08915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lirui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mingbao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yunyun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yiwu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xingjia Han</a>, 
<a href="/search/cs?searchtype=author&query=Tanner%2C+J">Jared Tanner</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08943" title="Abstract">arXiv:2310.08943</a> (replaced) [<a href="/pdf/2310.08943" title="Download PDF">pdf</a>, <a href="/format/2310.08943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-level Adaptive Contrastive Learning for Knowledge Internalization  in Dialogue Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenxu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lanrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangnan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+Q">Qirong Ho</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09053" title="Abstract">arXiv:2310.09053</a> (replaced) [<a href="/pdf/2310.09053" title="Download PDF">pdf</a>, <a href="/format/2310.09053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DATT: Deep Adaptive Trajectory Tracking for Quadrotor Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kevin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+R">Rwik Rana</a>, 
<a href="/search/cs?searchtype=author&query=Spitzer%2C+A">Alexander Spitzer</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guanya Shi</a>, 
<a href="/search/cs?searchtype=author&query=Boots%2C+B">Byron Boots</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09234" title="Abstract">arXiv:2310.09234</a> (replaced) [<a href="/pdf/2310.09234" title="Download PDF">pdf</a>, <a href="/format/2310.09234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClickPrompt: CTR Models are Strong Prompt Generators for Adapting  Language Models to CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Y">Yunjia Xi</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yanru Qu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xinyi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09430" title="Abstract">arXiv:2310.09430</a> (replaced) [<a href="/pdf/2310.09430" title="Download PDF">pdf</a>, <a href="/ps/2310.09430" title="Download PostScript">ps</a>, <a href="/format/2310.09430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Evaluation of Large Language Models on Out-of-Distribution  Logical Reasoning Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+Q">Qiming Bao</a>, 
<a href="/search/cs?searchtype=author&query=Gendron%2C+G">Gael Gendron</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+A+Y">Alex Yuxuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanjun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+N">Neset Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Witbrock%2C+M">Michael Witbrock</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamou Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for oral presentation at the LLM@IJCAI 2023 non-archival symposium
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09486" title="Abstract">arXiv:2310.09486</a> (replaced) [<a href="/pdf/2310.09486" title="Download PDF">pdf</a>, <a href="/format/2310.09486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirage: Model-Agnostic Graph Distillation for Graph Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Mridul Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Manchanda%2C+S">Sahil Manchanda</a>, 
<a href="/search/cs?searchtype=author&query=Kodamana%2C+H">Hariprasad Kodamana</a>, 
<a href="/search/cs?searchtype=author&query=Ranu%2C+S">Sayan Ranu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09520" title="Abstract">arXiv:2310.09520</a> (replaced) [<a href="/pdf/2310.09520" title="Download PDF">pdf</a>, <a href="/format/2310.09520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reward-Augmented Decoding: Efficient Controlled Text Generation With a  Unidirectional Reward Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Haikang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+C">Colin Raffel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09619" title="Abstract">arXiv:2310.09619</a> (replaced) [<a href="/pdf/2310.09619" title="Download PDF">pdf</a>, <a href="/format/2310.09619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Expression Tree Decoding Strategy for Mathematical Equation  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yongliang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Nong%2C+Q">Qingpeng Nong</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z+T+Y">Zeqi Tan Yanna Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weiming Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP-2023, camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09680" title="Abstract">arXiv:2310.09680</a> (replaced) [<a href="/pdf/2310.09680" title="Download PDF">pdf</a>, <a href="/format/2310.09680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Contextual Recognition In Automatic Speech Recognition Systems  By Semantic Lattice Rescoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sudarshan%2C+A">Ankitha Sudarshan</a>, 
<a href="/search/cs?searchtype=author&query=Samuel%2C+V">Vinay Samuel</a>, 
<a href="/search/cs?searchtype=author&query=Patwa%2C+P">Parth Patwa</a>, 
<a href="/search/cs?searchtype=author&query=Amara%2C+I">Ibtihel Amara</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2209.01250">arXiv:2209.01250</a>, <a href="/abs/2301.06735">arXiv:2301.06735</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09749" title="Abstract">arXiv:2310.09749</a> (replaced) [<a href="/pdf/2310.09749" title="Download PDF">pdf</a>, <a href="/format/2310.09749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Torch to Projector: Fundamental Tradeoff of Integrated Sensing and  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yifeng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+K">Kai Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weijie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yuanhao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures, submitted to IEEE BITS the Information Theory Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09759" title="Abstract">arXiv:2310.09759</a> (replaced) [<a href="/pdf/2310.09759" title="Download PDF">pdf</a>, <a href="/format/2310.09759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype-oriented Unsupervised Change Detection for Disaster Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+Y">Youngtack Oh</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minseok Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Doyi Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Junghoon Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4page, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09903" title="Abstract">arXiv:2310.09903</a> (replaced) [<a href="/pdf/2310.09903" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of feature selection performance for identification of best  effective technical indicators on stock market price prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Moodi%2C+F">Fatemeh Moodi</a>, 
<a href="/search/q-fin?searchtype=author&query=Jahangard-Rafsanjani%2C+A">Amir Jahangard-Rafsanjani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures,4 tables,45 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09909" title="Abstract">arXiv:2310.09909</a> (replaced) [<a href="/pdf/2310.09909" title="Download PDF">pdf</a>, <a href="/format/2310.09909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for  Multimodal Medical Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chaoyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiayu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qiaoyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weike Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weixiong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoman Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09970" title="Abstract">arXiv:2310.09970</a> (replaced) [<a href="/pdf/2310.09970" title="Download PDF">pdf</a>, <a href="/format/2310.09970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Estimation with Partially Accessible Information: An IMAT  Approach to LMS Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shamsi%2C+M">Mahdi Shamsi</a>, 
<a href="/search/eess?searchtype=author&query=Marvasti%2C+F">Farokh Marvasti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09986" title="Abstract">arXiv:2310.09986</a> (replaced) [<a href="/pdf/2310.09986" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Statistical Learning of Branch and Bound for Vehicle Routing  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naguib%2C+A">Andrew Naguib</a>, 
<a href="/search/cs?searchtype=author&query=Yousef%2C+W+A">Waleed A. Yousef</a>, 
<a href="/search/cs?searchtype=author&query=Traor%C3%A9%2C+I">Issa Traor&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Mamun%2C+M">Mohammad Mamun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10021" title="Abstract">arXiv:2310.10021</a> (replaced) [<a href="/pdf/2310.10021" title="Download PDF">pdf</a>, <a href="/format/2310.10021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrap Your Own Skills: Learning to Solve New Tasks with Large  Language Model Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jesse Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pertsch%2C+K">Karl Pertsch</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Minsuk Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shao-Hua Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J+J">Joseph J. Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023 (Oral); 24 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10046" title="Abstract">arXiv:2310.10046</a> (replaced) [<a href="/pdf/2310.10046" title="Download PDF">pdf</a>, <a href="/format/2310.10046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRANSOM: An Efficient Fault-Tolerant System for Training LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baodong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingping Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kangyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yongqiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tieyao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shigang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10123" title="Abstract">arXiv:2310.10123</a> (replaced) [<a href="/pdf/2310.10123" title="Download PDF">pdf</a>, <a href="/format/2310.10123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoDIR: Automatic All-in-One Image Restoration with Latent Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yitong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Tianfan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinwei Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10136" title="Abstract">arXiv:2310.10136</a> (replaced) [<a href="/pdf/2310.10136" title="Download PDF">pdf</a>, <a href="/format/2310.10136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mata, a Fast and Simple Finite Automata Library (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chocholat%C3%BD%2C+D">David Chocholat&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Fiedor%2C+T">Tom&#xe1;&#x161; Fiedor</a>, 
<a href="/search/cs?searchtype=author&query=Havlena%2C+V">Vojt&#x11b;ch Havlena</a>, 
<a href="/search/cs?searchtype=author&query=Hol%C3%ADk%2C+L">Luk&#xe1;&#x161; Hol&#xed;k</a>, 
<a href="/search/cs?searchtype=author&query=Hru%C5%A1ka%2C+M">Martin Hru&#x161;ka</a>, 
<a href="/search/cs?searchtype=author&query=Leng%C3%A1l%2C+O">Ond&#x159;ej Leng&#xe1;l</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%AD%C4%8D%2C+J">Juraj S&#xed;&#x10d;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10198" title="Abstract">arXiv:2310.10198</a> (replaced) [<a href="/pdf/2310.10198" title="Download PDF">pdf</a>, <a href="/format/2310.10198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoConVQ: Unified Physics-Based Motion Control via Scalable Discrete  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Heyuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhenhua Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ao%2C+T">Tenglong Ao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baoquan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Libin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://pku-mocca.github.io/MoConVQ-page/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10333" title="Abstract">arXiv:2310.10333</a> (replaced) [<a href="/pdf/2310.10333" title="Download PDF">pdf</a>, <a href="/format/2310.10333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NLP for Crypto-Asset Regulation: A Roadmap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Camassa%2C+C">Carolina Camassa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NLLP23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); General Finance (q-fin.GN)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10497" title="Abstract">arXiv:2310.10497</a> (replaced) [<a href="/pdf/2310.10497" title="Download PDF">pdf</a>, <a href="/format/2310.10497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LocSelect: Target Speaker Localization with an Auditory Selective  Hearing Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xinyuan Qian</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zexu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kainan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10505" title="Abstract">arXiv:2310.10505</a> (replaced) [<a href="/pdf/2310.10505" title="Download PDF">pdf</a>, <a href="/format/2310.10505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method  for Aligning Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziniu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yushun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruoyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhi-Quan Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10533" title="Abstract">arXiv:2310.10533</a> (replaced) [<a href="/pdf/2310.10533" title="Download PDF">pdf</a>, <a href="/format/2310.10533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label-efficient Segmentation via Affinity Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wentong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuqian Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Dongqi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS2023 Acceptance. Project Page:<a href="https://LiWentomng.github.io/apro/.">this https URL</a> Code: <a href="https://github.com/CircleRadon/APro">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10553" title="Abstract">arXiv:2310.10553</a> (replaced) [<a href="/pdf/2310.10553" title="Download PDF">pdf</a>, <a href="/format/2310.10553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TacticAI: an AI assistant for football tactics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Veli%C4%8Dkovi%C4%87%2C+P">Petar Veli&#x10d;kovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Hennes%2C+D">Daniel Hennes</a>, 
<a href="/search/cs?searchtype=author&query=Toma%C5%A1ev%2C+N">Nenad Toma&#x161;ev</a>, 
<a href="/search/cs?searchtype=author&query=Prince%2C+L">Laurel Prince</a>, 
<a href="/search/cs?searchtype=author&query=Kaisers%2C+M">Michael Kaisers</a>, 
<a href="/search/cs?searchtype=author&query=Bachrach%2C+Y">Yoram Bachrach</a>, 
<a href="/search/cs?searchtype=author&query=Elie%2C+R">Romuald Elie</a>, 
<a href="/search/cs?searchtype=author&query=Wenliang%2C+L+K">Li Kevin Wenliang</a>, 
<a href="/search/cs?searchtype=author&query=Piccinini%2C+F">Federico Piccinini</a>, 
<a href="/search/cs?searchtype=author&query=Spearman%2C+W">William Spearman</a>, 
<a href="/search/cs?searchtype=author&query=Graham%2C+I">Ian Graham</a>, 
<a href="/search/cs?searchtype=author&query=Connor%2C+J">Jerome Connor</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Recasens%2C+A">Adri&#xe0; Recasens</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M">Mina Khan</a>, 
<a href="/search/cs?searchtype=author&query=Beauguerlange%2C+N">Nathalie Beauguerlange</a>, 
<a href="/search/cs?searchtype=author&query=Sprechmann%2C+P">Pablo Sprechmann</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+P">Pol Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Heess%2C+N">Nicolas Heess</a>, 
<a href="/search/cs?searchtype=author&query=Bowling%2C+M">Michael Bowling</a>, 
<a href="/search/cs?searchtype=author&query=Hassabis%2C+D">Demis Hassabis</a>, 
<a href="/search/cs?searchtype=author&query=Tuyls%2C+K">Karl Tuyls</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10649" title="Abstract">arXiv:2310.10649</a> (replaced) [<a href="/pdf/2310.10649" title="Download PDF">pdf</a>, <a href="/format/2310.10649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Computational Framework for Solving Wasserstein Lagrangian Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neklyudov%2C+K">Kirill Neklyudov</a>, 
<a href="/search/cs?searchtype=author&query=Brekelmans%2C+R">Rob Brekelmans</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+A">Alexander Tong</a>, 
<a href="/search/cs?searchtype=author&query=Atanackovic%2C+L">Lazar Atanackovic</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Makhzani%2C+A">Alireza Makhzani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item348">Cross-lists</a></li>
<li><a href="#item397">Replacements</a></li>
</ul>
<small>[ total of 680 entries:  <b>1-680</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2310">2310</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
