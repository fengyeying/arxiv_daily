<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu 28 Sep 23  to  Fri 29 Sep 23, announced Mon,  2 Oct 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item370">Cross-lists</a></li>
<li><a href="#item412">Replacements</a></li>
</ul>
<small>[ total of 639 entries:  <b>1-639</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon,  2 Oct 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16673" title="Abstract">arXiv:2309.16673</a> [<a href="/pdf/2309.16673" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Digital Twin Technology for Adaptive Traffic Signal Control:  Improving Signalized Intersection Performance and User Satisfaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+S">Sagar Dasgupta</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M">Mizanur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=D.%2C+P">Ph.D.</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+S">Steven Jones</a>, 
<a href="/search/cs?searchtype=author&query=D%2C+P">Ph.D</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In this study, a digital twin (DT) technology based Adaptive Traffic Signal
Control (ATSC) framework is presented for improving signalized intersection
performance and user satisfaction. Specifically, real-time vehicle trajectory
data, future traffic demand prediction and parallel simulation strategy are
considered to develop two DT-based ATSC algorithms, namely DT1 (Digital Twin 1)
and DT2 (Digital Twin 2). DT1 uses the delay experienced by each vehicle from
all approaches connected to the subject intersection, while DT2 uses the delay
of each vehicle that occurred in all the approaches connected to the subject
intersection as well as immediate adjacent intersection. To demonstrate the
effectiveness of these algorithms, the DT-based ATSC algorithms are evaluated
with varying traffic demands at intersection, and individual user level.
Evaluation results show that both DT1 and DT2 performs significantly better
compared to the density-based baseline algorithm in terms of control delay
reductions ranging from 1% to 52% for low traffic demands. DT1 outperforms
baseline algorithm for moderate traffic demands, achieving reduction in control
delay ranging from 3% to 19%, while the performance of DT2 declines with
increasing demand. For high traffic demands, DT1 achieved control delay
reduction ranging from 1% to 45% and DT2 achieved 8% to 36% compared to the
baseline algorithm. Moreover, DT1 and DT2 effectively distribute the delay per
vehicle among all the vehicles, which approach towards intersection, compared
to the baseline ATSC algorithm. This helps to improve user satisfaction by
reducing prolonged delays at a traffic signal, specifically, for moderate and
high traffic demands.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16677" title="Abstract">arXiv:2309.16677</a> [<a href="/pdf/2309.16677" title="Download PDF">pdf</a>, <a href="/ps/2309.16677" title="Download PostScript">ps</a>, <a href="/format/2309.16677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanical Artifacts in Optical Projection Tomography: Classification  and Automatic Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jonathan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thanh-An Pham</a>, 
<a href="/search/cs?searchtype=author&query=Marelli%2C+F">Francois Marelli</a>, 
<a href="/search/cs?searchtype=author&query=Unser%2C+M">Michael Unser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in ISCS2023. arXiv admin note: substantial text overlap with <a href="/abs/2210.03513">arXiv:2210.03513</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Optical projection tomography (OPT) is a powerful tool for biomedical
studies. It achieves 3D visualization of mesoscopic biological samples with
high spatial resolution using conventional tomographic-reconstruction
algorithms. However, various artifacts degrade the quality of the reconstructed
images due to experimental imperfections in the OPT instruments. While many
efforts have been made to characterize and correct for these artifacts, they
focus on one specific type of artifacts. This work has two contributions.
First, we systematically document a catalog of mechanical artifacts based on a
3D description of the imaging system that uses a set of angular and
translational parameters. Then, we introduce a calibration algorithm that
recovers the unknown system parameters fed into the final 3D iterative
reconstruction algorithm for a distortion-free volumetric image. Simulations
with beads data and experimental results on a fluorescent textile fiber confirm
that our algorithm successfully removes miscalibration artifacts in the
reconstruction.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16680" title="Abstract">arXiv:2309.16680</a> [<a href="/pdf/2309.16680" title="Download PDF">pdf</a>, <a href="/format/2309.16680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Persistent Scheduling in NR Sidelink Mode 2: MAC Packet Reception  Ratio Model and Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Liu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Sumit Roy</a>, 
<a href="/search/cs?searchtype=author&query=Brady%2C+C">Collin Brady</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. 13 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">5G NR Sidelink (SL) has demonstrated the promising capability for
infrastructure-less cellular coverage. Understanding the fundamentals of the NR
SL channel access mechanism, Semi-Persistent Scheduling (SPS), which is
specified by the 3rd Generation Partnership Project (3GPP), is a necessity to
enhance the NR SL Packet Reception Ratio (PRR). However, most existing works
fail to account for the new SPS features introduced in NR SL, which might be
out-of-date for comprehensively describing the NR SL PRR. The existing models
ignore the relationships between SPS parameters and therefore do not provide
sufficient insights into the PRR of SPS. This work proposes a novel SPS PRR
model incorporating MAC collisions based on new features in NR SL. We extend
our model by loosening several simplifying assumptions made in our initial
modeling. The extended models illustrate how the PRR is affected by various SPS
parameters. The computed results are validated via simulations using the
network simulator (ns-3), which provides important guidelines for future NR SL
enhancement work.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16681" title="Abstract">arXiv:2309.16681</a> [<a href="/pdf/2309.16681" title="Download PDF">pdf</a>, <a href="/format/2309.16681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alternate Learning based Sparse Semantic Communications for Visual  Transmission
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+S">Siyu Tong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaoxue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Kun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Honggang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Semantic communication (SemCom) demonstrates strong superiority over
conventional bit-level accurate transmission, by only attempting to recover the
essential semantic information of data. In this paper, in order to tackle the
non-differentiability of channels, we propose an alternate learning based
SemCom system for visual transmission, named SparseSBC. Specially, SparseSBC
leverages two separate Deep Neural Network (DNN)-based models at the
transmitter and receiver, respectively, and learns the encoding and decoding in
an alternate manner, rather than the joint optimization in existing literature,
so as to solving the non-differentiability in the channel. In particular, a
``self-critic" training scheme is leveraged for stable training. Moreover, the
DNN-based transmitter generates a sparse set of bits in deduced ``semantic
bases", by further incorporating a binary quantization module on the basis of
minimal detrimental effect to the semantic accuracy. Extensive simulation
results validate that SparseSBC shows efficient and effective transmission
performance under various channel conditions, and outperforms typical SemCom
solutions.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16682" title="Abstract">arXiv:2309.16682</a> [<a href="/pdf/2309.16682" title="Download PDF">pdf</a>, <a href="/ps/2309.16682" title="Download PostScript">ps</a>, <a href="/format/2309.16682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VMT19937: A SIMD-Friendly Pseudo Random Number Generator based on  Mersenne Twister 19937
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cannizzo%2C+F">Fabio Cannizzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS); Performance (cs.PF)

</div>
<p class="mathjax">Many simulation applications require the generation of long sequences of
pseudo-random numbers. Linear recurrences modulo 2 are commonly used as the
fundamental building block for constructing pseudo-random number generators
with extended periods and excellent statistical properties. These generators
consist of a lengthy binary state vector that evolves iteratively through
linear transformations. One widely accepted pseudo-random generator in this
category is the Mersenne twister 19937 (MT19937), proposed by Matsumoto and
Nishimura, which has been implemented in numerous software libraries and
numerical packages. The MT19937's popularity stems from its favorable
distribution properties and the simplicity and speed of its algorithm. The
linear transformation responsible for evolving the binary state vector can be
expressed as a concise set of elementary bit manipulations. However, this
transformation does not fully utilize the potential for parallelization through
SIMD instructions available on modern hardware, limiting further speed
enhancements. This paper introduces a new SIMD-friendly random number
generator, which maintains the same statistical properties and period as the
MT19937. It combines the random streams of multiple MT19937 instances with
state vectors de-phased via jump-ahead transformations, then polls each
instance in a round-robin fashion. By evolving their vector states
simultaneously, the new generator achieves perfect vectorization, fully
leveraging on SIMD hardware capabilities. Comprehensive test results
demonstrate that the throughput of the new generator scales approximately
linearly with the width of the SIMD registers used. This provides significant
speed improvements, especially on modern CPUs equipped with larger SIMD
registers, and allows for efficient generation of random numbers for various
simulation applications.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16683" title="Abstract">arXiv:2309.16683</a> [<a href="/pdf/2309.16683" title="Download PDF">pdf</a>, <a href="/format/2309.16683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling the Solo12 Quadruped Robot with Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aractingi%2C+M">Michel Aractingi</a> (LAAS-GEPETTO), 
<a href="/search/cs?searchtype=author&query=L%C3%A9ziart%2C+P">Pierre-Alexandre L&#xe9;ziart</a> (LAAS-GEPETTO), 
<a href="/search/cs?searchtype=author&query=Flayols%2C+T">Thomas Flayols</a> (LAAS-GEPETTO), 
<a href="/search/cs?searchtype=author&query=Perez%2C+J">Julien Perez</a>, 
<a href="/search/cs?searchtype=author&query=Silander%2C+T">Tomi Silander</a>, 
<a href="/search/cs?searchtype=author&query=Sou%C3%A8res%2C+P">Philippe Sou&#xe8;res</a> (LAAS-GEPETTO)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Scientific Reports, 2023, 13 (11945), pp.12
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quadruped robots require robust and general locomotion skills to exploit
their mobility potential in complex and challenging environments. In this work,
we present the first implementation of a robust end-to-end learning-based
controller on the Solo12 quadruped. Our method is based on deep reinforcement
learning of joint impedance references. The resulting control policies follow a
commanded velocity reference while being efficient in its energy consumption,
robust and easy to deploy. We detail the learning procedure and method for
transfer on the real robot. In our experiments, we show that the Solo12 robot
is a suitable open-source platform for research combining learning and control
because of the easiness in transferring and deploying learned controllers.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16686" title="Abstract">arXiv:2309.16686</a> [<a href="/pdf/2309.16686" title="Download PDF">pdf</a>, <a href="/format/2309.16686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ecoBLE: A Low-Computation Energy Consumption Prediction Framework for  Bluetooth Low Energy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schuhmacher%2C+L">Luisa Schuhmacher</a>, 
<a href="/search/cs?searchtype=author&query=Pollin%2C+S">Sofie Pollin</a>, 
<a href="/search/cs?searchtype=author&query=Sallouha%2C+H">Hazem Sallouha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in proceedings of the 2023 International Conference on Embedded Wireless Systems and Networks (EWSN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Bluetooth Low Energy (BLE) is a de-facto technology for Internet of Things
(IoT) applications, promising very low energy consumption. However, this low
energy consumption accounts only for the radio part, and it overlooks the
energy consumption of other hardware and software components. Monitoring and
predicting the energy consumption of IoT nodes after deployment can
substantially aid in ensuring low energy consumption, calculating the remaining
battery lifetime, predicting needed energy for energy-harvesting nodes, and
detecting anomalies. In this paper, we introduce a Long Short-Term Memory
Projection (LSTMP)-based BLE energy consumption prediction framework together
with a dataset for a healthcare application scenario where BLE is widely
adopted. Unlike radio-focused theoretical energy models, our framework provides
a comprehensive energy consumption prediction, considering all components of
the IoT node, including the radio, sensor as well as microcontroller unit
(MCU). Our measurement-based results show that the proposed framework predicts
the energy consumption of different BLE nodes with a Mean Absolute Percentage
Error (MAPE) of up to 12%, giving comparable accuracy to state-of-the-art
energy consumption prediction with a five times smaller prediction model size.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16687" title="Abstract">arXiv:2309.16687</a> [<a href="/pdf/2309.16687" title="Download PDF">pdf</a>, <a href="/ps/2309.16687" title="Download PostScript">ps</a>, <a href="/format/2309.16687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Duality Principle and Biologically Plausible Learning: Connecting the  Representer Theorem and Hebbian Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahroun%2C+Y">Yanis Bahroun</a>, 
<a href="/search/cs?searchtype=author&query=Chklovskii%2C+D+B">Dmitri B. Chklovskii</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+A+M">Anirvan M. Sengupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">A normative approach called Similarity Matching was recently introduced for
deriving and understanding the algorithmic basis of neural computation focused
on unsupervised problems. It involves deriving algorithms from computational
objectives and evaluating their compatibility with anatomical and physiological
observations. In particular, it introduces neural architectures by considering
dual alternatives instead of primal formulations of popular models such as PCA.
However, its connection to the Representer theorem remains unexplored. In this
work, we propose to use teachings from this approach to explore supervised
learning algorithms and clarify the notion of Hebbian learning. We examine
regularized supervised learning and elucidate the emergence of neural
architecture and additive versus multiplicative update rules. In this work, we
focus not on developing new algorithms but on showing that the Representer
theorem offers the perfect lens to study biologically plausible learning
algorithms. We argue that many past and current advancements in the field rely
on some form of dual formulation to introduce biological plausibility. In
short, as long as a dual formulation exists, it is possible to derive
biologically plausible algorithms. Our work sheds light on the pivotal role of
the Representer theorem in advancing our comprehension of neural computation.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16689" title="Abstract">arXiv:2309.16689</a> [<a href="/pdf/2309.16689" title="Download PDF">pdf</a>, <a href="/format/2309.16689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New 1-mg Fast Unimorph SMA-Based Actuator for Microrobotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trygstad%2C+C+K">Conor K. Trygstad</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+X">Xuan-Truc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Arancibia%2C+N+O">Nestor O. Perez-Arancibia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a new unimorph actuator for micro-robotics, which is driven by
thin shape-memory alloy (SMA) wires. Using a passive-capillary-alignment
technique and existing SMA-microsystem fabrication methods, we developed an
actuator that is 7 mm long, has a volume of 0.45 mm^3, weighs 0.96 mg, and can
achieve operation frequencies of up to 40 Hz as well as lift 155 times its own
weight. To demonstrate the capabilities of the proposed actuator, we created an
8-mg crawler, the MiniBug, and a bioinspired 56-mg controllable
water-surface-tension crawler, the WaterStrider. The MiniBug is 8.5 mm long,
can locomote at speeds as high as 0.76 BL/s (body-lengths per second), and is
the lightest fully-functional crawling microrobot of its type ever created. The
WaterStrider is 22 mm long, and can locomote at speeds of up to 0.28 BL/s as
well as execute turning maneuvers at angular rates on the order of 0.144 rad/s.
The WaterStrider is the lightest controllable SMA-driven water-surface-tension
crawler developed to date.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16692" title="Abstract">arXiv:2309.16692</a> [<a href="/pdf/2309.16692" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbiotic PBFT Consensus: Cognitive Backscatter Communications-enabled  Wireless PBFT Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haoxiang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qianqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongfang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Gang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shizhong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Global Communications Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Wireless blockchain networks have played an important role in many network
scenarios, among which wireless Practical Byzantine Fault Tolerance (PBFT)
consensus is regarded as one of the most important consensus mechanisms. It
enables nodes in wireless networks to reach consistency without any trusted
entity. However, due to the instability of wireless communication links, the
reliability of the PBFT consensus will be seriously affected. Meanwhile, it is
difficult for nodes in wireless scenarios to obtain a timely energy supply. The
high-energy-consumption blockchain functions will quickly consume the power of
nodes, thus, affecting consensus performance. Fortunately, the symbiotic radio
(SR) system enabled by cognitive backscatter communications can provide a
solution to the above problems. In SR, the secondary transmitter (STx)
transmits messages by modulating its information over the radio frequency (RF)
signal of the primary transmitter (PTx) with extremely low energy consumption,
and the STx can provide multipath gain to the PTx in return. In our paper, we
propose the symbiotic PBFT (S-PBFT) consensus benefited from the mutualistic
transmission in SR, which can increase the consensus security by 54.82%, and
save energy consumption by about 10%.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16694" title="Abstract">arXiv:2309.16694</a> [<a href="/pdf/2309.16694" title="Download PDF">pdf</a>, <a href="/format/2309.16694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Direct k-Way Hypergraph Partitioning Algorithm for Optimizing the  Steiner Tree Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heuer%2C+T">Tobias Heuer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Minimizing wire-lengths is one of the most important objectives in circuit
design. The process involves initially placing the logical units (cells) of a
circuit onto a physical layout, and subsequently routing the wires to connect
the cells. Hypergraph partitioning (HGP) has been long used as a placement
strategy in this process. However, it has been replaced by other methods due to
the limitation that common HGP objective funtions only optimize wire-lengths
implicitly. In this work, we present a novel HGP formulation that maps a
hypergraph $H$, representing a logical circuit, onto a routing layout
represented by a weighted graph $G$. The objective is to minimize the total
length of all wires induced by the hyperedges of $H$ on $G$. To capture
wire-lengths, we compute minimal Steiner trees - a metric commonly used in
routing algorithms. For this formulation, we present the first direct $k$-way
multilevel mapping algorithm that incorporates techniques used by the
highest-quality partitioning algorithms. We contribute a greedy mapping
algorithm to compute an initial solution and three refinement algorithms to
improve the initial: Two move-based local search heuristics (based on label
propagation and the FM algorithm) and a refinement algorithm based on max-flow
min-cut computations. Our experiments demonstrate that our new algorithm
achieves an improvement in the Steiner tree metric by 7% (median) on VLSI
instances when compared to the best performing partitioning algorithm that
optimizes the mapping in a postprocessing step. Although computing Steiner
trees is an NP-hard problem, we achieve this improvement with only a 2-3 times
slowdown in partitioning time compared to optimizing the connectivity metric.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16697" title="Abstract">arXiv:2309.16697</a> [<a href="/pdf/2309.16697" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inappropriate Benefits and Identification of ChatGPT Misuse in  Programming Tests: A Controlled Experiment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toba%2C+H">Hapnes Toba</a>, 
<a href="/search/cs?searchtype=author&query=Karnalim%2C+O">Oscar Karnalim</a>, 
<a href="/search/cs?searchtype=author&query=Johan%2C+M+C">Meliana Christianti Johan</a>, 
<a href="/search/cs?searchtype=author&query=Tada%2C+T">Terutoshi Tada</a>, 
<a href="/search/cs?searchtype=author&query=Djajalaksana%2C+Y+M">Yenni Merlin Djajalaksana</a>, 
<a href="/search/cs?searchtype=author&query=Vivaldy%2C+T">Tristan Vivaldy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 26th International Conference on Interactive Collaborative Learning (ICL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">While ChatGPT may help students to learn to program, it can be misused to do
plagiarism, a breach of academic integrity. Students can ask ChatGPT to
complete a programming task, generating a solution from other people's work
without proper acknowledgment of the source(s). To help address this new kind
of plagiarism, we performed a controlled experiment measuring the inappropriate
benefits of using ChatGPT in terms of completion time and programming
performance. We also reported how to manually identify programs aided with
ChatGPT (via student behavior while using ChatGPT) and student perspective of
ChatGPT (via a survey). Seventeen students participated in the experiment. They
were asked to complete two programming tests. They were divided into two groups
per the test: one group should complete the test without help while the other
group should complete it with ChatGPT. Our study shows that students with
ChatGPT complete programming tests two times faster than those without ChatGPT,
though their programming performance is comparable. The generated code is
highly efficient and uses complex data structures like lists and dictionaries.
Based on the survey results, ChatGPT is recommended to be used as an assistant
to complete programming tasks and other general assignments. ChatGPT will be
beneficial as a reference as other search engines do. Logical and critical
thinking are needed to validate the result presented by ChatGPT.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16698" title="Abstract">arXiv:2309.16698</a> [<a href="/pdf/2309.16698" title="Download PDF">pdf</a>, <a href="/format/2309.16698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Guidance Navigation and Control of the VISORS  Formation-Flying Mission
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guffanti%2C+T">Tommaso Guffanti</a>, 
<a href="/search/cs?searchtype=author&query=Bell%2C+T">Toby Bell</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+S+Y+W">Samuel Y. W. Low</a>, 
<a href="/search/cs?searchtype=author&query=Murray-Cooper%2C+M">Mason Murray-Cooper</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amico%2C+S">Simone D&#x27;Amico</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in 2023 AAS/AIAA Astrodynamics Specialist Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Virtual Super-resolution Optics with Reconfigurable Swarms (VISORS) is a
distributed telescope mission for high-resolution imaging of the Sun using two
6U CubeSats flying in formation in a Sun-synchronous low-Earth orbit. An optics
spacecraft carries a photon sieve acting as a high-resolution lens in the
extreme ultraviolet spectrum, while the image passing through the sieve is
focused on a detector spacecraft. This paper presents the newly conceived
design of the on-board guidance, navigation and control (GNC) system, which is
highly autonomous, robust, passively safe, and validated under realistic
mission simulations. The primary objective of the GNC system is to establish a
passively safe and high-precision formation alignment at 40-meter separation,
with sub-centimeter relative navigation and position control accuracy, over
repeated observations of 10-second duration. Science mission success rates are
assessed via Monte-Carlo analyses under realistically modelled uncertainties
stemming from sensing errors, maneuver errors, unmodelled dynamics, and
erroneous knowledge of internal spacecraft components. Precise real-time
relative navigation is achieved by carrier phase differential GPS with integer
ambiguity resolution. Precise control over short baselines is achieved via
closed-loop optimization-based stochastic model predictive control with
centimeter-level accuracy. Control at far range and during approach is achieved
by closed-form impulsive control with meter-level accuracy. Passive safety is
enforced throughout the mission to mitigate collision risks even under critical
subsystem failure. Beyond VISORS, this work also realizes the crucial insight
that the described GNC architecture is generalizable to other distributed space
missions where accuracy and fault-tolerant safety are key requirements, such as
rendezvous, proximity operations, and swarming missions.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16699" title="Abstract">arXiv:2309.16699</a> [<a href="/pdf/2309.16699" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circular-Line Trajectory Tracking Controller for Mobile Robot using  Multi-Pixy2 Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngo%2C+X+Q">Xuan Quang Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T+D">Tri Duc Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Huy Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V+D">Van Dong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Duong%2C+V+T">Van Tu Duong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+T">Tan Tien Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 12 figures, the 2023 International Symposium on Electrical and Electronics Engineering, Ho Chi Minh, Viet Nam, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This study suggests a novel tracking method that employs three Pixy2 sensors
to identify the desired line trajectories instead of traditional perceiving
means. Firstly, the kinematic model of the mobile robot is derived from the
information gathered by three Pixy2 sensors. Secondly, the sliding mode
controller is implemented to regulate the tracking error. Finally, simulation
results are analyzed to show the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16700" title="Abstract">arXiv:2309.16700</a> [<a href="/pdf/2309.16700" title="Download PDF">pdf</a>, <a href="/format/2309.16700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Framework and Model Analysis on Bengali Document Layout Analysis  Dataset: BaDLAD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+K+R">Kazi Reyazul Hasan</a> (1), 
<a href="/search/cs?searchtype=author&query=Musarrat%2C+M">Mubasshira Musarrat</a> (1), 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Sadif Ahmed</a> (1), 
<a href="/search/cs?searchtype=author&query=Raj%2C+S">Shahriar Raj</a> (1) ((1) Bangladesh University of Engineering and Technology)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 6 figures, uses IEEEtran.cls
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study focuses on understanding Bengali Document Layouts using advanced
computer programs: Detectron2, YOLOv8, and SAM. We looked at lots of different
Bengali documents in our study. Detectron2 is great at finding and separating
different parts of documents, like text boxes and paragraphs. YOLOv8 is good at
figuring out different tables and pictures. We also tried SAM, which helps us
understand tricky layouts. We tested these programs to see how well they work.
By comparing their accuracy and speed, we learned which one is good for
different types of documents. Our research helps make sense of complex layouts
in Bengali documents and can be useful for other languages too.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16701" title="Abstract">arXiv:2309.16701</a> [<a href="/pdf/2309.16701" title="Download PDF">pdf</a>, <a href="/format/2309.16701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVMR: Evaluating Natural Language Video Localization Bias over Multiple  Reliable Videos Pool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nakyeong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Seunghyun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Joongbo Shin</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+K">Kyomin Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">With the explosion of multimedia content in recent years, natural language
video localization, which focuses on detecting video moment that matches a
given natural language query, has become a critical problem. However, none of
the previous research explores localizing a moment from a large corpus where
multiple positive and negative videos exist. In this paper, we propose an MVMR
(Massive Videos Moment Retrieval) task, which aims to localize video frames
from a massive set of videos given a text query. For this task, we suggest
methods for constructing datasets by employing similarity filtering on the
existing video localization datasets and introduce three MVMR datasets.
Specifically, we employ embedding-based text similarity matching and
video-language grounding techniques to calculate the relevance score between a
target query and videos to define positive and negative sets. For the proposed
MVMR task, we further develop a strong model, Reliable Mutual Matching Network
(RMMN), which employs a contrastive learning scheme that selectively filters
the reliable and informative negatives leading the model more robust on the
MVMR task. Experimental results on the introduced datasets reveal that existing
NLVL models are easily distracted by negative video frames, whereas our model
shows significant performance.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16702" title="Abstract">arXiv:2309.16702</a> [<a href="/pdf/2309.16702" title="Download PDF">pdf</a>, <a href="/format/2309.16702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction and Interpretation of Vehicle Trajectories in the Graph  Spectral Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neumeier%2C+M">Marion Neumeier</a>, 
<a href="/search/cs?searchtype=author&query=Dorn%2C+S">Sebastian Dorn</a>, 
<a href="/search/cs?searchtype=author&query=Botsch%2C+M">Michael Botsch</a>, 
<a href="/search/cs?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a conference paper for IEEE ITSC 2023, Bilbao, Spain
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This work provides a comprehensive analysis and interpretation of the graph
spectral representation of traffic scenarios. Based on a spatio-temporal
vehicle interaction graph, an observed traffic scenario can be transformed into
the graph spectral domain by means of the multidimensional Graph Fourier
Transformation. Since these spectral scenario representations have shown to
successfully incorporate the complex and interactive nature of traffic
scenarios, the beneficial feature representation is employed for the purpose of
predicting vehicle trajectories. This work introduces GFTNNv2, a deep learning
network predicting vehicle trajectories in the graph spectral domain.
Evaluation of the GFTNNv2 on the publicly available datasets highD and NGSIM
shows a performance gain of up to 25% in comparison to state-of-the-art
prediction approaches.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16703" title="Abstract">arXiv:2309.16703</a> [<a href="/pdf/2309.16703" title="Download PDF">pdf</a>, <a href="/ps/2309.16703" title="Download PostScript">ps</a>, <a href="/format/2309.16703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incompatibilities Between Current Practices in Statistical Data Analysis  and Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Snoke%2C+J">Joshua Snoke</a>, 
<a href="/search/cs?searchtype=author&query=Bowen%2C+C+M">Claire McKay Bowen</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A+R">Aaron R. Williams</a>, 
<a href="/search/cs?searchtype=author&query=Barrientos%2C+A+F">Andr&#xe9;s F. Barrientos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, no figures or tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The authors discuss their experience applying differential privacy with a
complex data set with the goal of enabling standard approaches to statistical
data analysis. They highlight lessons learned and roadblocks encountered,
distilling them into incompatibilities between current practices in statistical
data analysis and differential privacy that go beyond issues which can be
solved with a noisy measurements file. The authors discuss how overcoming these
incompatibilities require compromise and a change in either our approach to
statistical data analysis or differential privacy that should be addressed
head-on.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16705" title="Abstract">arXiv:2309.16705</a> [<a href="/pdf/2309.16705" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Imagery: Unleashing Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noever%2C+D">David Noever</a>, 
<a href="/search/cs?searchtype=author&query=Noever%2C+S+E+M">Samantha Elizabeth Miller Noever</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">In a challenge-response study, we subjected Google Bard to 64 visual
challenges designed to probe multimodal Large Language Models (LLMs). The
challenges spanned diverse categories, including "Visual Situational
Reasoning," "Visual Text Reasoning," and "Next Scene Prediction," among others,
to discern Bard's competence in melding visual and linguistic analyses. Our
findings indicate that Bard tends to rely on making educated guesses about
visuals, especially when determining cues from images. Unlike other models like
GPT4, Bard does not appear to rely on optical character recognition libraries
like Tesseract but recognizes text in complex images like deep learning models
such as Google Lens and Visual API. Significantly Bard can solve CAPTCHAs
visually that ChatGPT fails to understand, recommending Tesseract solutions.
Moreover, while the Bard model proposes solutions based on visual input, it
cannot recreate or modify the original visual objects to support its
conclusions. Bard fails to redraw ASCII art that the text can describe or
capture a simple Tic Tac Toe grid it claims to analyze for the next moves. This
study provides experimental insights into the current capacities and areas for
improvement in multimodal LLMs.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16706" title="Abstract">arXiv:2309.16706</a> [<a href="/pdf/2309.16706" title="Download PDF">pdf</a>, <a href="/format/2309.16706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIR: Threats of Adversarial Attacks on Deep Learning-Based Information  Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinyin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jie Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shilian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+L">Linhui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haibin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weiguo Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+K">Keqiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoniu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">A wireless communications system usually consists of a transmitter which
transmits the information and a receiver which recovers the original
information from the received distorted signal. Deep learning (DL) has been
used to improve the performance of the receiver in complicated channel
environments and state-of-the-art (SOTA) performance has been achieved.
However, its robustness has not been investigated. In order to evaluate the
robustness of DL-based information recovery models under adversarial
circumstances, we investigate adversarial attacks on the SOTA DL-based
information recovery model, i.e., DeepReceiver. We formulate the problem as an
optimization problem with power and peak-to-average power ratio (PAPR)
constraints. We design different adversarial attack methods according to the
adversary's knowledge of DeepReceiver's model and/or testing samples. Extensive
experiments show that the DeepReceiver is vulnerable to the designed attack
methods in all of the considered scenarios. Even in the scenario of both model
and test sample restricted, the adversary can attack the DeepReceiver and
increase its bit error rate (BER) above 10%. It can also be found that the
DeepReceiver is vulnerable to adversarial perturbations even with very low
power and limited PAPR. These results suggest that defense measures should be
taken to enhance the robustness of DeepReceiver.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16707" title="Abstract">arXiv:2309.16707</a> [<a href="/pdf/2309.16707" title="Download PDF">pdf</a>, <a href="/format/2309.16707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Taxonomy for Blockchain-based Decentralized Physical Infrastructure  Networks (DePIN)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ballandies%2C+M+C">Mark C. Ballandies</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Law%2C+A+C+C">Andrew Chung Chee Law</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J+C">Joshua C. Yang</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6sken%2C+C">Christophe G&#xf6;sken</a>, 
<a href="/search/cs?searchtype=author&query=Andrew%2C+M">Michael Andrew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computers and Society (cs.CY); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">As digitalization and technological advancements continue to shape the
infrastructure landscape, the emergence of blockchain-based decentralized
physical infrastructure networks (DePINs) has gained prominence. However, a
systematic categorization of DePIN components and their interrelationships is
still missing. To address this gap, we conduct a literature review and analysis
of existing frameworks and derived a taxonomy of DePIN systems from a
conceptual architecture. Our taxonomy encompasses three key dimensions:
distributed ledger technology, cryptoeconomic design and physicial
infrastructure network. Within each dimension, we identify and define relevant
components and attributes, establishing a clear hierarchical structure.
Moreover, we illustrate the relationships and dependencies among the identified
components, highlighting the interplay between governance models, hardware
architectures, networking protocols, token mechanisms, and distributed ledger
technologies. This taxonomy provides a foundation for understanding and
classifying diverse DePIN networks, serving as a basis for future research and
facilitating knowledge exchange, fostering collaboration and standardization
within the emerging field of decentralized physical infrastructure networks.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16708" title="Abstract">arXiv:2309.16708</a> [<a href="/pdf/2309.16708" title="Download PDF">pdf</a>, <a href="/format/2309.16708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Cadastral Boundary Detection of Very High Resolution Images  Using Mask R-CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anaraki%2C+N+R">Neda Rahimpour Anaraki</a>, 
<a href="/search/cs?searchtype=author&query=Azadbakht%2C+A">Alireza Azadbakht</a>, 
<a href="/search/cs?searchtype=author&query=Tahmasbi%2C+M">Maryam Tahmasbi</a>, 
<a href="/search/cs?searchtype=author&query=Farahani%2C+H">Hadi Farahani</a>, 
<a href="/search/cs?searchtype=author&query=Kheradpisheh%2C+S+R">Saeed Reza Kheradpisheh</a>, 
<a href="/search/cs?searchtype=author&query=Javaheri%2C+A">Alireza Javaheri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, there has been a high demand for accelerating and improving the
detection of automatic cadastral mapping. As this problem is in its starting
point, there are many methods of computer vision and deep learning that have
not been considered yet. In this paper, we focus on deep learning and provide
three geometric post-processing methods that improve the quality of the work.
Our framework includes two parts, each of which consists of a few phases. Our
solution to this problem uses instance segmentation. In the first part, we use
Mask R-CNN with the backbone of pre-trained ResNet-50 on the ImageNet dataset.
In the second phase, we apply three geometric post-processing methods to the
output of the first part to get better overall output. Here, we also use
computational geometry to introduce a new method for simplifying lines which we
call it pocket-based simplification algorithm. For evaluating the quality of
our solution, we use popular formulas in this field which are recall, precision
and F-score. The highest recall we gain is 95 percent which also maintains high
Precision of 72 percent. This resulted in an F-score of 82 percent.
Implementing instance segmentation using Mask R-CNN with some geometric
post-processes to its output gives us promising results for this field. Also,
results show that pocket-based simplification algorithms work better for
simplifying lines than Douglas-Puecker algorithm.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16710" title="Abstract">arXiv:2309.16710</a> [<a href="/pdf/2309.16710" title="Download PDF">pdf</a>, <a href="/format/2309.16710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Lipschitz: Certified Robustness Against Resolvable Semantic  Transformations via Transformation-Dependent Randomized Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korzh%2C+D">Dmitrii Korzh</a>, 
<a href="/search/cs?searchtype=author&query=Pautov%2C+M">Mikhail Pautov</a>, 
<a href="/search/cs?searchtype=author&query=Tsymboi%2C+O">Olga Tsymboi</a>, 
<a href="/search/cs?searchtype=author&query=Oseledets%2C+I">Ivan Oseledets</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Randomized smoothing is the state-of-the-art approach to construct image
classifiers that are provably robust against additive adversarial perturbations
of bounded magnitude. However, it is more complicated to construct reasonable
certificates against semantic transformation (e.g., image blurring,
translation, gamma correction) and their compositions. In this work, we propose
\emph{General Lipschitz (GL),} a new framework to certify neural networks
against composable resolvable semantic perturbations. Within the framework, we
analyze transformation-dependent Lipschitz-continuity of smoothed classifiers
w.r.t. transformation parameters and derive corresponding robustness
certificates. Our method performs comparably to state-of-the-art approaches on
the ImageNet dataset.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16712" title="Abstract">arXiv:2309.16712</a> [<a href="/pdf/2309.16712" title="Download PDF">pdf</a>, <a href="/format/2309.16712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Participation Incentive and Network Pricing Design for Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ningning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianwei Huang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Computer Communications
  (INFOCOM), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Federated learning protects users' data privacy through sharing users' local
model parameters (instead of raw data) with a server. However, when massive
users train a large machine learning model through federated learning, the
dynamically varying and often heavy communication overhead can put significant
pressure on the network operator. The operator may choose to dynamically change
the network prices in response, which will eventually affect the payoffs of the
server and users. This paper considers the under-explored yet important issue
of the joint design of participation incentives (for encouraging users'
contribution to federated learning) and network pricing (for managing network
resources). Due to heterogeneous users' private information and
multi-dimensional decisions, the optimization problems in Stage I of
multi-stage games are non-convex. Nevertheless, we are able to analytically
derive the corresponding optimal contract and pricing mechanism through proper
transformations of constraints, variables, and functions, under both vertical
and horizontal interaction structures of the participants. We show that the
vertical structure is better than the horizontal one, as it avoids the
interests misalignment between the server and the network operator. Numerical
results based on real-world datasets show that our proposed mechanisms decrease
server's cost by up to 24.87% comparing with the state-of-the-art benchmarks.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16713" title="Abstract">arXiv:2309.16713</a> [<a href="/pdf/2309.16713" title="Download PDF">pdf</a>, <a href="/format/2309.16713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UAV-assisted Semantic Communication with Hybrid Action Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+P">Peiyuan Si</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kwok-Yan Lam</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qing Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we aim to explore the use of uplink semantic communications
with the assistance of UAV in order to improve data collection effiicency for
metaverse users in remote areas. To reduce the time for uplink data collection
while balancing the trade-off between reconstruction quality and computational
energy cost, we propose a hybrid action reinforcement learning (RL) framework
to make decisions on semantic model scale, channel allocation, transmission
power, and UAV trajectory. The variables are classified into discrete type and
continuous type, which are optimized by two different RL agents to generate the
combined action. Simulation results indicate that the proposed hybrid action
reinforcement learning framework can effectively improve the efficiency of
uplink semantic data collection under different parameter settings and
outperforms the benchmark scenarios.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16714" title="Abstract">arXiv:2309.16714</a> [<a href="/pdf/2309.16714" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Security Strategies for Addressing Potential Vulnerabilities in 6G  Technologies Deployable in Healthcare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uwaoma%2C+C">Chinazunwa Uwaoma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Researchers are now focusing on 6G as a new network technology that will
bring significant gains over the previous generations while many sectors are
still implementing the 5G network in their business processes and operations.
Meanwhile, key technological fields that will be influenced by 6G networks have
been identified. These include distributed artificial intelligence, intelligent
radio, real-time intelligent edge computing, and 3D intercoms. Additionally,
each area and potential application of 6G is supported by relevant emerging
technologies. Nevertheless, these 6G technology and applications have
significant security vulnerabilities that must be addressed before the complete
adoption of 6G networks. The healthcare is one of the sectors that are
benefiting from the great features introduced in the 5G networks that enhance
digital communications and data protection; that notwithstanding, there are
still security flaws in 5G technologies that can be transferred to the 6G
networks if not properly addressed. This paper highlights the key areas of 6G
networks that would provide grand support for the development of healthcare
systems. It also identifies certain vulnerabilities in the previous cellular
networks that are transferable to 6G networks, and suggests security strategies
including zero trust initiatives that could be implemented to address the
security concerns.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16715" title="Abstract">arXiv:2309.16715</a> [<a href="/pdf/2309.16715" title="Download PDF">pdf</a>, <a href="/format/2309.16715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MV-DeepSDF: Implicit Modeling with Multi-Sweep Point Clouds for 3D  Vehicle Reconstruction in Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kelly Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guile Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingbing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+J">Jinjun Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reconstructing 3D vehicles from noisy and sparse partial point clouds is of
great significance to autonomous driving. Most existing 3D reconstruction
methods cannot be directly applied to this problem because they are elaborately
designed to deal with dense inputs with trivial noise. In this work, we propose
a novel framework, dubbed MV-DeepSDF, which estimates the optimal Signed
Distance Function (SDF) shape representation from multi-sweep point clouds to
reconstruct vehicles in the wild. Although there have been some SDF-based
implicit modeling methods, they only focus on single-view-based reconstruction,
resulting in low fidelity. In contrast, we first analyze multi-sweep
consistency and complementarity in the latent feature space and propose to
transform the implicit space shape estimation problem into an element-to-set
feature extraction problem. Then, we devise a new architecture to extract
individual element-level representations and aggregate them to generate a
set-level predicted latent code. This set-level latent code is an expression of
the optimal 3D shape in the implicit space, and can be subsequently decoded to
a continuous SDF of the vehicle. In this way, our approach learns consistent
and complementary information among multi-sweeps for 3D vehicle reconstruction.
We conduct thorough experiments on two real-world autonomous driving datasets
(Waymo and KITTI) to demonstrate the superiority of our approach over
state-of-the-art alternative methods both qualitatively and quantitatively.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16716" title="Abstract">arXiv:2309.16716</a> [<a href="/pdf/2309.16716" title="Download PDF">pdf</a>, <a href="/format/2309.16716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Safe Autonomy in Hybrid Traffic: Detecting Unpredictable  Abnormal Behaviors of Human Drivers via Information Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Lili Su</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Songyang Han</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dongjin Song</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+F">Fei Miao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to ACM Transactions on Cyber-Physical Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Hybrid traffic which involves both autonomous and human-driven vehicles would
be the norm of the autonomous vehicles practice for a while. On the one hand,
unlike autonomous vehicles, human-driven vehicles could exhibit sudden abnormal
behaviors such as unpredictably switching to dangerous driving modes, putting
its neighboring vehicles under risks; such undesired mode switching could arise
from numbers of human driver factors, including fatigue, drunkenness,
distraction, aggressiveness, etc. On the other hand, modern vehicle-to-vehicle
communication technologies enable the autonomous vehicles to efficiently and
reliably share the scarce run-time information with each other. In this paper,
we propose, to the best of our knowledge, the first efficient algorithm that
can (1) significantly improve trajectory prediction by effectively fusing the
run-time information shared by surrounding autonomous vehicles, and can (2)
accurately and quickly detect abnormal human driving mode switches or abnormal
driving behavior with formal assurance without hurting human drivers privacy.
To validate our proposed algorithm, we first evaluate our proposed trajectory
predictor on NGSIM and Argoverse datasets and show that our proposed predictor
outperforms the baseline methods. Then through extensive experiments on SUMO
simulator, we show that our proposed algorithm has great detection performance
in both highway and urban traffic. The best performance achieves detection rate
of 97.3%, average detection delay of 1.2s, and 0 false alarm.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16718" title="Abstract">arXiv:2309.16718</a> [<a href="/pdf/2309.16718" title="Download PDF">pdf</a>, <a href="/format/2309.16718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Real-World Quadrupedal Locomotion Benchmark for Offline Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donglin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Online reinforcement learning (RL) methods are often data-inefficient or
unreliable, making them difficult to train on real robotic hardware, especially
quadruped robots. Learning robotic tasks from pre-collected data is a promising
direction. Meanwhile, agile and stable legged robotic locomotion remains an
open question in their general form. Offline reinforcement learning (ORL) has
the potential to make breakthroughs in this challenging field, but its current
bottleneck lies in the lack of diverse datasets for challenging realistic
tasks. To facilitate the development of ORL, we benchmarked 11 ORL algorithms
in the realistic quadrupedal locomotion dataset. Such dataset is collected by
the classic model predictive control (MPC) method, rather than the model-free
online RL method commonly used by previous benchmarks. Extensive experimental
results show that the best-performing ORL algorithms can achieve competitive
performance compared with the model-free RL, and even surpass it in some tasks.
However, there is still a gap between the learning-based methods and MPC,
especially in terms of stability and rapid adaptation. Our proposed benchmark
will serve as a development platform for testing and evaluating the performance
of ORL algorithms in real-world legged locomotion tasks.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16720" title="Abstract">arXiv:2309.16720</a> [<a href="/pdf/2309.16720" title="Download PDF">pdf</a>, <a href="/ps/2309.16720" title="Download PostScript">ps</a>, <a href="/format/2309.16720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy Efficient Foot-Shape Design for Bipedal Walkers on Granular  Terrain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xunjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingang Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 3rd Modeling, Estimation and Control Conference (MECC 2023), Lake Tahoe, NV, Oct 2-5 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">It is important to understand how bipedal walkers balance and walk
effectively on granular materials, such as sand and loose dirt, etc. This paper
first presents a computational approach to obtain the motion and energy
analysis of bipedal walkers on granular terrains and then discusses an
optimization method for the robot foot-shape contour design for energy
efficiently walking. We first present the foot-terrain interaction
characteristics of the intrusion process using the resistive force theory that
provides comprehensive force laws. Using human gait profiles, we compute and
compare the ground reaction forces and the external work for walking gaits with
various foot shapes on granular terrains. A multi-objective optimization
problem is finally formulated for the foot contour design considering energy
saving and walking efficiency. It is interesting to find out a non-convex foot
shape gives the best performance in term of energy and locomotion efficiency on
hard granular terrains. The presented work provides an enabling tool to further
understand and design efficient and effective bipedal walkers on granular
terrains.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16721" title="Abstract">arXiv:2309.16721</a> [<a href="/pdf/2309.16721" title="Download PDF">pdf</a>, <a href="/format/2309.16721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven  Robotic Lab
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xiaokai Qin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingda Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yangguan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Z">Zhehong Ai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jing Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The integration of robots in chemical experiments has enhanced experimental
efficiency, but lacking the human intelligence to comprehend literature, they
seldom provide assistance in experimental design. Therefore, achieving
full-process autonomy from experiment design to validation in self-driven
laboratories (SDL) remains a challenge. The introduction of Generative
Pre-trained Transformers (GPT), particularly GPT-4, into robotic
experimentation offers a solution. We introduce GPT-Lab, a paradigm that
employs GPT models to give robots human-like intelligence. With our robotic
experimentation platform, GPT-Lab mines literature for materials and methods
and validates findings through high-throughput synthesis. As a demonstration,
GPT-Lab analyzed 500 articles, identified 18 potential reagents, and
successfully produced an accurate humidity colorimetric sensor with a root mean
square error (RMSE) of 2.68%. This showcases the rapid materials discovery and
validation potential of our system.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16729" title="Abstract">arXiv:2309.16729</a> [<a href="/pdf/2309.16729" title="Download PDF">pdf</a>, <a href="/format/2309.16729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimPINNs: Simulation-Driven Physics-Informed Neural Networks for  Enhanced Performance in Nonlinear Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Besnard%2C+S">Sidney Besnard</a>, 
<a href="/search/cs?searchtype=author&query=Jurie%2C+F">Fr&#xe9;d&#xe9;ric Jurie</a> (UNICAEN), 
<a href="/search/cs?searchtype=author&query=Fadili%2C+J+M">Jalal M. Fadili</a> (NU, ENSICAEN, GREYC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces a novel approach to solve inverse problems by
leveraging deep learning techniques. The objective is to infer unknown
parameters that govern a physical system based on observed data. We focus on
scenarios where the underlying forward model demonstrates pronounced nonlinear
behaviour, and where the dimensionality of the unknown parameter space is
substantially smaller than that of the observations. Our proposed method builds
upon physics-informed neural networks (PINNs) trained with a hybrid loss
function that combines observed data with simulated data generated by a known
(approximate) physical model. Experimental results on an orbit restitution
problem demonstrate that our approach surpasses the performance of standard
PINNs, providing improved accuracy and robustness.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16730" title="Abstract">arXiv:2309.16730</a> [<a href="/pdf/2309.16730" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable machine learning-based prediction model for diabetic  nephropathy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jing-Mei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jun-Tang Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+G">Guo-Wei Zong</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhong-Ze Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+L">Lang Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The aim of this study is to analyze the effect of serum metabolites on
diabetic nephropathy (DN) and predict the prevalence of DN through a machine
learning approach. The dataset consists of 548 patients from April 2018 to
April 2019 in Second Affiliated Hospital of Dalian Medical University (SAHDMU).
We select the optimal 38 features through a Least absolute shrinkage and
selection operator (LASSO) regression model and a 10-fold cross-validation. We
compare four machine learning algorithms, including eXtreme Gradient Boosting
(XGB), random forest, decision tree and logistic regression, by AUC-ROC curves,
decision curves, calibration curves. We quantify feature importance and
interaction effects in the optimal predictive model by Shapley Additive
exPlanations (SHAP) method. The XGB model has the best performance to screen
for DN with the highest AUC value of 0.966. The XGB model also gains more
clinical net benefits than others and the fitting degree is better. In
addition, there are significant interactions between serum metabolites and
duration of diabetes. We develop a predictive model by XGB algorithm to screen
for DN. C2, C5DC, Tyr, Ser, Met, C24, C4DC, and Cys have great contribution in
the model, and can possibly be biomarkers for DN.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16733" title="Abstract">arXiv:2309.16733</a> [<a href="/pdf/2309.16733" title="Download PDF">pdf</a>, <a href="/format/2309.16733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilience of Deep Learning applications: a systematic survey of  analysis and hardening techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bolchini%2C+C">Cristiana Bolchini</a>, 
<a href="/search/cs?searchtype=author&query=Cassano%2C+L">Luca Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Miele%2C+A">Antonio Miele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ACM Computing Surveys on May 11, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine Learning (ML) is currently being exploited in numerous applications
being one of the most effective Artificial Intelligence (AI) technologies, used
in diverse fields, such as vision, autonomous systems, and alike. The trend
motivated a significant amount of contributions to the analysis and design of
ML applications against faults affecting the underlying hardware. The authors
investigate the existing body of knowledge on Deep Learning (among ML
techniques) resilience against hardware faults systematically through a
thoughtful review in which the strengths and weaknesses of this literature
stream are presented clearly and then future avenues of research are set out.
The review is based on 163 scientific articles published between January 2019
and March 2023. The authors adopt a classifying framework to interpret and
highlight research similarities and peculiarities, based on several parameters,
starting from the main scope of the work, the adopted fault and error models,
to their reproducibility. This framework allows for a comparison of the
different solutions and the identification of possible synergies. Furthermore,
suggestions concerning the future direction of research are proposed in the
form of open challenges to be addressed.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16736" title="Abstract">arXiv:2309.16736</a> [<a href="/pdf/2309.16736" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognizance of Post-COVID-19 Multi-Organ Dysfunction through Machine  Learning Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castro%2C+H+J">Hector J. Castro</a>, 
<a href="/search/cs?searchtype=author&query=Yousif%2C+M+G">Maitham G. Yousif</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Other Quantitative Biology (q-bio.OT)

</div>
<p class="mathjax">In the year 2022, a total of 466 patients from various cities across Iraq
were included in this study. This research paper focuses on the application of
machine learning techniques to analyse and predict multi-organ dysfunction in
individuals experiencing Post-COVID-19 Syndrome, commonly known as Long COVID.
Post-COVID-19 Syndrome presents a wide array of persistent symptoms affecting
various organ systems, posing a significant challenge to healthcare. Leveraging
the power of artificial intelligence, this study aims to enhance early
detection and management of this complex condition. The paper outlines the
importance of data collection and preprocessing, feature selection and
engineering, model development and validation, and ethical considerations in
conducting research in this field. By improving our understanding of
Post-COVID-19 Syndrome through machine learning, healthcare providers can
identify at-risk individuals and offer timely interventions, potentially
improving patient outcomes and quality of life. Further research is essential
to refine models, validate their clinical utility, and explore treatment
options for Long COVID. Keywords: Post-COVID-19 Syndrome, Machine Learning,
Multi-Organ Dysfunction, Healthcare, Artificial Intelligence.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16737" title="Abstract">arXiv:2309.16737</a> [<a href="/pdf/2309.16737" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Team Fuses Fewer Breakthrough Ideas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiling Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lingfei Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">The past half-century has seen a dramatic increase in the scale and
complexity of scientific research, to which researchers have responded by
lengthening their education and training, specializing more narrowly, and
working in teams. A widely held view is that by permitting more specialization
and increasing combinatorial novelty, the rise of team collaboration will
accelerate scientific innovation. Yet, recent work has challenged this view and
shown that solo researchers and small teams consistently disrupt science and
technology with fresh ideas and opportunities, while larger teams tend to
refine existing ones. This paper has been cited by many follow-up studies on
knowledge production and collective innovation due to its novelty and
significance in correcting the zeitgeist of our time that views collaboration
as an inevitable trend. Yet, very few studies re-examine this paper's main
finding-the advantage in the inventive capacity of small teams over large
teams, using alternative metrics. Against this background, it is essential to
further validate this finding through alternative innovation measures,
especially given the debates surrounding the nature and validity of the
Disruption index, the main metrics the authors used to quantify and compare the
inventive capacity of small and large teams. To do so, we measure disruptive
innovation with a variable identifying papers that proposed new scientific
concepts and patents introducing new technology codes. We confirm that large
teams develop and small teams disrupt both science and technology.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16738" title="Abstract">arXiv:2309.16738</a> [<a href="/pdf/2309.16738" title="Download PDF">pdf</a>, <a href="/format/2309.16738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ELIP: Efficient Language-Image Pre-training with Fewer Vision Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yangyang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+Y">Yongkang Wong</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning a versatile language-image model is computationally prohibitive
under a limited computing budget. This paper delves into the efficient
language-image pre-training, an area that has received relatively little
attention despite its importance in reducing computational cost and footprint.
To that end, we propose a vision token pruning and merging method, ie ELIP, to
remove less influential tokens based on the supervision of language outputs.
Our method is designed with several strengths, such as being
computation-efficient, memory-efficient, and trainable-parameter-free, and is
distinguished from previous vision-only token pruning approaches by its
alignment with task objectives. We implement this method in a progressively
pruning manner using several sequential blocks. To evaluate its generalization
performance, we apply ELIP to three commonly used language-image pre-training
models and utilize public image-caption pairs with 4M images for pre-training.
Our experiments demonstrate that with the removal of ~30$\%$ vision tokens
across 12 ViT layers, ELIP maintains significantly comparable performance with
baselines ($\sim$0.32 accuracy drop on average) over various downstream tasks
including cross-modal retrieval, VQA, image captioning, etc. In addition, the
spared GPU resources by our ELIP allow us to scale up with larger batch sizes,
thereby accelerating model pre-training and even sometimes enhancing downstream
model performance. Our code will be released at
https://github.com/guoyang9/ELIP.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16739" title="Abstract">arXiv:2309.16739</a> [<a href="/pdf/2309.16739" title="Download PDF">pdf</a>, <a href="/format/2309.16739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing Large Language Models to the 6G Edge: Vision, Challenges, and  Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+G">Guanqiao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaibin Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs), which have shown remarkable capabilities, are
revolutionizing AI development and potentially shaping our future. However,
given their multimodality, the status quo cloud-based deployment faces some
critical challenges: 1) long response time; 2) high bandwidth costs; and 3) the
violation of data privacy. 6G mobile edge computing (MEC) systems may resolve
these pressing issues. In this article, we explore the potential of deploying
LLMs at the 6G edge. We start by introducing killer applications powered by
multimodal LLMs, including robotics and healthcare, to highlight the need for
deploying LLMs in the vicinity of end users. Then, we identify the critical
challenges for LLM deployment at the edge and envision the 6G MEC architecture
for LLMs. Furthermore, we delve into two design aspects, i.e., edge training
and edge inference for LLMs. In both aspects, considering the inherent resource
limitations at the edge, we discuss various cutting-edge techniques, including
split learning/inference, parameter-efficient fine-tuning, quantization, and
parameter-sharing inference, to facilitate the efficient deployment of LLMs.
This article serves as a position paper for thoroughly identifying the
motivation, challenges, and pathway for empowering LLMs at the 6G edge.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16741" title="Abstract">arXiv:2309.16741</a> [<a href="/pdf/2309.16741" title="Download PDF">pdf</a>, <a href="/format/2309.16741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Financial Time-Series Retrieval Through Latent Space  Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bamford%2C+T">Tom Bamford</a>, 
<a href="/search/cs?searchtype=author&query=Coletta%2C+A">Andrea Coletta</a>, 
<a href="/search/cs?searchtype=author&query=Fons%2C+E">Elizabeth Fons</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+S">Sriram Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>, 
<a href="/search/cs?searchtype=author&query=Balch%2C+T">Tucker Balch</a>, 
<a href="/search/cs?searchtype=author&query=Veloso%2C+M">Manuela Veloso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICAIF 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Financial firms commonly process and store billions of time-series data,
generated continuously and at a high frequency. To support efficient data
storage and retrieval, specialized time-series databases and systems have
emerged. These databases support indexing and querying of time-series by a
constrained Structured Query Language(SQL)-like format to enable queries like
"Stocks with monthly price returns greater than 5%", and expressed in rigid
formats. However, such queries do not capture the intrinsic complexity of high
dimensional time-series data, which can often be better described by images or
language (e.g., "A stock in low volatility regime"). Moreover, the required
storage, computational time, and retrieval complexity to search in the
time-series space are often non-trivial. In this paper, we propose and
demonstrate a framework to store multi-modal data for financial time-series in
a lower-dimensional latent space using deep encoders, such that the latent
space projections capture not only the time series trends but also other
desirable information or properties of the financial time-series data (such as
price volatility). Moreover, our approach allows user-friendly query
interfaces, enabling natural language text or sketches of time-series, for
which we have developed intuitive interfaces. We demonstrate the advantages of
our method in terms of computational efficiency and accuracy on real historical
data as well as synthetic data, and highlight the utility of latent-space
projections in the storage and retrieval of financial time-series data with
intuitive query modalities.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16742" title="Abstract">arXiv:2309.16742</a> [<a href="/pdf/2309.16742" title="Download PDF">pdf</a>, <a href="/format/2309.16742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervised Learning Models for Early Detection of Albuminuria Risk in  Type-2 Diabetes Mellitus Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muharram%2C+A+P">Arief Purnama Muharram</a>, 
<a href="/search/cs?searchtype=author&query=Tahapary%2C+D+L">Dicky Levenus Tahapary</a>, 
<a href="/search/cs?searchtype=author&query=Lestari%2C+Y+D">Yeni Dwi Lestari</a>, 
<a href="/search/cs?searchtype=author&query=Sarayar%2C+R">Randy Sarayar</a>, 
<a href="/search/cs?searchtype=author&query=Dirjayanto%2C+V+J">Valerie Josephine Dirjayanto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 10th International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Diabetes, especially T2DM, continues to be a significant health problem. One
of the major concerns associated with diabetes is the development of its
complications. Diabetic nephropathy, one of the chronic complication of
diabetes, adversely affects the kidneys, leading to kidney damage. Diagnosing
diabetic nephropathy involves considering various criteria, one of which is the
presence of a pathologically significant quantity of albumin in urine, known as
albuminuria. Thus, early prediction of albuminuria in diabetic patients holds
the potential for timely preventive measures. This study aimed to develop a
supervised learning model to predict the risk of developing albuminuria in T2DM
patients. The selected supervised learning algorithms included Na\"ive Bayes,
Support Vector Machine (SVM), decision tree, random forest, AdaBoost, XGBoost,
and Multi-Layer Perceptron (MLP). Our private dataset, comprising 184 entries
of diabetes complications risk factors, was used to train the algorithms. It
consisted of 10 attributes as features and 1 attribute as the target
(albuminuria). Upon conducting the experiments, the MLP demonstrated superior
performance compared to the other algorithms. It achieved accuracy and f1-score
values as high as 0.74 and 0.75, respectively, making it suitable for screening
purposes in predicting albuminuria in T2DM. Nonetheless, further studies are
warranted to enhance the model's performance.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16743" title="Abstract">arXiv:2309.16743</a> [<a href="/pdf/2309.16743" title="Download PDF">pdf</a>, <a href="/format/2309.16743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Throughput Training of Deep Surrogates from Large Ensemble Runs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+L">Lucas Meyer</a> (DATAMOVE, SINCLAIR AI Lab, EDF R&amp;D), 
<a href="/search/cs?searchtype=author&query=Schouler%2C+M">Marc Schouler</a> (DATAMOVE ), 
<a href="/search/cs?searchtype=author&query=Caulk%2C+R+A">Robert Alexander Caulk</a> (DATAMOVE ), 
<a href="/search/cs?searchtype=author&query=Rib%C3%A9s%2C+A">Alejandro Rib&#xe9;s</a> (EDF R&amp;D), 
<a href="/search/cs?searchtype=author&query=Raffin%2C+B">Bruno Raffin</a> (DATAMOVE )
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The International Conference for High Performance Computing, Networking, Storage, and Analysis, Nov 2023, Denver, CO, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Recent years have seen a surge in deep learning approaches to accelerate
numerical solvers, which provide faithful but computationally intensive
simulations of the physical world. These deep surrogates are generally trained
in a supervised manner from limited amounts of data slowly generated by the
same solver they intend to accelerate. We propose an open-source framework that
enables the online training of these models from a large ensemble run of
simulations. It leverages multiple levels of parallelism to generate rich
datasets. The framework avoids I/O bottlenecks and storage issues by directly
streaming the generated data. A training reservoir mitigates the inherent bias
of streaming while maximizing GPU throughput. Experiment on training a fully
connected network as a surrogate for the heat equation shows the proposed
approach enables training on 8TB of data in 2 hours with an accuracy improved
by 47% and a batch throughput multiplied by 13 compared to a traditional
offline procedure.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16744" title="Abstract">arXiv:2309.16744</a> [<a href="/pdf/2309.16744" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Long-term Renal Impairment in Post-COVID-19 Patients with  Machine Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yousif%2C+M+G">Maitham G. Yousif</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+H+J">Hector J. Castro</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+J">John Martin</a>, 
<a href="/search/cs?searchtype=author&query=Albaqer%2C+H+A">Hayder A. Albaqer</a>, 
<a href="/search/cs?searchtype=author&query=Al-Amran%2C+F+G">Fadhil G. Al-Amran</a>, 
<a href="/search/cs?searchtype=author&query=Shubber%2C+H+W">Habeeb W. Shubber</a>, 
<a href="/search/cs?searchtype=author&query=Rawaf%2C+S">Salman Rawaf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Other Quantitative Biology (q-bio.OT)

</div>
<p class="mathjax">The COVID-19 pandemic has had far-reaching implications for global public
health. As we continue to grapple with its consequences, it becomes
increasingly clear that post-COVID-19 complications are a significant concern.
Among these complications, renal impairment has garnered particular attention
due to its potential long-term health impacts. This study, conducted with a
cohort of 821 post-COVID-19 patients from diverse regions of Iraq across the
years 2021, 2022, and 2023, endeavors to predict the risk of long-term renal
impairment using advanced machine learning algorithms. Our findings have the
potential to revolutionize post-COVID-19 patient care by enabling early
identification and intervention for those at risk of renal impairment,
ultimately improving clinical outcomes. This research encompasses comprehensive
data collection and preprocessing, feature selection, and the development of
predictive models using various machine learning algorithms. The study's
objectives are to assess the incidence of long-term renal impairment in
post-COVID-19 patients, identify associated risk factors, create predictive
models, and evaluate their accuracy. We anticipate that our machine learning
models, drawing from a rich dataset, will provide valuable insights into the
risk of renal impairment, ultimately enhancing patient care and quality of
life. In conclusion, the research presented herein offers a critical
contribution to the field of post-COVID-19 care. By harnessing the power of
machine learning, we aim to predict long-term renal impairment risk accurately.
These predictions have the potential to inform healthcare professionals,
enabling them to take proactive measures and provide targeted interventions for
post-COVID-19 patients at risk of renal complications, thus minimizing the
impact of this serious health concern.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16745" title="Abstract">arXiv:2309.16745</a> [<a href="/pdf/2309.16745" title="Download PDF">pdf</a>, <a href="/ps/2309.16745" title="Download PostScript">ps</a>, <a href="/format/2309.16745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Training of One Class Classification-SVMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yowetu%2C+I+A">Isaac Amornortey Yowetu</a>, 
<a href="/search/cs?searchtype=author&query=Frempong%2C+N+K">Nana Kena Frempong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study examines the use of a highly effective training method to conduct
one-class classification. The existence of both positive and negative examples
in the training data is necessary to develop an effective classifier in common
binary classification scenarios. Unfortunately, this criteria is not met in
many domains. Here, there is just one class of examples. Classification
algorithms that learn from solely positive input have been created to deal with
this setting. In this paper, an effective algorithm for dual soft-margin
one-class SVM training is presented. Our approach makes use of the Augmented
Lagrangian (AL-FPGM), a variant of the Fast Projected Gradient Method. The FPGM
requires only first derivatives, which for the dual soft margin OCC-SVM means
computing mainly a matrix-vector product. Therefore, AL-FPGM, being
computationally inexpensive, may complement existing quadratic programming
solvers for training large SVMs. We extensively validate our approach over
real-world datasets and demonstrate that our strategy obtains statistically
significant results.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16746" title="Abstract">arXiv:2309.16746</a> [<a href="/pdf/2309.16746" title="Download PDF">pdf</a>, <a href="/format/2309.16746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Gaussian process representation of vector fields over arbitrary  latent manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peach%2C+R+L">Robert L. Peach</a>, 
<a href="/search/cs?searchtype=author&query=Vinao-Carl%2C+M">Matteo Vinao-Carl</a>, 
<a href="/search/cs?searchtype=author&query=Grossman%2C+N">Nir Grossman</a>, 
<a href="/search/cs?searchtype=author&query=David%2C+M">Michael David</a>, 
<a href="/search/cs?searchtype=author&query=Mallas%2C+E">Emma Mallas</a>, 
<a href="/search/cs?searchtype=author&query=Sharp%2C+D">David Sharp</a>, 
<a href="/search/cs?searchtype=author&query=Malhotra%2C+P+A">Paresh A. Malhotra</a>, 
<a href="/search/cs?searchtype=author&query=Vandergheynst%2C+P">Pierre Vandergheynst</a>, 
<a href="/search/cs?searchtype=author&query=Gosztolai%2C+A">Adam Gosztolai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Mathematical Software (cs.MS); Data Analysis, Statistics and Probability (physics.data-an); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)

</div>
<p class="mathjax">Gaussian processes (GPs) are popular nonparametric statistical models for
learning unknown functions and quantifying the spatiotemporal uncertainty in
data. Recent works have extended GPs to model scalar and vector quantities
distributed over non-Euclidean domains, including smooth manifolds appearing in
numerous fields such as computer vision, dynamical systems, and neuroscience.
However, these approaches assume that the manifold underlying the data is
known, limiting their practical utility. We introduce RVGP, a generalisation of
GPs for learning vector signals over latent Riemannian manifolds. Our method
uses positional encoding with eigenfunctions of the connection Laplacian,
associated with the tangent bundle, readily derived from common graph-based
approximation of data. We demonstrate that RVGP possesses global regularity
over the manifold, which allows it to super-resolve and inpaint vector fields
while preserving singularities. Furthermore, we use RVGP to reconstruct
high-density neural dynamics derived from low-density EEG recordings in healthy
individuals and Alzheimer's patients. We show that vector field singularities
are important disease markers and that their reconstruction leads to a
comparable classification accuracy of disease states to high-density
recordings. Thus, our method overcomes a significant practical limitation in
experimental and clinical applications.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16747" title="Abstract">arXiv:2309.16747</a> [<a href="/pdf/2309.16747" title="Download PDF">pdf</a>, <a href="/format/2309.16747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Diverse Data for Global Disaster Prediction: A Multimodal  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gengyin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Huaiyang Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As climate change intensifies, the urgency for accurate global-scale disaster
predictions grows. This research presents a novel multimodal disaster
prediction framework, combining weather statistics, satellite imagery, and
textual insights. We particularly focus on "flood" and "landslide" predictions,
given their ties to meteorological and topographical factors. The model is
meticulously crafted based on the available data and we also implement
strategies to address class imbalance. While our findings suggest that
integrating multiple data sources can bolster model performance, the extent of
enhancement differs based on the specific nature of each disaster and their
unique underlying causes.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16748" title="Abstract">arXiv:2309.16748</a> [<a href="/pdf/2309.16748" title="Download PDF">pdf</a>, <a href="/format/2309.16748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering environments with XRM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pezeshki%2C+M">Mohammad Pezeshki</a>, 
<a href="/search/cs?searchtype=author&query=Bouchacourt%2C+D">Diane Bouchacourt</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+M">Mark Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Ballas%2C+N">Nicolas Ballas</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+P">Pascal Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Paz%2C+D">David Lopez-Paz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Successful out-of-distribution generalization requires environment
annotations. Unfortunately, these are resource-intensive to obtain, and their
relevance to model performance is limited by the expectations and perceptual
biases of human annotators. Therefore, to enable robust AI systems across
applications, we must develop algorithms to automatically discover environments
inducing broad generalization. Current proposals, which divide examples based
on their training error, suffer from one fundamental problem. These methods add
hyper-parameters and early-stopping criteria that are impossible to tune
without a validation set with human-annotated environments, the very
information subject to discovery. In this paper, we propose
Cross-Risk-Minimization (XRM) to address this issue. XRM trains two twin
networks, each learning from one random half of the training data, while
imitating confident held-out mistakes made by its sibling. XRM provides a
recipe for hyper-parameter tuning, does not require early-stopping, and can
discover environments for all training and validation data. Domain
generalization algorithms built on top of XRM environments achieve oracle
worst-group-accuracy, solving a long-standing problem in out-of-distribution
generalization.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16750" title="Abstract">arXiv:2309.16750</a> [<a href="/pdf/2309.16750" title="Download PDF">pdf</a>, <a href="/format/2309.16750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory in Plain Sight: A Survey of the Uncanny Resemblances between  Diffusion Models and Associative Memories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoover%2C+B">Benjamin Hoover</a>, 
<a href="/search/cs?searchtype=author&query=Strobelt%2C+H">Hendrik Strobelt</a>, 
<a href="/search/cs?searchtype=author&query=Krotov%2C+D">Dmitry Krotov</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Kira%2C+Z">Zsolt Kira</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+D+H">Duen Horng Chau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Diffusion Models (DMs) have recently set state-of-the-art on many generation
benchmarks. However, there are myriad ways to describe them mathematically,
which makes it difficult to develop a simple understanding of how they work. In
this survey, we provide a concise overview of DMs from the perspective of
dynamical systems and Ordinary Differential Equations (ODEs) which exposes a
mathematical connection to the highly related yet often overlooked class of
energy-based models, called Associative Memories (AMs). Energy-based AMs are a
theoretical framework that behave much like denoising DMs, but they enable us
to directly compute a Lyapunov energy function on which we can perform gradient
descent to denoise data. We then summarize the 40 year history of energy-based
AMs, beginning with the original Hopfield Network, and discuss new research
directions for AMs and DMs that are revealed by characterizing the extent of
their similarities and differences
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16768" title="Abstract">arXiv:2309.16768</a> [<a href="/pdf/2309.16768" title="Download PDF">pdf</a>, <a href="/format/2309.16768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Encountered-Type Haptic Display via Tracking Calibrated Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chenxi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In the past decades, a variety of haptic devices have been developed to
facilitate high-fidelity human-computer interaction (HCI) in virtual reality
(VR). In particular, passive haptic feedback can create a compelling sensation
based on real objects spatially overlapping with their virtual counterparts.
However, these approaches require pre-deployment efforts, hindering their
democratizing use in practice. We propose the Tracking Calibrated Robot (TCR),
a novel and general haptic approach to free developers from deployment efforts,
which can be potentially deployed in any scenario. Specifically, we augment the
VR with a collaborative robot that renders haptic contact in the real world
while the user touches a virtual object in the virtual world. The distance
between the user's finger and the robot end-effector is controlled over time.
The distance starts to smoothly reduce to zero when the user intends to touch
the virtual object. A mock user study tested users' perception of three virtual
objects, and the result shows that TCR is effective in terms of conveying
discriminative shape information.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16770" title="Abstract">arXiv:2309.16770</a> [<a href="/pdf/2309.16770" title="Download PDF">pdf</a>, <a href="/format/2309.16770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Persona-Coded Poly-Encoder: Persona-Guided Multi-Stream Conversational  Sentence Scoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Symons%2C+C">Christopher Symons</a>, 
<a href="/search/cs?searchtype=author&query=Vatsavai%2C+R+R">Ranga Raju Vatsavai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 35th IEEE International Conference on Tools with Artificial Intelligence (ICTAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in machine learning and deep learning have led to the
widespread use of Conversational AI in many practical applications. However, it
is still very challenging to leverage auxiliary information that can provide
conversational context or personalized tuning to improve the quality of
conversations. For example, there has only been limited research on using an
individuals persona information to improve conversation quality, and even
state-of-the-art conversational AI techniques are unable to effectively
leverage signals from heterogeneous sources of auxiliary data, such as
multi-modal interaction data, demographics, SDOH data, etc. In this paper, we
present a novel Persona-Coded Poly-Encoder method that leverages persona
information in a multi-stream encoding scheme to improve the quality of
response generation for conversations. To show the efficacy of the proposed
method, we evaluate our method on two different persona-based conversational
datasets, and compared against two state-of-the-art methods. Our experimental
results and analysis demonstrate that our method can improve conversation
quality over the baseline method Poly-Encoder by 3.32% and 2.94% in terms of
BLEU score and HR@1, respectively. More significantly, our method offers a path
to better utilization of multi-modal data in conversational tasks. Lastly, our
study outlines several challenges and future research directions for advancing
personalized conversational AI technology.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16772" title="Abstract">arXiv:2309.16772</a> [<a href="/pdf/2309.16772" title="Download PDF">pdf</a>, <a href="/format/2309.16772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XVO: Generalized Visual Odometry via Cross-Modal Self-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+L">Lei Lai</a>, 
<a href="/search/cs?searchtype=author&query=Shangguan%2C+Z">Zhongkai Shangguan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jimuyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ohn-Bar%2C+E">Eshed Ohn-Bar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">We propose XVO, a semi-supervised learning method for training generalized
monocular Visual Odometry (VO) models with robust off-the-self operation across
diverse datasets and settings. In contrast to standard monocular VO approaches
which often study a known calibration within a single dataset, XVO efficiently
learns to recover relative pose with real-world scale from visual scene
semantics, i.e., without relying on any known camera parameters. We optimize
the motion estimation model via self-training from large amounts of
unconstrained and heterogeneous dash camera videos available on YouTube. Our
key contribution is twofold. First, we empirically demonstrate the benefits of
semi-supervised training for learning a general-purpose direct VO regression
network. Second, we demonstrate multi-modal supervision, including
segmentation, flow, depth, and audio auxiliary prediction tasks, to facilitate
generalized representations for the VO task. Specifically, we find audio
prediction task to significantly enhance the semi-supervised learning process
while alleviating noisy pseudo-labels, particularly in highly dynamic and
out-of-domain video data. Our proposed teacher network achieves
state-of-the-art performance on the commonly used KITTI benchmark despite no
multi-frame optimization or knowledge of camera parameters. Combined with the
proposed semi-supervised step, XVO demonstrates off-the-shelf knowledge
transfer across diverse conditions on KITTI, nuScenes, and Argoverse without
fine-tuning.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16773" title="Abstract">arXiv:2309.16773</a> [<a href="/pdf/2309.16773" title="Download PDF">pdf</a>, <a href="/format/2309.16773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural scaling laws for phenotypic drug discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Linsley%2C+D">Drew Linsley</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+J">John Griffin</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+J+P">Jason Parker Brown</a>, 
<a href="/search/cs?searchtype=author&query=Roose%2C+A+N">Adam N Roose</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+M">Michael Frank</a>, 
<a href="/search/cs?searchtype=author&query=Linsley%2C+P">Peter Linsley</a>, 
<a href="/search/cs?searchtype=author&query=Finkbeiner%2C+S">Steven Finkbeiner</a>, 
<a href="/search/cs?searchtype=author&query=Linsley%2C+J">Jeremy Linsley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Recent breakthroughs by deep neural networks (DNNs) in natural language
processing (NLP) and computer vision have been driven by a scale-up of models
and data rather than the discovery of novel computing paradigms. Here, we
investigate if scale can have a similar impact for models designed to aid small
molecule drug discovery. We address this question through a large-scale and
systematic analysis of how DNN size, data diet, and learning routines interact
to impact accuracy on our Phenotypic Chemistry Arena (Pheno-CA) benchmark: a
diverse set of drug development tasks posed on image-based high content
screening data. Surprisingly, we find that DNNs explicitly supervised to solve
tasks in the Pheno-CA do not continuously improve as their data and model size
is scaled-up. To address this issue, we introduce a novel precursor task, the
Inverse Biological Process (IBP), which is designed to resemble the causal
objective functions that have proven successful for NLP. We indeed find that
DNNs first trained with IBP then probed for performance on the Pheno-CA
significantly outperform task-supervised DNNs. More importantly, the
performance of these IBP-trained DNNs monotonically improves with data and
model scale. Our findings reveal that the DNN ingredients needed to accurately
solve small molecule drug development tasks are already in our hands, and
project how much more experimental data is needed to achieve any desired level
of improvement. We release our Pheno-CA benchmark and code to encourage further
study of neural scaling laws for small molecule drug discovery.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16777" title="Abstract">arXiv:2309.16777</a> [<a href="/pdf/2309.16777" title="Download PDF">pdf</a>, <a href="/format/2309.16777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How many words does ChatGPT know? The answer is ChatWords
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez%2C+G">Gonzalo Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Conde%2C+J">Javier Conde</a>, 
<a href="/search/cs?searchtype=author&query=Reviriego%2C+P">Pedro Reviriego</a>, 
<a href="/search/cs?searchtype=author&query=Merino-G%C3%B3mez%2C+E">Elena Merino-G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez%2C+J+A">Jos&#xe9; Alberto Hern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Lombardi%2C+F">Fabrizio Lombardi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The introduction of ChatGPT has put Artificial Intelligence (AI) Natural
Language Processing (NLP) in the spotlight. ChatGPT adoption has been
exponential with millions of users experimenting with it in a myriad of tasks
and application domains with impressive results. However, ChatGPT has
limitations and suffers hallucinations, for example producing answers that look
plausible but they are completely wrong. Evaluating the performance of ChatGPT
and similar AI tools is a complex issue that is being explored from different
perspectives. In this work, we contribute to those efforts with ChatWords, an
automated test system, to evaluate ChatGPT knowledge of an arbitrary set of
words. ChatWords is designed to be extensible, easy to use, and adaptable to
evaluate also other NLP AI tools. ChatWords is publicly available and its main
goal is to facilitate research on the lexical knowledge of AI tools. The
benefits of ChatWords are illustrated with two case studies: evaluating the
knowledge that ChatGPT has of the Spanish lexicon (taken from the official
dictionary of the "Real Academia Espa\~nola") and of the words that appear in
the Quixote, the well-known novel written by Miguel de Cervantes. The results
show that ChatGPT is only able to recognize approximately 80% of the words in
the dictionary and 90% of the words in the Quixote, in some cases with an
incorrect meaning. The implications of the lexical knowledge of NLP AI tools
and potential applications of ChatWords are also discussed providing directions
for further work on the study of the lexical knowledge of AI tools.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16778" title="Abstract">arXiv:2309.16778</a> [<a href="/pdf/2309.16778" title="Download PDF">pdf</a>, <a href="/format/2309.16778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coupled Active Perception and Manipulation Planning for a Mobile  Manipulator in Precision Agriculture Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shuangyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chengsong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+J">Joe Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Bagavathiannan%2C+M">Muthukumar Bagavathiannan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dezhen Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A mobile manipulator often finds itself in an application where it needs to
take a close-up view before performing a manipulation task. Named this as a
coupled active perception and manipulation (CAPM) problem, we model the
uncertainty in the perception process and devise a key state/task planning
approach that considers reachability conditions as task constraints of both
perception and manipulation tasks for the mobile platform. By minimizing the
expected energy usage in the body key state planning while satisfying task
constraints, our algorithm achieves the best balance between the task success
rate and energy usage. We have implemented the algorithm and tested it in both
simulation and physical experiments. The results have confirmed that our
algorithm has a lower energy consumption compared to a two-stage decoupled
approach, while still maintaining a success rate of 100\% for the task.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16779" title="Abstract">arXiv:2309.16779</a> [<a href="/pdf/2309.16779" title="Download PDF">pdf</a>, <a href="/format/2309.16779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intriguing properties of generative classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaini%2C+P">Priyank Jaini</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+K">Kevin Clark</a>, 
<a href="/search/cs?searchtype=author&query=Geirhos%2C+R">Robert Geirhos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)

</div>
<p class="mathjax">What is the best paradigm to recognize objects -- discriminative inference
(fast but potentially prone to shortcut learning) or using a generative model
(slow but potentially more robust)? We build on recent advances in generative
modeling that turn text-to-image models into classifiers. This allows us to
study their behavior and to compare them against discriminative models and
human psychophysical data. We report four intriguing emergent properties of
generative classifiers: they show a record-breaking human-like shape bias (99%
for Imagen), near human-level out-of-distribution accuracy, state-of-the-art
alignment with human classification errors, and they understand certain
perceptual illusions. Our results indicate that while the current dominant
paradigm for modeling human object recognition is discriminative inference,
zero-shot generative models approximate human object recognition data
surprisingly well.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16781" title="Abstract">arXiv:2309.16781</a> [<a href="/pdf/2309.16781" title="Download PDF">pdf</a>, <a href="/format/2309.16781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hallucination Reduction in Long Input Text Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rehman%2C+T">Tohida Rehman</a>, 
<a href="/search/cs?searchtype=author&query=Mandal%2C+R">Ronit Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Abhishek Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+D+K">Debarshi Kumar Sanyal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Hallucination in text summarization refers to the phenomenon where the model
generates information that is not supported by the input source document.
Hallucination poses significant obstacles to the accuracy and reliability of
the generated summaries. In this paper, we aim to reduce hallucinated outputs
or hallucinations in summaries of long-form text documents. We have used the
PubMed dataset, which contains long scientific research documents and their
abstracts. We have incorporated the techniques of data filtering and joint
entity and summary generation (JAENS) in the fine-tuning of the Longformer
Encoder-Decoder (LED) model to minimize hallucinations and thereby improve the
quality of the generated summary. We have used the following metrics to measure
factual consistency at the entity level: precision-source, and F1-target. Our
experiments show that the fine-tuned LED model performs well in generating the
paper abstract. Data filtering techniques based on some preprocessing steps
reduce entity-level hallucinations in the generated summaries in terms of some
of the factual consistency metrics.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16782" title="Abstract">arXiv:2309.16782</a> [<a href="/pdf/2309.16782" title="Download PDF">pdf</a>, <a href="/format/2309.16782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STIR: Surgical Tattoos in Infrared
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+A">Adam Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Mohareri%2C+O">Omid Mohareri</a>, 
<a href="/search/cs?searchtype=author&query=DiMaio%2C+S">Simon DiMaio</a>, 
<a href="/search/cs?searchtype=author&query=Salcudean%2C+S+E">Septimiu E. Salcudean</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Quantifying performance of methods for tracking and mapping tissue in
endoscopic environments is essential for enabling image guidance and automation
of medical interventions and surgery. Datasets developed so far either use
rigid environments, visible markers, or require annotators to label salient
points in videos after collection. These are respectively: not general, visible
to algorithms, or costly and error-prone. We introduce a novel labeling
methodology along with a dataset that uses said methodology, Surgical Tattoos
in Infrared (STIR). STIR has labels that are persistent but invisible to
visible spectrum algorithms. This is done by labelling tissue points with
IR-flourescent dye, indocyanine green (ICG), and then collecting visible light
video clips. STIR comprises hundreds of stereo video clips in both in-vivo and
ex-vivo scenes with start and end points labelled in the IR spectrum. With over
3,000 labelled points, STIR will help to quantify and enable better analysis of
tracking and mapping methods. After introducing STIR, we analyze multiple
different frame-based tracking methods on STIR using both 3D and 2D endpoint
error and accuracy metrics. STIR is available at
https://dx.doi.org/10.21227/w8g4-g548
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16783" title="Abstract">arXiv:2309.16783</a> [<a href="/pdf/2309.16783" title="Download PDF">pdf</a>, <a href="/format/2309.16783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Photonic Accelerators for Image Segmentation in Autonomous Driving and  Defect Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+L">Lakshmi Nair</a>, 
<a href="/search/cs?searchtype=author&query=Widemann%2C+D">David Widemann</a>, 
<a href="/search/cs?searchtype=author&query=Turcott%2C+B">Brad Turcott</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+N">Nick Moore</a>, 
<a href="/search/cs?searchtype=author&query=Wleklinski%2C+A">Alexandra Wleklinski</a>, 
<a href="/search/cs?searchtype=author&query=Bunandar%2C+D">Darius Bunandar</a>, 
<a href="/search/cs?searchtype=author&query=Papavasileiou%2C+I">Ioannis Papavasileiou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shihu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Logan%2C+E">Eric Logan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Photonic computing promises faster and more energy-efficient deep neural
network (DNN) inference than traditional digital hardware. Advances in photonic
computing can have profound impacts on applications such as autonomous driving
and defect detection that depend on fast, accurate and energy efficient
execution of image segmentation models. In this paper, we investigate image
segmentation on photonic accelerators to explore: a) the types of image
segmentation DNN architectures that are best suited for photonic accelerators,
and b) the throughput and energy efficiency of executing the different image
segmentation models on photonic accelerators, along with the trade-offs
involved therein. Specifically, we demonstrate that certain segmentation models
exhibit negligible loss in accuracy (compared to digital float32 models) when
executed on photonic accelerators, and explore the empirical reasoning for
their robustness. We also discuss techniques for recovering accuracy in the
case of models that do not perform well. Further, we compare throughput
(inferences-per-second) and energy consumption estimates for different image
segmentation workloads on photonic accelerators. We discuss the challenges and
potential optimizations that can help improve the application of photonic
accelerators to such computer vision tasks.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16789" title="Abstract">arXiv:2309.16789</a> [<a href="/pdf/2309.16789" title="Download PDF">pdf</a>, <a href="/format/2309.16789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extensible Consent Management Architectures for Data Trusts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayappane%2C+B">Balambiga Ayappane</a>, 
<a href="/search/cs?searchtype=author&query=Vaidyanathan%2C+R">Rohith Vaidyanathan</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+S">Srinath Srinivasa</a>, 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+J">Jayati Deshmukh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An earlier version of this paper was published in ISIC 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Sensitive personal information of individuals and non-personal information of
organizations or communities often needs to be legitimately exchanged among
different stakeholders, to provide services, maintain public health, law and
order, and so on. While such exchanges are necessary, they also impose enormous
privacy and security challenges. Data protection laws like GDPR for personal
data and Indian Non-personal data protection draft specify conditions and the
\textit{legal capacity} in which personal and non-personal information can be
solicited and disseminated further. But there is a dearth of formalisms for
specifying legal capacities and jurisdictional boundaries, so that open-ended
exchange of such data can be implemented. This paper proposes an extensible
framework for consent management in Data Trusts in which data can flow across a
network through "role tunnels" established based on corresponding legal
capacities.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16792" title="Abstract">arXiv:2309.16792</a> [<a href="/pdf/2309.16792" title="Download PDF">pdf</a>, <a href="/format/2309.16792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent Coordination via Contextual Regression (AgentCONCUR) for Data  Center Flexibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dvorkin%2C+V">Vladimir Dvorkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">A network of spatially distributed data centers can provide operational
flexibility to power systems by shifting computing tasks among electrically
remote locations. However, harnessing this flexibility in real-time through the
standard optimization techniques is challenged by the need for sensitive
operational datasets and substantial computational resources. To alleviate the
data and computational requirements, this paper introduces a coordination
mechanism based on contextual regression. This mechanism, abbreviated as
AgentCONCUR, associates cost-optimal task shifts with public and trusted
contextual data (e.g., real-time prices) and uses regression on this data as a
coordination policy. Notably, regression-based coordination does not learn the
optimal coordination actions from a labeled dataset. Instead, it exploits the
optimization structure of the coordination problem to ensure feasible and
cost-effective actions. A NYISO-based study reveals large coordination gains
and the optimal features for the successful regression-based coordination.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16793" title="Abstract">arXiv:2309.16793</a> [<a href="/pdf/2309.16793" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software-Intensive Product Engineering in Start-Ups: A Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klotins%2C+E">Eriks Klotins</a>, 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Gorschek%2C+T">Tony Gorschek</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Softw. 35(4): 44-52 (2018)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software start-ups are new companies aiming to launch an innovative product
to mass markets fast with minimal resources. However, most start-ups fail
before realizing their potential. Poor software engineering, among other
factors, could be a significant contributor to the challenges that start-ups
experience. Little is known about the engineering context in start-up
companies. On the surface, start-ups are characterized by uncertainty, high
risk, and minimal resources. However, such a characterization isn't granular
enough to support identification of specific engineering challenges and to
devise start-up-specific engineering practices. The first step toward an
understanding of software engineering in start-ups is the definition of a
Start-Up Context Map - a taxonomy of engineering practices, environment
factors, and goals influencing the engineering process. This map aims to
support further research on the field and serve as an engineering decision
support tool for start-ups. This article is part of a theme issue on Process
Improvement.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16795" title="Abstract">arXiv:2309.16795</a> [<a href="/pdf/2309.16795" title="Download PDF">pdf</a>, <a href="/format/2309.16795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra-low-power Image Classification on Neuromorphic Hardware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lenz%2C+G">Gregor Lenz</a>, 
<a href="/search/cs?searchtype=author&query=Orchard%2C+G">Garrick Orchard</a>, 
<a href="/search/cs?searchtype=author&query=Sheik%2C+S">Sadique Sheik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Spiking neural networks (SNNs) promise ultra-low-power applications by
exploiting temporal and spatial sparsity. The number of binary activations,
called spikes, is proportional to the power consumed when executed on
neuromorphic hardware. Training such SNNs using backpropagation through time
for vision tasks that rely mainly on spatial features is computationally
costly. Training a stateless artificial neural network (ANN) to then convert
the weights to an SNN is a straightforward alternative when it comes to image
recognition datasets. Most conversion methods rely on rate coding in the SNN to
represent ANN activation, which uses enormous amounts of spikes and, therefore,
energy to encode information. Recently, temporal conversion methods have shown
promising results requiring significantly fewer spikes per neuron, but
sometimes complex neuron models. We propose a temporal ANN-to-SNN conversion
method, which we call Quartz, that is based on the time to first spike (TTFS).
Quartz achieves high classification accuracy and can be easily implemented on
neuromorphic hardware while using the least amount of synaptic operations and
memory accesses. It incurs a cost of two additional synapses per neuron
compared to previous temporal conversion methods, which are readily available
on neuromorphic hardware. We benchmark Quartz on MNIST, CIFAR10, and ImageNet
in simulation to show the benefits of our method and follow up with an
implementation on Loihi, a neuromorphic chip by Intel. We provide evidence that
temporal coding has advantages in terms of power consumption, throughput, and
latency for similar classification accuracy. Our code and models are publicly
available.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16797" title="Abstract">arXiv:2309.16797</a> [<a href="/pdf/2309.16797" title="Download PDF">pdf</a>, <a href="/format/2309.16797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernando%2C+C">Chrisantha Fernando</a>, 
<a href="/search/cs?searchtype=author&query=Banarse%2C+D">Dylan Banarse</a>, 
<a href="/search/cs?searchtype=author&query=Michalewski%2C+H">Henryk Michalewski</a>, 
<a href="/search/cs?searchtype=author&query=Osindero%2C+S">Simon Osindero</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Popular prompt strategies like Chain-of-Thought Prompting can dramatically
improve the reasoning abilities of Large Language Models (LLMs) in various
domains. However, such hand-crafted prompt-strategies are often sub-optimal. In
this paper, we present Promptbreeder, a general-purpose self-referential
self-improvement mechanism that evolves and adapts prompts for a given domain.
Driven by an LLM, Promptbreeder mutates a population of task-prompts, and
subsequently evaluates them for fitness on a training set. Crucially, the
mutation of these task-prompts is governed by mutation-prompts that the LLM
generates and improves throughout evolution in a self-referential way. That is,
Promptbreeder is not just improving task-prompts, but it is also improving the
mutationprompts that improve these task-prompts. Promptbreeder outperforms
state-of-the-art prompt strategies such as Chain-of-Thought and Plan-and-Solve
Prompting on commonly used arithmetic and commonsense reasoning benchmarks.
Furthermore, Promptbreeder is able to evolve intricate task-prompts for the
challenging problem of hate speech classification.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16798" title="Abstract">arXiv:2309.16798</a> [<a href="/pdf/2309.16798" title="Download PDF">pdf</a>, <a href="/format/2309.16798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expert-sourcing Domain-specific Knowledge: The Case of Synonym  Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Yates%2C+A">Andrew Yates</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> REFSQ Workshops (NLP4RE). 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">One prerequisite for supervised machine learning is high quality labelled
data. Acquiring such data is, particularly if expert knowledge is required,
costly or even impossible if the task needs to be performed by a single expert.
In this paper, we illustrate tool support that we adopted and extended to
source domain-specific knowledge from experts. We provide insight in design
decisions that aim at motivating experts to dedicate their time at performing
the labelling task. We are currently using the approach to identify true
synonyms from a list of candidate synonyms. The identification of synonyms is
important in scenarios were stakeholders from different companies and
background need to collaborate, for example when defining and negotiating
requirements. We foresee that the approach of expert-sourcing is applicable to
any data labelling task in software engineering. The discussed design decisions
and implementation are an initial draft that can be extended, refined and
validated with further application.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16801" title="Abstract">arXiv:2309.16801</a> [<a href="/pdf/2309.16801" title="Download PDF">pdf</a>, <a href="/ps/2309.16801" title="Download PostScript">ps</a>, <a href="/format/2309.16801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Case Quality -- Understanding Practitioners&#x27; Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+H+K+V">Huynh Khanh Vi Tran</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+N+B">Nauman Bin Ali</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6rstler%2C+J">J&#xfc;rgen B&#xf6;rstler</a>, 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PROFES 2019: 37-52
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Background: Test-case quality has always been one of the major concerns in
software testing. To improve test-case quality, it is important to better
understand how practitioners perceive the quality of test-cases. Objective:
Motivated by that need, we investigated how practitioners define test-case
quality and which aspects of test-cases are important for quality assessment.
Method: We conducted semi-structured interviews with professional developers,
testers and test architects from a multinational software company in Sweden.
Before the interviews, we asked participants for actual test cases (written in
natural language) that they perceive as good, normal, and bad respectively
together with rationales for their assessment. We also compared their opinions
on shared test cases and contrasted their views with the relevant literature.
Results: We present a quality model which consists of 11 test-case quality
attributes. We also identify a misalignment in defining test-case quality among
practitioners and between academia and industry, along with suggestions for
improving test-case quality in industry. Conclusion: The results show that
practitioners' background, including roles and working experience, are critical
dimensions of how test-case quality is defined and assessed.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16804" title="Abstract">arXiv:2309.16804</a> [<a href="/pdf/2309.16804" title="Download PDF">pdf</a>, <a href="/format/2309.16804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum-Driven Edubot: A Framework for Developing Language Learning  Chatbots Through Synthesizing Conversational Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+S">Shang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jili Shen</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+S">Shangchao Min</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Chatbots have become popular in educational settings, revolutionizing how
students interact with material and how teachers teach. We present
Curriculum-Driven EduBot, a framework for developing a chatbot that combines
the interactive features of chatbots with the systematic material of English
textbooks to assist students in enhancing their conversational skills. We begin
by extracting pertinent topics from textbooks and then using large language
models to generate dialogues related to these topics. We then fine-tune an
open-source LLM using our generated conversational data to create our
curriculum-driven chatbot. User studies demonstrate that our chatbot
outperforms ChatGPT in leading curriculum-based dialogues and adapting its
dialogue to match the user's English proficiency level. By combining
traditional textbook methodologies with conversational AI, our approach offers
learners an interactive tool that aligns with their curriculum and provides
user-tailored conversation practice. This facilitates meaningful student-bot
dialogues and enriches the overall learning experience within the curriculum's
pedagogical framework.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16805" title="Abstract">arXiv:2309.16805</a> [<a href="/pdf/2309.16805" title="Download PDF">pdf</a>, <a href="/ps/2309.16805" title="Download PostScript">ps</a>, <a href="/format/2309.16805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascaded Nonlinear Control Design for Highly Underactuated Balance  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Feng Han</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingang Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a nonlinear control design for highly underactuated
balance robots, which possess more numbers of unactuated degree-of-freedom
(DOF) than actuated ones. To address the challenge of simultaneously trajectory
tracking of actuated coordinates and balancing of unactuated coordinates, the
proposed control converts a robot dynamics into a series of cascaded subsystems
and each of them is considered virtually actuated. To achieve the control goal,
we sequentially design and update the virtual and actual control inputs to
incorporate the balance task such that the unactuated coordinates are balanced
to their instantaneous equilibrium. The closed-loop dynamics are shown to be
stable and the tracking errors exponentially converge towards a neighborhood
near the origin. The simulation results demonstrate the effectiveness of the
proposed control design by using a triple-inverted pendulum cart system.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16808" title="Abstract">arXiv:2309.16808</a> [<a href="/pdf/2309.16808" title="Download PDF">pdf</a>, <a href="/format/2309.16808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Granularity at Scale: Estimating Neighborhood Well-Being from  High-Resolution Orthographic Imagery and Hybrid Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brewer%2C+E">Ethan Brewer</a>, 
<a href="/search/cs?searchtype=author&query=Valdrighi%2C+G">Giovani Valdrighi</a>, 
<a href="/search/cs?searchtype=author&query=Solunke%2C+P">Parikshit Solunke</a>, 
<a href="/search/cs?searchtype=author&query=Rulff%2C+J">Joao Rulff</a>, 
<a href="/search/cs?searchtype=author&query=Piadyk%2C+Y">Yurii Piadyk</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zhonghui Lv</a>, 
<a href="/search/cs?searchtype=author&query=Poco%2C+J">Jorge Poco</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+C">Claudio Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Many areas of the world are without basic information on the well-being of
the residing population due to limitations in existing data collection methods.
Overhead images obtained remotely, such as from satellite or aircraft, can help
serve as windows into the state of life on the ground and help "fill in the
gaps" where community information is sparse, with estimates at smaller
geographic scales requiring higher resolution sensors. Concurrent with improved
sensor resolutions, recent advancements in machine learning and computer vision
have made it possible to quickly extract features from and detect patterns in
image data, in the process correlating these features with other information.
In this work, we explore how well two approaches, a supervised convolutional
neural network and semi-supervised clustering based on bag-of-visual-words,
estimate population density, median household income, and educational
attainment of individual neighborhoods from publicly available high-resolution
imagery of cities throughout the United States. Results and analyses indicate
that features extracted from the imagery can accurately estimate the density
(R$^2$ up to 0.81) of neighborhoods, with the supervised approach able to
explain about half the variation in a population's income and education. In
addition to the presented approaches serving as a basis for further geographic
generalization, the novel semi-supervised approach provides a foundation for
future work seeking to estimate fine-scale information from overhead imagery
without the need for label data.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16809" title="Abstract">arXiv:2309.16809</a> [<a href="/pdf/2309.16809" title="Download PDF">pdf</a>, <a href="/format/2309.16809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraB-sampler: Optimal Permutation-based SGD Data Sampler for PyTorch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Guanghao Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The online Gradient Balancing (GraB) algorithm greedily choosing the examples
ordering by solving the herding problem using per-sample gradients is proved to
be the theoretically optimal solution that guarantees to outperform Random
Reshuffling. However, there is currently no efficient implementation of GraB
for the community to easily use it.
<br />This work presents an efficient Python library, $\textit{GraB-sampler}$, that
allows the community to easily use GraB algorithms and proposes 5 variants of
the GraB algorithm. The best performance result of the GraB-sampler reproduces
the training loss and test accuracy results while only in the cost of 8.7%
training time overhead and 0.85% peak GPU memory usage overhead.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16812" title="Abstract">arXiv:2309.16812</a> [<a href="/pdf/2309.16812" title="Download PDF">pdf</a>, <a href="/format/2309.16812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SatDM: Synthesizing Realistic Satellite Image with Semantic Layout  Conditioning using Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baghirli%2C+O">Orkhan Baghirli</a>, 
<a href="/search/cs?searchtype=author&query=Askarov%2C+H">Hamid Askarov</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahimli%2C+I">Imran Ibrahimli</a>, 
<a href="/search/cs?searchtype=author&query=Bakhishov%2C+I">Ismat Bakhishov</a>, 
<a href="/search/cs?searchtype=author&query=Nabiyev%2C+N">Nabi Nabiyev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Deep learning models in the Earth Observation domain heavily rely on the
availability of large-scale accurately labeled satellite imagery. However,
obtaining and labeling satellite imagery is a resource-intensive endeavor.
While generative models offer a promising solution to address data scarcity,
their potential remains underexplored. Recently, Denoising Diffusion
Probabilistic Models (DDPMs) have demonstrated significant promise in
synthesizing realistic images from semantic layouts. In this paper, a
conditional DDPM model capable of taking a semantic map and generating
high-quality, diverse, and correspondingly accurate satellite images is
implemented. Additionally, a comprehensive illustration of the optimization
dynamics is provided. The proposed methodology integrates cutting-edge
techniques such as variance learning, classifier-free guidance, and improved
noise scheduling. The denoising network architecture is further complemented by
the incorporation of adaptive normalization and self-attention mechanisms,
enhancing the model's capabilities. The effectiveness of our proposed model is
validated using a meticulously labeled dataset introduced within the context of
this study. Validation encompasses both algorithmic methods such as Frechet
Inception Distance (FID) and Intersection over Union (IoU), as well as a human
opinion study. Our findings indicate that the generated samples exhibit minimal
deviation from real ones, opening doors for practical applications such as data
augmentation. We look forward to further explorations of DDPMs in a wider
variety of settings and data modalities. An open-source reference
implementation of the algorithm and a link to the benchmarked dataset are
provided at https://github.com/obaghirli/syn10-diffusion.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16813" title="Abstract">arXiv:2309.16813</a> [<a href="/pdf/2309.16813" title="Download PDF">pdf</a>, <a href="/format/2309.16813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wi-Fi 8: Embracing the Millimeter-Wave Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoqian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tingwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuhan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+M">Ming Gan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianmin Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">With the increasing demands in communication, Wi-Fi technology is advancing
towards its next generation. Building on the foundation of Wi-Fi 7,
millimeter-wave technology is anticipated to converge with Wi-Fi 8 in the near
future. In this paper, we look into the millimeter-wave technology and other
potential feasible features, providing a comprehensive perspective on the
future of Wi-Fi 8. Our simulation results demonstrate that significant
performance gains can be achieved, even in the presence of hardware
impairments.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16816" title="Abstract">arXiv:2309.16816</a> [<a href="/pdf/2309.16816" title="Download PDF">pdf</a>, <a href="/format/2309.16816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROSE: Predicting Operators and Symbolic Expressions using Multimodal  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zecheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Schaeffer%2C+H">Hayden Schaeffer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Approximating nonlinear differential equations using a neural network
provides a robust and efficient tool for various scientific computing tasks,
including real-time predictions, inverse problems, optimal controls, and
surrogate modeling. Previous works have focused on embedding dynamical systems
into networks through two approaches: learning a single solution operator
(i.e., the mapping from input parametrized functions to solutions) or learning
the governing system of equations (i.e., the constitutive model relative to the
state variables). Both of these approaches yield different representations for
the same underlying data or function. Additionally, observing that families of
differential equations often share key characteristics, we seek one network
representation across a wide range of equations. Our method, called Predicting
Operators and Symbolic Expressions (PROSE), learns maps from multimodal inputs
to multimodal outputs, capable of generating both numerical predictions and
mathematical equations. By using a transformer structure and a feature fusion
approach, our network can simultaneously embed sets of solution operators for
various parametric differential equations using a single trained network.
Detailed experiments demonstrate that the network benefits from its multimodal
nature, resulting in improved prediction accuracy and better generalization.
The network is shown to be able to handle noise in the data and errors in the
symbolic representation, including noisy numerical values, model
misspecification, and erroneous addition or deletion of terms. PROSE provides a
new neural network framework for differential equations which allows for more
flexibility and generality in learning operators and governing equations from
data.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16817" title="Abstract">arXiv:2309.16817</a> [<a href="/pdf/2309.16817" title="Download PDF">pdf</a>, <a href="/format/2309.16817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Non-Stochastic Control of Control-Affine Systems: An Online Convex  Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Hongyu Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Y">Yichen Song</a>, 
<a href="/search/eess?searchtype=author&query=Tzoumas%2C+V">Vasileios Tzoumas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We study how to safely control nonlinear control-affine systems that are
corrupted with bounded non-stochastic noise, i.e., noise that is unknown a
priori and that is not necessarily governed by a stochastic model. We focus on
safety constraints that take the form of time-varying convex constraints such
as collision-avoidance and control-effort constraints. We provide an algorithm
with bounded dynamic regret, i.e., bounded suboptimality against an optimal
clairvoyant controller that knows the realization of the noise a prior. We are
motivated by the future of autonomy where robots will autonomously perform
complex tasks despite real-world unpredictable disturbances such as wind gusts.
To develop the algorithm, we capture our problem as a sequential game between a
controller and an adversary, where the controller plays first, choosing the
control input, whereas the adversary plays second, choosing the noise's
realization. The controller aims to minimize its cumulative tracking error
despite being unable to know the noise's realization a prior. We validate our
algorithm in simulated scenarios of (i) an inverted pendulum aiming to stay
upright, and (ii) a quadrotor aiming to fly to a goal location through an
unknown cluttered environment.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16818" title="Abstract">arXiv:2309.16818</a> [<a href="/pdf/2309.16818" title="Download PDF">pdf</a>, <a href="/format/2309.16818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEM: Multi-Modal Elevation Mapping for Robotics and Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erni%2C+G">Gian Erni</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+J">Jonas Frey</a>, 
<a href="/search/cs?searchtype=author&query=Miki%2C+T">Takahiro Miki</a>, 
<a href="/search/cs?searchtype=author&query=Mattamala%2C+M">Matias Mattamala</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accapted for IROS2023. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Elevation maps are commonly used to represent the environment of mobile
robots and are instrumental for locomotion and navigation tasks. However, pure
geometric information is insufficient for many field applications that require
appearance or semantic information, which limits their applicability to other
platforms or domains. In this work, we extend a 2.5D robot-centric elevation
mapping framework by fusing multi-modal information from multiple sources into
a popular map representation. The framework allows inputting data contained in
point clouds or images in a unified manner. To manage the different nature of
the data, we also present a set of fusion algorithms that can be selected based
on the information type and user requirements. Our system is designed to run on
the GPU, making it real-time capable for various robotic and learning tasks. We
demonstrate the capabilities of our framework by deploying it on multiple
robots with varying sensor configurations and showcasing a range of
applications that utilize multi-modal layers, including line detection, human
detection, and colorization.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16819" title="Abstract">arXiv:2309.16819</a> [<a href="/pdf/2309.16819" title="Download PDF">pdf</a>, <a href="/format/2309.16819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Bellman operator for convergence of $Q$-learning with linear  function approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+D+S">Diogo S. Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+P+A">Pedro A. Santos</a>, 
<a href="/search/cs?searchtype=author&query=Melo%2C+F+S">Francisco S. Melo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We study the convergence of $Q$-learning with linear function approximation.
Our key contribution is the introduction of a novel multi-Bellman operator that
extends the traditional Bellman operator. By exploring the properties of this
operator, we identify conditions under which the projected multi-Bellman
operator becomes contractive, providing improved fixed-point guarantees
compared to the Bellman operator. To leverage these insights, we propose the
multi $Q$-learning algorithm with linear function approximation. We demonstrate
that this algorithm converges to the fixed-point of the projected multi-Bellman
operator, yielding solutions of arbitrary accuracy. Finally, we validate our
approach by applying it to well-known environments, showcasing the
effectiveness and applicability of our findings.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16824" title="Abstract">arXiv:2309.16824</a> [<a href="/pdf/2309.16824" title="Download PDF">pdf</a>, <a href="/format/2309.16824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The fork and its role in unification of closure algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%BCntsch%2C+I">Ivo D&#xfc;ntsch</a>, 
<a href="/search/cs?searchtype=author&query=Dzik%2C+W">Wojciech Dzik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Rings and Algebras (math.RA)

</div>
<p class="mathjax">We consider the two-pronged fork frame $F$ and the variety $\mathbf{Eq}(B_F)$
generated by its dual closure algebra $B_F$. We describe the finite projective
algebras in $\mathbf{Eq}(B_F)$ and give a purely semantic proof that
unification in $\mathbf{Eq}(B_F)$ is finitary and not unitary.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16825" title="Abstract">arXiv:2309.16825</a> [<a href="/pdf/2309.16825" title="Download PDF">pdf</a>, <a href="/format/2309.16825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FENDA-FL: Personalized Federated Learning on Heterogeneous Clinical  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tavakoli%2C+F">Fatemeh Tavakoli</a>, 
<a href="/search/cs?searchtype=author&query=Emerson%2C+D+B">D.B. Emerson</a>, 
<a href="/search/cs?searchtype=author&query=Jewell%2C+J">John Jewell</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+A">Amrit Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuchong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+A">Amol Verma</a>, 
<a href="/search/cs?searchtype=author&query=Razak%2C+F">Fahad Razak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures, 6 tables, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL) is increasingly being recognized as a key approach to
overcoming the data silos that so frequently obstruct the training and
deployment of machine-learning models in clinical settings. This work
contributes to a growing body of FL research specifically focused on clinical
applications along three important directions. First, an extension of the FENDA
method (Kim et al., 2016) to the FL setting is proposed. Experiments conducted
on the FLamby benchmarks (du Terrail et al., 2022a) and GEMINI datasets (Verma
et al., 2017) show that the approach is robust to heterogeneous clinical data
and often outperforms existing global and personalized FL techniques. Further,
the experimental results represent substantive improvements over the original
FLamby benchmarks and expand such benchmarks to include evaluation of
personalized FL methods. Finally, we advocate for a comprehensive checkpointing
and evaluation framework for FL to better reflect practical settings and
provide multiple baselines for comparison.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16826" title="Abstract">arXiv:2309.16826</a> [<a href="/pdf/2309.16826" title="Download PDF">pdf</a>, <a href="/format/2309.16826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Attentional Recurrent Neural Network for Occlusion-Aware Proactive  Anomaly Detection in Field Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schreiber%2C+A">Andre Schreiber</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tianchen Ji</a>, 
<a href="/search/cs?searchtype=author&query=McPherson%2C+D+L">D. Livingston McPherson</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IROS 2023. Code available at <a href="https://github.com/andreschreiber/ROAR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The use of mobile robots in unstructured environments like the agricultural
field is becoming increasingly common. The ability for such field robots to
proactively identify and avoid failures is thus crucial for ensuring efficiency
and avoiding damage. However, the cluttered field environment introduces
various sources of noise (such as sensor occlusions) that make proactive
anomaly detection difficult. Existing approaches can show poor performance in
sensor occlusion scenarios as they typically do not explicitly model occlusions
and only leverage current sensory inputs. In this work, we present an
attention-based recurrent neural network architecture for proactive anomaly
detection that fuses current sensory inputs and planned control actions with a
latent representation of prior robot state. We enhance our model with an
explicitly-learned model of sensor occlusion that is used to modulate the use
of our latent representation of prior robot state. Our method shows improved
anomaly detection performance and enables mobile field robots to display
increased resilience to predicting false positives regarding navigation failure
during periods of sensor occlusion, particularly in cases where all sensors are
briefly occluded. Our code is available at:
https://github.com/andreschreiber/roar
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16827" title="Abstract">arXiv:2309.16827</a> [<a href="/pdf/2309.16827" title="Download PDF">pdf</a>, <a href="/format/2309.16827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post-Training Overfitting Mitigation in DNN Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+D+J">David J. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Kesidis%2C+G">George Kesidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Well-known (non-malicious) sources of overfitting in deep neural net (DNN)
classifiers include: i) large class imbalances; ii) insufficient training-set
diversity; and iii) over-training. In recent work, it was shown that backdoor
data-poisoning also induces overfitting, with unusually large classification
margins to the attacker's target class, mediated particularly by (unbounded)
ReLU activations that allow large signals to propagate in the DNN. Thus, an
effective post-training (with no knowledge of the training set or training
process) mitigation approach against backdoors was proposed, leveraging a small
clean dataset, based on bounding neural activations. Improving upon that work,
we threshold activations specifically to limit maximum margins (MMs), which
yields performance gains in backdoor mitigation. We also provide some
analytical support for this mitigation approach. Most importantly, we show that
post-training MM-based regularization substantially mitigates non-malicious
overfitting due to class imbalances and overtraining. Thus, unlike adversarial
training, which provides some resilience against attacks but which harms clean
(attack-free) generalization, we demonstrate an approach originating from
adversarial learning that helps clean generalization accuracy. Experiments on
CIFAR-10 and CIFAR-100, in comparison with peer methods, demonstrate strong
performance of our methods.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16829" title="Abstract">arXiv:2309.16829</a> [<a href="/pdf/2309.16829" title="Download PDF">pdf</a>, <a href="/format/2309.16829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An analysis of the derivative-free loss method for solving PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Han%2C+J">Jihun Han</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+Y">Yoonsang Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">This study analyzes the derivative-free loss method to solve a certain class
of elliptic PDEs using neural networks. The derivative-free loss method uses
the Feynman-Kac formulation, incorporating stochastic walkers and their
corresponding average values. We investigate the effect of the time interval
related to the Feynman-Kac formulation and the walker size in the context of
computational efficiency, trainability, and sampling errors. Our analysis shows
that the training loss bias is proportional to the time interval and the
spatial gradient of the neural network while inversely proportional to the
walker size. We also show that the time interval must be sufficiently long to
train the network. These analytic results tell that we can choose the walker
size as small as possible based on the optimal lower bound of the time
interval. We also provide numerical tests supporting our analysis.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16830" title="Abstract">arXiv:2309.16830</a> [<a href="/pdf/2309.16830" title="Download PDF">pdf</a>, <a href="/format/2309.16830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Safe Control with Multi-Modal Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Tianhao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liqian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pandya%2C+R">Ravi Pandya</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Safety in dynamic systems with prevalent uncertainties is crucial. Current
robust safe controllers, designed primarily for uni-modal uncertainties, may be
either overly conservative or unsafe when handling multi-modal uncertainties.
To address the problem, we introduce a novel framework for robust safe control,
tailored to accommodate multi-modal Gaussian dynamics uncertainties and control
limits.
<br />We first present an innovative method for deriving the least conservative
robust safe control under additive multi-modal uncertainties. Next, we propose
a strategy to identify a locally least-conservative robust safe control under
multiplicative uncertainties. Following these, we introduce a unique safety
index synthesis method. This provides the foundation for a robust safe
controller that ensures a high probability of realizability under control
limits and multi-modal uncertainties.
<br />Experiments on a simulated Segway validate our approach, showing consistent
realizability and less conservatism than controllers designed using uni-modal
uncertainty methods. The framework offers significant potential for enhancing
safety and performance in robotic applications.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16831" title="Abstract">arXiv:2309.16831</a> [<a href="/pdf/2309.16831" title="Download PDF">pdf</a>, <a href="/format/2309.16831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Propagation and Attribution of Uncertainty in Medical Imaging Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feiner%2C+L+F">Leonhard F. Feiner</a>, 
<a href="/search/cs?searchtype=author&query=Menten%2C+M+J">Martin J. Menten</a>, 
<a href="/search/cs?searchtype=author&query=Hammernik%2C+K">Kerstin Hammernik</a>, 
<a href="/search/cs?searchtype=author&query=Hager%2C+P">Paul Hager</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Braren%2C+R+F">Rickmer F. Braren</a>, 
<a href="/search/cs?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Uncertainty estimation, which provides a means of building explainable neural
networks for medical imaging applications, have mostly been studied for single
deep learning models that focus on a specific task. In this paper, we propose a
method to propagate uncertainty through cascades of deep learning models in
medical imaging pipelines. This allows us to aggregate the uncertainty in later
stages of the pipeline and to obtain a joint uncertainty measure for the
predictions of later models. Additionally, we can separately report
contributions of the aleatoric, data-based, uncertainty of every component in
the pipeline. We demonstrate the utility of our method on a realistic imaging
pipeline that reconstructs undersampled brain and knee magnetic resonance (MR)
images and subsequently predicts quantitative information from the images, such
as the brain volume, or knee side or patient's sex. We quantitatively show that
the propagated uncertainty is correlated with input uncertainty and compare the
proportions of contributions of pipeline stages to the joint uncertainty
measure.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16834" title="Abstract">arXiv:2309.16834</a> [<a href="/pdf/2309.16834" title="Download PDF">pdf</a>, <a href="/format/2309.16834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy Optimal Control of a Harmonic Oscillator with a State Inequality  Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+M">Mi Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Verriest%2C+E+I">Erik I Verriest</a>, 
<a href="/search/eess?searchtype=author&query=Abdallah%2C+C">Chaouki Abdallah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this article, the optimal control problem for a harmonic oscillator with
an inequality constraint is considered. The applied energy of the oscillator
during a fixed final time period is used as the performance criterion. The
analytical solution with both small and large terminal time is found for a
special case when the undriven oscillator system is initially at rest. For
other initial states of the Harmonic oscillator, the optimal solution is found
to have three modes: wait-move, move-wait, and move-wait-move given a longer
terminal time.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16838" title="Abstract">arXiv:2309.16838</a> [<a href="/pdf/2309.16838" title="Download PDF">pdf</a>, <a href="/format/2309.16838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Navigation in Crowded Environments with Model Predictive Control  and Deep Learning-Based Human Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+V">Viet-Anh Le</a>, 
<a href="/search/cs?searchtype=author&query=Chalaki%2C+B">Behdad Chalaki</a>, 
<a href="/search/cs?searchtype=author&query=Tadiparthi%2C+V">Vaishnav Tadiparthi</a>, 
<a href="/search/cs?searchtype=author&query=Mahjoub%2C+H+N">Hossein Nourkhiz Mahjoub</a>, 
<a href="/search/cs?searchtype=author&query=D%27sa%2C+J">Jovin D&#x27;sa</a>, 
<a href="/search/cs?searchtype=author&query=Moradi-Pari%2C+E">Ehsan Moradi-Pari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Crowd navigation has received increasing attention from researchers over the
last few decades, resulting in the emergence of numerous approaches aimed at
addressing this problem to date. Our proposed approach couples agent motion
prediction and planning to avoid the freezing robot problem while
simultaneously capturing multi-agent social interactions by utilizing a
state-of-the-art trajectory prediction model i.e., social long short-term
memory model (Social-LSTM). Leveraging the output of Social-LSTM for the
prediction of future trajectories of pedestrians at each time-step given the
robot's possible actions, our framework computes the optimal control action
using Model Predictive Control (MPC) for the robot to navigate among
pedestrians. We demonstrate the effectiveness of our proposed approach in
multiple scenarios of simulated crowd navigation and compare it against several
state-of-the-art reinforcement learning-based methods.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16840" title="Abstract">arXiv:2309.16840</a> [<a href="/pdf/2309.16840" title="Download PDF">pdf</a>, <a href="/format/2309.16840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constant Approximation for Individual Preference Stable Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aamand%2C+A">Anders Aamand</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+Y">Justin Y. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Allen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Silwal%2C+S">Sandeep Silwal</a>, 
<a href="/search/cs?searchtype=author&query=Sukprasert%2C+P">Pattara Sukprasert</a>, 
<a href="/search/cs?searchtype=author&query=Vakilian%2C+A">Ali Vakilian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fred Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Individual preference (IP) stability, introduced by Ahmadi et al. (ICML
2022), is a natural clustering objective inspired by stability and fairness
constraints. A clustering is $\alpha$-IP stable if the average distance of
every data point to its own cluster is at most $\alpha$ times the average
distance to any other cluster. Unfortunately, determining if a dataset admits a
$1$-IP stable clustering is NP-Hard. Moreover, before this work, it was unknown
if an $o(n)$-IP stable clustering always \emph{exists}, as the prior state of
the art only guaranteed an $O(n)$-IP stable clustering. We close this gap in
understanding and show that an $O(1)$-IP stable clustering always exists for
general metrics, and we give an efficient algorithm which outputs such a
clustering. We also introduce generalizations of IP stability beyond average
distance and give efficient, near-optimal algorithms in the cases where we
consider the maximum and minimum distances within and between clusters.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16842" title="Abstract">arXiv:2309.16842</a> [<a href="/pdf/2309.16842" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layered Security Guidance for Data Asset Management in Additive  Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milaat%2C+F+A">Fahad Ali Milaat</a>, 
<a href="/search/cs?searchtype=author&query=Lubell%2C+J">Joshua Lubell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the ASME Journal of Computing and Information Science in Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Manufacturing industries are increasingly adopting additive manufacturing
(AM) technologies to produce functional parts in critical systems. However, the
inherent complexity of both AM designs and AM processes render them attractive
targets for cyber-attacks. Risk-based Information Technology (IT) and
Operational Technology (OT) security guidance standards are useful resources
for AM security practitioners, but the guidelines they provide are insufficient
without additional AM-specific revisions. Therefore, a structured layering
approach is needed to efficiently integrate these revisions with preexisting IT
and OT security guidance standards. To implement such an approach, this paper
proposes leveraging the National Institute of Standards and Technology's
Cybersecurity Framework (CSF) to develop layered, risk-based guidance for
fulfilling specific security outcomes. It begins with an in-depth literature
review that reveals the importance of AM data and asset management to
risk-based security. Next, this paper adopts the CSF asset identification and
management security outcomes as an example for providing AM-specific guidance
and identifies the AM geometry and process definitions to aid manufacturers in
mapping data flows and documenting processes. Finally, this paper uses the Open
Security Controls Assessment Language to integrate the AM-specific guidance
together with existing IT and OT security guidance in a rigorous and traceable
manner. This paper's contribution is to show how a risk-based layered approach
enables the authoring, publishing, and management of AM-specific security
guidance that is currently lacking. The authors believe implementation of the
layered approach would result in value-added, non-redundant security guidance
for AM that is consistent with the preexisting guidance.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16844" title="Abstract">arXiv:2309.16844</a> [<a href="/pdf/2309.16844" title="Download PDF">pdf</a>, <a href="/ps/2309.16844" title="Download PostScript">ps</a>, <a href="/format/2309.16844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeBERTinha: A Multistep Approach to Adapt DebertaV3 XSmall for Brazilian  Portuguese Natural Language Processing Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campiotti%2C+I">Israel Campiotti</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+M">Matheus Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Albuquerque%2C+Y">Yuri Albuquerque</a>, 
<a href="/search/cs?searchtype=author&query=Azevedo%2C+R">Rafael Azevedo</a>, 
<a href="/search/cs?searchtype=author&query=Andrade%2C+A">Alyson Andrade</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents an approach for adapting the DebertaV3 XSmall model
pre-trained in English for Brazilian Portuguese natural language processing
(NLP) tasks. A key aspect of the methodology involves a multistep training
process to ensure the model is effectively tuned for the Portuguese language.
Initial datasets from Carolina and BrWac are preprocessed to address issues
like emojis, HTML tags, and encodings. A Portuguese-specific vocabulary of
50,000 tokens is created using SentencePiece. Rather than training from
scratch, the weights of the pre-trained English model are used to initialize
most of the network, with random embeddings, recognizing the expensive cost of
training from scratch. The model is fine-tuned using the replaced token
detection task in the same format of DebertaV3 training. The adapted model,
called DeBERTinha, demonstrates effectiveness on downstream tasks like named
entity recognition, sentiment analysis, and determining sentence relatedness,
outperforming BERTimbau-Large in two tasks despite having only 40M parameters.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16845" title="Abstract">arXiv:2309.16845</a> [<a href="/pdf/2309.16845" title="Download PDF">pdf</a>, <a href="/format/2309.16845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Business Model Canvas for Micro Operators in 5G Coopetitive Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rostampoor%2C+J">Javane Rostampoor</a>, 
<a href="/search/cs?searchtype=author&query=Joda%2C+R">Roghayeh Joda</a>, 
<a href="/search/cs?searchtype=author&query=Dindoost%2C+M">Mohammad Dindoost</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Emerging Technologies (cs.ET); Signal Processing (eess.SP)

</div>
<p class="mathjax">In order to address the need for more capacity and coverage in the 5th
generation (5G) of wireless networks, ultra-dense wireless networks are
introduced which mainly consist of indoor small cells. This new architecture
has paved the way for the advent of a new concept called Micro Operator. A
micro operator is an entity that provides connections and local 5G services to
the customers and relies on local frequency resources. We discuss business
models of micro operators in a 5G coopetitive environment and develop a
framework to indicate the business model canvas (BMC) of this new concept.
Providing BMC for new businesses is a strategic approach to offer value to
customers. In this research study, BMC and its elements are introduced and
explained for 5G micro operators.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16846" title="Abstract">arXiv:2309.16846</a> [<a href="/pdf/2309.16846" title="Download PDF">pdf</a>, <a href="/format/2309.16846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Nonlinearities Improve Generalization Performance of Random  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demir%2C+S">Samet Demir</a>, 
<a href="/search/cs?searchtype=author&query=Do%C4%9Fan%2C+Z">Zafer Do&#x11f;an</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Random feature model with a nonlinear activation function has been shown to
perform asymptotically equivalent to a Gaussian model in terms of training and
generalization errors. Analysis of the equivalent model reveals an important
yet not fully understood role played by the activation function. To address
this issue, we study the "parameters" of the equivalent model to achieve
improved generalization performance for a given supervised learning problem. We
show that acquired parameters from the Gaussian model enable us to define a set
of optimal nonlinearities. We provide two example classes from this set, e.g.,
second-order polynomial and piecewise linear functions. These functions are
optimized to improve generalization performance regardless of the actual form.
We experiment with regression and classification problems, including synthetic
and real (e.g., CIFAR10) data. Our numerical results validate that the
optimized nonlinearities achieve better generalization performance than
widely-used nonlinear functions such as ReLU. Furthermore, we illustrate that
the proposed nonlinearities also mitigate the so-called double descent
phenomenon, which is known as the non-monotonic generalization performance
regarding the sample size and the model size.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16849" title="Abstract">arXiv:2309.16849</a> [<a href="/pdf/2309.16849" title="Download PDF">pdf</a>, <a href="/format/2309.16849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-Time Attention with Shifted Non-Local Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gauen%2C+K">Kent Gauen</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+S">Stanley Chan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Efficiently computing attention maps for videos is challenging due to the
motion of objects between frames. While a standard non-local search is
high-quality for a window surrounding each query point, the window's small size
cannot accommodate motion. Methods for long-range motion use an auxiliary
network to predict the most similar key coordinates as offsets from each query
location. However, accurately predicting this flow field of offsets remains
challenging, even for large-scale networks. Small spatial inaccuracies
significantly impact the attention module's quality. This paper proposes a
search strategy that combines the quality of a non-local search with the range
of predicted offsets. The method, named Shifted Non-Local Search, executes a
small grid search surrounding the predicted offsets to correct small spatial
errors. Our method's in-place computation consumes 10 times less memory and is
over 3 times faster than previous work. Experimentally, correcting the small
spatial errors improves the video frame alignment quality by over 3 dB PSNR.
Our search upgrades existing space-time attention modules, which improves video
denoising results by 0.30 dB PSNR for a 7.5% increase in overall runtime. We
integrate our space-time attention module into a UNet-like architecture to
achieve state-of-the-art results on video denoising.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16850" title="Abstract">arXiv:2309.16850</a> [<a href="/pdf/2309.16850" title="Download PDF">pdf</a>, <a href="/format/2309.16850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketch2CADScript: 3D Scene Reconstruction from 2D Sketch using Visual  Transformer and Rhino Grasshopper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hong-Bin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing 3D model reconstruction methods typically produce outputs in the
form of voxels, point clouds, or meshes. However, each of these approaches has
its limitations and may not be suitable for every scenario. For instance, the
resulting model may exhibit a rough surface and distorted structure, making
manual editing and post-processing challenging for humans. In this paper, we
introduce a novel 3D reconstruction method designed to address these issues. We
trained a visual transformer to predict a "scene descriptor" from a single
wire-frame image. This descriptor encompasses crucial information, including
object types and parameters such as position, rotation, and size. With the
predicted parameters, a 3D scene can be reconstructed using 3D modeling
software like Blender or Rhino Grasshopper which provides a programmable
interface, resulting in finely and easily editable 3D models. To evaluate the
proposed model, we created two datasets: one featuring simple scenes and
another with complex scenes. The test results demonstrate the model's ability
to accurately reconstruct simple scenes but reveal its challenges with more
complex ones.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16854" title="Abstract">arXiv:2309.16854</a> [<a href="/pdf/2309.16854" title="Download PDF">pdf</a>, <a href="/format/2309.16854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of Federated Learning in IoT for Hyper Personalisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dosi%2C+V">Veer Dosi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Billions of IoT devices are being deployed, taking advantage of faster
internet, and the opportunity to access more endpoints. Vast quantities of data
are being generated constantly by these devices but are not effectively being
utilised. Using FL training machine learning models over these multiple clients
without having to bring it to a central server. We explore how to use such a
model to implement ultra levels of personalization unlike before
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16857" title="Abstract">arXiv:2309.16857</a> [<a href="/pdf/2309.16857" title="Download PDF">pdf</a>, <a href="/format/2309.16857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General and Unified Model of the Power Flow Problem in Multiterminal  AC/DC Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lambrichts%2C+W">Willem Lambrichts</a>, 
<a href="/search/eess?searchtype=author&query=Paolone%2C+M">Mario Paolone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a generic and unified model of the power flow (PF)
problem for multiterminal hybrid AC/DC networks. The proposed model is an
extension of the standard AC-PF. The DC network is treated as an AC one and, in
addition to the Slack, PV and PQ nodes, four new node types are introduced to
model the DC buses and the buses connecting the AC/DC interfacing converters
(IC). The unified model is solved using the Newton-Raphson method. The extended
PF equations can be used in the presence of multiple ICs operating under
different control modes. Compared to other recent works, the proposed method
allows multiple ICs to regulate the DC voltage simultaneously. This corresponds
to more realistic operational conditions that ensure redundancy and allow for
more flexible control of the hybrid grid. The proposed model can be used for
networks under unbalanced conditions and allows for an intentionally negative
sequence power injection. In addition to the operational advantages of this
method, it is shown that the computational performance of the proposed method
is one order of magnitude better than that of other methods presented in the
existing recent literature while having the same accuracy.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16859" title="Abstract">arXiv:2309.16859</a> [<a href="/pdf/2309.16859" title="Download PDF">pdf</a>, <a href="/format/2309.16859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preface: A Data-driven Volumetric Prior for Few-shot Ultra  High-resolution Face Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%BChler%2C+M+C">Marcel C. B&#xfc;hler</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+K">Kripasindhu Sarkar</a> (2), 
<a href="/search/cs?searchtype=author&query=Shah%2C+T">Tanmay Shah</a> (2), 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gengyan Li</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Daoye Wang</a> (2), 
<a href="/search/cs?searchtype=author&query=Helminger%2C+L">Leonhard Helminger</a> (2), 
<a href="/search/cs?searchtype=author&query=Orts-Escolano%2C+S">Sergio Orts-Escolano</a> (2), 
<a href="/search/cs?searchtype=author&query=Lagun%2C+D">Dmitry Lagun</a> (2), 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a> (1), 
<a href="/search/cs?searchtype=author&query=Beeler%2C+T">Thabo Beeler</a> (2), 
<a href="/search/cs?searchtype=author&query=Meka%2C+A">Abhimitra Meka</a> (2) ((1) ETH Zurich, (2) Google)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">NeRFs have enabled highly realistic synthesis of human faces including
complex appearance and reflectance effects of hair and skin. These methods
typically require a large number of multi-view input images, making the process
hardware intensive and cumbersome, limiting applicability to unconstrained
settings. We propose a novel volumetric human face prior that enables the
synthesis of ultra high-resolution novel views of subjects that are not part of
the prior's training distribution. This prior model consists of an
identity-conditioned NeRF, trained on a dataset of low-resolution multi-view
images of diverse humans with known camera calibration. A simple sparse
landmark-based 3D alignment of the training dataset allows our model to learn a
smooth latent space of geometry and appearance despite a limited number of
training identities. A high-quality volumetric representation of a novel
subject can be obtained by model fitting to 2 or 3 camera views of arbitrary
resolution. Importantly, our method requires as few as two views of casually
captured images as input at inference time.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16862" title="Abstract">arXiv:2309.16862</a> [<a href="/pdf/2309.16862" title="Download PDF">pdf</a>, <a href="/format/2309.16862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Implicit Neural Signed Distance Functions for Safe Motion  Planning under Sensing Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quintero-Pe%C3%B1a%2C+C">Carlos Quintero-Pe&#xf1;a</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+W">Wil Thomason</a>, 
<a href="/search/cs?searchtype=author&query=Kingston%2C+Z">Zachary Kingston</a>, 
<a href="/search/cs?searchtype=author&query=Kyrillidis%2C+A">Anastasios Kyrillidis</a>, 
<a href="/search/cs?searchtype=author&query=Kavraki%2C+L+E">Lydia E. Kavraki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 1 table. Submitted to the 2024 IEEE International Conference on Robotics and Automation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Motion planning under sensing uncertainty is critical for robots in
unstructured environments to guarantee safety for both the robot and any nearby
humans. Most work on planning under uncertainty does not scale to
high-dimensional robots such as manipulators, assumes simplified geometry of
the robot or environment, or requires per-object knowledge of noise. Instead,
we propose a method that directly models sensor-specific aleatoric uncertainty
to find safe motions for high-dimensional systems in complex environments,
without exact knowledge of environment geometry. We combine a novel implicit
neural model of stochastic signed distance functions with a hierarchical
optimization-based motion planner to plan low-risk motions without sacrificing
path quality. Our method also explicitly bounds the risk of the path, offering
trustworthiness. We empirically validate that our method produces safe motions
and accurate risk bounds and is safer than baseline approaches.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16866" title="Abstract">arXiv:2309.16866</a> [<a href="/pdf/2309.16866" title="Download PDF">pdf</a>, <a href="/format/2309.16866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Digital Twin for Copy Detection Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belousov%2C+Y">Yury Belousov</a>, 
<a href="/search/cs?searchtype=author&query=Taran%2C+O">Olga Taran</a>, 
<a href="/search/cs?searchtype=author&query=Kinakh%2C+V">Vitaliy Kinakh</a>, 
<a href="/search/cs?searchtype=author&query=Voloshynovskiy%2C+S">Slava Voloshynovskiy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at the IEEE International Workshop on Information Forensics and Security (WIFS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Copy detection patterns (CDP) present an efficient technique for product
protection against counterfeiting. However, the complexity of studying CDP
production variability often results in time-consuming and costly procedures,
limiting CDP scalability. Recent advancements in computer modelling, notably
the concept of a "digital twin" for printing-imaging channels, allow for
enhanced scalability and the optimization of authentication systems. Yet, the
development of an accurate digital twin is far from trivial.
<br />This paper extends previous research which modelled a printing-imaging
channel using a machine learning-based digital twin for CDP. This model, built
upon an information-theoretic framework known as "Turbo", demonstrated superior
performance over traditional generative models such as CycleGAN and pix2pix.
However, the emerging field of Denoising Diffusion Probabilistic Models (DDPM)
presents a potential advancement in generative models due to its ability to
stochastically model the inherent randomness of the printing-imaging process,
and its impressive performance in image-to-image translation tasks.
<br />This study aims at comparing the capabilities of the Turbo framework and DDPM
on the same CDP datasets, with the goal of establishing the real-world benefits
of DDPM models for digital twin applications in CDP security. Furthermore, the
paper seeks to evaluate the generative potential of the studied models in the
context of mobile phone data acquisition. Despite the increased complexity of
DDPM methods when compared to traditional approaches, our study highlights
their advantages and explores their potential for future applications.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16868" title="Abstract">arXiv:2309.16868</a> [<a href="/pdf/2309.16868" title="Download PDF">pdf</a>, <a href="/format/2309.16868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytically Computation of Sensitivity Coefficients in Hybrid AC/DC  Micro-Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lambrichts%2C+W">Willem Lambrichts</a>, 
<a href="/search/eess?searchtype=author&query=Paolone%2C+M">Mario Paolone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we present a generic and exact (i.e. non-approximated) method
for the analytical computation of the sensitivity coefficient (SC) of hybrid
AC-DC micro-grids. The sensitivity coefficients are used to linearize the grid
constraints in the Optimal Power Flow (OPF) problem and are traditionally
computed by computing the inverse of the Jacobian of the power flow equations.
The proposed method allows for a fast computation of the SC in hybrid AC/DC
systems and allows to solve the OPF problem with a sub-second time resolution.
The proposed method is an extension of the standard AC-SC theory. The DC
network is treated as an AC one and, in addition to the Slack, PV and PQ nodes,
four new node types are introduced. The methodology can be used in the presence
of multiple AC/DC interfacing converters operating under different control
modes.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16869" title="Abstract">arXiv:2309.16869</a> [<a href="/pdf/2309.16869" title="Download PDF">pdf</a>, <a href="/format/2309.16869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vidaptive: Efficient and Responsive Rate Control for Real-Time Video on  Variable Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karimi%2C+P">Pantea Karimi</a>, 
<a href="/search/cs?searchtype=author&query=Fouladi%2C+S">Sadjad Fouladi</a>, 
<a href="/search/cs?searchtype=author&query=Sivaraman%2C+V">Vibhaalakshmi Sivaraman</a>, 
<a href="/search/cs?searchtype=author&query=Alizadeh%2C+M">Mohammad Alizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Real-time video streaming relies on rate control mechanisms to adapt video
bitrate to network capacity while maintaining high utilization and low delay.
However, the current video rate controllers, such as Google Congestion Control
(GCC) in WebRTC, are very slow to respond to network changes, leading to link
under-utilization and latency spikes. While recent delay-based congestion
control algorithms promise high efficiency and rapid adaptation to variable
conditions, low-latency video applications have been unable to adopt these
schemes due to the intertwined relationship between video encoders and rate
control in current systems.
<br />This paper introduces Vidaptive, a new rate control mechanism designed for
low-latency video applications. Vidaptive decouples packet transmission
decisions from encoder output, injecting dummy padding traffic as needed to
treat video streams akin to backlogged flows controlled by a delay-based
congestion controller. Vidaptive then adapts the frame rate, resolution, and
target bitrate of the encoder to align the video bitrate with the congestion
controller's sending rate. Our evaluations atop WebRTC show that, across a set
of cellular traces, Vidaptive achieves ~2x higher video bitrate and 1.6 dB
higher PSNR, and it reduces 95th-percentile frame latency by 2.7s with a slight
increase in median frame latency.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16870" title="Abstract">arXiv:2309.16870</a> [<a href="/pdf/2309.16870" title="Download PDF">pdf</a>, <a href="/format/2309.16870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEF: Late-to-Early Temporal Fusion for LiDAR 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Pei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+Z">Zhaoqi Leng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Anguelov%2C+D">Dragomir Anguelov</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingxing Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">We propose a late-to-early recurrent feature fusion scheme for 3D object
detection using temporal LiDAR point clouds. Our main motivation is fusing
object-aware latent embeddings into the early stages of a 3D object detector.
This feature fusion strategy enables the model to better capture the shapes and
poses for challenging objects, compared with learning from raw points directly.
Our method conducts late-to-early feature fusion in a recurrent manner. This is
achieved by enforcing window-based attention blocks upon temporally calibrated
and aligned sparse pillar tokens. Leveraging bird's eye view foreground pillar
segmentation, we reduce the number of sparse history features that our model
needs to fuse into its current frame by 10$\times$. We also propose a
stochastic-length FrameDrop training technique, which generalizes the model to
variable frame lengths at inference for improved performance without
retraining. We evaluate our method on the widely adopted Waymo Open Dataset and
demonstrate improvement on 3D object detection against the baseline model,
especially for the challenging category of large objects.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16873" title="Abstract">arXiv:2309.16873</a> [<a href="/pdf/2309.16873" title="Download PDF">pdf</a>, <a href="/format/2309.16873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Object Interactions with Behavior Primitives: An Application  in Stowing Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haonan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yilong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Kaiwen Hong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuijing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yunzhu">Yunzhu</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, Accepted for an oral presentation at CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Stowing, the task of placing objects in cluttered shelves or bins, is a
common task in warehouse and manufacturing operations. However, this task is
still predominantly carried out by human workers as stowing is challenging to
automate due to the complex multi-object interactions and long-horizon nature
of the task. Previous works typically involve extensive data collection and
costly human labeling of semantic priors across diverse object categories. This
paper presents a method to learn a generalizable robot stowing policy from
predictive model of object interactions and a single demonstration with
behavior primitives. We propose a novel framework that utilizes Graph Neural
Networks to predict object interactions within the parameter space of
behavioral primitives. We further employ primitive-augmented trajectory
optimization to search the parameters of a predefined library of heterogeneous
behavioral primitives to instantiate the control action. Our framework enables
robots to proficiently execute long-horizon stowing tasks with a few keyframes
(3-4) from a single demonstration. Despite being solely trained in a
simulation, our framework demonstrates remarkable generalization capabilities.
It efficiently adapts to a broad spectrum of real-world conditions, including
various shelf widths, fluctuating quantities of objects, and objects with
diverse attributes such as sizes and shapes.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16874" title="Abstract">arXiv:2309.16874</a> [<a href="/pdf/2309.16874" title="Download PDF">pdf</a>, <a href="/format/2309.16874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sandwich Approach for Motion Planning and Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+M">Mohamadreza Ramezani</a>, 
<a href="/search/cs?searchtype=author&query=Rastgoftar%2C+H">Hossein Rastgoftar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper develops a new approach for robot motion planning and control in
obstacle-laden environments that is inspired by fundamentals of fluid
mechanics. For motion planning, we propose a novel transformation between
motion space, with arbitrary obstacles of random sizes and shapes, and an
obstacle-free planning space with geodesically-varying distances and
constrained transitions. We then obtain robot desired trajectory by A*
searching over a uniform grid distributed over the planning space. We show that
implementing the A* search over the planning space can generate shorter paths
when compared to the existing A* searching over the motion space. For
trajectory tracking, we propose an MPC-based trajectory tracking control, with
linear equality and inequality safety constraints, enforcing the safety
requirements of planning and control.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16876" title="Abstract">arXiv:2309.16876</a> [<a href="/pdf/2309.16876" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Efficiency of Software-only Techniques to Detect SEU and  SET in Microprocessors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azambuja%2C+J+R">Jose Rodrigo Azambuja</a>, 
<a href="/search/cs?searchtype=author&query=Sousa%2C+F">Fernando Sousa</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+L">Lucas Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Kastensmidt%2C+F+L">Fernanda Lima Kastensmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Latin American Symposium on Circuits and Systems 2010
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">This paper presents a detailed evaluation of the efficiency of software-only
techniques to mitigate SEU and SET in microprocessors. A set of well-known
rules is presented and implemented automatically to transform an unprotected
program into a hardened one. SEU and SET are injected in all sensitive areas of
a MIPS-based microprocessor architecture. The efficiency of each rule and a
combination of them are tested. Experimental results show the inefficiency of
the control-flow techniques in detecting the majority of SEU and SET faults.
Three effects of the non-detected faults are explained. The conclusions can
lead designers in developing more efficient techniques to detect these types of
faults.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16878" title="Abstract">arXiv:2309.16878</a> [<a href="/pdf/2309.16878" title="Download PDF">pdf</a>, <a href="/format/2309.16878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Human-Identifiable Features Hidden in Adversarial  Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menn%2C+D+Y">Dennis Y. Menn</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tzu-hsun Feng</a>, 
<a href="/search/cs?searchtype=author&query=Vishwanath%2C+S">Sriram Vishwanath</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Neural networks perform exceedingly well across various machine learning
tasks but are not immune to adversarial perturbations. This vulnerability has
implications for real-world applications. While much research has been
conducted, the underlying reasons why neural networks fall prey to adversarial
attacks are not yet fully understood. Central to our study, which explores up
to five attack algorithms across three datasets, is the identification of
human-identifiable features in adversarial perturbations. Additionally, we
uncover two distinct effects manifesting within human-identifiable features.
Specifically, the masking effect is prominent in untargeted attacks, while the
generation effect is more common in targeted attacks. Using pixel-level
annotations, we extract such features and demonstrate their ability to
compromise target models. In addition, our findings indicate a notable extent
of similarity in perturbations across different attack algorithms when averaged
over multiple models. This work also provides insights into phenomena
associated with adversarial perturbations, such as transferability and model
interpretability. Our study contributes to a deeper understanding of the
underlying mechanisms behind adversarial attacks and offers insights for the
development of more resilient defense strategies for neural networks.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16880" title="Abstract">arXiv:2309.16880</a> [<a href="/pdf/2309.16880" title="Download PDF">pdf</a>, <a href="/ps/2309.16880" title="Download PostScript">ps</a>, <a href="/format/2309.16880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near Delay-Optimal Scheduling of Batch Jobs in Multi-Server Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Koksal%2C+C+E">C. Emre Koksal</a>, 
<a href="/search/cs?searchtype=author&query=Shroff%2C+N+B">Ness B. Shroff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint prepared in 2017. arXiv admin note: substantial text overlap with <a href="/abs/1603.07322">arXiv:1603.07322</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Optimization and Control (math.OC); Probability (math.PR)

</div>
<p class="mathjax">We study a class of scheduling problems, where each job is divided into a
batch of unit-size tasks and these tasks can be executed in parallel on
multiple servers with New-Better-than-Used (NBU) service time distributions.
While many delay optimality results are available for single-server queueing
systems, generalizing these results to the multi-server case has been
challenging. This motivated us to investigate near delay-optimal scheduling of
batch jobs in multi-server queueing systems. We consider three lowcomplexity
scheduling policies: the Fewest Unassigned Tasks first (FUT) policy, the
Earliest Due Date first (EDD) policy, and the First-Come, First-Served (FCFS)
policy. We prove that for arbitrary number, batch sizes, arrival times, and due
times of the jobs, these scheduling policies are near delay-optimal in
stochastic ordering for minimizing three classes of delay metrics among all
causal and non-preemptive policies. In particular, the FUT policy is within a
constant additive delay gap from the optimum for minimizing the mean average
delay, and the FCFS policy within twice of the optimum for minimizing the mean
maximum delay and the mean p-norm of delay. The key proof tools are several
novel samplepath orderings, which can be used to compare the sample-path delay
of different policies in a near-optimal sense.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16882" title="Abstract">arXiv:2309.16882</a> [<a href="/pdf/2309.16882" title="Download PDF">pdf</a>, <a href="/format/2309.16882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Message Propagation Through Time: An Algorithm for Sequence Dependency  Retention in Time Series Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaoming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+A">Ankush Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Renganathan%2C+A">Arvind Renganathan</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vipin Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time series modeling, a crucial area in science, often encounters challenges
when training Machine Learning (ML) models like Recurrent Neural Networks
(RNNs) using the conventional mini-batch training strategy that assumes
independent and identically distributed (IID) samples and initializes RNNs with
zero hidden states. The IID assumption ignores temporal dependencies among
samples, resulting in poor performance. This paper proposes the Message
Propagation Through Time (MPTT) algorithm to effectively incorporate long
temporal dependencies while preserving faster training times relative to the
stateful solutions. MPTT utilizes two memory modules to asynchronously manage
initial hidden states for RNNs, fostering seamless information exchange between
samples and allowing diverse mini-batches throughout epochs. MPTT further
implements three policies to filter outdated and preserve essential information
in the hidden states to generate informative initial hidden states for RNNs,
facilitating robust training. Experimental results demonstrate that MPTT
outperforms seven strategies on four climate datasets with varying levels of
temporal dependencies.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16883" title="Abstract">arXiv:2309.16883</a> [<a href="/pdf/2309.16883" title="Download PDF">pdf</a>, <a href="/format/2309.16883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delattre%2C+B">Blaise Delattre</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+A">Alexandre Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Barth%C3%A9lemy%2C+Q">Quentin Barth&#xe9;lemy</a>, 
<a href="/search/cs?searchtype=author&query=Allauzen%2C+A">Alexandre Allauzen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Real-life applications of deep neural networks are hindered by their unsteady
predictions when faced with noisy inputs and adversarial attacks. The certified
radius is in this context a crucial indicator of the robustness of models.
However how to design an efficient classifier with a sufficient certified
radius? Randomized smoothing provides a promising framework by relying on noise
injection in inputs to obtain a smoothed and more robust classifier. In this
paper, we first show that the variance introduced by randomized smoothing
closely interacts with two other important properties of the classifier, i.e.
its Lipschitz constant and margin. More precisely, our work emphasizes the dual
impact of the Lipschitz constant of the base classifier, on both the smoothed
classifier and the empirical variance. Moreover, to increase the certified
robust radius, we introduce a different simplex projection technique for the
base classifier to leverage the variance-margin trade-off thanks to Bernstein's
concentration inequality, along with an enhanced Lipschitz bound. Experimental
results show a significant improvement in certified accuracy compared to
current state-of-the-art methods. Our novel certification procedure allows us
to use pre-trained models that are used with randomized smoothing, effectively
improving the current certification radius in a zero-shot manner.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16884" title="Abstract">arXiv:2309.16884</a> [<a href="/pdf/2309.16884" title="Download PDF">pdf</a>, <a href="/format/2309.16884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An MCTS-DRL Based Obstacle and Occlusion Avoidance Methodology in  Robotic Follow-Ahead Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leisiazar%2C+S">Sahar Leisiazar</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E+J">Edward J. Park</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+A">Angelica Lim</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mo Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We propose a novel methodology for robotic follow-ahead applications that
address the critical challenge of obstacle and occlusion avoidance. Our
approach effectively navigates the robot while ensuring avoidance of collisions
and occlusions caused by surrounding objects. To achieve this, we developed a
high-level decision-making algorithm that generates short-term navigational
goals for the mobile robot. Monte Carlo Tree Search is integrated with a Deep
Reinforcement Learning method to enhance the performance of the decision-making
process and generate more reliable navigational goals. Through extensive
experimentation and analysis, we demonstrate the effectiveness and superiority
of our proposed approach in comparison to the existing follow-ahead
human-following robotic methods. Our code is available at
https://github.com/saharLeisiazar/follow-ahead-ros.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16887" title="Abstract">arXiv:2309.16887</a> [<a href="/pdf/2309.16887" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Platformization of Inequality: Gender and Race in Digital Labor  Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munoz%2C+I">Isabel Munoz</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+P">Pyeonghwa Kim</a>, 
<a href="/search/cs?searchtype=author&query=O%27Neil%2C+C">Clea O&#x27;Neil</a>, 
<a href="/search/cs?searchtype=author&query=Dunn%2C+M">Michael Dunn</a>, 
<a href="/search/cs?searchtype=author&query=Sawyer%2C+S">Steve Sawyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PAPER WAS ACCEPTED AT CSCW ON SEPTEMBER 2023, 21 PAGES, 2 FIGURES
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We contribute empirical and conceptual insights regarding the roles of
digital labor platforms in online freelancing, focusing attention to social
identities such as gender, race, ethnicity, and occupation. Findings highlight
how digital labor platforms reinforce and exacerbate identity-based
stereotypes, bias and expectations in online freelance work. We focus on online
freelancing as this form of working arrangement is becoming more prevalent.
Online freelancing also relies on the market-making power of digital platforms
to create an online labor market. Many see this as one likely future of work
with less bias. Others worry that labor platforms' market power allows them to
embed known biases into new working arrangements: a platformization of
inequality. Drawing on data from 108 online freelancers, we discuss six
findings: 1) female freelance work is undervalued; 2) gendered occupational
expectations; 3) gendered treatment; 4) shared expectations of differential
values; 5) racial stereotypes and expectations; and 6) race and ethnicity as an
asset. We discuss the role of design in the platformization and visibility of
social identity dimensions and the implications of the reinforced identity
perceptions and marginalization in digital labor platforms.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16888" title="Abstract">arXiv:2309.16888</a> [<a href="/pdf/2309.16888" title="Download PDF">pdf</a>, <a href="/format/2309.16888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sourcing Investment Targets for Venture and Growth Capital Using  Multivariate Time Series Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lele Cao</a>, 
<a href="/search/cs?searchtype=author&query=Halvardsson%2C+G">Gustaf Halvardsson</a>, 
<a href="/search/cs?searchtype=author&query=McCornack%2C+A">Andrew McCornack</a>, 
<a href="/search/cs?searchtype=author&query=von+Ehrenheim%2C+V">Vilhelm von Ehrenheim</a>, 
<a href="/search/cs?searchtype=author&query=Herman%2C+P">Pawel Herman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Portfolio Management (q-fin.PM)

</div>
<p class="mathjax">This paper addresses the growing application of data-driven approaches within
the Private Equity (PE) industry, particularly in sourcing investment targets
(i.e., companies) for Venture Capital (VC) and Growth Capital (GC). We present
a comprehensive review of the relevant approaches and propose a novel approach
leveraging a Transformer-based Multivariate Time Series Classifier (TMTSC) for
predicting the success likelihood of any candidate company. The objective of
our research is to optimize sourcing performance for VC and GC investments by
formally defining the sourcing problem as a multivariate time series
classification task. We consecutively introduce the key components of our
implementation which collectively contribute to the successful application of
TMTSC in VC/GC sourcing: input features, model architecture, optimization
target, and investor-centric data augmentation and split. Our extensive
experiments on four datasets, benchmarked towards three popular baselines,
demonstrate the effectiveness of our approach in improving decision making
within the VC and GC industry.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16889" title="Abstract">arXiv:2309.16889</a> [<a href="/pdf/2309.16889" title="Download PDF">pdf</a>, <a href="/format/2309.16889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Superpixel Transformers for Efficient Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+A+Z">Alex Zihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jieru Mei</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+S">Siyuan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yukun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang-Chieh Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kretzschmar%2C+H">Henrik Kretzschmar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 4 tables. Presented at IROS 2023. Equal contribution by A. Zhu and J. Mei
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation, which aims to classify every pixel in an image, is a
key task in machine perception, with many applications across robotics and
autonomous driving. Due to the high dimensionality of this task, most existing
approaches use local operations, such as convolutions, to generate per-pixel
features. However, these methods are typically unable to effectively leverage
global context information due to the high computational costs of operating on
a dense image. In this work, we propose a solution to this issue by leveraging
the idea of superpixels, an over-segmentation of the image, and applying them
with a modern transformer framework. In particular, our model learns to
decompose the pixel space into a spatially low dimensional superpixel space via
a series of local cross-attentions. We then apply multi-head self-attention to
the superpixels to enrich the superpixel features with global context and then
directly produce a class prediction for each superpixel. Finally, we directly
project the superpixel class predictions back into the pixel space using the
associations between the superpixels and the image pixel features. Reasoning in
the superpixel space allows our method to be substantially more computationally
efficient compared to convolution-based decoder methods. Yet, our method
achieves state-of-the-art performance in semantic segmentation due to the rich
superpixel features generated by the global self-attention mechanism. Our
experiments on Cityscapes and ADE20K demonstrate that our method matches the
state of the art in terms of accuracy, while outperforming in terms of model
parameters and latency.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16892" title="Abstract">arXiv:2309.16892</a> [<a href="/pdf/2309.16892" title="Download PDF">pdf</a>, <a href="/format/2309.16892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernels for the Disjoint Paths Problem on Subclasses of Chordal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+J">Juhi Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Gahlawat%2C+H">Harmender Gahlawat</a>, 
<a href="/search/cs?searchtype=author&query=W%C5%82odarczyk%2C+M">Michal W&#x142;odarczyk</a>, 
<a href="/search/cs?searchtype=author&query=Zehavi%2C+M">Meirav Zehavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of this paper will appear in the Proceedings of IPEC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Given an undirected graph $G$ and a multiset of $k$ terminal pairs
$\mathcal{X}$, the Vertex-Disjoint Paths (\VDP) and Edge-Disjoint Paths (\EDP)
problems ask whether $G$ has $k$ pairwise internally vertex-disjoint paths and
$k$ pairwise edge-disjoint paths, respectively, connecting every terminal pair
in~$\mathcal{X}$. In this paper, we study the kernelization complexity of
\VDP~and~\EDP~on subclasses of chordal graphs. For \VDP, we design a $4k$
vertex kernel on split graphs and an $\mathcal{O}(k^2)$ vertex kernel on
well-partitioned chordal graphs. We also show that the problem becomes
polynomial-time solvable on threshold graphs. For \textsc{EDP}, we first prove
that the problem is $\mathsf{NP}$-complete on complete graphs. Then, we design
an $\mathcal{O}(k^{2.75})$ vertex kernel for \EDP~on split graphs, and improve
it to a $7k+1$ vertex kernel on threshold graphs. Lastly, we provide an
$\mathcal{O}(k^2)$ vertex kernel for \EDP~on block graphs and a $2k+1$ vertex
kernel for clique paths. Our contributions improve upon several results in the
literature, as well as resolve an open question by Heggernes et al.~[Theory
Comput. Syst., 2015].
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16896" title="Abstract">arXiv:2309.16896</a> [<a href="/pdf/2309.16896" title="Download PDF">pdf</a>, <a href="/format/2309.16896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic Recourse for Anomaly Detection in Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongkai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuhan Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Anomaly detection in multivariate time series has received extensive study
due to the wide spectrum of applications. An anomaly in multivariate time
series usually indicates a critical event, such as a system fault or an
external attack. Therefore, besides being effective in anomaly detection,
recommending anomaly mitigation actions is also important in practice yet
under-investigated. In this work, we focus on algorithmic recourse in time
series anomaly detection, which is to recommend fixing actions on abnormal time
series with a minimum cost so that domain experts can understand how to fix the
abnormal behavior. To this end, we propose an algorithmic recourse framework,
called RecAD, which can recommend recourse actions to flip the abnormal time
steps. Experiments on two synthetic and one real-world datasets show the
effectiveness of our framework.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16897" title="Abstract">arXiv:2309.16897</a> [<a href="/pdf/2309.16897" title="Download PDF">pdf</a>, <a href="/format/2309.16897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Algorithms for Semirandom Planted CSPs at the Refutation  Threshold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guruswami%2C+V">Venkatesan Guruswami</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+J">Jun-Ting Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Kothari%2C+P+K">Pravesh K. Kothari</a>, 
<a href="/search/cs?searchtype=author&query=Manohar%2C+P">Peter Manohar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We present an efficient algorithm to solve semirandom planted instances of
any Boolean constraint satisfaction problem (CSP). The semirandom model is a
hybrid between worst-case and average-case input models, where the input is
generated by (1) choosing an arbitrary planted assignment $x^*$, (2) choosing
an arbitrary clause structure, and (3) choosing literal negations for each
clause from an arbitrary distribution "shifted by $x^*$" so that $x^*$
satisfies each constraint. For an $n$ variable semirandom planted instance of a
$k$-arity CSP, our algorithm runs in polynomial time and outputs an assignment
that satisfies all but a $o(1)$-fraction of constraints, provided that the
instance has at least $\tilde{O}(n^{k/2})$ constraints. This matches, up to
$polylog(n)$ factors, the clause threshold for algorithms that solve fully
random planted CSPs [FPV15], as well as algorithms that refute random and
semirandom CSPs [AOW15, AGK21]. Our result shows that despite having worst-case
clause structure, the randomness in the literal patterns makes semirandom
planted CSPs significantly easier than worst-case, where analogous results
require $O(n^k)$ constraints [AKK95, FLP16].
<br />Perhaps surprisingly, our algorithm follows a significantly different
conceptual framework when compared to the recent resolution of semirandom CSP
refutation. This turns out to be inherent and, at a technical level, can be
attributed to the need for relative spectral approximation of certain random
matrices - reminiscent of the classical spectral sparsification - which ensures
that an SDP can certify the uniqueness of the planted assignment. In contrast,
in the refutation setting, it suffices to obtain a weaker guarantee of absolute
upper bounds on the spectral norm of related matrices.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16898" title="Abstract">arXiv:2309.16898</a> [<a href="/pdf/2309.16898" title="Download PDF">pdf</a>, <a href="/format/2309.16898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sign Language Recognition System with Pepper, Lightweight-Transformer,  and LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+J">JongYoon Lim</a>, 
<a href="/search/cs?searchtype=author&query=Sa%2C+I">Inkyu Sa</a>, 
<a href="/search/cs?searchtype=author&query=MacDonald%2C+B">Bruce MacDonald</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+H+S">Ho Seok Ahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This research explores using lightweight deep neural network architectures to
enable the humanoid robot Pepper to understand American Sign Language (ASL) and
facilitate non-verbal human-robot interaction. First, we introduce a
lightweight and efficient model for ASL understanding optimized for embedded
systems, ensuring rapid sign recognition while conserving computational
resources. Building upon this, we employ large language models (LLMs) for
intelligent robot interactions. Through intricate prompt engineering, we tailor
interactions to allow the Pepper Robot to generate natural Co-Speech Gesture
responses, laying the foundation for more organic and intuitive humanoid-robot
dialogues. Finally, we present an integrated software pipeline, embodying
advancements in a socially aware AI interaction model. Leveraging the Pepper
Robot's capabilities, we demonstrate the practicality and effectiveness of our
approach in real-world scenarios. The results highlight a profound potential
for enhancing human-robot interaction through non-verbal interactions, bridging
communication gaps, and making technology more accessible and understandable.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16899" title="Abstract">arXiv:2309.16899</a> [<a href="/pdf/2309.16899" title="Download PDF">pdf</a>, <a href="/format/2309.16899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Contractivity of Plug-and-Play Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Athalye%2C+C+D">Chirayu D. Athalye</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhury%2C+K+N">Kunal N. Chaudhury</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+B">Bhartendu Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Signal Processing Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In plug-and-play (PnP) regularization, the proximal operator in algorithms
such as ISTA and ADMM is replaced by a powerful denoiser. This formal
substitution works surprisingly well in practice. In fact, PnP has been shown
to give state-of-the-art results for various imaging applications. The
empirical success of PnP has motivated researchers to understand its
theoretical underpinnings and, in particular, its convergence. It was shown in
prior work that for kernel denoisers such as the nonlocal means, PnP-ISTA
provably converges under some strong assumptions on the forward model. The
present work is motivated by the following questions: Can we relax the
assumptions on the forward model? Can the convergence analysis be extended to
PnP-ADMM? Can we estimate the convergence rate? In this letter, we resolve
these questions using the contraction mapping theorem: (i) for symmetric
denoisers, we show that (under mild conditions) PnP-ISTA and PnP-ADMM exhibit
linear convergence; and (ii) for kernel denoisers, we show that PnP-ISTA and
PnP-ADMM converge linearly for image inpainting. We validate our theoretical
findings using reconstruction experiments.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16901" title="Abstract">arXiv:2309.16901</a> [<a href="/pdf/2309.16901" title="Download PDF">pdf</a>, <a href="/format/2309.16901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shortest Paths of Mutually Visible Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alsaedi%2C+R+J">Rusul J. Alsaedi</a>, 
<a href="/search/cs?searchtype=author&query=Gudmundsson%2C+J">Joachim Gudmundsson</a>, 
<a href="/search/cs?searchtype=author&query=van+Renssen%2C+A">Andr&#xe9; van Renssen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Given a set of $n$ point robots inside a simple polygon $P$, the task is to
move the robots from their starting positions to their target positions along
their shortest paths, while the mutual visibility of these robots is preserved.
Previous work only considered two robots. In this paper, we present an $O(mn)$
time algorithm, where $m$ is the complexity of the polygon, when all the
starting positions lie on a line segment $S$, all the target positions lie on a
line segment $T$, and $S$ and $T$ do not intersect. We also argue that there is
no polynomial-time algorithm, whose running time depends only on $n$ and $m$,
that uses a single strategy for the case where $S$ and $T$ intersect.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16902" title="Abstract">arXiv:2309.16902</a> [<a href="/pdf/2309.16902" title="Download PDF">pdf</a>, <a href="/format/2309.16902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Shift Equivalence of Convolutional Neural Networks in  Industrial Defect Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zhen Qu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xian Tao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Fei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengtao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submit to IEEE Transactions on Instrumentation &amp; Measurement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In industrial defect segmentation tasks, while pixel accuracy and
Intersection over Union (IoU) are commonly employed metrics to assess
segmentation performance, the output consistency (also referred to equivalence)
of the model is often overlooked. Even a small shift in the input image can
yield significant fluctuations in the segmentation results. Existing
methodologies primarily focus on data augmentation or anti-aliasing to enhance
the network's robustness against translational transformations, but their shift
equivalence performs poorly on the test set or is susceptible to nonlinear
activation functions. Additionally, the variations in boundaries resulting from
the translation of input images are consistently disregarded, thus imposing
further limitations on the shift equivalence. In response to this particular
challenge, a novel pair of down/upsampling layers called component attention
polyphase sampling (CAPS) is proposed as a replacement for the conventional
sampling layers in CNNs. To mitigate the effect of image boundary variations on
the equivalence, an adaptive windowing module is designed in CAPS to adaptively
filter out the border pixels of the image. Furthermore, a component attention
module is proposed to fuse all downsampled features to improve the segmentation
performance. The experimental results on the micro surface defect (MSD) dataset
and four real-world industrial defect datasets demonstrate that the proposed
method exhibits higher equivalence and segmentation performance compared to
other state-of-the-art methods.Our code will be available at
https://github.com/xiaozhen228/CAPS.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16905" title="Abstract">arXiv:2309.16905</a> [<a href="/pdf/2309.16905" title="Download PDF">pdf</a>, <a href="/format/2309.16905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Unified Framework for Adaptable Problematic Content Detection  via Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Omrani%2C+A">Ali Omrani</a>, 
<a href="/search/cs?searchtype=author&query=Ziabari%2C+A+S">Alireza S. Ziabari</a>, 
<a href="/search/cs?searchtype=author&query=Golazizian%2C+P">Preni Golazizian</a>, 
<a href="/search/cs?searchtype=author&query=Sorensen%2C+J">Jeffery Sorensen</a>, 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+M">Morteza Dehghani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Detecting problematic content, such as hate speech, is a multifaceted and
ever-changing task, influenced by social dynamics, user populations, diversity
of sources, and evolving language. There has been significant efforts, both in
academia and in industry, to develop annotated resources that capture various
aspects of problematic content. Due to researchers' diverse objectives, the
annotations are inconsistent and hence, reports of progress on detection of
problematic content are fragmented. This pattern is expected to persist unless
we consolidate resources considering the dynamic nature of the problem. We
propose integrating the available resources, and leveraging their dynamic
nature to break this pattern. In this paper, we introduce a continual learning
benchmark and framework for problematic content detection comprising over 84
related tasks encompassing 15 annotation schemas from 8 sources. Our benchmark
creates a novel measure of progress: prioritizing the adaptability of
classifiers to evolving tasks over excelling in specific tasks. To ensure the
continuous relevance of our framework, we designed it so that new tasks can
easily be integrated into the benchmark. Our baseline results demonstrate the
potential of continual learning in capturing the evolving content and adapting
to novel manifestations of problematic content.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16909" title="Abstract">arXiv:2309.16909</a> [<a href="/pdf/2309.16909" title="Download PDF">pdf</a>, <a href="/format/2309.16909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASAP: Automated Sequence Planning for Complex Robotic Assembly with  Physical Feasibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yunsheng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Willis%2C+K+D+D">Karl D.D. Willis</a>, 
<a href="/search/cs?searchtype=author&query=Omari%2C+B+A">Bassel Al Omari</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jieliang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yichen Li</a>, 
<a href="/search/cs?searchtype=author&query=Javid%2C+F">Farhad Javid</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+E">Edward Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+J">Joshua Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Sueda%2C+S">Shinjiro Sueda</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Chitta%2C+S">Sachin Chitta</a>, 
<a href="/search/cs?searchtype=author&query=Matusik%2C+W">Wojciech Matusik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">The automated assembly of complex products requires a system that can
automatically plan a physically feasible sequence of actions for assembling
many parts together. In this paper, we present ASAP, a physics-based planning
approach for automatically generating such a sequence for general-shaped
assemblies. ASAP accounts for gravity to design a sequence where each
sub-assembly is physically stable with a limited number of parts being held and
a support surface. We apply efficient tree search algorithms to reduce the
combinatorial complexity of determining such an assembly sequence. The search
can be guided by either geometric heuristics or graph neural networks trained
on data with simulation labels. Finally, we show the superior performance of
ASAP at generating physically realistic assembly sequence plans on a large
dataset of hundreds of complex product assemblies. We further demonstrate the
applicability of ASAP on both simulation and real-world robotic setups. Project
website: asap.csail.mit.edu
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16911" title="Abstract">arXiv:2309.16911</a> [<a href="/pdf/2309.16911" title="Download PDF">pdf</a>, <a href="/format/2309.16911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Batching of Online Arrivals to Leverage Economies of Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhimaraju%2C+A">Akhil Bhimaraju</a>, 
<a href="/search/cs?searchtype=author&query=Etesami%2C+S+R">S. Rasoul Etesami</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+L+R">Lav R. Varshney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Many settings, such as medical testing of patients in hospitals or matching
riders to drivers in ride-hailing platforms, require handling arrivals over
time. In such applications, it is often beneficial to group the arriving
orders, samples, or requests into batches and process the larger batches rather
than individual arrivals. However, waiting too long to create larger batches
incurs a waiting cost for past arrivals. On the other hand, processing the
arrivals too soon leads to higher processing costs by missing the economies of
scale of grouping larger numbers of arrivals into larger batches. Moreover, the
timing of the next arrival is often unknown, meaning that fixed-size batches or
fixed wait times tend to be suboptimal. In this work, we consider the problem
of finding the optimal batching schedule to minimize the average wait time plus
the average processing cost under both offline and online settings. In the
offline problem in which all arrival times are known a priori, we show that the
optimal batching schedule can be found in polynomial time by reducing it to a
shortest path problem on a weighted acyclic graph. For the online problem with
unknown arrival times, we develop online algorithms that are provably
competitive for a broad range of processing-cost functions. We also provide a
lower bound on the competitive ratio that no online algorithm can beat.
Finally, we run extensive numerical experiments on simulated and real data to
demonstrate the effectiveness of our proposed algorithms against the optimal
offline benchmark.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16913" title="Abstract">arXiv:2309.16913</a> [<a href="/pdf/2309.16913" title="Download PDF">pdf</a>, <a href="/format/2309.16913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIMD-ified R-tree Query Processing and Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rayhan%2C+Y">Yeasir Rayhan</a>, 
<a href="/search/cs?searchtype=author&query=Aref%2C+W+G">Walid G. Aref</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ACM SIGSPATIAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The introduction of Single Instruction Multiple Data (SIMD) instructions in
mainstream CPUs has enabled modern database engines to leverage data
parallelism by performing more computation with a single instruction, resulting
in a reduced number of instructions required to execute a query as well as the
elimination of conditional branches. Though SIMD in the context of traditional
database engines has been studied extensively, it has been overlooked in the
context of spatial databases. In this paper, we investigate how spatial
database engines can benefit from SIMD vectorization in the context of an
R-tree spatial index. We present vectorized versions of the spatial range
select, and spatial join operations over a vectorized R-tree index. For each of
the operations, we investigate two storage layouts for an R-tree node to
leverage SIMD instructions. We design vectorized algorithms for each of the
spatial operations given each of the two data layouts. We show that the
introduction of SIMD can improve the latency of the spatial query operators up
to 9x. We introduce several optimizations over the vectorized implementation of
these query operators, and study their effectiveness in query performance and
various hardware performance counters under different scenarios.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16914" title="Abstract">arXiv:2309.16914</a> [<a href="/pdf/2309.16914" title="Download PDF">pdf</a>, <a href="/ps/2309.16914" title="Download PostScript">ps</a>, <a href="/format/2309.16914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharing the Cost of IoT Wireless Coverage with a Strengthened Linear  Programming Formulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aarts%2C+S">Sander Aarts</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Manxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shmoys%2C+D+B">David B. Shmoys</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Sharing infrastructure between many users is often advantageous, however
finding a fair and reasonable way to allocate its cost between its users can be
challenging. This is particularly true for LPWANs, a popular Internet of Things
solution for wirelessly connecting devices to the internet. We study
cost-allocation of LPWANS using a covering integer program. Standard
cost-allocation methods are inapplicable in this model, because the integrality
gap of its natural LP-relaxation is unbounded. We overcome this challenge by
strengthening the natural LP with knapsack-cover inequalities. Our main result
is proving that all dual-feasible solutions to the strengthened LP produce
cost-allocations that satisfy the core property. This reduces the problem of
finding a cost-allocation to that of finding a strengthened-LP-relative
approximation algorithm. Existing algorithms imply improved cost-recovery
ratios for families of sparse CIP instances. Finally, we show that the
strengthened formulation simplifies and improves the analysis of a
cross-monotone cost-allocation mechanism as well.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16915" title="Abstract">arXiv:2309.16915</a> [<a href="/pdf/2309.16915" title="Download PDF">pdf</a>, <a href="/format/2309.16915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vistrust: a Multidimensional Framework and Empirical Study of Trust in  Data Visualizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elhamdadi%2C+H">Hamza Elhamdadi</a>, 
<a href="/search/cs?searchtype=author&query=Stefkovics%2C+A">Adam Stefkovics</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+J">Johanna Beyer</a>, 
<a href="/search/cs?searchtype=author&query=Moerth%2C+E">Eric Moerth</a>, 
<a href="/search/cs?searchtype=author&query=Bearfield%2C+C+X">Cindy Xiong Bearfield</a>, 
<a href="/search/cs?searchtype=author&query=Nobre%2C+C">Carolina Nobre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 Pages, IEEE VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Trust is an essential aspect of data visualization, as it plays a crucial
role in the interpretation and decision-making processes of users. While
research in social sciences outlines the multi-dimensional factors that can
play a role in trust formation, most data visualization trust researchers
employ a single-item scale to measure trust. We address this gap by proposing a
comprehensive, multidimensional conceptualization and operationalization of
trust in visualization. We do this by applying general theories of trust from
social sciences, as well as synthesizing and extending earlier work and factors
identified by studies in the visualization field. We apply a two-dimensional
approach to trust in visualization, to distinguish between cognitive and
affective elements, as well as between visualization and data-specific trust
antecedents. We use our framework to design and run a large crowd-sourced study
to quantify the role of visual complexity in establishing trust in science
visualizations. Our study provides empirical evidence for several aspects of
our proposed theoretical framework, most notably the impact of cognition,
affective responses, and individual differences when establishing trust in
visualizations.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16916" title="Abstract">arXiv:2309.16916</a> [<a href="/pdf/2309.16916" title="Download PDF">pdf</a>, <a href="/format/2309.16916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ONNXExplainer: an ONNX Based Generic Framework to Explain Neural  Networks Using Shapley Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Runxin He</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+N">Nicholas Kersting</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Can Liu</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+S">Shubham Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Chetia%2C+C">Chiranjeet Chetia</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Understanding why a neural network model makes certain decisions can be as
important as the inference performance. Various methods have been proposed to
help practitioners explain the prediction of a neural network model, of which
Shapley values are most popular. SHAP package is a leading implementation of
Shapley values to explain neural networks implemented in TensorFlow or PyTorch
but lacks cross-platform support, one-shot deployment and is highly
inefficient. To address these problems, we present the ONNXExplainer, which is
a generic framework to explain neural networks using Shapley values in the ONNX
ecosystem. In ONNXExplainer, we develop its own automatic differentiation and
optimization approach, which not only enables One-Shot Deployment of neural
networks inference and explanations, but also significantly improves the
efficiency to compute explanation with less memory consumption. For fair
comparison purposes, we also implement the same optimization in TensorFlow and
PyTorch and measure its performance against the current state of the art
open-source counterpart, SHAP. Extensive benchmarks demonstrate that the
proposed optimization approach improves the explanation latency of VGG19,
ResNet50, DenseNet201, and EfficientNetB0 by as much as 500%.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16918" title="Abstract">arXiv:2309.16918</a> [<a href="/pdf/2309.16918" title="Download PDF">pdf</a>, <a href="/format/2309.16918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACGAN-GNNExplainer: Auxiliary Conditional Generative Explainer for Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiqiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianlong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yifei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Shafiabady%2C+N">Niusha Shafiabady</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph neural networks (GNNs) have proven their efficacy in a variety of
real-world applications, but their underlying mechanisms remain a mystery. To
address this challenge and enable reliable decision-making, many GNN explainers
have been proposed in recent years. However, these methods often encounter
limitations, including their dependence on specific instances, lack of
generalizability to unseen graphs, producing potentially invalid explanations,
and yielding inadequate fidelity. To overcome these limitations, we, in this
paper, introduce the Auxiliary Classifier Generative Adversarial Network
(ACGAN) into the field of GNN explanation and propose a new GNN explainer
dubbed~\emph{ACGAN-GNNExplainer}. Our approach leverages a generator to produce
explanations for the original input graphs while incorporating a discriminator
to oversee the generation process, ensuring explanation fidelity and improving
accuracy. Experimental evaluations conducted on both synthetic and real-world
graph datasets demonstrate the superiority of our proposed method compared to
other existing GNN explainers.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16921" title="Abstract">arXiv:2309.16921</a> [<a href="/pdf/2309.16921" title="Download PDF">pdf</a>, <a href="/format/2309.16921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOLOR-Based Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hung-Shuo Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chien-Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R+R">Richard Robert Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+G">Gene Chou</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H+M">Hong-Yuan Mark Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-task learning (MTL) aims to learn multiple tasks using a single model
and jointly improve all of them assuming generalization and shared semantics.
Reducing conflicts between tasks during joint learning is difficult and
generally requires careful network design and extremely large models. We
propose building on You Only Learn One Representation (YOLOR), a network
architecture specifically designed for multitasking. YOLOR leverages both
explicit and implicit knowledge, from data observations and learned latents,
respectively, to improve a shared representation while minimizing the number of
training parameters. However, YOLOR and its follow-up, YOLOv7, only trained two
tasks at once. In this paper, we jointly train object detection, instance
segmentation, semantic segmentation, and image captioning. We analyze tradeoffs
and attempt to maximize sharing of semantic information. Through our
architecture and training strategies, we find that our method achieves
competitive performance on all tasks while maintaining a low parameter count
and without any pre-training. We will release code soon.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16923" title="Abstract">arXiv:2309.16923</a> [<a href="/pdf/2309.16923" title="Download PDF">pdf</a>, <a href="/format/2309.16923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mode Connectivity and Data Heterogeneity of Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tailin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+D+H+K">Danny H.K. Tsang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning (FL) enables multiple clients to train a model while
keeping their data private collaboratively. Previous studies have shown that
data heterogeneity between clients leads to drifts across client updates.
However, there are few studies on the relationship between client and global
modes, making it unclear where these updates end up drifting. We perform
empirical and theoretical studies on this relationship by utilizing mode
connectivity, which measures performance change (i.e., connectivity) along
parametric paths between different modes. Empirically, reducing data
heterogeneity makes the connectivity on different paths more similar, forming
more low-error overlaps between client and global modes. We also find that a
barrier to connectivity occurs when linearly connecting two global modes, while
it disappears with considering non-linear mode connectivity. Theoretically, we
establish a quantitative bound on the global-mode connectivity using mean-field
theory or dropout stability. The bound demonstrates that the connectivity
improves when reducing data heterogeneity and widening trained models.
Numerical results further corroborate our analytical findings.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16924" title="Abstract">arXiv:2309.16924</a> [<a href="/pdf/2309.16924" title="Download PDF">pdf</a>, <a href="/format/2309.16924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Rotation Averaging Revisited and More: A New Rotation  Averaging Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hainan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shuhan Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In order to further advance the accuracy and robustness of the incremental
parameter estimation-based rotation averaging methods, in this paper, a new
member of the Incremental Rotation Averaging (IRA) family is introduced, which
is termed as IRAv4. As the most significant feature of the IRAv4, a
task-specific connected dominating set is extracted to serve as a more reliable
and accurate reference for rotation global alignment. In addition, to further
address the limitations of the existing rotation averaging benchmark of relying
on the slightly outdated Bundler camera calibration results as ground truths
and focusing solely on rotation estimation accuracy, this paper presents a new
COLMAP-based rotation averaging benchmark that incorporates a cross check
between COLMAP and Bundler, and employ the accuracy of both rotation and
downstream location estimation as evaluation metrics, which is desired to
provide a more reliable and comprehensive evaluation tool for the rotation
averaging research. Comprehensive comparisons between the proposed IRAv4 and
other mainstream rotation averaging methods on this new benchmark demonstrate
the effectiveness of our proposed approach.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16928" title="Abstract">arXiv:2309.16928</a> [<a href="/pdf/2309.16928" title="Download PDF">pdf</a>, <a href="/format/2309.16928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Receive Help: Intervention-Aware Concept Embedding Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zarlenga%2C+M+E">Mateo Espinosa Zarlenga</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+K+M">Katherine M. Collins</a>, 
<a href="/search/cs?searchtype=author&query=Dvijotham%2C+K">Krishnamurthy Dvijotham</a>, 
<a href="/search/cs?searchtype=author&query=Weller%2C+A">Adrian Weller</a>, 
<a href="/search/cs?searchtype=author&query=Shams%2C+Z">Zohreh Shams</a>, 
<a href="/search/cs?searchtype=author&query=Jamnik%2C+M">Mateja Jamnik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a spotlight at the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Concept Bottleneck Models (CBMs) tackle the opacity of neural architectures
by constructing and explaining their predictions using a set of high-level
concepts. A special property of these models is that they permit concept
interventions, wherein users can correct mispredicted concepts and thus improve
the model's performance. Recent work, however, has shown that intervention
efficacy can be highly dependent on the order in which concepts are intervened
on and on the model's architecture and training hyperparameters. We argue that
this is rooted in a CBM's lack of train-time incentives for the model to be
appropriately receptive to concept interventions. To address this, we propose
Intervention-aware Concept Embedding models (IntCEMs), a novel CBM-based
architecture and training paradigm that improves a model's receptiveness to
test-time interventions. Our model learns a concept intervention policy in an
end-to-end fashion from where it can sample meaningful intervention
trajectories at train-time. This conditions IntCEMs to effectively select and
receive concept interventions when deployed at test-time. Our experiments show
that IntCEMs significantly outperform state-of-the-art concept-interpretable
models when provided with test-time concept interventions, demonstrating the
effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16930" title="Abstract">arXiv:2309.16930</a> [<a href="/pdf/2309.16930" title="Download PDF">pdf</a>, <a href="/format/2309.16930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PONG: Probabilistic Object Normals for Grasping via Analytic Bounds on  Force Closure Probability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+A+H">Albert H. Li</a>, 
<a href="/search/cs?searchtype=author&query=Culbertson%2C+P">Preston Culbertson</a>, 
<a href="/search/cs?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Classical approaches to grasp planning are deterministic, requiring perfect
knowledge of an object's pose and geometry. In response, data-driven approaches
have emerged that plan grasps entirely from sensory data. While these
data-driven methods have excelled in generating parallel-jaw and power grasps,
their application to precision grasps (those using the fingertips of a
dexterous hand, e.g, for tool use) remains limited. Precision grasping poses a
unique challenge due to its sensitivity to object geometry, which allows small
uncertainties in the object's shape and pose to cause an otherwise robust grasp
to fail. In response to these challenges, we introduce Probabilistic Object
Normals for Grasping (PONG), a novel, analytic approach for calculating a
conservative estimate of force closure probability in the case when contact
locations are known but surface normals are uncertain. We then present a
practical application where we use PONG as a grasp metric for generating robust
grasps both in simulation and real-world hardware experiments. Our results
demonstrate that maximizing PONG efficiently produces robust grasps, even for
challenging object geometries, and that it can serve as a well-calibrated,
uncertainty-aware metric of grasp quality.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16931" title="Abstract">arXiv:2309.16931</a> [<a href="/pdf/2309.16931" title="Download PDF">pdf</a>, <a href="/format/2309.16931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rationality and connectivity in stochastic learning for networked  coordination games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Vasconcelos%2C+M+M">Marcos M. Vasconcelos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to American Control Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Coordination is a desirable feature in many multi-agent systems such as
robotic and socioeconomic networks. We consider a task allocation problem as a
binary networked coordination game over an undirected regular graph. Each agent
in the graph has bounded rationality, and uses a distributed stochastic
learning algorithm to update its action choice conditioned on the actions
currently played by its neighbors. After establishing that our framework leads
to a potential game, we analyze the regime of bounded rationality, where the
agents are allowed to make sub-optimal decisions with some probability. Our
analysis shows that there is a relationship between the connectivity of the
network, and the rationality of the agents. In particular, we show that in some
scenarios, an agent can afford to be less rational and still converge to a near
optimal collective strategy, provided that its connectivity degree increases.
Such phenomenon is akin to the wisdom of crowds.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16932" title="Abstract">arXiv:2309.16932</a> [<a href="/pdf/2309.16932" title="Download PDF">pdf</a>, <a href="/format/2309.16932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetry Leads to Structured Constraint of Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziyin%2C+L">Liu Ziyin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Due to common architecture designs, symmetries exist extensively in
contemporary neural networks. In this work, we unveil the importance of the
loss function symmetries in affecting, if not deciding, the learning behavior
of machine learning models. We prove that every mirror symmetry of the loss
function leads to a structured constraint, which becomes a favored solution
when either the weight decay or gradient noise is large. As direct corollaries,
we show that rescaling symmetry leads to sparsity, rotation symmetry leads to
low rankness, and permutation symmetry leads to homogeneous ensembling. Then,
we show that the theoretical framework can explain the loss of plasticity and
various collapse phenomena in neural networks and suggest how symmetries can be
used to design algorithms to enforce hard constraints in a differentiable way.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16934" title="Abstract">arXiv:2309.16934</a> [<a href="/pdf/2309.16934" title="Download PDF">pdf</a>, <a href="/format/2309.16934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Aware Neural Dynamic Equivalence of Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shen%2C+Q">Qing Shen</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Maslennikov%2C+S">Slava Maslennikov</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+X">Xiaochuan Luo</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This letter devises Neural Dynamic Equivalence (NeuDyE), which explores
physics-aware machine learning and neural-ordinary-differential-equations
(ODE-Net) to discover a dynamic equivalence of external power grids while
preserving its dynamic behaviors after disturbances. The contributions are
threefold: (1) an ODE-Net-enabled NeuDyE formulation to enable a
continuous-time, data-driven dynamic equivalence of power systems; (2) a
physics-informed NeuDyE learning method (PI-NeuDyE) to actively control the
closed-loop accuracy of NeuDyE without an additional verification module; (3) a
physics-guided NeuDyE (PG-NeuDyE) to enhance the method's applicability even in
the absence of analytical physics models. Extensive case studies in the NPCC
system validate the efficacy of NeuDyE, and, in particular, its capability
under various contingencies.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16935" title="Abstract">arXiv:2309.16935</a> [<a href="/pdf/2309.16935" title="Download PDF">pdf</a>, <a href="/format/2309.16935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TranDRL: A Transformer-Driven Deep Reinforcement Learning Enabled  Prescriptive Maintenance Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenbo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Industrial systems demand reliable predictive maintenance strategies to
enhance operational efficiency and reduce downtime. This paper introduces a
novel, integrated framework that leverages the power of transformer neural
networks and deep reinforcement learning (DRL) algorithms to optimize
maintenance actions. Our approach employs the transformer model to effectively
capture complex temporal patterns in sensor data, thereby accurately predicting
the Remaining Useful Life (RUL) of equipment. Simultaneously, the DRL component
of our framework provides cost-effective and timely maintenance
recommendations. We validate the efficacy of our framework on the NASA C-MPASS
dataset, where it demonstrates significant advancements in both RUL prediction
accuracy and the optimization of maintenance actions. Consequently, our
pioneering approach provides an innovative data-driven methodology for
prescriptive maintenance, addressing key challenges in industrial operations
and leading the way to more efficient, cost-effective, and reliable systems.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16936" title="Abstract">arXiv:2309.16936</a> [<a href="/pdf/2309.16936" title="Download PDF">pdf</a>, <a href="/format/2309.16936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PC-Adapter: Topology-Aware Adapter for Efficient Domain Adaption on  Point Clouds with Rectified Pseudo-label
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Joonhyung Park</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+H">Hyunjin Seo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+E">Eunho Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages; Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding point clouds captured from the real-world is challenging due to
shifts in data distribution caused by varying object scales, sensor angles, and
self-occlusion. Prior works have addressed this issue by combining recent
learning principles such as self-supervised learning, self-training, and
adversarial training, which leads to significant computational overhead.Toward
succinct yet powerful domain adaptation for point clouds, we revisit the unique
challenges of point cloud data under domain shift scenarios and discover the
importance of the global geometry of source data and trends of target
pseudo-labels biased to the source label distribution. Motivated by our
observations, we propose an adapter-guided domain adaptation method,
PC-Adapter, that preserves the global shape information of the source domain
using an attention-based adapter, while learning the local characteristics of
the target domain via another adapter equipped with graph convolution.
Additionally, we propose a novel pseudo-labeling strategy resilient to the
classifier bias by adjusting confidence scores using their class-wise
confidence distributions to consider relative confidences. Our method
demonstrates superiority over baselines on various domain shift settings in
benchmark datasets - PointDA, GraspNetPC, and PointSegDA.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16937" title="Abstract">arXiv:2309.16937</a> [<a href="/pdf/2309.16937" title="Download PDF">pdf</a>, <a href="/format/2309.16937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSHR: Leveraging Self-supervised Hierarchical Representations for  Multilingual Automatic Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hongfei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Q">Qijie Shao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaixun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peikun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multilingual automatic speech recognition (ASR) systems have garnered
attention for their potential to extend language coverage globally. While
self-supervised learning (SSL) has demonstrated its effectiveness in
multilingual ASR, it is worth noting that the various layers' representations
of SSL potentially contain distinct information that has not been fully
leveraged. In this study, we propose a novel method that leverages
self-supervised hierarchical representations (SSHR) to fine-tune multilingual
ASR. We first analyze the different layers of the SSL model for
language-related and content-related information, uncovering layers that show a
stronger correlation. Then, we extract a language-related frame from correlated
middle layers and guide specific content extraction through self-attention
mechanisms. Additionally, we steer the model toward acquiring more
content-related information in the final layers using our proposed Cross-CTC.
We evaluate SSHR on two multilingual datasets, Common Voice and ML-SUPERB, and
the experimental results demonstrate that our method achieves state-of-the-art
performance to the best of our knowledge.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16938" title="Abstract">arXiv:2309.16938</a> [<a href="/pdf/2309.16938" title="Download PDF">pdf</a>, <a href="/format/2309.16938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I Wish to Have an Argument: Argumentative Reasoning in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Wynter%2C+A">Adrian de Wynter</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+T">Tommy Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We evaluate the ability of contemporary large language models (LLMs) to
perform argumentative reasoning. We frame our experiments in terms of the
argument mining (AM) and argument pair extraction (APE) tasks, and evaluate
their ability to perform reasoning at increasing levels of abstraction in the
input and output representations (e.g., arbitrary label sets, semantic graphs).
We find that, although LLMs are able to match or surpass the state-of-the-art
in AM and APE, their argumentative reasoning performance is very dependent on
the input and output representation. We also find an "exemplar effect", where
too many exemplars increasingly become detrimental for task performance, and
about 4-5 being the optimal amount. Neither result extends to chain-of-thought
(CoT) prompting: we find the exemplar effect to be nullified, and our results
suggest that CoT allows for better performance under ill-conditioned problems.
We hope that the work reported contributes to the improvement of argumentative
reasoning in LLMs.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16940" title="Abstract">arXiv:2309.16940</a> [<a href="/pdf/2309.16940" title="Download PDF">pdf</a>, <a href="/format/2309.16940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Asynchronous Collaborative 3D Detection via Bird&#x27;s Eye View Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Sizhe Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yifan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiqi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures. Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">By facilitating communication among multiple agents, collaborative perception
can substantially boost each agent's perception ability. However, temporal
asynchrony among agents is inevitable in real-world due to communication
delays, interruptions, and clock misalignments. This issue causes information
mismatch during multi-agent fusion, seriously shaking the foundation of
collaboration. To address this issue, we propose CoBEVFlow, an
asynchrony-robust collaborative 3D perception system based on bird's eye view
(BEV) flow. The key intuition of CoBEVFlow is to compensate motions to align
asynchronous collaboration messages sent by multiple agents. To model the
motion in a scene, we propose BEV flow, which is a collection of the motion
vector corresponding to each spatial location. Based on BEV flow, asynchronous
perceptual features can be reassigned to appropriate positions, mitigating the
impact of asynchrony. CoBEVFlow has two advantages: (i) CoBEVFlow can handle
asynchronous collaboration messages sent at irregular, continuous time stamps
without discretization; and (ii) with BEV flow, CoBEVFlow only transports the
original perceptual features, instead of generating new perceptual features,
avoiding additional noises. To validate CoBEVFlow's efficacy, we create
IRregular V2V(IRV2V), the first synthetic collaborative perception dataset with
various temporal asynchronies that simulate different real-world scenarios.
Extensive experiments conducted on both IRV2V and the real-world dataset
DAIR-V2X show that CoBEVFlow consistently outperforms other baselines and is
robust in extremely asynchronous settings. The code will be released.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16941" title="Abstract">arXiv:2309.16941</a> [<a href="/pdf/2309.16941" title="Download PDF">pdf</a>, <a href="/format/2309.16941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G4SATBench: Benchmarking and Advancing SAT Solving with Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaoyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jinpei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+X">Xujie Si</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks (GNNs) have recently emerged as a promising approach
for solving the Boolean Satisfiability Problem (SAT), offering potential
alternatives to traditional backtracking or local search SAT solvers. However,
despite the growing volume of literature in this field, there remains a notable
absence of a unified dataset and a fair benchmark to evaluate and compare
existing approaches. To address this crucial gap, we present G4SATBench, the
first benchmark study that establishes a comprehensive evaluation framework for
GNN-based SAT solvers. In G4SATBench, we meticulously curate a large and
diverse set of SAT datasets comprising 7 problems with 3 difficulty levels and
benchmark a broad range of GNN models across various prediction tasks, training
objectives, and inference algorithms. To explore the learning abilities and
comprehend the strengths and limitations of GNN-based SAT solvers, we also
compare their solving processes with the heuristics in search-based SAT
solvers. Our empirical results provide valuable insights into the performance
of GNN-based SAT solvers and further suggest that existing GNN models can
effectively learn a solving strategy akin to greedy local search but struggle
to learn backtracking search in the latent space.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16943" title="Abstract">arXiv:2309.16943</a> [<a href="/pdf/2309.16943" title="Download PDF">pdf</a>, <a href="/format/2309.16943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Induction Machine Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Q">Qing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This rapid communication devises a Neural Induction Machine (NeuIM) model,
which pilots the use of physics-informed machine learning to enable AI-based
electromagnetic transient simulations. The contributions are threefold: (1) a
formation of NeuIM to represent the induction machine in phase domain; (2) a
physics-informed neural network capable of capturing fast and slow IM dynamics
even in the absence of data; and (3) a data-physics-integrated hybrid NeuIM
approach which is adaptive to various levels of data availability. Extensive
case studies validate the efficacy of NeuIM and in particular, its advantage
over purely data-driven approaches.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16945" title="Abstract">arXiv:2309.16945</a> [<a href="/pdf/2309.16945" title="Download PDF">pdf</a>, <a href="/format/2309.16945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disturbance Observer-based Robust Integral Control Barrier Functions for  Nonlinear Systems with High Relative Degree
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zinage%2C+V">Vrushabh Zinage</a>, 
<a href="/search/eess?searchtype=author&query=Chandra%2C+R">Rohan Chandra</a>, 
<a href="/search/eess?searchtype=author&query=Bakolas%2C+E">Efstathios Bakolas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages and 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we consider the problem of safe control synthesis of general
controlled nonlinear systems in the presence of bounded additive disturbances.
Towards this aim, we first construct a governing augmented state space model
consisting of the equations of motion of the original system, the integral
control law and the nonlinear disturbance observer. Next, we propose the
concept of Disturbance Observer based Integral Control Barrier Functions
(DO-ICBFs) which we utilize to synthesize safe control inputs. The
characterization of the safe controller is obtained after modifying the
governing integral control law with an additive auxiliary control input which
is computed via the solution of a quadratic problem. In contrast to prior
methods in the relevant literature which can be unnecessarily cautious due to
their reliance on the worst case disturbance estimates, our DO-ICBF based
controller uses the available control effort frugally by leveraging the
disturbance estimates computed by the disturbance observer. By construction,
the proposed DO-ICBF based controller can ensure state and input constraint
satisfaction at all times. Further, we propose Higher Order DO-ICBFs that
extend our proposed method to nonlinear systems with higher relative degree
with respect to the auxiliary control input. Finally, numerical simulations are
provided to validate our proposed approach.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16948" title="Abstract">arXiv:2309.16948</a> [<a href="/pdf/2309.16948" title="Download PDF">pdf</a>, <a href="/format/2309.16948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Diffusion Bridge Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Linqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+A">Aaron Lou</a>, 
<a href="/search/cs?searchtype=author&query=Khanna%2C+S">Samar Khanna</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models are powerful generative models that map noise to data using
stochastic processes. However, for many applications such as image editing, the
model input comes from a distribution that is not random noise. As such,
diffusion models must rely on cumbersome methods like guidance or projected
sampling to incorporate this information in the generative process. In our
work, we propose Denoising Diffusion Bridge Models (DDBMs), a natural
alternative to this paradigm based on diffusion bridges, a family of processes
that interpolate between two paired distributions given as endpoints. Our
method learns the score of the diffusion bridge from data and maps from one
endpoint distribution to the other by solving a (stochastic) differential
equation based on the learned score. Our method naturally unifies several
classes of generative models, such as score-based diffusion models and
OT-Flow-Matching, allowing us to adapt existing design and architectural
choices to our more general problem. Empirically, we apply DDBMs to challenging
image datasets in both pixel and latent space. On standard image translation
problems, DDBMs achieve significant improvement over baseline methods, and,
when we reduce the problem to image generation by setting the source
distribution to random noise, DDBMs achieve comparable FID scores to
state-of-the-art methods despite being built for a more general task.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16949" title="Abstract">arXiv:2309.16949</a> [<a href="/pdf/2309.16949" title="Download PDF">pdf</a>, <a href="/format/2309.16949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrossZoom: Simultaneously Motion Deblurring and Event Super-Resolving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mingyuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chu He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gui-Song Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Even though the collaboration between traditional and neuromorphic event
cameras brings prosperity to frame-event based vision applications, the
performance is still confined by the resolution gap crossing two modalities in
both spatial and temporal domains. This paper is devoted to bridging the gap by
increasing the temporal resolution for images, i.e., motion deblurring, and the
spatial resolution for events, i.e., event super-resolving, respectively. To
this end, we introduce CrossZoom, a novel unified neural Network (CZ-Net) to
jointly recover sharp latent sequences within the exposure period of a blurry
input and the corresponding High-Resolution (HR) events. Specifically, we
present a multi-scale blur-event fusion architecture that leverages the
scale-variant properties and effectively fuses cross-modality information to
achieve cross-enhancement. Attention-based adaptive enhancement and
cross-interaction prediction modules are devised to alleviate the distortions
inherent in Low-Resolution (LR) events and enhance the final results through
the prior blur-event complementary information. Furthermore, we propose a new
dataset containing HR sharp-blurry images and the corresponding HR-LR event
streams to facilitate future research. Extensive qualitative and quantitative
experiments on synthetic and real-world datasets demonstrate the effectiveness
and robustness of the proposed method. Codes and datasets are released at
https://bestrivenzc.github.io/CZ-Net/.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16950" title="Abstract">arXiv:2309.16950</a> [<a href="/pdf/2309.16950" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Powering the Future: Harnessing Neural Dynamic Equivalence for Enhanced  Power System Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shen%2C+Q">Qing Shen</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+H">Huanfeng Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Maslenniko%2C+S">Slava Maslenniko</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+X">Xiaochuan Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Traditional grid analytics are model-based, relying strongly on accurate
models of power systems, especially the dynamic models of generators,
controllers, loads and other dynamic components. However, acquiring thorough
power system models can be impractical in real operation due to inaccessible
system parameters and privacy of consumers, which necessitate data-driven
dynamic equivalencing of unknown subsystems. Learning reliable dynamic
equivalent models for the external systems from SCADA and PMU data, however, is
a long-standing intractable problem in power system analysis due to complicated
nonlinearity and unforeseeable dynamic modes of power systems. This paper
advances a practical application of neural dynamic equivalence (NeuDyE) called
Driving Port NeuDyE (DP-NeuDyE), which exploits physics-informed machine
learning and neural-ordinary-differential-equations (ODE-NET) to discover a
dynamic equivalence of external power grids while preserving its dynamic
behaviors after disturbances. The new contributions are threefold: A NeuDyE
formulation to enable a continuous-time, data-driven dynamic equivalence of
power systems, saving the effort and expense of acquiring inaccessible system;
An introduction of a Physics-Informed NeuDyE learning (PI-NeuDyE) to actively
control the closed-loop accuracy of NeuDyE; and A DP-NeuDyE to reduce the
number of inputs required for the training. We conduct extensive case studies
on the NPCC system to validate the generalizability and accuracy of both
PI-NeuDyE and DP-NeuDyE, which span a multitude of scenarios, differing in the
time required for fault clearance, the specific fault locations, and the
limitations of data. Test results have demonstrated the scalability and
practicality of NeuDyE, showing its potential to be used in ISO and utility
control centers for online transient stability analysis and for planning
purposes.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16952" title="Abstract">arXiv:2309.16952</a> [<a href="/pdf/2309.16952" title="Download PDF">pdf</a>, <a href="/format/2309.16952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Optimization for Adaptive Attacks on Image Watermarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lukas%2C+N">Nils Lukas</a>, 
<a href="/search/cs?searchtype=author&query=Diaa%2C+A">Abdulrahman Diaa</a>, 
<a href="/search/cs?searchtype=author&query=Fenaux%2C+L">Lucas Fenaux</a>, 
<a href="/search/cs?searchtype=author&query=Kerschbaum%2C+F">Florian Kerschbaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Untrustworthy users can misuse image generators to synthesize high-quality
deepfakes and engage in online spam or disinformation campaigns. Watermarking
deters misuse by marking generated content with a hidden message, enabling its
detection using a secret watermarking key. A core security property of
watermarking is robustness, which states that an attacker can only evade
detection by substantially degrading image quality. Assessing robustness
requires designing an adaptive attack for the specific watermarking algorithm.
A challenge when evaluating watermarking algorithms and their (adaptive)
attacks is to determine whether an adaptive attack is optimal, i.e., it is the
best possible attack. We solve this problem by defining an objective function
and then approach adaptive attacks as an optimization problem. The core idea of
our adaptive attacks is to replicate secret watermarking keys locally by
creating surrogate keys that are differentiable and can be used to optimize the
attack's parameters. We demonstrate for Stable Diffusion models that such an
attacker can break all five surveyed watermarking methods at negligible
degradation in image quality. These findings emphasize the need for more
rigorous robustness testing against adaptive, learnable attackers.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16956" title="Abstract">arXiv:2309.16956</a> [<a href="/pdf/2309.16956" title="Download PDF">pdf</a>, <a href="/format/2309.16956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model2Scene: Learning 3D Scene Representation via Contrastive  Language-CAD Models Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runnan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nenglun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dawei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruigang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2203.10546">arXiv:2203.10546</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current successful methods of 3D scene perception rely on the large-scale
annotated point cloud, which is tedious and expensive to acquire. In this
paper, we propose Model2Scene, a novel paradigm that learns free 3D scene
representation from Computer-Aided Design (CAD) models and languages. The main
challenges are the domain gaps between the CAD models and the real scene's
objects, including model-to-scene (from a single model to the scene) and
synthetic-to-real (from synthetic model to real scene's object). To handle the
above challenges, Model2Scene first simulates a crowded scene by mixing
data-augmented CAD models. Next, we propose a novel feature regularization
operation, termed Deep Convex-hull Regularization (DCR), to project point
features into a unified convex hull space, reducing the domain gap. Ultimately,
we impose contrastive loss on language embedding and the point features of CAD
models to pre-train the 3D network. Extensive experiments verify the learned 3D
scene representation is beneficial for various downstream tasks, including
label-free 3D object salient detection, label-efficient 3D scene perception and
zero-shot 3D semantic segmentation. Notably, Model2Scene yields impressive
label-free 3D object salient detection with an average mAP of 46.08\% and
55.49\% on the ScanNet and S3DIS datasets, respectively. The code will be
publicly available.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16957" title="Abstract">arXiv:2309.16957</a> [<a href="/pdf/2309.16957" title="Download PDF">pdf</a>, <a href="/format/2309.16957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Data and Experiences: Engaging Youth in Digital Civics through  Participatory Mapmaking for Resilience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yousufi%2C+M">Mohsin Yousufi</a>, 
<a href="/search/cs?searchtype=author&query=Loukissas%2C+Y">Yanni Loukissas</a>, 
<a href="/search/cs?searchtype=author&query=Hyde%2C+A">Allen Hyde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at ACM DIS'23 Workshop on Designing for and Reflecting upon Resilience in Health and Wellbeing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The paper reports on a participatory map-making workshop with middle school
students in Savannah, Georgia. The workshop, which took place over a seven week
period as part of Youth Advocacy for Resilience to Disasters (YARD) program,
students worked together to make maps that examine local natural disasters and
their consequences. We developed a map-making platform that enabled the youth
to leverage spatial data on local environmental, economic and social issues, as
a means of interrogating their existing stories about disasters and their
impacts. This allowed the students to share their specific experiences of the
city, while also inquiring about the validity of such experiences. Through the
use of our platform, we illustrate the potential of maps as representations
that bridge two worlds, that of data and experience. We argue that Map Spot
leverages existing data to help youth surface and communicate what they already
know, but were otherwise unable to articulate
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16959" title="Abstract">arXiv:2309.16959</a> [<a href="/pdf/2309.16959" title="Download PDF">pdf</a>, <a href="/ps/2309.16959" title="Download PostScript">ps</a>, <a href="/format/2309.16959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COMNet: Co-Occurrent Matching for Weakly Supervised Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yukun Su</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jingliang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zonghan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image-level weakly supervised semantic segmentation is a challenging task
that has been deeply studied in recent years. Most of the common solutions
exploit class activation map (CAM) to locate object regions. However, such
response maps generated by the classification network usually focus on
discriminative object parts. In this paper, we propose a novel Co-Occurrent
Matching Network (COMNet), which can promote the quality of the CAMs and
enforce the network to pay attention to the entire parts of objects.
Specifically, we perform inter-matching on paired images that contain common
classes to enhance the corresponded areas, and construct intra-matching on a
single image to propagate the semantic features across the object regions. The
experiments on the Pascal VOC 2012 and MS-COCO datasets show that our network
can effectively boost the performance of the baseline model and achieve new
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16960" title="Abstract">arXiv:2309.16960</a> [<a href="/pdf/2309.16960" title="Download PDF">pdf</a>, <a href="/format/2309.16960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Generating Explanations for Reinforcement Learning Policies: An  Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuasa%2C+M">Mikihisa Yuasa</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+H+T">Huy T. Tran</a>, 
<a href="/search/cs?searchtype=author&query=Sreenivas%2C+R+S">Ramavarapu S. Sreenivas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this paper, we introduce a set of \textit{Linear Temporal Logic} (LTL)
formulae designed to provide explanations for policies. Our focus is on
crafting explanations that elucidate both the ultimate objectives accomplished
by the policy and the prerequisites it upholds throughout its execution. These
LTL-based explanations feature a structured representation, which is
particularly well-suited for local-search techniques. The effectiveness of our
proposed approach is illustrated through a simulated capture the flag
environment. The paper concludes with suggested directions for future research.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16962" title="Abstract">arXiv:2309.16962</a> [<a href="/pdf/2309.16962" title="Download PDF">pdf</a>, <a href="/format/2309.16962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifting the Fog of Uncertainties: Dynamic Resource Orchestration for the  Containerized Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuqiu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tongkun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gengrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jacobsen%2C+H">Hans-Arno Jacobsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ACM SoCC '23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The advances in virtualization technologies have sparked a growing transition
from virtual machine (VM)-based to container-based infrastructure for cloud
computing. From the resource orchestration perspective, containers' lightweight
and highly configurable nature not only enables opportunities for more
optimized strategies, but also poses greater challenges due to additional
uncertainties and a larger configuration parameter search space. Towards this
end, we propose Drone, a resource orchestration framework that adaptively
configures resource parameters to improve application performance and reduce
operational cost in the presence of cloud uncertainties. Built on Contextual
Bandit techniques, Drone is able to achieve a balance between performance and
resource cost on public clouds, and optimize performance on private clouds
where a hard resource constraint is present. We show that our algorithms can
achieve sub-linear growth in cumulative regret, a theoretically sound
convergence guarantee, and our extensive experiments show that Drone achieves
an up to 45% performance improvement and a 20% resource footprint reduction
across batch processing jobs and microservice workloads.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16964" title="Abstract">arXiv:2309.16964</a> [<a href="/pdf/2309.16964" title="Download PDF">pdf</a>, <a href="/format/2309.16964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaPose: Towards Cross-Site Device-Free Human Pose Estimation with  Commodity WiFi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yunjiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">He Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lihua Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">WiFi-based pose estimation is a technology with great potential for the
development of smart homes and metaverse avatar generation. However, current
WiFi-based pose estimation methods are predominantly evaluated under controlled
laboratory conditions with sophisticated vision models to acquire accurately
labeled data. Furthermore, WiFi CSI is highly sensitive to environmental
variables, and direct application of a pre-trained model to a new environment
may yield suboptimal results due to domain shift. In this paper, we proposes a
domain adaptation algorithm, AdaPose, designed specifically for
weakly-supervised WiFi-based pose estimation. The proposed method aims to
identify consistent human poses that are highly resistant to environmental
dynamics. To achieve this goal, we introduce a Mapping Consistency Loss that
aligns the domain discrepancy of source and target domains based on inner
consistency between input and output at the mapping level. We conduct extensive
experiments on domain adaptation in two different scenes using our
self-collected pose estimation dataset containing WiFi CSI frames. The results
demonstrate the effectiveness and robustness of AdaPose in eliminating domain
shift, thereby facilitating the widespread application of WiFi-based pose
estimation in smart cities.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16967" title="Abstract">arXiv:2309.16967</a> [<a href="/pdf/2309.16967" title="Download PDF">pdf</a>, <a href="/format/2309.16967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> nnSAM: Plug-and-play Segment Anything Model Improves nnUNet Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+B">Bowen Jing</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zihan Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yongbo He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">You Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The recent developments of foundation models in computer vision, especially
the Segment Anything Model (SAM), allow scalable and domain-agnostic image
segmentation to serve as a general-purpose segmentation tool. In parallel, the
field of medical image segmentation has benefited significantly from
specialized neural networks like the nnUNet, which is trained on
domain-specific datasets and can automatically configure the network to tailor
to specific segmentation challenges. To combine the advantages of foundation
models and domain-specific models, we present nnSAM, which synergistically
integrates the SAM model with the nnUNet model to achieve more accurate and
robust medical image segmentation. The nnSAM model leverages the powerful and
robust feature extraction capabilities of SAM, while harnessing the automatic
configuration capabilities of nnUNet to promote dataset-tailored learning. Our
comprehensive evaluation of nnSAM model on different sizes of training samples
shows that it allows few-shot learning, which is highly relevant for medical
image segmentation where high-quality, annotated data can be scarce and costly
to obtain. By melding the strengths of both its predecessors, nnSAM positions
itself as a potential new benchmark in medical image segmentation, offering a
tool that combines broad applicability with specialized efficiency. The code is
available at https://github.com/Kent0n-Li/Medical-Image-Segmentation.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16968" title="Abstract">arXiv:2309.16968</a> [<a href="/pdf/2309.16968" title="Download PDF">pdf</a>, <a href="/format/2309.16968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Data Generation and Deep Learning for the Topological Analysis  of 3D Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peek%2C+D">Dylan Peek</a>, 
<a href="/search/cs?searchtype=author&query=Skerritt%2C+M+P">Matt P. Skerritt</a>, 
<a href="/search/cs?searchtype=author&query=Chalup%2C+S">Stephan Chalup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, Dicta 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This research uses deep learning to estimate the topology of manifolds
represented by sparse, unordered point cloud scenes in 3D. A new labelled
dataset was synthesised to train neural networks and evaluate their ability to
estimate the genus of these manifolds. This data used random homeomorphic
deformations to provoke the learning of visual topological features. We
demonstrate that deep learning models could extract these features and discuss
some advantages over existing topological data analysis tools that are based on
persistent homology. Semantic segmentation was used to provide additional
geometric information in conjunction with topological labels. Common point
cloud multi-layer perceptron and transformer networks were both used to compare
the viability of these methods. The experimental results of this pilot study
support the hypothesis that, with the aid of sophisticated synthetic data
generation, neural networks can perform segmentation-based topological data
analysis. While our study focused on simulated data, the accuracy achieved
suggests a potential for future applications using real data.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16970" title="Abstract">arXiv:2309.16970</a> [<a href="/pdf/2309.16970" title="Download PDF">pdf</a>, <a href="/format/2309.16970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete-Choice Model with Generalized Additive Utility Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nishi%2C+T">Tomoki Nishi</a>, 
<a href="/search/cs?searchtype=author&query=Hara%2C+Y">Yusuke Hara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Discrete-choice models are a powerful framework for analyzing decision-making
behavior to provide valuable insights for policymakers and businesses.
Multinomial logit models (MNLs) with linear utility functions have been used in
practice because they are ease to use and interpretable. Recently, MNLs with
neural networks (e.g., ASU-DNN) have been developed, and they have achieved
higher prediction accuracy in behavior choice than classical MNLs. However,
these models lack interpretability owing to complex structures. We developed
utility functions with a novel neural-network architecture based on generalized
additive models, named generalized additive utility network ( GAUNet), for
discrete-choice models. We evaluated the performance of the MNL with GAUNet
using the trip survey data collected in Tokyo. Our models were comparable to
ASU-DNN in accuracy and exhibited improved interpretability compared to
previous models.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16971" title="Abstract">arXiv:2309.16971</a> [<a href="/pdf/2309.16971" title="Download PDF">pdf</a>, <a href="/format/2309.16971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Resolution Active Learning of Fourier Neural Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+W">Wei Xing</a>, 
<a href="/search/cs?searchtype=author&query=Kirby%2C+M">Mike Kirby</a>, 
<a href="/search/cs?searchtype=author&query=Narayan%2C+A">Akil Narayan</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+S">Shandian Zhe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Fourier Neural Operator (FNO) is a popular operator learning framework, which
not only achieves the state-of-the-art performance in many tasks, but also is
highly efficient in training and prediction. However, collecting training data
for the FNO is a costly bottleneck in practice, because it often demands
expensive physical simulations. To overcome this problem, we propose
Multi-Resolution Active learning of FNO (MRA-FNO), which can dynamically select
the input functions and resolutions to lower the data cost as much as possible
while optimizing the learning efficiency. Specifically, we propose a
probabilistic multi-resolution FNO and use ensemble Monte-Carlo to develop an
effective posterior inference algorithm. To conduct active learning, we
maximize a utility-cost ratio as the acquisition function to acquire new
examples and resolutions at each step. We use moment matching and the matrix
determinant lemma to enable tractable, efficient utility computation.
Furthermore, we develop a cost annealing framework to avoid over-penalizing
high-resolution queries at the early stage. The over-penalization is severe
when the cost difference is significant between the resolutions, which renders
active learning often stuck at low-resolution queries and inferior performance.
Our method overcomes this problem and applies to general multi-fidelity active
learning and optimization problems. We have shown the advantage of our method
in several benchmark operator learning tasks.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16973" title="Abstract">arXiv:2309.16973</a> [<a href="/pdf/2309.16973" title="Download PDF">pdf</a>, <a href="/format/2309.16973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Offline-to-Online Reinforcement Learning via Uncertainty  and Smoothness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xiaoyu Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xudong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+C">Chenjia Bai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">To obtain a near-optimal policy with fewer interactions in Reinforcement
Learning (RL), a promising approach involves the combination of offline RL,
which enhances sample efficiency by leveraging offline datasets, and online RL,
which explores informative transitions by interacting with the environment.
Offline-to-Online (O2O) RL provides a paradigm for improving an offline trained
agent within limited online interactions. However, due to the significant
distribution shift between online experiences and offline data, most offline RL
algorithms suffer from performance drops and fail to achieve stable policy
improvement in O2O adaptation. To address this problem, we propose the Robust
Offline-to-Online (RO2O) algorithm, designed to enhance offline policies
through uncertainty and smoothness, and to mitigate the performance drop in
online adaptation. Specifically, RO2O incorporates Q-ensemble for uncertainty
penalty and adversarial samples for policy and value smoothness, which enable
RO2O to maintain a consistent learning procedure in online adaptation without
requiring special changes to the learning objective. Theoretical analyses in
linear MDPs demonstrate that the uncertainty and smoothness lead to a tighter
optimality bound in O2O against distribution shift. Experimental results
illustrate the superiority of RO2O in facilitating stable offline-to-online
learning and achieving significant improvement with limited online
interactions.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16975" title="Abstract">arXiv:2309.16975</a> [<a href="/pdf/2309.16975" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Tone Mapping Model for High Dynamic Range Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehmood%2C+I">Imran Mehmood</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xinye Shi</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+U">M. Usman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M+R">Ming Ronnier Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">One of the key challenges in tone mapping is to preserve the perceptual
quality of high dynamic range (HDR) images when mapping them to standard
dynamic range (SDR) displays. Traditional tone mapping operators (TMOs)
compress the luminance of HDR images without considering the surround and
display conditions emanating into suboptimal results. Current research
addresses this challenge by incorporating perceptual color appearance
attributes. In this work, we propose a TMO (TMOz) that leverages CIECAM16
perceptual attributes, i.e., brightness, colorfulness, and hue. TMOz accounts
for the effects of both the surround and the display conditions to achieve more
optimal colorfulness reproduction. The perceptual brightness is compressed, and
the perceptual color scales, i.e., colorfulness and hue are derived from HDR
images by employing CIECAM16 color adaptation equations. A psychophysical
experiment was conducted to automate the brightness compression parameter. The
model employs fully automatic and adaptive approach, obviating the requirement
for manual parameter selection. TMOz was evaluated in terms of contrast,
colorfulness and overall image quality. The objective and subjective evaluation
methods revealed that the proposed model outperformed the state-of-the-art
TMOs.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16976" title="Abstract">arXiv:2309.16976</a> [<a href="/pdf/2309.16976" title="Download PDF">pdf</a>, <a href="/format/2309.16976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking and In-depth Performance Study of Large Language Models on  Habana Gaudi Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chengming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Baixi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaodong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weijian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Iskra%2C+K">Kamil Iskra</a>, 
<a href="/search/cs?searchtype=author&query=Beckman%2C+P">Pete Beckman</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dingwen Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Transformer models have achieved remarkable success in various machine
learning tasks but suffer from high computational complexity and resource
requirements. The quadratic complexity of the self-attention mechanism further
exacerbates these challenges when dealing with long sequences and large
datasets. Specialized AI hardware accelerators, such as the Habana GAUDI
architecture, offer a promising solution to tackle these issues. GAUDI features
a Matrix Multiplication Engine (MME) and a cluster of fully programmable Tensor
Processing Cores (TPC). This paper explores the untapped potential of using
GAUDI processors to accelerate Transformer-based models, addressing key
challenges in the process. Firstly, we provide a comprehensive performance
comparison between the MME and TPC components, illuminating their relative
strengths and weaknesses. Secondly, we explore strategies to optimize MME and
TPC utilization, offering practical insights to enhance computational
efficiency. Thirdly, we evaluate the performance of Transformers on GAUDI,
particularly in handling long sequences and uncovering performance bottlenecks.
Lastly, we evaluate the end-to-end performance of two Transformer-based large
language models (LLM) on GAUDI. The contributions of this work encompass
practical insights for practitioners and researchers alike. We delve into
GAUDI's capabilities for Transformers through systematic profiling, analysis,
and optimization exploration. Our study bridges a research gap and offers a
roadmap for optimizing Transformer-based model training on the GAUDI
architecture.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16977" title="Abstract">arXiv:2309.16977</a> [<a href="/pdf/2309.16977" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability Quantification of Deep Reinforcement Learning-based Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yoshioka%2C+H">Hitoshi Yoshioka</a>, 
<a href="/search/eess?searchtype=author&query=Hashimoto%2C+H">Hirotada Hashimoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages and 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reliability quantification of deep reinforcement learning (DRL)-based control
is a significant challenge for the practical application of artificial
intelligence (AI) in safety-critical systems. This study proposes a method for
quantifying the reliability of DRL-based control. First, an existing method,
random noise distillation, was applied to the reliability evaluation to clarify
the issues to be solved. Second, a novel method for reliability quantification
was proposed to solve these issues. The reliability is quantified using two
neural networks: reference and evaluator. They have the same structure with the
same initial parameters. The outputs of the two networks were the same before
training. During training, the evaluator network parameters were updated to
maximize the difference between the reference and evaluator networks for
trained data. Thus, the reliability of the DRL-based control for a state can be
evaluated based on the difference in output between the two networks. The
proposed method was applied to DQN-based control as an example of a simple
task, and its effectiveness was demonstrated. Finally, the proposed method was
applied to the problem of switching trained models depending on the state.
Con-sequently, the performance of the DRL-based control was improved by
switching the trained models according to their reliability.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16980" title="Abstract">arXiv:2309.16980</a> [<a href="/pdf/2309.16980" title="Download PDF">pdf</a>, <a href="/format/2309.16980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Impact of Data Reduction Techniques on Visualization for AMR  Applications Using AMReX Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Daoce Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pulido%2C+J">Jesus Pulido</a>, 
<a href="/search/cs?searchtype=author&query=Grosset%2C+P">Pascal Grosset</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiannan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ahrens%2C+J">James Ahrens</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dingwen Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Today's scientific simulations generate exceptionally large volumes of data,
challenging the capacities of available I/O bandwidth and storage space. This
necessitates a substantial reduction in data volume, for which error-bounded
lossy compression has emerged as a highly effective strategy. A crucial metric
for assessing the efficacy of lossy compression is visualization. Despite
extensive research on the impact of compression on visualization, there is a
notable gap in the literature concerning the effects of compression on the
visualization of Adaptive Mesh Refinement (AMR) data. AMR has proven to be a
potent solution for addressing the rising computational intensity and the
explosive growth in data volume that requires storage and transmission.
However, the hierarchical and multi-resolution characteristics of AMR data
introduce unique challenges to its visualization, and these challenges are
further compounded when data compression comes into play. This article delves
into the intricacies of how data compression influences and introduces novel
challenges to the visualization of AMR data.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16984" title="Abstract">arXiv:2309.16984</a> [<a href="/pdf/2309.16984" title="Download PDF">pdf</a>, <a href="/format/2309.16984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency Models as a Rich and Efficient Policy Class for  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zihan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Chi Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Score-based generative models like the diffusion model have been testified to
be effective in modeling multi-modal data from image generation to
reinforcement learning (RL). However, the inference process of diffusion model
can be slow, which hinders its usage in RL with iterative sampling. We propose
to apply the consistency model as an efficient yet expressive policy
representation, namely consistency policy, with an actor-critic style algorithm
for three typical RL settings: offline, offline-to-online and online. For
offline RL, we demonstrate the expressiveness of generative models as policies
from multi-modal data. For offline-to-online RL, the consistency policy is
shown to be more computational efficient than diffusion policy, with a
comparable performance. For online RL, the consistency policy demonstrates
significant speedup and even higher average performances than the diffusion
policy.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16987" title="Abstract">arXiv:2309.16987</a> [<a href="/pdf/2309.16987" title="Download PDF">pdf</a>, <a href="/format/2309.16987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpikeMOT: Event-based Multi-Object Tracking with Sparse Motion Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Can Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+H+K">Hayden Kwok-Hay So</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In comparison to conventional RGB cameras, the superior temporal resolution
of event cameras allows them to capture rich information between frames, making
them prime candidates for object tracking. Yet in practice, despite their
theoretical advantages, the body of work on event-based multi-object tracking
(MOT) remains in its infancy, especially in real-world settings where events
from complex background and camera motion can easily obscure the true target
motion. In this work, an event-based multi-object tracker, called SpikeMOT, is
presented to address these challenges. SpikeMOT leverages spiking neural
networks to extract sparse spatiotemporal features from event streams
associated with objects. The resulting spike train representations are used to
track the object movement at high frequency, while a simultaneous object
detector provides updated spatial information of these objects at an equivalent
frame rate. To evaluate the effectiveness of SpikeMOT, we introduce DSEC-MOT,
the first large-scale event-based MOT benchmark incorporating fine-grained
annotations for objects experiencing severe occlusions, frequent trajectory
intersections, and long-term re-identification in real-world contexts.
Extensive experiments employing DSEC-MOT and another event-based dataset, named
FE240hz, demonstrate SpikeMOT's capability to achieve high tracking accuracy
amidst challenging real-world scenarios, advancing the state-of-the-art in
event-based multi-object tracking.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16990" title="Abstract">arXiv:2309.16990</a> [<a href="/pdf/2309.16990" title="Download PDF">pdf</a>, <a href="/format/2309.16990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Synchronization and Calibration for Wide-baseline Stereo  Event Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+W">Wanli Xing</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shijie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guangze Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yanjun Du</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jia Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Event-based cameras are increasingly utilized in various applications, owing
to their high temporal resolution and low power consumption. However, a
fundamental challenge arises when deploying multiple such cameras: they operate
on independent time systems, leading to temporal misalignment. This
misalignment can significantly degrade performance in downstream applications.
Traditional solutions, which often rely on hardware-based synchronization, face
limitations in compatibility and are impractical for long-distance setups. To
address these challenges, we propose a novel algorithm that exploits the motion
of objects in the shared field of view to achieve millisecond-level
synchronization among multiple event-based cameras. Our method also
concurrently estimates extrinsic parameters. We validate our approach in both
simulated and real-world indoor/outdoor scenarios, demonstrating successful
synchronization and accurate extrinsic parameters estimation.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16992" title="Abstract">arXiv:2309.16992</a> [<a href="/pdf/2309.16992" title="Download PDF">pdf</a>, <a href="/format/2309.16992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Anything Model is a Good Teacher for Local Feature Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jingqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rongtao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wood-Doughty%2C+Z">Zach Wood-Doughty</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changwei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Local feature detection and description play an important role in many
computer vision tasks, which are designed to detect and describe keypoints in
"any scene" and "any downstream task". Data-driven local feature learning
methods need to rely on pixel-level correspondence for training, which is
challenging to acquire at scale, thus hindering further improvements in
performance. In this paper, we propose SAMFeat to introduce SAM (segment
anything model), a fundamental model trained on 11 million images, as a teacher
to guide local feature learning and thus inspire higher performance on limited
datasets. To do so, first, we construct an auxiliary task of Pixel Semantic
Relational Distillation (PSRD), which distillates feature relations with
category-agnostic semantic information learned by the SAM encoder into a local
feature learning network, to improve local feature description using semantic
discrimination. Second, we develop a technique called Weakly Supervised
Contrastive Learning Based on Semantic Grouping (WSC), which utilizes semantic
groupings derived from SAM as weakly supervised signals, to optimize the metric
space of local descriptors. Third, we design an Edge Attention Guidance (EAG)
to further improve the accuracy of local feature detection and description by
prompting the network to pay more attention to the edge region guided by SAM.
SAMFeat's performance on various tasks such as image matching on HPatches, and
long-term visual localization on Aachen Day-Night showcases its superiority
over previous local features. The release code is available at
https://github.com/vignywang/SAMFeat.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16995" title="Abstract">arXiv:2309.16995</a> [<a href="/pdf/2309.16995" title="Download PDF">pdf</a>, <a href="/ps/2309.16995" title="Download PostScript">ps</a>, <a href="/format/2309.16995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Max Weight Independent Set in sparse graphs with no long claws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abrishami%2C+T">Tara Abrishami</a>, 
<a href="/search/cs?searchtype=author&query=Chudnovsky%2C+M">Maria Chudnovsky</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Marcin Pilipczuk</a>, 
<a href="/search/cs?searchtype=author&query=Rz%C4%85%C5%BCewski%2C+P">Pawe&#x142; Rz&#x105;&#x17c;ewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We revisit the recent polynomial-time algorithm for the Max Weight
Independent Set (MWIS) problem in bounded-degree graphs excluding a fixed
subdivided claw $S_{t,t,t}$ as an induced subgraph [Abrishami, Dibek,
Chudnovsky, Rz\k{a}\.zewski, SODA 2022]. First, we show that with an arguably
simpler approach we can obtain a faster algorithm with running time
$n^{O(\Delta^2)}$, where $n$ is the number of vertices of the instance and
$\Delta$ is the maximum degree. Then we combine our technique with known
results concerning tree decompositions and provide a polynomial-time algorithm
for MWIS in graphs excluding a fixed subdivided claw as an induced subgraph and
a fixed biclique as a subgraph.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17001" title="Abstract">arXiv:2309.17001</a> [<a href="/pdf/2309.17001" title="Download PDF">pdf</a>, <a href="/format/2309.17001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Closer Look at Bearing Fault Classification Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abburi%2C+H">Harika Abburi</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+T">Tanya Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Ilyas%2C+H">Haider Ilyas</a>, 
<a href="/search/cs?searchtype=author&query=Manne%2C+L">Lakshmi Manne</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+D">Deepak Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+D">Don Williams</a>, 
<a href="/search/cs?searchtype=author&query=Snaidauf%2C+D">Derek Snaidauf</a>, 
<a href="/search/cs?searchtype=author&query=Bowen%2C+E">Edward Bowen</a>, 
<a href="/search/cs?searchtype=author&query=Veeramani%2C+B">Balaji Veeramani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Rolling bearing fault diagnosis has garnered increased attention in recent
years owing to its presence in rotating machinery across various industries,
and an ever increasing demand for efficient operations. Prompt detection and
accurate prediction of bearing failures can help reduce the likelihood of
unexpected machine downtime and enhance maintenance schedules, averting lost
productivity. Recent technological advances have enabled monitoring the health
of these assets at scale using a variety of sensors, and predicting the
failures using modern Machine Learning (ML) approaches including deep learning
architectures. Vibration data has been collected using accelerated
run-to-failure of overloaded bearings, or by introducing known failure in
bearings, under a variety of operating conditions such as rotating speed, load
on the bearing, type of bearing fault, and data acquisition frequency. However,
in the development of bearing failure classification models using vibration
data there is a lack of consensus in the metrics used to evaluate the models,
data partitions used to evaluate models, and methods used to generate failure
labels in run-to-failure experiments. An understanding of the impact of these
choices is important to reliably develop models, and deploy them in practical
settings. In this work, we demonstrate the significance of these choices on the
performance of the models using publicly-available vibration datasets, and
suggest model development considerations for real world scenarios. Our
experimental findings demonstrate that assigning vibration data from a given
bearing across training and evaluation splits leads to over-optimistic
performance estimates, PCA-based approach is able to robustly generate labels
for failure classification in run-to-failure experiments, and $F$ scores are
more insightful to evaluate the models with unbalanced real-world failure data.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17002" title="Abstract">arXiv:2309.17002</a> [<a href="/pdf/2309.17002" title="Download PDF">pdf</a>, <a href="/format/2309.17002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Mitigating the Label Noise in Pre-training on  Downstream Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Ankit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+R">Ran Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hongxin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 16 figures, 16 tables, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Pre-training on large-scale datasets and then fine-tuning on downstream tasks
have become a standard practice in deep learning. However, pre-training data
often contain label noise that may adversely affect the generalization of the
model. This paper aims to understand the nature of noise in pre-training
datasets and to mitigate its impact on downstream tasks. More specifically,
through extensive experiments of supervised pre-training models on synthetic
noisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise
in pre-training can benefit in-domain (ID) transfer performance, where the
training and testing data share the same distribution, it always deteriorates
out-of-domain (OOD) performance, where training and testing data distribution
are different. We empirically verify that the reason behind is noise in
pre-training shapes the feature space differently. We then propose a
lightweight black-box tuning method (NMTune) to affine the feature space to
mitigate the malignant effect of noise and improve generalization on both ID
and OOD tasks, considering one may not be able to fully fine-tune or even
access the pre-trained models. We conduct practical experiments on popular
vision and language models that are pre-trained on noisy data for evaluation of
our approach. Our analysis and results show the importance of this interesting
and novel research direction, which we term Noisy Model Learning.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17007" title="Abstract">arXiv:2309.17007</a> [<a href="/pdf/2309.17007" title="Download PDF">pdf</a>, <a href="/format/2309.17007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical Foundation Models are Susceptible to Targeted Misinformation  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tianyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Nebelung%2C+S">Sven Nebelung</a>, 
<a href="/search/cs?searchtype=author&query=Khader%2C+F">Firas Khader</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianci Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mueller-Franzes%2C+G">Gustav Mueller-Franzes</a>, 
<a href="/search/cs?searchtype=author&query=Kuhl%2C+C">Christiane Kuhl</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%B6rsch%2C+S">Sebastian F&#xf6;rsch</a>, 
<a href="/search/cs?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/cs?searchtype=author&query=Haarburger%2C+C">Christoph Haarburger</a>, 
<a href="/search/cs?searchtype=author&query=Bressem%2C+K+K">Keno K. Bressem</a>, 
<a href="/search/cs?searchtype=author&query=Kather%2C+J+N">Jakob Nikolas Kather</a>, 
<a href="/search/cs?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Large language models (LLMs) have broad medical knowledge and can reason
about medical information across many domains, holding promising potential for
diverse medical applications in the near future. In this study, we demonstrate
a concerning vulnerability of LLMs in medicine. Through targeted manipulation
of just 1.1% of the model's weights, we can deliberately inject an incorrect
biomedical fact. The erroneous information is then propagated in the model's
output, whilst its performance on other biomedical tasks remains intact. We
validate our findings in a set of 1,038 incorrect biomedical facts. This
peculiar susceptibility raises serious security and trustworthiness concerns
for the application of LLMs in healthcare settings. It accentuates the need for
robust protective measures, thorough verification mechanisms, and stringent
management of access to these models, ensuring their reliable and safe use in
medical practice.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17009" title="Abstract">arXiv:2309.17009</a> [<a href="/pdf/2309.17009" title="Download PDF">pdf</a>, <a href="/format/2309.17009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Representation Learning for Prediction of Temporal Event Sets in  the Continuous Time Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+P">Parag Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Mayilvaghanan%2C+K">Kawin Mayilvaghanan</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+P">Pratyaksha Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Dukkipati%2C+A">Ambedkar Dukkipati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ACML 2023 - Conference Track (Long Paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Temporal Point Processes (TPP) play an important role in predicting or
forecasting events. Although these problems have been studied extensively,
predicting multiple simultaneously occurring events can be challenging. For
instance, more often than not, a patient gets admitted to a hospital with
multiple conditions at a time. Similarly people buy more than one stock and
multiple news breaks out at the same time. Moreover, these events do not occur
at discrete time intervals, and forecasting event sets in the continuous time
domain remains an open problem. Naive approaches for extending the existing TPP
models for solving this problem lead to dealing with an exponentially large
number of events or ignoring set dependencies among events. In this work, we
propose a scalable and efficient approach based on TPPs to solve this problem.
Our proposed approach incorporates contextual event embeddings, temporal
information, and domain features to model the temporal event sets. We
demonstrate the effectiveness of our approach through extensive experiments on
multiple datasets, showing that our model outperforms existing methods in terms
of prediction metrics and computational efficiency. To the best of our
knowledge, this is the first work that solves the problem of predicting event
set intensities in the continuous time domain by using TPPs.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17011" title="Abstract">arXiv:2309.17011</a> [<a href="/pdf/2309.17011" title="Download PDF">pdf</a>, <a href="/format/2309.17011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Cognition Enhancement via Interaction-Aware Automated  Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azim%2C+E">Ehtesamul Azim</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kunpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanjie Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to SIAM Conference on Data Mining(SDM) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Creating an effective representation space is crucial for mitigating the
curse of dimensionality, enhancing model generalization, addressing data
sparsity, and leveraging classical models more effectively. Recent advancements
in automated feature engineering (AutoFE) have made significant progress in
addressing various challenges associated with representation learning, issues
such as heavy reliance on intensive labor and empirical experiences, lack of
explainable explicitness, and inflexible feature space reconstruction embedded
into downstream tasks. However, these approaches are constrained by: 1)
generation of potentially unintelligible and illogical reconstructed feature
spaces, stemming from the neglect of expert-level cognitive processes; 2) lack
of systematic exploration, which subsequently results in slower model
convergence for identification of optimal feature space. To address these, we
introduce an interaction-aware reinforced generation perspective. We redefine
feature space reconstruction as a nested process of creating meaningful
features and controlling feature set size through selection. We develop a
hierarchical reinforcement learning structure with cascading Markov Decision
Processes to automate feature and operation selection, as well as feature
crossing. By incorporating statistical measures, we reward agents based on the
interaction strength between selected features, resulting in intelligent and
efficient exploration of the feature space that emulates human decision-making.
Extensive experiments are conducted to validate our proposed approach.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17012" title="Abstract">arXiv:2309.17012</a> [<a href="/pdf/2309.17012" title="Download PDF">pdf</a>, <a href="/format/2309.17012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Cognitive Biases in Large Language Models as Evaluators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koo%2C+R">Ryan Koo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minhwa Lee</a>, 
<a href="/search/cs?searchtype=author&query=Raheja%2C+V">Vipul Raheja</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J+I">Jong Inn Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Z+M">Zae Myung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongyeop Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at ICLR 2024. 26 pages, 8 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have recently been shown to be effective as
automatic evaluators with simple prompting and in-context learning. In this
work, we assemble 15 LLMs of four different size ranges and evaluate their
output responses by preference ranking from the other LLMs as evaluators, such
as System Star is better than System Square. We then evaluate the quality of
ranking outputs introducing the Cognitive Bias Benchmark for LLMs as Evaluators
(CoBBLEr), a benchmark to measure six different cognitive biases in LLM
evaluation outputs, such as the Egocentric bias where a model prefers to rank
its own outputs highly in evaluation. We find that LLMs are biased text quality
evaluators, exhibiting strong indications on our bias benchmark (average of 40%
of comparisons across all models) within each of their evaluations that
question their robustness as evaluators. Furthermore, we examine the
correlation between human and machine preferences and calculate the average
Rank-Biased Overlap (RBO) score to be 49.6%, indicating that machine
preferences are misaligned with humans. According to our findings, LLMs may
still be unable to be utilized for automatic annotation aligned with human
preferences. Our project page is at: https://minnesotanlp.github.io/cobbler.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17016" title="Abstract">arXiv:2309.17016</a> [<a href="/pdf/2309.17016" title="Download PDF">pdf</a>, <a href="/format/2309.17016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Agnostic Learning with Average Smoothness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanneke%2C+S">Steve Hanneke</a>, 
<a href="/search/cs?searchtype=author&query=Kontorovich%2C+A">Aryeh Kontorovich</a>, 
<a href="/search/cs?searchtype=author&query=Kornowski%2C+G">Guy Kornowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2302.06005">arXiv:2302.06005</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study distribution-free nonparametric regression following a notion of
average smoothness initiated by Ashlagi et al. (2021), which measures the
"effective" smoothness of a function with respect to an arbitrary unknown
underlying distribution. While the recent work of Hanneke et al. (2023)
established tight uniform convergence bounds for average-smooth functions in
the realizable case and provided a computationally efficient realizable
learning algorithm, both of these results currently lack analogs in the general
agnostic (i.e. noisy) case.
<br />In this work, we fully close these gaps. First, we provide a
distribution-free uniform convergence bound for average-smoothness classes in
the agnostic setting. Second, we match the derived sample complexity with a
computationally efficient agnostic learning algorithm. Our results, which are
stated in terms of the intrinsic geometry of the data and hold over any totally
bounded metric space, show that the guarantees recently obtained for realizable
learning of average-smooth functions transfer to the agnostic setting. At the
heart of our proof, we establish the uniform convergence rate of a function
class in terms of its bracketing entropy, which may be of independent interest.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17019" title="Abstract">arXiv:2309.17019</a> [<a href="/pdf/2309.17019" title="Download PDF">pdf</a>, <a href="/ps/2309.17019" title="Download PostScript">ps</a>, <a href="/format/2309.17019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization on the smallest eigenvalue of grounded Laplacian matrix via  edge addition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaotian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haoxin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongzhi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">The grounded Laplacian matrix $\LL_{-S}$ of a graph $\calG=(V,E)$ with
$n=|V|$ nodes and $m=|E|$ edges is a $(n-s)\times (n-s)$ submatrix of its
Laplacian matrix $\LL$, obtained from $\LL$ by deleting rows and columns
corresponding to $s=|S| \ll n $ ground nodes forming set $S\subset V$. The
smallest eigenvalue of $\LL_{-S}$ plays an important role in various practical
scenarios, such as characterizing the convergence rate of leader-follower
opinion dynamics, with a larger eigenvalue indicating faster convergence of
opinion. In this paper, we study the problem of adding $k \ll n$ edges among
all the nonexistent edges forming the candidate edge set $Q = (V\times
V)\backslash E$, in order to maximize the smallest eigenvalue of the grounded
Laplacian matrix. We show that the objective function of the combinatorial
optimization problem is monotone but non-submodular. To solve the problem, we
first simplify the problem by restricting the candidate edge set $Q$ to be
$(S\times (V\backslash S))\backslash E$, and prove that it has the same optimal
solution as the original problem, although the size of set $Q$ is reduced from
$O(n^2)$ to $O(n)$. Then, we propose two greedy approximation algorithms. One
is a simple greedy algorithm with an approximation ratio
$(1-e^{-\alpha\gamma})/\alpha$ and time complexity $O(kn^4)$, where $\gamma$
and $\alpha$ are, respectively, submodularity ratio and curvature, whose bounds
are provided for some particular cases. The other is a fast greedy algorithm
without approximation guarantee, which has a running time $\tilde{O}(km)$,
where $\tilde{O}(\cdot)$ suppresses the ${\rm poly} (\log n)$ factors. Numerous
experiments on various real networks are performed to validate the superiority
of our algorithms, in terms of effectiveness and efficiency.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17022" title="Abstract">arXiv:2309.17022</a> [<a href="/pdf/2309.17022" title="Download PDF">pdf</a>, <a href="/format/2309.17022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positionality in &#x3a3;_0^2 and a completeness result
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ohlmann%2C+P">Pierre Ohlmann</a>, 
<a href="/search/cs?searchtype=author&query=Skrzypczak%2C+M">Micha&#x142; Skrzypczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We study the existence of positional strategies for the protagonist in
infinite duration games over arbitrary game graphs. We prove that
prefix-independent objectives in {\Sigma}_0^2 which are positional and admit a
(strongly) neutral letter are exactly those that are recognised by
history-deterministic monotone co-B\"uchi automata over countable ordinals.
This generalises a criterion proposed by [Kopczy\'nski, ICALP 2006] and gives
an alternative proof of closure under union for these objectives, which was
known from [Ohlmann, TheoretiCS 2023].
<br />We then give two applications of our result. First, we prove that the
mean-payoff objective is positional over arbitrary game graphs. Second, we
establish the following completeness result: for any objective W which is
prefix-independent, admits a (weakly) neutral letter, and is positional over
finite game graphs, there is an objective W' which is equivalent to W over
finite game graphs and positional over arbitrary game graphs.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17024" title="Abstract">arXiv:2309.17024</a> [<a href="/pdf/2309.17024" title="Download PDF">pdf</a>, <a href="/format/2309.17024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HoloAssist: an Egocentric Human Interaction Dataset for Interactive AI  Assistants in the Real World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+T">Taein Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Rad%2C+M">Mahdi Rad</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Bowen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+I">Ishani Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Andrist%2C+S">Sean Andrist</a>, 
<a href="/search/cs?searchtype=author&query=Bohus%2C+D">Dan Bohus</a>, 
<a href="/search/cs?searchtype=author&query=Feniello%2C+A">Ashley Feniello</a>, 
<a href="/search/cs?searchtype=author&query=Tekin%2C+B">Bugra Tekin</a>, 
<a href="/search/cs?searchtype=author&query=Frujeri%2C+F+V">Felipe Vieira Frujeri</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+N">Neel Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Building an interactive AI assistant that can perceive, reason, and
collaborate with humans in the real world has been a long-standing pursuit in
the AI community. This work is part of a broader research effort to develop
intelligent agents that can interactively guide humans through performing tasks
in the physical world. As a first step in this direction, we introduce
HoloAssist, a large-scale egocentric human interaction dataset, where two
people collaboratively complete physical manipulation tasks. The task performer
executes the task while wearing a mixed-reality headset that captures seven
synchronized data streams. The task instructor watches the performer's
egocentric video in real time and guides them verbally. By augmenting the data
with action and conversational annotations and observing the rich behaviors of
various participants, we present key insights into how human assistants correct
mistakes, intervene in the task completion procedure, and ground their
instructions to the environment. HoloAssist spans 166 hours of data captured by
350 unique instructor-performer pairs. Furthermore, we construct and present
benchmarks on mistake detection, intervention type prediction, and hand
forecasting, along with detailed analysis. We expect HoloAssist will provide an
important resource for building AI assistants that can fluidly collaborate with
humans in the real world. Data can be downloaded at
https://holoassist.github.io/.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17027" title="Abstract">arXiv:2309.17027</a> [<a href="/pdf/2309.17027" title="Download PDF">pdf</a>, <a href="/format/2309.17027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unfitted Spectral Element Method for interfacial models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gonzalez%2C+N">Nicolas Gonzalez</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+H">Hailong Guo</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+X">Xu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we propose the unfitted spectral element method for solving
elliptic interface and corresponding eigenvalue problems. The novelty of the
proposed method lies in its combination of the spectral accuracy of the
spectral element method and the flexibility of the unfitted Nitsche's method.
We also use tailored ghost penalty terms to enhance its robustness. We
establish optimal $hp$ convergence rates for both elliptic interface problems
and interface eigenvalue problems. Additionally, we demonstrate spectral
accuracy for model problems in terms of polynomial degree.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17031" title="Abstract">arXiv:2309.17031</a> [<a href="/pdf/2309.17031" title="Download PDF">pdf</a>, <a href="/format/2309.17031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Multi-Temporal Remote Sensing Change Data Generation via  Simulating Stochastic Change Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhuo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Shiqi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+A">Ailong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangpei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yanfei Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding the temporal dynamics of Earth's surface is a mission of
multi-temporal remote sensing image analysis, significantly promoted by deep
vision models with its fuel -- labeled multi-temporal images. However,
collecting, preprocessing, and annotating multi-temporal remote sensing images
at scale is non-trivial since it is expensive and knowledge-intensive. In this
paper, we present a scalable multi-temporal remote sensing change data
generator via generative modeling, which is cheap and automatic, alleviating
these problems. Our main idea is to simulate a stochastic change process over
time. We consider the stochastic change process as a probabilistic semantic
state transition, namely generative probabilistic change model (GPCM), which
decouples the complex simulation problem into two more trackable sub-problems,
\ie, change event simulation and semantic change synthesis. To solve these two
problems, we present the change generator (Changen), a GAN-based GPCM, enabling
controllable object change data generation, including customizable object
property, and change event. The extensive experiments suggest that our Changen
has superior generation capability, and the change detectors with Changen
pre-training exhibit excellent transferability to real-world change datasets.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17032" title="Abstract">arXiv:2309.17032</a> [<a href="/pdf/2309.17032" title="Download PDF">pdf</a>, <a href="/format/2309.17032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refined Kolmogorov Complexity of Analog, Evolving and Stochastic  Recurrent Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabessa%2C+J">J&#xe9;r&#xe9;mie Cabessa</a>, 
<a href="/search/cs?searchtype=author&query=Strozecki%2C+Y">Yann Strozecki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We provide a refined characterization of the super-Turing computational power
of analog, evolving, and stochastic neural networks based on the Kolmogorov
complexity of their real weights, evolving weights, and real probabilities,
respectively. First, we retrieve an infinite hierarchy of classes of analog
networks defined in terms of the Kolmogorov complexity of their underlying real
weights. This hierarchy is located between the complexity classes $\mathbf{P}$
and $\mathbf{P/poly}$. Then, we generalize this result to the case of evolving
networks. A similar hierarchy of Kolomogorov-based complexity classes of
evolving networks is obtained. This hierarchy also lies between $\mathbf{P}$
and $\mathbf{P/poly}$. Finally, we extend these results to the case of
stochastic networks employing real probabilities as source of randomness. An
infinite hierarchy of stochastic networks based on the Kolmogorov complexity of
their probabilities is therefore achieved. In this case, the hierarchy bridges
the gap between $\mathbf{BPP}$ and $\mathbf{BPP/log^*}$. Beyond proving the
existence and providing examples of such hierarchies, we describe a generic way
of constructing them based on classes of functions of increasing complexity.
For the sake of clarity, this study is formulated within the framework of echo
state networks. Overall, this paper intends to fill the missing results and
provide a unified view about the refined capabilities of analog, evolving and
stochastic neural networks.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17033" title="Abstract">arXiv:2309.17033</a> [<a href="/pdf/2309.17033" title="Download PDF">pdf</a>, <a href="/format/2309.17033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Document Structures with YOLOv5 Layout Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sugiharto%2C+H">Herman Sugiharto</a>, 
<a href="/search/cs?searchtype=author&query=Silviana%2C+Y">Yorissa Silviana</a>, 
<a href="/search/cs?searchtype=author&query=Nurpazrin%2C+Y+S">Yani Siti Nurpazrin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The current digital environment is characterized by the widespread presence
of data, particularly unstructured data, which poses many issues in sectors
including finance, healthcare, and education. Conventional techniques for data
extraction encounter difficulties in dealing with the inherent variety and
complexity of unstructured data, hence requiring the adoption of more efficient
methodologies. This research investigates the utilization of YOLOv5, a
cutting-edge computer vision model, for the purpose of rapidly identifying
document layouts and extracting unstructured data.
<br />The present study establishes a conceptual framework for delineating the
notion of "objects" as they pertain to documents, incorporating various
elements such as paragraphs, tables, photos, and other constituent parts. The
main objective is to create an autonomous system that can effectively recognize
document layouts and extract unstructured data, hence improving the
effectiveness of data extraction.
<br />In the conducted examination, the YOLOv5 model exhibits notable effectiveness
in the task of document layout identification, attaining a high accuracy rate
along with a precision value of 0.91, a recall value of 0.971, an F1-score of
0.939, and an area under the receiver operating characteristic curve (AUC-ROC)
of 0.975. The remarkable performance of this system optimizes the process of
extracting textual and tabular data from document images. Its prospective
applications are not limited to document analysis but can encompass
unstructured data from diverse sources, such as audio data.
<br />This study lays the foundation for future investigations into the wider
applicability of YOLOv5 in managing various types of unstructured data,
offering potential for novel applications across multiple domains.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17034" title="Abstract">arXiv:2309.17034</a> [<a href="/pdf/2309.17034" title="Download PDF">pdf</a>, <a href="/format/2309.17034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Method for Identification and Ranking of Requirements Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klotins%2C+E">Eriks Klotins</a>, 
<a href="/search/cs?searchtype=author&query=Boeva%2C+V">Veselka Boeva</a>, 
<a href="/search/cs?searchtype=author&query=Wnuk%2C+K">Krzysztof Wnuk</a>, 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Gorschek%2C+T">Tony Gorschek</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+S">Slinger Jansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Requirements engineering (RE) literature acknowledges the importance of early
stakeholder identification. The sources of requirements are many and also
constantly changing as the market and business constantly change.
<br />Identifying and consulting all stakeholders on the market is impractical;
thus many companies utilize indirect data sources, e.g. documents and
representatives of larger groups of stakeholders. However, companies often
collect irrelevant data or develop their products based on the sub-optimal
information sources that may lead to missing market opportunities.
<br />We propose a collaborative method for identification and selection of data
sources. The method consists of four steps and aims to build consensus between
different perspectives in an organization. We demonstrate the use of the method
with three industrial case studies. We have presented and statically validated
the method to support prioritization of stakeholders for MDRE. Our results show
that the method can support the identification and selection of data sources in
three ways: (1) by providing systematic steps to identify and prioritize data
sources for RE, (2) by highlighting and resolving discrepancies between
different perspectives in an organization, and (3) by analyzing the underlying
rationale for using certain data sources.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17035" title="Abstract">arXiv:2309.17035</a> [<a href="/pdf/2309.17035" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextualising Levels of Language Resourcedness affecting Digital  Processing of Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keet%2C+C+M">C. Maria Keet</a>, 
<a href="/search/cs?searchtype=author&query=Khumalo%2C+L">Langa Khumalo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Application domains such as digital humanities and tool like chatbots involve
some form of processing natural language, from digitising hardcopies to speech
generation. The language of the content is typically characterised as either a
low resource language (LRL) or high resource language (HRL), also known as
resource-scarce and well-resourced languages, respectively. African languages
have been characterized as resource-scarce languages (Bosch et al. 2007;
Pretorius &amp; Bosch 2003; Keet &amp; Khumalo 2014) and English is by far the most
well-resourced language. Varied language resources are used to develop software
systems for these languages to accomplish a wide range of tasks. In this paper
we argue that the dichotomous typology LRL and HRL for all languages is
problematic. Through a clear understanding of language resources situated in a
society, a matrix is developed that characterizes languages as Very LRL, LRL,
RL, HRL and Very HRL. The characterization is based on the typology of
contextual features for each category, rather than counting tools, and
motivation is provided for each feature and each characterization. The
contextualisation of resourcedness, with a focus on African languages in this
paper, and an increased understanding of where on the scale the language used
in a project is, may assist in, among others, better planning of research and
implementation projects. We thus argue in this paper that the characterization
of language resources within a given scale in a project is an indispensable
component particularly in the context of low-resourced languages.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17036" title="Abstract">arXiv:2309.17036</a> [<a href="/pdf/2309.17036" title="Download PDF">pdf</a>, <a href="/format/2309.17036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniQuadric: A SLAM Backend for Unknown Rigid Object 3D Tracking and  Light-Weight Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linghao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanmin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yu Deng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+R">Rui Tian</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinggang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tiefeng Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Tracking and modeling unknown rigid objects in the environment play a crucial
role in autonomous unmanned systems and virtual-real interactive applications.
However, many existing Simultaneous Localization, Mapping and Moving Object
Tracking (SLAMMOT) methods focus solely on estimating specific object poses and
lack estimation of object scales and are unable to effectively track unknown
objects. In this paper, we propose a novel SLAM backend that unifies ego-motion
tracking, rigid object motion tracking, and modeling within a joint
optimization framework. In the perception part, we designed a pixel-level
asynchronous object tracker (AOT) based on the Segment Anything Model (SAM) and
DeAOT, enabling the tracker to effectively track target unknown objects guided
by various predefined tasks and prompts. In the modeling part, we present a
novel object-centric quadric parameterization to unify both static and dynamic
object initialization and optimization. Subsequently, in the part of object
state estimation, we propose a tightly coupled optimization model for object
pose and scale estimation, incorporating hybrids constraints into a novel dual
sliding window optimization framework for joint estimation. To our knowledge,
we are the first to tightly couple object pose tracking with light-weight
modeling of dynamic and static objects using quadric. We conduct qualitative
and quantitative experiments on simulation datasets and real-world datasets,
demonstrating the state-of-the-art robustness and accuracy in motion estimation
and modeling. Our system showcases the potential application of object
perception in complex dynamic scenes.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17037" title="Abstract">arXiv:2309.17037</a> [<a href="/pdf/2309.17037" title="Download PDF">pdf</a>, <a href="/format/2309.17037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Co-occurrence: Multi-modal Session-based Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaokun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fenglong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongfei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by TKDE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Session-based recommendation is devoted to characterizing preferences of
anonymous users based on short sessions. Existing methods mostly focus on
mining limited item co-occurrence patterns exposed by item ID within sessions,
while ignoring what attracts users to engage with certain items is rich
multi-modal information displayed on pages. Generally, the multi-modal
information can be classified into two categories: descriptive information
(e.g., item images and description text) and numerical information (e.g.,
price). In this paper, we aim to improve session-based recommendation by
modeling the above multi-modal information holistically. There are mainly three
issues to reveal user intent from multi-modal information: (1) How to extract
relevant semantics from heterogeneous descriptive information with different
noise? (2) How to fuse these heterogeneous descriptive information to
comprehensively infer user interests? (3) How to handle probabilistic influence
of numerical information on user behaviors? To solve above issues, we propose a
novel multi-modal session-based recommendation (MMSBR) that models both
descriptive and numerical information under a unified framework. Specifically,
a pseudo-modality contrastive learning is devised to enhance the representation
learning of descriptive information. Afterwards, a hierarchical pivot
transformer is presented to fuse heterogeneous descriptive information.
Moreover, we represent numerical information with Gaussian distribution and
design a Wasserstein self-attention to handle the probabilistic influence mode.
Extensive experiments on three real-world datasets demonstrate the
effectiveness of the proposed MMSBR. Further analysis also proves that our
MMSBR can alleviate the cold-start problem in SBR effectively.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17038" title="Abstract">arXiv:2309.17038</a> [<a href="/pdf/2309.17038" title="Download PDF">pdf</a>, <a href="/format/2309.17038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost Reduction on Testing Evolving Cancer Registry System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isaku%2C+E">Erblin Isaku</a>, 
<a href="/search/cs?searchtype=author&query=Sartaj%2C+H">Hassan Sartaj</a>, 
<a href="/search/cs?searchtype=author&query=Laaber%2C+C">Christoph Laaber</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>, 
<a href="/search/cs?searchtype=author&query=Schwitalla%2C+T">Thomas Schwitalla</a>, 
<a href="/search/cs?searchtype=author&query=Nyg%C3%A5rd%2C+J+F">Jan F. Nyg&#xe5;rd</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, accepted to the industry track of the 2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The Cancer Registration Support System (CaReSS), built by the Cancer Registry
of Norway (CRN), is a complex real-world socio-technical software system that
undergoes continuous evolution in its implementation. Consequently, continuous
testing of CaReSS with automated testing tools is needed such that its
dependability is always ensured. Towards automated testing of a key software
subsystem of CaReSS, i.e., GURI, we present a real-world application of an
extension to the open-source tool EvoMaster, which automatically generates test
cases with evolutionary algorithms. We named the extension EvoClass, which
enhances EvoMaster with a machine learning classifier to reduce the overall
testing cost. This is imperative since testing with EvoMaster involves sending
many requests to GURI deployed in different environments, including the
production environment, whose performance and functionality could potentially
be affected by many requests. The machine learning classifier of EvoClass can
predict whether a request generated by EvoMaster will be executed successfully
or not; if not, the classifier filters out such requests, consequently reducing
the number of requests to be executed on GURI. We evaluated EvoClass on ten
GURI versions over four years in three environments: development, testing, and
production. Results showed that EvoClass can significantly reduce the testing
cost of evolving GURI without reducing testing effectiveness (measured as rule
coverage) across all three environments, as compared to the default EvoMaster.
Overall, EvoClass achieved ~31% of overall cost reduction. Finally, we report
our experiences and lessons learned that are equally valuable for researchers
and practitioners.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17039" title="Abstract">arXiv:2309.17039</a> [<a href="/pdf/2309.17039" title="Download PDF">pdf</a>, <a href="/format/2309.17039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing singular and near-singular integrals over curved boundary  elements: The strongly singular case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Montanelli%2C+H">Hadrien Montanelli</a>, 
<a href="/search/math?searchtype=author&query=Collino%2C+F">Francis Collino</a>, 
<a href="/search/math?searchtype=author&query=Haddar%2C+H">Houssem Haddar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present algorithms for computing strongly singular and near-singular
surface integrals over curved triangular patches, based on singularity
subtraction, the continuation approach, and transplanted Gauss quadrature. We
demonstrate the accuracy and robustness of our method for quadratic basis
functions and quadratic triangles by integrating it into a boundary element
code and solving several scattering problems in 3D. We also give numerical
evidence that the utilization of curved boundary elements enhances
computational efficiency compared to conventional planar elements.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17042" title="Abstract">arXiv:2309.17042</a> [<a href="/pdf/2309.17042" title="Download PDF">pdf</a>, <a href="/format/2309.17042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumeration Complexity: Incremental Time, Delay and Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strozecki%2C+Y">Yann Strozecki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Habilitation thesis manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">This habilitation thesis is intended to be a good introduction to
enumeration, the problem of listing solutions. It focuses on the different ways
of measuring complexity in enumeration, with a particular emphasis on my
contributions to the field.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17046" title="Abstract">arXiv:2309.17046</a> [<a href="/pdf/2309.17046" title="Download PDF">pdf</a>, <a href="/format/2309.17046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrossLoco: Human Motion Driven Control of Legged Robots via Guided  Unsupervised Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">Hyunyoung Jung</a>, 
<a href="/search/cs?searchtype=author&query=Gombolay%2C+M">Matthew Gombolay</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y+K">Yong Kwon Cho</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+S">Sehoon Ha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Human motion driven control (HMDC) is an effective approach for generating
natural and compelling robot motions while preserving high-level semantics.
However, establishing the correspondence between humans and robots with
different body structures is not straightforward due to the mismatches in
kinematics and dynamics properties, which causes intrinsic ambiguity to the
problem. Many previous algorithms approach this motion retargeting problem with
unsupervised learning, which requires the prerequisite skill sets. However, it
will be extremely costly to learn all the skills without understanding the
given human motions, particularly for high-dimensional robots. In this work, we
introduce CrossLoco, a guided unsupervised reinforcement learning framework
that simultaneously learns robot skills and their correspondence to human
motions. Our key innovation is to introduce a cycle-consistency-based reward
term designed to maximize the mutual information between human motions and
robot states. We demonstrate that the proposed framework can generate
compelling robot motions by translating diverse human motions, such as running,
hopping, and dancing. We quantitatively compare our CrossLoco against the
manually engineered and unsupervised baseline algorithms along with the ablated
versions of our framework and demonstrate that our method translates human
motions with better accuracy, diversity, and user preference. We also showcase
its utility in other applications, such as synthesizing robot movements from
language input and enabling interactive robot control.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17048" title="Abstract">arXiv:2309.17048</a> [<a href="/pdf/2309.17048" title="Download PDF">pdf</a>, <a href="/format/2309.17048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Continuity of Robust and Accurate Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barati%2C+R">Ramin Barati</a>, 
<a href="/search/cs?searchtype=author&query=Safabakhsh%2C+R">Reza Safabakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Rahmati%2C+M">Mohammad Rahmati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The reliability of a learning model is key to the successful deployment of
machine learning in various applications. Creating a robust model, particularly
one unaffected by adversarial attacks, requires a comprehensive understanding
of the adversarial examples phenomenon. However, it is difficult to describe
the phenomenon due to the complicated nature of the problems in machine
learning. It has been shown that adversarial training can improve the
robustness of the hypothesis. However, this improvement comes at the cost of
decreased performance on natural samples. Hence, it has been suggested that
robustness and accuracy of a hypothesis are at odds with each other. In this
paper, we put forth the alternative proposal that it is the continuity of a
hypothesis that is incompatible with its robustness and accuracy. In other
words, a continuous function cannot effectively learn the optimal robust
hypothesis. To this end, we will introduce a framework for a rigorous study of
harmonic and holomorphic hypothesis in learning theory terms and provide
empirical evidence that continuous hypotheses does not perform as well as
discontinuous hypotheses in some common machine learning tasks. From a
practical point of view, our results suggests that a robust and accurate
learning rule would train different continuous hypotheses for different regions
of the domain. From a theoretical perspective, our analysis explains the
adversarial examples phenomenon as a conflict between the continuity of a
sequence of functions and its uniform convergence to a discontinuous function.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17049" title="Abstract">arXiv:2309.17049</a> [<a href="/pdf/2309.17049" title="Download PDF">pdf</a>, <a href="/format/2309.17049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPT Approximation of Generalised Hypertree Width for Bounded  Intersection Hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lanzinger%2C+M">Matthias Lanzinger</a>, 
<a href="/search/cs?searchtype=author&query=Razgon%2C+I">Igor Razgon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Generalised hypertree width ($ghw$) is a hypergraph parameter that is central
to the tractability of many prominent problems with natural hypergraph
structure. Computing $ghw$ of a hypergraph is notoriously hard. The decision
version of the problem, checking whether $ghw(H) \leq k$, is paraNP-hard when
parameterised by $k$. Furthermore, approximation of $ghw$ is at least as hard
as approximation of Set-Cover, which is known to not admit any fpt
approximation algorithms.
<br />Research in the computation of ghw so far has focused on identifying
structural restrictions to hypergraphs -- such as bounds on the size of edge
intersections -- that permit XP algorithms for $ghw$. Yet, even under these
restrictions that problem has so far evaded any kind of fpt algorithm. In this
paper we make the first step towards fpt algorithms for $ghw$ by showing that
the parameter can be approximated in fpt time for graphs of bounded edge
intersection size. In concrete terms we show that there exists an fpt
algorithm, parameterised by $k$ and $d$, that for input hypergraph $H$ with
maximal cardinality of edge intersections $d$ and integer $k$ either outputs a
tree decomposition with $ghw(H) \leq 4k(k+d+1+)(2k-1)$, or rejects, in which
case it is guaranteed that $ghw(H) &gt; k$. Thus, in the special case, of
hypergraphs of bounded edge intersection, we obtain an fpt
$O(k^3)$-approximation algorithm for $ghw$.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17050" title="Abstract">arXiv:2309.17050</a> [<a href="/pdf/2309.17050" title="Download PDF">pdf</a>, <a href="/format/2309.17050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Long-Form Legal Question Answering with  Retrieval-Augmented Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Louis%2C+A">Antoine Louis</a>, 
<a href="/search/cs?searchtype=author&query=van+Dijck%2C+G">Gijs van Dijck</a>, 
<a href="/search/cs?searchtype=author&query=Spanakis%2C+G">Gerasimos Spanakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. Code is available at <a href="https://github.com/maastrichtlawtech/lleqa">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Many individuals are likely to face a legal dispute at some point in their
lives, but their lack of understanding of how to navigate these complex issues
often renders them vulnerable. The advancement of natural language processing
opens new avenues for bridging this legal literacy gap through the development
of automated legal aid systems. However, existing legal question answering
(LQA) approaches often suffer from a narrow scope, being either confined to
specific legal domains or limited to brief, uninformative responses. In this
work, we propose an end-to-end methodology designed to generate long-form
answers to any statutory law questions, utilizing a "retrieve-then-read"
pipeline. To support this approach, we introduce and release the Long-form
Legal Question Answering (LLeQA) dataset, comprising 1,868 expert-annotated
legal questions in the French language, complete with detailed answers rooted
in pertinent legal provisions. Our experimental results demonstrate promising
performance on automatic evaluation metrics, but a qualitative analysis
uncovers areas for refinement. As one of the only comprehensive,
expert-annotated long-form LQA dataset, LLeQA has the potential to not only
accelerate research towards resolving a significant real-world issue, but also
act as a rigorous benchmark for evaluating NLP models in specialized domains.
We publicly release our code, data, and models.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17051" title="Abstract">arXiv:2309.17051</a> [<a href="/pdf/2309.17051" title="Download PDF">pdf</a>, <a href="/format/2309.17051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Uniform Scalar Quantization for Learned Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haotian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learned image compression possesses a unique challenge when incorporating
non-differentiable quantization into the gradient-based training of the
networks. Several quantization surrogates have been proposed to fulfill the
training, but they were not systematically justified from a theoretical
perspective. We fill this gap by contrasting uniform scalar quantization, the
most widely used category with rounding being its simplest case, and its
training surrogates. In principle, we find two factors crucial: one is the
discrepancy between the surrogate and rounding, leading to train-test mismatch;
the other is gradient estimation risk due to the surrogate, which consists of
bias and variance of the gradient estimation. Our analyses and simulations
imply that there is a tradeoff between the train-test mismatch and the gradient
estimation risk, and the tradeoff varies across different network structures.
Motivated by these analyses, we present a method based on stochastic uniform
annealing, which has an adjustable temperature coefficient to control the
tradeoff. Moreover, our analyses enlighten us as to two subtle tricks: one is
to set an appropriate lower bound for the variance parameter of the estimated
quantized latent distribution, which effectively reduces the train-test
mismatch; the other is to use zero-center quantization with partial
stop-gradient, which reduces the gradient estimation variance and thus
stabilize the training. Our method with the tricks is verified to outperform
the existing practices of quantization surrogates on a variety of
representative image compression networks.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17053" title="Abstract">arXiv:2309.17053</a> [<a href="/pdf/2309.17053" title="Download PDF">pdf</a>, <a href="/ps/2309.17053" title="Download PostScript">ps</a>, <a href="/format/2309.17053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Power of the Weisfeiler-Leman Test for Graph Motif Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barcel%C3%B3%2C+P">Pablo Barcel&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Lanzinger%2C+M">Matthias Lanzinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Seminal research in the field of graph neural networks (GNNs) has revealed a
direct correspondence between the expressive capabilities of GNNs and the
$k$-dimensional Weisfeiler-Leman ($k$WL) test, a widely-recognized method for
verifying graph isomorphism. This connection has reignited interest in
comprehending the specific graph properties effectively distinguishable by the
$k$WL test. A central focus of research in this field revolves around
determining the least dimensionality $k$, for which $k$WL can discern graphs
with different number of occurrences of a pattern graph $P$. We refer to such a
least $k$ as the WL-dimension of this pattern counting problem. This inquiry
traditionally delves into two distinct counting problems related to patterns:
subgraph counting and induced subgraph counting. Intriguingly, despite their
initial appearance as separate challenges with seemingly divergent approaches,
both of these problems are interconnected components of a more comprehensive
problem: "graph motif parameters". In this paper, we provide a precise
characterization of the WL-dimension of labeled graph motif parameters. As
specific instances of this result, we obtain characterizations of the
WL-dimension of the subgraph counting and induced subgraph counting problem for
every labeled pattern $P$. We additionally demonstrate that in cases where the
$k$WL test distinguishes between graphs with varying occurrences of a pattern
$P$, the exact number of occurrences of $P$ can be computed uniformly using
only local information of the last layer of a corresponding GNN. We finally
delve into the challenge of recognizing the WL-dimension of various graph
parameters. We give a polynomial time algorithm for determining the
WL-dimension of the subgraph counting problem for given pattern $P$, answering
an open question from previous work.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17054" title="Abstract">arXiv:2309.17054</a> [<a href="/pdf/2309.17054" title="Download PDF">pdf</a>, <a href="/format/2309.17054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A 5-Point Minimal Solver for Event Camera Relative Motion Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Ling Gao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Gehrig%2C+D">Daniel Gehrig</a>, 
<a href="/search/cs?searchtype=author&query=Cannici%2C+M">Marco Cannici</a>, 
<a href="/search/cs?searchtype=author&query=Scaramuzza%2C+D">Davide Scaramuzza</a>, 
<a href="/search/cs?searchtype=author&query=Kneip%2C+L">Laurent Kneip</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE/CVF International Conference on Computer Vision (ICCV), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Event-based cameras are ideal for line-based motion estimation, since they
predominantly respond to edges in the scene. However, accurately determining
the camera displacement based on events continues to be an open problem. This
is because line feature extraction and dynamics estimation are tightly coupled
when using event cameras, and no precise model is currently available for
describing the complex structures generated by lines in the space-time volume
of events. We solve this problem by deriving the correct non-linear
parametrization of such manifolds, which we term eventails, and demonstrate its
application to event-based linear motion estimation, with known rotation from
an Inertial Measurement Unit. Using this parametrization, we introduce a novel
minimal 5-point solver that jointly estimates line parameters and linear camera
velocity projections, which can be fused into a single, averaged linear
velocity when considering multiple lines. We demonstrate on both synthetic and
real data that our solver generates more stable relative motion estimates than
other methods while capturing more inliers than clustering based on
spatio-temporal planes. In particular, our method consistently achieves a 100%
success rate in estimating linear velocity where existing closed-form solvers
only achieve between 23% and 70%. The proposed eventails contribute to a better
understanding of spatio-temporal event-generated geometries and we thus believe
it will become a core building block of future event-based motion estimation
algorithms.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17055" title="Abstract">arXiv:2309.17055</a> [<a href="/pdf/2309.17055" title="Download PDF">pdf</a>, <a href="/format/2309.17055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Application Driven Method for Assembling Numerical Schemes for the  Solution of Complex Multiphysics Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zimbrod%2C+P">Patrick Zimbrod</a>, 
<a href="/search/math?searchtype=author&query=Fleck%2C+M">Michael Fleck</a>, 
<a href="/search/math?searchtype=author&query=Schilp%2C+J">Johannes Schilp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The accurate representation and prediction of physical phenomena through
numerical computer codes remains to be a vast and intricate interdisciplinary
topic of research. Especially within the last decades, there has been a
considerable push toward high performance numerical schemes to solve partial
differential equations (PDEs) from the applied mathematics and numerics
community. The resulting landscape of choices regarding numerical schemes for a
given system of PDEs can thus easily appear daunting for an application expert
that is familiar with the relevant physics, but not necessarily with the
numerics. Bespoke high performance schemes in particular pose a substantial
hurdle for domain scientists regarding their theory and implementation. Here,
we propose a unifying scheme for grid based approximation methods to address
this issue. We introduce some well defined restrictions to systematically guide
an application expert through the process of classifying a given multiphysics
problem, identifying suitable numerical schemes and implementing them. We
introduce a fixed set of input parameters, amongst them for example the
governing equations and the hardware configuration. This method not only helps
to identify and assemble suitable schemes, but enables the unique combination
of multiple methods on a per field basis. We exemplarily demonstrate this
process and its effectiveness using different approaches and systematically
show how one should exploit some given properties of a PDE problem to arrive at
an efficient compound discretisation.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17056" title="Abstract">arXiv:2309.17056</a> [<a href="/pdf/2309.17056" title="Download PDF">pdf</a>, <a href="/format/2309.17056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReFlow-TTS: A Rectified Flow Model for High-fidelity Text-to-Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+W">Wenhao Guan</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Q">Qi Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haodong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+S">Shiyu Miao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xingjia Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Q">Qingyang Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The diffusion models including Denoising Diffusion Probabilistic Models
(DDPM) and score-based generative models have demonstrated excellent
performance in speech synthesis tasks. However, its effectiveness comes at the
cost of numerous sampling steps, resulting in prolonged sampling time required
to synthesize high-quality speech. This drawback hinders its practical
applicability in real-world scenarios. In this paper, we introduce ReFlow-TTS,
a novel rectified flow based method for speech synthesis with high-fidelity.
Specifically, our ReFlow-TTS is simply an Ordinary Differential Equation (ODE)
model that transports Gaussian distribution to the ground-truth Mel-spectrogram
distribution by straight line paths as much as possible. Furthermore, our
proposed approach enables high-quality speech synthesis with a single sampling
step and eliminates the need for training a teacher model. Our experiments on
LJSpeech Dataset show that our ReFlow-TTS method achieves the best performance
compared with other diffusion based models. And the ReFlow-TTS with one step
sampling achieves competitive performance compared with existing one-step TTS
models.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17057" title="Abstract">arXiv:2309.17057</a> [<a href="/pdf/2309.17057" title="Download PDF">pdf</a>, <a href="/format/2309.17057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tell Me a Story! Narrative-Driven XAI with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martens%2C+D">David Martens</a>, 
<a href="/search/cs?searchtype=author&query=Dams%2C+C">Camille Dams</a>, 
<a href="/search/cs?searchtype=author&query=Hinns%2C+J">James Hinns</a>, 
<a href="/search/cs?searchtype=author&query=Vergouwen%2C+M">Mark Vergouwen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In today's critical domains, the predominance of black-box machine learning
models amplifies the demand for Explainable AI (XAI). The widely used SHAP
values, while quantifying feature importance, are often too intricate and lack
human-friendly explanations. Furthermore, counterfactual (CF) explanations
present `what ifs' but leave users grappling with the 'why'. To bridge this
gap, we introduce XAIstories. Leveraging Large Language Models, XAIstories
provide narratives that shed light on AI predictions: SHAPstories do so based
on SHAP explanations to explain a prediction score, while CFstories do so for
CF explanations to explain a decision. Our results are striking: over 90% of
the surveyed general audience finds the narrative generated by SHAPstories
convincing. Data scientists primarily see the value of SHAPstories in
communicating explanations to a general audience, with 92% of data scientists
indicating that it will contribute to the ease and confidence of nonspecialists
in understanding AI predictions. Additionally, 83% of data scientists indicate
they are likely to use SHAPstories for this purpose. In image classification,
CFstories are considered more or equally convincing as users own crafted
stories by over 75% of lay user participants. CFstories also bring a tenfold
speed gain in creating a narrative, and improves accuracy by over 20% compared
to manually created narratives. The results thereby suggest that XAIstories may
provide the missing link in truly explaining and understanding AI predictions.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17058" title="Abstract">arXiv:2309.17058</a> [<a href="/pdf/2309.17058" title="Download PDF">pdf</a>, <a href="/format/2309.17058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imagery Dataset for Condition Monitoring of Synthetic Fibre Ropes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rani%2C+A">Anju Rani</a>, 
<a href="/search/cs?searchtype=author&query=Arroyo%2C+D+O">Daniel O. Arroyo</a>, 
<a href="/search/cs?searchtype=author&query=Durdevic%2C+P">Petar Durdevic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, database
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic visual inspection of synthetic fibre ropes (SFRs) is a challenging
task in the field of offshore, wind turbine industries, etc. The presence of
any defect in SFRs can compromise their structural integrity and pose
significant safety risks. Due to the large size and weight of these ropes, it
is often impractical to detach and inspect them frequently. Therefore, there is
a critical need to develop efficient defect detection methods to assess their
remaining useful life (RUL). To address this challenge, a comprehensive dataset
has been generated, comprising a total of 6,942 raw images representing both
normal and defective SFRs. The dataset encompasses a wide array of defect
scenarios which may occur throughout their operational lifespan, including but
not limited to placking defects, cut strands, chafings, compressions, core outs
and normal. This dataset serves as a resource to support computer vision
applications, including object detection, classification, and segmentation,
aimed at detecting and analyzing defects in SFRs. The availability of this
dataset will facilitate the development and evaluation of robust defect
detection algorithms. The aim of generating this dataset is to assist in the
development of automated defect detection systems that outperform traditional
visual inspection methods, thereby paving the way for safer and more efficient
utilization of SFRs across a wide range of applications.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17059" title="Abstract">arXiv:2309.17059</a> [<a href="/pdf/2309.17059" title="Download PDF">pdf</a>, <a href="/format/2309.17059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSDC Transformer: An Efficient and Effective Cue Fusion for Monocular  Multi-Frame Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+N">Naiyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lemiao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zheyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kerui Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depth estimation provides an alternative approach for perceiving 3D
information in autonomous driving. Monocular depth estimation, whether with
single-frame or multi-frame inputs, has achieved significant success by
learning various types of cues and specializing in either static or dynamic
scenes. Recently, these cues fusion becomes an attractive topic, aiming to
enable the combined cues to perform well in both types of scenes. However,
adaptive cue fusion relies on attention mechanisms, where the quadratic
complexity limits the granularity of cue representation. Additionally, explicit
cue fusion depends on precise segmentation, which imposes a heavy burden on
mask prediction. To address these issues, we propose the GSDC Transformer, an
efficient and effective component for cue fusion in monocular multi-frame depth
estimation. We utilize deformable attention to learn cue relationships at a
fine scale, while sparse attention reduces computational requirements when
granularity increases. To compensate for the precision drop in dynamic scenes,
we represent scene attributes in the form of super tokens without relying on
precise shapes. Within each super token attributed to dynamic scenes, we gather
its relevant cues and learn local dense relationships to enhance cue fusion.
Our method achieves state-of-the-art performance on the KITTI dataset with
efficient fusion speed.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17061" title="Abstract">arXiv:2309.17061</a> [<a href="/pdf/2309.17061" title="Download PDF">pdf</a>, <a href="/format/2309.17061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCALE: Synergized Collaboration of Asymmetric Language Translation  Engines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Si-Qing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we introduce SCALE, a collaborative framework that connects
compact Specialized Translation Models (STMs) and general-purpose Large
Language Models (LLMs) as one unified translation engine. By introducing
translation from STM into the triplet in-context demonstrations, SCALE unlocks
refinement and pivoting ability of LLM, thus mitigating language bias of LLM
and parallel data bias of STM, enhancing LLM speciality without sacrificing
generality, and facilitating continual learning without expensive LLM
fine-tuning. Our comprehensive experiments show that SCALE significantly
outperforms both few-shot LLMs (GPT-4) and specialized models (NLLB) in
challenging low-resource settings. Moreover, in Xhosa to English translation,
SCALE experiences consistent improvement by a 4 BLEURT score without tuning LLM
and surpasses few-shot GPT-4 by 2.5 COMET score and 3.8 BLEURT score when
equipped with a compact model consisting of merely 600M parameters. SCALE could
also effectively exploit the existing language bias of LLMs by using an
English-centric STM as a pivot for translation between any language pairs,
outperforming few-shot GPT-4 by an average of 6 COMET points across eight
translation directions. Furthermore we provide an in-depth analysis of SCALE's
robustness, translation characteristics, and latency costs, providing solid
foundation for future studies exploring the potential synergy between LLMs and
more specialized, task-specific models.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17063" title="Abstract">arXiv:2309.17063</a> [<a href="/pdf/2309.17063" title="Download PDF">pdf</a>, <a href="/format/2309.17063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GateSeeder: Near-memory CPU-FPGA Acceleration of Short and Long Read  Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eudine%2C+J">Julien Eudine</a>, 
<a href="/search/cs?searchtype=author&query=Alser%2C+M">Mohammed Alser</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gagandeep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Alkan%2C+C">Can Alkan</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Data Structures and Algorithms (cs.DS); Genomics (q-bio.GN)

</div>
<p class="mathjax">Motivation: Read mapping is a computationally expensive process and a major
bottleneck in genomics analyses. The performance of read mapping is mainly
limited by the performance of three key computational steps: Index Querying,
Seed Chaining, and Sequence Alignment. The first step is dominated by how fast
and frequent it accesses the main memory (i.e., memory-bound), while the latter
two steps are dominated by how fast the CPU can compute their
computationally-costly dynamic programming algorithms (i.e., compute-bound).
Accelerating these three steps by exploiting new algorithms and new hardware
devices is essential to accelerate most genome analysis pipelines that widely
use read mapping. Given the large body of work on accelerating Sequence
Alignment, this work focuses on significantly improving the remaining steps.
Results: We introduce GateSeeder, the first CPU-FPGA-based near-memory
acceleration of both short and long read mapping. GateSeeder exploits
near-memory computation capability provided by modern FPGAs that couple a
reconfigurable compute fabric with high-bandwidth memory (HBM) to overcome the
memory-bound and compute-bound bottlenecks. GateSeeder also introduces a new
lightweight algorithm for finding the potential matching segment pairs. Using
real ONT, HiFi, and Illumina sequences, we experimentally demonstrate that
GateSeeder outperforms Minimap2, without performing sequence alignment, by up
to 40.3x, 4.8x, and 2.3x, respectively. When performing read mapping with
sequence alignment, GateSeeder outperforms Minimap2 by 1.15-4.33x (using KSW2)
and by 1.97-13.63x (using WFA-GPU). Availability:
https://github.com/CMU-SAFARI/GateSeeder
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17072" title="Abstract">arXiv:2309.17072</a> [<a href="/pdf/2309.17072" title="Download PDF">pdf</a>, <a href="/format/2309.17072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaaSDB: Spatial Databases in the Era of Large Language Models (Vision  Paper)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jianzhong Qi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Tanin%2C+E">Egemen Tanin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to appear in ACM SIGSPATIAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Large language models (LLMs) are advancing rapidly. Such models have
demonstrated strong capabilities in learning from large-scale (unstructured)
text data and answering user queries. Users do not need to be experts in
structured query languages to interact with systems built upon such models.
This provides great opportunities to reduce the barrier of information
retrieval for the general public. By introducing LLMs into spatial data
management, we envisage an LLM-based spatial database system to learn from both
structured and unstructured spatial data. Such a system will offer seamless
access to spatial knowledge for the users, thus benefiting individuals,
business, and government policy makers alike.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17074" title="Abstract">arXiv:2309.17074</a> [<a href="/pdf/2309.17074" title="Download PDF">pdf</a>, <a href="/format/2309.17074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeeDiff: Dynamic Uncertainty-Aware Early Exiting for Accelerating  Diffusion Model Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shengkun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models achieve great success in generating diverse and
high-fidelity images. The performance improvements come with low generation
speed per image, which hinders the application diffusion models in real-time
scenarios. While some certain predictions benefit from the full computation of
the model in each sample iteration, not every iteration requires the same
amount of computation, potentially leading to computation waste. In this work,
we propose DeeDiff, an early exiting framework that adaptively allocates
computation resources in each sampling step to improve the generation
efficiency of diffusion models. Specifically, we introduce a timestep-aware
uncertainty estimation module (UEM) for diffusion models which is attached to
each intermediate layer to estimate the prediction uncertainty of each layer.
The uncertainty is regarded as the signal to decide if the inference
terminates. Moreover, we propose uncertainty-aware layer-wise loss to fill the
performance gap between full models and early-exited models. With such loss
strategy, our model is able to obtain comparable results as full-layer models.
Extensive experiments of class-conditional, unconditional, and text-guided
generation on several datasets show that our method achieves state-of-the-art
performance and efficiency trade-off compared with existing early exiting
methods on diffusion models. More importantly, our method even brings extra
benefits to baseline models and obtains better performance on CIFAR-10 and
Celeb-A datasets. Full code and model are released for reproduction.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17078" title="Abstract">arXiv:2309.17078</a> [<a href="/pdf/2309.17078" title="Download PDF">pdf</a>, <a href="/format/2309.17078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning the Capabilities of Large Language Models with the Context of  Information Retrieval via Contrastive Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qian Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiding Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhijing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haitao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shaoping Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Arxiv version of RLCF
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Information Retrieval (IR), the process of finding information to satisfy
user's information needs, plays an essential role in modern people's lives.
Recently, large language models (LLMs) have demonstrated remarkable
capabilities across various tasks, some of which are important for IR.
Nonetheless, LLMs frequently confront the issue of generating responses that
lack specificity. This has limited the overall effectiveness of LLMs for IR in
many cases. To address these issues, we present an unsupervised alignment
framework called Reinforcement Learning from Contrastive Feedback (RLCF), which
empowers LLMs to generate both high-quality and context-specific responses that
suit the needs of IR tasks. Specifically, we construct contrastive feedback by
comparing each document with its similar documents, and then propose a reward
function named Batched-MRR to teach LLMs to generate responses that captures
the fine-grained information that distinguish documents from their similar
ones. To demonstrate the effectiveness of RLCF, we conducted experiments in two
typical applications of LLMs in IR, i.e., data augmentation and summarization.
The experimental results show that RLCF can effectively improve the performance
of LLMs in IR context.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17079" title="Abstract">arXiv:2309.17079</a> [<a href="/pdf/2309.17079" title="Download PDF">pdf</a>, <a href="/ps/2309.17079" title="Download PostScript">ps</a>, <a href="/format/2309.17079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double-Layer Power Control for Mobile Cell-Free XL-MIMO with Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Huahua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Cell-free (CF) extremely large-scale multiple-input multiple-output (XL-MIMO)
is regarded as a promising technology for enabling future wireless
communication systems. Significant attention has been generated by its
considerable advantages in augmenting degrees of freedom. In this paper, we
first investigate a CF XL-MIMO system with base stations equipped with XL-MIMO
panels under a dynamic environment. Then, we propose an innovative multi-agent
reinforcement learning (MARL)-based power control algorithm that incorporates
predictive management and distributed optimization architecture, which provides
a dynamic strategy for addressing high-dimension signal processing problems.
Specifically, we compare various MARL-based algorithms, which shows that the
proposed MARL-based algorithm effectively strikes a balance between spectral
efficiency (SE) performance and convergence time. Moreover, we consider a
double-layer power control architecture based on the large-scale fading
coefficients between antennas to suppress interference within dynamic systems.
Compared to the single-layer architecture, the results obtained unveil that the
proposed double-layer architecture has a nearly24% SE performance improvement,
especially with massive antennas and smaller antenna spacing.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17080" title="Abstract">arXiv:2309.17080</a> [<a href="/pdf/2309.17080" title="Download PDF">pdf</a>, <a href="/format/2309.17080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAIA-1: A Generative World Model for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+A">Anthony Hu</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+L">Lloyd Russell</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+H">Hudson Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Murez%2C+Z">Zak Murez</a>, 
<a href="/search/cs?searchtype=author&query=Fedoseev%2C+G">George Fedoseev</a>, 
<a href="/search/cs?searchtype=author&query=Kendall%2C+A">Alex Kendall</a>, 
<a href="/search/cs?searchtype=author&query=Shotton%2C+J">Jamie Shotton</a>, 
<a href="/search/cs?searchtype=author&query=Corrado%2C+G">Gianluca Corrado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Autonomous driving promises transformative improvements to transportation,
but building systems capable of safely navigating the unstructured complexity
of real-world scenarios remains challenging. A critical problem lies in
effectively predicting the various potential outcomes that may emerge in
response to the vehicle's actions as the world evolves.
<br />To address this challenge, we introduce GAIA-1 ('Generative AI for
Autonomy'), a generative world model that leverages video, text, and action
inputs to generate realistic driving scenarios while offering fine-grained
control over ego-vehicle behavior and scene features. Our approach casts world
modeling as an unsupervised sequence modeling problem by mapping the inputs to
discrete tokens, and predicting the next token in the sequence. Emerging
properties from our model include learning high-level structures and scene
dynamics, contextual awareness, generalization, and understanding of geometry.
The power of GAIA-1's learned representation that captures expectations of
future events, combined with its ability to generate realistic samples,
provides new possibilities for innovation in the field of autonomy, enabling
enhanced and accelerated training of autonomous driving technology.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17083" title="Abstract">arXiv:2309.17083</a> [<a href="/pdf/2309.17083" title="Download PDF">pdf</a>, <a href="/format/2309.17083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegRCDB: Semantic Segmentation via Formula-Driven Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shinoda%2C+R">Risa Shinoda</a>, 
<a href="/search/cs?searchtype=author&query=Hayamizu%2C+R">Ryo Hayamizu</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+K">Kodai Nakashima</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+N">Nakamasa Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Yokota%2C+R">Rio Yokota</a>, 
<a href="/search/cs?searchtype=author&query=Kataoka%2C+H">Hirokatsu Kataoka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023. Code: <a href="https://github.com/dahlian00/SegRCDB">this https URL</a>, Project page: <a href="https://dahlian00.github.io/SegRCDBPage/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-training is a strong strategy for enhancing visual models to efficiently
train them with a limited number of labeled images. In semantic segmentation,
creating annotation masks requires an intensive amount of labor and time, and
therefore, a large-scale pre-training dataset with semantic labels is quite
difficult to construct. Moreover, what matters in semantic segmentation
pre-training has not been fully investigated. In this paper, we propose the
Segmentation Radial Contour DataBase (SegRCDB), which for the first time
applies formula-driven supervised learning for semantic segmentation. SegRCDB
enables pre-training for semantic segmentation without real images or any
manual semantic labels. SegRCDB is based on insights about what is important in
pre-training for semantic segmentation and allows efficient pre-training.
Pre-training with SegRCDB achieved higher mIoU than the pre-training with
COCO-Stuff for fine-tuning on ADE-20k and Cityscapes with the same number of
training images. SegRCDB has a high potential to contribute to semantic
segmentation pre-training and investigation by enabling the creation of large
datasets without manual annotation. The SegRCDB dataset will be released under
a license that allows research and commercial use. Code is available at:
https://github.com/dahlian00/SegRCDB
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17086" title="Abstract">arXiv:2309.17086</a> [<a href="/pdf/2309.17086" title="Download PDF">pdf</a>, <a href="/format/2309.17086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Empirical Measurements to Augmented Data Rates: A Machine Learning  Approach for MCS Adaptation in Sidelink Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rokoni%2C+A+A">Asif Abdullah Rokoni</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4ufele%2C+D">Daniel Sch&#xe4;ufele</a>, 
<a href="/search/cs?searchtype=author&query=Kasparick%2C+M">Martin Kasparick</a>, 
<a href="/search/cs?searchtype=author&query=Sta%C5%84czak%2C+S">S&#x142;awomir Sta&#x144;czak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Due to the lack of a feedback channel in the C-V2X sidelink, finding a
suitable modulation and coding scheme (MCS) is a difficult task. However,
recent use cases for vehicle-to-everything (V2X) communication with higher
demands on data rate necessitate choosing the MCS adaptively. In this paper, we
propose a machine learning approach to predict suitable MCS levels.
Additionally, we propose the use of quantile prediction and evaluate it in
combination with different algorithms for the task of predicting the MCS level
with the highest achievable data rate. Thereby, we show significant
improvements over conventional methods of choosing the MCS level. Using a
machine learning approach, however, requires larger real-world data sets than
are currently publicly available for research. For this reason, this paper
presents a data set that was acquired in extensive drive tests, and that we
make publicly available.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17088" title="Abstract">arXiv:2309.17088</a> [<a href="/pdf/2309.17088" title="Download PDF">pdf</a>, <a href="/format/2309.17088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> White Paper on Radio Channel Modeling and Prediction to Support Future  Environment-aware Wireless Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boban%2C+M">Mate Boban</a>, 
<a href="/search/cs?searchtype=author&query=Degli-Esposti%2C+V">Vittorio Degli-Esposti</a> (editors)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> COST CA20120 INTERACT Working Group 1 (Radio Channels) white paper. 28 authors, 72 pages, 270 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">COST INTERACT working group (WG)1 aims at increasing the theoretical and
experimental understanding of radio propagation and channels in environments of
interest and at deriving models for design, simulation, planning and operation
of future wireless systems. Wide frequency ranges from sub-GHz to terahertz
(THz), potentially high mobility, diverse and highly cluttered environments,
dense networks, massive antenna systems, and the use of intelligent surfaces,
are some of the challenges for radio channel measurements and modeling for next
generation systems. As indicated in [1], with increased number of use cases
(e.g., those identified by one6G [2] and shown in Fig. 1) to be supported and a
larger number of frequency bands, a paradigm shift in channel measurements and
modeling will be required. To address the particular challenges that come with
such a paradigm shift, WG1 started the work on relevant topics, ranging from
channel sounder design, metrology and measurement methodologies, measurements,
modeling, and systematic dataset collection and analysis. In addition to the
core activities of WG1, based on the strong interest of the participants, two
sub-working groups (subWGs) have been initiated as part of WG1: i) subWG1.1 on
millimeter-wave (mmWave) and THz sounding (subWG THz) and ii) subWG1.2 on
propagation aspects related to reconfigurable intelligent surfaces (RIS) (subWG
RIS). This white paper has two main goals: i) it summarizes the state-of-theart
in radio channel measurement and modeling and the key challenges that the
scientific community will have to face over the next years to support the
development of 6G networks, as identified by WG1 and its subWGs; and ii) it
charts the main directions for the work of WG1 and subWGs for the remainder of
COST INTERACT duration (i.e., until October 2025).
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17089" title="Abstract">arXiv:2309.17089</a> [<a href="/pdf/2309.17089" title="Download PDF">pdf</a>, <a href="/format/2309.17089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Too Big, so Fail? -- Enabling Neural Construction Methods to Solve  Large-Scale Routing Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Falkner%2C+J+K">Jonas K. Falkner</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Thieme%2C+L">Lars Schmidt-Thieme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In recent years new deep learning approaches to solve combinatorial
optimization problems, in particular NP-hard Vehicle Routing Problems (VRP),
have been proposed. The most impactful of these methods are sequential neural
construction approaches which are usually trained via reinforcement learning.
Due to the high training costs of these models, they usually are trained on
limited instance sizes (e.g. serving 100 customers) and later applied to vastly
larger instance size (e.g. 2000 customers). By means of a systematic scale-up
study we show that even state-of-the-art neural construction methods are
outperformed by simple heuristics, failing to generalize to larger problem
instances. We propose to use the ruin recreate principle that alternates
between completely destroying a localized part of the solution and then
recreating an improved variant. In this way, neural construction methods like
POMO are never applied to the global problem but just in the reconstruction
step, which only involves partial problems much closer in size to their
original training instances. In thorough experiments on four datasets of
varying distributions and modalities we show that our neural ruin recreate
approach outperforms alternative forms of improving construction methods such
as sampling and beam search and in several experiments also advanced local
search approaches.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17093" title="Abstract">arXiv:2309.17093</a> [<a href="/pdf/2309.17093" title="Download PDF">pdf</a>, <a href="/format/2309.17093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype-based Aleatoric Uncertainty Quantification for Cross-modal  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaosu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-modal Retrieval methods build similarity relations between vision and
language modalities by jointly learning a common representation space. However,
the predictions are often unreliable due to the Aleatoric uncertainty, which is
induced by low-quality data, e.g., corrupt images, fast-paced videos, and
non-detailed texts. In this paper, we propose a novel Prototype-based Aleatoric
Uncertainty Quantification (PAU) framework to provide trustworthy predictions
by quantifying the uncertainty arisen from the inherent data ambiguity.
Concretely, we first construct a set of various learnable prototypes for each
modality to represent the entire semantics subspace. Then Dempster-Shafer
Theory and Subjective Logic Theory are utilized to build an evidential
theoretical framework by associating evidence with Dirichlet Distribution
parameters. The PAU model induces accurate uncertainty and reliable predictions
for cross-modal retrieval. Extensive experiments are performed on four major
benchmark datasets of MSR-VTT, MSVD, DiDeMo, and MS-COCO, demonstrating the
effectiveness of our method. The code is accessible at
https://github.com/leolee99/PAU.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17094" title="Abstract">arXiv:2309.17094</a> [<a href="/pdf/2309.17094" title="Download PDF">pdf</a>, <a href="/ps/2309.17094" title="Download PostScript">ps</a>, <a href="/format/2309.17094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Easy it is to Know How: An Upper Bound for the Satisfiability  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Areces%2C+C">Carlos Areces</a>, 
<a href="/search/cs?searchtype=author&query=Cassano%2C+V">Valentin Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Fervari%2C+R">Raul Fervari</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+P">Pablo Castro</a>, 
<a href="/search/cs?searchtype=author&query=Saravia%2C+A">Andres Saravia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We investigate the complexity of the satisfiability problem for a modal logic
expressing `knowing how' assertions, related to an agent's abilities to achieve
a certain goal. We take one of the most standard semantics for this kind of
logics based on linear plans. Our main result is a proof that checking
satisfiability of a `knowing how' formula can be done in $\Sigma_2^P$. The
algorithm we present relies on eliminating nested modalities in a formula, and
then performing multiple calls to a satisfiability checking oracle for
propositional logic.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17095" title="Abstract">arXiv:2309.17095</a> [<a href="/pdf/2309.17095" title="Download PDF">pdf</a>, <a href="/format/2309.17095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Interpretability for Model Comparison via Decision Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rida%2C+A">Adam Rida</a>, 
<a href="/search/cs?searchtype=author&query=Lesot%2C+M">Marie-Jeanne Lesot</a>, 
<a href="/search/cs?searchtype=author&query=Renard%2C+X">Xavier Renard</a>, 
<a href="/search/cs?searchtype=author&query=Marsala%2C+C">Christophe Marsala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Explainable AI (XAI) methods have mostly been built to investigate and shed
light on single machine learning models and are not designed to capture and
explain differences between multiple models effectively. This paper addresses
the challenge of understanding and explaining differences between machine
learning models, which is crucial for model selection, monitoring and lifecycle
management in real-world applications. We propose DeltaXplainer, a
model-agnostic method for generating rule-based explanations describing the
differences between two binary classifiers. To assess the effectiveness of
DeltaXplainer, we conduct experiments on synthetic and real-world datasets,
covering various model comparison scenarios involving different types of
concept drift.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17096" title="Abstract">arXiv:2309.17096</a> [<a href="/pdf/2309.17096" title="Download PDF">pdf</a>, <a href="/format/2309.17096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Obtaining Pseudo-inverse Solutions With MINRES
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/math?searchtype=author&query=Milzarek%2C+A">Andre Milzarek</a>, 
<a href="/search/math?searchtype=author&query=Roosta%2C+F">Fred Roosta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The celebrated minimum residual method (MINRES), proposed in the seminal
paper of Paige and Saunders, has seen great success and wide-spread use in
solving linear least-squared problems involving Hermitian matrices, with
further extensions to complex symmetric settings. Unless the system is
consistent whereby the right-hand side vector lies in the range of the matrix,
MINRES is not guaranteed to obtain the pseudo-inverse solution. Variants of
MINRES, such as MINRES-QLP, which can achieve such minimum norm solutions, are
known to be both computationally expensive and challenging to implement. We
propose a novel and remarkably simple lifting strategy that seamlessly
integrates with the final MINRES iteration, enabling us to obtain the minimum
norm solution with negligible additional computational costs. We study our
lifting strategy in a diverse range of settings encompassing Hermitian and
complex symmetric systems as well as those with semi-definite preconditioners.
We also provide numerical experiments to support our analysis and showcase the
effects of our lifting strategy.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17097" title="Abstract">arXiv:2309.17097</a> [<a href="/pdf/2309.17097" title="Download PDF">pdf</a>, <a href="/format/2309.17097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Collaborative Learning Methods Cost-Effectiveness for  Prostate Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Innocenti%2C+L">Lucia Innocenti</a>, 
<a href="/search/cs?searchtype=author&query=Antonelli%2C+M">Michela Antonelli</a>, 
<a href="/search/cs?searchtype=author&query=Cremonesi%2C+F">Francesco Cremonesi</a>, 
<a href="/search/cs?searchtype=author&query=Sarhan%2C+K">Kenaan Sarhan</a>, 
<a href="/search/cs?searchtype=author&query=Granados%2C+A">Alejandro Granados</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+V">Vicky Goh</a>, 
<a href="/search/cs?searchtype=author&query=Ourselin%2C+S">Sebastien Ourselin</a>, 
<a href="/search/cs?searchtype=author&query=Lorenzi%2C+M">Marco Lorenzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Healthcare data is often split into medium/small-sized collections across
multiple hospitals and access to it is encumbered by privacy regulations. This
brings difficulties to use them for the development of machine learning and
deep learning models, which are known to be data-hungry. One way to overcome
this limitation is to use collaborative learning (CL) methods, which allow
hospitals to work collaboratively to solve a task, without the need to
explicitly share local data.
<br />In this paper, we address a prostate segmentation problem from MRI in a
collaborative scenario by comparing two different approaches: federated
learning (FL) and consensus-based methods (CBM).
<br />To the best of our knowledge, this is the first work in which CBM, such as
label fusion techniques, are used to solve a problem of collaborative learning.
In this setting, CBM combine predictions from locally trained models to obtain
a federated strong learner with ideally improved robustness and predictive
variance properties.
<br />Our experiments show that, in the considered practical scenario, CBMs provide
equal or better results than FL, while being highly cost-effective. Our results
demonstrate that the consensus paradigm may represent a valid alternative to FL
for typical training tasks in medical imaging.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17099" title="Abstract">arXiv:2309.17099</a> [<a href="/pdf/2309.17099" title="Download PDF">pdf</a>, <a href="/format/2309.17099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Bayesian Identification for Motor Commutation: Applied to  Switched Reluctance Motors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=van+Meer%2C+M">Max van Meer</a>, 
<a href="/search/eess?searchtype=author&query=Gonz%C3%A1lez%2C+R+A">Rodrigo A. Gonz&#xe1;lez</a>, 
<a href="/search/eess?searchtype=author&query=Witvoet%2C+G">Gert Witvoet</a>, 
<a href="/search/eess?searchtype=author&query=Oomen%2C+T">Tom Oomen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Switched Reluctance Motors (SRMs) enable power-efficient actuation with
mechanically simple designs. This paper aims to identify the nonlinear
relationship between torque, rotor angle, and currents, to design commutation
functions that minimize torque ripple in SRMs. This is achieved by conducting
specific closed-loop experiments using purposely imperfect commutation
functions and identifying the nonlinear dynamics via Bayesian estimation. A
simulation example shows that the presented method is robust to
position-dependent disturbances, and experiments suggest that the
identification method enables the design of commutation functions that
significantly increase performance. The developed approach enables accurate
identification of the torque-current-angle relationship in SRMs, without the
need for torque sensors, an accurate linear model, or an accurate model of
position-dependent disturbances, making it easy to implement in production.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17100" title="Abstract">arXiv:2309.17100</a> [<a href="/pdf/2309.17100" title="Download PDF">pdf</a>, <a href="/format/2309.17100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turning Logs into Lumber: Preprocessing Tasks in Process Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dani%2C+V+S">Vinicius Stein Dani</a>, 
<a href="/search/cs?searchtype=author&query=Beerepoot%2C+I">Iris Beerepoot</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xixi Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Event logs are invaluable for conducting process mining projects, offering
insights into process improvement and data-driven decision-making. However,
data quality issues affect the correctness and trustworthiness of these
insights, making preprocessing tasks a necessity. Despite the recognized
importance, the execution of preprocessing tasks remains ad-hoc, lacking
support. This paper presents a systematic literature review that establishes a
comprehensive repository of preprocessing tasks and their usage in case
studies. We identify six high-level and 20 low-level preprocessing tasks in
case studies. Log filtering, transformation, and abstraction are commonly used,
while log enriching, integration, and reduction are less frequent. These
results can be considered a first step in contributing to more structured,
transparent event log preprocessing, enhancing process mining reliability.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17102" title="Abstract">arXiv:2309.17102</a> [<a href="/pdf/2309.17102" title="Download PDF">pdf</a>, <a href="/format/2309.17102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guiding Instruction-based Image Editing via Multimodal Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Tsu-Jui Fu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenze Hu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xianzhi Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yinfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhe Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project at <a href="https://mllm-ie.github.io">this https URL</a> ; Code will be released at <a href="https://github.com/tsujuifu/pytorch_mgie">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Instruction-based image editing improves the controllability and flexibility
of image manipulation via natural commands without elaborate descriptions or
regional masks. However, human instructions are sometimes too brief for current
methods to capture and follow. Multimodal large language models (MLLMs) show
promising capabilities in cross-modal understanding and visual-aware response
generation via LMs. We investigate how MLLMs facilitate edit instructions and
present MLLM-Guided Image Editing (MGIE). MGIE learns to derive expressive
instructions and provides explicit guidance. The editing model jointly captures
this visual imagination and performs manipulation through end-to-end training.
We evaluate various aspects of Photoshop-style modification, global photo
optimization, and local editing. Extensive experimental results demonstrate
that expressive instructions are crucial to instruction-based image editing,
and our MGIE can lead to a notable improvement in automatic metrics and human
evaluation while maintaining competitive inference efficiency.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17104" title="Abstract">arXiv:2309.17104</a> [<a href="/pdf/2309.17104" title="Download PDF">pdf</a>, <a href="/format/2309.17104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype-guided Cross-modal Completion and Alignment for Incomplete  Text-based Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+T">Tiantian Gong</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+G">Guodong Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yongkang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liyan Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM International Conference on Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traditional text-based person re-identification (ReID) techniques heavily
rely on fully matched multi-modal data, which is an ideal scenario. However,
due to inevitable data missing and corruption during the collection and
processing of cross-modal data, the incomplete data issue is usually met in
real-world applications. Therefore, we consider a more practical task termed
the incomplete text-based ReID task, where person images and text descriptions
are not completely matched and contain partially missing modality data. To this
end, we propose a novel Prototype-guided Cross-modal Completion and Alignment
(PCCA) framework to handle the aforementioned issues for incomplete text-based
ReID. Specifically, we cannot directly retrieve person images based on a text
query on missing modality data. Therefore, we propose the cross-modal nearest
neighbor construction strategy for missing data by computing the cross-modal
similarity between existing images and texts, which provides key guidance for
the completion of missing modal features. Furthermore, to efficiently complete
the missing modal features, we construct the relation graphs with the
aforementioned cross-modal nearest neighbor sets of missing modal data and the
corresponding prototypes, which can further enhance the generated missing modal
features. Additionally, for tighter fine-grained alignment between images and
texts, we raise a prototype-aware cross-modal alignment loss that can
effectively reduce the modality heterogeneity gap for better fine-grained
alignment in common space. Extensive experimental results on several benchmarks
with different missing ratios amply demonstrate that our method can
consistently outperform state-of-the-art text-image ReID approaches.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17105" title="Abstract">arXiv:2309.17105</a> [<a href="/pdf/2309.17105" title="Download PDF">pdf</a>, <a href="/format/2309.17105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Action Assessment via Task-Consistent Score-Discriminative  Feature Distribution Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Ling-An Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+J">Jing-Ke Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wei-Shi Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Action Quality Assessment (AQA) is a task that tries to answer how well an
action is carried out. While remarkable progress has been achieved, existing
works on AQA assume that all the training data are visible for training in one
time, but do not enable continual learning on assessing new technical actions.
In this work, we address such a Continual Learning problem in AQA
(Continual-AQA), which urges a unified model to learn AQA tasks sequentially
without forgetting. Our idea for modeling Continual-AQA is to sequentially
learn a task-consistent score-discriminative feature distribution, in which the
latent features express a strong correlation with the score labels regardless
of the task or action types. From this perspective, we aim to mitigate the
forgetting in Continual-AQA from two aspects. Firstly, to fuse the features of
new and previous data into a score-discriminative distribution, a novel
Feature-Score Correlation-Aware Rehearsal is proposed to store and reuse data
from previous tasks with limited memory size. Secondly, an Action
General-Specific Graph is developed to learn and decouple the action-general
and action-specific knowledge so that the task-consistent score-discriminative
features can be better extracted across various tasks. Extensive experiments
are conducted to evaluate the contributions of proposed components. The
comparisons with the existing continual learning methods additionally verify
the effectiveness and versatility of our approach.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17113" title="Abstract">arXiv:2309.17113</a> [<a href="/pdf/2309.17113" title="Download PDF">pdf</a>, <a href="/format/2309.17113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Path Learning for Multi-relational Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrini%2C+F">Francesco Ferrini</a>, 
<a href="/search/cs?searchtype=author&query=Longa%2C+A">Antonio Longa</a>, 
<a href="/search/cs?searchtype=author&query=Passerini%2C+A">Andrea Passerini</a>, 
<a href="/search/cs?searchtype=author&query=Jaeger%2C+M">Manfred Jaeger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing multi-relational graph neural networks use one of two strategies for
identifying informative relations: either they reduce this problem to low-level
weight learning, or they rely on handcrafted chains of relational dependencies,
called meta-paths. However, the former approach faces challenges in the
presence of many relations (e.g., knowledge graphs), while the latter requires
substantial domain expertise to identify relevant meta-paths. In this work we
propose a novel approach to learn meta-paths and meta-path GNNs that are highly
accurate based on a small number of informative meta-paths. Key element of our
approach is a scoring function for measuring the potential informativeness of a
relation in the incremental construction of the meta-path. Our experimental
evaluation shows that the approach manages to correctly identify relevant
meta-paths even with a large number of relations, and substantially outperforms
existing multi-relational GNNs on synthetic and real-world experiments.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17114" title="Abstract">arXiv:2309.17114</a> [<a href="/pdf/2309.17114" title="Download PDF">pdf</a>, <a href="/format/2309.17114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UXsim: An open source macroscopic and mesoscopic traffic simulator in  Python -- a technical overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Seo%2C+T">Toru Seo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This note describes a technical overview of UXsim, an open source
macro/mesoscopic traffic simulator in pure Python programming language. UXsim
is based on Kinematic Wave model (more specifically, mesoscopic version of
Newell's simplified car-following model) and dynamic user optimum-like route
choice principle, which are well established methodology in the transportation
research field. It can compute dynamical network traffic flow and have basic
visualization and analysis capability. Furthermore, users can implement their
own models and control methods into the simulator by using Python, thanks to
the flexibility of the language. The simulator and its codes are freely
available at https://github.com/toruseo/UXsim under the MIT license.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17115" title="Abstract">arXiv:2309.17115</a> [<a href="/pdf/2309.17115" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAppKG: Mobile App Recommendation Using Knowledge Graph and Side  Information-A Secure Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dave%2C+D">Daksh Dave</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Aditya Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Abdulhamid%2C+S+M">Shafii Muhammad Abdulhamid</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A">Adeel Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Akhunzada%2C+A">Adnan Akhunzada</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+R">Rashid Amin</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, vol. 11, pp. 76751-76767, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Due to the rapid development of technology and the widespread usage of
smartphones, the number of mobile applications is exponentially growing.
Finding a suitable collection of apps that aligns with users needs and
preferences can be challenging. However, mobile app recommender systems have
emerged as a helpful tool in simplifying this process. But there is a drawback
to employing app recommender systems. These systems need access to user data,
which is a serious security violation. While users seek accurate opinions, they
do not want to compromise their privacy in the process. We address this issue
by developing SAppKG, an end-to-end user privacy-preserving knowledge graph
architecture for mobile app recommendation based on knowledge graph models such
as SAppKG-S and SAppKG-D, that utilized the interaction data and side
information of app attributes. We tested the proposed model on real-world data
from the Google Play app store, using precision, recall, mean absolute
precision, and mean reciprocal rank. We found that the proposed model improved
results on all four metrics. We also compared the proposed model to baseline
models and found that it outperformed them on all four metrics.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17116" title="Abstract">arXiv:2309.17116</a> [<a href="/pdf/2309.17116" title="Download PDF">pdf</a>, <a href="/format/2309.17116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sheaf Hypergraph Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duta%2C+I">Iulia Duta</a>, 
<a href="/search/cs?searchtype=author&query=Cassar%C3%A0%2C+G">Giulia Cassar&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Silvestri%2C+F">Fabrizio Silvestri</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Higher-order relations are widespread in nature, with numerous phenomena
involving complex interactions that extend beyond simple pairwise connections.
As a result, advancements in higher-order processing can accelerate the growth
of various fields requiring structured data. Current approaches typically
represent these interactions using hypergraphs. We enhance this representation
by introducing cellular sheaves for hypergraphs, a mathematical construction
that adds extra structure to the conventional hypergraph while maintaining
their local, higherorder connectivity. Drawing inspiration from existing
Laplacians in the literature, we develop two unique formulations of sheaf
hypergraph Laplacians: linear and non-linear. Our theoretical analysis
demonstrates that incorporating sheaves into the hypergraph Laplacian provides
a more expressive inductive bias than standard hypergraph diffusion, creating a
powerful instrument for effectively modelling complex data structures. We
employ these sheaf hypergraph Laplacians to design two categories of models:
Sheaf Hypergraph Neural Networks and Sheaf Hypergraph Convolutional Networks.
These models generalize classical Hypergraph Networks often found in the
literature. Through extensive experimentation, we show that this generalization
significantly improves performance, achieving top results on multiple benchmark
datasets for hypergraph node classification.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17122" title="Abstract">arXiv:2309.17122</a> [<a href="/pdf/2309.17122" title="Download PDF">pdf</a>, <a href="/format/2309.17122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking the Abilities of Large Language Models for RDF Knowledge  Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frey%2C+J">Johannes Frey</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+L">Lars-Peter Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Arndt%2C+N">Natanael Arndt</a>, 
<a href="/search/cs?searchtype=author&query=Brei%2C+F">Felix Brei</a>, 
<a href="/search/cs?searchtype=author&query=Bulert%2C+K">Kirill Bulert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for proceedings of DL4KG Workshop @ ISWC 2023 at ceur-ws.org
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Databases (cs.DB)

</div>
<p class="mathjax">Large Language Models (LLMs) are advancing at a rapid pace, with significant
improvements at natural language processing and coding tasks. Yet, their
ability to work with formal languages representing data, specifically within
the realm of knowledge graph engineering, remains under-investigated. To
evaluate the proficiency of various LLMs, we created a set of five tasks that
probe their ability to parse, understand, analyze, and create knowledge graphs
serialized in Turtle syntax. These tasks, each embodying distinct degrees of
complexity and being able to scale with the size of the problem, have been
integrated into our automated evaluation system, the LLM-KG-Bench. The
evaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4,
Claude 1.3, and Claude 2.0, as well as two freely accessible offline models,
GPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth
understanding of the strengths and shortcomings of LLMs in relation to their
application within RDF knowledge graph engineering workflows utilizing Turtle
representation. While our findings show that the latest commercial models
outperform their forerunners in terms of proficiency with the Turtle language,
they also reveal an apparent weakness. These models fall short when it comes to
adhering strictly to the output formatting constraints, a crucial requirement
in this context.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17123" title="Abstract">arXiv:2309.17123</a> [<a href="/pdf/2309.17123" title="Download PDF">pdf</a>, <a href="/format/2309.17123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction of Patient-Specific Confounders in AI-based Radiologic  Image Interpretation using Generative Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tianyu Han</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BDigutyt%C4%97%2C+L">Laura &#x17d;igutyt&#x117;</a>, 
<a href="/search/cs?searchtype=author&query=Huck%2C+L">Luisa Huck</a>, 
<a href="/search/cs?searchtype=author&query=Huppertz%2C+M">Marc Huppertz</a>, 
<a href="/search/cs?searchtype=author&query=Siepmann%2C+R">Robert Siepmann</a>, 
<a href="/search/cs?searchtype=author&query=Gandelsman%2C+Y">Yossi Gandelsman</a>, 
<a href="/search/cs?searchtype=author&query=Bl%C3%BCthgen%2C+C">Christian Bl&#xfc;thgen</a>, 
<a href="/search/cs?searchtype=author&query=Khader%2C+F">Firas Khader</a>, 
<a href="/search/cs?searchtype=author&query=Kuhl%2C+C">Christiane Kuhl</a>, 
<a href="/search/cs?searchtype=author&query=Nebelung%2C+S">Sven Nebelung</a>, 
<a href="/search/cs?searchtype=author&query=Kather%2C+J">Jakob Kather</a>, 
<a href="/search/cs?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Detecting misleading patterns in automated diagnostic assistance systems,
such as those powered by Artificial Intelligence, is critical to ensuring their
reliability, particularly in healthcare. Current techniques for evaluating deep
learning models cannot visualize confounding factors at a diagnostic level.
Here, we propose a self-conditioned diffusion model termed DiffChest and train
it on a dataset of 515,704 chest radiographs from 194,956 patients from
multiple healthcare centers in the United States and Europe. DiffChest explains
classifications on a patient-specific level and visualizes the confounding
factors that may mislead the model. We found high inter-reader agreement when
evaluating DiffChest's capability to identify treatment-related confounders,
with Fleiss' Kappa values of 0.8 or higher across most imaging findings.
Confounders were accurately captured with 11.1% to 100% prevalence rates.
Furthermore, our pretraining process optimized the model to capture the most
relevant information from the input radiographs. DiffChest achieved excellent
diagnostic accuracy when diagnosing 11 chest conditions, such as pleural
effusion and cardiac insufficiency, and at least sufficient diagnostic accuracy
for the remaining conditions. Our findings highlight the potential of
pretraining based on diffusion models in medical image classification,
specifically in providing insights into confounding factors and model
robustness.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17124" title="Abstract">arXiv:2309.17124</a> [<a href="/pdf/2309.17124" title="Download PDF">pdf</a>, <a href="/format/2309.17124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mostree : Malicious Secure Private Decision Tree Evaluation with  Sublinear Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jianli Bai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiangfu Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaowu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shujie Cui</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+E">Ee-Chien Chang</a>, 
<a href="/search/cs?searchtype=author&query=Russello%2C+G">Giovanni Russello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ACSAC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">A private decision tree evaluation (PDTE) protocol allows a feature vector
owner (FO) to classify its data using a tree model from a model owner (MO) and
only reveals an inference result to the FO. This paper proposes Mostree, a PDTE
protocol secure in the presence of malicious parties with sublinear
communication. We design Mostree in the three-party honest-majority setting,
where an (untrusted) computing party (CP) assists the FO and MO in the secure
computation. We propose two low-communication oblivious selection (OS)
protocols by exploiting nice properties of three-party replicated secret
sharing (RSS) and distributed point function. Mostree combines OS protocols
with a tree encoding method and three-party secure computation to achieve
sublinear communication. We observe that most of the protocol components
already maintain privacy even in the presence of a malicious adversary, and
what remains to achieve is correctness. To ensure correctness, we propose a set
of lightweight consistency checks and seamlessly integrate them into Mostree.
As a result, Mostree achieves sublinear communication and malicious security
simultaneously. We implement Mostree and compare it with the state-of-the-art.
Experimental results demonstrate that Mostree is efficient and comparable to
semi-honest PDTE schemes with sublinear communication. For instance, when
evaluated on the MNIST dataset in a LAN setting, Mostree achieves an evaluation
using approximately 768 ms with communication of around 168 KB.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17125" title="Abstract">arXiv:2309.17125</a> [<a href="/pdf/2309.17125" title="Download PDF">pdf</a>, <a href="/format/2309.17125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style Transfer for Non-differentiable Audio Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grant%2C+K">Kieran Grant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Digital audio effects are widely used by audio engineers to alter the
acoustic and temporal qualities of audio data. However, these effects can have
a large number of parameters which can make them difficult to learn for
beginners and hamper creativity for professionals. Recently, there have been a
number of efforts to employ progress in deep learning to acquire the low-level
parameter configurations of audio effects by minimising an objective function
between an input and reference track, commonly referred to as style transfer.
However, current approaches use inflexible black-box techniques or require that
the effects under consideration are implemented in an auto-differentiation
framework. In this work, we propose a deep learning approach to audio
production style matching which can be used with effects implemented in some of
the most widely used frameworks, requiring only that the parameters under
consideration have a continuous domain. Further, our method includes style
matching for various classes of effects, many of which are difficult or
impossible to be approximated closely using differentiable functions. We show
that our audio embedding approach creates logical encodings of timbral
information, which can be used for a number of downstream tasks. Further, we
perform a listening test which demonstrates that our approach is able to
convincingly style match a multi-band compressor effect.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17128" title="Abstract">arXiv:2309.17128</a> [<a href="/pdf/2309.17128" title="Download PDF">pdf</a>, <a href="/format/2309.17128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAvatar: High-fidelity Head Avatar via Facial Model Conditioned Neural  Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaochen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lizhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Suo%2C+J">Jinli Suo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The problem of modeling an animatable 3D human head avatar under light-weight
setups is of significant importance but has not been well solved. Existing 3D
representations either perform well in the realism of portrait images synthesis
or the accuracy of expression control, but not both. To address the problem, we
introduce a novel hybrid explicit-implicit 3D representation, Facial Model
Conditioned Neural Radiance Field, which integrates the expressiveness of NeRF
and the prior information from the parametric template. At the core of our
representation, a synthetic-renderings-based condition method is proposed to
fuse the prior information from the parametric model into the implicit field
without constraining its topological flexibility. Besides, based on the hybrid
representation, we properly overcome the inconsistent shape issue presented in
existing methods and improve the animation stability. Moreover, by adopting an
overall GAN-based architecture using an image-to-image translation network, we
achieve high-resolution, realistic and view-consistent synthesis of dynamic
head appearance. Experiments demonstrate that our method can achieve
state-of-the-art performance for 3D head avatar animation compared with
previous methods.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17130" title="Abstract">arXiv:2309.17130</a> [<a href="/pdf/2309.17130" title="Download PDF">pdf</a>, <a href="/format/2309.17130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRANDE: Gradient-Based Decision Tree Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marton%2C+S">Sascha Marton</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCdtke%2C+S">Stefan L&#xfc;dtke</a>, 
<a href="/search/cs?searchtype=author&query=Bartelt%2C+C">Christian Bartelt</a>, 
<a href="/search/cs?searchtype=author&query=Stuckenschmidt%2C+H">Heiner Stuckenschmidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Despite the success of deep learning for text and image data, tree-based
ensemble models are still state-of-the-art for machine learning with
heterogeneous tabular data. However, there is a significant need for
tabular-specific gradient-based methods due to their high flexibility. In this
paper, we propose $\text{GRANDE}$, $\text{GRA}$die$\text{N}$t-Based
$\text{D}$ecision Tree $\text{E}$nsembles, a novel approach for learning hard,
axis-aligned decision tree ensembles using end-to-end gradient descent. GRANDE
is based on a dense representation of tree ensembles, which affords to use
backpropagation with a straight-through operator to jointly optimize all model
parameters. Our method combines axis-aligned splits, which is a useful
inductive bias for tabular data, with the flexibility of gradient-based
optimization. Furthermore, we introduce an advanced instance-wise weighting
that facilitates learning representations for both, simple and complex
relations, within a single model. We conducted an extensive evaluation on a
predefined benchmark with 19 classification datasets and demonstrate that our
method outperforms existing gradient-boosting and deep learning frameworks on
most datasets.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17133" title="Abstract">arXiv:2309.17133</a> [<a href="/pdf/2309.17133" title="Download PDF">pdf</a>, <a href="/format/2309.17133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-grained Late-interaction Multi-modal Retrieval for Retrieval  Augmented Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weizhe Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinghong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jingbiao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Coca%2C+A">Alexandru Coca</a>, 
<a href="/search/cs?searchtype=author&query=Byrne%2C+B">Bill Byrne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at NeurIPS 2023. This is a submission version, and the camera-ready version will be updated soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Knowledge-based Visual Question Answering (KB-VQA) requires VQA systems to
utilize knowledge from existing knowledge bases to answer visually-grounded
questions. Retrieval-Augmented Visual Question Answering (RA-VQA), a strong
framework to tackle KB-VQA, first retrieves related documents with Dense
Passage Retrieval (DPR) and then uses them to answer questions. This paper
proposes Fine-grained Late-interaction Multi-modal Retrieval (FLMR) which
significantly improves knowledge retrieval in RA-VQA. FLMR addresses two major
limitations in RA-VQA's retriever: (1) the image representations obtained via
image-to-text transforms can be incomplete and inaccurate and (2) relevance
scores between queries and documents are computed with one-dimensional
embeddings, which can be insensitive to finer-grained relevance. FLMR overcomes
these limitations by obtaining image representations that complement those from
the image-to-text transforms using a vision model aligned with an existing
text-based retriever through a simple alignment network. FLMR also encodes
images and questions using multi-dimensional embeddings to capture
finer-grained relevance between queries and documents. FLMR significantly
improves the original RA-VQA retriever's PRRecall@5 by approximately 8\%.
Finally, we equipped RA-VQA with two state-of-the-art large
multi-modal/language models to achieve $\sim61\%$ VQA score in the OK-VQA
dataset.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17134" title="Abstract">arXiv:2309.17134</a> [<a href="/pdf/2309.17134" title="Download PDF">pdf</a>, <a href="/format/2309.17134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promoting Generalized Cross-lingual Question Answering in Few-resource  Scenarios via Self-knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carrino%2C+C+P">Casimiro Pio Carrino</a>, 
<a href="/search/cs?searchtype=author&query=Escolano%2C+C">Carlos Escolano</a>, 
<a href="/search/cs?searchtype=author&query=Fonollosa%2C+J+A+R">Jos&#xe9; A. R. Fonollosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Journal of Artificial Intelligence Research (JAIR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite substantial progress in multilingual extractive Question Answering
(QA), models with high and uniformly distributed performance across languages
remain challenging, especially for languages with limited resources. We study
cross-lingual transfer mainly focusing on the Generalized Cross-Lingual
Transfer (G-XLT) task, where the question language differs from the context
language - a challenge that has received limited attention thus far. Our
approach seeks to enhance cross-lingual QA transfer using a high-performing
multilingual model trained on a large-scale dataset, complemented by a few
thousand aligned QA examples across languages. Our proposed strategy combines
cross-lingual sampling and advanced self-distillation training in generations
to tackle the previous challenge. Notably, we introduce the novel mAP@k
coefficients to fine-tune self-knowledge distillation loss, dynamically
regulating the teacher's model knowledge to perform a balanced and effective
knowledge transfer. We extensively evaluate our approach to assess XLT and
G-XLT capabilities in extractive QA. Results reveal that our self-knowledge
distillation approach outperforms standard cross-entropy fine-tuning by a
significant margin. Importantly, when compared to a strong baseline that
leverages a sizeable volume of machine-translated data, our approach shows
competitive results despite the considerable challenge of operating within
resource-constrained settings, even in zero-shot scenarios. Beyond performance
improvements, we offer valuable insights through comprehensive analyses and an
ablation study, further substantiating the benefits and constraints of our
approach. In essence, we propose a practical solution to improve cross-lingual
QA transfer by leveraging a few data resources in an efficient way.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17136" title="Abstract">arXiv:2309.17136</a> [<a href="/pdf/2309.17136" title="Download PDF">pdf</a>, <a href="/format/2309.17136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Dynamic Networked System Identification with High-Dimensional  Networked Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jiaxin Yu</a>, 
<a href="/search/eess?searchtype=author&query=Mo%2C+Y">Yanfang Mo</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+S+J">S. Joe Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Networked dynamic systems are ubiquitous in various domains, such as
industrial processes, social networks, and biological systems. These systems
produce high-dimensional data that reflect the complex interactions among the
network nodes with rich sensor measurements. In this paper, we propose a novel
algorithm for latent dynamic networked system identification that leverages the
network structure and performs dimension reduction for each node via dynamic
latent variables (DLVs). The algorithm assumes that the DLVs of each node have
an auto-regressive model with exogenous input and interactions from other
nodes. The DLVs of each node are extracted to capture the most predictable
latent variables in the high dimensional data, while the residual factors are
not predictable. The advantage of the proposed framework is demonstrated on an
industrial process network for system identification and dynamic data
analytics.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17140" title="Abstract">arXiv:2309.17140</a> [<a href="/pdf/2309.17140" title="Download PDF">pdf</a>, <a href="/format/2309.17140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Snapshot of the Mental Health of Software Professionals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Almeida%2C+E+S">Eduardo Santana de Almeida</a>, 
<a href="/search/cs?searchtype=author&query=de+Nunes%2C+I+O">Ingrid Oliveira de Nunes</a>, 
<a href="/search/cs?searchtype=author&query=de+Oliveira%2C+R+P">Raphael Pereira de Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+M+L+L">Michelle Larissa Luciano Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Brunoni%2C+A+R">Andre Russowsky Brunoni</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+S">Shiyue Rong</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+I">Iftekhar Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Mental health disorders affect a large number of people, leading to many
lives being lost every year. These disorders affect struggling individuals and
businesses whose productivity decreases due to days of lost work or lower
employee performance. Recent studies provide alarming numbers of individuals
who suffer from mental health disorders, e.g., depression and anxiety, in
particular contexts, such as academia. In the context of the software industry,
there are limited studies that aim to understand the presence of mental health
disorders and the characteristics of jobs in this context that can be triggers
for the deterioration of the mental health of software professionals. In this
paper, we present the results of a survey with 500 software professionals. We
investigate different aspects of their mental health and the characteristics of
their work to identify possible triggers of mental health deterioration. Our
results provide the first evidence that mental health is a critical issue to be
addressed in the software industry, as well as raise the direction of changes
that can be done in this context to improve the mental health of software
professionals.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17143" title="Abstract">arXiv:2309.17143</a> [<a href="/pdf/2309.17143" title="Download PDF">pdf</a>, <a href="/format/2309.17143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Cephalometric Landmark Detection from the view of Human Pose  Estimation with Lightweight Super-Resolution Head
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+S+Y">Si Yong Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yufei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Accurate localization of cephalometric landmarks holds great importance in
the fields of orthodontics and orthognathics due to its potential for
automating key point labeling. In the context of landmark detection,
particularly in cephalometrics, it has been observed that existing methods
often lack standardized pipelines and well-designed bias reduction processes,
which significantly impact their performance. In this paper, we revisit a
related task, human pose estimation (HPE), which shares numerous similarities
with cephalometric landmark detection (CLD), and emphasize the potential for
transferring techniques from the former field to benefit the latter. Motivated
by this insight, we have developed a robust and adaptable benchmark based on
the well-established HPE codebase known as MMPose. This benchmark can serve as
a dependable baseline for achieving exceptional CLD performance. Furthermore,
we introduce an upscaling design within the framework to further enhance
performance. This enhancement involves the incorporation of a lightweight and
efficient super-resolution module, which generates heatmap predictions on
high-resolution features and leads to further performance refinement,
benefiting from its ability to reduce quantization bias. In the MICCAI
CLDetection2023 challenge, our method achieves 1st place ranking on three
metrics and 3rd place on the remaining one. The code for our method is
available at https://github.com/5k5000/CLdetection2023.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17144" title="Abstract">arXiv:2309.17144</a> [<a href="/pdf/2309.17144" title="Download PDF">pdf</a>, <a href="/format/2309.17144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype Generation: Robust Feature Visualisation for Data Independent  Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tagade%2C+A">Arush Tagade</a>, 
<a href="/search/cs?searchtype=author&query=Rumbelow%2C+J">Jessica Rumbelow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce Prototype Generation, a stricter and more robust form of feature
visualisation for model-agnostic, data-independent interpretability of image
classification models. We demonstrate its ability to generate inputs that
result in natural activation paths, countering previous claims that feature
visualisation algorithms are untrustworthy due to the unnatural internal
activations. We substantiate these claims by quantitatively measuring
similarity between the internal activations of our generated prototypes and
natural images. We also demonstrate how the interpretation of generated
prototypes yields important insights, highlighting spurious correlations and
biases learned by models which quantitative methods over test-sets cannot
identify.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17145" title="Abstract">arXiv:2309.17145</a> [<a href="/pdf/2309.17145" title="Download PDF">pdf</a>, <a href="/format/2309.17145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Staying at the Roach Motel: Cross-Country Analysis of Manipulative  Subscription and Cancellation Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheil%2C+A">Ashley Sheil</a>, 
<a href="/search/cs?searchtype=author&query=Acar%2C+G">Gunes Acar</a>, 
<a href="/search/cs?searchtype=author&query=Schraffenberger%2C+H">Hanna Schraffenberger</a>, 
<a href="/search/cs?searchtype=author&query=Gellert%2C+R">Rapha&#xeb;l Gellert</a>, 
<a href="/search/cs?searchtype=author&query=Malone%2C+D">David Malone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Subscribing to online services is typically a straightforward process, but
cancelling them can be arduous and confusing -- causing many to resign and
continue paying for services they no longer use. Making the cancellation
intentionally difficult is recognized as a dark pattern called Roach Motel.
This paper characterizes the subscription and cancellation flows of popular
news websites from four different countries, and discusses them in the context
of recent regulatory changes. We study the design features that make it
difficult to cancel a subscription and find several cancellation flows that
feature intentional barriers, such as forcing users to type in a phrase or call
a representative. Further, we find many subscription flows that do not
adequately inform users about recurring charges. Our results point to a growing
need for effective regulation of designs that trick, coerce, or manipulate
users into paying for subscriptions they do not want.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17147" title="Abstract">arXiv:2309.17147</a> [<a href="/pdf/2309.17147" title="Download PDF">pdf</a>, <a href="/format/2309.17147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Language Models for Qualitative Analysis can Introduce  Serious Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashwin%2C+J">Julian Ashwin</a>, 
<a href="/search/cs?searchtype=author&query=Chhabra%2C+A">Aditya Chhabra</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+V">Vijayendra Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); General Economics (econ.GN)

</div>
<p class="mathjax">Large Language Models (LLMs) are quickly becoming ubiquitous, but the
implications for social science research are not yet well understood. This
paper asks whether LLMs can help us analyse large-N qualitative data from
open-ended interviews, with an application to transcripts of interviews with
Rohingya refugees in Cox's Bazaar, Bangladesh. We find that a great deal of
caution is needed in using LLMs to annotate text as there is a risk of
introducing biases that can lead to misleading inferences. We here mean bias in
the technical sense, that the errors that LLMs make in annotating interview
transcripts are not random with respect to the characteristics of the interview
subjects. Training simpler supervised models on high-quality human annotations
with flexible coding leads to less measurement error and bias than LLM
annotations. Therefore, given that some high quality annotations are necessary
in order to asses whether an LLM introduces bias, we argue that it is probably
preferable to train a bespoke model on these annotations than it is to use an
LLM for annotation.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17150" title="Abstract">arXiv:2309.17150</a> [<a href="/pdf/2309.17150" title="Download PDF">pdf</a>, <a href="/ps/2309.17150" title="Download PostScript">ps</a>, <a href="/format/2309.17150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Optimization of Bearing Formation Control of Rigid bodies on Lie  Group
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mansourinasab%2C+S">Sara Mansourinasab</a>, 
<a href="/search/eess?searchtype=author&query=Sojoodi%2C+M">Mahdi Sojoodi</a>, 
<a href="/search/eess?searchtype=author&query=Moghadasi%2C+S+R">Seyed Reza Moghadasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2309.10183">arXiv:2309.10183</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, the problem of reaching formation for a network of rigid
agents over a special orthogonal group is investigated by considering
bearing-only constraints as the desired formation. Each agent is able to gather
the measurements with respect to other agents in its own body frame. So, the
agents are coordinated-free concerning a global reference frame. Attracting to
the desired formation is founded on solving an optimization problem for
minimizing the difference between the instantaneous bearing between agents and
their desired bearing. In order to have a unique global solution, the convex
optimization method is implemented. Since the rotation matrices are not convex,
the method of convex relaxation of rotation matrices space is used to embed the
rotation matrices on the convex hull of the Lie group. Then the control law is
designed to achieve the desired bearing with minimum energy consumption.
Finally, a simulation example is provided to verify the results.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17154" title="Abstract">arXiv:2309.17154</a> [<a href="/pdf/2309.17154" title="Download PDF">pdf</a>, <a href="/format/2309.17154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Interpretable Nonlinear Modeling for Multiple Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kevin Roy</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Ramos%2C+L+M">Luis Miguel Lopez-Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Beferull-Lozano%2C+B">Baltasar Beferull-Lozano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Predictive linear and nonlinear models based on kernel machines or deep
neural networks have been used to discover dependencies among time series. This
paper proposes an efficient nonlinear modeling approach for multiple time
series, with a complexity comparable to linear vector autoregressive (VAR)
models while still incorporating nonlinear interactions among different
time-series variables. The modeling assumption is that the set of time series
is generated in two steps: first, a linear VAR process in a latent space, and
second, a set of invertible and Lipschitz continuous nonlinear mappings that
are applied per sensor, that is, a component-wise mapping from each latent
variable to a variable in the measurement space. The VAR coefficient
identification provides a topology representation of the dependencies among the
aforementioned variables. The proposed approach models each component-wise
nonlinearity using an invertible neural network and imposes sparsity on the VAR
coefficients to reflect the parsimonious dependencies usually found in real
applications. To efficiently solve the formulated optimization problems, a
custom algorithm is devised combining proximal gradient descent, stochastic
primal-dual updates, and projection to enforce the corresponding constraints.
Experimental results on both synthetic and real data sets show that the
proposed algorithm improves the identification of the support of the VAR
coefficients in a parsimonious manner while also improving the time-series
prediction, as compared to the current state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17156" title="Abstract">arXiv:2309.17156</a> [<a href="/pdf/2309.17156" title="Download PDF">pdf</a>, <a href="/format/2309.17156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Age Group Discrimination via Free Handwriting Indicators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lomurno%2C+E">Eugenio Lomurno</a>, 
<a href="/search/cs?searchtype=author&query=Toffoli%2C+S">Simone Toffoli</a>, 
<a href="/search/cs?searchtype=author&query=Di+Febbo%2C+D">Davide Di Febbo</a>, 
<a href="/search/cs?searchtype=author&query=Matteucci%2C+M">Matteo Matteucci</a>, 
<a href="/search/cs?searchtype=author&query=Lunardini%2C+F">Francesca Lunardini</a>, 
<a href="/search/cs?searchtype=author&query=Ferrante%2C+S">Simona Ferrante</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The growing global elderly population is expected to increase the prevalence
of frailty, posing significant challenges to healthcare systems. Frailty, a
syndrome associated with ageing, is characterised by progressive health
decline, increased vulnerability to stressors and increased risk of mortality.
It represents a significant burden on public health and reduces the quality of
life of those affected. The lack of a universally accepted method to assess
frailty and a standardised definition highlights a critical research gap. Given
this lack and the importance of early prevention, this study presents an
innovative approach using an instrumented ink pen to ecologically assess
handwriting for age group classification. Content-free handwriting data from 80
healthy participants in different age groups (20-40, 41-60, 61-70 and 70+) were
analysed. Fourteen gesture- and tremor-related indicators were computed from
the raw data and used in five classification tasks. These tasks included
discriminating between adjacent and non-adjacent age groups using Catboost and
Logistic Regression classifiers. Results indicate exceptional classifier
performance, with accuracy ranging from 82.5% to 97.5%, precision from 81.8% to
100%, recall from 75% to 100% and ROC-AUC from 92.2% to 100%. Model
interpretability, facilitated by SHAP analysis, revealed age-dependent
sensitivity of temporal and tremor-related handwriting features. Importantly,
this classification method offers potential for early detection of abnormal
signs of ageing in uncontrolled settings such as remote home monitoring,
thereby addressing the critical issue of frailty detection and contributing to
improved care for older adults.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17157" title="Abstract">arXiv:2309.17157</a> [<a href="/pdf/2309.17157" title="Download PDF">pdf</a>, <a href="/format/2309.17157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LatticeGen: A Cooperative Framework which Hides Generated Text in a  Lattice for Privacy-Aware Generation on Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianxing He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianle Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mireshghallah%2C+F">Fatemehsadat Mireshghallah</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Binyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkov%2C+Y">Yulia Tsvetkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the current user-server interaction paradigm of prompted generation with
large language models (LLM) on cloud, the server fully controls the generation
process, which leaves zero options for users who want to keep the generated
text to themselves. We propose LatticeGen, a cooperative framework in which the
server still handles most of the computation while the user controls the
sampling operation. The key idea is that the true generated sequence is mixed
with noise tokens by the user and hidden in a noised lattice. Considering
potential attacks from a hypothetically malicious server and how the user can
defend against it, we propose the repeated beam-search attack and the mixing
noise scheme. In our experiments we apply LatticeGen to protect both prompt and
generation. It is shown that while the noised lattice degrades generation
quality, LatticeGen successfully protects the true generation to a remarkable
degree under strong attacks (more than 50% of the semantic remains hidden as
measured by BERTScore).
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17158" title="Abstract">arXiv:2309.17158</a> [<a href="/pdf/2309.17158" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compromise in Multilateral Negotiations and the Global Regulation of  Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Natorski%2C+M">Michal Natorski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 3 tables, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As artificial intelligence (AI) technologies spread worldwide, international
discussions have increasingly focused on their consequences for democracy,
human rights, fundamental freedoms, security, and economic and social
development. In this context, UNESCO's Recommendation on the Ethics of
Artificial Intelligence, adopted in November 2021, has emerged as the first
global normative framework for AI development and deployment. The intense
negotiations of every detail of the document brought forth numerous
controversies among UNESCO member states. Drawing on a unique set of primary
sources, including written positions and recorded deliberations, this paper
explains the achievement of global compromise on AI regulation despite the
multiplicity of UNESCO member-state positions representing a variety of liberal
and sovereignist preferences. Building upon Boltanski's pragmatic sociology, it
conceptualises the practice of multilateral negotiations and attributes the
multilateral compromise to two embedded therein mechanisms: Structural
normative hybridity and situated normative ambiguity allowed to accomplish a
compromise by linking macro-normative structures with situated debates of
multilateral negotiations.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17160" title="Abstract">arXiv:2309.17160</a> [<a href="/pdf/2309.17160" title="Download PDF">pdf</a>, <a href="/format/2309.17160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redistributing the Precision and Content in 3D-LUT-based Inverse  Tone-mapping for HDR/WCG Display
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Cheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Leidong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kanglin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiuhua Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in CVMP2023 (the 20th ACM SIGGRAPH European Conference on Visual Media Production)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">ITM(inverse tone-mapping) converts SDR (standard dynamic range) footage to
HDR/WCG (high dynamic range /wide color gamut) for media production. It happens
not only when remastering legacy SDR footage in front-end content provider, but
also adapting on-theair SDR service on user-end HDR display. The latter
requires more efficiency, thus the pre-calculated LUT (look-up table) has
become a popular solution. Yet, conventional fixed LUT lacks adaptability, so
we learn from research community and combine it with AI. Meanwhile,
higher-bit-depth HDR/WCG requires larger LUT than SDR, so we consult
traditional ITM for an efficiency-performance trade-off: We use 3 smaller LUTs,
each has a non-uniform packing (precision) respectively denser in dark, middle
and bright luma range. In this case, their results will have less error only in
their own range, so we use a contribution map to combine their best parts to
final result. With the guidance of this map, the elements (content) of 3 LUTs
will also be redistributed during training. We conduct ablation studies to
verify method's effectiveness, and subjective and objective experiments to show
its practicability. Code is available at: https://github.com/AndreGuo/ITMLUT.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17162" title="Abstract">arXiv:2309.17162</a> [<a href="/pdf/2309.17162" title="Download PDF">pdf</a>, <a href="/format/2309.17162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APNet: Urban-level Scene Segmentation of Aerial Images and Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Weijie Wei</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>, 
<a href="/search/cs?searchtype=author&query=Nejadasl%2C+F+K">Fatemeh Karimi Nejadasl</a>, 
<a href="/search/cs?searchtype=author&query=Gevers%2C+T">Theo Gevers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV Workshop 2023 and selected as an oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we focus on semantic segmentation method for point clouds of
urban scenes. Our fundamental concept revolves around the collaborative
utilization of diverse scene representations to benefit from different context
information and network architectures. To this end, the proposed network
architecture, called APNet, is split into two branches: a point cloud branch
and an aerial image branch which input is generated from a point cloud. To
leverage the different properties of each branch, we employ a geometry-aware
fusion module that is learned to combine the results of each branch. Additional
separate losses for each branch avoid that one branch dominates the results,
ensure the best performance for each branch individually and explicitly define
the input domain of the fusion network assuring it only performs data fusion.
Our experiments demonstrate that the fusion output consistently outperforms the
individual network branches and that APNet achieves state-of-the-art
performance of 65.2 mIoU on the SensatUrban dataset. Upon acceptance, the
source code will be made accessible.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17164" title="Abstract">arXiv:2309.17164</a> [<a href="/pdf/2309.17164" title="Download PDF">pdf</a>, <a href="/format/2309.17164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retail-786k: a Large-Scale Dataset for Visual Entity Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamm%2C+B">Bianca Lamm</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Keuper%2C+J">Janis Keuper</a> (1) ((1) IMLA, Offenburg University, (2) Markant Services International GmbH)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Entity Matching (EM) defines the task of learning to group objects by
transferring semantic concepts from example groups (=entities) to unseen data.
Despite the general availability of image data in the context of many
EM-problems, most currently available EM-algorithms solely rely on (textual)
meta data. In this paper, we introduce the first publicly available large-scale
dataset for "visual entity matching", based on a production level use case in
the retail domain. Using scanned advertisement leaflets, collected over several
years from different European retailers, we provide a total of ~786k manually
annotated, high resolution product images containing ~18k different individual
retail products which are grouped into ~3k entities. The annotation of these
product entities is based on a price comparison task, where each entity forms
an equivalence class of comparable products. Following on a first baseline
evaluation, we show that the proposed "visual entity matching" constitutes a
novel learning problem which can not sufficiently be solved using standard
image based classification and retrieval algorithms. Instead, novel approaches
which allow to transfer example based visual equivalent classes to new data are
needed to address the proposed problem. The aim of this paper is to provide a
benchmark for such algorithms.
<br />Information about the dataset, evaluation code and download instructions are
provided under https://www.retail-786k.org/.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17166" title="Abstract">arXiv:2309.17166</a> [<a href="/pdf/2309.17166" title="Download PDF">pdf</a>, <a href="/format/2309.17166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advances in Kidney Biopsy Structural Assessment through Dense Instance  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junling He</a>, 
<a href="/search/cs?searchtype=author&query=Valkema%2C+P">Pieter Valkema</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+Q">Tri Q. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Naesens%2C+M">Maarten Naesens</a>, 
<a href="/search/cs?searchtype=author&query=Kers%2C+J">Jesper Kers</a>, 
<a href="/search/cs?searchtype=author&query=Verbeek%2C+F+J">Fons J. Verbeek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures, 3 tables, Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The kidney biopsy is the gold standard for the diagnosis of kidney diseases.
Lesion scores made by expert renal pathologists are semi-quantitative and
suffer from high inter-observer variability. Automatically obtaining statistics
per segmented anatomical object, therefore, can bring significant benefits in
reducing labor and this inter-observer variability. Instance segmentation for a
biopsy, however, has been a challenging problem due to (a) the on average large
number (around 300 to 1000) of densely touching anatomical structures, (b) with
multiple classes (at least 3) and (c) in different sizes and shapes. The
currently used instance segmentation models cannot simultaneously deal with
these challenges in an efficient yet generic manner. In this paper, we propose
the first anchor-free instance segmentation model that combines diffusion
models, transformer modules, and RCNNs (regional convolution neural networks).
Our model is trained on just one NVIDIA GeForce RTX 3090 GPU, but can
efficiently recognize more than 500 objects with 3 common anatomical object
classes in renal biopsies, i.e., glomeruli, tubuli, and arteries. Our data set
consisted of 303 patches extracted from 148 Jones' silver-stained renal whole
slide images (WSIs), where 249 patches were used for training and 54 patches
for evaluation. In addition, without adjustment or retraining, the model can
directly transfer its domain to generate decent instance segmentation results
from PAS-stained WSIs. Importantly, it outperforms other baseline models and
reaches an AP 51.7% in detection as the new state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17167" title="Abstract">arXiv:2309.17167</a> [<a href="/pdf/2309.17167" title="Download PDF">pdf</a>, <a href="/format/2309.17167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DyVal: Graph-informed Dynamic Evaluation of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kaijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+N+Z">Neil Zhenqiang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report; 36 pages; code will be released at aka.ms/dyval
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have achieved remarkable performance in various
evaluation benchmarks. However, concerns about their performance are raised on
potential data contamination in their considerable volume of training corpus.
Moreover, the static nature and fixed complexity of current benchmarks may
inadequately gauge the advancing capabilities of LLMs. In this paper, we
introduce DyVal, a novel, general, and flexible evaluation protocol for dynamic
evaluation of LLMs. Based on our proposed dynamic evaluation framework, we
build graph-informed DyVal by leveraging the structural advantage of directed
acyclic graphs to dynamically generate evaluation samples with controllable
complexities. DyVal generates challenging evaluation sets on reasoning tasks
including mathematics, logical reasoning, and algorithm problems. We evaluate
various LLMs ranging from Flan-T5-large to ChatGPT and GPT4. Experiments
demonstrate that LLMs perform worse in DyVal-generated evaluation samples with
different complexities, emphasizing the significance of dynamic evaluation. We
also analyze the failure cases and results of different prompting methods.
Moreover, DyVal-generated samples are not only evaluation sets, but also
helpful data for fine-tuning to improve the performance of LLMs on existing
benchmarks. We hope that DyVal can shed light on the future evaluation research
of LLMs.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17169" title="Abstract">arXiv:2309.17169</a> [<a href="/pdf/2309.17169" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An evaluation of GPT models for phenotype concept recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groza%2C+T">Tudor Groza</a>, 
<a href="/search/cs?searchtype=author&query=Caufield%2C+H">Harry Caufield</a>, 
<a href="/search/cs?searchtype=author&query=Gration%2C+D">Dylan Gration</a>, 
<a href="/search/cs?searchtype=author&query=Baynam%2C+G">Gareth Baynam</a>, 
<a href="/search/cs?searchtype=author&query=Haendel%2C+M+A">Melissa A Haendel</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+P+N">Peter N Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Mungall%2C+C+J">Chris J Mungall</a>, 
<a href="/search/cs?searchtype=author&query=Reese%2C+J+T">Justin T Reese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Objective: Clinical deep phenotyping plays a critical role in both the
diagnosis of patients with rare disorders as well as in building care
coordination plans. The process relies on modelling and curating patient
profiles using ontology concepts, usually from the Human Phenotype Ontology.
Machine learning methods have been widely adopted to support this phenotype
concept recognition task. With the significant shift in the use of large
language models (LLMs) for most NLP tasks, herewithin, we examine the
performance of the latest Generative Pre-trained Transformer (GPT) models
underpinning ChatGPT in clinical deep phenotyping. Materials and Methods: The
experimental setup of the study included seven prompts of various levels of
specificity, two GPT models (gpt-3.5 and gpt-4.0) and an established gold
standard for phenotype recognition. Results: Our results show that, currently,
these models have not yet achieved state of the art performance. The best run,
using few-shots learning, achieved 0.41 F1 score, compared to a 0.62 F1 score
achieved by the current best in class tool. Conclusion: The non-deterministic
nature of the outcomes and the lack of concordance between different runs using
the same prompt and input makes the use of these LLMs in clinical settings
problematic.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17170" title="Abstract">arXiv:2309.17170</a> [<a href="/pdf/2309.17170" title="Download PDF">pdf</a>, <a href="/format/2309.17170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Vision-Guided Robotic System for Grasping Harvested Tomato Trusses in  Cluttered Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+den+Bent%2C+L">Luuk van den Bent</a>, 
<a href="/search/cs?searchtype=author&query=Coleman%2C+T">Tom&#xe1;s Coleman</a>, 
<a href="/search/cs?searchtype=author&query=Babuska%2C+R">Robert Babuska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Currently, truss tomato weighing and packaging require significant manual
work. The main obstacle to automation lies in the difficulty of developing a
reliable robotic grasping system for already harvested trusses. We propose a
method to grasp trusses that are stacked in a crate with considerable clutter,
which is how they are commonly stored and transported after harvest. The method
consists of a deep learning-based vision system to first identify the
individual trusses in the crate and then determine a suitable grasping location
on the stem. To this end, we have introduced a grasp pose ranking algorithm
with online learning capabilities. After selecting the most promising grasp
pose, the robot executes a pinch grasp without needing touch sensors or
geometric models. Lab experiments with a robotic manipulator equipped with an
eye-in-hand RGB-D camera showed a 100% clearance rate when tasked to pick all
trusses from a pile. 93% of the trusses were successfully grasped on the first
try, while the remaining 7% required more attempts.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17171" title="Abstract">arXiv:2309.17171</a> [<a href="/pdf/2309.17171" title="Download PDF">pdf</a>, <a href="/format/2309.17171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Named Entity Recognition in the Dungeons and  Dragons Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weerasundara%2C+G">Gayashan Weerasundara</a>, 
<a href="/search/cs?searchtype=author&query=de+Silva%2C+N">Nisansa de Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Many NLP tasks, although well-resolved for general English, face challenges
in specific domains like fantasy literature. This is evident in Named Entity
Recognition (NER), which detects and categorizes entities in text. We analyzed
10 NER models on 7 Dungeons and Dragons (D&amp;D) adventure books to assess
domain-specific performance. Using open-source Large Language Models, we
annotated named entities in these books and evaluated each model's precision.
Our findings indicate that, without modifications, Flair, Trankit, and Spacy
outperform others in identifying named entities in the D&amp;D context.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17172" title="Abstract">arXiv:2309.17172</a> [<a href="/pdf/2309.17172" title="Download PDF">pdf</a>, <a href="/format/2309.17172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Adaptive Learning: Unsupervised Adaptation for Histology Images  with Improved Loss Function Combination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R+K">Ravi Kant Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Shounak Das</a>, 
<a href="/search/cs?searchtype=author&query=Sethi%2C+A">Amit Sethi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a novel approach for unsupervised domain adaptation (UDA)
targeting H&amp;E stained histology images. Existing adversarial domain adaptation
methods may not effectively align different domains of multimodal distributions
associated with classification problems. The objective is to enhance domain
alignment and reduce domain shifts between these domains by leveraging their
unique characteristics. Our approach proposes a novel loss function along with
carefully selected existing loss functions tailored to address the challenges
specific to histology images. This loss combination not only makes the model
accurate and robust but also faster in terms of training convergence. We
specifically focus on leveraging histology-specific features, such as tissue
structure and cell morphology, to enhance adaptation performance in the
histology domain. The proposed method is extensively evaluated in accuracy,
robustness, and generalization, surpassing state-of-the-art techniques for
histology images. We conducted extensive experiments on the FHIST dataset and
the results show that our proposed method - Domain Adaptive Learning (DAL)
significantly surpasses the ViT-based and CNN-based SoTA methods by 1.41% and
6.56% respectively.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17174" title="Abstract">arXiv:2309.17174</a> [<a href="/pdf/2309.17174" title="Download PDF">pdf</a>, <a href="/format/2309.17174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedZeN: Towards superlinear zeroth-order federated learning via  incremental Hessian estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maritan%2C+A">Alessio Maritan</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+S">Subhrakanti Dey</a>, 
<a href="/search/cs?searchtype=author&query=Schenato%2C+L">Luca Schenato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Federated learning is a distributed learning framework that allows a set of
clients to collaboratively train a model under the orchestration of a central
server, without sharing raw data samples. Although in many practical scenarios
the derivatives of the objective function are not available, only few works
have considered the federated zeroth-order setting, in which functions can only
be accessed through a budgeted number of point evaluations. In this work we
focus on convex optimization and design the first federated zeroth-order
algorithm to estimate the curvature of the global objective, with the purpose
of achieving superlinear convergence. We take an incremental Hessian estimator
whose error norm converges linearly, and we adapt it to the federated
zeroth-order setting, sampling the random search directions from the Stiefel
manifold for improved performance. In particular, both the gradient and Hessian
estimators are built at the central server in a communication-efficient and
privacy-preserving way by leveraging synchronized pseudo-random number
generators. We provide a theoretical analysis of our algorithm, named FedZeN,
proving local quadratic convergence with high probability and global linear
convergence up to zeroth-order precision. Numerical simulations confirm the
superlinear convergence rate and show that our algorithm outperforms the
federated zeroth-order methods available in the literature.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17175" title="Abstract">arXiv:2309.17175</a> [<a href="/pdf/2309.17175" title="Download PDF">pdf</a>, <a href="/format/2309.17175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy  Text Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yihan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bowen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+R+W+H">Rynson W.H. Lau</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project website is available at: <a href="https://tyhuang0428.github.io/textfield3d.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent works learn 3D representation explicitly under text-3D guidance.
However, limited text-3D data restricts the vocabulary scale and text control
of generations. Generators may easily fall into a stereotype concept for
certain text prompts, thus losing open-vocabulary generation ability. To tackle
this issue, we introduce a conditional 3D generative model, namely TextField3D.
Specifically, rather than using the text prompts as input directly, we suggest
to inject dynamic noise into the latent space of given text prompts, i.e.,
Noisy Text Fields (NTFs). In this way, limited 3D data can be mapped to the
appropriate range of textual latent space that is expanded by NTFs. To this
end, an NTFGen module is proposed to model general text latent code in noisy
fields. Meanwhile, an NTFBind module is proposed to align view-invariant image
latent code to noisy fields, further supporting image-conditional 3D
generation. To guide the conditional generation in both geometry and texture,
multi-modal discrimination is constructed with a text-3D discriminator and a
text-2.5D discriminator. Compared to previous methods, TextField3D includes
three merits: 1) large vocabulary, 2) text consistency, and 3) low latency.
Extensive experiments demonstrate that our method achieves a potential
open-vocabulary 3D generation capability.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17176" title="Abstract">arXiv:2309.17176</a> [<a href="/pdf/2309.17176" title="Download PDF">pdf</a>, <a href="/format/2309.17176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLAdapter: Bridging Large Language Models to Reinforcement Learning in  Open Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zongqing Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">While reinforcement learning (RL) shows remarkable success in decision-making
problems, it often requires a lot of interactions with the environment, and in
sparse-reward environments, it is challenging to learn meaningful policies.
Large Language Models (LLMs) can potentially provide valuable guidance to
agents in learning policies, thereby enhancing the performance of RL algorithms
in such environments. However, LLMs often encounter difficulties in
understanding downstream tasks, which hinders their ability to optimally assist
agents in these tasks. A common approach to mitigating this issue is to
fine-tune the LLMs with task-related data, enabling them to offer useful
guidance for RL agents. However, this approach encounters several difficulties,
such as inaccessible model weights or the need for significant computational
resources, making it impractical. In this work, we introduce RLAdapter, a
framework that builds a better connection between RL algorithms and LLMs by
incorporating an adapter model. Within the RLAdapter framework, fine-tuning a
lightweight language model with information generated during the training
process of RL agents significantly aids LLMs in adapting to downstream tasks,
thereby providing better guidance for RL agents. We conducted experiments to
evaluate RLAdapter in the Crafter environment, and the results show that
RLAdapter surpasses the SOTA baselines. Furthermore, agents under our framework
exhibit common-sense behaviors that are absent in baseline models.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17179" title="Abstract">arXiv:2309.17179</a> [<a href="/pdf/2309.17179" title="Download PDF">pdf</a>, <a href="/format/2309.17179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alphazero-like Tree-Search can Guide Large Language Model Decoding and  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xidong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Ziyu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Muning Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) typically employ sampling or beam search,
accompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning and
decoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning via
Planning (RAP) aim to augment the reasoning capabilities of LLMs by utilizing
tree-search algorithms to guide multi-step reasoning. These methods mainly
focus on LLMs' reasoning ability during inference and heavily rely on
human-designed prompts to activate LLM as a value function, which lacks general
applicability and scalability. To address these limitations, we present an
AlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematically
illustrating how tree-search with a learned value function can guide LLMs'
decoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging a
learned value function, our approach can be generally applied to different
tasks beyond reasoning (such as RLHF alignment), and LLMs of any size, without
prompting advanced, large-scale models. (2) It can guide LLM's decoding during
both inference and training. Empirical evaluations across reasoning, planning,
and RLHF alignment tasks validate the effectiveness of TS-LLM, even on trees
with a depth of 64.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17182" title="Abstract">arXiv:2309.17182</a> [<a href="/pdf/2309.17182" title="Download PDF">pdf</a>, <a href="/format/2309.17182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RECOMBINER: Robust and Enhanced Compression with Bayesian Implicit  Neural Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiajun He</a>, 
<a href="/search/cs?searchtype=author&query=Flamich%2C+G">Gergely Flamich</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zongyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">COMpression with Bayesian Implicit NEural Representations (COMBINER) is a
recent data compression method that addresses a key inefficiency of previous
Implicit Neural Representation (INR)-based approaches: it avoids quantization
and enables direct optimization of the rate-distortion performance. However,
COMBINER still has significant limitations: 1) it uses factorized priors and
posterior approximations that lack flexibility; 2) it cannot effectively adapt
to local deviations from global patterns in the data; and 3) its performance
can be susceptible to modeling choices and the variational parameters'
initializations. Our proposed method, Robust and Enhanced COMBINER
(RECOMBINER), addresses these issues by 1) enriching the variational
approximation while maintaining its computational cost via a linear
reparameterization of the INR weights, 2) augmenting our INRs with learnable
positional encodings that enable them to adapt to local details and 3)
splitting high-resolution data into patches to increase robustness and
utilizing expressive hierarchical priors to capture dependency across patches.
We conduct extensive experiments across several data modalities, showcasing
that RECOMBINER achieves competitive results with the best INR-based methods
and even outperforms autoencoder-based codecs on low-resolution images at low
bitrates.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17183" title="Abstract">arXiv:2309.17183</a> [<a href="/pdf/2309.17183" title="Download PDF">pdf</a>, <a href="/format/2309.17183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grand Perspective: Load Shedding in Distributed CEP Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%C3%B6ger%2C+H">Henriette R&#xf6;ger</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+S">Sukanya Bhowmik</a>, 
<a href="/search/cs?searchtype=author&query=Rothermel%2C+K">Kurt Rothermel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In distributed Complex Event Processing (CEP) applications with high load but
limited resources, bottleneck operators in the operator graph can significantly
slow down processing of event streams, thus compelling the need to shed load. A
high-quality load shedding strategy that resolves the bottleneck with high
output quality evaluates each event's importance with regards to the
application's final output and drops less important events from the event
stream for the benefit of important ones. So far, no solution has been proposed
that is able to permit good load shedding in distributed, multi-operator CEP
applications. On one hand, shedding strategies have been proposed for
single-operator CEP applications that can measure an event's importance
immediately at the bottleneck operator, only, and thereby ignore the effect of
other streams in the application on an event's importance. On the other hand,
shedding strategies have been proposed for applications with multiple operators
from the area of stream processing that provide a fixed selectivity which is
not given in the conditional CEP operators. We, therefore, propose a
load-shedding solution for distributed CEP applications that maximizes the
application's final output and ensures timely processing of important events by
using a set of CEP-tailored selectivity functions and a linear program, which
is an abstraction of the CEP application. Moreover, our solution ensures a
quality optimal shedder configuration even in the presence of dynamically
changing conditions. With the help of extensive evaluations on both synthetic
and real data, we show that our solution successfully resolves overload at
bottleneck operators and at the same time maximizes the quality of the
application's output.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17185" title="Abstract">arXiv:2309.17185</a> [<a href="/pdf/2309.17185" title="Download PDF">pdf</a>, <a href="/format/2309.17185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta Reinforcement Learning for Fast Spectrum Sharing in Vehicular  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Le Liang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G+Y">Geoffrey Ye Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by China Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we investigate the problem of fast spectrum sharing in
vehicle-to-everything communication. In order to improve the spectrum
efficiency of the whole system, the spectrum of vehicle-to-infrastructure links
is reused by vehicle-to-vehicle links. To this end, we model it as a problem of
deep reinforcement learning and tackle it with proximal policy optimization. A
considerable number of interactions are often required for training an agent
with good performance, so simulation-based training is commonly used in
communication networks. Nevertheless, severe performance degradation may occur
when the agent is directly deployed in the real world, even though it can
perform well on the simulator, due to the reality gap between the simulation
and the real environments. To address this issue, we make preliminary efforts
by proposing an algorithm based on meta reinforcement learning. This algorithm
enables the agent to rapidly adapt to a new task with the knowledge extracted
from similar tasks, leading to fewer interactions and less training time.
Numerical results show that our method achieves near-optimal performance and
exhibits rapid convergence.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17186" title="Abstract">arXiv:2309.17186</a> [<a href="/pdf/2309.17186" title="Download PDF">pdf</a>, <a href="/format/2309.17186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unaware, Unfunded and Uneducated: A Systematic Review of SME  Cybersecurity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Junior%2C+C+R">Carlos Rombaldo Junior</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+I">Ingolf Becker</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+S">Shane Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Small and Medium Enterprises (SMEs) are pivotal in the global economy,
accounting for over 90% of businesses and 60% of employment worldwide. Despite
their significance, SMEs have been disregarded from cybersecurity initiatives,
rendering them ill-equipped to deal with the growing frequency, sophistication,
and destructiveness of cyber-attacks. We systematically reviewed the
cybersecurity literature on SMEs published between 2017 and 2023.
<br />We focus on research discussing cyber threats, adopted controls, challenges,
and constraints SMEs face in pursuing cybersecurity resilience.
<br />Our search yielded 916 studies that we narrowed to 77 relevant papers. We
identified 44 unique themes and categorised them as novel findings or
established knowledge. This distinction revealed that research on SMEs is
shallow and has made little progress in understanding SMEs' roles, threats, and
needs. Studies often repeated early discoveries without replicating or offering
new insights.
<br />The existing research indicates that the main challenges to attaining
cybersecurity resilience of SMEs are a lack of awareness of the cybersecurity
risks, limited cybersecurity literacy and constrained financial resources.
However, resource availability varied between developed and developing
countries. Our analysis indicated a relationship among these themes, suggesting
that limited literacy is the root cause of awareness and resource constraint
issues.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17187" title="Abstract">arXiv:2309.17187</a> [<a href="/pdf/2309.17187" title="Download PDF">pdf</a>, <a href="/format/2309.17187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TBD Pedestrian Data Collection: Towards Rich, Portable, and Large-Scale  Natural Pedestrian Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Allan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+D">Daisuke Sato</a>, 
<a href="/search/cs?searchtype=author&query=Corzo%2C+Y">Yasser Corzo</a>, 
<a href="/search/cs?searchtype=author&query=Simkin%2C+S">Sonya Simkin</a>, 
<a href="/search/cs?searchtype=author&query=Steinfeld%2C+A">Aaron Steinfeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: substantial text overlap with <a href="/abs/2203.01974">arXiv:2203.01974</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
<p class="mathjax">Social navigation and pedestrian behavior research has shifted towards
machine learning-based methods and converged on the topic of modeling
inter-pedestrian interactions and pedestrian-robot interactions. For this,
large-scale datasets that contain rich information are needed. We describe a
portable data collection system, coupled with a semi-autonomous labeling
pipeline. As part of the pipeline, we designed a label correction web app that
facilitates human verification of automated pedestrian tracking outcomes. Our
system enables large-scale data collection in diverse environments and fast
trajectory label production. Compared with existing pedestrian data collection
methods, our system contains three components: a combination of top-down and
ego-centric views, natural human behavior in the presence of a socially
appropriate "robot", and human-verified labels grounded in the metric space. To
the best of our knowledge, no prior data collection system has a combination of
all three components. We further introduce our ever-expanding dataset from the
ongoing data collection effort -- the TBD Pedestrian Dataset and show that our
collected data is larger in scale, contains richer information when compared to
prior datasets with human-verified labels, and supports new research
opportunities.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17189" title="Abstract">arXiv:2309.17189</a> [<a href="/pdf/2309.17189" title="Download PDF">pdf</a>, <a href="/format/2309.17189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTFS-Net: Recurrent time-frequency modelling for efficient audio-visual  speech separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pegg%2C+S">Samuel Pegg</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaolin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio-visual speech separation methods aim to integrate different modalities
to generate high-quality separated speech, thereby enhancing the performance of
downstream tasks such as speech recognition. Most existing state-of-the-art
(SOTA) models operate in the time domain. However, their overly simplistic
approach to modeling acoustic features often necessitates larger and more
computationally intensive models in order to achieve SOTA performance. In this
paper, we present a novel time-frequency domain audio-visual speech separation
method: Recurrent Time-Frequency Separation Network (RTFS-Net), which applies
its algorithms on the complex time-frequency bins yielded by the Short-Time
Fourier Transform. We model and capture the time and frequency dimensions of
the audio independently using a multi-layered RNN along each dimension.
Furthermore, we introduce a unique attention-based fusion technique for the
efficient integration of audio and visual information, and a new mask
separation approach that takes advantage of the intrinsic spectral nature of
the acoustic features for a clearer separation. RTFS-Net outperforms the
previous SOTA method using only 10% of the parameters and 18% of the MACs. This
is the first time-frequency domain audio-visual speech separation method to
outperform all contemporary time-domain counterparts.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17190" title="Abstract">arXiv:2309.17190</a> [<a href="/pdf/2309.17190" title="Download PDF">pdf</a>, <a href="/format/2309.17190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PARF: Primitive-Aware Radiance Fusion for Indoor Scene Novel View  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+H">Haiyang Ying</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Baowei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Di Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qionghai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Lu Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023; Project page: <a href="https://oceanying.github.io/PARF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper proposes a method for fast scene radiance field reconstruction
with strong novel view synthesis performance and convenient scene editing
functionality. The key idea is to fully utilize semantic parsing and primitive
extraction for constraining and accelerating the radiance field reconstruction
process. To fulfill this goal, a primitive-aware hybrid rendering strategy was
proposed to enjoy the best of both volumetric and primitive rendering. We
further contribute a reconstruction pipeline conducts primitive parsing and
radiance field learning iteratively for each input frame which successfully
fuses semantic, primitive, and radiance information into a single framework.
Extensive evaluations demonstrate the fast reconstruction ability, high
rendering quality, and convenient editing functionality of our method.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17192" title="Abstract">arXiv:2309.17192</a> [<a href="/pdf/2309.17192" title="Download PDF">pdf</a>, <a href="/format/2309.17192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Incremental Transfer Learning: Combining Peer-to-Peer  Federated Learning and Domain Incremental Learning for Multicenter  Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yixing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bert%2C+C">Christoph Bert</a>, 
<a href="/search/cs?searchtype=author&query=Gomaa%2C+A">Ahmed Gomaa</a>, 
<a href="/search/cs?searchtype=author&query=Fietkau%2C+R">Rainer Fietkau</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+A">Andreas Maier</a>, 
<a href="/search/cs?searchtype=author&query=Putz%2C+F">Florian Putz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Due to data privacy constraints, data sharing among multiple clinical centers
is restricted, which impedes the development of high performance deep learning
models from multicenter collaboration. Naive weight transfer methods share
intermediate model weights without raw data and hence can bypass data privacy
restrictions. However, performance drops are typically observed when the model
is transferred from one center to the next because of the forgetting problem.
Incremental transfer learning, which combines peer-to-peer federated learning
and domain incremental learning, can overcome the data privacy issue and
meanwhile preserve model performance by using continual learning techniques. In
this work, a conventional domain/task incremental learning framework is adapted
for incremental transfer learning. A comprehensive survey on the efficacy of
different regularization-based continual learning methods for multicenter
collaboration is performed. The influences of data heterogeneity, classifier
head setting, network optimizer, model initialization, center order, and weight
transfer type have been investigated thoroughly. Our framework is publicly
accessible to the research community for further development.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17193" title="Abstract">arXiv:2309.17193</a> [<a href="/pdf/2309.17193" title="Download PDF">pdf</a>, <a href="/format/2309.17193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M-DAB: An Input-Distribution Optimization Algorithm for Composite DNA  Storage by the Multinomial Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kobovich%2C+A">Adir Kobovich</a>, 
<a href="/search/cs?searchtype=author&query=Yaakobi%2C+E">Eitan Yaakobi</a>, 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+N">Nir Weinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Recent experiments have shown that the capacity of DNA storage systems may be
significantly increased by synthesizing composite DNA letters. In this work, we
model a DNA storage channel with composite inputs as a \textit{multinomial
channel}, and propose an optimization algorithm for its capacity achieving
input distribution, for an arbitrary number of output reads. The algorithm is
termed multidimensional dynamic assignment Blahut-Arimoto (M-DAB), and is a
generalized version of the DAB algorithm, proposed by Wesel et al. developed
for the binomial channel. We also empirically observe a scaling law behavior of
the capacity as a function of the support size of the capacity-achieving input
distribution.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17194" title="Abstract">arXiv:2309.17194</a> [<a href="/pdf/2309.17194" title="Download PDF">pdf</a>, <a href="/format/2309.17194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Activation via Multivariate Projection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayun Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuxiao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhuofan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yilin Mo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Activation functions are essential to introduce nonlinearity into neural
networks, with the Rectified Linear Unit (ReLU) often favored for its
simplicity and effectiveness. Motivated by the structural similarity between a
shallow Feedforward Neural Network (FNN) and a single iteration of the
Projected Gradient Descent (PGD) algorithm, a standard approach for solving
constrained optimization problems, we consider ReLU as a projection from R onto
the nonnegative half-line R+. Building on this interpretation, we extend ReLU
by substituting it with a generalized projection operator onto a convex cone,
such as the Second-Order Cone (SOC) projection, thereby naturally extending it
to a Multivariate Projection Unit (MPU), an activation function with multiple
inputs and multiple outputs. We further provide a mathematical proof
establishing that FNNs activated by SOC projections outperform those utilizing
ReLU in terms of expressive power. Experimental evaluations on widely-adopted
architectures further corroborate MPU's effectiveness against a broader range
of existing activation functions.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17196" title="Abstract">arXiv:2309.17196</a> [<a href="/pdf/2309.17196" title="Download PDF">pdf</a>, <a href="/format/2309.17196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResBit: Residual Bit Vector for Categorical Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuchi%2C+M">Masane Fuchi</a>, 
<a href="/search/cs?searchtype=author&query=Zanashir%2C+A">Amar Zanashir</a>, 
<a href="/search/cs?searchtype=author&query=Minami%2C+H">Hiroto Minami</a>, 
<a href="/search/cs?searchtype=author&query=Takagi%2C+T">Tomohiro Takagi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16pages and 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The one-hot vector has long been widely used in machine learning as a simple
and generic method for representing discrete data. However, this method
increases the number of dimensions linearly with the categorical data to be
represented, which is problematic from the viewpoint of spatial computational
complexity in deep learning, which requires a large amount of data. Recently,
Analog Bits, a method for representing discrete data as a sequence of bits, was
proposed on the basis of the high expressiveness of diffusion models. However,
since the number of category types to be represented in a generation task is
not necessarily at a power of two, there is a discrepancy between the range
that Analog Bits can represent and the range represented as category data. If
such a value is generated, the problem is that the original category value
cannot be restored. To address this issue, we propose Residual Bit Vector
(ResBit), which is a hierarchical bit representation. Although it is a
general-purpose representation method, in this paper, we treat it as numerical
data and show that it can be used as an extension of Analog Bits using Table
Residual Bit Diffusion (TRBD), which is incorporated into TabDDPM, a tabular
data generation method. We experimentally confirmed that TRBD can generate
diverse and high-quality data from small-scale table data to table data
containing diverse category values faster than TabDDPM. Furthermore, we show
that ResBit can also serve as an alternative to the one-hot vector by utilizing
ResBit for conditioning in GANs and as a label expression in image
classification.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17197" title="Abstract">arXiv:2309.17197</a> [<a href="/pdf/2309.17197" title="Download PDF">pdf</a>, <a href="/ps/2309.17197" title="Download PostScript">ps</a>, <a href="/format/2309.17197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Investigation Into Race Bias in Random Forest Models Based on Breast  DCE-MRI Derived Radiomics Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huti%2C+M">Mohamed Huti</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Tiarna Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sawyer%2C+E">Elinor Sawyer</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+A+P">Andrew P. King</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the MICCAI Workshop on Fairness of AI in Medical Imaging (FAIMI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent research has shown that artificial intelligence (AI) models can
exhibit bias in performance when trained using data that are imbalanced by
protected attribute(s). Most work to date has focused on deep learning models,
but classical AI techniques that make use of hand-crafted features may also be
susceptible to such bias. In this paper we investigate the potential for race
bias in random forest (RF) models trained using radiomics features. Our
application is prediction of tumour molecular subtype from dynamic contrast
enhanced magnetic resonance imaging (DCE-MRI) of breast cancer patients. Our
results show that radiomics features derived from DCE-MRI data do contain
race-identifiable information, and that RF models can be trained to predict
White and Black race from these data with 60-70% accuracy, depending on the
subset of features used. Furthermore, RF models trained to predict tumour
molecular subtype using race-imbalanced data seem to produce biased behaviour,
exhibiting better performance on test data from the race on which they were
trained.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17200" title="Abstract">arXiv:2309.17200</a> [<a href="/pdf/2309.17200" title="Download PDF">pdf</a>, <a href="/format/2309.17200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure-by-design smart contract based on dataflow implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brunet%2C+S+C">Simone Casale Brunet</a>, 
<a href="/search/cs?searchtype=author&query=Mattavelli%2C+M">Marco Mattavelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">This article conducts an extensive examination of the persisting challenges
related to smart contract attacks within blockchain networks, with a particular
focus on the reentrancy attack. It emphasizes the inherent vulnerabilities
embedded in the programming languages commonly employed for smart contract
development, particularly within Ethereum Virtual Machine (EVM)-based
blockchains. While the concrete example used primarily employs the Solidity
programming language, the insights garnered from this study are readily
generalizable to a wide array of blockchain architectures. Significantly, this
article extends beyond the mere identification of vulnerabilities and ventures
into the realm of proactive security measures. It explores the adaptation and
adoption of dataflow programming paradigms, employing Domain-Specific Languages
(DSLs) to enforce security by design in the context of smart contract
development. This forward-looking approach aims to bolster the foundational
principles of blockchain security, offering a promising research direction for
mitigating the risks associated with smart contract vulnerabilities. The
objective of this article is to cater to a diverse audience, ranging from
individuals with limited computer science and programming expertise to seasoned
experts in the field. It provides a comprehensive and accessible resource for
fostering a deeper understanding of the intricate dynamics between blockchain
technology and the imperative need for secure smart contract development
practices.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17203" title="Abstract">arXiv:2309.17203</a> [<a href="/pdf/2309.17203" title="Download PDF">pdf</a>, <a href="/format/2309.17203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ComSD: Balancing Behavioral Quality and Diversity in Unsupervised Skill  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yaran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongbin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Learning diverse and qualified behaviors for utilization and adaptation
without supervision is a key ability of intelligent creatures. Ideal
unsupervised skill discovery methods are able to produce diverse and qualified
skills in the absence of extrinsic reward, while the discovered skill set can
efficiently adapt to downstream tasks in various ways. Maximizing the Mutual
Information (MI) between skills and visited states can achieve ideal
skill-conditioned behavior distillation in theory. However, it's difficult for
recent advanced methods to well balance behavioral quality (exploration) and
diversity (exploitation) in practice, which may be attributed to the
unreasonable MI estimation by their rigid intrinsic reward design. In this
paper, we propose Contrastive multi-objectives Skill Discovery (ComSD) which
tries to mitigate the quality-versus-diversity conflict of discovered behaviors
through a more reasonable MI estimation and a dynamically weighted intrinsic
reward. ComSD proposes to employ contrastive learning for a more reasonable
estimation of skill-conditioned entropy in MI decomposition. In addition, a
novel weighting mechanism is proposed to dynamically balance different entropy
(in MI decomposition) estimations into a novel multi-objective intrinsic
reward, to improve both skill diversity and quality. For challenging robot
behavior discovery, ComSD can produce a qualified skill set consisting of
diverse behaviors at different activity levels, which recent advanced methods
cannot. On numerical evaluations, ComSD exhibits state-of-the-art adaptation
performance, significantly outperforming recent advanced skill discovery
methods across all skill combination tasks and most skill finetuning tasks.
Codes will be released at https://github.com/liuxin0824/ComSD.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17204" title="Abstract">arXiv:2309.17204</a> [<a href="/pdf/2309.17204" title="Download PDF">pdf</a>, <a href="/format/2309.17204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bandwidth Parameterized by Cluster Vertex Deletion Number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gima%2C+T">Tatsuya Gima</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+E+J">Eun Jung Kim</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6hler%2C+N">Noleen K&#xf6;hler</a>, 
<a href="/search/cs?searchtype=author&query=Melissinos%2C+N">Nikolaos Melissinos</a>, 
<a href="/search/cs?searchtype=author&query=Vasilakis%2C+M">Manolis Vasilakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extended abstract of this article was presented at IPEC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Given a graph $G$ and an integer $b$, Bandwidth asks whether there exists a
bijection $\pi$ from $V(G)$ to $\{1, \ldots, |V(G)|\}$ such that $\max_{\{u, v
\} \in E(G)} | \pi(u) - \pi(v) | \leq b$. This is a classical NP-complete
problem, known to remain NP-complete even on very restricted classes of graphs,
such as trees of maximum degree 3 and caterpillars of hair length 3. In the
realm of parameterized complexity, these results imply that the problem remains
NP-hard on graphs of bounded pathwidth, while it is additionally known to be
W[1]-hard when parameterized by the treedepth of the input graph. In contrast,
the problem does become FPT when parameterized by the vertex cover number of
the input graph. In this paper, we make progress towards the parameterized
(in)tractability of Bandwidth. We first show that it is FPT when parameterized
by the cluster vertex deletion number cvd plus the clique number $\omega$ of
the input graph, thus generalizing the previously mentioned result for vertex
cover. On the other hand, we show that Bandwidth is W[1]-hard when
parameterized only by cvd. Our results generalize some of the previous results
and narrow some of the complexity gaps.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17205" title="Abstract">arXiv:2309.17205</a> [<a href="/pdf/2309.17205" title="Download PDF">pdf</a>, <a href="/format/2309.17205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Complex-query Referring Image Segmentation: A Novel Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juncheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+R">Roger Zimmermann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring Image Understanding (RIS) has been extensively studied over the
past decade, leading to the development of advanced algorithms. However, there
has been a lack of research investigating how existing algorithms should be
benchmarked with complex language queries, which include more informative
descriptions of surrounding objects and backgrounds (\eg \textit{"the black
car."} vs. \textit{"the black car is parking on the road and beside the
bus."}). Given the significant improvement in the semantic understanding
capability of large pre-trained models, it is crucial to take a step further in
RIS by incorporating complex language that resembles real-world applications.
To close this gap, building upon the existing RefCOCO and Visual Genome
datasets, we propose a new RIS benchmark with complex queries, namely
\textbf{RIS-CQ}. The RIS-CQ dataset is of high quality and large scale, which
challenges the existing RIS with enriched, specific and informative queries,
and enables a more realistic scenario of RIS research. Besides, we present a
nichetargeting method to better task the RIS-CQ, called dual-modality graph
alignment model (\textbf{\textsc{DuMoGa}}), which outperforms a series of RIS
methods.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17207" title="Abstract">arXiv:2309.17207</a> [<a href="/pdf/2309.17207" title="Download PDF">pdf</a>, <a href="/format/2309.17207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Gym: Partially Observable Challenges to Memory-Based Agents in  Endless Episodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pleines%2C+M">Marco Pleines</a>, 
<a href="/search/cs?searchtype=author&query=Pallasch%2C+M">Matthias Pallasch</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+F">Frank Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Preuss%2C+M">Mike Preuss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 17 figures, 5 tables, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Memory Gym introduces a unique benchmark designed to test Deep Reinforcement
Learning agents, specifically comparing Gated Recurrent Unit (GRU) against
Transformer-XL (TrXL), on their ability to memorize long sequences, withstand
noise, and generalize. It features partially observable 2D environments with
discrete controls, namely Mortar Mayhem, Mystery Path, and Searing Spotlights.
These originally finite environments are extrapolated to novel endless tasks
that act as an automatic curriculum, drawing inspiration from the car game ``I
packed my bag". These endless tasks are not only beneficial for evaluating
efficiency but also intriguingly valuable for assessing the effectiveness of
approaches in memory-based agents. Given the scarcity of publicly available
memory baselines, we contribute an implementation driven by TrXL and Proximal
Policy Optimization. This implementation leverages TrXL as episodic memory
using a sliding window approach. In our experiments on the finite environments,
TrXL demonstrates superior sample efficiency in Mystery Path and outperforms in
Mortar Mayhem. However, GRU is more efficient on Searing Spotlights. Most
notably, in all endless tasks, GRU makes a remarkable resurgence, consistently
outperforming TrXL by significant margins.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17209" title="Abstract">arXiv:2309.17209</a> [<a href="/pdf/2309.17209" title="Download PDF">pdf</a>, <a href="/format/2309.17209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robots That Can See: Leveraging Human Pose for Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salzmann%2C+T">Tim Salzmann</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+L">Lewis Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Ryll%2C+M">Markus Ryll</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Parada%2C+C">Carolina Parada</a>, 
<a href="/search/cs?searchtype=author&query=Bewley%2C+A">Alex Bewley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://human-scene-transformer.github.io/">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, vol. 8, no. 11, pp.
  7090-7097, Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Anticipating the motion of all humans in dynamic environments such as homes
and offices is critical to enable safe and effective robot navigation. Such
spaces remain challenging as humans do not follow strict rules of motion and
there are often multiple occluded entry points such as corners and doors that
create opportunities for sudden encounters. In this work, we present a
Transformer based architecture to predict human future trajectories in
human-centric environments from input features including human positions, head
orientations, and 3D skeletal keypoints from onboard in-the-wild sensory
information. The resulting model captures the inherent uncertainty for future
human trajectory prediction and achieves state-of-the-art performance on common
prediction benchmarks and a human tracking dataset captured from a mobile robot
adapted for the prediction task. Furthermore, we identify new agents with
limited historical data as a major contributor to error and demonstrate the
complementary nature of 3D skeletal poses in reducing prediction error in such
challenging scenarios.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17211" title="Abstract">arXiv:2309.17211</a> [<a href="/pdf/2309.17211" title="Download PDF">pdf</a>, <a href="/format/2309.17211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instant Complexity Reduction in CNNs using Locality-Sensitive Hashing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meiner%2C+L">Lukas Meiner</a>, 
<a href="/search/cs?searchtype=author&query=Mehnert%2C+J">Jens Mehnert</a>, 
<a href="/search/cs?searchtype=author&query=Condurache%2C+A+P">Alexandru Paul Condurache</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To reduce the computational cost of convolutional neural networks (CNNs) for
usage on resource-constrained devices, structured pruning approaches have shown
promising results, drastically reducing floating-point operations (FLOPs)
without substantial drops in accuracy. However, most recent methods require
fine-tuning or specific training procedures to achieve a reasonable trade-off
between retained accuracy and reduction in FLOPs. This introduces additional
cost in the form of computational overhead and requires training data to be
available. To this end, we propose HASTE (Hashing for Tractable Efficiency), a
parameter-free and data-free module that acts as a plug-and-play replacement
for any regular convolution module. It instantly reduces the network's
test-time inference cost without requiring any training or fine-tuning. We are
able to drastically compress latent feature maps without sacrificing much
accuracy by using locality-sensitive hashing (LSH) to detect redundancies in
the channel dimension. Similar channels are aggregated to reduce the input and
filter depth simultaneously, allowing for cheaper convolutions. We demonstrate
our approach on the popular vision benchmarks CIFAR-10 and ImageNet. In
particular, we are able to instantly drop 46.72% of FLOPs while only losing
1.25% accuracy by just swapping the convolution modules in a ResNet34 on
CIFAR-10 for our HASTE module.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17215" title="Abstract">arXiv:2309.17215</a> [<a href="/pdf/2309.17215" title="Download PDF">pdf</a>, <a href="/format/2309.17215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RSAM: Learning on manifolds with Riemannian Sharpness-aware Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+T">Tuan Truong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hoang-Phi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Tung Pham</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Minh-Tuan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Harandi%2C+M">Mehrtash Harandi</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+D">Dinh Phung</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Nowadays, understanding the geometry of the loss landscape shows promise in
enhancing a model's generalization ability. In this work, we draw upon prior
works that apply geometric principles to optimization and present a novel
approach to improve robustness and generalization ability for constrained
optimization problems. Indeed, this paper aims to generalize the
Sharpness-Aware Minimization (SAM) optimizer to Riemannian manifolds. In doing
so, we first extend the concept of sharpness and introduce a novel notion of
sharpness on manifolds. To support this notion of sharpness, we present a
theoretical analysis characterizing generalization capabilities with respect to
manifold sharpness, which demonstrates a tighter bound on the generalization
gap, a result not known before. Motivated by this analysis, we introduce our
algorithm, Riemannian Sharpness-Aware Minimization (RSAM). To demonstrate
RSAM's ability to enhance generalization ability, we evaluate and contrast our
algorithm on a broad set of problems, such as image classification and
contrastive learning across different datasets, including CIFAR100, CIFAR10,
and FGVCAircraft. Our code is publicly available at
\url{https://t.ly/RiemannianSAM}.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17218" title="Abstract">arXiv:2309.17218</a> [<a href="/pdf/2309.17218" title="Download PDF">pdf</a>, <a href="/format/2309.17218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Epipolar Constraint Meets Non-local Operators in Multi-View Stereo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xinyi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weiyue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Min Shi</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguo Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning-based multi-view stereo (MVS) method heavily relies on feature
matching, which requires distinctive and descriptive representations. An
effective solution is to apply non-local feature aggregation, e.g.,
Transformer. Albeit useful, these techniques introduce heavy computation
overheads for MVS. Each pixel densely attends to the whole image. In contrast,
we propose to constrain non-local feature augmentation within a pair of lines:
each point only attends the corresponding pair of epipolar lines. Our idea
takes inspiration from the classic epipolar geometry, which shows that one
point with different depth hypotheses will be projected to the epipolar line on
the other view. This constraint reduces the 2D search space into the epipolar
line in stereo matching. Similarly, this suggests that the matching of MVS is
to distinguish a series of points lying on the same line. Inspired by this
point-to-line search, we devise a line-to-point non-local augmentation
strategy. We first devise an optimized searching algorithm to split the 2D
feature maps into epipolar line pairs. Then, an Epipolar Transformer (ET)
performs non-local feature augmentation among epipolar line pairs. We
incorporate the ET into a learning-based MVS baseline, named ET-MVSNet.
ET-MVSNet achieves state-of-the-art reconstruction performance on both the DTU
and Tanks-and-Temples benchmark with high efficiency. Code is available at
https://github.com/TQTQliu/ET-MVSNet.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17224" title="Abstract">arXiv:2309.17224</a> [<a href="/pdf/2309.17224" title="Download PDF">pdf</a>, <a href="/format/2309.17224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training and inference of large language models using 8-bit floating  point
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perez%2C+S+P">Sergio P. Perez</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Briggs%2C+J">James Briggs</a>, 
<a href="/search/cs?searchtype=author&query=Blake%2C+C">Charlie Blake</a>, 
<a href="/search/cs?searchtype=author&query=Levy-Kramer%2C+J">Josh Levy-Kramer</a>, 
<a href="/search/cs?searchtype=author&query=Balanca%2C+P">Paul Balanca</a>, 
<a href="/search/cs?searchtype=author&query=Luschi%2C+C">Carlo Luschi</a>, 
<a href="/search/cs?searchtype=author&query=Barlow%2C+S">Stephen Barlow</a>, 
<a href="/search/cs?searchtype=author&query=Fitzgibbon%2C+A+W">Andrew William Fitzgibbon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Computation and Language (cs.CL); Emerging Technologies (cs.ET); Performance (cs.PF)

</div>
<p class="mathjax">FP8 formats are gaining popularity to boost the computational efficiency for
training and inference of large deep learning models. Their main challenge is
that a careful choice of scaling is needed to prevent degradation due to the
reduced dynamic range compared to higher-precision formats. Although there
exists ample literature about selecting such scalings for INT formats, this
critical aspect has yet to be addressed for FP8. This paper presents a
methodology to select the scalings for FP8 linear layers, based on dynamically
updating per-tensor scales for the weights, gradients and activations. We apply
this methodology to train and validate large language models of the type of GPT
and Llama 2 using FP8, for model sizes ranging from 111M to 70B. To facilitate
the understanding of the FP8 dynamics, our results are accompanied by plots of
the per-tensor scale distribution for weights, activations and gradients during
both training and inference.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17226" title="Abstract">arXiv:2309.17226</a> [<a href="/pdf/2309.17226" title="Download PDF">pdf</a>, <a href="/format/2309.17226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Optimization Based Time-Varying Control Barrier Functions  for Dynamic Obstacle Avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bolun Dai</a>, 
<a href="/search/cs?searchtype=author&query=Khorrambakht%2C+R">Rooholla Khorrambakht</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+P">Prashanth Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Khorrami%2C+F">Farshad Khorrami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Control barrier functions (CBFs) provide a simple yet effective way for safe
control synthesis. Recently, work has been done using differentiable
optimization based methods to systematically construct CBFs for static obstacle
avoidance tasks between geometric shapes. In this work, we extend the
application of differentiable optimization based CBFs to perform dynamic
obstacle avoidance tasks. We show that by using the time-varying CBF (TVCBF)
formulation, we can perform obstacle avoidance for dynamic geometric obstacles.
Additionally, we show how to alter the TVCBF constraint to consider measurement
noise and actuation limits. To demonstrate the efficacy of our proposed
approach, we first compare its performance with a model predictive control
based method on a simulated dynamic obstacle avoidance task with
non-ellipsoidal obstacles. Then, we demonstrate the performance of our proposed
approach in experimental studies using a 7-degree-of-freedom Franka Research 3
robotic manipulator.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17227" title="Abstract">arXiv:2309.17227</a> [<a href="/pdf/2309.17227" title="Download PDF">pdf</a>, <a href="/format/2309.17227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MORPH: Design Co-optimization with Reinforcement Learning via a  Differentiable Hardware Model Proxy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhanpeng He</a>, 
<a href="/search/cs?searchtype=author&query=Ciocarlie%2C+M">Matei Ciocarlie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce MORPH, a method for co-optimization of hardware design
parameters and control policies in simulation using reinforcement learning.
Like most co-optimization methods, MORPH relies on a model of the hardware
being optimized, usually simulated based on the laws of physics. However, such
a model is often difficult to integrate into an effective optimization routine.
To address this, we introduce a proxy hardware model, which is always
differentiable and enables efficient co-optimization alongside a long-horizon
control policy using RL. MORPH is designed to ensure that the optimized
hardware proxy remains as close as possible to its realistic counterpart, while
still enabling task completion. We demonstrate our approach on simulated 2D
reaching and 3D multi-fingered manipulation tasks.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17228" title="Abstract">arXiv:2309.17228</a> [<a href="/pdf/2309.17228" title="Download PDF">pdf</a>, <a href="/format/2309.17228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Roundoff error analysis of the double exponential formula-based method  for the matrix sign function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miyashita%2C+T">Tomoya Miyashita</a>, 
<a href="/search/math?searchtype=author&query=Kudo%2C+S">Shuhei Kudo</a>, 
<a href="/search/math?searchtype=author&query=Yamamoto%2C+Y">Yusaku Yamamoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we perform a roundoff error analysis of an integration-based
method for computing the matrix sign function recently proposed by Nakaya and
Tanaka. The method expresses the matrix sign function using an integral
representation and computes the integral numerically by the double-exponential
formula. While the method has large-grain parallelism and works well for
well-conditioned matrices, its accuracy deteriorates when the input matrix is
ill-conditioned or highly nonnormal. We investigate the reason for this
phenomenon by a detailed roundoff error analysis.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17230" title="Abstract">arXiv:2309.17230</a> [<a href="/pdf/2309.17230" title="Download PDF">pdf</a>, <a href="/format/2309.17230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spurious Feature Diversification Improves Out-of-distribution  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+L">Lu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yifan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+H">Honam Wong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hanze Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 70+ pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Generalization to out-of-distribution (OOD) data is a critical challenge in
machine learning. Ensemble-based methods, like weight space ensembles that
interpolate model parameters, have been shown to achieve superior OOD
performance. However, the underlying mechanism for their effectiveness remains
unclear. In this study, we closely examine WiSE-FT, a popular weight space
ensemble method that interpolates between a pre-trained and a fine-tuned model.
We observe an unexpected phenomenon, in which WiSE-FT successfully corrects
many cases where each individual model makes incorrect predictions, which
contributes significantly to its OOD effectiveness. To gain further insights,
we conduct theoretical analysis in a multi-class setting with a large number of
spurious features. Our analysis predicts the above phenomenon and it further
shows that ensemble-based models reduce prediction errors in the OOD settings
by utilizing a more diverse set of spurious features. Contrary to the
conventional wisdom that focuses on learning invariant features for better OOD
performance, our findings suggest that incorporating a large number of diverse
spurious features weakens their individual contributions, leading to improved
overall OOD generalization performance. Empirically we demonstrate the
effectiveness of utilizing diverse spurious features on a MultiColorMNIST
dataset, and our experimental results are consistent with the theoretical
analysis. Building upon the new theoretical insights into the efficacy of
ensemble methods, we further identify an issue of WiSE-FT caused by the
overconfidence of fine-tuned models in OOD situations. This overconfidence
magnifies the fine-tuned model's incorrect prediction, leading to deteriorated
OOD ensemble performance. To remedy this problem, we propose a novel method
called BAlaNced averaGing (BANG), which significantly enhances the OOD
performance of WiSE-FT.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17234" title="Abstract">arXiv:2309.17234</a> [<a href="/pdf/2309.17234" title="Download PDF">pdf</a>, <a href="/format/2309.17234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent  Negotiation Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelnabi%2C+S">Sahar Abdelnabi</a>, 
<a href="/search/cs?searchtype=author&query=Gomaa%2C+A">Amr Gomaa</a>, 
<a href="/search/cs?searchtype=author&query=Sivaprasad%2C+S">Sarath Sivaprasad</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nherr%2C+L">Lea Sch&#xf6;nherr</a>, 
<a href="/search/cs?searchtype=author&query=Fritz%2C+M">Mario Fritz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">There is a growing interest in using Large Language Models (LLMs) as agents
to tackle real-world tasks that may require assessing complex situations. Yet,
we have a limited understanding of LLMs' reasoning and decision-making
capabilities, partly stemming from a lack of dedicated evaluation benchmarks.
As negotiating and compromising are key aspects of our everyday communication
and collaboration, we propose using scorable negotiation games as a new
evaluation framework for LLMs. We create a testbed of diverse text-based,
multi-agent, multi-issue, semantically rich negotiation games, with easily
tunable difficulty. To solve the challenge, agents need to have strong
arithmetic, inference, exploration, and planning capabilities, while seamlessly
integrating them. Via a systematic zero-shot Chain-of-Thought prompting (CoT),
we show that agents can negotiate and consistently reach successful deals. We
quantify the performance with multiple metrics and observe a large gap between
GPT-4 and earlier models. Importantly, we test the generalization to new games
and setups. Finally, we show that these games can help evaluate other critical
aspects, such as the interaction dynamics between agents in the presence of
greedy and adversarial players.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17238" title="Abstract">arXiv:2309.17238</a> [<a href="/pdf/2309.17238" title="Download PDF">pdf</a>, <a href="/format/2309.17238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework and a python-package for Real-time NMPC parameters settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alamir%2C+M">Mazen Alamir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a framework that enables a systematic and rational choice
of NMPC design components such as control updating period, down-sampling period
for prediction, control parameterization, prediction horizon's length, the
maximum number of iterations as well as penalties on the terminal cost and the
soft constraints. The rationale that underlines the design choices is based on
real-time implementability, convergence and constraints satisfaction for a
given computational device and a specific optimization algorithm. Moreover, a
freely available associated Python-based implementation is also described with
a fully developed illustrative example implementing a nonlinear MPC controller
for a Planar Vertical Take-Off and Landing (PVTOL) aircraft under control
saturation and state constraints.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17239" title="Abstract">arXiv:2309.17239</a> [<a href="/pdf/2309.17239" title="Download PDF">pdf</a>, <a href="/format/2309.17239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EGVD: Event-Guided Video Deraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yueyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+W">Wenming Weng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the rapid development of deep learning, video deraining has experienced
significant progress. However, existing video deraining pipelines cannot
achieve satisfying performance for scenes with rain layers of complex
spatio-temporal distribution. In this paper, we approach video deraining by
employing an event camera. As a neuromorphic sensor, the event camera suits
scenes of non-uniform motion and dynamic light conditions. We propose an
end-to-end learning-based network to unlock the potential of the event camera
for video deraining. First, we devise an event-aware motion detection module to
adaptively aggregate multi-frame motion contexts using event-aware masks.
Second, we design a pyramidal adaptive selection module for reliably separating
the background and rain layers by incorporating multi-modal contextualized
priors. In addition, we build a real-world dataset consisting of rainy videos
and temporally synchronized event streams. We compare our method with extensive
state-of-the-art methods on synthetic and self-collected real-world datasets,
demonstrating the clear superiority of our method. The code and dataset are
available at \url{https://github.com/booker-max/EGVD}.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17243" title="Abstract">arXiv:2309.17243</a> [<a href="/pdf/2309.17243" title="Download PDF">pdf</a>, <a href="/format/2309.17243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Handling Correlated Rounding Error via Preclustering: A  1.73-approximation for Correlation Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen-Addad%2C+V">Vincent Cohen-Addad</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Euiwoong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shi Li</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+A">Alantha Newman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We consider the classic Correlation Clustering problem: Given a complete
graph where edges are labelled either $+$ or $-$, the goal is to find a
partition of the vertices that minimizes the number of the \pedges across parts
plus the number of the \medges within parts. Recently, Cohen-Addad, Lee and
Newman [CLN22] presented a 1.994-approximation algorithm for the problem using
the Sherali-Adams hierarchy, hence breaking through the integrality gap of 2
for the classic linear program and improving upon the 2.06-approximation of
Chawla, Makarychev, Schramm and Yaroslavtsev [CMSY15].
<br />We significantly improve the state-of-the-art by providing a
1.73-approximation for the problem. Our approach introduces a preclustering of
Correlation Clustering instances that allows us to essentially ignore the error
arising from the {\em correlated rounding} used by [CLN22]. This additional
power simplifies the previous algorithm and analysis. More importantly, it
enables a new {\em set-based rounding} that complements the previous roundings.
A combination of these two rounding algorithms yields the improved bound.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17245" title="Abstract">arXiv:2309.17245</a> [<a href="/pdf/2309.17245" title="Download PDF">pdf</a>, <a href="/format/2309.17245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Performance Evaluation of Byzantine Fault-Tolerant Systems  Using Network Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berger%2C+C">Christian Berger</a>, 
<a href="/search/cs?searchtype=author&query=Toumia%2C+S+B">Sadok Ben Toumia</a>, 
<a href="/search/cs?searchtype=author&query=Reiser%2C+H+P">Hans P. Reiser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, accepted at the 28th IEEE Pacific Rim International Symposium on Dependable Computing (PRDC 2023) 24-27, OCT, 2023, Singapore, Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Recent Byzantine fault-tolerant (BFT) state machine replication (SMR)
protocols increasingly focus on scalability to meet the requirements of
distributed ledger technology (DLT). Validating the performance of scalable BFT
protocol implementations requires careful evaluation. Our solution uses network
simulations to forecast the performance of BFT protocols while experimentally
scaling the environment. Our method seamlessly plug-and-plays existing BFT
implementations into the simulation without requiring code modification or
re-implementation, which is often time-consuming and error-prone. Furthermore,
our approach is also significantly cheaper than experiments with real
large-scale cloud deployments. In this paper, we first explain our simulation
architecture, which enables scalable performance evaluations of BFT systems
through high performance network simulations. We validate the accuracy of these
simulations for predicting the performance of BFT systems by comparing
simulation results with measurements of real systems deployed on cloud
infrastructures. We found that simulation results display a reasonable
approximation at a larger system scale, because the network eventually becomes
the dominating factor limiting system performance. In the second part of our
paper, we use our simulation method to evaluate the performance of PBFT and BFT
protocols from the blockchain generation, such as HotStuff and Kauri, in
large-scale and realistic wide-area network scenarios, as well as under induced
faults.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17249" title="Abstract">arXiv:2309.17249</a> [<a href="/pdf/2309.17249" title="Download PDF">pdf</a>, <a href="/format/2309.17249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Batch Calibration: Rethinking Calibration for In-Context Learning and  Prompt Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Han Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xingchen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Proleev%2C+L">Lev Proleev</a>, 
<a href="/search/cs?searchtype=author&query=Mincu%2C+D">Diana Mincu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jilin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+K">Katherine Heller</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Subhrajit Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 10 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Prompting and in-context learning (ICL) have become efficient learning
paradigms for large language models (LLMs). However, LLMs suffer from prompt
brittleness and various bias factors in the prompt, including but not limited
to the formatting, the choice verbalizers, and the ICL examples. To address
this problem that results in unexpected performance degradation, calibration
methods have been developed to mitigate the effects of these biases while
recovering LLM performance. In this work, we first conduct a systematic
analysis of the existing calibration methods, where we both provide a unified
view and reveal the failure cases. Inspired by these analyses, we propose Batch
Calibration (BC), a simple yet intuitive method that controls the contextual
bias from the batched input, unifies various prior approaches, and effectively
addresses the aforementioned issues. BC is zero-shot, inference-only, and
incurs negligible additional costs. In the few-shot setup, we further extend BC
to allow it to learn the contextual bias from labeled data. We validate the
effectiveness of BC with PaLM 2-(S, M, L) and CLIP models and demonstrate
state-of-the-art performance over previous calibration baselines across more
than 10 natural language understanding and image classification tasks.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17252" title="Abstract">arXiv:2309.17252</a> [<a href="/pdf/2309.17252" title="Download PDF">pdf</a>, <a href="/format/2309.17252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forest Mixing: investigating the impact of multiple search trees and a  shared refinements pool on ontology learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pop-Mihali%2C+M">Marco Pop-Mihali</a>, 
<a href="/search/cs?searchtype=author&query=Groza%2C+A">Adrian Groza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We aim at development white-box machine learning algorithms. We focus here on
algorithms for learning axioms in description logic. We extend the Class
Expression Learning for Ontology Engineering (CELOE) algorithm contained in the
DL-Learner tool. The approach uses multiple search trees and a shared pool of
refinements in order to split the search space in smaller subspaces. We
introduce the conjunction operation of best class expressions from each tree,
keeping the results which give the most information. The aim is to foster
exploration from a diverse set of starting classes and to streamline the
process of finding class expressions in ontologies. %, particularly in large
search spaces. The current implementation and settings indicated that the
Forest Mixing approach did not outperform the traditional CELOE. Despite these
results, the conceptual proposal brought forward by this approach may stimulate
future improvements in class expression finding in ontologies. % and influence.
% the way we traverse search spaces in general.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17253" title="Abstract">arXiv:2309.17253</a> [<a href="/pdf/2309.17253" title="Download PDF">pdf</a>, <a href="/format/2309.17253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secondary Defense Strategies of AC Microgrids Against Generally  Unbounded Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rajabinezhad%2C+M">Mohamadamin Rajabinezhad</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+S">Shan Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper develops a fully distributed attack-resilient secondary defense
strategies for AC microgrids, addressing more generally unbounded attacks on
control input channels than those addressed in existing literature. The
secondary control of local inverter includes consensus-based voltage and
current regulators utilizing relative information from neighboring inverters.
This distributed control approach relies on localized control and a sparse
communication network, making it susceptible to malicious cyber-physical
attacks that can impair consensus performance and potentially destabilize the
overall microgrid. In contrast to existing solutions that are limited to
addressing either bounded faults, noises or unbounded attacks with bounded
first-order time derivatives, we aim to surpass these constraints and enhance
the defense capabilities of counteracting cyber-physical attacks by enabling
the AC microgrids adopting the proposed strategies to withstand a much wider
range of unbounded cyber-attack signals. Fully distributed attack-resilient
secondary defense strategies are developed for AC microgrids to counteract the
detrimental effects of generally unbounded attacks on control input channels.
Rigorous proofs using Lyapunov techniques demonstrate that the proposed defense
strategies accomplish the uniformly ultimately bounded convergence on frequency
regulation and achieve voltage containment and active power sharing
simultaneously for multi-inverter-based AC microgrids in the face of generally
unbounded attacks. The proposed defense strategies are validated on a modified
IEEE 34-bus test feeder benchmark system incorporating four inverter-based
DERs.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17255" title="Abstract">arXiv:2309.17255</a> [<a href="/pdf/2309.17255" title="Download PDF">pdf</a>, <a href="/format/2309.17255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graphs for the Life Sciences: Recent Developments, Challenges  and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hastings%2C+J">Janna Hastings</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez-Ruiz%2C+E">Ernesto Jim&#xe9;nez-Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+V">Vanessa Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Monnin%2C+P">Pierre Monnin</a>, 
<a href="/search/cs?searchtype=author&query=Pesquita%2C+C">Catia Pesquita</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0koda%2C+P">Petr &#x160;koda</a>, 
<a href="/search/cs?searchtype=author&query=Tamma%2C+V">Valentina Tamma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 1 figure, accepted for Transactions on Graph Data and Knowledge (TGDK)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The term life sciences refers to the disciplines that study living organisms
and life processes, and include chemistry, biology, medicine, and a range of
other related disciplines. Research efforts in life sciences are heavily
data-driven, as they produce and consume vast amounts of scientific data, much
of which is intrinsically relational and graph-structured.
<br />The volume of data and the complexity of scientific concepts and relations
referred to therein promote the application of advanced knowledge-driven
technologies for managing and interpreting data, with the ultimate aim to
advance scientific discovery.
<br />In this survey and position paper, we discuss recent developments and
advances in the use of graph-based technologies in life sciences and set out a
vision for how these technologies will impact these fields into the future. We
focus on three broad topics: the construction and management of Knowledge
Graphs (KGs), the use of KGs and associated technologies in the discovery of
new knowledge, and the use of KGs in artificial intelligence applications to
support explanations (explainable AI). We select a few exemplary use cases for
each topic, discuss the challenges and open research questions within these
topics, and conclude with a perspective and outlook that summarizes the
overarching challenges and their potential solutions as a guide for future
research.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17257" title="Abstract">arXiv:2309.17257</a> [<a href="/pdf/2309.17257" title="Download PDF">pdf</a>, <a href="/format/2309.17257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Deep Learning Techniques for Action Anticipation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zeyun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+M">Manuel Martin</a>, 
<a href="/search/cs?searchtype=author&query=Voit%2C+M">Michael Voit</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+J">Juergen Gall</a>, 
<a href="/search/cs?searchtype=author&query=Beyerer%2C+J">J&#xfc;rgen Beyerer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The ability to anticipate possible future human actions is essential for a
wide range of applications, including autonomous driving and human-robot
interaction. Consequently, numerous methods have been introduced for action
anticipation in recent years, with deep learning-based approaches being
particularly popular. In this work, we review the recent advances of action
anticipation algorithms with a particular focus on daily-living scenarios.
Additionally, we classify these methods according to their primary
contributions and summarize them in tabular form, allowing readers to grasp the
details at a glance. Furthermore, we delve into the common evaluation metrics
and datasets used for action anticipation and provide future directions with
systematical discussions.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17260" title="Abstract">arXiv:2309.17260</a> [<a href="/pdf/2309.17260" title="Download PDF">pdf</a>, <a href="/format/2309.17260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlaceNav: Topological Navigation through Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suomela%2C+L">Lauri Suomela</a>, 
<a href="/search/cs?searchtype=author&query=Kalliola%2C+J">Jussi Kalliola</a>, 
<a href="/search/cs?searchtype=author&query=Dag%2C+A">Atakan Dag</a>, 
<a href="/search/cs?searchtype=author&query=Edelman%2C+H">Harry Edelman</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4m%C3%A4r%C3%A4inen%2C+J">Joni-Kristian K&#xe4;m&#xe4;r&#xe4;inen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent results suggest that splitting topological navigation into
robot-independent and robot-specific components improves navigation performance
by enabling the robot-independent part to be trained with data collected by
different robot types. However, the navigation methods are still limited by the
scarcity of suitable training data and suffer from poor computational scaling.
In this work, we present~\methodname, subdividing the robot-independent part
into navigation-specific and generic computer vision components. We utilize
visual place recognition for the subgoal selection of the topological
navigation pipeline. This makes subgoal selection more efficient and enables
leveraging large-scale datasets from non-robotics sources, increasing training
data availability. Bayes filtering, enabled by place recognition, further
improves navigation performance by increasing the temporal consistency of
subgoals. Our experimental results verify the design and the new model obtains
a 76% higher success rate in indoor and 23% higher in outdoor navigation tasks
with higher computational efficiency.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17261" title="Abstract">arXiv:2309.17261</a> [<a href="/pdf/2309.17261" title="Download PDF">pdf</a>, <a href="/format/2309.17261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent123: One Image to Highly Consistent 3D Asset Using Case-Aware  Diffusion Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yukang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Haonan Han</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chaoqun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zunnan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yachao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing 3D objects from a single image guided by pretrained diffusion
models has demonstrated promising outcomes. However, due to utilizing the
case-agnostic rigid strategy, their generalization ability to arbitrary cases
and the 3D consistency of reconstruction are still poor. In this work, we
propose Consistent123, a case-aware two-stage method for highly consistent 3D
asset reconstruction from one image with both 2D and 3D diffusion priors. In
the first stage, Consistent123 utilizes only 3D structural priors for
sufficient geometry exploitation, with a CLIP-based case-aware adaptive
detection mechanism embedded within this process. In the second stage, 2D
texture priors are introduced and progressively take on a dominant guiding
role, delicately sculpting the details of the 3D model. Consistent123 aligns
more closely with the evolving trends in guidance requirements, adaptively
providing adequate 3D geometric initialization and suitable 2D texture
refinement for different objects. Consistent123 can obtain highly 3D-consistent
reconstruction and exhibits strong generalization ability across various
objects. Qualitative and quantitative experiments show that our method
significantly outperforms state-of-the-art image-to-3D methods. See
https://Consistent123.github.io for a more comprehensive exploration of our
generated 3D assets.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17264" title="Abstract">arXiv:2309.17264</a> [<a href="/pdf/2309.17264" title="Download PDF">pdf</a>, <a href="/format/2309.17264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Foundation Model for General Moving Object Segmentation in Medical  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhongnuo Yan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tong Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Han Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiongquan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenlong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+D">Dong Ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Medical image segmentation aims to delineate the anatomical or pathological
structures of interest, playing a crucial role in clinical diagnosis. A
substantial amount of high-quality annotated data is crucial for constructing
high-precision deep segmentation models. However, medical annotation is highly
cumbersome and time-consuming, especially for medical videos or 3D volumes, due
to the huge labeling space and poor inter-frame consistency. Recently, a
fundamental task named Moving Object Segmentation (MOS) has made significant
advancements in natural images. Its objective is to delineate moving objects
from the background within image sequences, requiring only minimal annotations.
In this paper, we propose the first foundation model, named iMOS, for MOS in
medical images. Extensive experiments on a large multi-modal medical dataset
validate the effectiveness of the proposed iMOS. Specifically, with the
annotation of only a small number of images in the sequence, iMOS can achieve
satisfactory tracking and segmentation performance of moving objects throughout
the entire sequence in bi-directions. We hope that the proposed iMOS can help
accelerate the annotation speed of experts, and boost the development of
medical foundation models.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17265" title="Abstract">arXiv:2309.17265</a> [<a href="/pdf/2309.17265" title="Download PDF">pdf</a>, <a href="/format/2309.17265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effect of structure-based training on 3D localization precision and  quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdehkakha%2C+A">Armin Abdehkakha</a>, 
<a href="/search/cs?searchtype=author&query=Snoeyink%2C+C">Craig Snoeyink</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This study introduces a structural-based training approach for CNN-based
algorithms in single-molecule localization microscopy (SMLM) and 3D object
reconstruction. We compare this approach with the traditional random-based
training method, utilizing the LUENN package as our AI pipeline. The
quantitative evaluation demonstrates significant improvements in detection rate
and localization precision with the structural-based training approach,
particularly in varying signal-to-noise ratios (SNRs). Moreover, the method
effectively removes checkerboard artifacts, ensuring more accurate 3D
reconstructions. Our findings highlight the potential of the structural-based
training approach to advance super-resolution microscopy and deepen our
understanding of complex biological systems at the nanoscale.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17266" title="Abstract">arXiv:2309.17266</a> [<a href="/pdf/2309.17266" title="Download PDF">pdf</a>, <a href="/format/2309.17266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refined and refined harmonic Jacobi--Davidson methods for computing  several GSVD components of a large regular matrix pair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+J">Jinzhi Huang</a>, 
<a href="/search/math?searchtype=author&query=Jia%2C+Z">Zhongxiao Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Three refined and refined harmonic extraction-based Jacobi--Davidson (JD)
type methods are proposed, and their thick-restart algorithms with deflation
and purgation are developed to compute several generalized singular value
decomposition (GSVD) components of a large regular matrix pair. The new methods
are called refined cross product-free (RCPF), refined cross product-free
harmonic (RCPF-harmonic) and refined inverse-free harmonic (RIF-harmonic)
JDGSVD algorithms, abbreviated as RCPF-JDGSVD, RCPF-HJDGSVD and RIF-HJDGSVD,
respectively. The new JDGSVD methods are more efficient than the corresponding
standard and harmonic extraction-based JDSVD methods proposed previously by the
authors, and can overcome the erratic behavior and intrinsic possible
non-convergence of the latter ones. Numerical experiments illustrate that
RCPF-JDGSVD performs better for the computation of extreme GSVD components
while RCPF-HJDGSVD and RIF-HJDGSVD suit better for that of interior GSVD
components.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17270" title="Abstract">arXiv:2309.17270</a> [<a href="/pdf/2309.17270" title="Download PDF">pdf</a>, <a href="/format/2309.17270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomly sparsified Richardson iteration is really fast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Weare%2C+J">Jonathan Weare</a>, 
<a href="/search/math?searchtype=author&query=Webber%2C+R+J">Robert J. Webber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Recently, a class of algorithms combining classical fixed point iterations
with repeated random sparsification of approximate solution vectors has been
successfully applied to eigenproblems with matrices as large as $10^{108}
\times 10^{108}$. So far, a complete mathematical explanation for their success
has proven elusive. Additionally, the methods have not been extended to linear
system solves.
<br />In this paper we propose a new scheme based on repeated random sparsification
that is capable of solving linear systems in extremely high dimensions. We
provide a complete mathematical analysis of this new algorithm. Our analysis
establishes a faster-than-Monte Carlo convergence rate and justifies use of the
scheme even when the solution vector itself is too large to store.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17272" title="Abstract">arXiv:2309.17272</a> [<a href="/pdf/2309.17272" title="Download PDF">pdf</a>, <a href="/format/2309.17272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Large Language Models in Coding Through Multi-Perspective  Self-Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Baizhou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shuai Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaojun Wan</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Large language models (LLMs) have exhibited remarkable ability in textual
generation. However, in complex reasoning tasks such as code generation,
generating the correct answer in a single attempt remains a formidable
challenge for LLMs. Previous research has explored solutions by aggregating
multiple outputs, leveraging the consistency among them. However, none of them
have comprehensively captured this consistency from different perspectives. In
this paper, we propose the Multi-Perspective Self-Consistency (MPSC) framework,
a novel decoding strategy for LLM that incorporates both inter-consistency
across outputs from multiple perspectives and intra-consistency within a single
perspective. Specifically, we ask LLMs to sample multiple diverse outputs from
various perspectives for a given query and then construct a multipartite graph
based on them. With two predefined measures of consistency, we embed both
inter- and intra-consistency information into the graph. The optimal choice is
then determined based on consistency analysis in the graph. We conduct
comprehensive evaluation on the code generation task by introducing solution,
specification and test case as three perspectives. We leverage a code
interpreter to quantitatively measure the inter-consistency and propose several
intra-consistency measure functions. Our MPSC framework significantly boosts
the performance on various popular benchmarks, including HumanEval (+17.60%),
HumanEval Plus (+17.61%), MBPP (+6.50%) and CodeContests (+11.82%) in Pass@1,
when compared to original outputs generated from ChatGPT, and even surpassing
GPT-4.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17275" title="Abstract">arXiv:2309.17275</a> [<a href="/pdf/2309.17275" title="Download PDF">pdf</a>, <a href="/format/2309.17275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utility-based Adaptive Teaching Strategies using Bayesian Theory of Mind
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grislain%2C+C">Cl&#xe9;mence Grislain</a>, 
<a href="/search/cs?searchtype=author&query=Caselles-Dupr%C3%A9%2C+H">Hugo Caselles-Dupr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Sigaud%2C+O">Olivier Sigaud</a>, 
<a href="/search/cs?searchtype=author&query=Chetouani%2C+M">Mohamed Chetouani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Good teachers always tailor their explanations to the learners. Cognitive
scientists model this process under the rationality principle: teachers try to
maximise the learner's utility while minimising teaching costs. To this end,
human teachers seem to build mental models of the learner's internal state, a
capacity known as Theory of Mind (ToM). Inspired by cognitive science, we build
on Bayesian ToM mechanisms to design teacher agents that, like humans, tailor
their teaching strategies to the learners. Our ToM-equipped teachers construct
models of learners' internal states from observations and leverage them to
select demonstrations that maximise the learners' rewards while minimising
teaching costs. Our experiments in simulated environments demonstrate that
learners taught this way are more efficient than those taught in a
learner-agnostic way. This effect gets stronger when the teacher's model of the
learner better aligns with the actual learner's state, either using a more
accurate prior or after accumulating observations of the learner's behaviour.
This work is a first step towards social machines that teach us and each other,
see https://teacher-with-tom.github.io.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17277" title="Abstract">arXiv:2309.17277</a> [<a href="/pdf/2309.17277" title="Download PDF">pdf</a>, <a href="/format/2309.17277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind  Aware GPT4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaxian Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+P">Paul Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Iwasawa%2C+Y">Yusuke Iwasawa</a>, 
<a href="/search/cs?searchtype=author&query=Matsuo%2C+Y">Yutaka Matsuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Unlike perfect information games, where all elements are known to every
player, imperfect information games emulate the real-world complexities of
decision-making under uncertain or incomplete information. GPT-4, the recent
breakthrough in large language models (LLMs) trained on massive passive data,
is notable for its knowledge retrieval and reasoning abilities. This paper
delves into the applicability of GPT-4's learned knowledge for imperfect
information games. To achieve this, we introduce \textbf{Suspicion-Agent}, an
innovative agent that leverages GPT-4's capabilities for performing in
imperfect information games. With proper prompt engineering to achieve
different functions, Suspicion-Agent based on GPT-4 demonstrates remarkable
adaptability across a range of imperfect information card games. Importantly,
GPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning it
can understand others and intentionally impact others' behavior. Leveraging
this, we design a planning strategy that enables GPT-4 to competently play
against different opponents, adapting its gameplay style as needed, while
requiring only the game rules and descriptions of observations as input. In the
experiments, we qualitatively showcase the capabilities of Suspicion-Agent
across three different imperfect information games and then quantitatively
evaluate it in Leduc Hold'em. The results show that Suspicion-Agent can
potentially outperform traditional algorithms designed for imperfect
information games, without any specialized training or examples. In order to
encourage and foster deeper insights within the community, we make our
game-related data publicly available.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17278" title="Abstract">arXiv:2309.17278</a> [<a href="/pdf/2309.17278" title="Download PDF">pdf</a>, <a href="/format/2309.17278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Robust Recommendation via Real-time Vicinal Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yichang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenwang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Recommender systems have been shown to be vulnerable to poisoning attacks,
where malicious data is injected into the dataset to cause the recommender
system to provide biased recommendations. To defend against such attacks,
various robust learning methods have been proposed. However, most methods are
model-specific or attack-specific, making them lack generality, while other
methods, such as adversarial training, are oriented towards evasion attacks and
thus have a weak defense strength in poisoning attacks.
<br />In this paper, we propose a general method, Real-time Vicinal Defense (RVD),
which leverages neighboring training data to fine-tune the model before making
a recommendation for each user. RVD works in the inference phase to ensure the
robustness of the specific sample in real-time, so there is no need to change
the model structure and training process, making it more practical. Extensive
experimental results demonstrate that RVD effectively mitigates targeted
poisoning attacks across various models without sacrificing accuracy. Moreover,
the defensive effect can be further amplified when our method is combined with
other strategies.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17280" title="Abstract">arXiv:2309.17280</a> [<a href="/pdf/2309.17280" title="Download PDF">pdf</a>, <a href="/format/2309.17280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STRONG -- Structure Controllable Legal Opinion Summary Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Litman%2C+D">Diane Litman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Findings of IJCNLP-AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose an approach for the structure controllable summarization of long
legal opinions that considers the argument structure of the document. Our
approach involves using predicted argument role information to guide the model
in generating coherent summaries that follow a provided structure pattern. We
demonstrate the effectiveness of our approach on a dataset of legal opinions
and show that it outperforms several strong baselines with respect to ROUGE,
BERTScore, and structure similarity.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17281" title="Abstract">arXiv:2309.17281</a> [<a href="/pdf/2309.17281" title="Download PDF">pdf</a>, <a href="/format/2309.17281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Flow in Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhiquan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingqin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weiran Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we provide a comprehensive toolbox for understanding and
enhancing self-supervised learning (SSL) methods through the lens of matrix
information theory. Specifically, by leveraging the principles of matrix mutual
information and joint entropy, we offer a unified analysis for both contrastive
and feature decorrelation based methods. Furthermore, we propose the matrix
variational masked auto-encoder (M-MAE) method, grounded in matrix information
theory, as an enhancement to masked image modeling. The empirical evaluations
underscore the effectiveness of M-MAE compared with the state-of-the-art
methods, including a 3.9% improvement in linear probing ViT-Base, and a 1%
improvement in fine-tuning ViT-Large, both on ImageNet.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17284" title="Abstract">arXiv:2309.17284</a> [<a href="/pdf/2309.17284" title="Download PDF">pdf</a>, <a href="/format/2309.17284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Computation of Basic Reproduction Numbers in  Networked Epidemic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+B">Baike She</a>, 
<a href="/search/cs?searchtype=author&query=Hawkins%2C+C">Calvin Hawkins</a>, 
<a href="/search/cs?searchtype=author&query=Benvenuti%2C+A">Alex Benvenuti</a>, 
<a href="/search/cs?searchtype=author&query=Fallin%2C+B">Brandon Fallin</a>, 
<a href="/search/cs?searchtype=author&query=Par%C3%A9%2C+P+E">Philip E. Par&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Hale%2C+M">Matthew Hale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Cryptography and Security (cs.CR); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The basic reproduction number of a networked epidemic model, denoted $R_0$,
can be computed from a network's topology to quantify epidemic spread. However,
disclosure of $R_0$ risks revealing sensitive information about the underlying
network, such as an individual's relationships within a social network.
Therefore, we propose a framework to compute and release $R_0$ in a
differentially private way. First, we provide a new result that shows how $R_0$
can be used to bound the level of penetration of an epidemic within a single
community as a motivation for the need of privacy, which may also be of
independent interest. We next develop a privacy mechanism to formally safeguard
the edge weights in the underlying network when computing $R_0$. Then we
formalize tradeoffs between the level of privacy and the accuracy of values of
the privatized $R_0$. To show the utility of the private $R_0$ in practice, we
use it to bound this level of penetration under privacy, and concentration
bounds on these analyses show they remain accurate with privacy implemented. We
apply our results to real travel data gathered during the spread of COVID-19,
and we show that, under real-world conditions, we can compute $R_0$ in a
differentially private way while incurring errors as low as $7.6\%$ on average.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17285" title="Abstract">arXiv:2309.17285</a> [<a href="/pdf/2309.17285" title="Download PDF">pdf</a>, <a href="/format/2309.17285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Large Scale Medical Image Dataset Preparation for Machine  Learning Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Denner%2C+S">Stefan Denner</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+J">Jonas Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Kades%2C+K">Klaus Kades</a>, 
<a href="/search/cs?searchtype=author&query=Bounias%2C+D">Dimitrios Bounias</a>, 
<a href="/search/cs?searchtype=author&query=Schader%2C+P">Philipp Schader</a>, 
<a href="/search/cs?searchtype=author&query=Kausch%2C+L">Lisa Kausch</a>, 
<a href="/search/cs?searchtype=author&query=Bujotzek%2C+M">Markus Bujotzek</a>, 
<a href="/search/cs?searchtype=author&query=Bucher%2C+A+M">Andreas Michael Bucher</a>, 
<a href="/search/cs?searchtype=author&query=Penzkofer%2C+T">Tobias Penzkofer</a>, 
<a href="/search/cs?searchtype=author&query=Maier-Hein%2C+K">Klaus Maier-Hein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the rapidly evolving field of medical imaging, machine learning algorithms
have become indispensable for enhancing diagnostic accuracy. However, the
effectiveness of these algorithms is contingent upon the availability and
organization of high-quality medical imaging datasets. Traditional Digital
Imaging and Communications in Medicine (DICOM) data management systems are
inadequate for handling the scale and complexity of data required to be
facilitated in machine learning algorithms. This paper introduces an innovative
data curation tool, developed as part of the Kaapana open-source toolkit, aimed
at streamlining the organization, management, and processing of large-scale
medical imaging datasets. The tool is specifically tailored to meet the needs
of radiologists and machine learning researchers. It incorporates advanced
search, auto-annotation and efficient tagging functionalities for improved data
curation. Additionally, the tool facilitates quality control and review,
enabling researchers to validate image and segmentation quality in large
datasets. It also plays a critical role in uncovering potential biases in
datasets by aggregating and visualizing metadata, which is essential for
developing robust machine learning models. Furthermore, Kaapana is integrated
within the Radiological Cooperative Network (RACOON), a pioneering initiative
aimed at creating a comprehensive national infrastructure for the aggregation,
transmission, and consolidation of radiological data across all university
clinics throughout Germany. A supplementary video showcasing the tool's
functionalities can be accessed at https://bit.ly/MICCAI-DEMI2023.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17288" title="Abstract">arXiv:2309.17288</a> [<a href="/pdf/2309.17288" title="Download PDF">pdf</a>, <a href="/format/2309.17288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoAgents: A Framework for Automatic Agent Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Siwei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yu Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sesay%2C+J">Jaward Sesay</a>, 
<a href="/search/cs?searchtype=author&query=Karlsson%2C+B+F">B&#xf6;rje F. Karlsson</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yemin Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large language models (LLMs) have enabled remarkable advances in automated
task-solving with multi-agent systems. However, most existing LLM-based
multi-agent approaches rely on predefined agents to handle simple tasks,
limiting the adaptability of multi-agent collaboration to different scenarios.
Therefore, we introduce AutoAgents, an innovative framework that adaptively
generates and coordinates multiple specialized agents to build an AI team
according to different tasks. Specifically, AutoAgents couples the relationship
between tasks and roles by dynamically generating multiple required agents
based on task content and planning solutions for the current task based on the
generated expert agents. Multiple specialized agents collaborate with each
other to efficiently accomplish tasks. Concurrently, an observer role is
incorporated into the framework to reflect on the designated plans and agents'
responses and improve upon them. Our experiments on various benchmarks
demonstrate that AutoAgents generates more coherent and accurate solutions than
the existing multi-agent methods. This underscores the significance of
assigning different roles to different tasks and of team cooperation, offering
new perspectives for tackling complex tasks. The repository of this project is
available at https://github.com/LinkSoul-AI/AutoAgents.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17296" title="Abstract">arXiv:2309.17296</a> [<a href="/pdf/2309.17296" title="Download PDF">pdf</a>, <a href="/format/2309.17296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Design Space of Equivariant Diffusion-Based Generative  Models for De Novo 3D Molecule Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Tuan Le</a>, 
<a href="/search/cs?searchtype=author&query=Cremer%2C+J">Julian Cremer</a>, 
<a href="/search/cs?searchtype=author&query=No%C3%A9%2C+F">Frank No&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Clevert%2C+D">Djork-Arn&#xe9; Clevert</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtt%2C+K">Kristof Sch&#xfc;tt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep generative diffusion models are a promising avenue for de novo 3D
molecular design in material science and drug discovery. However, their utility
is still constrained by suboptimal performance with large molecular structures
and limited training data. Addressing this gap, we explore the design space of
E(3) equivariant diffusion models, focusing on previously blank spots. Our
extensive comparative analysis evaluates the interplay between continuous and
discrete state spaces. Out of this investigation, we introduce the EQGAT-diff
model, which consistently surpasses the performance of established models on
the QM9 and GEOM-Drugs datasets by a large margin. Distinctively, EQGAT-diff
takes continuous atomic positions while chemical elements and bond types are
categorical and employ a time-dependent loss weighting that significantly
increases training convergence and the quality of generated samples. To further
strengthen the applicability of diffusion models to limited training data, we
examine the transferability of EQGAT-diff trained on the large PubChem3D
dataset with implicit hydrogens to target distributions with explicit
hydrogens. Fine-tuning EQGAT-diff for a couple of iterations further pushes
state-of-the-art performance across datasets. We envision that our findings
will find applications in structure-based drug design, where the accuracy of
generative models for small datasets of complex molecules is critical.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17301" title="Abstract">arXiv:2309.17301</a> [<a href="/pdf/2309.17301" title="Download PDF">pdf</a>, <a href="/format/2309.17301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Resilient Control of DC Microgrids Under Generally Unbounded  FDI Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yichao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Rajabinezhad%2C+M">Mohamadamin Rajabinezhad</a>, 
<a href="/search/eess?searchtype=author&query=Beg%2C+O+A">Omar A. Beg</a>, 
<a href="/search/eess?searchtype=author&query=Zuo%2C+S">Shan Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Due to the nature of distributed secondary control paradigm, DC microgrids
are prone to malicious cyber-physical attacks, which could be unbounded to
maximize their damage. Existing resilient secondary control methods addressing
unbounded attacks require that the first time derivatives of cyber-physical
attack signals be bounded. The secondary defense strategy presented in this
letter relax such a strict constraint by addressing more generally unbounded
attack signals and hence, enhance the resilience of DC microgrids in
adversarial environments. Rigorous proofs, based on Lyapunov techniques, show
that the proposed method guarantees the uniformly ultimately bounded
convergence for both voltage regulation and proportional load sharing under
generally unbounded attacks. Comparative case studies further validate the
enhanced resilience of the proposed attack-resilient control strategy.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17307" title="Abstract">arXiv:2309.17307</a> [<a href="/pdf/2309.17307" title="Download PDF">pdf</a>, <a href="/ps/2309.17307" title="Download PostScript">ps</a>, <a href="/format/2309.17307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Min-Max MPC for Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+Y">Yifan Xie</a>, 
<a href="/search/eess?searchtype=author&query=Berberich%2C+J">Julian Berberich</a>, 
<a href="/search/eess?searchtype=author&query=Allgower%2C+F">Frank Allgower</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Designing data-driven controllers in the presence of noise is an important
research problem, in particular when guarantees on stability, robustness, and
constraint satisfaction are desired. In this paper, we propose a data-driven
min-max model predictive control (MPC) scheme to design state-feedback
controllers from noisy data for unknown linear time-invariant (LTI) system. The
considered min-max problem minimizes the worst-case cost over the set of system
matrices consistent with the data. We show that the resulting optimization
problem can be reformulated as a semidefinite program (SDP). By solving the
SDP, we obtain a state-feedback control law that stabilizes the closed-loop
system and guarantees input and state constraint satisfaction. A numerical
example demonstrates the validity of our theoretical results.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17310" title="Abstract">arXiv:2309.17310</a> [<a href="/pdf/2309.17310" title="Download PDF">pdf</a>, <a href="/format/2309.17310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leave-one-out Distinguishability in Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiayuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Borovykh%2C+A">Anastasia Borovykh</a>, 
<a href="/search/cs?searchtype=author&query=Hayou%2C+S">Soufiane Hayou</a>, 
<a href="/search/cs?searchtype=author&query=Shokri%2C+R">Reza Shokri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce a new analytical framework to quantify the changes in a machine
learning algorithm's output distribution following the inclusion of a few data
points in its training set, a notion we define as leave-one-out
distinguishability (LOOD). This problem is key to measuring data
**memorization** and **information leakage** in machine learning, and the
**influence** of training data points on model predictions. We illustrate how
our method broadens and refines existing empirical measures of memorization and
privacy risks associated with training data. We use Gaussian processes to model
the randomness of machine learning algorithms, and validate LOOD with extensive
empirical analysis of information leakage using membership inference attacks.
Our theoretical framework enables us to investigate the causes of information
leakage and where the leakage is high. For example, we analyze the influence of
activation functions, on data memorization. Additionally, our method allows us
to optimize queries that disclose the most significant information about the
training data in the leave-one-out setting. We illustrate how optimal queries
can be used for accurate **reconstruction** of training data.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17313" title="Abstract">arXiv:2309.17313</a> [<a href="/pdf/2309.17313" title="Download PDF">pdf</a>, <a href="/format/2309.17313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Domain Adaptation for Charge Prediction on Unprofessional  Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Ziyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofei He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent works considering professional legal-linguistic style (PLLS) texts
have shown promising results on the charge prediction task. However,
unprofessional users also show an increasing demand on such a prediction
service. There is a clear domain discrepancy between PLLS texts and non-PLLS
texts expressed by those laypersons, which degrades the current SOTA models'
performance on non-PLLS texts. A key challenge is the scarcity of non-PLLS data
for most charge classes. This paper proposes a novel few-shot domain adaptation
(FSDA) method named Disentangled Legal Content for Charge Prediction (DLCCP).
Compared with existing FSDA works, which solely perform instance-level
alignment without considering the negative impact of text style information
existing in latent features, DLCCP (1) disentangles the content and style
representations for better domain-invariant legal content learning with
carefully designed optimization goals for content and style spaces and, (2)
employs the constitutive elements knowledge of charges to extract and align
element-level and instance-level content representations simultaneously. We
contribute the first publicly available non-PLLS dataset named NCCP for
developing layperson-friendly charge prediction models. Experiments on NCCP
show the superiority of our methods over competitive baselines.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17315" title="Abstract">arXiv:2309.17315</a> [<a href="/pdf/2309.17315" title="Download PDF">pdf</a>, <a href="/format/2309.17315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Newton Raphson Controller Based on Koopman Operator Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+M">Mi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Newton-Raphson controller is a powerful prediction-based variable gain
integral controller. Basically, the classical model-based Newton-Raphson
controller requires two elements: the prediction of the system output and the
derivative of the predicted output with respect to the control input. In real
applications, the model may not be known and it is infeasible to predict the
system sometime ahead and calculate the derivative by finite difference method
as done in simulation. To solve these problems, in this work, we utilize the
Koopman operator framework to reconstruct a linear model of the original
nonlinear dynamical system and then utilize the output of the new linear system
as the predictor of the Newton-Raphson controller. This method is only based on
collected data within some time instant thus more practical. Three examples
related to highly nonlinear systems are provided to verify the effectiveness of
our proposed method.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17318" title="Abstract">arXiv:2309.17318</a> [<a href="/html/2309.17318" title="Download HTML">html</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the Fourteenth International Symposium on Games,  Automata, Logics, and Formal Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Achilleos%2C+A">Antonis Achilleos</a> (Reykjavik University), 
<a href="/search/cs?searchtype=author&query=Della+Monica%2C+D">Dario Della Monica</a> (University of Udine)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 390, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Computational Complexity (cs.CC); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">This volume contains the proceedings of the 14th International Symposium on
Games, Automata, Logics, and Formal Verification (GandALF 2023). The aim of
GandALF 2023 symposium is to bring together researchers from academia and
industry who are actively working in the fields of Games, Automata, Logics, and
Formal Verification. The idea is to cover an ample spectrum of themes, ranging
from theory to applications, and stimulate cross-fertilization.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17319" title="Abstract">arXiv:2309.17319</a> [<a href="/pdf/2309.17319" title="Download PDF">pdf</a>, <a href="/format/2309.17319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Privacy-Preserving and Secure Geospatial Artificial  Intelligence Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+J">Jinmeng Rao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Song Gao</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+G">Gengchen Mai</a>, 
<a href="/search/cs?searchtype=author&query=Janowicz%2C+K">Krzysztof Janowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1 figure
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM SIGSPATIAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In recent years we have seen substantial advances in foundation models for
artificial intelligence, including language, vision, and multimodal models.
Recent studies have highlighted the potential of using foundation models in
geospatial artificial intelligence, known as GeoAI Foundation Models or
Geo-Foundation Models, for geographic question answering, remote sensing image
understanding, map generation, and location-based services, among others.
However, the development and application of GeoAI foundation models can pose
serious privacy and security risks, which have not been fully discussed or
addressed to date. This paper introduces the potential privacy and security
risks throughout the lifecycle of GeoAI foundation models and proposes a
comprehensive blueprint for preventative and control strategies. Through this
vision paper, we hope to draw the attention of researchers and policymakers in
geospatial domains to these privacy and security risks inherent in GeoAI
foundation models and advocate for the development of privacy-preserving and
secure GeoAI foundation models.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17321" title="Abstract">arXiv:2309.17321</a> [<a href="/pdf/2309.17321" title="Download PDF">pdf</a>, <a href="/ps/2309.17321" title="Download PostScript">ps</a>, <a href="/format/2309.17321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STARS for Integrated Sensing and Communications: Challenges, Solutions,  and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xidong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This article discusses the employment of simultaneously transmitting and
reflecting surface (STARS) for integrated sensing and communication (ISAC)
networks. First, two fundamental configurations of STARS-enabled ISAC systems
are introduced, namely integrated full-space configuration and separated
half-space configuration, as well as their respective advantages and common
challenges are identified. To address the aforementioned challenges, a novel
sensing-at-STARS design is proposed, where the sensing functionality is
achieved at the STARS instead of at the base station. Such a design
significantly improves the echo signal energy by eliminating undesired echo
energy attenuation/leakage, in addition to establishing favorable echo
propagation paths to facilitate sensing information extraction. We also present
three practical implementations for sensing-at-STARS, including separated
elements, mode-selection elements, and power-splitting elements. Each
implementation enables flexible sensing-communication tradeoffs. Numerical
results are provided to demonstrate the superiority of the proposed
STARS-enabled ISAC design. Finally, we discuss several future research
directions.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17327" title="Abstract">arXiv:2309.17327</a> [<a href="/pdf/2309.17327" title="Download PDF">pdf</a>, <a href="/format/2309.17327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Telling Stories for Common Sense Zero-Shot Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gowda%2C+S+N">Shreyank N Gowda</a>, 
<a href="/search/cs?searchtype=author&query=Sevilla-Lara%2C+L">Laura Sevilla-Lara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video understanding has long suffered from reliance on large labeled
datasets, motivating research into zero-shot learning. Recent progress in
language modeling presents opportunities to advance zero-shot video analysis,
but constructing an effective semantic space relating action classes remains
challenging. We address this by introducing a novel dataset, Stories, which
contains rich textual descriptions for diverse action classes extracted from
WikiHow articles. For each class, we extract multi-sentence narratives
detailing the necessary steps, scenes, objects, and verbs that characterize the
action. This contextual data enables modeling of nuanced relationships between
actions, paving the way for zero-shot transfer. We also propose an approach
that harnesses Stories to improve feature generation for training zero-shot
classification. Without any target dataset fine-tuning, our method achieves new
state-of-the-art on multiple benchmarks, improving top-1 accuracy by up to
6.1%. We believe Stories provides a valuable resource that can catalyze
progress in zero-shot action recognition. The textual narratives forge
connections between seen and unseen classes, overcoming the bottleneck of
labeled data that has long impeded advancements in this exciting domain. The
data can be found here: https://github.com/kini5gowda/Stories .
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17329" title="Abstract">arXiv:2309.17329</a> [<a href="/pdf/2309.17329" title="Download PDF">pdf</a>, <a href="/format/2309.17329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Anatomical labeling of Pulmonary Tree Structures via Implicit  Point-Graph Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+K">Kangxian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiancheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Donglai Wei</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+Z">Ziqiao Weng</a>, 
<a href="/search/cs?searchtype=author&query=Fua%2C+P">Pascal Fua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Pulmonary diseases rank prominently among the principal causes of death
worldwide. Curing them will require, among other things, a better understanding
of the many complex 3D tree-shaped structures within the pulmonary system, such
as airways, arteries, and veins. In theory, they can be modeled using
high-resolution image stacks. Unfortunately, standard CNN approaches operating
on dense voxel grids are prohibitively expensive. To remedy this, we introduce
a point-based approach that preserves graph connectivity of tree skeleton and
incorporates an implicit surface representation. It delivers SOTA accuracy at a
low computational cost and the resulting models have usable surfaces. Due to
the scarcity of publicly accessible data, we have also curated an extensive
dataset to evaluate our approach and will make it public.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17330" title="Abstract">arXiv:2309.17330</a> [<a href="/pdf/2309.17330" title="Download PDF">pdf</a>, <a href="/ps/2309.17330" title="Download PostScript">ps</a>, <a href="/format/2309.17330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Bounds on Private Graph Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingcheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+J">Jalaj Upadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zongrui Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We propose an efficient $\epsilon$-differentially private algorithm, that
given a simple {\em weighted} $n$-vertex, $m$-edge graph $G$ with a
\emph{maximum unweighted} degree $\Delta(G) \leq n-1$, outputs a synthetic
graph which approximates the spectrum with $\widetilde{O}(\min\{\Delta(G),
\sqrt{n}\})$ bound on the purely additive error. To the best of our knowledge,
this is the first $\epsilon$-differentially private algorithm with a
non-trivial additive error for approximating the spectrum of the graph. One of
the subroutines of our algorithm also precisely simulates the exponential
mechanism over a non-convex set, which could be of independent interest given
the recent interest in sampling from a {\em log-concave distribution} defined
over a convex set. Spectral approximation also allows us to approximate all
possible $(S,T)$-cuts, but it incurs an error that depends on the maximum
degree, $\Delta(G)$. We further show that using our sampler, we can also output
a synthetic graph that approximates the sizes of all $(S,T)$-cuts on $n$
vertices weighted graph $G$ with $m$ edges while preserving
$(\epsilon,\delta)$-differential privacy and an additive error of
$\widetilde{O}(\sqrt{mn}/\epsilon)$. We also give a matching lower bound (with
respect to all the parameters) on the private cut approximation for weighted
graphs. This removes the gap of $\sqrt{W_{\mathsf{avg}}}$ in the upper and
lower bound in Eli{\'a}{\v{s}}, Kapralov, Kulkarni, and Lee (SODA 2020), where
$W_{\mathsf{avg}}$ is the average edge weight.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17332" title="Abstract">arXiv:2309.17332</a> [<a href="/pdf/2309.17332" title="Download PDF">pdf</a>, <a href="/format/2309.17332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of the BioLaySumm 2023 Shared Task on Lay Summarization of  Biomedical Research Articles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldsack%2C+T">Tomsa Goldsack</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zheheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qianqian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Scarton%2C+C">Carolina Scarton</a>, 
<a href="/search/cs?searchtype=author&query=Shardlow%2C+M">Matthew Shardlow</a>, 
<a href="/search/cs?searchtype=author&query=Ananiadou%2C+S">Sophia Ananiadou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at BioNLP@ACL2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 22nd Workshop on Biomedical Natural Language Processing and
  BioNLP Shared Tasks (2023) 468-477
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents the results of the shared task on Lay Summarisation of
Biomedical Research Articles (BioLaySumm), hosted at the BioNLP Workshop at ACL
2023. The goal of this shared task is to develop abstractive summarisation
models capable of generating "lay summaries" (i.e., summaries that are
comprehensible to non-technical audiences) in both a controllable and
non-controllable setting. There are two subtasks: 1) Lay Summarisation, where
the goal is for participants to build models for lay summary generation only,
given the full article text and the corresponding abstract as input; and 2)
Readability-controlled Summarisation, where the goal is for participants to
train models to generate both the technical abstract and the lay summary, given
an article's main text as input. In addition to overall results, we report on
the setup and insights from the BioLaySumm shared task, which attracted a total
of 20 participating teams across both subtasks.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17335" title="Abstract">arXiv:2309.17335</a> [<a href="/pdf/2309.17335" title="Download PDF">pdf</a>, <a href="/format/2309.17335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Graph Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ley%2C+C+P">Christopher P. Ley</a>, 
<a href="/search/cs?searchtype=author&query=Tobar%2C+F">Felipe Tobar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce the asynchronous graph generator (AGG), a novel graph neural
network architecture for multi-channel time series which models observations as
nodes on a dynamic graph and can thus perform data imputation by transductive
node generation. Completely free from recurrent components or assumptions about
temporal regularity, AGG represents measurements, timestamps and metadata
directly in the nodes via learnable embeddings, to then leverage attention to
learn expressive relationships across the variables of interest. This way, the
proposed architecture implicitly learns a causal graph representation of sensor
measurements which can be conditioned on unseen timestamps and metadata to
predict new measurements by an expansion of the learnt graph. The proposed AGG
is compared both conceptually and empirically to previous work, and the impact
of data augmentation on the performance of AGG is also briefly discussed. Our
experiments reveal that AGG achieved state-of-the-art results in time series
data imputation, classification and prediction for the benchmark datasets
Beijing Air Quality, PhysioNet Challenge 2012 and UCI localisation.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17336" title="Abstract">arXiv:2309.17336</a> [<a href="/pdf/2309.17336" title="Download PDF">pdf</a>, <a href="/format/2309.17336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> See Beyond Seeing: Robust 3D Object Detection from Point Clouds via  Cross-Modal Hallucination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jianning Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+G">Gabriel Chan</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Hantao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C+X">Chris Xiaoxuan Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper presents a novel framework for robust 3D object detection from
point clouds via cross-modal hallucination. Our proposed approach is agnostic
to either hallucination direction between LiDAR and 4D radar. We introduce
multiple alignments on both spatial and feature levels to achieve simultaneous
backbone refinement and hallucination generation. Specifically, spatial
alignment is proposed to deal with the geometry discrepancy for better instance
matching between LiDAR and radar. The feature alignment step further bridges
the intrinsic attribute gap between the sensing modalities and stabilizes the
training. The trained object detection models can deal with difficult detection
cases better, even though only single-modal data is used as the input during
the inference stage. Extensive experiments on the View-of-Delft (VoD) dataset
show that our proposed method outperforms the state-of-the-art (SOTA) methods
for both radar and LiDAR object detection while maintaining competitive
efficiency in runtime.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17337" title="Abstract">arXiv:2309.17337</a> [<a href="/pdf/2309.17337" title="Download PDF">pdf</a>, <a href="/format/2309.17337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Operationalizing Pipeline-aware ML Fairness: A Research Agenda  for Developing Practical Guidelines and Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Black%2C+E">Emily Black</a>, 
<a href="/search/cs?searchtype=author&query=Naidu%2C+R">Rakshit Naidu</a>, 
<a href="/search/cs?searchtype=author&query=Ghani%2C+R">Rayid Ghani</a>, 
<a href="/search/cs?searchtype=author&query=Rodolfa%2C+K+T">Kit T. Rodolfa</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+D+E">Daniel E. Ho</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+H">Hoda Heidari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EAAMO'23 (Archival)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">While algorithmic fairness is a thriving area of research, in practice,
mitigating issues of bias often gets reduced to enforcing an arbitrarily chosen
fairness metric, either by enforcing fairness constraints during the
optimization step, post-processing model outputs, or by manipulating the
training data. Recent work has called on the ML community to take a more
holistic approach to tackle fairness issues by systematically investigating the
many design choices made through the ML pipeline, and identifying interventions
that target the issue's root cause, as opposed to its symptoms. While we share
the conviction that this pipeline-based approach is the most appropriate for
combating algorithmic unfairness on the ground, we believe there are currently
very few methods of \emph{operationalizing} this approach in practice. Drawing
on our experience as educators and practitioners, we first demonstrate that
without clear guidelines and toolkits, even individuals with specialized ML
knowledge find it challenging to hypothesize how various design choices
influence model behavior. We then consult the fair-ML literature to understand
the progress to date toward operationalizing the pipeline-aware approach: we
systematically collect and organize the prior work that attempts to detect,
measure, and mitigate various sources of unfairness through the ML pipeline. We
utilize this extensive categorization of previous contributions to sketch a
research agenda for the community. We hope this work serves as the stepping
stone toward a more comprehensive set of resources for ML researchers,
practitioners, and students interested in exploring, designing, and testing
pipeline-oriented approaches to algorithmic fairness.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17338" title="Abstract">arXiv:2309.17338</a> [<a href="/pdf/2309.17338" title="Download PDF">pdf</a>, <a href="/format/2309.17338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Trajectory Prediction in Dynamic Multi-Agent Environment by  Dropping Waypoints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chib%2C+P+S">Pranav Singh Chib</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Pravendra Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The inherently diverse and uncertain nature of trajectories presents a
formidable challenge in accurately modeling them. Motion prediction systems
must effectively learn spatial and temporal information from the past to
forecast the future trajectories of the agent. Many existing methods learn
temporal motion via separate components within stacked models to capture
temporal features. This paper introduces a novel framework, called Temporal
Waypoint Dropping (TWD), that promotes explicit temporal learning through the
waypoint dropping technique. Learning through waypoint dropping can compel the
model to improve its understanding of temporal correlations among agents, thus
leading to a significant enhancement in trajectory prediction. Trajectory
prediction methods often operate under the assumption that observed trajectory
waypoint sequences are complete, disregarding real-world scenarios where
missing values may occur, which can influence their performance. Moreover,
these models frequently exhibit a bias towards particular waypoint sequences
when making predictions. Our TWD is capable of effectively addressing these
issues. It incorporates stochastic and fixed processes that regularize
projected past trajectories by strategically dropping waypoints based on
temporal sequences. Through extensive experiments, we demonstrate the
effectiveness of TWD in forcing the model to learn complex temporal
correlations among agents. Our approach can complement existing trajectory
prediction methods to enhance prediction accuracy. We also evaluate our
proposed method across three datasets: NBA Sports VU, ETH-UCY, and TrajNet++.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17339" title="Abstract">arXiv:2309.17339</a> [<a href="/pdf/2309.17339" title="Download PDF">pdf</a>, <a href="/format/2309.17339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Experiments in Self-Supervised Cross-Table Representation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schambach%2C+M">Maximilian Schambach</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+D">Dominique Paul</a>, 
<a href="/search/cs?searchtype=author&query=Otterbach%2C+J+S">Johannes S. Otterbach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">To analyze the scaling potential of deep tabular representation learning
models, we introduce a novel Transformer-based architecture specifically
tailored to tabular data and cross-table representation learning by utilizing
table-specific tokenizers and a shared Transformer backbone. Our training
approach encompasses both single-table and cross-table models, trained via
missing value imputation through a self-supervised masked cell recovery
objective. To understand the scaling behavior of our method, we train models of
varying sizes, ranging from approximately $10^4$ to $10^7$ parameters. These
models are trained on a carefully curated pretraining dataset, consisting of
135M training tokens sourced from 76 diverse datasets. We assess the scaling of
our architecture in both single-table and cross-table pretraining setups by
evaluating the pretrained models using linear probing on a curated set of
benchmark datasets and comparing the results with conventional baselines.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17340" title="Abstract">arXiv:2309.17340</a> [<a href="/pdf/2309.17340" title="Download PDF">pdf</a>, <a href="/format/2309.17340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outage-Watch: Early Prediction of Outages using Extreme Event  Regularizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Shubham Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Sarthak Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Shaddy Garg</a>, 
<a href="/search/cs?searchtype=author&query=Bisht%2C+S">Sumit Bisht</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+C">Chahat Jain</a>, 
<a href="/search/cs?searchtype=author&query=Gonuguntla%2C+A">Ashritha Gonuguntla</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+S">Shiv Saini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ESEC/FSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cloud services are omnipresent and critical cloud service failure is a fact
of life. In order to retain customers and prevent revenue loss, it is important
to provide high reliability guarantees for these services. One way to do this
is by predicting outages in advance, which can help in reducing the severity as
well as time to recovery. It is difficult to forecast critical failures due to
the rarity of these events. Moreover, critical failures are ill-defined in
terms of observable data. Our proposed method, Outage-Watch, defines critical
service outages as deteriorations in the Quality of Service (QoS) captured by a
set of metrics. Outage-Watch detects such outages in advance by using current
system state to predict whether the QoS metrics will cross a threshold and
initiate an extreme event. A mixture of Gaussian is used to model the
distribution of the QoS metrics for flexibility and an extreme event
regularizer helps in improving learning in tail of the distribution. An outage
is predicted if the probability of any one of the QoS metrics crossing
threshold changes significantly. Our evaluation on a real-world SaaS company
dataset shows that Outage-Watch significantly outperforms traditional methods
with an average AUC of 0.98. Additionally, Outage-Watch detects all the outages
exhibiting a change in service metrics and reduces the Mean Time To Detection
(MTTD) of outages by up to 88% when deployed in an enterprise cloud-service
system, demonstrating efficacy of our proposed method.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17341" title="Abstract">arXiv:2309.17341</a> [<a href="/pdf/2309.17341" title="Download PDF">pdf</a>, <a href="/ps/2309.17341" title="Download PostScript">ps</a>, <a href="/format/2309.17341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixQuant: Mixed Precision Quantization with a Bit-width Optimization  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kloberdanz%2C+E">Eliska Kloberdanz</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+W">Wei Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Quantization is a technique for creating efficient Deep Neural Networks
(DNNs), which involves performing computations and storing tensors at lower
bit-widths than f32 floating point precision. Quantization reduces model size
and inference latency, and therefore allows for DNNs to be deployed on
platforms with constrained computational resources and real-time systems.
However, quantization can lead to numerical instability caused by roundoff
error which leads to inaccurate computations and therefore, a decrease in
quantized model accuracy. Similarly to prior works, which have shown that both
biases and activations are more sensitive to quantization and are best kept in
full precision or quantized with higher bit-widths, we show that some weights
are more sensitive than others which should be reflected on their quantization
bit-width. To that end we propose MixQuant, a search algorithm that finds the
optimal custom quantization bit-width for each layer weight based on roundoff
error and can be combined with any quantization method as a form of
pre-processing optimization. We show that combining MixQuant with BRECQ, a
state-of-the-art quantization method, yields better quantized model accuracy
than BRECQ alone. Additionally, we combine MixQuant with vanilla asymmetric
quantization to show that MixQuant has the potential to optimize the
performance of any quantization technique.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17342" title="Abstract">arXiv:2309.17342</a> [<a href="/pdf/2309.17342" title="Download PDF">pdf</a>, <a href="/format/2309.17342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Free Data Selection with General-Purpose Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yichen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wei Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A desirable data selection algorithm can efficiently choose the most
informative samples to maximize the utility of limited annotation budgets.
However, current approaches, represented by active learning methods, typically
follow a cumbersome pipeline that iterates the time-consuming model training
and batch data selection repeatedly. In this paper, we challenge this status
quo by designing a distinct data selection pipeline that utilizes existing
general-purpose models to select data from various datasets with a single-pass
inference without the need for additional training or supervision. A novel free
data selection (FreeSel) method is proposed following this new pipeline.
Specifically, we define semantic patterns extracted from inter-mediate features
of the general-purpose model to capture subtle local information in each image.
We then enable the selection of all data samples in a single pass through
distance-based sampling at the fine-grained semantic pattern level. FreeSel
bypasses the heavy batch selection process, achieving a significant improvement
in efficiency and being 530x faster than existing active learning methods.
Extensive experiments verify the effectiveness of FreeSel on various computer
vision tasks. Our code is available at https://github.com/yichen928/FreeSel.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17347" title="Abstract">arXiv:2309.17347</a> [<a href="/pdf/2309.17347" title="Download PDF">pdf</a>, <a href="/format/2309.17347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demographic Parity: Mitigating Biases in Real-World Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loukas%2C+O">Orestis Loukas</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H">Ho-Ryun Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 16 Figures, Python code attached
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Computer-based decision systems are widely used to automate decisions in many
aspects of everyday life, which include sensitive areas like hiring, loaning
and even criminal sentencing. A decision pipeline heavily relies on large
volumes of historical real-world data for training its models. However,
historical training data often contains gender, racial or other biases which
are propagated to the trained models influencing computer-based decisions. In
this work, we propose a robust methodology that guarantees the removal of
unwanted biases while maximally preserving classification utility. Our approach
can always achieve this in a model-independent way by deriving from real-world
data the asymptotic dataset that uniquely encodes demographic parity and
realism. As a proof-of-principle, we deduce from public census records such an
asymptotic dataset from which synthetic samples can be generated to train
well-established classifiers. Benchmarking the generalization capability of
these classifiers trained on our synthetic data, we confirm the absence of any
explicit or implicit bias in the computer-aided decision.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17348" title="Abstract">arXiv:2309.17348</a> [<a href="/pdf/2309.17348" title="Download PDF">pdf</a>, <a href="/format/2309.17348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Biologically Plausible Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farinha%2C+M+T">Matilde Tristany Farinha</a>, 
<a href="/search/cs?searchtype=author&query=Ortner%2C+T">Thomas Ortner</a>, 
<a href="/search/cs?searchtype=author&query=Dellaferrera%2C+G">Giorgia Dellaferrera</a>, 
<a href="/search/cs?searchtype=author&query=Grewe%2C+B">Benjamin Grewe</a>, 
<a href="/search/cs?searchtype=author&query=Pantazi%2C+A">Angeliki Pantazi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Artificial Neural Networks (ANNs) trained with Backpropagation (BP) show
astounding performance and are increasingly often used in performing our daily
life tasks. However, ANNs are highly vulnerable to adversarial attacks, which
alter inputs with small targeted perturbations that drastically disrupt the
models' performance. The most effective method to make ANNs robust against
these attacks is adversarial training, in which the training dataset is
augmented with exemplary adversarial samples. Unfortunately, this approach has
the drawback of increased training complexity since generating adversarial
samples is very computationally demanding. In contrast to ANNs, humans are not
susceptible to adversarial attacks. Therefore, in this work, we investigate
whether biologically-plausible learning algorithms are more robust against
adversarial attacks than BP. In particular, we present an extensive comparative
analysis of the adversarial robustness of BP and \textit{Present the Error to
Perturb the Input To modulate Activity} (PEPITA), a recently proposed
biologically-plausible learning algorithm, on various computer vision tasks. We
observe that PEPITA has higher intrinsic adversarial robustness and, with
adversarial training, has a more favourable natural-vs-adversarial performance
trade-off as, for the same natural accuracies, PEPITA's adversarial accuracies
decrease in average by 0.26% and BP's by 8.05%.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17352" title="Abstract">arXiv:2309.17352</a> [<a href="/pdf/2309.17352" title="Download PDF">pdf</a>, <a href="/format/2309.17352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Audio Captioning Models with Fine-grained Audio Features, Text  Embedding Supervision, and LLM Mix-up Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shih-Lun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wichern%2C+G">Gordon Wichern</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jee-weon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Germain%2C+F">Fran&#xe7;ois Germain</a>, 
<a href="/search/cs?searchtype=author&query=Roux%2C+J+L">Jonathan Le Roux</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, under review at ICASSP 2024. Winner of the DCASE 2023 Challenge Task 6A: Automated Audio Captioning (AAC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automated audio captioning (AAC) aims to generate informative descriptions
for various sounds from nature and/or human activities. In recent years, AAC
has quickly attracted research interest, with state-of-the-art systems now
relying on a sequence-to-sequence (seq2seq) backbone powered by strong models
such as Transformers. Following the macro-trend of applied machine learning
research, in this work, we strive to improve the performance of seq2seq AAC
models by extensively leveraging pretrained models and large language models
(LLMs). Specifically, we utilize BEATs to extract fine-grained audio features.
Then, we employ Instructor LLM to fetch text embeddings of captions, and infuse
their language-modality knowledge into BEATs audio features via an auxiliary
InfoNCE loss function. Moreover, we propose a novel data augmentation method
that uses ChatGPT to produce caption mix-ups (i.e., grammatical and compact
combinations of two captions) which, together with the corresponding audio
mixtures, increase not only the amount but also the complexity and diversity of
training data. During inference, we propose to employ nucleus sampling and a
hybrid reranking algorithm, which has not been explored in AAC research.
Combining our efforts, our model achieves a new state-of-the-art 32.6 SPIDEr-FL
score on the Clotho evaluation split, and wins the 2023 DCASE AAC challenge.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17354" title="Abstract">arXiv:2309.17354</a> [<a href="/pdf/2309.17354" title="Download PDF">pdf</a>, <a href="/format/2309.17354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Layered Architecture Enabling Metaverse Applications in Smart  Manufacturing Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bujari%2C+A">Armir Bujari</a>, 
<a href="/search/cs?searchtype=author&query=Calvio%2C+A">Alessandro Calvio</a>, 
<a href="/search/cs?searchtype=author&query=Garbugli%2C+A">Andrea Garbugli</a>, 
<a href="/search/cs?searchtype=author&query=Bellavista%2C+P">Paolo Bellavista</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The steady rollout of Industrial IoT (IIoT) technology in the manufacturing
domain embodies the potential to implement smarter and more resilient
production processes. To this end, it is expected that there will be a strong
reliance of manufacturing processes on cloud/edge services so as to act
intelligently and flexibly. While automation is necessary to handle the
environment's complexity, human-in-the-loop design approaches are paramount. In
this context, Digital Twins play a crucial role by allowing human operators to
inspect and monitor the environment to ensure stability and reliability.
Integrating the IIoT with the Metaverse enhances the system's capabilities even
further, offering new opportunities for efficiency and collaboration while
enabling integrated management of assets and processes. This article presents a
layered conceptual architecture as an enabler for smart manufacturing metaverse
environments, targeting real-time data collection and representations from
shopfloor assets and processes. At the bottom layer, our proposal relies on
middleware technology, serving differentiated Quality of Service (QoS) needs of
the Operation Technology (OT) monitoring processes. The latter contributes to
feeding a virtual layer where data processes reside, creating representations
of the monitored phenomena at different timescales. Metaverse applications can
consume data by tapping into the metaverse engine, a microservice-oriented and
accelerated Platform as a Service (PaaS) layer tasked with bringing data to
life. Without loss of generality, we profile different facets of our proposal
by relying on two different proof-of-concept inspection applications aimed at
real-time monitoring of the network fabric activity and a visual asset
monitoring one.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17357" title="Abstract">arXiv:2309.17357</a> [<a href="/pdf/2309.17357" title="Download PDF">pdf</a>, <a href="/format/2309.17357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Module-wise Training of Neural Networks via the Minimizing Movement  Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karkar%2C+S">Skander Karkar</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+I">Ibrahim Ayed</a>, 
<a href="/search/cs?searchtype=author&query=de+B%C3%A9zenac%2C+E">Emmanuel de B&#xe9;zenac</a>, 
<a href="/search/cs?searchtype=author&query=Gallinari%2C+P">Patrick Gallinari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Greedy layer-wise or module-wise training of neural networks is compelling in
constrained and on-device settings where memory is limited, as it circumvents a
number of problems of end-to-end back-propagation. However, it suffers from a
stagnation problem, whereby early layers overfit and deeper layers stop
increasing the test accuracy after a certain depth. We propose to solve this
issue by introducing a module-wise regularization inspired by the minimizing
movement scheme for gradient flows in distribution space. We call the method
TRGL for Transport Regularized Greedy Learning and study it theoretically,
proving that it leads to greedy modules that are regular and that progressively
solve the task. Experimentally, we show improved accuracy of module-wise
training of various architectures such as ResNets, Transformers and VGG, when
our regularization is added, superior to that of other module-wise training
methods and often to end-to-end training, with as much as 60% less memory
usage.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17358" title="Abstract">arXiv:2309.17358</a> [<a href="/pdf/2309.17358" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alignment-Tolerant Fi-Wi-Fi Free-Space Optical Bridge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Honz%2C+F">Florian Honz</a> (1), 
<a href="/search/cs?searchtype=author&query=Marti%2C+A+V">Aina Val Marti</a> (1), 
<a href="/search/cs?searchtype=author&query=Walther%2C+P">Philip Walther</a> (2), 
<a href="/search/cs?searchtype=author&query=H%C3%BCbel%2C+H">Hannes H&#xfc;bel</a> (1), 
<a href="/search/cs?searchtype=author&query=Schrenk%2C+B">Bernhard Schrenk</a> (1) ((1) AIT Austrian Institute of Technology, (2) University of Vienna, Faculty of Physics)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We demonstrate a simplified out-door FSO link with modal split for
down-/uplink and confirm its long-term stability without active beam tracking.
We further prove the duality of modal and directional split through
penalty-free full-duplex transmission.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17361" title="Abstract">arXiv:2309.17361</a> [<a href="/pdf/2309.17361" title="Download PDF">pdf</a>, <a href="/format/2309.17361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Memory Footprint Compression Through Jointly Learnable Codebooks  and Mappings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yvinec%2C+E">Edouard Yvinec</a>, 
<a href="/search/cs?searchtype=author&query=Dapogny%2C+A">Arnaud Dapogny</a>, 
<a href="/search/cs?searchtype=author&query=Bailly%2C+K">Kevin Bailly</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The massive interest in deep neural networks (DNNs) for both computer vision
and natural language processing has been sparked by the growth in computational
power. However, this led to an increase in the memory footprint, to a point
where it can be challenging to simply load a model on commodity devices such as
mobile phones. To address this limitation, quantization is a favored solution
as it maps high precision tensors to a low precision, memory efficient format.
In terms of memory footprint reduction, its most effective variants are based
on codebooks. These methods, however, suffer from two limitations. First, they
either define a single codebook for each tensor, or use a memory-expensive
mapping to multiple codebooks. Second, gradient descent optimization of the
mapping favors jumps toward extreme values, hence not defining a proximal
search. In this work, we propose to address these two limitations. First, we
initially group similarly distributed neurons and leverage the re-ordered
structure to either apply different scale factors to the different groups, or
map weights that fall in these groups to several codebooks, without any mapping
overhead. Second, stemming from this initialization, we propose a joint
learning of the codebook and weight mappings that bears similarities with
recent gradient-based post-training quantization techniques. Third, drawing
estimation from straight-through estimation techniques, we introduce a novel
gradient update definition to enable a proximal search of the codebooks and
their mappings. The proposed jointly learnable codebooks and mappings (JLCM)
method allows a very efficient approximation of any DNN: as such, a Llama 7B
can be compressed down to 2Go and loaded on 5-year-old smartphones.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17364" title="Abstract">arXiv:2309.17364</a> [<a href="/pdf/2309.17364" title="Download PDF">pdf</a>, <a href="/format/2309.17364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Should you make your decisions on a WhIM? Data-Driven Decision making  using a What-If Machine for Evaluation of Hypothetical Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Echterhoff%2C+J+M">Jessica Maria Echterhoff</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+B">Bhaskar Sen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yifei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Gopal%2C+N">Nikhil Gopal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">What-if analysis can be used as a process in data-driven decision making to
inspect the behavior of a complex system under some given hypothesis. We
propose a What-If Machine that creates hypothetical realities by resampling the
data distribution and comparing it to the an alternate baseline to measure the
impact on a target metric. Our What-If Machine enables both a method to
confirm/reject manually developed intuitions of practitioners as well as give
high-impact insights on a target metric automatically. This can support
data-informed decision making by using historical data to infer future
possibilities. Our method is not bound by a specific use-case and can be used
on any tabular data. Compared to previous work, our work enables real-time
analysis and gives insights into areas with high impact on the target metric
automatically, moving beyond human intuitions to provide data-driven insights.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17370" title="Abstract">arXiv:2309.17370</a> [<a href="/pdf/2309.17370" title="Download PDF">pdf</a>, <a href="/format/2309.17370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-based Neural Weather Prediction for Limited Area Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oskarsson%2C+J">Joel Oskarsson</a>, 
<a href="/search/cs?searchtype=author&query=Landelius%2C+T">Tomas Landelius</a>, 
<a href="/search/cs?searchtype=author&query=Lindsten%2C+F">Fredrik Lindsten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 26 figures. Code will be made available at: <a href="https://github.com/joeloskarsson/neural-lam">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The rise of accurate machine learning methods for weather forecasting is
creating radical new possibilities for modeling the atmosphere. In the time of
climate change, having access to high-resolution forecasts from models like
these is also becoming increasingly vital. While most existing Neural Weather
Prediction (NeurWP) methods focus on global forecasting, an important question
is how these techniques can be applied to limited area modeling. In this work
we adapt the graph-based NeurWP approach to the limited area setting and
propose a multi-scale hierarchical model extension. Our approach is validated
by experiments with a local model for the Nordic region.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17371" title="Abstract">arXiv:2309.17371</a> [<a href="/pdf/2309.17371" title="Download PDF">pdf</a>, <a href="/format/2309.17371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Imitation Learning from Visual Observations using Latent  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giammarino%2C+V">Vittorio Giammarino</a>, 
<a href="/search/cs?searchtype=author&query=Queeney%2C+J">James Queeney</a>, 
<a href="/search/cs?searchtype=author&query=Paschalidis%2C+I+C">Ioannis Ch. Paschalidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
<p class="mathjax">We focus on the problem of imitation learning from visual observations, where
the learning agent has access to videos of experts as its sole learning source.
The challenges of this framework include the absence of expert actions and the
partial observability of the environment, as the ground-truth states can only
be inferred from pixels. To tackle this problem, we first conduct a theoretical
analysis of imitation learning in partially observable environments. We
establish upper bounds on the suboptimality of the learning agent with respect
to the divergence between the expert and the agent latent state-transition
distributions. Motivated by this analysis, we introduce an algorithm called
Latent Adversarial Imitation from Observations, which combines off-policy
adversarial imitation techniques with a learned latent representation of the
agent's state from sequences of observations. In experiments on
high-dimensional continuous robotic tasks, we show that our algorithm matches
state-of-the-art performance while providing significant computational
advantages. Additionally, we show how our method can be used to improve the
efficiency of reinforcement learning from pixels by leveraging expert videos.
To ensure reproducibility, we provide free access to our code.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17382" title="Abstract">arXiv:2309.17382</a> [<a href="/pdf/2309.17382" title="Download PDF">pdf</a>, <a href="/format/2309.17382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reason for Future, Act for Now: A Principled Framework for Autonomous  LLM Agents with Provable Sample Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shenao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongyi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+S">Shuqi Ke</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Boyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) demonstrate impressive reasoning abilities, but
translating reasoning into actions in the real world remains challenging. In
particular, it remains unclear how to complete a given task provably within a
minimum number of interactions with the external environment, e.g., through an
internal mechanism of reasoning. To this end, we propose a principled framework
with provable regret guarantees to orchestrate reasoning and acting, which we
call ``reason for future, act for now" (\texttt{RAFA}). Specifically, we design
a prompt template for reasoning that learns from the memory buffer and plans a
future trajectory over a long horizon (``reason for future"). At each step, the
LLM agent takes the initial action of the planned trajectory (``act for now"),
stores the collected feedback in the memory buffer, and reinvokes the reasoning
routine to replan the future trajectory from the new state.
<br />The key idea is to cast reasoning in LLMs as learning and planning in
Bayesian adaptive Markov decision processes (MDPs). Correspondingly, we prompt
LLMs to form an updated posterior of the unknown environment from the memory
buffer (learning) and generate an optimal trajectory for multiple future steps
that maximizes a value function (planning). The learning and planning
subroutines are performed in an "in-context" manner to emulate the actor-critic
update for MDPs. Our theoretical analysis proves that the novel combination of
long-term reasoning and short-term acting achieves a $\sqrt{T}$ regret. In
particular, the regret bound highlights an intriguing interplay between the
prior knowledge obtained through pretraining and the uncertainty reduction
achieved by reasoning and acting. Our empirical validation shows that it
outperforms various existing frameworks and achieves nearly perfect scores on a
few benchmarks.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17383" title="Abstract">arXiv:2309.17383</a> [<a href="/pdf/2309.17383" title="Download PDF">pdf</a>, <a href="/format/2309.17383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Computation of Multi-Slice Clustering of Third-Order Tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andriantsiory%2C+D+F">Dina Faneva Andriantsiory</a>, 
<a href="/search/cs?searchtype=author&query=Coti%2C+C">Camille Coti</a>, 
<a href="/search/cs?searchtype=author&query=Geloun%2C+J+B">Joseph Ben Geloun</a>, 
<a href="/search/cs?searchtype=author&query=Lebbah%2C+M">Mustapha Lebbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine Learning approaches like clustering methods deal with massive
datasets that present an increasing challenge. We devise parallel algorithms to
compute the Multi-Slice Clustering (MSC) for 3rd-order tensors. The MSC method
is based on spectral analysis of the tensor slices and works independently on
each tensor mode. Such features fit well in the parallel paradigm via a
distributed memory system. We show that our parallel scheme outperforms
sequential computing and allows for the scalability of the MSC method.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17388" title="Abstract">arXiv:2309.17388</a> [<a href="/pdf/2309.17388" title="Download PDF">pdf</a>, <a href="/format/2309.17388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree Cross Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Leo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+F">Frederick Tung</a>, 
<a href="/search/cs?searchtype=author&query=Hajimirsadeghi%2C+H">Hossein Hajimirsadeghi</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M+O">Mohamed Osama Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Cross Attention is a popular method for retrieving information from a set of
context tokens for making predictions. At inference time, for each prediction,
Cross Attention scans the full set of $\mathcal{O}(N)$ tokens. In practice,
however, often only a small subset of tokens are required for good performance.
Methods such as Perceiver IO are cheap at inference as they distill the
information to a smaller-sized set of latent tokens $L &lt; N$ on which cross
attention is then applied, resulting in only $\mathcal{O}(L)$ complexity.
However, in practice, as the number of input tokens and the amount of
information to distill increases, the number of latent tokens needed also
increases significantly. In this work, we propose Tree Cross Attention (TCA) -
a module based on Cross Attention that only retrieves information from a
logarithmic $\mathcal{O}(\log(N))$ number of tokens for performing inference.
TCA organizes the data in a tree structure and performs a tree search at
inference time to retrieve the relevant tokens for prediction. Leveraging TCA,
we introduce ReTreever, a flexible architecture for token-efficient inference.
We show empirically that Tree Cross Attention (TCA) performs comparable to
Cross Attention across various classification and uncertainty regression tasks
while being significantly more token-efficient. Furthermore, we compare
ReTreever against Perceiver IO, showing significant gains while using the same
number of tokens for inference.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17389" title="Abstract">arXiv:2309.17389</a> [<a href="/pdf/2309.17389" title="Download PDF">pdf</a>, <a href="/format/2309.17389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-based test-time real image dehazing: a novel pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zewei He</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Ziqian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhe-Ming Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing methods attempt to improve models' generalization ability on
real-world hazy images by exploring well-designed training schemes (e.g.,
cycleGAN, prior loss). However, most of them need very complicated training
procedures to achieve satisfactory results. In this work, we present a totally
novel testing pipeline called Prompt-based Test-Time Dehazing (PTTD) to help
generate visually pleasing results of real-captured hazy images during the
inference phase. We experimentally find that given a dehazing model trained on
synthetic data, by fine-tuning the statistics (i.e., mean and standard
deviation) of encoding features, PTTD is able to narrow the domain gap,
boosting the performance of real image dehazing. Accordingly, we first apply a
prompt generation module (PGM) to generate a visual prompt, which is the source
of appropriate statistical perturbations for mean and standard deviation. And
then, we employ the feature adaptation module (FAM) into the existing dehazing
models for adjusting the original statistics with the guidance of the generated
prompt. Note that, PTTD is model-agnostic and can be equipped with various
state-of-the-art dehazing models trained on synthetic hazy-clean pairs.
Extensive experimental results demonstrate that our PTTD is flexible meanwhile
achieves superior performance against state-of-the-art dehazing methods in
real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17390" title="Abstract">arXiv:2309.17390</a> [<a href="/pdf/2309.17390" title="Download PDF">pdf</a>, <a href="/format/2309.17390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forward Flow for Novel View Synthesis of Dynamic Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiadai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuchao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xiaoqing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xiao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+E">Errui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yumeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023 as oral. Project page: <a href="https://npucvr.github.io/ForwardFlowDNeRF">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes a neural radiance field (NeRF) approach for novel view
synthesis of dynamic scenes using forward warping. Existing methods often adopt
a static NeRF to represent the canonical space, and render dynamic images at
other time steps by mapping the sampled 3D points back to the canonical space
with the learned backward flow field. However, this backward flow field is
non-smooth and discontinuous, which is difficult to be fitted by commonly used
smooth motion models. To address this problem, we propose to estimate the
forward flow field and directly warp the canonical radiance field to other time
steps. Such forward flow field is smooth and continuous within the object
region, which benefits the motion model learning. To achieve this goal, we
represent the canonical radiance field with voxel grids to enable efficient
forward warping, and propose a differentiable warping process, including an
average splatting operation and an inpaint network, to resolve the many-to-one
and one-to-many mapping issues. Thorough experiments show that our method
outperforms existing methods in both novel view rendering and motion modeling,
demonstrating the effectiveness of our forward flow motion modeling. Project
page: https://npucvr.github.io/ForwardFlowDNeRF
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17395" title="Abstract">arXiv:2309.17395</a> [<a href="/pdf/2309.17395" title="Download PDF">pdf</a>, <a href="/format/2309.17395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AV-CPL: Continuous Pseudo-Labeling for Audio-Visual Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rouditchenko%2C+A">Andrew Rouditchenko</a>, 
<a href="/search/cs?searchtype=author&query=Collobert%2C+R">Ronan Collobert</a>, 
<a href="/search/cs?searchtype=author&query=Likhomanenko%2C+T">Tatiana Likhomanenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Machine Learning (stat.ML)

</div>
<p class="mathjax">Audio-visual speech contains synchronized audio and visual information that
provides cross-modal supervision to learn representations for both automatic
speech recognition (ASR) and visual speech recognition (VSR). We introduce
continuous pseudo-labeling for audio-visual speech recognition (AV-CPL), a
semi-supervised method to train an audio-visual speech recognition (AVSR) model
on a combination of labeled and unlabeled videos with continuously regenerated
pseudo-labels. Our models are trained for speech recognition from audio-visual
inputs and can perform speech recognition using both audio and visual
modalities, or only one modality. Our method uses the same audio-visual model
for both supervised training and pseudo-label generation, mitigating the need
for external speech recognition models to generate pseudo-labels. AV-CPL
obtains significant improvements in VSR performance on the LRS3 dataset while
maintaining practical ASR and AVSR performance. Finally, using visual-only
speech data, our method is able to leverage unlabeled visual speech to improve
VSR.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17397" title="Abstract">arXiv:2309.17397</a> [<a href="/pdf/2309.17397" title="Download PDF">pdf</a>, <a href="/format/2309.17397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytic and Gevrey class regularity for parametric semilinear  reaction-diffusion problems and applications in uncertainty quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chernov%2C+A">Alexey Chernov</a>, 
<a href="/search/math?searchtype=author&query=Le%2C+T">Tung Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.07010">arXiv:2306.07010</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We investigate a class of parametric elliptic semilinear partial differential
equations of second order with homogeneous essential boundary conditions, where
the coefficients and the right-hand side (and hence the solution) may depend on
a parameter. This model can be seen as a reaction-diffusion problem with a
polynomial nonlinearity in the reaction term. The efficiency of various
numerical approximations across the entire parameter space is closely related
to the regularity of the solution with respect to the parameter. We show that
if the coefficients and the right-hand side are analytic or Gevrey class
regular with respect to the parameter, the same type of parametric regularity
is valid for the solution. The key ingredient of the proof is the combination
of the alternative-to-factorial technique from our previous work [1] with a
novel argument for the treatment of the power-type nonlinearity in the reaction
term. As an application of this abstract result, we obtain rigorous convergence
estimates for numerical integration of semilinear reaction-diffusion problems
with random coefficients using Gaussian and Quasi-Monte Carlo quadrature. Our
theoretical findings are confirmed in numerical experiments.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17399" title="Abstract">arXiv:2309.17399</a> [<a href="/pdf/2309.17399" title="Download PDF">pdf</a>, <a href="/format/2309.17399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IFAST: Weakly Supervised Interpretable Face Anti-spoofing from  Single-shot Binocular NIR Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiancheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Donghao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single-shot face anti-spoofing (FAS) is a key technique for securing face
recognition systems, and it requires only static images as input. However,
single-shot FAS remains a challenging and under-explored problem due to two
main reasons: 1) on the data side, learning FAS from RGB images is largely
context-dependent, and single-shot images without additional annotations
contain limited semantic information. 2) on the model side, existing
single-shot FAS models are infeasible to provide proper evidence for their
decisions, and FAS methods based on depth estimation require expensive
per-pixel annotations. To address these issues, a large binocular NIR image
dataset (BNI-FAS) is constructed and published, which contains more than
300,000 real face and plane attack images, and an Interpretable FAS Transformer
(IFAST) is proposed that requires only weak supervision to produce
interpretable predictions. Our IFAST can produce pixel-wise disparity maps by
the proposed disparity estimation Transformer with Dynamic Matching Attention
(DMA) block. Besides, a well-designed confidence map generator is adopted to
cooperate with the proposed dual-teacher distillation module to obtain the
final discriminant results. The comprehensive experiments show that our IFAST
can achieve state-of-the-art results on BNI-FAS, proving the effectiveness of
the single-shot FAS based on binocular NIR images.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17400" title="Abstract">arXiv:2309.17400</a> [<a href="/pdf/2309.17400" title="Download PDF">pdf</a>, <a href="/format/2309.17400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directly Fine-Tuning Diffusion Models on Differentiable Rewards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clark%2C+K">Kevin Clark</a>, 
<a href="/search/cs?searchtype=author&query=Vicol%2C+P">Paul Vicol</a>, 
<a href="/search/cs?searchtype=author&query=Swersky%2C+K">Kevin Swersky</a>, 
<a href="/search/cs?searchtype=author&query=Fleet%2C+D+J">David J Fleet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present Direct Reward Fine-Tuning (DRaFT), a simple and effective method
for fine-tuning diffusion models to maximize differentiable reward functions,
such as scores from human preference models. We first show that it is possible
to backpropagate the reward function gradient through the full sampling
procedure, and that doing so achieves strong performance on a variety of
rewards, outperforming reinforcement learning-based approaches. We then propose
more efficient variants of DRaFT: DRaFT-K, which truncates backpropagation to
only the last K steps of sampling, and DRaFT-LV, which obtains lower-variance
gradient estimates for the case when K=1. We show that our methods work well
for a variety of reward functions and can be used to substantially improve the
aesthetic quality of images generated by Stable Diffusion 1.4. Finally, we draw
connections between our approach and prior work, providing a unifying
perspective on the design space of gradient-based fine-tuning algorithms.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17401" title="Abstract">arXiv:2309.17401</a> [<a href="/pdf/2309.17401" title="Download PDF">pdf</a>, <a href="/ps/2309.17401" title="Download PostScript">ps</a>, <a href="/format/2309.17401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Machine Learning in Latent Representations of Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Milin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Abdi%2C+M">Mohammad Abdi</a>, 
<a href="/search/cs?searchtype=author&query=Restuccia%2C+F">Francesco Restuccia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Distributed deep neural networks (DNNs) have been shown to reduce the
computational burden of mobile devices and decrease the end-to-end inference
latency in edge computing scenarios. While distributed DNNs have been studied,
to the best of our knowledge the resilience of distributed DNNs to adversarial
action still remains an open problem. In this paper, we fill the existing
research gap by rigorously analyzing the robustness of distributed DNNs against
adversarial action. We cast this problem in the context of information theory
and introduce two new measurements for distortion and robustness. Our
theoretical findings indicate that (i) assuming the same level of information
distortion, latent features are always more robust than input representations;
(ii) the adversarial robustness is jointly determined by the feature dimension
and the generalization capability of the DNN. To test our theoretical findings,
we perform extensive experimental analysis by considering 6 different DNN
architectures, 6 different approaches for distributed DNN and 10 different
adversarial attacks to the ImageNet-1K dataset. Our experimental results
support our theoretical findings by showing that the compressed latent
representations can reduce the success rate of adversarial attacks by 88% in
the best case and by 57% on the average compared to attacks to the input space.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17403" title="Abstract">arXiv:2309.17403</a> [<a href="/pdf/2309.17403" title="Download PDF">pdf</a>, <a href="/format/2309.17403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximal Volume Matrix Cross Approximation for Image Compression and  Least Squares Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Allen%2C+K">Kenneth Allen</a>, 
<a href="/search/math?searchtype=author&query=Lai%2C+M">Ming-Jun Lai</a>, 
<a href="/search/math?searchtype=author&query=Shen%2C+Z">Zhaiming Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study the classic cross approximation of matrices based on the maximal
volume submatrices. Our main results consist of an improvement of a classic
estimate for matrix cross approximation and a greedy approach for finding the
maximal volume submatrices. Indeed, we present a new proof of a classic
estimate of the inequality with an improved constant. Also, we present a family
of greedy maximal volume algorithms which improve the error bound of cross
approximation of a matrix in the Chebyshev norm and also improve the
computational efficiency of classic maximal volume algorithm. The proposed
algorithms are shown to have theoretical guarantees of convergence. Finally, we
present two applications: one is image compression and the other is least
squares approximation of continuous functions. Our numerical results in the end
of the paper demonstrate the effective performances of our approach.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17410" title="Abstract">arXiv:2309.17410</a> [<a href="/pdf/2309.17410" title="Download PDF">pdf</a>, <a href="/format/2309.17410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Sensitive Information Be Deleted From LLMs? Objectives for Defending  Against Extraction Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patil%2C+V">Vaidehi Patil</a>, 
<a href="/search/cs?searchtype=author&query=Hase%2C+P">Peter Hase</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Equal contribution from first two authors. 19 pages, 5 figures. Our code is available at: <a href="https://github.com/Vaidehi99/InfoDeletionAttacks">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pretrained language models sometimes possess knowledge that we do not wish
them to, including memorized personal information and knowledge that could be
used to harm people. They can also output toxic or harmful text. To mitigate
these safety and informational issues, we propose an attack-and-defense
framework for studying the task of deleting sensitive information directly from
model weights. We study direct edits to model weights because (1) this approach
should guarantee that particular deleted information is never extracted by
future prompt attacks, and (2) it should protect against whitebox attacks,
which is necessary for making claims about safety/privacy in a setting where
publicly available model weights could be used to elicit sensitive information.
Our threat model assumes that an attack succeeds if the answer to a sensitive
question is located among a set of B generated candidates, based on scenarios
where the information would be insecure if the answer is among B candidates.
Experimentally, we show that even state-of-the-art model editing methods such
as ROME struggle to truly delete factual information from models like GPT-J, as
our whitebox and blackbox attacks can recover "deleted" information from an
edited model 38% of the time. These attacks leverage two key observations: (1)
that traces of deleted information can be found in intermediate model hidden
states, and (2) that applying an editing method for one question may not delete
information across rephrased versions of the question. Finally, we provide new
defense methods that protect against some extraction attacks, but we do not
find a single universally effective defense method. Our results suggest that
truly deleting sensitive information is a tractable but difficult problem,
since even relatively low attack success rates have potentially severe societal
implications for real-world deployment of language models.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17411" title="Abstract">arXiv:2309.17411</a> [<a href="/pdf/2309.17411" title="Download PDF">pdf</a>, <a href="/format/2309.17411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient Model-Free Asymmetric Bipartite Consensus for Nonlinear  Multi-Agent Systems against DoS Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yichao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+J">Junbo Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zuo%2C+S">Shan Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this letter, we study an unified resilient asymmetric bipartite consensus
(URABC) problem for nonlinear multi-agent systems with both cooperative and
antagonistic interactions under denial-of-service (DoS) attacks. We first prove
that the URABC problem is solved by stabilizing the neighborhood asymmetric
bipartite consensus error. Then, we develop a distributed compact form dynamic
linearization method to linearize the neighborhood asymmetric bipartite
consensus error. By using an extended discrete state observer to enhance the
robustness against unknown dynamics and an attack compensation mechanism to
eliminate the adverse effects of DoS attacks, we finally propose a distributed
resilient model-free adaptive control algorithm to solve the URABC problem. A
numerical example validates the proposed results.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17414" title="Abstract">arXiv:2309.17414</a> [<a href="/pdf/2309.17414" title="Download PDF">pdf</a>, <a href="/format/2309.17414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QR TPM in Programmable Low-Power Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiolhais%2C+L">Lu&#xed;s Fiolhais</a>, 
<a href="/search/cs?searchtype=author&query=Sousa%2C+L">Leonel Sousa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Trusted Platform Modules (TPMs), which serve as the root of trust in secure
systems, are secure crypto-processors that carry out cryptographic primitives.
Should large-scale quantum computing become a reality, the cryptographic
primitives adopted in the TPM 2.0 standard will no longer be secure. Thus, the
design of TPMs that provide Quantum Resistant (QR) primitives is of utmost
importance, in particular with the restrictions imposed by embedded systems. In
this paper, we investigate the deployment of QR primitives and protocols in the
standard TPM 2.0. Cryptographic algorithms that are already in the NIST QR
cryptography standardization process, as well as an Oblivious Transfer (OT), a
fundamental cryptographic primitive, are the QR cryptographic schemes selected
to extend TPM 2.0. In particular, the Kyber algorithm for key encapsulation,
the Dilithium algorithm for digital signature, and a 3-round Random Oblivious
Transfer (ROT) protocol, supporting protocols such as Multi-Party Computation
and Private Set Intersection (PSI). The QR extended TPM 2.0 is implemented in
ARM and RISC-V embedded processors, its computational requirements are analysed
and experimentally evaluated in comparison to the standard TPM. It is shown
that Kyber and Dilithium are faster at creating keys than RSA, due to the key
size and secure random sampling required in RSA, while they meet the same
performance level as ECC. For digital signatures, both in signature creation
and verification, Dilithium is on par with RSA and ECC. The ROT protocol shows
decent performance and its support required small modifications to the TPM.
This paper also shows that it would be possible to backport the required code
to already available TPMs to ensure that current TPMs remain secure against
quantum adversaries.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17415" title="Abstract">arXiv:2309.17415</a> [<a href="/pdf/2309.17415" title="Download PDF">pdf</a>, <a href="/format/2309.17415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intuitive or Dependent? Investigating LLMs&#x27; Robustness to Conflicting  Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+J">Jiahao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+K">Kai Xiong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yidong He</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Long Cui</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongbin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper explores the robustness of LLMs' preference to their internal
memory or the given prompt, which may contain contrasting information in
real-world applications due to noise or task settings. To this end, we
establish a quantitative benchmarking framework and conduct the role playing
intervention to control LLMs' preference. In specific, we define two types of
robustness, factual robustness targeting the ability to identify the correct
fact from prompts or memory, and decision style to categorize LLMs' behavior in
making consistent choices -- assuming there is no definitive "right" answer --
intuitive, dependent, or rational based on cognitive theory. Our findings,
derived from extensive experiments on seven open-source and closed-source LLMs,
reveal that these models are highly susceptible to misleading prompts,
especially for instructing commonsense knowledge. While detailed instructions
can mitigate the selection of misleading answers, they also increase the
incidence of invalid responses. After Unraveling the preference, we intervene
different sized LLMs through specific style of role instruction, showing their
varying upper bound of robustness and adaptivity.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17417" title="Abstract">arXiv:2309.17417</a> [<a href="/pdf/2309.17417" title="Download PDF">pdf</a>, <a href="/format/2309.17417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Networked Inequality: Preferential Attachment Bias in Graph Neural  Network Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subramonian%2C+A">Arjun Subramonian</a>, 
<a href="/search/cs?searchtype=author&query=Sagun%2C+L">Levent Sagun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yizhou Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph neural network (GNN) link prediction is increasingly deployed in
citation, collaboration, and online social networks to recommend academic
literature, collaborators, and friends. While prior research has investigated
the dyadic fairness of GNN link prediction, the within-group fairness and
``rich get richer'' dynamics of link prediction remain underexplored. However,
these aspects have significant consequences for degree and power imbalances in
networks. In this paper, we shed light on how degree bias in networks affects
Graph Convolutional Network (GCN) link prediction. In particular, we
theoretically uncover that GCNs with a symmetric normalized graph filter have a
within-group preferential attachment bias. We validate our theoretical analysis
on real-world citation, collaboration, and online social networks. We further
bridge GCN's preferential attachment bias with unfairness in link prediction
and propose a new within-group fairness metric. This metric quantifies
disparities in link prediction scores between social groups, towards combating
the amplification of degree and power disparities. Finally, we propose a simple
training-time strategy to alleviate within-group unfairness, and we show that
it is effective on citation, online social, and credit networks.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17419" title="Abstract">arXiv:2309.17419</a> [<a href="/pdf/2309.17419" title="Download PDF">pdf</a>, <a href="/format/2309.17419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumerating minimal solution sets for metric graph problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergougnoux%2C+B">Benjamin Bergougnoux</a>, 
<a href="/search/cs?searchtype=author&query=Defrain%2C+O">Oscar Defrain</a>, 
<a href="/search/cs?searchtype=author&query=Inerney%2C+F+M">Fionn Mc Inerney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
<p class="mathjax">Problems from metric graph theory such as Metric Dimension, Geodetic Set, and
Strong Metric Dimension have recently had a strong impact on the field of
parameterized complexity by being the first problems in NP to admit
double-exponential lower bounds in the treewidth, and even in the vertex cover
number for the latter. We initiate the study of enumerating minimal solution
sets for these problems and show that they are also of great interest in
enumeration. More specifically, we show that enumerating minimal resolving sets
in graphs and minimal geodetic sets in split graphs are equivalent to
hypergraph dualization, arguably one of the most important open problems in
algorithmic enumeration. This provides two new natural examples to a question
that emerged in different works this last decade: for which vertex (or edge)
set graph property $\Pi$ is the enumeration of minimal (or maximal) subsets
satisfying $\Pi$ equivalent to hypergraph dualization? As only very few
properties are known to fit within this context -- namely, properties related
to minimal domination -- our results make significant progress in
characterizing such properties, and provide new angles of approach for tackling
hypergraph dualization.
<br />In a second step, we consider cases where our reductions do not apply, namely
graphs with no long induced paths, and show these cases to be mainly tractable.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17420" title="Abstract">arXiv:2309.17420</a> [<a href="/pdf/2309.17420" title="Download PDF">pdf</a>, <a href="/format/2309.17420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Flux Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sochat%2C+V">Vanessa Sochat</a>, 
<a href="/search/cs?searchtype=author&query=Culquicondor%2C+A">Aldo Culquicondor</a>, 
<a href="/search/cs?searchtype=author&query=Ojea%2C+A">Antonio Ojea</a>, 
<a href="/search/cs?searchtype=author&query=Milroy%2C+D">Daniel Milroy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages (plus 5 references), 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Converged computing brings together the best of both worlds for high
performance computing (HPC) and cloud-native communities. In fact, the economic
impact of cloud-computing, and need for portability, flexibility, and
manageability make it not important, but inevitable. Navigating this uncharted
territory requires not just innovation in the technology space, but also effort
toward collaboration and sharing of ideas. With these goals in mind, this work
first tackles the central component of running batch workflows, whether in
cloud or HPC: the workload manager. For cloud, Kubernetes has become the de
facto tool for this kind of batch orchestration. For HPC, the next-generation
HPC workload manager Flux Framework is analogous -- combining fully
hierarchical resource management and graph-based scheduling to support
intelligent scheduling and job management. Convergence of these managers would
mean the implementation of Flux inside of Kubernetes, allowing for hierarchical
resource management and scheduling that scales impressively without burdening
the Kubernetes scheduler itself. This paper introduces the Flux Operator -- an
on-demand HPC workload manager that is easily deployed in Kubernetes. The work
here highlights design decisions, mapping of components between environments,
experimental features, and shares the results of experiments that compare
performance with an equivalent operator in the space, the MPI Operator.
Finally, discussion closes with a review of challenges remaining, and hopes for
the future for improved technological innovation and collaboration.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17421" title="Abstract">arXiv:2309.17421</a> [<a href="/pdf/2309.17421" title="Download PDF">pdf</a>, <a href="/format/2309.17421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chung-Ching Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large multimodal models (LMMs) extend large language models (LLMs) with
multi-sensory skills, such as visual understanding, to achieve stronger generic
intelligence. In this paper, we analyze the latest model, GPT-4V(ision), to
deepen the understanding of LMMs. The analysis focuses on the intriguing tasks
that GPT-4V can perform, containing test samples to probe the quality and
genericity of GPT-4V's capabilities, its supported inputs and working modes,
and the effective ways to prompt the model. In our approach to exploring
GPT-4V, we curate and organize a collection of carefully designed qualitative
samples spanning a variety of domains and tasks. Observations from these
samples demonstrate that GPT-4V's unprecedented ability in processing
arbitrarily interleaved multimodal inputs and the genericity of its
capabilities together make GPT-4V a powerful multimodal generalist system.
Furthermore, GPT-4V's unique capability of understanding visual markers drawn
on input images can give rise to new human-computer interaction methods such as
visual referring prompting. We conclude the report with in-depth discussions on
the emerging application scenarios and the future research directions for
GPT-4V-based systems. We hope that this preliminary exploration will inspire
future research on the next-generation multimodal task formulation, new ways to
exploit and enhance LMMs to solve real-world problems, and gaining better
understanding of multimodal foundation models.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17425" title="Abstract">arXiv:2309.17425</a> [<a href="/pdf/2309.17425" title="Download PDF">pdf</a>, <a href="/format/2309.17425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Filtering Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+A">Alex Fang</a>, 
<a href="/search/cs?searchtype=author&query=Jose%2C+A+M">Albin Madappally Jose</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Amit Jain</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+L">Ludwig Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Toshev%2C+A">Alexander Toshev</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+V">Vaishaal Shankar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large training sets have become a cornerstone of machine learning and are the
foundation for recent advances in language modeling and multimodal learning.
While data curation for pre-training is often still ad-hoc, one common paradigm
is to first collect a massive pool of data from the Web and then filter this
candidate pool down to an actual training set via various heuristics. In this
work, we study the problem of learning a data filtering network (DFN) for this
second step of filtering a large uncurated dataset. Our key finding is that the
quality of a network for filtering is distinct from its performance on
downstream tasks: for instance, a model that performs well on ImageNet can
yield worse training sets than a model with low ImageNet accuracy that is
trained on a small amount of high-quality data. Based on our insights, we
construct new data filtering networks that induce state-of-the-art image-text
datasets. Specifically, our best performing dataset DFN-5B enables us to train
state-of-the-art models for their compute budgets: among other improvements on
a variety of tasks, a ViT-H trained on our dataset achieves 83.0% zero-shot
transfer accuracy on ImageNet, out-performing models trained on other datasets
such as LAION-2B, DataComp-1B, or OpenAI's WIT. In order to facilitate further
research in dataset design, we also release a new 2 billion example dataset
DFN-2B and show that high performance data filtering networks can be trained
from scratch using only publicly available data.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17426" title="Abstract">arXiv:2309.17426</a> [<a href="/pdf/2309.17426" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Potholes Based on Surface Area Using Pre-Trained  Models of Convolutional Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+C+F">Chauhdary Fazeel Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Cheema%2C+A">Abdullah Cheema</a>, 
<a href="/search/cs?searchtype=author&query=Qayyum%2C+W">Waqas Qayyum</a>, 
<a href="/search/cs?searchtype=author&query=Ehtisham%2C+R">Rana Ehtisham</a>, 
<a href="/search/cs?searchtype=author&query=Yousaf%2C+M+H">Muhammad Haroon Yousaf</a>, 
<a href="/search/cs?searchtype=author&query=Mir%2C+J">Junaid Mir</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoudabadi%2C+N+S">Nasim Shakouri Mahmoudabadi</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+A">Afaq Ahmad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 Pages, 26 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Potholes are fatal and can cause severe damage to vehicles as well as can
cause deadly accidents. In South Asian countries, pavement distresses are the
primary cause due to poor subgrade conditions, lack of subsurface drainage, and
excessive rainfalls. The present research compares the performance of three
pre-trained Convolutional Neural Network (CNN) models, i.e., ResNet 50, ResNet
18, and MobileNet. At first, pavement images are classified to find whether
images contain potholes, i.e., Potholes or Normal. Secondly, pavements images
are classi-fied into three categories, i.e., Small Pothole, Large Pothole, and
Normal. Pavement images are taken from 3.5 feet (waist height) and 2 feet.
MobileNet v2 has an accuracy of 98% for detecting a pothole. The classification
of images taken at the height of 2 feet has an accuracy value of 87.33%,
88.67%, and 92% for classifying the large, small, and normal pavement,
respectively. Similarly, the classification of the images taken from full of
waist (FFW) height has an accuracy value of 98.67%, 98.67%, and 100%.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17428" title="Abstract">arXiv:2309.17428</a> [<a href="/pdf/2309.17428" title="Download PDF">pdf</a>, <a href="/format/2309.17428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRAFT: Customizing LLMs by Creating and Retrieving from Specialized  Toolsets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lifan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yangyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+Y+R">Yi R. Fung</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at \url{<a href="https://github.com/lifan-yuan/CRAFT">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are often augmented with tools to solve complex
tasks. By generating code snippets and executing them through task-specific
Application Programming Interfaces (APIs), they can offload certain functions
to dedicated external modules, such as image encoding and performing
calculations. However, most existing approaches to augment LLMs with tools are
constrained by general-purpose APIs and lack the flexibility for tailoring them
to specific tasks. In this work, we present CRAFT, a general tool creation and
retrieval framework for LLMs. It creates toolsets specifically curated for the
tasks and equips LLMs with a component that retrieves tools from these sets to
enhance their capability to solve complex tasks. For each task, we collect
specific code solutions by prompting GPT-4 to solve the training examples.
Following a validation step ensuring the correctness, these solutions are
abstracted into code snippets to enhance reusability, and deduplicated for
higher quality. At inference time, the language model retrieves snippets from
the toolsets and then executes them or generates the output conditioning on the
retrieved snippets. Our method is designed to be flexible and offers a
plug-and-play approach to adapt off-the-shelf LLMs to unseen domains and
modalities, without any finetuning. Experiments on vision-language, tabular
processing, and mathematical reasoning tasks show that our approach achieves
substantial improvements compared to strong baselines. In addition, our
in-depth analysis reveals that: (1) consistent performance improvement can be
achieved by scaling up the number of tools and the capability of the backbone
models; (2) each component of our approach contributes to the performance
gains; (3) the created tools are well-structured and reliable with low
complexity and atomicity. The code is available at
\url{https://github.com/lifan-yuan/CRAFT}.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17430" title="Abstract">arXiv:2309.17430</a> [<a href="/pdf/2309.17430" title="Download PDF">pdf</a>, <a href="/format/2309.17430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FACTS: First Amplify Correlations and Then Slice to Discover Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yenamandra%2C+S">Sriram Yenamandra</a>, 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+P">Pratik Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+V">Viraj Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Computer vision datasets frequently contain spurious correlations between
task-relevant labels and (easy to learn) latent task-irrelevant attributes
(e.g. context). Models trained on such datasets learn "shortcuts" and
underperform on bias-conflicting slices of data where the correlation does not
hold. In this work, we study the problem of identifying such slices to inform
downstream bias mitigation strategies. We propose First Amplify Correlations
and Then Slice to Discover Bias (FACTS), wherein we first amplify correlations
to fit a simple bias-aligned hypothesis via strongly regularized empirical risk
minimization. Next, we perform correlation-aware slicing via mixture modeling
in bias-aligned feature space to discover underperforming data slices that
capture distinct correlations. Despite its simplicity, our method considerably
improves over prior work (by as much as 35% precision@10) in correlation bias
identification across a range of diverse evaluation settings. Our code is
available at: https://github.com/yvsriram/FACTS.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17433" title="Abstract">arXiv:2309.17433</a> [<a href="/pdf/2309.17433" title="Download PDF">pdf</a>, <a href="/format/2309.17433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DREAM: Decentralized Reinforcement Learning for Exploration and  Efficient Energy Management in Multi-Robot Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+D">Dipam Patel</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+P">Phu Pham</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+K">Kshitij Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Aniket Bera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Resource-constrained robots often suffer from energy inefficiencies,
underutilized computational abilities due to inadequate task allocation, and a
lack of robustness in dynamic environments, all of which strongly affect their
performance. This paper introduces DREAM - Decentralized Reinforcement Learning
for Exploration and Efficient Energy Management in Multi-Robot Systems, a
comprehensive framework that optimizes the allocation of resources for
efficient exploration. It advances beyond conventional heuristic-based task
planning as observed conventionally. The framework incorporates Operational
Range Estimation using Reinforcement Learning to perform exploration and
obstacle avoidance in unfamiliar terrains. DREAM further introduces an Energy
Consumption Model for goal allocation, thereby ensuring mission completion
under constrained resources using a Graph Neural Network. This approach also
ensures that the entire Multi-Robot System can survive for an extended period
of time for further missions compared to the conventional approach of randomly
allocating goals, which compromises one or more agents. Our approach adapts to
prioritizing agents in real-time, showcasing remarkable resilience against
dynamic environments. This robust solution was evaluated in various simulated
environments, demonstrating adaptability and applicability across diverse
scenarios. We observed a substantial improvement of about 25% over the baseline
method, leading the way for future research in resource-constrained robotics.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17437" title="Abstract">arXiv:2309.17437</a> [<a href="/pdf/2309.17437" title="Download PDF">pdf</a>, <a href="/format/2309.17437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Decentralized Flocking Controllers with Spatio-Temporal Graph  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siji Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanshen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peihan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lifeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chang-Tien Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently a line of researches has delved the use of graph neural networks
(GNNs) for decentralized control in swarm robotics. However, it has been
observed that relying solely on the states of immediate neighbors is
insufficient to imitate a centralized control policy. To address this
limitation, prior studies proposed incorporating $L$-hop delayed states into
the computation. While this approach shows promise, it can lead to a lack of
consensus among distant flock members and the formation of small clusters,
consequently resulting in the failure of cohesive flocking behaviors. Instead,
our approach leverages spatiotemporal GNN, named STGNN that encompasses both
spatial and temporal expansions. The spatial expansion collects delayed states
from distant neighbors, while the temporal expansion incorporates previous
states from immediate neighbors. The broader and more comprehensive information
gathered from both expansions results in more effective and accurate
predictions. We develop an expert algorithm for controlling a swarm of robots
and employ imitation learning to train our decentralized STGNN model based on
the expert algorithm. We simulate the proposed STGNN approach in various
settings, demonstrating its decentralized capacity to emulate the global expert
algorithm. Further, we implemented our approach to achieve cohesive flocking,
leader following and obstacle avoidance by a group of Crazyflie drones. The
performance of STGNN underscores its potential as an effective and reliable
approach for achieving cohesive flocking, leader following and obstacle
avoidance tasks.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17442" title="Abstract">arXiv:2309.17442</a> [<a href="/pdf/2309.17442" title="Download PDF">pdf</a>, <a href="/ps/2309.17442" title="Download PostScript">ps</a>, <a href="/format/2309.17442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Powertrain Hybridization for Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nazari%2C+S">Shima Nazari</a>, 
<a href="/search/eess?searchtype=author&query=Gowans%2C+N">Norma Gowans</a>, 
<a href="/search/eess?searchtype=author&query=Abtahi%2C+M">Mohammad Abtahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO); Optimization and Control (math.OC)

</div>
<p class="mathjax">The powertrains of today's hybrid electric vehicles (HEVs) are developed for
human drivers and, therefore, may not be the optimum choice for future
Autonomous vehicles (AVs), given that AVs can accurately manipulate their
velocity profile to avoid unnecessary energy loss. In this work, we closely
examine the necessary degree of hybridization for AVs compared to human drivers
by deploying real-world urban driving profiles and generating equivalent AV
drive cycles in a mixed autonomy scenario. We solve the optimal energy
management problem for HEVs with various motor sizes from the automotive
market, and demonstrate that while human drivers typically require a motor size
of around 30 kW to fully benefit from hybridization, AVs can achieve similar
gains with only a 12 kW motor. This greater benefit from a smaller motor size
can be attributed to a more optimal torque request, allowing for higher gains
from regenerative braking and a more efficient engine operation. Furthermore,
We investigate the benefits of velocity smoothing for both traditional cars and
HEVs and explore the role of different mechanisms contributing to fuel
consumption reduction. Our analysis reveals that velocity smoothing provides
greater benefits to HEVs equipped with small motors compared to non-hybrid
vehicles and HEVs with larger motors.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17444" title="Abstract">arXiv:2309.17444</a> [<a href="/pdf/2309.17444" title="Download PDF">pdf</a>, <a href="/format/2309.17444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-grounded Video Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lian%2C+L">Long Lian</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Baifeng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yala%2C+A">Adam Yala</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://llm-grounded-video-diffusion.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Text-conditioned diffusion models have emerged as a promising tool for neural
video generation. However, current models still struggle with intricate
spatiotemporal prompts and often generate restricted or incorrect motion (e.g.,
even lacking the ability to be prompted for objects moving from left to right).
To address these limitations, we introduce LLM-grounded Video Diffusion (LVD).
Instead of directly generating videos from the text inputs, LVD first leverages
a large language model (LLM) to generate dynamic scene layouts based on the
text inputs and subsequently uses the generated layouts to guide a diffusion
model for video generation. We show that LLMs are able to understand complex
spatiotemporal dynamics from text alone and generate layouts that align closely
with both the prompts and the object motion patterns typically observed in the
real world. We then propose to guide video diffusion models with these layouts
by adjusting the attention maps. Our approach is training-free and can be
integrated into any video diffusion model that admits classifier guidance. Our
results demonstrate that LVD significantly outperforms its base video diffusion
model and several strong baseline methods in faithfully generating videos with
the desired attributes and motion patterns.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17446" title="Abstract">arXiv:2309.17446</a> [<a href="/pdf/2309.17446" title="Download PDF">pdf</a>, <a href="/format/2309.17446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L2CEval: Evaluating Language-to-Code Generation Capabilities of Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+A">Ansong Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+P">Pengcheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yilun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Riddell%2C+M">Martin Riddell</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Troy Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+R">Rui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Stephen Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+S">Semih Yavuz</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yingbo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+D">Dragomir Radev</a>, 
<a href="/search/cs?searchtype=author&query=Cohan%2C+A">Arman Cohan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Website: <a href="https://l2c-eval.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Recently, large language models (LLMs), especially those that are pretrained
on code, have demonstrated strong capabilities in generating programs from
natural language inputs in a few-shot or even zero-shot manner. Despite
promising results, there is a notable lack of a comprehensive evaluation of
these models language-to-code generation capabilities. Existing studies often
focus on specific tasks, model architectures, or learning paradigms, leading to
a fragmented understanding of the overall landscape. In this work, we present
L2CEval, a systematic evaluation of the language-to-code generation
capabilities of LLMs on 7 tasks across the domain spectrum of semantic parsing,
math reasoning and Python programming, analyzing the factors that potentially
affect their performance, such as model size, pretraining data, instruction
tuning, and different prompting methods. In addition to assessing model
performance, we measure confidence calibration for the models and conduct human
evaluations of the output programs. This enables us to identify and analyze the
typical failure modes across various tasks and models. L2CEval offers a
comprehensive understanding of the capabilities and limitations of LLMs in
language-to-code generation. We also release the evaluation framework and all
model outputs, hoping to lay the groundwork for further future research in this
domain.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17447" title="Abstract">arXiv:2309.17447</a> [<a href="/pdf/2309.17447" title="Download PDF">pdf</a>, <a href="/format/2309.17447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large Language Model Approach to Educational Survey Feedback Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parker%2C+M+J">Michael J. Parker</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C">Caitlin Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+C">Claire Stone</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+Y">YeaRim Oh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper assesses the potential for the large language models (LLMs) GPT-4
and GPT-3.5 to aid in deriving insight from education feedback surveys.
Exploration of LLM use cases in education has focused on teaching and learning,
with less exploration of capabilities in education feedback analysis. Survey
analysis in education involves goals such as finding gaps in curricula or
evaluating teachers, often requiring time-consuming manual processing of
textual responses. LLMs have the potential to provide a flexible means of
achieving these goals without specialized machine learning models or
fine-tuning. We demonstrate a versatile approach to such goals by treating them
as sequences of natural language processing (NLP) tasks including
classification (multi-label, multi-class, and binary), extraction, thematic
analysis, and sentiment analysis, each performed by LLM. We apply these
workflows to a real-world dataset of 2500 end-of-course survey comments from
biomedical science courses, and evaluate a zero-shot approach (i.e., requiring
no examples or labeled training data) across all tasks, reflecting education
settings, where labeled data is often scarce. By applying effective prompting
practices, we achieve human-level performance on multiple tasks with GPT-4,
enabling workflows necessary to achieve typical goals. We also show the
potential of inspecting LLMs' chain-of-thought (CoT) reasoning for providing
insight that may foster confidence in practice. Moreover, this study features
development of a versatile set of classification categories, suitable for
various course types (online, hybrid, or in-person) and amenable to
customization. Our results suggest that LLMs can be used to derive a range of
insights from survey text.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17448" title="Abstract">arXiv:2309.17448</a> [<a href="/pdf/2309.17448" title="Download PDF">pdf</a>, <a href="/format/2309.17448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMPLer-X: Scaling Up Expressive Human Pose and Shape Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wanqi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Ailing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qingping Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+H+E">Hui En Pang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Haiyi Mei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Homepage: <a href="https://caizhongang.github.io/projects/SMPLer-X/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Expressive human pose and shape estimation (EHPS) unifies body, hands, and
face motion capture with numerous applications. Despite encouraging progress,
current state-of-the-art methods still depend largely on confined training
datasets. In this work, we investigate scaling up EHPS towards the first
generalist foundation model (dubbed SMPLer-X), with up to ViT-Huge as the
backbone and training with up to 4.5M instances from diverse data sources. With
big data and the large model, SMPLer-X exhibits strong performance across
diverse test benchmarks and excellent transferability to even unseen
environments. 1) For the data scaling, we perform a systematic investigation on
32 EHPS datasets, encompassing a wide range of scenarios that a model trained
on any single dataset cannot handle. More importantly, capitalizing on insights
obtained from the extensive benchmarking process, we optimize our training
scheme and select datasets that lead to a significant leap in EHPS
capabilities. 2) For the model scaling, we take advantage of vision
transformers to study the scaling law of model sizes in EHPS. Moreover, our
finetuning strategy turn SMPLer-X into specialist models, allowing them to
achieve further performance boosts. Notably, our foundation model SMPLer-X
consistently delivers state-of-the-art results on seven benchmarks such as
AGORA (107.2 mm NMVE), UBody (57.4 mm PVE), EgoBody (63.6 mm PVE), and EHF
(62.3 mm PVE without finetuning).
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17450" title="Abstract">arXiv:2309.17450</a> [<a href="/pdf/2309.17450" title="Download PDF">pdf</a>, <a href="/format/2309.17450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task View Synthesis with Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuhong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Z">Zhipeng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Hebert%2C+M">Martial Hebert</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Website: <a href="https://zsh2000.github.io/mtvs.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-task visual learning is a critical aspect of computer vision. Current
research, however, predominantly concentrates on the multi-task dense
prediction setting, which overlooks the intrinsic 3D world and its multi-view
consistent structures, and lacks the capability for versatile imagination. In
response to these limitations, we present a novel problem setting -- multi-task
view synthesis (MTVS), which reinterprets multi-task prediction as a set of
novel-view synthesis tasks for multiple scene properties, including RGB. To
tackle the MTVS problem, we propose MuvieNeRF, a framework that incorporates
both multi-task and cross-view knowledge to simultaneously synthesize multiple
scene properties. MuvieNeRF integrates two key modules, the Cross-Task
Attention (CTA) and Cross-View Attention (CVA) modules, enabling the efficient
use of information across multiple views and tasks. Extensive evaluation on
both synthetic and realistic benchmarks demonstrates that MuvieNeRF is capable
of simultaneously synthesizing different scene properties with promising visual
quality, even outperforming conventional discriminative models in various
settings. Notably, we show that MuvieNeRF exhibits universal applicability
across a range of NeRF backbones. Our code is available at
https://github.com/zsh2000/MuvieNeRF.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17452" title="Abstract">arXiv:2309.17452</a> [<a href="/pdf/2309.17452" title="Download PDF">pdf</a>, <a href="/format/2309.17452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gou%2C+Z">Zhibin Gou</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhihong Shao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yeyun Gong</a>, 
<a href="/search/cs?searchtype=author&query=shen%2C+y">yelong shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors equal contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models have made significant progress in various language
tasks, yet they still struggle with complex mathematics. In this paper, we
propose ToRA a series of Tool-integrated Reasoning Agents designed to solve
challenging mathematical problems by seamlessly integrating natural language
reasoning with the utilization of external tools (e.g., computation libraries
and symbolic solvers), thereby amalgamating the analytical prowess of language
and the computational efficiency of tools. To train ToRA, we curate interactive
tool-use trajectories on mathematical datasets, apply imitation learning on the
annotations, and propose output space shaping to further refine models'
reasoning behavior. As a result, ToRA models significantly outperform
open-source models on 10 mathematical reasoning datasets across all scales with
13%-19% absolute improvements on average. Notably, ToRA-7B reaches 44.6% on the
competition-level dataset MATH, surpassing the best open-source model
WizardMath-70B by 22% absolute. ToRA-34B is also the first open-source model
that achieves an accuracy exceeding 50% on MATH, which significantly
outperforms GPT-4's CoT result, and is competitive with GPT-4 solving problems
with programs. Additionally, we conduct a comprehensive analysis of the
benefits and remaining challenges of tool interaction for mathematical
reasoning, providing valuable insights for future research.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17453" title="Abstract">arXiv:2309.17453</a> [<a href="/pdf/2309.17453" title="Download PDF">pdf</a>, <a href="/format/2309.17453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Streaming Language Models with Attention Sinks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+G">Guangxuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beidi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Mike Lewis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deploying Large Language Models (LLMs) in streaming applications such as
multi-round dialogue, where long interactions are expected, is urgently needed
but poses two major challenges. Firstly, during the decoding stage, caching
previous tokens' Key and Value states (KV) consumes extensive memory. Secondly,
popular LLMs cannot generalize to longer texts than the training sequence
length. Window attention, where only the most recent KVs are cached, is a
natural approach -- but we show that it fails when the text length surpasses
the cache size. We observe an interesting phenomenon, namely attention sink,
that keeping the KV of initial tokens will largely recover the performance of
window attention. In this paper, we first demonstrate that the emergence of
attention sink is due to the strong attention scores towards initial tokens as
a ``sink'' even if they are not semantically important. Based on the above
analysis, we introduce StreamingLLM, an efficient framework that enables LLMs
trained with a finite length attention window to generalize to infinite
sequence lengths without any fine-tuning. We show that StreamingLLM can enable
Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language
modeling with up to 4 million tokens and more. In addition, we discover that
adding a placeholder token as a dedicated attention sink during pre-training
can further improve streaming deployment. In streaming settings, StreamingLLM
outperforms the sliding window recomputation baseline by up to 22.2x speedup.
Code and datasets are provided at https://github.com/mit-han-lab/streaming-llm.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon,  2 Oct 23</h3>
<dl>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16678" title="Abstract">arXiv:2309.16678</a> (cross-list from econ.GN) [<a href="/pdf/2309.16678" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Water Markets as a Coping Mechanism for Climate-Induced Water Changes on  the Canadian Economy: A Computable General Equilibrium Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Garcia-Hernandez%2C+J">Jorge Garcia-Hernandez</a>, 
<a href="/search/econ?searchtype=author&query=Brouwer%2C+R">Roy Brouwer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Water markets represent a policy tool that aims at finding efficient water
allocations among competing users by promoting reallocations from low-value to
high-value uses. In Canada, water markets have been discussed and implemented
at the provincial level; however, at the national level a study about the
economic benefits of its implementation is still lacking. This paper fills this
void by implementing a water market in Canada and examine how water endowment
shocks would affect the economy under the assumptions of general equilibrium
theory. Our results show a water market would damp the economic loss in case of
reductions in water endowment, but it also cuts back on the economic expansion
that would follow from an increase on it. These results provide new insights on
the subject and will provide a novel look and reinvigorate informed discussions
on the use of water markets in Canada as a potential tool to cope with
climate-induced water supply changes.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16679" title="Abstract">arXiv:2309.16679</a> (cross-list from q-fin.PM) [<a href="/pdf/2309.16679" title="Download PDF">pdf</a>, <a href="/format/2309.16679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Deep Learning and Online Source Sentiment for Financial  Portfolio Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Nousi%2C+P">Paraskevi Nousi</a>, 
<a href="/search/q-fin?searchtype=author&query=Avramelou%2C+L">Loukia Avramelou</a>, 
<a href="/search/q-fin?searchtype=author&query=Rodinos%2C+G">Georgios Rodinos</a>, 
<a href="/search/q-fin?searchtype=author&query=Tzelepi%2C+M">Maria Tzelepi</a>, 
<a href="/search/q-fin?searchtype=author&query=Manousis%2C+T">Theodoros Manousis</a>, 
<a href="/search/q-fin?searchtype=author&query=Tsampazis%2C+K">Konstantinos Tsampazis</a>, 
<a href="/search/q-fin?searchtype=author&query=Stefanidis%2C+K">Kyriakos Stefanidis</a>, 
<a href="/search/q-fin?searchtype=author&query=Spanos%2C+D">Dimitris Spanos</a>, 
<a href="/search/q-fin?searchtype=author&query=Kirtas%2C+E">Emmanouil Kirtas</a>, 
<a href="/search/q-fin?searchtype=author&query=Tosidis%2C+P">Pavlos Tosidis</a>, 
<a href="/search/q-fin?searchtype=author&query=Tsantekidis%2C+A">Avraam Tsantekidis</a>, 
<a href="/search/q-fin?searchtype=author&query=Passalis%2C+N">Nikolaos Passalis</a>, 
<a href="/search/q-fin?searchtype=author&query=Tefas%2C+A">Anastasios Tefas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Financial portfolio management describes the task of distributing funds and
conducting trading operations on a set of financial assets, such as stocks,
index funds, foreign exchange or cryptocurrencies, aiming to maximize the
profit while minimizing the loss incurred by said operations. Deep Learning
(DL) methods have been consistently excelling at various tasks and automated
financial trading is one of the most complex one of those. This paper aims to
provide insight into various DL methods for financial trading, under both the
supervised and reinforcement learning schemes. At the same time, taking into
consideration sentiment information regarding the traded assets, we discuss and
demonstrate their usefulness through corresponding research studies. Finally,
we discuss commonly found problems in training such financial agents and equip
the reader with the necessary knowledge to avoid these problems and apply the
discussed methods in practice.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16684" title="Abstract">arXiv:2309.16684</a> (cross-list from q-bio.BM) [<a href="/pdf/2309.16684" title="Download PDF">pdf</a>, <a href="/format/2309.16684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Side Information for Ligand Conformation Generation using  Diffusion-Based Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+J">Jiamin Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Cao%2C+H">He Cao</a>, 
<a href="/search/q-bio?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Ligand molecule conformation generation is a critical challenge in drug
discovery. Deep learning models have been developed to tackle this problem,
particularly through the use of generative models in recent years. However,
these models often generate conformations that lack meaningful structure and
randomness due to the absence of essential side information. Examples of such
side information include the chemical and geometric features of the target
protein, ligand-target compound interactions, and ligand chemical properties.
Without these constraints, the generated conformations may not be suitable for
further selection and design of new drugs. To address this limitation, we
propose a novel method for generating ligand conformations that leverage side
information and incorporate flexible constraints into standard diffusion
models. Drawing inspiration from the concept of message passing, we introduce
ligand-target massage passing block, a mechanism that facilitates the exchange
of information between target nodes and ligand nodes, thereby incorporating
target node features. To capture non-covalent interactions, we introduce
ligand-target compound inter and intra edges. To further improve the biological
relevance of the generated conformations, we train energy models using scalar
chemical features. These models guide the progress of the standard Denoising
Diffusion Probabilistic Models, resulting in more biologically meaningful
conformations. We evaluate the performance of SIDEGEN using the PDBBind-2020
dataset, comparing it against other methods. The results demonstrate
improvements in both Aligned RMSD and Ligand RMSD evaluations. Specifically,
our model outperforms GeoDiff (trained on PDBBind-2020) by 20% in terms of the
median aligned RMSD metric.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16685" title="Abstract">arXiv:2309.16685</a> (cross-list from q-bio.BM) [<a href="/pdf/2309.16685" title="Download PDF">pdf</a>, <a href="/format/2309.16685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-aware Variational Auto-encoders for Ligand Generation with  Multimodal Protein Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ngo%2C+N+K">Nhat Khang Ngo</a>, 
<a href="/search/q-bio?searchtype=author&query=Hy%2C+T+S">Truong Son Hy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Without knowledge of specific pockets, generating ligands based on the global
structure of a protein target plays a crucial role in drug discovery as it
helps reduce the search space for potential drug-like candidates in the
pipeline. However, contemporary methods require optimizing tailored networks
for each protein, which is arduous and costly. To address this issue, we
introduce TargetVAE, a target-aware variational auto-encoder that generates
ligands with high binding affinities to arbitrary protein targets, guided by a
novel multimodal deep neural network built based on graph Transformers as the
prior for the generative model. This is the first effort to unify different
representations of proteins (e.g., sequence of amino-acids, 3D structure) into
a single model that we name as Protein Multimodal Network (PMN). Our multimodal
architecture learns from the entire protein structures and is able to capture
their sequential, topological and geometrical information. We showcase the
superiority of our approach by conducting extensive experiments and
evaluations, including the assessment of generative model quality, ligand
generation for unseen targets, docking score computation, and binding affinity
prediction. Empirical results demonstrate the promising performance of our
proposed approach. Our software package is publicly available at
https://github.com/HySonLab/Ligand_Generation
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16693" title="Abstract">arXiv:2309.16693</a> (cross-list from q-bio.BM) [<a href="/pdf/2309.16693" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extension of Transformational Machine Learning: Classification Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Mahmud%2C+A">Adnan Mahmud</a>, 
<a href="/search/q-bio?searchtype=author&query=Orhobor%2C+O">Oghenejokpeme Orhobor</a>, 
<a href="/search/q-bio?searchtype=author&query=King%2C+R+D">Ross D. King</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study explores the application and performance of Transformational
Machine Learning (TML) in drug discovery. TML, a meta learning algorithm,
excels in exploiting common attributes across various domains, thus developing
composite models that outperform conventional models. The drug discovery
process, which is complex and time-consuming, can benefit greatly from the
enhanced prediction accuracy, improved interpretability and greater
generalizability provided by TML. We explore the efficacy of different machine
learning classifiers, where no individual classifier exhibits distinct
superiority, leading to the consideration of ensemble classifiers such as the
Random Forest.
<br />Our findings show that TML outperforms base Machine Learning (ML) as the
number of training datasets increases, due to its capacity to better
approximate the correct hypothesis, overcome local optima, and expand the space
of representable functions by combining separate classifiers capabilities.
However, this superiority is relative to the resampling methods applied, with
Near Miss demonstrating poorer performance due to noisy data, overlapping
classes, and nonlinear class boundaries. Conversely, Random Over Sampling (ROS)
provides a more robust performance given its resistance to noise and outliers,
improved class overlap management, and suitability for nonlinear class
boundaries.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16696" title="Abstract">arXiv:2309.16696</a> (cross-list from eess.SP) [<a href="/pdf/2309.16696" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 170-260 GHz Sub-THz Optical Heterodyne Analog Radio-over-Fiber Link for  6G Wireless System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Delmade%2C+A">Amol Delmade</a>, 
<a href="/search/eess?searchtype=author&query=Kearney%2C+A">Alison Kearney</a>, 
<a href="/search/eess?searchtype=author&query=Nellen%2C+S">Simon Nellen</a>, 
<a href="/search/eess?searchtype=author&query=Kohlhaas%2C+R+B">Robert B. Kohlhaas</a>, 
<a href="/search/eess?searchtype=author&query=Browning%2C+C">Colm Browning</a>, 
<a href="/search/eess?searchtype=author&query=Schell%2C+M">Martin Schell</a>, 
<a href="/search/eess?searchtype=author&query=Smyth%2C+F">Frank Smyth</a>, 
<a href="/search/eess?searchtype=author&query=Barry%2C+L">Liam Barry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The frequency and phase fluctuations of free-running lasers limit the
performance of optical heterodyne sub-THz systems - especially for low
subcarrier spacing OFDM signals. Digital impairment compensation is implemented
here for the successful generation of 170 - 260 GHz sub-THz OFDM signals over
10km analog-RoF link.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16704" title="Abstract">arXiv:2309.16704</a> (cross-list from q-bio.NC) [<a href="/pdf/2309.16704" title="Download PDF">pdf</a>, <a href="/format/2309.16704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memories in the Making: Predicting Video Memorability with Encoding  Phase EEG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Sweeney%2C+L">Lorin Sweeney</a>, 
<a href="/search/q-bio?searchtype=author&query=Healy%2C+G">Graham Healy</a>, 
<a href="/search/q-bio?searchtype=author&query=Smeaton%2C+A+F">Alan F. Smeaton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Content-Based Multimedia Indexing, CBMI, September 20-22, Orleans, France, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)

</div>
<p class="mathjax">In a world of ephemeral moments, our brain diligently sieves through a
cascade of experiences, like a skilled gold prospector searching for precious
nuggets amidst the river's relentless flow. This study delves into the elusive
"moment of memorability" -- a fleeting, yet vital instant where experiences are
prioritised for consolidation in our memory. By transforming subjects' encoding
phase electroencephalography (EEG) signals into the visual domain using
scaleograms and leveraging deep learning techniques, we investigate the neural
signatures that underpin this moment, with the aim of predicting
subject-specific recognition of video. Our findings not only support the
involvement of theta band (4-8Hz) oscillations over the right temporal lobe in
the encoding of declarative memory, but also support the existence of a
distinct moment of memorability, akin to the gold nuggets that define our
personal river of experiences.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16709" title="Abstract">arXiv:2309.16709</a> (cross-list from eess.SP) [<a href="/pdf/2309.16709" title="Download PDF">pdf</a>, <a href="/format/2309.16709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Task Offloading and Resource Allocation in Aerial-Terrestrial UAV  Networks with Edge and Fog Computing for Post-Disaster Rescue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+G">Geng Sun</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+L">Long He</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zemin Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jiahui Li</a>, 
<a href="/search/eess?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/eess?searchtype=author&query=Leung%2C+V+C+M">Victor C. M. Leung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Science and Game Theory (cs.GT); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Unmanned aerial vehicles (UAVs) play an increasingly important role in
assisting fast-response post-disaster rescue due to their fast deployment,
flexible mobility, and low cost. However, UAVs face the challenges of limited
battery capacity and computing resources, which could shorten the expected
flight endurance of UAVs and increase the rescue response delay during
performing mission-critical tasks. To address this challenge, we first present
a three-layer post-disaster rescue computing architecture by leveraging the
aerial-terrestrial edge capabilities of mobile edge computing (MEC) and vehicle
fog computing (VFC), which consists of a vehicle fog layer, a UAV client layer,
and a UAV edge layer. Moreover, we formulate a joint task offloading and
resource allocation optimization problem (JTRAOP) with the aim of maximizing
the time-average system utility. Since the formulated JTRAOP is proved to be
NP-hard, we propose an MEC-VFC-aided task offloading and resource allocation
(MVTORA) approach, which consists of a game theoretic algorithm for task
offloading decision, a convex optimization-based algorithm for MEC resource
allocation, and an evolutionary computation-based hybrid algorithm for VFC
resource allocation. Simulation results validate that the proposed approach can
achieve superior system performance compared to the other benchmark schemes,
especially under heavy system workloads.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16725" title="Abstract">arXiv:2309.16725</a> (cross-list from physics.comp-ph) [<a href="/pdf/2309.16725" title="Download PDF">pdf</a>, <a href="/format/2309.16725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Solution of The Stationary Fokker-Plank Equation for a  Class of Nonlinear Dynamical Systems: An Evaluation Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Alhussein%2C+H">Hussam Alhussein</a>, 
<a href="/search/physics?searchtype=author&query=Khasawneh%2C+M">Mohammed Khasawneh</a>, 
<a href="/search/physics?searchtype=author&query=Daqaq%2C+M+F">Mohammed F. Daqaq</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">The Fokker-Planck (FP) equation is a linear partial differential equation
which governs the temporal and spatial evolution of the probability density
function (PDF) associated with the response of stochastic dynamical systems. An
exact analytical solution of the FP equation is only available for a limited
subset of dynamical systems. Semi-analytical methods are available for larger,
yet still a small subset of systems, while traditional computational methods;
e.g. Finite Elements and Finite Difference require dividing the computational
domain into a grid of discrete points, which incurs significant computational
costs for high-dimensional systems. Physics-informed learning offers a
potentially powerful alternative to traditional computational schemes. To
evaluate its potential, we present a data-free, physics-informed neural network
(PINN) framework to solve the FP equation for a class of nonlinear stochastic
dynamical systems. In particular, through several examples concerning the
stochastic response of the Duffing, Van der Pol, and the Duffing-Van der Pol
oscillators, we assess the ability and accuracy of the PINN framework in $i)$
predicting the PDF under the combined effect of additive and multiplicative
noise, $ii)$ capturing P-bifurcations of the PDF, and $iii)$ effectively
treating high-dimensional systems. Through comparisons with Monte-Carlo
simulations and the available literature, we show that PINN can effectively
address all of the afore-described points. We also demonstrate that the
computational time associated with the PINN solution can be substantially
reduced by using transfer learning.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16858" title="Abstract">arXiv:2309.16858</a> (cross-list from stat.ML) [<a href="/pdf/2309.16858" title="Download PDF">pdf</a>, <a href="/format/2309.16858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp Generalization of Transductive Learning: A Transductive Local  Rademacher Complexity Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yang%2C+Y">Yingzhen Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a new tool, Transductive Local Rademacher Complexity (TLRC), to
analyze the generalization performance of transductive learning methods and
motivate new transductive learning algorithms. Our work extends the idea of the
popular Local Rademacher Complexity (LRC) to the transductive setting with
considerable changes compared to the analysis of typical LRC methods in the
inductive setting. We present a localized version of Rademacher complexity
based tool wihch can be applied to various transductive learning problems and
gain sharp bounds under proper conditions. Similar to the development of LRC,
we build TLRC by starting from a sharp concentration inequality for independent
variables with variance information. The prediction function class of a
transductive learning model is then divided into pieces with a sub-root
function being the upper bound for the Rademacher complexity of each piece, and
the variance of all the functions in each piece is limited. A carefully
designed variance operator is used to ensure that the bound for the test loss
on unlabeled test data in the transductive setting enjoys a remarkable
similarity to that of the classical LRC bound in the inductive setting. We use
the new TLRC tool to analyze the Transductive Kernel Learning (TKL) model,
where the labels of test data are generated by a kernel function. The result of
TKL lays the foundation for generalization bounds for two types of transductive
learning tasks, Graph Transductive Learning (GTL) and Transductive
Nonparametric Kernel Regression (TNKR). When the target function is
low-dimensional or approximately low-dimensional, we design low rank methods
for both GTL and TNKR, which enjoy particularly sharper generalization bounds
by TLRC which cannot be achieved by existing learning theory methods, to the
best of our knowledge.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16867" title="Abstract">arXiv:2309.16867</a> (cross-list from eess.AS) [<a href="/pdf/2309.16867" title="Download PDF">pdf</a>, <a href="/format/2309.16867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards High Resolution Weather Monitoring with Sound Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=%C3%87oban%2C+E+B">Enis Berk &#xc7;oban</a>, 
<a href="/search/eess?searchtype=author&query=Perra%2C+M">Megan Perra</a>, 
<a href="/search/eess?searchtype=author&query=Mandel%2C+M+I">Michael I. Mandel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Across various research domains, remotely-sensed weather products are
valuable for answering many scientific questions; however, their temporal and
spatial resolutions are often too coarse to answer many questions. For
instance, in wildlife research, it's crucial to have fine-scaled, highly
localized weather observations when studying animal movement and behavior. This
paper harnesses acoustic data to identify variations in rain, wind and air
temperature at different thresholds, with rain being the most successfully
predicted. Training a model solely on acoustic data yields optimal results, but
it demands labor-intensive sample labeling. Meanwhile, hourly satellite data
from the MERRA-2 system, though sufficient for certain tasks, produced
predictions that were notably less accurate in predict these acoustic labels.
We find that acoustic classifiers can be trained from the MERRA-2 data that are
more accurate than the raw MERRA-2 data itself. By using MERRA-2 to roughly
identify rain in the acoustic data, we were able to produce a functional model
without using human-validated labels. Since MERRA-2 has global coverage, our
method offers a practical way to train rain models using acoustic datasets
around the world.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16951" title="Abstract">arXiv:2309.16951</a> (cross-list from stat.ML) [<a href="/pdf/2309.16951" title="Download PDF">pdf</a>, <a href="/format/2309.16951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Water quality prediction using machine learning and neural network  approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+Y">Yinpu Li</a>, 
<a href="/search/stat?searchtype=author&query=Mao%2C+S">Siqi Mao</a>, 
<a href="/search/stat?searchtype=author&query=Yuan%2C+Y">Yaping Yuan</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Z">Ziren Wang</a>, 
<a href="/search/stat?searchtype=author&query=Kang%2C+Y">Yixin Kang</a>, 
<a href="/search/stat?searchtype=author&query=Yao%2C+Y">Yuanxin Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Water resources serve as the cornerstone of human livelihoods and economic
progress, with intrinsic links to both public health and environmental
well-being. The accurate prediction of water quality stands as a pivotal factor
in enhancing water resource management and combating pollution. This research,
employing diverse performance metrics, assesses the efficacy of five distinct
models, namely, linear regression, Random Forest, XGBoost, LightGBM, and MLP
neural network, in forecasting pH values within Georgia, USA. Concurrently,
LightGBM attains the highest average precision among all models examined.
Tree-based models underscore their supremacy in addressing regression
challenges. Furthermore, the performance of MLP neural network is sensitive to
feature scaling. Additionally, we expound upon and dissect the reasons behind
the superior precision of the machine learning models when they are compared to
the original study, which factors in time dependencies and spatial
considerations. The primary objective of this endeavor is to establish a robust
predictive pipeline, specifically tailored for practical applications. It
caters not only to individuals well-versed in the realm of data science but
also to those lacking specialization in particular application domains. In
essence, we offer a fresh perspective for achieving relative precision in data
science methodologies, emphasizing both prediction accuracy and
interpretability.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16953" title="Abstract">arXiv:2309.16953</a> (cross-list from eess.AS) [<a href="/pdf/2309.16953" title="Download PDF">pdf</a>, <a href="/format/2309.16953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Code-switching Speech Recognition with Interactive Language  Biases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Hexin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Garcia%2C+L+P">Leibny Paola Garcia</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Khong%2C+A+W+H">Andy W. H. Khong</a>, 
<a href="/search/eess?searchtype=author&query=Khudanpur%2C+S">Sanjeev Khudanpur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Languages usually switch within a multilingual speech signal, especially in a
bilingual society. This phenomenon is referred to as code-switching (CS),
making automatic speech recognition (ASR) challenging under a multilingual
scenario. We propose to improve CS-ASR by biasing the hybrid CTC/attention ASR
model with multi-level language information comprising frame- and token-level
language posteriors. The interaction between various resolutions of language
biases is subsequently explored in this work. We conducted experiments on
datasets from the ASRU 2019 code-switching challenge. Compared to the baseline,
the proposed interactive language biases (ILB) method achieves higher
performance and ablation studies highlight the effects of different language
biases and their interactions. In addition, the results presented indicate that
language bias implicitly enhances internal language modeling, leading to
performance degradation after employing an external language model.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16954" title="Abstract">arXiv:2309.16954</a> (cross-list from eess.AS) [<a href="/pdf/2309.16954" title="Download PDF">pdf</a>, <a href="/format/2309.16954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Speech Detection Based on Temporal Consistency and  Distribution of Speaker Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhuo Li</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jingze Lu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wenchao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+P">Pengyuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Current synthetic speech detection (SSD) methods perform well on certain
datasets but still face issues of robustness and interpretability. A possible
reason is that these methods do not analyze the deficiencies of synthetic
speech. In this paper, the flaws of the speaker features inherent in the
text-to-speech (TTS) process are analyzed. Differences in the temporal
consistency of intra-utterance speaker features arise due to the lack of
fine-grained control over speaker features in TTS. Since the speaker
representations in TTS are based on speaker embeddings extracted by encoders,
the distribution of inter-utterance speaker features differs between synthetic
and bonafide speech. Based on these analyzes, an SSD method based on temporal
consistency and distribution of speaker features is proposed. On one hand,
modeling the temporal consistency of intra-utterance speaker features can aid
speech anti-spoofing. On the other hand, distribution differences in
inter-utterance speaker features can be utilized for SSD. The proposed method
offers low computational complexity and performs well in both cross-dataset and
silence trimming scenarios.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16965" title="Abstract">arXiv:2309.16965</a> (cross-list from stat.ML) [<a href="/pdf/2309.16965" title="Download PDF">pdf</a>, <a href="/format/2309.16965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling Continuous Relaxation for Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ichikawa%2C+Y">Yuma Ichikawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO); Methodology (stat.ME)

</div>
<p class="mathjax">Recent advancements in combinatorial optimization (CO) problems emphasize the
potential of graph neural networks (GNNs). The physics-inspired GNN (PI-GNN)
solver, which finds approximate solutions through unsupervised learning, has
attracted significant attention for large-scale CO problems. Nevertheless,
there has been limited discussion on the performance of the PI-GNN solver for
CO problems on relatively dense graphs where the performance of greedy
algorithms worsens. In addition, since the PI-GNN solver employs a relaxation
strategy, an artificial transformation from the continuous space back to the
original discrete space is necessary after learning, potentially undermining
the robustness of the solutions. This paper numerically demonstrates that the
PI-GNN solver can be trapped in a local solution, where all variables are zero,
in the early stage of learning for CO problems on the dense graphs. Then, we
address these problems by controlling the continuity and discreteness of
relaxed variables while avoiding the local solution: (i) introducing a new
penalty term that controls the continuity and discreteness of the relaxed
variables and eliminates the local solution; (ii) proposing a new continuous
relaxation annealing (CRA) strategy. This new annealing first prioritizes
continuous solutions and intensifies exploration by leveraging the continuity
while avoiding the local solution and then schedules the penalty term for
prioritizing a discrete solution until the relaxed variables are almost
discrete values, which eliminates the need for an artificial transformation
from the continuous to the original discrete space. Empirically, better results
are obtained for CO problems on the dense graphs, where the PI-GNN solver
struggles to find reasonable solutions, and for those on relatively sparse
graphs. Furthermore, the computational time scaling is identical to that of the
PI-GNN solver.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16972" title="Abstract">arXiv:2309.16972</a> (cross-list from quant-ph) [<a href="/pdf/2309.16972" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantum States Preparation Method Based on Difference-Driven  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+W">Wenjie Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+B">Bosi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Spin, 2023, online
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">Due to the large state space of the two-qubit system, and the adoption of
ladder reward function in the existing quantum state preparation methods, the
convergence speed is slow and it is difficult to prepare the desired target
quantum state with high fidelity under limited conditions. To solve the above
problems, a difference-driven reinforcement learning (RL) algorithm for quantum
state preparation of two-qubit system is proposed by improving the reward
function and action selection strategy. Firstly, a model is constructed for the
problem of preparing quantum states of a two-qubit system, with restrictions on
the type of quantum gates and the time for quantum state evolution. In the
preparation process, a weighted differential dynamic reward function is
designed to assist the algorithm quickly obtain the maximum expected cumulative
reward. Then, an adaptive e-greedy action selection strategy is adopted to
achieve a balance between exploration and utilization to a certain extent,
thereby improving the fidelity of the final quantum state. The simulation
results show that the proposed algorithm can prepare quantum state with high
fidelity under limited conditions. Compared with other algorithms, it has
different degrees of improvement in convergence speed and fidelity of the final
quantum state.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16979" title="Abstract">arXiv:2309.16979</a> (cross-list from quant-ph) [<a href="/pdf/2309.16979" title="Download PDF">pdf</a>, <a href="/format/2309.16979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEMQSim: Highly Memory-Efficient and Modularized Quantum State-Vector  Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+B">Boyuan Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fang%2C+B">Bo Fang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Guan%2C+Q">Qiang Guan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tao%2C+D">Dingwen Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">In this extended abstract, we have introduced a highly memory-efficient state
vector simulation of quantum circuits premised on data compression, harnessing
the capabilities of both CPUs and GPUs. We have elucidated the inherent
challenges in architecting this system, while concurrently proposing our
tailored solutions. Moreover, we have delineated our preliminary implementation
and deliberated upon the potential for integration with other GPU-oriented
simulators. In forthcoming research, we aim to present a more comprehensive set
of results, bolstering the assertion of the efficacy and performance of our
approach.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17008" title="Abstract">arXiv:2309.17008</a> (cross-list from eess.SP) [<a href="/pdf/2309.17008" title="Download PDF">pdf</a>, <a href="/format/2309.17008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Efficient Secure Offloading System Designed via UAV-Mounted  Intelligent Reflecting Surface for Resilience Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+D">Doyoung Kim</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+S">Seongah Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+J">Jinkyu Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">With increasing interest in mmWave and THz communication systems, an unmanned
aerial vehicle (UAV)-mounted intelligent reflecting surface (IRS) has been
suggested as a key enabling technology to establish robust line-of-sight (LoS)
connections with ground nodes owing to their free mobility and high altitude,
especially for emergency and disaster response. This paper investigates a
secure offloading system, where the UAV-mounted IRS assists the offloading
procedures between ground users and an access point (AP) acting as an edge
cloud. In this system, the users except the intended recipients in the
offloading process are considered as potential eavesdroppers. The system aims
to achieve the minimum total energy consumption of battery-limited ground user
devices under constraints for secure offloading accomplishment and operability
of UAV-mounted IRS, which is done by optimizing the transmit power of ground
user devices, the trajectory and phase shift matrix of UAV-mounted IRS, and the
offloading ratio between local execution and edge computing based on the
successive convex approximation (SCA) algorithms. Numerical results show that
the proposed algorithm can provide the considerable energy savings compared
with local execution and partial optimizations.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17020" title="Abstract">arXiv:2309.17020</a> (cross-list from eess.AS) [<a href="/pdf/2309.17020" title="Download PDF">pdf</a>, <a href="/format/2309.17020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Resource Self-Supervised Learning with SSL-Enhanced TTS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hsu%2C+P">Po-chun Hsu</a>, 
<a href="/search/eess?searchtype=author&query=Elkahky%2C+A">Ali Elkahky</a>, 
<a href="/search/eess?searchtype=author&query=Hsu%2C+W">Wei-Ning Hsu</a>, 
<a href="/search/eess?searchtype=author&query=Adi%2C+Y">Yossi Adi</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+T+A">Tu Anh Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Copet%2C+J">Jade Copet</a>, 
<a href="/search/eess?searchtype=author&query=Dupoux%2C+E">Emmanuel Dupoux</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>, 
<a href="/search/eess?searchtype=author&query=Mohamed%2C+A">Abdelrahman Mohamed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Self-supervised learning (SSL) techniques have achieved remarkable results in
various speech processing tasks. Nonetheless, a significant challenge remains
in reducing the reliance on vast amounts of speech data for pre-training. This
paper proposes to address this challenge by leveraging synthetic speech to
augment a low-resource pre-training corpus. We construct a high-quality
text-to-speech (TTS) system with limited resources using SSL features and
generate a large synthetic corpus for pre-training. Experimental results
demonstrate that our proposed approach effectively reduces the demand for
speech data by 90\% with only slight performance degradation. To the best of
our knowledge, this is the first work aiming to enhance low-resource
self-supervised learning in speech processing.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17076" title="Abstract">arXiv:2309.17076</a> (cross-list from eess.IV) [<a href="/pdf/2309.17076" title="Download PDF">pdf</a>, <a href="/format/2309.17076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benefits of mirror weight symmetry for 3D mesh segmentation in  biomedical applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dordiuk%2C+V">Vladislav Dordiuk</a>, 
<a href="/search/eess?searchtype=author&query=Dzhigil%2C+M">Maksim Dzhigil</a>, 
<a href="/search/eess?searchtype=author&query=Ushenin%2C+K">Konstantin Ushenin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> was sent to IEEE conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">3D mesh segmentation is an important task with many biomedical applications.
The human body has bilateral symmetry and some variations in organ positions.
It allows us to expect a positive effect of rotation and inversion invariant
layers in convolutional neural networks that perform biomedical segmentations.
In this study, we show the impact of weight symmetry in neural networks that
perform 3D mesh segmentation. We analyze the problem of 3D mesh segmentation
for pathological vessel structures (aneurysms) and conventional anatomical
structures (endocardium and epicardium of ventricles). Local geometrical
features are encoded as sampling from the signed distance function, and the
neural network performs prediction for each mesh node. We show that weight
symmetry gains from 1 to 3% of additional accuracy and allows decreasing the
number of trainable parameters up to 8 times without suffering the performance
loss if neural networks have at least three convolutional layers. This also
works for very small training sets.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17082" title="Abstract">arXiv:2309.17082</a> (cross-list from hep-lat) [<a href="/pdf/2309.17082" title="Download PDF">pdf</a>, <a href="/format/2309.17082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models as Stochastic Quantization in Lattice Field Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-lat?searchtype=author&query=Wang%2C+L">Lingxiao Wang</a>, 
<a href="/search/hep-lat?searchtype=author&query=Aarts%2C+G">Gert Aarts</a>, 
<a href="/search/hep-lat?searchtype=author&query=Zhou%2C+K">Kai Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 9 figures, comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Lattice (hep-lat)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we establish a direct connection between generative diffusion
models (DMs) and stochastic quantization (SQ). The DM is realized by
approximating the reversal of a stochastic process dictated by the Langevin
equation, generating samples from a prior distribution to effectively mimic the
target distribution. Using numerical simulations, we demonstrate that the DM
can serve as a global sampler for generating quantum lattice field
configurations in two-dimensional $\phi^4$ theory. We demonstrate that DMs can
notably reduce autocorrelation times in the Markov chain, especially in the
critical region where standard Markov Chain Monte-Carlo (MCMC) algorithms
experience critical slowing down. The findings can potentially inspire further
advancements in lattice field theory simulations, in particular in cases where
it is expensive to generate large ensembles.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17120" title="Abstract">arXiv:2309.17120</a> (cross-list from physics.comp-ph) [<a href="/pdf/2309.17120" title="Download PDF">pdf</a>, <a href="/ps/2309.17120" title="Download PostScript">ps</a>, <a href="/format/2309.17120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Direction Preserving Discretizations for Computing Phase-Space  Densities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chappell%2C+D+J">David J. Chappell</a>, 
<a href="/search/physics?searchtype=author&query=Richter%2C+M">Martin Richter</a>, 
<a href="/search/physics?searchtype=author&query=Tanner%2C+G">Gregor Tanner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures, Proceedings of ICNAAM 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Ray flow methods provide efficient tools for modelling wave energy transport
in complex systems at high-frequencies. We compare two Petrov-Galerkin
discretizations of a phase-space boundary integral model for stationary wave
energy densities in two-dimensional domains. The directional dependence is
approximated using a finite set of directions oriented into the domain from the
boundary. The propagation direction can be preserved across multi-component
domains when the directions within the local set for a given region of the
boundary are taken as a subset of a global direction set. In this work we
compare the use of piecewise constant and piecewise linear test functions,
which physically corresponds to the interpolation scheme used when the
transport is in a direction not belonging to the finite global set.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17161" title="Abstract">arXiv:2309.17161</a> (cross-list from q-bio.BM) [<a href="/pdf/2309.17161" title="Download PDF">pdf</a>, <a href="/format/2309.17161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Current Methods for Drug Property Prediction in the Real World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Green%2C+J">Jacob Green</a>, 
<a href="/search/q-bio?searchtype=author&query=Diaz%2C+C+C">Cecilia Cabrera Diaz</a>, 
<a href="/search/q-bio?searchtype=author&query=Jakobs%2C+M+A+H">Maximilian A. H. Jakobs</a>, 
<a href="/search/q-bio?searchtype=author&query=Dimitracopoulos%2C+A">Andrea Dimitracopoulos</a>, 
<a href="/search/q-bio?searchtype=author&query=van+der+Wilk%2C+M">Mark van der Wilk</a>, 
<a href="/search/q-bio?searchtype=author&query=Greenhalgh%2C+R+D">Ryan D. Greenhalgh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Predicting drug properties is key in drug discovery to enable de-risking of
assets before expensive clinical trials, and to find highly active compounds
faster. Interest from the Machine Learning community has led to the release of
a variety of benchmark datasets and proposed methods. However, it remains
unclear for practitioners which method or approach is most suitable, as
different papers benchmark on different datasets and methods, leading to
varying conclusions that are not easily compared. Our large-scale empirical
study links together numerous earlier works on different datasets and methods;
thus offering a comprehensive overview of the existing property classes,
datasets, and their interactions with different methods. We emphasise the
importance of uncertainty quantification and the time and therefore cost of
applying these methods in the drug development decision-making cycle. We
discover that the best method depends on the dataset, and that engineered
features with classical ML methods often outperform deep learning.
Specifically, QSAR datasets are typically best analysed with classical methods
such as Gaussian Processes while ADMET datasets are sometimes better described
by Trees or Deep Learning methods such as Graph Neural Networks or language
models. Our work highlights that practitioners do not yet have a
straightforward, black-box procedure to rely on, and sets the precedent for
creating practitioner-relevant benchmarks. Deep learning approaches must be
proven on these benchmarks to become the practical method of choice in drug
property prediction.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17223" title="Abstract">arXiv:2309.17223</a> (cross-list from eess.IV) [<a href="/pdf/2309.17223" title="Download PDF">pdf</a>, <a href="/format/2309.17223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Glioma subtype classification from histopathological images using  in-domain and out-of-domain transfer learning: An experimental study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Despotovic%2C+V">Vladimir Despotovic</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+S">Sang-Yoon Kim</a>, 
<a href="/search/eess?searchtype=author&query=Hau%2C+A">Ann-Christin Hau</a>, 
<a href="/search/eess?searchtype=author&query=Kakoichankava%2C+A">Aliaksandra Kakoichankava</a>, 
<a href="/search/eess?searchtype=author&query=Klamminger%2C+G+G">Gilbert Georg Klamminger</a>, 
<a href="/search/eess?searchtype=author&query=Borgmann%2C+F+B+K">Felix Bruno Kleine Borgmann</a>, 
<a href="/search/eess?searchtype=author&query=Frauenknecht%2C+K+B+M">Katrin B. M. Frauenknecht</a>, 
<a href="/search/eess?searchtype=author&query=Mittelbronnf%2C+M">Michel Mittelbronnf</a>, 
<a href="/search/eess?searchtype=author&query=Nazarov%2C+P+V">Petr V. Nazarov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We provide in this paper a comprehensive comparison of various transfer
learning strategies and deep learning architectures for computer-aided
classification of adult-type diffuse gliomas. We evaluate the generalizability
of out-of-domain ImageNet representations for a target domain of
histopathological images, and study the impact of in-domain adaptation using
self-supervised and multi-task learning approaches for pretraining the models
using the medium-to-large scale datasets of histopathological images. A
semi-supervised learning approach is furthermore proposed, where the fine-tuned
models are utilized to predict the labels of unannotated regions of the whole
slide images (WSI). The models are subsequently retrained using the
ground-truth labels and weak labels determined in the previous step, providing
superior performance in comparison to standard in-domain transfer learning with
balanced accuracy of 96.91% and F1-score 97.07%, and minimizing the
pathologist's efforts for annotation. Finally, we provide a visualization tool
working at WSI level which generates heatmaps that highlight tumor areas; thus,
providing insights to pathologists concerning the most informative parts of the
WSI.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17240" title="Abstract">arXiv:2309.17240</a> (cross-list from nlin.PS) [<a href="/pdf/2309.17240" title="Download PDF">pdf</a>, <a href="/ps/2309.17240" title="Download PostScript">ps</a>, <a href="/format/2309.17240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven localized waves and parameter discovery in the massive  Thirring model via extended physics-informed neural networks with interface  zones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Chen%2C+J">Junchao Chen</a>, 
<a href="/search/nlin?searchtype=author&query=Song%2C+J">Jin Song</a>, 
<a href="/search/nlin?searchtype=author&query=Zhou%2C+Z">Zijian Zhou</a>, 
<a href="/search/nlin?searchtype=author&query=Yan%2C+Z">Zhenya Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 12 figures; Chaos, Solitons &amp; Fractals (accepted for publication)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Pattern Formation and Solitons (nlin.PS)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we study data-driven localized wave solutions and parameter
discovery in the massive Thirring (MT) model via the deep learning in the
framework of physics-informed neural networks (PINNs) algorithm. Abundant
data-driven solutions including soliton of bright/dark type, breather and rogue
wave are simulated accurately and analyzed contrastively with relative and
absolute errors. For higher-order localized wave solutions, we employ the
extended PINNs (XPINNs) with domain decomposition to capture the complete
pictures of dynamic behaviors such as soliton collisions, breather oscillations
and rogue-wave superposition. In particular, we modify the interface line in
domain decomposition of XPINNs into a small interface zone and introduce the
pseudo initial, residual and gradient conditions as interface conditions linked
adjacently with individual neural networks. Then this modified approach is
applied successfully to various solutions ranging from bright-bright soliton,
dark-dark soliton, dark-antidark soliton, general breather, Kuznetsov-Ma
breather and second-order rogue wave. Experimental results show that this
improved version of XPINNs reduce the complexity of computation with faster
convergence rate and keep the quality of learned solutions with smoother
stitching performance as well. For the inverse problems, the unknown
coefficient parameters of linear and nonlinear terms in the MT model are
identified accurately with and without noise by using the classical PINNs
algorithm.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17262" title="Abstract">arXiv:2309.17262</a> (cross-list from stat.ML) [<a href="/pdf/2309.17262" title="Download PDF">pdf</a>, <a href="/format/2309.17262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation and Inference in Distributional Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+L">Liangyu Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Peng%2C+Y">Yang Peng</a>, 
<a href="/search/stat?searchtype=author&query=Liang%2C+J">Jiadong Liang</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+W">Wenhao Yang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Z">Zhihua Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we study distributional reinforcement learning from the
perspective of statistical efficiency.
<br />We investigate distributional policy evaluation, aiming to estimate the
complete distribution of the random return (denoted $\eta^\pi$) attained by a
given policy $\pi$.
<br />We use the certainty-equivalence method to construct our estimator
$\hat\eta^\pi$, given a generative model is available.
<br />We show that in this circumstance we need a dataset of size $\widetilde
O\left(\frac{|\mathcal{S}||\mathcal{A}|}{\epsilon^{2p}(1-\gamma)^{2p+2}}\right)$
to guarantee a $p$-Wasserstein metric between $\hat\eta^\pi$ and $\eta^\pi$ is
less than $\epsilon$ with high probability.
<br />This implies the distributional policy evaluation problem can be solved with
sample efficiency.
<br />Also, we show that under different mild assumptions a dataset of size
$\widetilde
O\left(\frac{|\mathcal{S}||\mathcal{A}|}{\epsilon^{2}(1-\gamma)^{4}}\right)$
suffices to ensure the Kolmogorov metric and total variation metric between
$\hat\eta^\pi$ and $\eta^\pi$ is below $\epsilon$ with high probability.
<br />Furthermore, we investigate the asymptotic behavior of $\hat\eta^\pi$.
<br />We demonstrate that the ``empirical process''
$\sqrt{n}(\hat\eta^\pi-\eta^\pi)$ converges weakly to a Gaussian process in the
space of bounded functionals on Lipschitz function class
$\ell^\infty(\mathcal{F}_{W_1})$, also in the space of bounded functionals on
indicator function class $\ell^\infty(\mathcal{F}_{\mathrm{KS}})$ and bounded
measurable function class $\ell^\infty(\mathcal{F}_{\mathrm{TV}})$ when some
mild conditions hold.
<br />Our findings give rise to a unified approach to statistical inference of a
wide class of statistical functionals of $\eta^\pi$.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17267" title="Abstract">arXiv:2309.17267</a> (cross-list from eess.AS) [<a href="/pdf/2309.17267" title="Download PDF">pdf</a>, <a href="/format/2309.17267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wiki-En-ASR-Adapt: Large-scale synthetic dataset for English ASR  Customization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Antonova%2C+A">Alexandra Antonova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">We present a first large-scale public synthetic dataset for contextual
spellchecking customization of automatic speech recognition (ASR) with focus on
diverse rare and out-of-vocabulary (OOV) phrases, such as proper names or
terms. The proposed approach allows creating millions of realistic examples of
corrupted ASR hypotheses and simulate non-trivial biasing lists for the
customization task. Furthermore, we propose injecting two types of ``hard
negatives" to the simulated biasing lists in training examples and describe our
procedures to automatically mine them. We report experiments with training an
open-source customization model on the proposed dataset and show that the
injection of hard negative biasing phrases decreases WER and the number of
false alarms.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17269" title="Abstract">arXiv:2309.17269</a> (cross-list from eess.IV) [<a href="/pdf/2309.17269" title="Download PDF">pdf</a>, <a href="/ps/2309.17269" title="Download PostScript">ps</a>, <a href="/format/2309.17269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unpaired Optical Coherence Tomography Angiography Image Super-Resolution  via Frequency-Aware Inverse-Consistency GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Weiwen Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+D">Dawei Yang</a>, 
<a href="/search/eess?searchtype=author&query=Che%2C+H">Haoxuan Che</a>, 
<a href="/search/eess?searchtype=author&query=Ran%2C+A+R">An Ran Ran</a>, 
<a href="/search/eess?searchtype=author&query=Cheung%2C+C+Y">Carol Y. Cheung</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">For optical coherence tomography angiography (OCTA) images, a limited
scanning rate leads to a trade-off between field-of-view (FOV) and imaging
resolution. Although larger FOV images may reveal more parafoveal vascular
lesions, their application is greatly hampered due to lower resolution. To
increase the resolution, previous works only achieved satisfactory performance
by using paired data for training, but real-world applications are limited by
the challenge of collecting large-scale paired images. Thus, an unpaired
approach is highly demanded. Generative Adversarial Network (GAN) has been
commonly used in the unpaired setting, but it may struggle to accurately
preserve fine-grained capillary details, which are critical biomarkers for
OCTA. In this paper, our approach aspires to preserve these details by
leveraging the frequency information, which represents details as
high-frequencies ($\textbf{hf}$) and coarse-grained backgrounds as
low-frequencies ($\textbf{lf}$). In general, we propose a GAN-based unpaired
super-resolution method for OCTA images and exceptionally emphasize
$\textbf{hf}$ fine capillaries through a dual-path generator. To facilitate a
precise spectrum of the reconstructed image, we also propose a frequency-aware
adversarial loss for the discriminator and introduce a frequency-aware focal
consistency loss for end-to-end optimization. Experiments show that our method
outperforms other state-of-the-art unpaired methods both quantitatively and
visually.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17290" title="Abstract">arXiv:2309.17290</a> (cross-list from stat.ML) [<a href="/pdf/2309.17290" title="Download PDF">pdf</a>, <a href="/format/2309.17290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In search of dispersed memories: Generative diffusion models are  associative memory networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ambrogioni%2C+L">Luca Ambrogioni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hopfield networks are widely used in neuroscience as simplified theoretical
models of biological associative memory. The original Hopfield networks store
memories by encoding patterns of binary associations, which result in a
synaptic learning mechanism known as Hebbian learning rule. Modern Hopfield
networks can achieve exponential capacity scaling by using highly non-linear
energy functions. However, the energy function of these newer models cannot be
straightforwardly compressed into binary synaptic couplings and it does not
directly provide new synaptic learning rules. In this work we show that
generative diffusion models can be interpreted as energy-based models and that,
when trained on discrete patterns, their energy function is equivalent to that
of modern Hopfield networks. This equivalence allows us to interpret the
supervised training of diffusion models as a synaptic learning process that
encodes the associative dynamics of a modern Hopfield network in the weight
structure of a deep neural network. Accordingly, in our experiments we show
that the storage capacity of a continuous modern Hopfield network is identical
to the capacity of a diffusion model. Our results establish a strong link
between generative modeling and the theoretical neuroscience of memory, which
provide a powerful computational foundation for the reconstructive theory of
memory, where creative generation and memory recall can be seen as parts of a
unified continuum.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17293" title="Abstract">arXiv:2309.17293</a> (cross-list from quant-ph) [<a href="/pdf/2309.17293" title="Download PDF">pdf</a>, <a href="/format/2309.17293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Privacy-preserving Two-party Circle Intersection Protocol Based  on Phase-encoded Query
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Z">Zi-Xian Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+Q">Qi Yang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Feng%2C+B">Bao Feng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+W">Wen-Jie Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Theoretical Physics, 2023. 62(7): p. 138
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Privacy-preserving geometric intersection (PGI) is an important issue in
Secure multiparty computation (SMC). The existing quantum PGI protocols are
mainly based on grid coding, which requires a lot of computational complexity.
The phase-encoded query method which has been used in some Quantum SMC
protocols is suitable to solve the decision problem, but it needs to apply high
dimensional Oracle operators. In this paper, we use the principle of
phase-encoded query to solve an important PGI problem, namely
privacy-preserving two-party circle intersection. We study the implementation
of Oracle operator in detail, and achieve polynomial computational complexity
by decompsing it into quantum arithmetic operations. Performance analysis shows
that our protocol is correct and efficient, and can protect the privacy of all
participants against internal and external attacks.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17294" title="Abstract">arXiv:2309.17294</a> (cross-list from physics.soc-ph) [<a href="/pdf/2309.17294" title="Download PDF">pdf</a>, <a href="/format/2309.17294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time dynamics of income segregation at neighborhood scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Mori%2C+L+R">Lavinia Rossi Mori</a>, 
<a href="/search/physics?searchtype=author&query=Loreto%2C+V">Vittorio Loreto</a>, 
<a href="/search/physics?searchtype=author&query=Di+Clemente%2C+R">Riccardo Di Clemente</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Traditional approaches to urban income segregation focus on static
residential patterns, often failing to capture the dynamic nature of social
mixing at the neighborhood level. Leveraging high-resolution location-based
data from mobile phones, we capture the interplay of three different income
groups (high, medium, low) based on their daily routines. We propose a
three-dimensional space to analyze social mixing, which is embedded in the
temporal dynamics of urban activities. This framework offers a more detailed
perspective on social interactions, closely linked to the geographical features
of each neighborhood. While residential areas fail to encourage social mixing
in the nighttime, the working hours foster inclusion, with the city center
showing a heightened level of interaction. As evening sets in, leisure areas
emerge as potential facilitators for social interactions, depending on urban
features such as public transport and a variety of Points Of Interest. These
characteristics significantly modulate the magnitude and type of social
stratification involved in social mixing, also underscoring the significance of
urban design in either bridging or widening socio-economic divides.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17298" title="Abstract">arXiv:2309.17298</a> (cross-list from eess.AS) [<a href="/pdf/2309.17298" title="Download PDF">pdf</a>, <a href="/format/2309.17298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LRPD: Large Replay Parallel Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yakovlev%2C+I">Ivan Yakovlev</a>, 
<a href="/search/eess?searchtype=author&query=Melnikov%2C+M">Mikhail Melnikov</a>, 
<a href="/search/eess?searchtype=author&query=Bukhal%2C+N">Nikita Bukhal</a>, 
<a href="/search/eess?searchtype=author&query=Makarov%2C+R">Rostislav Makarov</a>, 
<a href="/search/eess?searchtype=author&query=Alenin%2C+A">Alexander Alenin</a>, 
<a href="/search/eess?searchtype=author&query=Torgashov%2C+N">Nikita Torgashov</a>, 
<a href="/search/eess?searchtype=author&query=Okhotnikov%2C+A">Anton Okhotnikov</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICASSP 2022 - 2022 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), 6612-6616
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The latest research in the field of voice anti-spoofing (VAS) shows that deep
neural networks (DNN) outperform classic approaches like GMM in the task of
presentation attack detection. However, DNNs require a lot of data to converge,
and still lack generalization ability. In order to foster the progress of
neural network systems, we introduce a Large Replay Parallel Dataset (LRPD)
aimed for a detection of replay attacks. LRPD contains more than 1M utterances
collected by 19 recording devices in 17 various environments. We also provide
an example training pipeline in PyTorch [1] and a baseline system, that
achieves 0.28% Equal Error Rate (EER) on evaluation subset of LRPD and 11.91%
EER on publicly available ASVpoof 2017 [2] eval set. These results show that
model trained with LRPD dataset has a consistent performance on the fully
unknown conditions. Our dataset is free for research purposes and hosted on
GDrive. Baseline code and pre-trained models are available at GitHub.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17299" title="Abstract">arXiv:2309.17299</a> (cross-list from quant-ph) [<a href="/pdf/2309.17299" title="Download PDF">pdf</a>, <a href="/format/2309.17299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Amplitude Estimation for Probabilistic Methods in Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jong%2C+E">Emilie Jong</a>, 
<a href="/search/quant-ph?searchtype=author&query=S%C3%A6varsson%2C+B">Brynjar S&#xe6;varsson</a>, 
<a href="/search/quant-ph?searchtype=author&query=J%C3%B3hannsson%2C+H">Hj&#xf6;rtur J&#xf3;hannsson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chatzivasileiadis%2C+S">Spyros Chatzivasileiadis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper introduces quantum computing methods for Monte Carlo simulations
in power systems which are expected to be exponentially faster than their
classical computing counterparts. Monte Carlo simulations is a fundamental
method, widely used in power systems to estimate key parameters of unknown
probability distributions, such as the mean value, the standard deviation, or
the value at risk. It is, however, very computationally intensive. Approaches
based on Quantum Amplitude Estimation can offer a quadratic speedup, requiring
orders of magnitude less samples to achieve the same accuracy. This paper
explains three Quantum Amplitude Estimation methods to replace the Classical
Monte Carlo method, namely the Iterative Quantum Amplitude Estimation (IQAE),
Maximum Likelihood Amplitude Estimation (MLAE), and Faster Amplitude Estimation
(FAE), and compares their performance for three different types of probability
distributions for power systems.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17316" title="Abstract">arXiv:2309.17316</a> (cross-list from stat.ML) [<a href="/pdf/2309.17316" title="Download PDF">pdf</a>, <a href="/format/2309.17316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Stochastic Optimization via Gradient Quantile Clipping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Merad%2C+I">Ibrahim Merad</a>, 
<a href="/search/stat?searchtype=author&query=Ga%C3%AFffas%2C+S">St&#xe9;phane Ga&#xef;ffas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a clipping strategy for Stochastic Gradient Descent (SGD) which
uses quantiles of the gradient norm as clipping thresholds. We prove that this
new strategy provides a robust and efficient optimization algorithm for smooth
objectives (convex or non-convex), that tolerates heavy-tailed samples
(including infinite variance) and a fraction of outliers in the data stream
akin to Huber contamination. Our mathematical analysis leverages the connection
between constant step size SGD and Markov chains and handles the bias
introduced by clipping in an original way. For strongly convex objectives, we
prove that the iteration converges to a concentrated distribution and derive
high probability bounds on the final estimation error. In the non-convex case,
we prove that the limit distribution is localized on a neighborhood with low
gradient. We propose an implementation of this algorithm using rolling
quantiles which leads to a highly efficient optimization procedure with strong
robustness properties, as confirmed by our numerical experiments.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17320" title="Abstract">arXiv:2309.17320</a> (cross-list from eess.IV) [<a href="/pdf/2309.17320" title="Download PDF">pdf</a>, <a href="/format/2309.17320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development of a Deep Learning Method to Identify Acute Ischemic Stroke  Lesions on Brain CT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fontanella%2C+A">Alessandro Fontanella</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+W">Wenwen Li</a>, 
<a href="/search/eess?searchtype=author&query=Mair%2C+G">Grant Mair</a>, 
<a href="/search/eess?searchtype=author&query=Antoniou%2C+A">Antreas Antoniou</a>, 
<a href="/search/eess?searchtype=author&query=Platt%2C+E">Eleanor Platt</a>, 
<a href="/search/eess?searchtype=author&query=Armitage%2C+P">Paul Armitage</a>, 
<a href="/search/eess?searchtype=author&query=Trucco%2C+E">Emanuele Trucco</a>, 
<a href="/search/eess?searchtype=author&query=Wardlaw%2C+J">Joanna Wardlaw</a>, 
<a href="/search/eess?searchtype=author&query=Storkey%2C+A">Amos Storkey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Computed Tomography (CT) is commonly used to image acute ischemic stroke
(AIS) patients, but its interpretation by radiologists is time-consuming and
subject to inter-observer variability. Deep learning (DL) techniques can
provide automated CT brain scan assessment, but usually require annotated
images. Aiming to develop a DL method for AIS using labelled but not annotated
CT brain scans from patients with AIS, we designed a convolutional neural
network-based DL algorithm using routinely-collected CT brain scans from the
Third International Stroke Trial (IST-3), which were not acquired using strict
research protocols. The DL model aimed to detect AIS lesions and classify the
side of the brain affected. We explored the impact of AIS lesion features,
background brain appearances, and timing on DL performance. From 5772 unique CT
scans of 2347 AIS patients (median age 82), 54% had visible AIS lesions
according to expert labelling. Our best-performing DL method achieved 72%
accuracy for lesion presence and side. Lesions that were larger (80% accuracy)
or multiple (87% accuracy for two lesions, 100% for three or more), were better
detected. Follow-up scans had 76% accuracy, while baseline scans 67% accuracy.
Chronic brain conditions reduced accuracy, particularly non-stroke lesions and
old stroke lesions (32% and 31% error rates respectively). DL methods can be
designed for AIS lesion detection on CT using the vast quantities of
routinely-collected CT brain scan data. Ultimately, this should lead to more
robust and widely-applicable methods.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17322" title="Abstract">arXiv:2309.17322</a> (cross-list from q-fin.GN) [<a href="/pdf/2309.17322" title="Download PDF">pdf</a>, <a href="/format/2309.17322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Look-Ahead Bias in Stock Return Predictions Generated By GPT  Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Glasserman%2C+P">Paul Glasserman</a>, 
<a href="/search/q-fin?searchtype=author&query=Lin%2C+C">Caden Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs), including ChatGPT, can extract profitable
trading signals from the sentiment in news text. However, backtesting such
strategies poses a challenge because LLMs are trained on many years of data,
and backtesting produces biased results if the training and backtesting periods
overlap. This bias can take two forms: a look-ahead bias, in which the LLM may
have specific knowledge of the stock returns that followed a news article, and
a distraction effect, in which general knowledge of the companies named
interferes with the measurement of a text's sentiment. We investigate these
sources of bias through trading strategies driven by the sentiment of financial
news headlines. We compare trading performance based on the original headlines
with de-biased strategies in which we remove the relevant company's identifiers
from the text. In-sample (within the LLM training window), we find,
surprisingly, that the anonymized headlines outperform, indicating that the
distraction effect has a greater impact than look-ahead bias. This tendency is
particularly strong for larger companies--companies about which we expect an
LLM to have greater general knowledge. Out-of-sample, look-ahead bias is not a
concern but distraction remains possible. Our proposed anonymization procedure
is therefore potentially useful in out-of-sample implementation, as well as for
de-biased backtesting.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17334" title="Abstract">arXiv:2309.17334</a> (cross-list from eess.IV) [<a href="/pdf/2309.17334" title="Download PDF">pdf</a>, <a href="/format/2309.17334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Depth Branches Network for Efficient Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tian%2C+H">Huiyuan Tian</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shijian Li</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+M">Min Yao</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+G">Gang Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Significant progress has been made in the field of super-resolution (SR), yet
many convolutional neural networks (CNNs) based SR models primarily focus on
restoring high-frequency details, often overlooking crucial low-frequency
contour information. Transformer-based SR methods, while incorporating global
structural details, frequently come with an abundance of parameters, leading to
high computational overhead. In this paper, we address these challenges by
introducing a Multi-Depth Branches Network (MDBN). This framework extends the
ResNet architecture by integrating an additional branch that captures vital
structural characteristics of images. Our proposed multi-depth branches module
(MDBM) involves the stacking of convolutional kernels of identical size at
varying depths within distinct branches. By conducting a comprehensive analysis
of the feature maps, we observe that branches with differing depths can extract
contour and detail information respectively. By integrating these branches, the
overall architecture can preserve essential low-frequency semantic structural
information during the restoration of high-frequency visual elements, which is
more closely with human visual cognition. Compared to GoogLeNet-like models,
our basic multi-depth branches structure has fewer parameters, higher
computational efficiency, and improved performance. Our model outperforms
state-of-the-art (SOTA) lightweight SR methods with less inference time. Our
code is available at https://github.com/thy960112/MDBN
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17343" title="Abstract">arXiv:2309.17343</a> (cross-list from physics.optics) [<a href="/pdf/2309.17343" title="Download PDF">pdf</a>, <a href="/format/2309.17343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Lithography: Close the Design-to-Manufacturing Gap in  Computational Optics with a &#x27;Real2Sim&#x27; Learned Photolithography Simulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zheng%2C+C">Cheng Zheng</a>, 
<a href="/search/physics?searchtype=author&query=Zhao%2C+G">Guangyuan Zhao</a>, 
<a href="/search/physics?searchtype=author&query=So%2C+P+T+C">Peter T.C. So</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper, titled "Close the Design-to-Manufacturing Gap in Computational Optics with a 'Real2Sim' Learned Two-Photon Neural Lithography Simulator," has been accepted for presentation at SIGGRAPH Asia 2023. This version offers a more comprehensive and accessible read. Project page: <a href="https://neural-litho.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)

</div>
<p class="mathjax">We introduce neural lithography to address the 'design-to-manufacturing' gap
in computational optics. Computational optics with large design degrees of
freedom enable advanced functionalities and performance beyond traditional
optics. However, the existing design approaches often overlook the numerical
modeling of the manufacturing process, which can result in significant
performance deviation between the design and the fabricated optics. To bridge
this gap, we, for the first time, propose a fully differentiable design
framework that integrates a pre-trained photolithography simulator into the
model-based optical design loop. Leveraging a blend of physics-informed
modeling and data-driven training using experimentally collected datasets, our
photolithography simulator serves as a regularizer on fabrication feasibility
during design, compensating for structure discrepancies introduced in the
lithography process. We demonstrate the effectiveness of our approach through
two typical tasks in computational optics, where we design and fabricate a
holographic optical element (HOE) and a multi-level diffractive lens (MDL)
using a two-photon lithography system, showcasing improved optical performance
on the task-specific metrics.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17366" title="Abstract">arXiv:2309.17366</a> (cross-list from q-bio.BM) [<a href="/pdf/2309.17366" title="Download PDF">pdf</a>, <a href="/format/2309.17366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-Mol: A Novel Contrastive Learning Framework for Molecular Property  Prediction with 3D Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kuang%2C+T">Taojie Kuang</a>, 
<a href="/search/q-bio?searchtype=author&query=Ren%2C+Y">Yiming Ren</a>, 
<a href="/search/q-bio?searchtype=author&query=Ren%2C+Z">Zhixiang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Molecular property prediction offers an effective and efficient approach for
early screening and optimization of drug candidates. Although deep learning
based methods have made notable progress, most existing works still do not
fully utilize 3D spatial information. This can lead to a single molecular
representation representing multiple actual molecules. To address these issues,
we propose a novel 3D structure-based molecular modeling method named 3D-Mol.
In order to accurately represent complete spatial structure, we design a novel
encoder to extract 3D features by deconstructing the molecules into three
geometric graphs. In addition, we use 20M unlabeled data to pretrain our model
by contrastive learning. We consider conformations with the same topological
structure as positive pairs and the opposites as negative pairs, while the
weight is determined by the dissimilarity between the conformations. We compare
3D-Mol with various state-of-the-art (SOTA) baselines on 7 benchmarks and
demonstrate our outstanding performance in 5 benchmarks.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17384" title="Abstract">arXiv:2309.17384</a> (cross-list from eess.AS) [<a href="/pdf/2309.17384" title="Download PDF">pdf</a>, <a href="/format/2309.17384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Universal Speech Enhancement for Diverse Input Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Wangyou Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Saijo%2C+K">Kohei Saijo</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhong-Qiu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+Y">Yanmin Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 5 tables, accepted by ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">The past decade has witnessed substantial growth of data-driven speech
enhancement (SE) techniques thanks to deep learning. While existing approaches
have shown impressive performance in some common datasets, most of them are
designed only for a single condition (e.g., single-channel, multi-channel, or a
fixed sampling frequency) or only consider a single task (e.g., denoising or
dereverberation). Currently, there is no universal SE approach that can
effectively handle diverse input conditions with a single model. In this paper,
we make the first attempt to investigate this line of research. First, we
devise a single SE model that is independent of microphone channels, signal
lengths, and sampling frequencies. Second, we design a universal SE benchmark
by combining existing public corpora with multiple conditions. Our experiments
on a wide range of datasets show that the proposed single model can
successfully handle diverse conditions with strong performance.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17385" title="Abstract">arXiv:2309.17385</a> (cross-list from math.CO) [<a href="/pdf/2309.17385" title="Download PDF">pdf</a>, <a href="/ps/2309.17385" title="Download PostScript">ps</a>, <a href="/format/2309.17385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dichromatic number of chordal graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bessy%2C+S">St&#xe9;phane Bessy</a>, 
<a href="/search/math?searchtype=author&query=Havet%2C+F">Fr&#xe9;d&#xe9;ric Havet</a>, 
<a href="/search/math?searchtype=author&query=Picasarri-Arrieta%2C+L">Lucas Picasarri-Arrieta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The dichromatic number of a digraph is the minimum integer $k$ such that it
admits a $k$-dicolouring, i.e. a partition of its vertices into $k$ acyclic
subdigraphs. We say that a digraph $D$ is a super-orientation of an undirected
graph $G$ if $G$ is the underlying graph of $D$. If $D$ does not contain any
pair of symmetric arcs, we just say that $D$ is an orientation of $G$. In this
work, we give both lower and upper bounds on the dichromatic number of
super-orientations of chordal graphs. We also show a family of orientations of
cographs for which the dichromatic number is equal to the clique number of the
underlying graph.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17424" title="Abstract">arXiv:2309.17424</a> (cross-list from math.NT) [<a href="/pdf/2309.17424" title="Download PDF">pdf</a>, <a href="/ps/2309.17424" title="Download PostScript">ps</a>, <a href="/format/2309.17424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing the inverse map as a composition of quadratics in a finite  field of characteristic $2$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Luca%2C+F">Florian Luca</a>, 
<a href="/search/math?searchtype=author&query=Sarkar%2C+S">Santanu Sarkar</a>, 
<a href="/search/math?searchtype=author&query=Stanica%2C+P">Pantelimon Stanica</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In 1953, Carlitz~\cite{Car53} showed that all permutation polynomials over
$\F_q$, where $q&gt;2$ is a power of a prime, are generated by the special
permutation polynomials $x^{q-2}$ (the inversion) and $ ax+b$ (affine
functions, where $0\neq a, b\in \F_q$). Recently, Nikova, Nikov and
Rijmen~\cite{NNR19} proposed an algorithm (NNR) to find a decomposition of the
inverse function in quadratics, and computationally covered all dimensions
$n\leq 16$. Petrides~\cite{P23} found a class of integers for which it is easy
to decompose the inverse into quadratics, and improved the NNR algorithm,
thereby extending the computation up to $n\leq 32$. Here, we extend Petrides'
result, as well as we propose a number theoretical approach, which allows us to
cover easily all (surely, odd) exponents up to~$250$, at least.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon,  2 Oct 23</h3>
<dl>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1906.07430" title="Abstract">arXiv:1906.07430</a> (replaced) [<a href="/pdf/1906.07430" title="Download PDF">pdf</a>, <a href="/format/1906.07430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orienting undirected phylogenetic networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huber%2C+K+T">Katharina T. Huber</a>, 
<a href="/search/cs?searchtype=author&query=van+Iersel%2C+L">Leo van Iersel</a>, 
<a href="/search/cs?searchtype=author&query=Janssen%2C+R">Remie Janssen</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+M">Mark Jones</a>, 
<a href="/search/cs?searchtype=author&query=Moulton%2C+V">Vincent Moulton</a>, 
<a href="/search/cs?searchtype=author&query=Murakami%2C+Y">Yukihiro Murakami</a>, 
<a href="/search/cs?searchtype=author&query=Semple%2C+C">Charles Semple</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> contains an appendix with additional results not presented in the journal version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO); Populations and Evolution (q-bio.PE)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.01502" title="Abstract">arXiv:2101.01502</a> (replaced) [<a href="/pdf/2101.01502" title="Download PDF">pdf</a>, <a href="/format/2101.01502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control-Data Separation and Logical Condition Propagation for Efficient  Inference on Probabilistic Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasuo%2C+I">Ichiro Hasuo</a>, 
<a href="/search/cs?searchtype=author&query=Oyabu%2C+Y">Yuichiro Oyabu</a>, 
<a href="/search/cs?searchtype=author&query=Eberhart%2C+C">Clovis Eberhart</a>, 
<a href="/search/cs?searchtype=author&query=Suenaga%2C+K">Kohei Suenaga</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kenta Cho</a>, 
<a href="/search/cs?searchtype=author&query=Katsumata%2C+S">Shin-ya Katsumata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.06152" title="Abstract">arXiv:2108.06152</a> (replaced) [<a href="/pdf/2108.06152" title="Download PDF">pdf</a>, <a href="/format/2108.06152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional DETR for Fast Training Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Depu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaokang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zejia Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Gang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2021. The first two authors share first authorship, and the order was determined by rolling dice
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.12529" title="Abstract">arXiv:2108.12529</a> (replaced) [<a href="/pdf/2108.12529" title="Download PDF">pdf</a>, <a href="/format/2108.12529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralizing Platform Power: A Design Space of Multi-level Governance  in Online Social Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jhaver%2C+S">Shagun Jhaver</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+S">Seth Frey</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Amy Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.07346" title="Abstract">arXiv:2110.07346</a> (replaced) [<a href="/pdf/2110.07346" title="Download PDF">pdf</a>, <a href="/format/2110.07346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast value iteration for energy games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casares%2C+A">Antonio Casares</a>, 
<a href="/search/cs?searchtype=author&query=Ohlmann%2C+P">Pierre Ohlmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures. arXiv admin note: substantial text overlap with <a href="/abs/2110.04533">arXiv:2110.04533</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.15482" title="Abstract">arXiv:2110.15482</a> (replaced) [<a href="/pdf/2110.15482" title="Download PDF">pdf</a>, <a href="/format/2110.15482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> First order strong approximation of Ait-Sahalia-type interest rate model  with Poisson jumps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lei%2C+Z">Ziyi Lei</a>, 
<a href="/search/math?searchtype=author&query=Gan%2C+S">Siqing Gan</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+J">Jing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.12665" title="Abstract">arXiv:2111.12665</a> (replaced) [<a href="/pdf/2111.12665" title="Download PDF">pdf</a>, <a href="/ps/2111.12665" title="Download PostScript">ps</a>, <a href="/format/2111.12665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite-Time Error Bounds for Distributed Linear Stochastic Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yixuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vijay Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A shortened version has been accepted by Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.03881" title="Abstract">arXiv:2112.03881</a> (replaced) [<a href="/pdf/2112.03881" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nashian game theory is incompatible with quantum physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Baczyk%2C+M">Michal Baczyk</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fourny%2C+G">Ghislain Fourny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in "Quantum Studies: Mathematics and Foundations" on September 28, 2023. 14 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Quantum Stud.: Math. Found. (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08491" title="Abstract">arXiv:2112.08491</a> (replaced) [<a href="/pdf/2112.08491" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Languages with Greater Information Density Increase Communication  Speed, but Decrease Conversation Breadth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aceves%2C+P">Pedro Aceves</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+J+A">James A. Evans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.13257" title="Abstract">arXiv:2112.13257</a> (replaced) [<a href="/pdf/2112.13257" title="Download PDF">pdf</a>, <a href="/format/2112.13257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fast Row-Stochastic Decentralized Method for Distributed Optimization  Over Directed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ghaderyan%2C+D">Diyako Ghaderyan</a>, 
<a href="/search/math?searchtype=author&query=Aybat%2C+N+S">Necdet Serhat Aybat</a>, 
<a href="/search/math?searchtype=author&query=Aguiar%2C+A+P">A. Pedro Aguiar</a>, 
<a href="/search/math?searchtype=author&query=Pereira%2C+F+L">Fernando Lobo Pereira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.01940" title="Abstract">arXiv:2201.01940</a> (replaced) [<a href="/pdf/2201.01940" title="Download PDF">pdf</a>, <a href="/format/2201.01940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMSE: A Serverless Platform for Multimedia Cloud Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Denninnart%2C+C">Chavit Denninnart</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M+A">Mohsen Amini Salehi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the Journal of Concurrency and Computation: Practice and Experience (CCPE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.01243" title="Abstract">arXiv:2203.01243</a> (replaced) [<a href="/pdf/2203.01243" title="Download PDF">pdf</a>, <a href="/format/2203.01243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flow-based density of states for complex actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-lat?searchtype=author&query=Pawlowski%2C+J+M">Jan M. Pawlowski</a>, 
<a href="/search/hep-lat?searchtype=author&query=Urban%2C+J+M">Julian M. Urban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. D 108, 054511 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Lattice (hep-lat)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.01974" title="Abstract">arXiv:2203.01974</a> (replaced) [<a href="/pdf/2203.01974" title="Download PDF">pdf</a>, <a href="/format/2203.01974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Rich, Portable, and Large-Scale Pedestrian Data Collection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Allan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+A">Abhijat Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Admoni%2C+H">Henny Admoni</a>, 
<a href="/search/cs?searchtype=author&query=Steinfeld%2C+A">Aaron Steinfeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS 2022 Workshop paper (Evaluating Motion Planning Performance: Metrics, Tools, Datasets, and Experimental Design)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.09337" title="Abstract">arXiv:2203.09337</a> (replaced) [<a href="/pdf/2203.09337" title="Download PDF">pdf</a>, <a href="/format/2203.09337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoBRA: A Composable Benchmark for Robotics Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mayer%2C+M">Matthias Mayer</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BClz%2C+J">Jonathan K&#xfc;lz</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00680" title="Abstract">arXiv:2205.00680</a> (replaced) [<a href="/pdf/2205.00680" title="Download PDF">pdf</a>, <a href="/ps/2205.00680" title="Download PostScript">ps</a>, <a href="/format/2205.00680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Typed Non-determinism in Functional and Concurrent Calculi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+den+Heuvel%2C+B">Bas van den Heuvel</a>, 
<a href="/search/cs?searchtype=author&query=Paulus%2C+J+W+N">Joseph W. N. Paulus</a>, 
<a href="/search/cs?searchtype=author&query=Nantes-Sobrinho%2C+D">Daniele Nantes-Sobrinho</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+J+A">Jorge A. P&#xe9;rez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.04878" title="Abstract">arXiv:2205.04878</a> (replaced) [<a href="/pdf/2205.04878" title="Download PDF">pdf</a>, <a href="/format/2205.04878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid quantum ResNet for car classification and its hyperparameter  optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sagingalieva%2C+A">Asel Sagingalieva</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kordzanganeh%2C+M">Mo Kordzanganeh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kurkin%2C+A">Andrii Kurkin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Melnikov%2C+A">Artem Melnikov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kuhmistrov%2C+D">Daniil Kuhmistrov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Perelshtein%2C+M">Michael Perelshtein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Melnikov%2C+A">Alexey Melnikov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Skolik%2C+A">Andrea Skolik</a>, 
<a href="/search/quant-ph?searchtype=author&query=Von+Dollen%2C+D">David Von Dollen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Quantum Mach. Intell. 5(2), 38 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.06892" title="Abstract">arXiv:2205.06892</a> (replaced) [<a href="/pdf/2205.06892" title="Download PDF">pdf</a>, <a href="/ps/2205.06892" title="Download PostScript">ps</a>, <a href="/format/2205.06892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Gs-monoidal to Oplax Cartesian Categories: Constructions and  Functorial Completeness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fritz%2C+T">Tobias Fritz</a>, 
<a href="/search/cs?searchtype=author&query=Gadducci%2C+F">Fabio Gadducci</a>, 
<a href="/search/cs?searchtype=author&query=Trotta%2C+D">Davide Trotta</a>, 
<a href="/search/cs?searchtype=author&query=Corradini%2C+A">Andrea Corradini</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Appl. Categ. Structures 31, 42 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11119" title="Abstract">arXiv:2205.11119</a> (replaced) [<a href="/pdf/2205.11119" title="Download PDF">pdf</a>, <a href="/format/2205.11119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Linear Convergence of Nested Primal-Dual Gradient Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jingwang Li</a>, 
<a href="/search/math?searchtype=author&query=Su%2C+H">Housheng Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14865" title="Abstract">arXiv:2205.14865</a> (replaced) [<a href="/pdf/2205.14865" title="Download PDF">pdf</a>, <a href="/format/2205.14865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-aligned Gradient for Prompt Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Beier Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yulei Niu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yucheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01544" title="Abstract">arXiv:2206.01544</a> (replaced) [<a href="/pdf/2206.01544" title="Download PDF">pdf</a>, <a href="/ps/2206.01544" title="Download PostScript">ps</a>, <a href="/format/2206.01544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial approximation on $C^2$-domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dai%2C+F">Feng Dai</a>, 
<a href="/search/math?searchtype=author&query=Prymak%2C+A">Andriy Prymak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> the material in this article is based heavily on a part of <a href="/abs/1910.11719">arXiv:1910.11719</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Classical Analysis and ODEs (math.CA)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11177" title="Abstract">arXiv:2206.11177</a> (replaced) [<a href="/pdf/2206.11177" title="Download PDF">pdf</a>, <a href="/ps/2206.11177" title="Download PostScript">ps</a>, <a href="/format/2206.11177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frugal Splitting Operators: Representation, Minimal Lifting, and  Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Morin%2C+M">Martin Morin</a>, 
<a href="/search/math?searchtype=author&query=Banert%2C+S">Sebastian Banert</a>, 
<a href="/search/math?searchtype=author&query=Giselsson%2C+P">Pontus Giselsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03566" title="Abstract">arXiv:2207.03566</a> (replaced) [<a href="/pdf/2207.03566" title="Download PDF">pdf</a>, <a href="/format/2207.03566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on Stability of Event-Triggered Control Systems with Time Delays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+K">Kexue Zhang</a>, 
<a href="/search/math?searchtype=author&query=Gharesifard%2C+B">Bahman Gharesifard</a>, 
<a href="/search/math?searchtype=author&query=Braverman%2C+E">Elena Braverman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.09797" title="Abstract">arXiv:2207.09797</a> (replaced) [<a href="/pdf/2207.09797" title="Download PDF">pdf</a>, <a href="/format/2207.09797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Matching: Correct Parity and FPT Parameterized by Independence  Number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maalouly%7D%2C+N+%7B">Nicolas {El Maalouly}</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+R">Raphael Steiner</a>, 
<a href="/search/cs?searchtype=author&query=Wulf%2C+L">Lasse Wulf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10294" title="Abstract">arXiv:2207.10294</a> (replaced) [<a href="/pdf/2207.10294" title="Download PDF">pdf</a>, <a href="/format/2207.10294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Control of Multi-Agent Systems with Processing Delays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kashyap%2C+M">Mruganka Kashyap</a>, 
<a href="/search/math?searchtype=author&query=Lessard%2C+L">Laurent Lessard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10793" title="Abstract">arXiv:2207.10793</a> (replaced) [<a href="/pdf/2207.10793" title="Download PDF">pdf</a>, <a href="/format/2207.10793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Dirty Secret of SSDs: Embodied Carbon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tannu%2C+S">Swamit Tannu</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+P+J">Prashant J. Nair</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Energy Informatics Review (Volume 3 Issue 3, October 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14222" title="Abstract">arXiv:2207.14222</a> (replaced) [<a href="/pdf/2207.14222" title="Download PDF">pdf</a>, <a href="/format/2207.14222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A universal matrix-free split preconditioner for the fixed-point  iterative solution of non-symmetric linear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vettenburg%2C+T">Tom Vettenburg</a>, 
<a href="/search/math?searchtype=author&query=Vellekoop%2C+I+M">Ivo M. Vellekoop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Rewritten version, includes efficiency comparison with shift preconditioner by Bai et al, which is shown to be a special case
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.03241" title="Abstract">arXiv:2208.03241</a> (replaced) [<a href="/pdf/2208.03241" title="Download PDF">pdf</a>, <a href="/ps/2208.03241" title="Download PostScript">ps</a>, <a href="/format/2208.03241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine Grained Analysis of High Dimensional Random Walks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gotlib%2C+R">Roy Gotlib</a>, 
<a href="/search/math?searchtype=author&query=Kaufman%2C+T">Tali Kaufman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12491" title="Abstract">arXiv:2208.12491</a> (replaced) [<a href="/pdf/2208.12491" title="Download PDF">pdf</a>, <a href="/format/2208.12491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformation equivariant cross-modality image synthesis with paired  non-aligned training data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Honkamaa%2C+J">Joel Honkamaa</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+U">Umair Khan</a>, 
<a href="/search/cs?searchtype=author&query=Koivukoski%2C+S">Sonja Koivukoski</a>, 
<a href="/search/cs?searchtype=author&query=Valkonen%2C+M">Mira Valkonen</a>, 
<a href="/search/cs?searchtype=author&query=Latonen%2C+L">Leena Latonen</a>, 
<a href="/search/cs?searchtype=author&query=Ruusuvuori%2C+P">Pekka Ruusuvuori</a>, 
<a href="/search/cs?searchtype=author&query=Marttinen%2C+P">Pekka Marttinen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Medical Image Analysis 90 (2023): 102940
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03837" title="Abstract">arXiv:2209.03837</a> (replaced) [<a href="/pdf/2209.03837" title="Download PDF">pdf</a>, <a href="/format/2209.03837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning arrays with rays: Physics-informed tuning of quantum dot charge  states
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Ziegler%2C+J">Joshua Ziegler</a>, 
<a href="/search/cond-mat?searchtype=author&query=Luthi%2C+F">Florian Luthi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ramsey%2C+M">Mick Ramsey</a>, 
<a href="/search/cond-mat?searchtype=author&query=Borjans%2C+F">Felix Borjans</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zheng%2C+G">Guoji Zheng</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zwolak%2C+J+P">Justyna P. Zwolak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. Applied 20, 034067 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04266" title="Abstract">arXiv:2209.04266</a> (replaced) [<a href="/pdf/2209.04266" title="Download PDF">pdf</a>, <a href="/format/2209.04266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Smooth: Certified Continuous-Time Range-Only Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%BCmbgen%2C+F">Frederike D&#xfc;mbgen</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+C">Connor Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Barfoot%2C+T+D">Timothy D. Barfoot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, accepted to IEEE Robotics and Automation Letters (this arXiv version contains supplementary appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05735" title="Abstract">arXiv:2209.05735</a> (replaced) [<a href="/pdf/2209.05735" title="Download PDF">pdf</a>, <a href="/format/2209.05735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning ASR pathways: A sparse multilingual ASR model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+M">Mu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Tjandra%2C+A">Andros Tjandra</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Chunxi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+D">David Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Le%2C+D">Duc Le</a>, 
<a href="/search/eess?searchtype=author&query=Kalinli%2C+O">Ozlem Kalinli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11436" title="Abstract">arXiv:2209.11436</a> (replaced) [<a href="/pdf/2209.11436" title="Download PDF">pdf</a>, <a href="/format/2209.11436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Open-Set Recognition by Jacobian Norm and Inter-Class  Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaewoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hojin Park</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+E">Eunju Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Teoh%2C+A+B+J">Andrew Beng Jin Teoh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Pattern Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12163" title="Abstract">arXiv:2209.12163</a> (replaced) [<a href="/pdf/2209.12163" title="Download PDF">pdf</a>, <a href="/ps/2209.12163" title="Download PostScript">ps</a>, <a href="/format/2209.12163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced basis stochastic Galerkin methods for partial differential  equations with random inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+G">Guanjie Wang</a>, 
<a href="/search/math?searchtype=author&query=Liao%2C+Q">Qifeng Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14007" title="Abstract">arXiv:2209.14007</a> (replaced) [<a href="/pdf/2209.14007" title="Download PDF">pdf</a>, <a href="/format/2209.14007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OA-Bug: An Olfactory-Auditory Augmented Bug Algorithm for Swarm Robots  in a Denied Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Siqi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+R">Ruitao Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mufan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+Q">Quan Quan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, accepted by 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02197" title="Abstract">arXiv:2210.02197</a> (replaced) [<a href="/pdf/2210.02197" title="Download PDF">pdf</a>, <a href="/format/2210.02197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Neyman-Pearson Classification for Prioritizing Severe  Disease Categories in COVID-19 Patient Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+X+R">Y. X. Rachel Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J+J">Jingyi Jessica Li</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06788" title="Abstract">arXiv:2210.06788</a> (replaced) [<a href="/pdf/2210.06788" title="Download PDF">pdf</a>, <a href="/format/2210.06788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TiDAL: Learning Training Dynamics for Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kye%2C+S+M">Seong Min Kye</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Kwanghee Choi</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+H">Hyeongmin Byun</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Buru Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Camera-Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09923" title="Abstract">arXiv:2210.09923</a> (replaced) [<a href="/pdf/2210.09923" title="Download PDF">pdf</a>, <a href="/format/2210.09923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot point cloud segmentation by transferring geometric primitives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runnan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nenglun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruigang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10956" title="Abstract">arXiv:2210.10956</a> (replaced) [<a href="/pdf/2210.10956" title="Download PDF">pdf</a>, <a href="/format/2210.10956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Iterative Scribble-Supervised Learning with Pacing Pseudo-Masks for  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zefan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Di Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+D">Dong Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11983" title="Abstract">arXiv:2210.11983</a> (replaced) [<a href="/pdf/2210.11983" title="Download PDF">pdf</a>, <a href="/format/2210.11983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pyrit: A Finite Element Based Field Simulation Software Written in  Python
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bundschuh%2C+J">Jonas Bundschuh</a>, 
<a href="/search/cs?searchtype=author&query=Ruppert%2C+M+G">M. Greta Ruppert</a>, 
<a href="/search/cs?searchtype=author&query=Sp%C3%A4ck-Leigsnering%2C+Y">Yvonne Sp&#xe4;ck-Leigsnering</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, Published in COMPEL - The international journal for computation and mathematics in electrical and electronic engineering. This preprint offers a more precise formatting and includes software parts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13905" title="Abstract">arXiv:2210.13905</a> (replaced) [<a href="/pdf/2210.13905" title="Download PDF">pdf</a>, <a href="/format/2210.13905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidence-Calibrated Face and Kinship Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Min Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Ximiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiuzhuang Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures, and 9 tables, IEEE Transactions on Information Forensics and Security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14547" title="Abstract">arXiv:2210.14547</a> (replaced) [<a href="/pdf/2210.14547" title="Download PDF">pdf</a>, <a href="/format/2210.14547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking-based distributed equilibrium seeking for aggregative games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Carnevale%2C+G">Guido Carnevale</a>, 
<a href="/search/eess?searchtype=author&query=Fabiani%2C+F">Filippo Fabiani</a>, 
<a href="/search/eess?searchtype=author&query=Fele%2C+F">Filiberto Fele</a>, 
<a href="/search/eess?searchtype=author&query=Margellos%2C+K">Kostas Margellos</a>, 
<a href="/search/eess?searchtype=author&query=Notarstefano%2C+G">Giuseppe Notarstefano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16349" title="Abstract">arXiv:2210.16349</a> (replaced) [<a href="/pdf/2210.16349" title="Download PDF">pdf</a>, <a href="/format/2210.16349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical analysis of a time-stepping method for the Westervelt equation  with time-fractional damping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Baker%2C+K">Katherine Baker</a>, 
<a href="/search/math?searchtype=author&query=Banjai%2C+L">Lehel Banjai</a>, 
<a href="/search/math?searchtype=author&query=Ptashnyk%2C+M">Mariya Ptashnyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05862" title="Abstract">arXiv:2211.05862</a> (replaced) [<a href="/pdf/2211.05862" title="Download PDF">pdf</a>, <a href="/format/2211.05862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a  Study on Thyroid Cancer Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadermayr%2C+M">Michael Gadermayr</a>, 
<a href="/search/cs?searchtype=author&query=Koller%2C+L">Lukas Koller</a>, 
<a href="/search/cs?searchtype=author&query=Tschuchnig%2C+M">Maximilian Tschuchnig</a>, 
<a href="/search/cs?searchtype=author&query=Stangassinger%2C+L+M">Lea Maria Stangassinger</a>, 
<a href="/search/cs?searchtype=author&query=Kreutzer%2C+C">Christina Kreutzer</a>, 
<a href="/search/cs?searchtype=author&query=Couillard-Despres%2C+S">Sebastien Couillard-Despres</a>, 
<a href="/search/cs?searchtype=author&query=Oostingh%2C+G+J">Gertie Janneke Oostingh</a>, 
<a href="/search/cs?searchtype=author&query=Hittmair%2C+A">Anton Hittmair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI'23, <a href="https://gitlab.com/mgadermayr/mixupmil">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12345" title="Abstract">arXiv:2211.12345</a> (replaced) [<a href="/pdf/2211.12345" title="Download PDF">pdf</a>, <a href="/format/2211.12345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Sparse Feature Updates in Deep Networks using Iterative  Linearisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldwaser%2C+A">Adrian Goldwaser</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+H">Hong Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00484" title="Abstract">arXiv:2212.00484</a> (replaced) [<a href="/pdf/2212.00484" title="Download PDF">pdf</a>, <a href="/format/2212.00484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially-Private Data Synthetisation for Efficient  Re-Identification Risk Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+T">T&#xe2;nia Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Moniz%2C+N">Nuno Moniz</a>, 
<a href="/search/cs?searchtype=author&query=Antunes%2C+L">Lu&#xed;s Antunes</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N">Nitesh Chawla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00856" title="Abstract">arXiv:2212.00856</a> (replaced) [<a href="/pdf/2212.00856" title="Download PDF">pdf</a>, <a href="/ps/2212.00856" title="Download PostScript">ps</a>, <a href="/format/2212.00856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-Adaptive Approaches to Learning and Decision Making: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Royset%2C+J+O">Johannes O. Royset</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05176" title="Abstract">arXiv:2212.05176</a> (replaced) [<a href="/pdf/2212.05176" title="Download PDF">pdf</a>, <a href="/format/2212.05176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adore: Differentially Oblivious Relational Database Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lianke Qin</a>, 
<a href="/search/cs?searchtype=author&query=Jayaram%2C+R">Rajesh Jayaram</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+E">Elaine Shi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+D">Danyang Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+S">Shumo Chu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> VLDB 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08839" title="Abstract">arXiv:2212.08839</a> (replaced) [<a href="/pdf/2212.08839" title="Download PDF">pdf</a>, <a href="/ps/2212.08839" title="Download PostScript">ps</a>, <a href="/format/2212.08839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of the tamed-Euler-Maruyama method for SDEs with  discontinuous and polynomially growing drift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Spendier%2C+K">Kathrin Spendier</a>, 
<a href="/search/math?searchtype=author&query=Sz%C3%B6lgyenyi%2C+M">Michaela Sz&#xf6;lgyenyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13447" title="Abstract">arXiv:2212.13447</a> (replaced) [<a href="/pdf/2212.13447" title="Download PDF">pdf</a>, <a href="/format/2212.13447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Enabling Block Semantics and Data Updates in DNA Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Puru Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+C">Cheng-Kai Lim</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dehui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pote%2C+Y">Yash Pote</a>, 
<a href="/search/cs?searchtype=author&query=Jevdjic%2C+D">Djordje Jevdjic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Databases (cs.DB); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03313" title="Abstract">arXiv:2301.03313</a> (replaced) [<a href="/pdf/2301.03313" title="Download PDF">pdf</a>, <a href="/format/2301.03313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BQ-NCO: Bisimulation Quotienting for Efficient Neural Combinatorial  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Drakulic%2C+D">Darko Drakulic</a>, 
<a href="/search/cs?searchtype=author&query=Michel%2C+S">Sofia Michel</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+F">Florian Mai</a>, 
<a href="/search/cs?searchtype=author&query=Sors%2C+A">Arnaud Sors</a>, 
<a href="/search/cs?searchtype=author&query=Andreoli%2C+J">Jean-Marc Andreoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06196" title="Abstract">arXiv:2301.06196</a> (replaced) [<a href="/pdf/2301.06196" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Young Male and Female Scientists: A Quantitative Exploratory Study of  the Changing Demographics of the Global Scientific Workforce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwiek%2C+M">Marek Kwiek</a>, 
<a href="/search/cs?searchtype=author&query=Szymula%2C+L">Lukasz Szymula</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 7 tables, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08570" title="Abstract">arXiv:2301.08570</a> (replaced) [<a href="/pdf/2301.08570" title="Download PDF">pdf</a>, <a href="/ps/2301.08570" title="Download PostScript">ps</a>, <a href="/format/2301.08570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Non-Interference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorrieri%2C+R">Roberto Gorrieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12592" title="Abstract">arXiv:2301.12592</a> (replaced) [<a href="/pdf/2301.12592" title="Download PDF">pdf</a>, <a href="/format/2301.12592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Learning for Fusion of Multiview Vision with Occlusion and  Missing Information: Framework and Evaluations with Real-World Data and  Applications in Driver Hand Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Greer%2C+R">Ross Greer</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+M">Mohan Trivedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02506" title="Abstract">arXiv:2302.02506</a> (replaced) [<a href="/pdf/2302.02506" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Dispatching Rules for the Interrupting Swap-Allowed Blocking  Job Shop Problem Using Graph Neural Network and Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+V+W+H">Vivian W.H. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+H">Sang Hun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinkyoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Law%2C+K+H">Kincho H. Law</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures. Supplementary Material not included
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03530" title="Abstract">arXiv:2302.03530</a> (replaced) [<a href="/pdf/2302.03530" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Loss in Community Resilience due to Hurricanes using  Facebook Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jamal%2C+T+B">Tasnuba Binte Jamal</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+S">Samiul Hasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04783" title="Abstract">arXiv:2302.04783</a> (replaced) [<a href="/pdf/2302.04783" title="Download PDF">pdf</a>, <a href="/ps/2302.04783" title="Download PostScript">ps</a>, <a href="/format/2302.04783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $t$-sails and sparse hereditary classes of unbounded tree-width
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cocks%2C+D">Daniel Cocks</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04823" title="Abstract">arXiv:2302.04823</a> (replaced) [<a href="/pdf/2302.04823" title="Download PDF">pdf</a>, <a href="/format/2302.04823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Generative Adversarial Imitation Learning with Mid-level  Input Generation for Autonomous Driving on Urban Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Couto%2C+G+C+K">Gustavo Claudio Karl Couto</a>, 
<a href="/search/cs?searchtype=author&query=Antonelo%2C+E+A">Eric Aislan Antonelo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05030" title="Abstract">arXiv:2302.05030</a> (replaced) [<a href="/pdf/2302.05030" title="Download PDF">pdf</a>, <a href="/ps/2302.05030" title="Download PostScript">ps</a>, <a href="/format/2302.05030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic $(1+&#x3b5;)$-Approximate Matching Size in Truly Sublinear  Update Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Sayan Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Kiss%2C+P">Peter Kiss</a>, 
<a href="/search/cs?searchtype=author&query=Saranurak%2C+T">Thatchaphol Saranurak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05319" title="Abstract">arXiv:2302.05319</a> (replaced) [<a href="/pdf/2302.05319" title="Download PDF">pdf</a>, <a href="/format/2302.05319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Code: Security Hardening and Adversarial  Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM CCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01015" title="Abstract">arXiv:2303.01015</a> (replaced) [<a href="/pdf/2303.01015" title="Download PDF">pdf</a>, <a href="/format/2303.01015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward a certified greedy Loewner framework with minimal sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pradovera%2C+D">Davide Pradovera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01242" title="Abstract">arXiv:2303.01242</a> (replaced) [<a href="/pdf/2303.01242" title="Download PDF">pdf</a>, <a href="/format/2303.01242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Optimization in Sensor Network for Scalable Multi-Robot  Relative State Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended technical report (14 pages, 5 figures, 2 tables)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01526" title="Abstract">arXiv:2303.01526</a> (replaced) [<a href="/pdf/2303.01526" title="Download PDF">pdf</a>, <a href="/format/2303.01526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Attention Flow Fields for Monocular Dynamic Scene Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yiqing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Laidlaw%2C+E">Eliot Laidlaw</a>, 
<a href="/search/cs?searchtype=author&query=Meyerowitz%2C+A">Alexander Meyerowitz</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S">Srinath Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Tompkin%2C+J">James Tompkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Computer Vision (ICCV) 2023; 10 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01666" title="Abstract">arXiv:2303.01666</a> (replaced) [<a href="/pdf/2303.01666" title="Download PDF">pdf</a>, <a href="/format/2303.01666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An infeasible interior-point arc-search method with Nesterov&#x27;s  restarting strategy for linear programming problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Iida%2C+E">Einosuke Iida</a>, 
<a href="/search/math?searchtype=author&query=Yamashita%2C+M">Makoto Yamashita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04068" title="Abstract">arXiv:2303.04068</a> (replaced) [<a href="/pdf/2303.04068" title="Download PDF">pdf</a>, <a href="/format/2303.04068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VOCALExplore: Pay-as-You-Go Video Data Exploration and Model Building  [Technical Report]
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daum%2C+M">Maureen Daum</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Enhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Dong He</a>, 
<a href="/search/cs?searchtype=author&query=Mussmann%2C+S">Stephen Mussmann</a>, 
<a href="/search/cs?searchtype=author&query=Haynes%2C+B">Brandon Haynes</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Balazinska%2C+M">Magdalena Balazinska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06090" title="Abstract">arXiv:2303.06090</a> (replaced) [<a href="/pdf/2303.06090" title="Download PDF">pdf</a>, <a href="/ps/2303.06090" title="Download PostScript">ps</a>, <a href="/format/2303.06090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple and efficient four-cycle counting on sparse graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burkhardt%2C+P">Paul Burkhardt</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+D+G">David G. Harris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06373" title="Abstract">arXiv:2303.06373</a> (replaced) [<a href="/pdf/2303.06373" title="Download PDF">pdf</a>, <a href="/format/2303.06373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Generalization Transformer for Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Linghe Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/zhengchen1999/RGT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07268" title="Abstract">arXiv:2303.07268</a> (replaced) [<a href="/pdf/2303.07268" title="Download PDF">pdf</a>, <a href="/format/2303.07268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An unconditionally stable space-time isogeometric method for the  acoustic wave equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fraschini%2C+S">Sara Fraschini</a>, 
<a href="/search/math?searchtype=author&query=Loli%2C+G">Gabriele Loli</a>, 
<a href="/search/math?searchtype=author&query=Moiola%2C+A">Andrea Moiola</a>, 
<a href="/search/math?searchtype=author&query=Sangalli%2C+G">Giancarlo Sangalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07344" title="Abstract">arXiv:2303.07344</a> (replaced) [<a href="/pdf/2303.07344" title="Download PDF">pdf</a>, <a href="/format/2303.07344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Contact Pressure Estimation for Grippers in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collins%2C+J+A">Jeremy A. Collins</a>, 
<a href="/search/cs?searchtype=author&query=Houff%2C+C">Cody Houff</a>, 
<a href="/search/cs?searchtype=author&query=Grady%2C+P">Patrick Grady</a>, 
<a href="/search/cs?searchtype=author&query=Kemp%2C+C+C">Charles C. Kemp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07960" title="Abstract">arXiv:2303.07960</a> (replaced) [<a href="/pdf/2303.07960" title="Download PDF">pdf</a>, <a href="/format/2303.07960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coloring and Recognizing Directed Interval Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gutowski%2C+G">Grzegorz Gutowski</a>, 
<a href="/search/cs?searchtype=author&query=Junosza-Szaniawski%2C+K">Konstanty Junosza-Szaniawski</a>, 
<a href="/search/cs?searchtype=author&query=Klesen%2C+F">Felix Klesen</a>, 
<a href="/search/cs?searchtype=author&query=Rz%C4%85%C5%BCewski%2C+P">Pawe&#x142; Rz&#x105;&#x17c;ewski</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+A">Alexander Wolff</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+J">Johannes Zink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Proc. ISAAC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08103" title="Abstract">arXiv:2303.08103</a> (replaced) [<a href="/pdf/2303.08103" title="Download PDF">pdf</a>, <a href="/format/2303.08103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task Meta Label Correction for Time Series Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Luxuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Ting Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+M">Min Dai</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Cheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jinqiao Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10211" title="Abstract">arXiv:2303.10211</a> (replaced) [<a href="/pdf/2303.10211" title="Download PDF">pdf</a>, <a href="/format/2303.10211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SITReg: Multi-resolution architecture for symmetric, inverse consistent,  and topology preserving image registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Honkamaa%2C+J">Joel Honkamaa</a>, 
<a href="/search/cs?searchtype=author&query=Marttinen%2C+P">Pekka Marttinen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10631" title="Abstract">arXiv:2303.10631</a> (replaced) [<a href="/pdf/2303.10631" title="Download PDF">pdf</a>, <a href="/format/2303.10631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bideterministic Weighted Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kostol%C3%A1nyi%2C+P">Peter Kostol&#xe1;nyi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of an article published in the proceedings of the conference CAI 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11217" title="Abstract">arXiv:2303.11217</a> (replaced) [<a href="/pdf/2303.11217" title="Download PDF">pdf</a>, <a href="/format/2303.11217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse problem regularization with hierarchical variational  autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prost%2C+J">Jean Prost</a>, 
<a href="/search/cs?searchtype=author&query=Houdard%2C+A">Antoine Houdard</a>, 
<a href="/search/cs?searchtype=author&query=Almansa%2C+A">Andr&#xe9;s Almansa</a>, 
<a href="/search/cs?searchtype=author&query=Papadakis%2C+N">Nicolas Papadakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11712" title="Abstract">arXiv:2303.11712</a> (replaced) [<a href="/pdf/2303.11712" title="Download PDF">pdf</a>, <a href="/format/2303.11712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Explaining CSPs with Unsatisfiable Subset Optimization  (extended algorithms and examples)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gamba%2C+E">Emilio Gamba</a>, 
<a href="/search/cs?searchtype=author&query=Bogaerts%2C+B">Bart Bogaerts</a>, 
<a href="/search/cs?searchtype=author&query=Guns%2C+T">Tias Guns</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2105.11763">arXiv:2105.11763</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15256" title="Abstract">arXiv:2303.15256</a> (replaced) [<a href="/pdf/2303.15256" title="Download PDF">pdf</a>, <a href="/format/2303.15256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Self-Supervised Learning: A Few Low-Cost Relationships Are All  You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabannes%2C+V">Vivien Cabannes</a>, 
<a href="/search/cs?searchtype=author&query=Bottou%2C+L">Leon Bottou</a>, 
<a href="/search/cs?searchtype=author&query=Lecun%2C+Y">Yann Lecun</a>, 
<a href="/search/cs?searchtype=author&query=Balestriero%2C+R">Randall Balestriero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 main pages, 20 totals, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15404" title="Abstract">arXiv:2303.15404</a> (replaced) [<a href="/e-print/2303.15404" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chromatic Community Structure Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delaplace%2C+F">Franck Delaplace</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An article drastically improving this result with a different title has been proposed. I intend to load it in ArXiv when this article was withdrawn
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17051" title="Abstract">arXiv:2303.17051</a> (replaced) [<a href="/pdf/2303.17051" title="Download PDF">pdf</a>, <a href="/format/2303.17051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards foundation models and few-shot parameter-efficient fine-tuning  for volumetric organ segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva-Rodr%C3%ADguez%2C+J">Julio Silva-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Dolz%2C+J">Jose Dolz</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+I+B">Ismail Ben Ayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI - MedAGI Workshop 2023. Code in <a href="https://github.com/jusiro/fewshot-finetuning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17057" title="Abstract">arXiv:2303.17057</a> (replaced) [<a href="/pdf/2303.17057" title="Download PDF">pdf</a>, <a href="/format/2303.17057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Avian-Inspired Claws Enable Robot Perching or Walking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Askari%2C+M">Mohammad Askari</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W+D">Won Dong Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lenherr%2C+D">Damian Lenherr</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+W">William Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Floreano%2C+D">Dario Floreano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17569" title="Abstract">arXiv:2303.17569</a> (replaced) [<a href="/pdf/2303.17569" title="Download PDF">pdf</a>, <a href="/format/2303.17569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Prompt Learning for Unsupervised Backlit Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhexin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shangchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruicheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 as Oral. Project page: <a href="https://zhexinliang.github.io/CLIP_LIT_page/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02613" title="Abstract">arXiv:2304.02613</a> (replaced) [<a href="/pdf/2304.02613" title="Download PDF">pdf</a>, <a href="/format/2304.02613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Quantum Algorithms for Quantum Optimal Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+X">Xiantao Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+C">Chunhao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures. Minor corrections. In ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02639" title="Abstract">arXiv:2304.02639</a> (replaced) [<a href="/pdf/2304.02639" title="Download PDF">pdf</a>, <a href="/format/2304.02639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ENTL: Embodied Navigation Trajectory Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotar%2C+K">Klemen Kotar</a>, 
<a href="/search/cs?searchtype=author&query=Walsman%2C+A">Aaron Walsman</a>, 
<a href="/search/cs?searchtype=author&query=Mottaghi%2C+R">Roozbeh Mottaghi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04066" title="Abstract">arXiv:2304.04066</a> (replaced) [<a href="/pdf/2304.04066" title="Download PDF">pdf</a>, <a href="/format/2304.04066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable and Safe Reinforcement Learning via a Barrier-Lyapunov  Actor-Critic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+L">Liqun Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Gatsis%2C+K">Konstantinos Gatsis</a>, 
<a href="/search/eess?searchtype=author&query=Papachristodoulou%2C+A">Antonis Papachristodoulou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08324" title="Abstract">arXiv:2304.08324</a> (replaced) [<a href="/pdf/2304.08324" title="Download PDF">pdf</a>, <a href="/format/2304.08324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-oriented Uncertainty Quantification for Inverse Problems via  Variational Encoder-Decoder Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Afkham%2C+B+M">Babak Maboudi Afkham</a>, 
<a href="/search/math?searchtype=author&query=Chung%2C+J">Julianne Chung</a>, 
<a href="/search/math?searchtype=author&query=Chung%2C+M">Matthias Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09691" title="Abstract">arXiv:2304.09691</a> (replaced) [<a href="/pdf/2304.09691" title="Download PDF">pdf</a>, <a href="/format/2304.09691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DarSwin: Distortion Aware Radial Swin Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Athwale%2C+A">Akshaya Athwale</a>, 
<a href="/search/cs?searchtype=author&query=Afrasiyabi%2C+A">Arman Afrasiyabi</a>, 
<a href="/search/cs?searchtype=author&query=Lag%C3%BCe%2C+J">Justin Lag&#xfc;e</a>, 
<a href="/search/cs?searchtype=author&query=Shili%2C+I">Ichrak Shili</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+O">Ola Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Lalonde%2C+J">Jean-Fran&#xe7;ois Lalonde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10728" title="Abstract">arXiv:2304.10728</a> (replaced) [<a href="/pdf/2304.10728" title="Download PDF">pdf</a>, <a href="/format/2304.10728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PiXi: Password Inspiration by Exploring Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Salehi-Abari%2C+A">Amirali Salehi-Abari</a>, 
<a href="/search/cs?searchtype=author&query=Thorpe%2C+J">Julie Thorpe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12175" title="Abstract">arXiv:2304.12175</a> (replaced) [<a href="/pdf/2304.12175" title="Download PDF">pdf</a>, <a href="/format/2304.12175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOTLEE: Distributed Mobile Multi-Object Tracking with Localization Error  Elimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peterson%2C+M+B">Mason B. Peterson</a>, 
<a href="/search/cs?searchtype=author&query=Lusk%2C+P+C">Parker C. Lusk</a>, 
<a href="/search/cs?searchtype=author&query=How%2C+J+P">Jonathan P. How</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, accepted to IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12521" title="Abstract">arXiv:2304.12521</a> (replaced) [<a href="/pdf/2304.12521" title="Download PDF">pdf</a>, <a href="/format/2304.12521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foley Sound Synthesis at the DCASE 2023 Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Keunwoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Im%2C+J">Jaekwon Im</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+L">Laurie Heller</a>, 
<a href="/search/cs?searchtype=author&query=McFee%2C+B">Brian McFee</a>, 
<a href="/search/cs?searchtype=author&query=Imoto%2C+K">Keisuke Imoto</a>, 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+Y">Yuki Okamoto</a>, 
<a href="/search/cs?searchtype=author&query=Lagrange%2C+M">Mathieu Lagrange</a>, 
<a href="/search/cs?searchtype=author&query=Takamichi%2C+S">Shinosuke Takamichi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DCASE 2023 Challenge - Task 7 - Technical Report (Submitted to DCASE 2023 Workshop)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13915" title="Abstract">arXiv:2304.13915</a> (replaced) [<a href="/pdf/2304.13915" title="Download PDF">pdf</a>, <a href="/format/2304.13915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Stabilizer Estimation via Bell Difference Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Grewal%2C+S">Sabee Grewal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Iyer%2C+V">Vishnu Iyer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kretschmer%2C+W">William Kretschmer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liang%2C+D">Daniel Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01074" title="Abstract">arXiv:2305.01074</a> (replaced) [<a href="/pdf/2305.01074" title="Download PDF">pdf</a>, <a href="/format/2305.01074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physical Adversarial Attacks for Surveillance: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Kien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+T">Tharindu Fernando</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Sridharan%2C+S">Sridha Sridharan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in T-NNLS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03403" title="Abstract">arXiv:2305.03403</a> (replaced) [<a href="/pdf/2305.03403" title="Download PDF">pdf</a>, <a href="/format/2305.03403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Automated Data Science: Introducing CAAFE for  Context-Aware Automated Feature Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hollmann%2C+N">Noah Hollmann</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+S">Samuel M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07893" title="Abstract">arXiv:2305.07893</a> (replaced) [<a href="/pdf/2305.07893" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PESTS: Persian_English Cross Lingual Corpus for Semantic Textual  Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdous%2C+M">Mohammad Abdous</a>, 
<a href="/search/cs?searchtype=author&query=Piroozfar%2C+P">Poorya Piroozfar</a>, 
<a href="/search/cs?searchtype=author&query=Bidgoli%2C+B+M">Behrouz Minaei Bidgoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08622" title="Abstract">arXiv:2305.08622</a> (replaced) [<a href="/pdf/2305.08622" title="Download PDF">pdf</a>, <a href="/ps/2305.08622" title="Download PostScript">ps</a>, <a href="/format/2305.08622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Size-stochastic Knapsack Online Contention Resolution Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshinaga%2C+T">Toru Yoshinaga</a>, 
<a href="/search/cs?searchtype=author&query=Kawase%2C+Y">Yasushi Kawase</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09807" title="Abstract">arXiv:2305.09807</a> (replaced) [<a href="/pdf/2305.09807" title="Download PDF">pdf</a>, <a href="/format/2305.09807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Dataset Transferability in Active Learning for Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeleni%C4%87%2C+F">Fran Jeleni&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Juki%C4%87%2C+J">Josip Juki&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Drobac%2C+N">Nina Drobac</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0najder%2C+J">Jan &#x160;najder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of the Association for Computational Linguistics: ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10503" title="Abstract">arXiv:2305.10503</a> (replaced) [<a href="/pdf/2305.10503" title="Download PDF">pdf</a>, <a href="/format/2305.10503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OR-NeRF: Object Removing from 3D Scenes Guided by Multiview Segmentation  with Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Youtan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zhoujie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project site: <a href="https://ornerf.github.io/">this https URL</a> (codes available)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10841" title="Abstract">arXiv:2305.10841</a> (replaced) [<a href="/pdf/2305.10841" title="Download PDF">pdf</a>, <a href="/format/2305.10841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GETMusic: Generating Any Music Tracks with a Unified Representation and  Diffusion Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+A">Ang Lv</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Peiling Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11616" title="Abstract">arXiv:2305.11616</a> (replaced) [<a href="/pdf/2305.11616" title="Download PDF">pdf</a>, <a href="/format/2305.11616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversifying Deep Ensembles: A Saliency Map Approach for Enhanced OOD  Detection, Calibration, and Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dereka%2C+S">Stanislav Dereka</a>, 
<a href="/search/cs?searchtype=author&query=Karpukhin%2C+I">Ivan Karpukhin</a>, 
<a href="/search/cs?searchtype=author&query=Zhdanov%2C+M">Maksim Zhdanov</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+S">Sergey Kolesnikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11917" title="Abstract">arXiv:2305.11917</a> (replaced) [<a href="/pdf/2305.11917" title="Download PDF">pdf</a>, <a href="/format/2305.11917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable neural architecture search and transfer learning for  understanding CRISPR/Cas9 off-target enzymatic reactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Z">Zijun Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Lamson%2C+A+R">Adam R. Lamson</a>, 
<a href="/search/q-bio?searchtype=author&query=Shelley%2C+M">Michael Shelley</a>, 
<a href="/search/q-bio?searchtype=author&query=Troyanskaya%2C+O">Olga Troyanskaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12715" title="Abstract">arXiv:2305.12715</a> (replaced) [<a href="/pdf/2305.12715" title="Download PDF">pdf</a>, <a href="/format/2305.12715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imprecise Label Learning: A Unified Framework for Learning with Various  Imprecise Label Configurations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Ankit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+R">Ran Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rita Singh</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 3 figures, 16 tables, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13289" title="Abstract">arXiv:2305.13289</a> (replaced) [<a href="/pdf/2305.13289" title="Download PDF">pdf</a>, <a href="/format/2305.13289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving Minimax Optimal Sample Complexity of Offline Reinforcement  Learning: A DRO-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jinjun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shaofeng Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13849" title="Abstract">arXiv:2305.13849</a> (replaced) [<a href="/pdf/2305.13849" title="Download PDF">pdf</a>, <a href="/format/2305.13849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Latent Representations for Uncertainty Estimation using  Mahalanobis Distance in Deep Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkataramanan%2C+A">Aishwarya Venkataramanan</a>, 
<a href="/search/cs?searchtype=author&query=Benbihi%2C+A">Assia Benbihi</a>, 
<a href="/search/cs?searchtype=author&query=Laviale%2C+M">Martin Laviale</a>, 
<a href="/search/cs?searchtype=author&query=Pradalier%2C+C">Cedric Pradalier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14718" title="Abstract">arXiv:2305.14718</a> (replaced) [<a href="/pdf/2305.14718" title="Download PDF">pdf</a>, <a href="/format/2305.14718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Language Models with Advantage-based Offline Policy Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baheti%2C+A">Ashutosh Baheti</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=Bras%2C+R+L">Ronan Le Bras</a>, 
<a href="/search/cs?searchtype=author&query=Sap%2C+M">Maarten Sap</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+M">Mark Riedl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15196" title="Abstract">arXiv:2305.15196</a> (replaced) [<a href="/pdf/2305.15196" title="Download PDF">pdf</a>, <a href="/format/2305.15196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature-aligned N-BEATS with Sinkhorn divergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonhun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+M">Myeongho Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Myungjoo Kang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Kyunghyun Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15613" title="Abstract">arXiv:2305.15613</a> (replaced) [<a href="/pdf/2305.15613" title="Download PDF">pdf</a>, <a href="/format/2305.15613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Deep O($n$)-Equivariant Hyperspheres
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+P">Pavlo Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>, 
<a href="/search/cs?searchtype=author&query=Wadenb%C3%A4ck%2C+M">M&#xe5;rten Wadenb&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+A">Andreas Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+C">Cuong Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15912" title="Abstract">arXiv:2305.15912</a> (replaced) [<a href="/pdf/2305.15912" title="Download PDF">pdf</a>, <a href="/format/2305.15912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Characteristic Activation Value Analysis for Improved ReLU  Network Feature Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenlin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+H">Hong Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures, 3 tables; code available at: <a href="https://github.com/Wenlin-Chen/geometric-parameterization">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15927" title="Abstract">arXiv:2305.15927</a> (replaced) [<a href="/pdf/2305.15927" title="Download PDF">pdf</a>, <a href="/format/2305.15927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Directed Graphical Models with Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vo%2C+V">Vy Vo</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung Le</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+L">Long-Tung Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">He Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bonilla%2C+E">Edwin Bonilla</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+D">Dinh Phung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16038" title="Abstract">arXiv:2305.16038</a> (replaced) [<a href="/pdf/2305.16038" title="Download PDF">pdf</a>, <a href="/format/2305.16038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit bias of SGD in $L_{2}$-regularized linear DNNs: One-way jumps  from high to low rank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jacot%2C+A">Arthur Jacot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16791" title="Abstract">arXiv:2305.16791</a> (replaced) [<a href="/pdf/2305.16791" title="Download PDF">pdf</a>, <a href="/format/2305.16791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Generalization and Approximation Capacities of Neural Controlled  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bleistein%2C+L">Linus Bleistein</a>, 
<a href="/search/stat?searchtype=author&query=Guilloux%2C+A">Agathe Guilloux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First presented at the F4CLD Workshop at ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16891" title="Abstract">arXiv:2305.16891</a> (replaced) [<a href="/pdf/2305.16891" title="Download PDF">pdf</a>, <a href="/format/2305.16891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization Guarantees of Gradient Descent for Multi-Layer Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Puyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yunwen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+Y">Yiming Ying</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Ding-Xuan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17048" title="Abstract">arXiv:2305.17048</a> (replaced) [<a href="/pdf/2305.17048" title="Download PDF">pdf</a>, <a href="/format/2305.17048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SelfClean: A Self-Supervised Data Cleaning Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gr%C3%B6ger%2C+F">Fabian Gr&#xf6;ger</a>, 
<a href="/search/cs?searchtype=author&query=Lionetti%2C+S">Simone Lionetti</a>, 
<a href="/search/cs?searchtype=author&query=Gottfrois%2C+P">Philippe Gottfrois</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Jimenez%2C+A">Alvaro Gonzalez-Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Amruthalingam%2C+L">Ludovic Amruthalingam</a>, 
<a href="/search/cs?searchtype=author&query=Consortium%2C+L">Labelling Consortium</a>, 
<a href="/search/cs?searchtype=author&query=Groh%2C+M">Matthew Groh</a>, 
<a href="/search/cs?searchtype=author&query=Navarini%2C+A+A">Alexander A. Navarini</a>, 
<a href="/search/cs?searchtype=author&query=Pouly%2C+M">Marc Pouly</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17326" title="Abstract">arXiv:2305.17326</a> (replaced) [<a href="/pdf/2305.17326" title="Download PDF">pdf</a>, <a href="/format/2305.17326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Information Theory for Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhiquan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingqin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weiran Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yang Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18149" title="Abstract">arXiv:2305.18149</a> (replaced) [<a href="/pdf/2305.18149" title="Download PDF">pdf</a>, <a href="/format/2305.18149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Positive-Unlabeled Detection of AI-Generated Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuchuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xutao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Zheyuan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinghua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18944" title="Abstract">arXiv:2305.18944</a> (replaced) [<a href="/pdf/2305.18944" title="Download PDF">pdf</a>, <a href="/format/2305.18944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Dynamic 1D Simulation of Divertor Plasmas with Neural PDE  Surrogates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Poels%2C+Y">Yoeri Poels</a>, 
<a href="/search/physics?searchtype=author&query=Derks%2C+G">Gijs Derks</a>, 
<a href="/search/physics?searchtype=author&query=Westerhof%2C+E">Egbert Westerhof</a>, 
<a href="/search/physics?searchtype=author&query=Minartz%2C+K">Koen Minartz</a>, 
<a href="/search/physics?searchtype=author&query=Wiesen%2C+S">Sven Wiesen</a>, 
<a href="/search/physics?searchtype=author&query=Menkovski%2C+V">Vlado Menkovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Nuclear Fusion
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Nucl. Fusion 63 126012 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19402" title="Abstract">arXiv:2305.19402</a> (replaced) [<a href="/pdf/2305.19402" title="Download PDF">pdf</a>, <a href="/format/2305.19402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Vision Transformers for Robust Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yujia Bao</a>, 
<a href="/search/cs?searchtype=author&query=Karaletsos%2C+T">Theofanis Karaletsos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19473" title="Abstract">arXiv:2305.19473</a> (replaced) [<a href="/pdf/2305.19473" title="Download PDF">pdf</a>, <a href="/format/2305.19473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of Log-Concave Markov Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Saremi%2C+S">Saeed Saremi</a>, 
<a href="/search/stat?searchtype=author&query=Park%2C+J+W">Ji Won Park</a>, 
<a href="/search/stat?searchtype=author&query=Bach%2C+F">Francis Bach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19891" title="Abstract">arXiv:2305.19891</a> (replaced) [<a href="/pdf/2305.19891" title="Download PDF">pdf</a>, <a href="/format/2305.19891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Neighborhood Construction for Structured Large Discrete Action  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akkerman%2C+F">Fabian Akkerman</a>, 
<a href="/search/cs?searchtype=author&query=Luy%2C+J">Julius Luy</a>, 
<a href="/search/cs?searchtype=author&query=van+Heeswijk%2C+W">Wouter van Heeswijk</a>, 
<a href="/search/cs?searchtype=author&query=Schiffer%2C+M">Maximilian Schiffer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00637" title="Abstract">arXiv:2306.00637</a> (replaced) [<a href="/pdf/2306.00637" title="Download PDF">pdf</a>, <a href="/format/2306.00637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wuerstchen: An Efficient Architecture for Large-Scale Text-to-Image  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pernias%2C+P">Pablo Pernias</a>, 
<a href="/search/cs?searchtype=author&query=Rampas%2C+D">Dominic Rampas</a>, 
<a href="/search/cs?searchtype=author&query=Richter%2C+M+L">Mats L. Richter</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+C+J">Christopher J. Pal</a>, 
<a href="/search/cs?searchtype=author&query=Aubreville%2C+M">Marc Aubreville</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corresponding to "W\"urstchen v2"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00658" title="Abstract">arXiv:2306.00658</a> (replaced) [<a href="/pdf/2306.00658" title="Download PDF">pdf</a>, <a href="/format/2306.00658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroGF: A Neural Representation for Fast Geodesic Distance and Path  Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Adikusuma%2C+Y+Y">Yohanes Yudhi Adikusuma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Ying He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00740" title="Abstract">arXiv:2306.00740</a> (replaced) [<a href="/pdf/2306.00740" title="Download PDF">pdf</a>, <a href="/format/2306.00740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Limitations of Temperature Scaling for Distributions with  Overlaps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chidambaram%2C+M">Muthu Chidambaram</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+R">Rong Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 9 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01474" title="Abstract">arXiv:2306.01474</a> (replaced) [<a href="/pdf/2306.01474" title="Download PDF">pdf</a>, <a href="/format/2306.01474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalist Equivariant Transformer Towards 3D Molecular Interaction  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangzhe Kong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenbing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01904" title="Abstract">arXiv:2306.01904</a> (replaced) [<a href="/pdf/2306.01904" title="Download PDF">pdf</a>, <a href="/format/2306.01904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming the Stability Gap in Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harun%2C+M+Y">Md Yousuf Harun</a>, 
<a href="/search/cs?searchtype=author&query=Kanan%2C+C">Christopher Kanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures, 14 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02747" title="Abstract">arXiv:2306.02747</a> (replaced) [<a href="/pdf/2306.02747" title="Download PDF">pdf</a>, <a href="/format/2306.02747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling Non-Stationarity in Reinforcement Learning via Causal-Origin  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yilin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Boyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zongqing Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02797" title="Abstract">arXiv:2306.02797</a> (replaced) [<a href="/pdf/2306.02797" title="Download PDF">pdf</a>, <a href="/format/2306.02797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-like Few-Shot Learning via Bayesian Reasoning over Natural  Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ellis%2C+K">Kevin Ellis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03857" title="Abstract">arXiv:2306.03857</a> (replaced) [<a href="/pdf/2306.03857" title="Download PDF">pdf</a>, <a href="/format/2306.03857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with a Mole: Transferable latent spatial representations for  navigation without reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bono%2C+G">Guillaume Bono</a>, 
<a href="/search/cs?searchtype=author&query=Antsfeld%2C+L">Leonid Antsfeld</a>, 
<a href="/search/cs?searchtype=author&query=Sadek%2C+A">Assem Sadek</a>, 
<a href="/search/cs?searchtype=author&query=Monaci%2C+G">Gianluca Monaci</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+C">Christian Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04048" title="Abstract">arXiv:2306.04048</a> (replaced) [<a href="/pdf/2306.04048" title="Download PDF">pdf</a>, <a href="/format/2306.04048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite Element Modeling of Pneumatic Bending Actuators for Inflated-Beam  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasquier%2C+C+d">Cosima du Pasquier</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+S">Sehui Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Okamura%2C+A+M">Allison M. Okamura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04244" title="Abstract">arXiv:2306.04244</a> (replaced) [<a href="/pdf/2306.04244" title="Download PDF">pdf</a>, <a href="/format/2306.04244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coarse Is Better? A New Pipeline Towards Self-Supervised Learning with  Uncurated Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Ke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yin-Yin He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianxin Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04719" title="Abstract">arXiv:2306.04719</a> (replaced) [<a href="/pdf/2306.04719" title="Download PDF">pdf</a>, <a href="/format/2306.04719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t trust your eyes: on the (un)reliability of feature visualizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geirhos%2C+R">Robert Geirhos</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+R+S">Roland S. Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=Bilodeau%2C+B">Blair Bilodeau</a>, 
<a href="/search/cs?searchtype=author&query=Brendel%2C+W">Wieland Brendel</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Been Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04817" title="Abstract">arXiv:2306.04817</a> (replaced) [<a href="/pdf/2306.04817" title="Download PDF">pdf</a>, <a href="/format/2306.04817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SiBBlInGS: Similarity-driven Building-Block Inference using Graphs  across States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mudrik%2C+N">Noga Mudrik</a>, 
<a href="/search/stat?searchtype=author&query=Mishne%2C+G">Gal Mishne</a>, 
<a href="/search/stat?searchtype=author&query=Charles%2C+A+S">Adam S. Charles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05274" title="Abstract">arXiv:2306.05274</a> (replaced) [<a href="/pdf/2306.05274" title="Download PDF">pdf</a>, <a href="/format/2306.05274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structify-Net: Random Graph generation with controlled size and  customized structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cazabet%2C+R">Remy Cazabet</a>, 
<a href="/search/cs?searchtype=author&query=Citraro%2C+S">Salvatore Citraro</a>, 
<a href="/search/cs?searchtype=author&query=Rossetti%2C+G">Giulio Rossetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version at PCI network science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05281" title="Abstract">arXiv:2306.05281</a> (replaced) [<a href="/e-print/2306.05281" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Graph Reconstruction by Dynamic Signal Coefficient for Fault  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=He%2C+W">Wenbin He</a>, 
<a href="/search/eess?searchtype=author&query=Mao%2C+J">Jianxu Mao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yaonan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhe Li</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+Q">Qiu Fang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Haotian Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The feature extraction algorithm DFSL has errors in derivation and experimental deficiencies
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06192" title="Abstract">arXiv:2306.06192</a> (replaced) [<a href="/pdf/2306.06192" title="Download PDF">pdf</a>, <a href="/format/2306.06192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ada-NAV: Adaptive Trajectory-Based Sample Efficient Policy Learning for  Robotic Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+B">Bhrij Patel</a>, 
<a href="/search/cs?searchtype=author&query=Weerakoon%2C+K">Kasun Weerakoon</a>, 
<a href="/search/cs?searchtype=author&query=Suttle%2C+W+A">Wesley A. Suttle</a>, 
<a href="/search/cs?searchtype=author&query=Koppel%2C+A">Alec Koppel</a>, 
<a href="/search/cs?searchtype=author&query=Sadler%2C+B+M">Brian M. Sadler</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bedi%2C+A+S">Amrit Singh Bedi</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06391" title="Abstract">arXiv:2306.06391</a> (replaced) [<a href="/pdf/2306.06391" title="Download PDF">pdf</a>, <a href="/format/2306.06391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Design Principles of the Elixir Type System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castagna%2C+G">Giuseppe Castagna</a>, 
<a href="/search/cs?searchtype=author&query=Duboc%2C+G">Guillaume Duboc</a>, 
<a href="/search/cs?searchtype=author&query=Valim%2C+J">Jos&#xe9; Valim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07261" title="Abstract">arXiv:2306.07261</a> (replaced) [<a href="/pdf/2306.07261" title="Download PDF">pdf</a>, <a href="/format/2306.07261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unprocessing Seven Years of Algorithmic Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruz%2C+A+F">Andr&#xe9; F. Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Hardt%2C+M">Moritz Hardt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11957" title="Abstract">arXiv:2306.11957</a> (replaced) [<a href="/pdf/2306.11957" title="Download PDF">pdf</a>, <a href="/format/2306.11957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Mitigating Spurious Correlations in the Wild: A Benchmark and a  more Realistic Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Siddharth Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yihao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mirzasoleiman%2C+B">Baharan Mirzasoleiman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Package: <a href="https://github.com/BigML-CS-UCLA/SpuCo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13253" title="Abstract">arXiv:2306.13253</a> (replaced) [<a href="/pdf/2306.13253" title="Download PDF">pdf</a>, <a href="/format/2306.13253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Grokking Long Before it Happens: A look into the loss  landscape of models which grok
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Notsawo%2C+P+J+T">Pascal Jr. Tikeng Notsawo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hattie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pezeshki%2C+M">Mohammad Pezeshki</a>, 
<a href="/search/cs?searchtype=author&query=Rish%2C+I">Irina Rish</a>, 
<a href="/search/cs?searchtype=author&query=Dumas%2C+G">Guillaume Dumas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 30 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14565" title="Abstract">arXiv:2306.14565</a> (replaced) [<a href="/pdf/2306.14565" title="Download PDF">pdf</a>, <a href="/format/2306.14565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Hallucination in Large Multi-Modal Models via Robust  Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fuxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yacoob%2C+Y">Yaser Yacoob</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 32 figures. Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14861" title="Abstract">arXiv:2306.14861</a> (replaced) [<a href="/pdf/2306.14861" title="Download PDF">pdf</a>, <a href="/format/2306.14861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Task Structures for Improved Identifiability in Neural  Network Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+W">Wenlin Chen</a>, 
<a href="/search/stat?searchtype=author&query=Horwood%2C+J">Julien Horwood</a>, 
<a href="/search/stat?searchtype=author&query=Heo%2C+J">Juyeon Heo</a>, 
<a href="/search/stat?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures, 5 tables, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15927" title="Abstract">arXiv:2306.15927</a> (replaced) [<a href="/pdf/2306.15927" title="Download PDF">pdf</a>, <a href="/format/2306.15927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Dynamic Graphs from All Contextual Information for Accurate  Point-of-Interest Visit Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hajisafi%2C+A">Arash Hajisafi</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haowen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shaham%2C+S">Sina Shaham</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haoji Hu</a>, 
<a href="/search/cs?searchtype=author&query=Siampou%2C+M+D">Maria Despoina Siampou</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+Y">Yao-Yi Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Shahabi%2C+C">Cyrus Shahabi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15993" title="Abstract">arXiv:2306.15993</a> (replaced) [<a href="/pdf/2306.15993" title="Download PDF">pdf</a>, <a href="/format/2306.15993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Condorcet Domains of Degree at most Seven
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akello-Egwell%2C+D">Dolica Akello-Egwell</a>, 
<a href="/search/cs?searchtype=author&query=Leedham-Green%2C+C">Charles Leedham-Green</a>, 
<a href="/search/cs?searchtype=author&query=Litterick%2C+A">Alastair Litterick</a>, 
<a href="/search/cs?searchtype=author&query=Markstr%C3%B6m%2C+K">Klas Markstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Riis%2C+S">S&#xf8;ren Riis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Typos corrected, some open problems, a conjecture, and a new figure has been added in the latest version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Theoretical Economics (econ.TH); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00398" title="Abstract">arXiv:2307.00398</a> (replaced) [<a href="/pdf/2307.00398" title="Download PDF">pdf</a>, <a href="/format/2307.00398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProbVLM: Probabilistic Adapter for Frozen Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+U">Uddeshya Upadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Karthik%2C+S">Shyamgopal Karthik</a>, 
<a href="/search/cs?searchtype=author&query=Mancini%2C+M">Massimiliano Mancini</a>, 
<a href="/search/cs?searchtype=author&query=Akata%2C+Z">Zeynep Akata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00986" title="Abstract">arXiv:2307.00986</a> (replaced) [<a href="/pdf/2307.00986" title="Download PDF">pdf</a>, <a href="/format/2307.00986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing impact-resistant bio-inspired low-porosity structures using  neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kushwaha%2C+S">Shashank Kushwaha</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junyan He</a>, 
<a href="/search/cs?searchtype=author&query=Abueidda%2C+D">Diab Abueidda</a>, 
<a href="/search/cs?searchtype=author&query=Jasiuk%2C+I">Iwona Jasiuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01362" title="Abstract">arXiv:2307.01362</a> (replaced) [<a href="/pdf/2307.01362" title="Download PDF">pdf</a>, <a href="/format/2307.01362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Superpoints Matching for Robust Point Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aniket Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yiming Xie</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+H">Hanumant Singh</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Huaizu Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01429" title="Abstract">arXiv:2307.01429</a> (replaced) [<a href="/pdf/2307.01429" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart filter aided domain adversarial neural network for fault diagnosis  in noisy industrial scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dai%2C+B">Baorui Dai</a>, 
<a href="/search/eess?searchtype=author&query=Frusque%2C+G">Ga&#xeb;tan Frusque</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tianfu Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/eess?searchtype=author&query=Fink%2C+O">Olga Fink</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03811" title="Abstract">arXiv:2307.03811</a> (replaced) [<a href="/pdf/2307.03811" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formulation Graphs for Mapping Structure-Composition of Battery  Electrolytes to Device Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sharma%2C+V">Vidushi Sharma</a>, 
<a href="/search/cond-mat?searchtype=author&query=Giammona%2C+M">Maxwell Giammona</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zubarev%2C+D">Dmitry Zubarev</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tek%2C+A">Andy Tek</a>, 
<a href="/search/cond-mat?searchtype=author&query=Nugyuen%2C+K">Khanh Nugyuen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sundberg%2C+L">Linda Sundberg</a>, 
<a href="/search/cond-mat?searchtype=author&query=Congiu%2C+D">Daniele Congiu</a>, 
<a href="/search/cond-mat?searchtype=author&query=La%2C+Y">Young-Hye La</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04172" title="Abstract">arXiv:2307.04172</a> (replaced) [<a href="/pdf/2307.04172" title="Download PDF">pdf</a>, <a href="/format/2307.04172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Generative Large Language Models Perform ASR Error Correction?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Rao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+M">Mengjie Qian</a>, 
<a href="/search/cs?searchtype=author&query=Manakul%2C+P">Potsawee Manakul</a>, 
<a href="/search/cs?searchtype=author&query=Gales%2C+M">Mark Gales</a>, 
<a href="/search/cs?searchtype=author&query=Knill%2C+K">Kate Knill</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07085" title="Abstract">arXiv:2307.07085</a> (replaced) [<a href="/pdf/2307.07085" title="Download PDF">pdf</a>, <a href="/ps/2307.07085" title="Download PostScript">ps</a>, <a href="/format/2307.07085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine-learned molecular mechanics force field for the simulation of  protein-ligand systems and beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Takaba%2C+K">Kenichiro Takaba</a>, 
<a href="/search/physics?searchtype=author&query=Pulido%2C+I">Iv&#xe1;n Pulido</a>, 
<a href="/search/physics?searchtype=author&query=Behara%2C+P+K">Pavan Kumar Behara</a>, 
<a href="/search/physics?searchtype=author&query=Henry%2C+M">Mike Henry</a>, 
<a href="/search/physics?searchtype=author&query=MacDermott-Opeskin%2C+H">Hugo MacDermott-Opeskin</a>, 
<a href="/search/physics?searchtype=author&query=Chodera%2C+J+D">John D. Chodera</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Y">Yuanqing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07218" title="Abstract">arXiv:2307.07218</a> (replaced) [<a href="/pdf/2307.07218" title="Download PDF">pdf</a>, <a href="/format/2307.07218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mega-TTS 2: Zero-Shot Text-to-Speech with Arbitrary Length Speech  Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Z">Ziyue Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jinglin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+Y">Yi Ren</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+J">Jinzheng He</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+Z">Zhenhui Ye</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+P">Pengfei Wei</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chunfeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xiang Yin</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Zejun Ma</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Unpublished technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07453" title="Abstract">arXiv:2307.07453</a> (replaced) [<a href="/pdf/2307.07453" title="Download PDF">pdf</a>, <a href="/format/2307.07453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigation of Deep Learning-Based Filtered Density Function for Large  Eddy Simulation of Turbulent Scalar Mixing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Bansude%2C+S">Shubhangi Bansude</a>, 
<a href="/search/physics?searchtype=author&query=Sheikhi%2C+R">Reza Sheikhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08202" title="Abstract">arXiv:2307.08202</a> (replaced) [<a href="/pdf/2307.08202" title="Download PDF">pdf</a>, <a href="/format/2307.08202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Beamforming and User Association Design for Integrated  HAPS-Terrestrial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shamsabadi%2C+A+A">Afsoon Alidadi Shamsabadi</a>, 
<a href="/search/eess?searchtype=author&query=Yadav%2C+A">Animesh Yadav</a>, 
<a href="/search/eess?searchtype=author&query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages singlecolumn, 5 figures, under review in IEEE Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08430" title="Abstract">arXiv:2307.08430</a> (replaced) [<a href="/pdf/2307.08430" title="Download PDF">pdf</a>, <a href="/format/2307.08430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-range Meta-path Search through Progressive Sampling on Large-scale  Heterogeneous Information Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zijie Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qiuting He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kun He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08945" title="Abstract">arXiv:2307.08945</a> (replaced) [<a href="/pdf/2307.08945" title="Download PDF">pdf</a>, <a href="/format/2307.08945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Label Bias via Decoupled Confident Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunyi Li</a>, 
<a href="/search/cs?searchtype=author&query=De-Arteaga%2C+M">Maria De-Arteaga</a>, 
<a href="/search/cs?searchtype=author&query=Saar-Tsechansky%2C+M">Maytal Saar-Tsechansky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AI &amp; HCI Workshop at the 40th International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09087" title="Abstract">arXiv:2307.09087</a> (replaced) [<a href="/pdf/2307.09087" title="Download PDF">pdf</a>, <a href="/format/2307.09087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Hitchhiker&#x27;s Guide to Malicious Third-Party Dependencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ladisa%2C+P">Piergiorgio Ladisa</a>, 
<a href="/search/cs?searchtype=author&query=Sahin%2C+M">Merve Sahin</a>, 
<a href="/search/cs?searchtype=author&query=Ponta%2C+S+E">Serena Elisa Ponta</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+M">Marco Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+M">Matias Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Barais%2C+O">Olivier Barais</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2023 Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses (SCORED '23), November 30, 2023, Copenhagen, Denmark
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09955" title="Abstract">arXiv:2307.09955</a> (replaced) [<a href="/pdf/2307.09955" title="Download PDF">pdf</a>, <a href="/format/2307.09955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XSkill: Cross Embodiment Skill Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengda Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenjia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+C">Cheng Chi</a>, 
<a href="/search/cs?searchtype=author&query=Veloso%2C+M">Manuela Veloso</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shuran Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15503" title="Abstract">arXiv:2307.15503</a> (replaced) [<a href="/pdf/2307.15503" title="Download PDF">pdf</a>, <a href="/format/2307.15503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Applicability of Federated Learning to Official Statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stock%2C+J">Joshua Stock</a>, 
<a href="/search/cs?searchtype=author&query=Hauke%2C+O">Oliver Hauke</a>, 
<a href="/search/cs?searchtype=author&query=Wei%C3%9Fmann%2C+J">Julius Wei&#xdf;mann</a>, 
<a href="/search/cs?searchtype=author&query=Federrath%2C+H">Hannes Federrath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16189" title="Abstract">arXiv:2307.16189</a> (replaced) [<a href="/pdf/2307.16189" title="Download PDF">pdf</a>, <a href="/format/2307.16189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Approach to Mitigate Numerical Instability in  Backpropagation for 16-bit Neural Network Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Juyoung Yun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00002" title="Abstract">arXiv:2308.00002</a> (replaced) [<a href="/pdf/2308.00002" title="Download PDF">pdf</a>, <a href="/ps/2308.00002" title="Download PostScript">ps</a>, <a href="/format/2308.00002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Overview Of Temporal Commonsense Reasoning and Acquisition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wenzel%2C+G">Georg Wenzel</a>, 
<a href="/search/cs?searchtype=author&query=Jatowt%2C+A">Adam Jatowt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 7 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03286" title="Abstract">arXiv:2308.03286</a> (replaced) [<a href="/pdf/2308.03286" title="Download PDF">pdf</a>, <a href="/format/2308.03286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Label Self-Supervised Learning with Scene Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Ke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+M">Minghao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianxin Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03817" title="Abstract">arXiv:2308.03817</a> (replaced) [<a href="/pdf/2308.03817" title="Download PDF">pdf</a>, <a href="/format/2308.03817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An improved local radial basis function method for solving small-strain  elasto-plasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vuga%2C+G">Ga&#x161;per Vuga</a>, 
<a href="/search/math?searchtype=author&query=Mavri%C4%8D%2C+B">Bo&#x161;tjan Mavri&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=%C5%A0arler%2C+B">Bo&#x17e;idar &#x160;arler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04553" title="Abstract">arXiv:2308.04553</a> (replaced) [<a href="/pdf/2308.04553" title="Download PDF">pdf</a>, <a href="/format/2308.04553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Fake to Real: Pretraining on Balanced Synthetic Images to Prevent  Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qraitem%2C+M">Maan Qraitem</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05021" title="Abstract">arXiv:2308.05021</a> (replaced) [<a href="/pdf/2308.05021" title="Download PDF">pdf</a>, <a href="/format/2308.05021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Error Propagation of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangming Li</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICLR-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06203" title="Abstract">arXiv:2308.06203</a> (replaced) [<a href="/pdf/2308.06203" title="Download PDF">pdf</a>, <a href="/format/2308.06203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Causal Probabilistic Framework for Prediction,  Action-Selection &amp; Explanations for Robot Block-Stacking Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cannizzaro%2C+R">Ricardo Cannizzaro</a>, 
<a href="/search/cs?searchtype=author&query=Routley%2C+J">Jonathan Routley</a>, 
<a href="/search/cs?searchtype=author&query=Kunze%2C+L">Lars Kunze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 4 figures, camera-ready manuscript, accepted to the "Causality for Robotics: Answering the Question of Why" workshop at the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07758" title="Abstract">arXiv:2308.07758</a> (replaced) [<a href="/pdf/2308.07758" title="Download PDF">pdf</a>, <a href="/format/2308.07758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forward-Backward Reasoning in Large Language Models for Mathematical  Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Weisen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Han Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Longhui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+J+T">James T. Kwok</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09440" title="Abstract">arXiv:2308.09440</a> (replaced) [<a href="/pdf/2308.09440" title="Download PDF">pdf</a>, <a href="/format/2308.09440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scope is all you need: Transforming LLMs for HPC Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadosh%2C+T">Tal Kadosh</a>, 
<a href="/search/cs?searchtype=author&query=Hasabnis%2C+N">Niranjan Hasabnis</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+V+A">Vy A. Vo</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+N">Nadav Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Krien%2C+N">Neva Krien</a>, 
<a href="/search/cs?searchtype=author&query=Wasay%2C+A">Abdul Wasay</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N">Nesreen Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Willke%2C+T">Ted Willke</a>, 
<a href="/search/cs?searchtype=author&query=Tamir%2C+G">Guy Tamir</a>, 
<a href="/search/cs?searchtype=author&query=Pinter%2C+Y">Yuval Pinter</a>, 
<a href="/search/cs?searchtype=author&query=Mattson%2C+T">Timothy Mattson</a>, 
<a href="/search/cs?searchtype=author&query=Oren%2C+G">Gal Oren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09959" title="Abstract">arXiv:2308.09959</a> (replaced) [<a href="/pdf/2308.09959" title="Download PDF">pdf</a>, <a href="/format/2308.09959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hummingbird: A Flexible and Lightweight Inter-Domain  Bandwidth-Reservation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giuliari%2C+G">Giacomo Giuliari</a>, 
<a href="/search/cs?searchtype=author&query=Legner%2C+M">Markus Legner</a>, 
<a href="/search/cs?searchtype=author&query=Perrig%2C+A">Adrian Perrig</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J">Jean-Pierre Smith</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCst%2C+K">Karl W&#xfc;st</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11819" title="Abstract">arXiv:2308.11819</a> (replaced) [<a href="/pdf/2308.11819" title="Download PDF">pdf</a>, <a href="/format/2308.11819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair and Accurate Prediction with Model Generalization via Deconfounder  in Healthcare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P">Philip Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11951" title="Abstract">arXiv:2308.11951</a> (replaced) [<a href="/pdf/2308.11951" title="Download PDF">pdf</a>, <a href="/format/2308.11951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose Modulated Avatars from Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chunjin Song</a>, 
<a href="/search/cs?searchtype=author&query=Wandt%2C+B">Bastian Wandt</a>, 
<a href="/search/cs?searchtype=author&query=Rhodin%2C+H">Helge Rhodin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12029" title="Abstract">arXiv:2308.12029</a> (replaced) [<a href="/pdf/2308.12029" title="Download PDF">pdf</a>, <a href="/format/2308.12029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Balancing for Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Baijiong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Weisen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Feiyang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying-Cong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+J+T">James T. Kwok</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12683" title="Abstract">arXiv:2308.12683</a> (replaced) [<a href="/pdf/2308.12683" title="Download PDF">pdf</a>, <a href="/format/2308.12683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The key to the enhanced performance of slab-like topologically  interlocked structures with non-planar blocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Koureas%2C+I">Ioannis Koureas</a>, 
<a href="/search/math?searchtype=author&query=Pundir%2C+M">Mohit Pundir</a>, 
<a href="/search/math?searchtype=author&query=Feldfogel%2C+S">Shai Feldfogel</a>, 
<a href="/search/math?searchtype=author&query=Kammer%2C+D+S">David S. Kammer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14477" title="Abstract">arXiv:2308.14477</a> (replaced) [<a href="/pdf/2308.14477" title="Download PDF">pdf</a>, <a href="/format/2308.14477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical needle tip tracking based on Optical Imaging and AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhuoqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%B8rensen%2C+S+L+B">Simon Lyck Bj&#xe6;rt S&#xf8;rensen</a>, 
<a href="/search/cs?searchtype=author&query=Olsen%2C+M+W">Mikkel Werge Olsen</a>, 
<a href="/search/cs?searchtype=author&query=Eriksen%2C+R+L">Ren&#xe9; Lynge Eriksen</a>, 
<a href="/search/cs?searchtype=author&query=Savarimuthu%2C+T+R">Thiusius Rajeeth Savarimuthu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15054" title="Abstract">arXiv:2308.15054</a> (replaced) [<a href="/pdf/2308.15054" title="Download PDF">pdf</a>, <a href="/format/2308.15054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quasi-Polynomial Algorithm for Subset-Sum Problems with At Most One  Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Costandin%2C+M">Marius Costandin</a>, 
<a href="/search/math?searchtype=author&query=Costandin%2C+B">Beniamin Costandin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2307.13015">arXiv:2307.13015</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15605" title="Abstract">arXiv:2308.15605</a> (replaced) [<a href="/pdf/2308.15605" title="Download PDF">pdf</a>, <a href="/format/2308.15605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarks for Detecting Measurement Tampering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roger%2C+F">Fabien Roger</a>, 
<a href="/search/cs?searchtype=author&query=Greenblatt%2C+R">Ryan Greenblatt</a>, 
<a href="/search/cs?searchtype=author&query=Nadeau%2C+M">Max Nadeau</a>, 
<a href="/search/cs?searchtype=author&query=Shlegeris%2C+B">Buck Shlegeris</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+N">Nate Thomas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Edits: extended and improved appendices, fixed references, figures, and typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16149" title="Abstract">arXiv:2308.16149</a> (replaced) [<a href="/pdf/2308.16149" title="Download PDF">pdf</a>, <a href="/format/2308.16149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open  Generative Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+N">Neha Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S+K">Sunil Kumar Sahu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+B">Bokang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Katipomu%2C+S">Satheesh Katipomu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haonan Li</a>, 
<a href="/search/cs?searchtype=author&query=Koto%2C+F">Fajri Koto</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+W">William Marshall</a>, 
<a href="/search/cs?searchtype=author&query=Gosal%2C+G">Gurpreet Gosal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cynthia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Afzal%2C+O+M">Osama Mohammed Afzal</a>, 
<a href="/search/cs?searchtype=author&query=Kamboj%2C+S">Samta Kamboj</a>, 
<a href="/search/cs?searchtype=author&query=Pandit%2C+O">Onkar Pandit</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+R">Rahul Pal</a>, 
<a href="/search/cs?searchtype=author&query=Pradhan%2C+L">Lalit Pradhan</a>, 
<a href="/search/cs?searchtype=author&query=Mujahid%2C+Z+M">Zain Muhammad Mujahid</a>, 
<a href="/search/cs?searchtype=author&query=Baali%2C+M">Massa Baali</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xudong Han</a>, 
<a href="/search/cs?searchtype=author&query=Bsharat%2C+S+M">Sondos Mahmoud Bsharat</a>, 
<a href="/search/cs?searchtype=author&query=Aji%2C+A+F">Alham Fikri Aji</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengzhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Vassilieva%2C+N">Natalia Vassilieva</a>, 
<a href="/search/cs?searchtype=author&query=Hestness%2C+J">Joel Hestness</a>, 
<a href="/search/cs?searchtype=author&query=Hock%2C+A">Andy Hock</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+A">Andrew Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jonathan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jackson%2C+A">Andrew Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H+X">Hector Xuguang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Timothy Baldwin</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Arabic-centric, foundation model, large-language model, LLM, generative model, instruction-tuned, Jais, Jais-chat
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00127" title="Abstract">arXiv:2309.00127</a> (replaced) [<a href="/pdf/2309.00127" title="Download PDF">pdf</a>, <a href="/format/2309.00127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FTA: Stealthy and Adaptive Backdoor Attack with Flexible Triggers on  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yanqi Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dazhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Congwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kaitai Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01188" title="Abstract">arXiv:2309.01188</a> (replaced) [<a href="/pdf/2309.01188" title="Download PDF">pdf</a>, <a href="/format/2309.01188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-trained Neural Recommenders: A Transferable Zero-Shot Framework for  Recommendation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+A">Adit Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+H">Hari Sundaram</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunzhe Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03179" title="Abstract">arXiv:2309.03179</a> (replaced) [<a href="/pdf/2309.03179" title="Download PDF">pdf</a>, <a href="/format/2309.03179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLiMe: Segment Like Me
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khani%2C+A">Aliasghar Khani</a>, 
<a href="/search/cs?searchtype=author&query=Taghanaki%2C+S+A">Saeid Asgari Taghanaki</a>, 
<a href="/search/cs?searchtype=author&query=Sanghi%2C+A">Aditya Sanghi</a>, 
<a href="/search/cs?searchtype=author&query=Amiri%2C+A+M">Ali Mahdavi Amiri</a>, 
<a href="/search/cs?searchtype=author&query=Hamarneh%2C+G">Ghassan Hamarneh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03377" title="Abstract">arXiv:2309.03377</a> (replaced) [<a href="/pdf/2309.03377" title="Download PDF">pdf</a>, <a href="/format/2309.03377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StreamBed: capacity planning for stream processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosinosky%2C+G">Guillaume Rosinosky</a>, 
<a href="/search/cs?searchtype=author&query=Schmitz%2C+D">Donatien Schmitz</a>, 
<a href="/search/cs?searchtype=author&query=Rivi%C3%A8re%2C+E">Etienne Rivi&#xe8;re</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures. This project has been funded by the Walloon region (Belgium) through the Win2Wal project GEPICIAD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03404" title="Abstract">arXiv:2309.03404</a> (replaced) [<a href="/pdf/2309.03404" title="Download PDF">pdf</a>, <a href="/format/2309.03404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Communication and Reference Songs in the Mixing Process:  Insights from Professional Mix Engineers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vanka%2C+S+S">Soumya Sai Vanka</a>, 
<a href="/search/cs?searchtype=author&query=Safi%2C+M">Maryam Safi</a>, 
<a href="/search/cs?searchtype=author&query=Rolland%2C+J">Jean-Baptiste Rolland</a>, 
<a href="/search/cs?searchtype=author&query=Fazekas%2C+G">Gy&#xf6;rgy Fazekas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04669" title="Abstract">arXiv:2309.04669</a> (replaced) [<a href="/pdf/2309.04669" title="Download PDF">pdf</a>, <a href="/format/2309.04669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual  Tokenization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Chao Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jianchao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Quzhe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Chenyi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">An Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chengru Song</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xiaoqiang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+W">Wenwu Ou</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Kun Gai</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+Y">Yadong Mu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04899" title="Abstract">arXiv:2309.04899</a> (replaced) [<a href="/pdf/2309.04899" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transient Attacks against the VMG-KLJN Secure Key Exchanger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdous%2C+S">Shahriar Ferdous</a>, 
<a href="/search/cs?searchtype=author&query=Kish%2C+L+B">Laszlo B. Kish</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05086" title="Abstract">arXiv:2309.05086</a> (replaced) [<a href="/pdf/2309.05086" title="Download PDF">pdf</a>, <a href="/format/2309.05086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural-Hidden-CRF: A Robust Weakly-Supervised Sequence Labeler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hailong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qianren Mao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengpeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, accepted by SIGKDD-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05833" title="Abstract">arXiv:2309.05833</a> (replaced) [<a href="/pdf/2309.05833" title="Download PDF">pdf</a>, <a href="/format/2309.05833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PACE-LM: Prompting and Augmentation for Calibrated Confidence Estimation  with GPT-4 in Cloud Incident Root Cause Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dylan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuchao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+C">Chetan Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Las-Casas%2C+P">Pedro Las-Casas</a>, 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+R">Rodrigo Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05854" title="Abstract">arXiv:2309.05854</a> (replaced) [<a href="/pdf/2309.05854" title="Download PDF">pdf</a>, <a href="/format/2309.05854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Information Acquisition and Social Learning Dynamics: A  Rational Inattention Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiqing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhanjiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huisheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H+V">H.Vicky Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06553" title="Abstract">arXiv:2309.06553</a> (replaced) [<a href="/pdf/2309.06553" title="Download PDF">pdf</a>, <a href="/format/2309.06553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query-Dependent Prompt Evaluation and Optimization with Offline Inverse  RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCy%C3%BCk%2C+A">Alihan H&#xfc;y&#xfc;k</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06600" title="Abstract">arXiv:2309.06600</a> (replaced) [<a href="/pdf/2309.06600" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Narrative as a Dynamical System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doxas%2C+I">Isidoros Doxas</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Meiss%2C+J">James Meiss</a> (3), 
<a href="/search/cs?searchtype=author&query=Bottone%2C+S">Steven Bottone</a> (1), 
<a href="/search/cs?searchtype=author&query=Strelich%2C+T">Tom Strelich</a> (4 and 5), 
<a href="/search/cs?searchtype=author&query=Plummer%2C+A">Andrew Plummer</a> (5 and 6), 
<a href="/search/cs?searchtype=author&query=Breland%2C+A">Adrienne Breland</a> (5 and 7), 
<a href="/search/cs?searchtype=author&query=Dennis%2C+S">Simon Dennis</a> (8 and 9), 
<a href="/search/cs?searchtype=author&query=Garvin-Doxas%2C+K">Kathy Garvin-Doxas</a> (9 and 10), 
<a href="/search/cs?searchtype=author&query=Klymkowsky%2C+M">Michael Klymkowsky</a> (3) ( (1) Northrop Grumman Corporation, (2) Some work performed at the University of Colorado, Boulder, (3) University of Colorado, Boulder, (4) Fusion Constructive LLC, (5) Work performed at Northop Grumman Corporation (6) Current Address JP Morgan, (7) Current address, GALT Aerospace, (8) University of Melbourne, (9) Work performed at the University of Colorado, Boulder, (10) Boulder Internet Technologies)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07156" title="Abstract">arXiv:2309.07156</a> (replaced) [<a href="/pdf/2309.07156" title="Download PDF">pdf</a>, <a href="/format/2309.07156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-efficient Deep Learning Approach for Single-Channel EEG-Based Sleep  Stage Classification with Model Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sharma%2C+S">Shivam Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Maiti%2C+S">Suvadeep Maiti</a>, 
<a href="/search/eess?searchtype=author&query=Mythirayee%2C+S">S. Mythirayee</a>, 
<a href="/search/eess?searchtype=author&query=Rajendran%2C+S">Srijithesh Rajendran</a>, 
<a href="/search/eess?searchtype=author&query=Bapi%2C+R+S">Raju Surampudi Bapi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07311" title="Abstract">arXiv:2309.07311</a> (replaced) [<a href="/pdf/2309.07311" title="Download PDF">pdf</a>, <a href="/format/2309.07311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and  Simplicity Bias in MLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Angelica Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shwartz-Ziv%2C+R">Ravid Shwartz-Ziv</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Leavitt%2C+M+L">Matthew L. Leavitt</a>, 
<a href="/search/cs?searchtype=author&query=Saphra%2C+N">Naomi Saphra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07797" title="Abstract">arXiv:2309.07797</a> (replaced) [<a href="/pdf/2309.07797" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Dynamical Principles of Storytelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doxas%2C+I">Isidoros Doxas</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Meiss%2C+J">James Meiss</a> (3), 
<a href="/search/cs?searchtype=author&query=Bottone%2C+S">Steven Bottone</a> (1), 
<a href="/search/cs?searchtype=author&query=Strelich%2C+T">Tom Strelich</a> (4 and 5), 
<a href="/search/cs?searchtype=author&query=Plummer%2C+A">Andrew Plummer</a> (5 and 6), 
<a href="/search/cs?searchtype=author&query=Breland%2C+A">Adrienne Breland</a> (5 and 7), 
<a href="/search/cs?searchtype=author&query=Dennis%2C+S">Simon Dennis</a> (8 and 9), 
<a href="/search/cs?searchtype=author&query=Garvin-Doxas%2C+K">Kathy Garvin-Doxas</a> (9 and 10), 
<a href="/search/cs?searchtype=author&query=Klymkowsky%2C+M">Michael Klymkowsky</a> (3) ((1) Northrop Grumman Corporation, (2) Some work performed at the University of Colorado, Boulder, (3) University of Colorado, Boulder, (4) Fusion Constructive LLC, (5) Work performed at Northop Grumman Corporation (6) Current Address JP Morgan, (7) Current address, GALT Aerospace, (8) University of Melbourne, (9) Work performed at the University of Colorado, Boulder, (10) Boulder Internet Technologies)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09117" title="Abstract">arXiv:2309.09117</a> (replaced) [<a href="/pdf/2309.09117" title="Download PDF">pdf</a>, <a href="/format/2309.09117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Decoding Improves Reasoning in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=O%27Brien%2C+S">Sean O&#x27;Brien</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Mike Lewis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09865" title="Abstract">arXiv:2309.09865</a> (replaced) [<a href="/pdf/2309.09865" title="Download PDF">pdf</a>, <a href="/format/2309.09865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning for Enhancing Robust Scene Transfer in Vision-based  Agile Flight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+J">Jiaxu Xing</a>, 
<a href="/search/cs?searchtype=author&query=Bauersfeld%2C+L">Leonard Bauersfeld</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yunlong Song</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+C">Chunwei Xing</a>, 
<a href="/search/cs?searchtype=author&query=Scaramuzza%2C+D">Davide Scaramuzza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10581" title="Abstract">arXiv:2309.10581</a> (replaced) [<a href="/pdf/2309.10581" title="Download PDF">pdf</a>, <a href="/format/2309.10581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gateway Station Geographical Planning for Emerging Non-Geostationary  Satellites Constellations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Baeza%2C+V+M">Victor Monzon Baeza</a>, 
<a href="/search/eess?searchtype=author&query=Ortiz%2C+F">Flor Ortiz</a>, 
<a href="/search/eess?searchtype=author&query=Lagunas%2C+E">Eva Lagunas</a>, 
<a href="/search/eess?searchtype=author&query=Abdu%2C+T+S">Tedros Salih Abdu</a>, 
<a href="/search/eess?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10930" title="Abstract">arXiv:2309.10930</a> (replaced) [<a href="/pdf/2309.10930" title="Download PDF">pdf</a>, <a href="/format/2309.10930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Time Training for Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dumpala%2C+S+H">Sri Harsha Dumpala</a>, 
<a href="/search/cs?searchtype=author&query=Sastry%2C+C">Chandramouli Sastry</a>, 
<a href="/search/cs?searchtype=author&query=Oore%2C+S">Sageev Oore</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10966" title="Abstract">arXiv:2309.10966</a> (replaced) [<a href="/pdf/2309.10966" title="Download PDF">pdf</a>, <a href="/format/2309.10966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MBR and QE Finetuning: Training-time Distillation of the Best and Most  Expensive Decoding Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Finkelstein%2C+M">Mara Finkelstein</a>, 
<a href="/search/cs?searchtype=author&query=Freitag%2C+M">Markus Freitag</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11038" title="Abstract">arXiv:2309.11038</a> (replaced) [<a href="/pdf/2309.11038" title="Download PDF">pdf</a>, <a href="/format/2309.11038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaveSeg: Deep Semantic Segmentation and Scene Parsing for Autonomous  Underwater Cave Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+A">A. Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Barua%2C+T">T. Barua</a>, 
<a href="/search/cs?searchtype=author&query=Tibbetts%2C+R">R. Tibbetts</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Z. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+J">M. J. Islam</a>, 
<a href="/search/cs?searchtype=author&query=Rekleitis%2C+I">I. Rekleitis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted for review in ICRA 2024. 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11696" title="Abstract">arXiv:2309.11696</a> (replaced) [<a href="/pdf/2309.11696" title="Download PDF">pdf</a>, <a href="/format/2309.11696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-Augmented LLM Personalization with Short- and Long-Term Memory  Coordination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fubang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yangyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaozhong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11840" title="Abstract">arXiv:2309.11840</a> (replaced) [<a href="/pdf/2309.11840" title="Download PDF">pdf</a>, <a href="/format/2309.11840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Four universal growth regimes in degree-dependent first passage  percolation on spatial random graphs I
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Komj%C3%A1thy%2C+J">J&#xfa;lia Komj&#xe1;thy</a>, 
<a href="/search/math?searchtype=author&query=Lapinskas%2C+J">John Lapinskas</a>, 
<a href="/search/math?searchtype=author&query=Lengler%2C+J">Johannes Lengler</a>, 
<a href="/search/math?searchtype=author&query=Schaller%2C+U">Ulysse Schaller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 78 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Social and Information Networks (cs.SI); Combinatorics (math.CO); Populations and Evolution (q-bio.PE)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12001" title="Abstract">arXiv:2309.12001</a> (replaced) [<a href="/pdf/2309.12001" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To The Effects of Anthropomorphic Cues on Human Perception of Non-Human  Robots: The Role of Gender
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+M">Mahya Ramezani</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez-Lopez%2C+J+L">Jose Luis Sanchez-Lopez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12625" title="Abstract">arXiv:2309.12625</a> (replaced) [<a href="/pdf/2309.12625" title="Download PDF">pdf</a>, <a href="/format/2309.12625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for  Hospitalized Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chufan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dantona%2C+C">Christopher Dantona</a>, 
<a href="/search/cs?searchtype=author&query=Hull%2C+B">Bryan Hull</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13147" title="Abstract">arXiv:2309.13147</a> (replaced) [<a href="/pdf/2309.13147" title="Download PDF">pdf</a>, <a href="/format/2309.13147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cardiovascular Disease Risk Prediction via Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habib%2C+A+Z+S+B">Al Zadid Sultan Bin Habib</a>, 
<a href="/search/cs?searchtype=author&query=Syed%2C+M+A+B">Md Asif Bin Syed</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+T">Md Tanvirul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Adjeroh%2C+D+A">Donald A. Adjeroh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, 16th International Conference on Social Computing, Behavioral-Cultural Modeling &amp; Prediction and Behavior Representation in Modeling and Simulation (SBP-BRiMS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13218" title="Abstract">arXiv:2309.13218</a> (replaced) [<a href="/pdf/2309.13218" title="Download PDF">pdf</a>, <a href="/format/2309.13218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Copilot for Business Optimisation: A Framework and A Case Study in  Production Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amarasinghe%2C+P+T">Pivithuru Thejan Amarasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+S">Su Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Alahakoon%2C+D">Damminda Alahakoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13405" title="Abstract">arXiv:2309.13405</a> (replaced) [<a href="/pdf/2309.13405" title="Download PDF">pdf</a>, <a href="/format/2309.13405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Large-Scale MTP$_2$ Gaussian Graphical Models via Bridge-Block  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+J">Jiaxi Ying</a>, 
<a href="/search/cs?searchtype=author&query=Palomar%2C+D+P">Daniel P. Palomar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13471" title="Abstract">arXiv:2309.13471</a> (replaced) [<a href="/pdf/2309.13471" title="Download PDF">pdf</a>, <a href="/format/2309.13471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cloud Watching: Understanding Attacks Against Cloud-Hosted Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izhikevich%2C+L">Liz Izhikevich</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Manda Tran</a>, 
<a href="/search/cs?searchtype=author&query=Kallitsis%2C+M">Michalis Kallitsis</a>, 
<a href="/search/cs?searchtype=author&query=Fass%2C+A">Aurore Fass</a>, 
<a href="/search/cs?searchtype=author&query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2023 ACM Internet Measurement Conference (IMC '23), October 24--26, 2023, Montreal, QC, Canada
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13743" title="Abstract">arXiv:2309.13743</a> (replaced) [<a href="/pdf/2309.13743" title="Download PDF">pdf</a>, <a href="/format/2309.13743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Adaptive MPC Using Uncertainty Compensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tao%2C+R">Ran Tao</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+P">Pan Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Kolmanovsky%2C+I">Ilya Kolmanovsky</a>, 
<a href="/search/eess?searchtype=author&query=Hovakimyan%2C+N">Naira Hovakimyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2208.02985">arXiv:2208.02985</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13860" title="Abstract">arXiv:2309.13860</a> (replaced) [<a href="/pdf/2309.13860" title="Download PDF">pdf</a>, <a href="/format/2309.13860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast-HuBERT: An Efficient Training Framework for Self-Supervised Speech  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanrou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhisheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yakun Song</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhikang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14068" title="Abstract">arXiv:2309.14068</a> (replaced) [<a href="/pdf/2309.14068" title="Download PDF">pdf</a>, <a href="/format/2309.14068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangming Li</a>, 
<a href="/search/cs?searchtype=author&query=van+Breugel%2C+B">Boris van Breugel</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICLR-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14089" title="Abstract">arXiv:2309.14089</a> (replaced) [<a href="/pdf/2309.14089" title="Download PDF">pdf</a>, <a href="/format/2309.14089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiSinger: Bilingual Singing Voice Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Huali Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yueqian Lin</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yao Shi</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+P">Peng Sun</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14303" title="Abstract">arXiv:2309.14303</a> (replaced) [<a href="/pdf/2309.14303" title="Download PDF">pdf</a>, <a href="/format/2309.14303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Diffusion: Diffusion-based Synthetic Dataset Generation for  Pixel-Level Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Truong Vu</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khoi Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14309" title="Abstract">arXiv:2309.14309</a> (replaced) [<a href="/pdf/2309.14309" title="Download PDF">pdf</a>, <a href="/format/2309.14309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Different Explanations for Image Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chockler%2C+H">Hana Chockler</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+D+A">David A. Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Kroening%2C+D">Daniel Kroening</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14490" title="Abstract">arXiv:2309.14490</a> (replaced) [<a href="/pdf/2309.14490" title="Download PDF">pdf</a>, <a href="/format/2309.14490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Can You Move It?&quot;: The Design and Evaluation of Moving VR Shots in  Sport Broadcast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiuqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zichun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yifan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yang Jiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14545" title="Abstract">arXiv:2309.14545</a> (replaced) [<a href="/pdf/2309.14545" title="Download PDF">pdf</a>, <a href="/format/2309.14545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motions in Microseconds via Vectorized Sampling-Based Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomason%2C+W">Wil Thomason</a>, 
<a href="/search/cs?searchtype=author&query=Kingston%2C+Z">Zachary Kingston</a>, 
<a href="/search/cs?searchtype=author&query=Kavraki%2C+L+E">Lydia E. Kavraki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 2 tables. Submitted to the 2024 IEEE International Conference on Robotics and Automation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14709" title="Abstract">arXiv:2309.14709</a> (replaced) [<a href="/pdf/2309.14709" title="Download PDF">pdf</a>, <a href="/format/2309.14709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrap Diffusion Model Curve Estimation for High Resolution Low-Light  Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiancheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14846" title="Abstract">arXiv:2309.14846</a> (replaced) [<a href="/pdf/2309.14846" title="Download PDF">pdf</a>, <a href="/format/2309.14846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supersonic: Learning to Generate Source Code Optimisations in C/C++
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zimin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Sen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Monperrus%2C+M">Martin Monperrus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15060" title="Abstract">arXiv:2309.15060</a> (replaced) [<a href="/pdf/2309.15060" title="Download PDF">pdf</a>, <a href="/format/2309.15060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Deep Reinforcement Learning for Fronthaul Compression  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gr%C3%B6nland%2C+A">Axel Gr&#xf6;nland</a>, 
<a href="/search/eess?searchtype=author&query=Russo%2C+A">Alessio Russo</a>, 
<a href="/search/eess?searchtype=author&query=Jedra%2C+Y">Yassir Jedra</a>, 
<a href="/search/eess?searchtype=author&query=Klaiqi%2C+B">Bleron Klaiqi</a>, 
<a href="/search/eess?searchtype=author&query=Gelabert%2C+X">Xavier Gelabert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> conference, ieee
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15112" title="Abstract">arXiv:2309.15112</a> (replaced) [<a href="/pdf/2309.15112" title="Download PDF">pdf</a>, <a href="/format/2309.15112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InternLM-XComposer: A Vision-Language Large Model for Advanced  Text-image Comprehension and Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuhang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+L">Linke Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shuangrui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haodong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingcheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/InternLM/InternLM-XComposer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15164" title="Abstract">arXiv:2309.15164</a> (replaced) [<a href="/pdf/2309.15164" title="Download PDF">pdf</a>, <a href="/format/2309.15164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Reconstruction with Generalizable Neural Fields using Scene Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yang Fu</a>, 
<a href="/search/cs?searchtype=author&query=De+Mello%2C+S">Shalini De Mello</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueting Li</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Amey Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sifei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://oasisyang.github.io/neural-prior">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15214" title="Abstract">arXiv:2309.15214</a> (replaced) [<a href="/pdf/2309.15214" title="Download PDF">pdf</a>, <a href="/format/2309.15214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Residual Diffusion Modeling for Km-scale Atmospheric  Downscaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mardani%2C+M">Morteza Mardani</a>, 
<a href="/search/cs?searchtype=author&query=Brenowitz%2C+N">Noah Brenowitz</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+Y">Yair Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+J">Jaideep Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chieh-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Chin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Vahdat%2C+A">Arash Vahdat</a>, 
<a href="/search/cs?searchtype=author&query=Kashinath%2C+K">Karthik Kashinath</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Pritchard%2C+M">Mike Pritchard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15293" title="Abstract">arXiv:2309.15293</a> (replaced) [<a href="/pdf/2309.15293" title="Download PDF">pdf</a>, <a href="/format/2309.15293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Diffusion Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berrueta%2C+T+A">Thomas A. Berrueta</a>, 
<a href="/search/cs?searchtype=author&query=Pinosky%2C+A">Allison Pinosky</a>, 
<a href="/search/cs?searchtype=author&query=Murphey%2C+T+D">Todd D. Murphey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For Supplementary Movies, see <a href="https://youtube.com/playlist?list=PLO5AGPa3klrCTSO-t7HZsVNQinHXFQmn9">this https URL</a>&amp;si=cICRyEuRWy565_36. This version fixes some equation reference numbers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15332" title="Abstract">arXiv:2309.15332</a> (replaced) [<a href="/pdf/2309.15332" title="Download PDF">pdf</a>, <a href="/format/2309.15332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Dataset for Localization, Mapping and Crop Monitoring in  Citrus Tree Farms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+H">Hanzhe Teng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yipeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiaoao Song</a>, 
<a href="/search/cs?searchtype=author&query=Karydis%2C+K">Konstantinos Karydis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 18th International Symposium on Visual Computing (ISVC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15423" title="Abstract">arXiv:2309.15423</a> (replaced) [<a href="/pdf/2309.15423" title="Download PDF">pdf</a>, <a href="/format/2309.15423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prosumers Participation in Markets: A Scalar-Parameterized Function  Bidding Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alawad%2C+A">Abdullah Alawad</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+M+A+u">Muhammad Aneeq uz Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Alshehri%2C+K">Khaled Alshehri</a>, 
<a href="/search/cs?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected typos in the figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15458" title="Abstract">arXiv:2309.15458</a> (replaced) [<a href="/pdf/2309.15458" title="Download PDF">pdf</a>, <a href="/format/2309.15458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lele Xie</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianshan He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongting Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Taifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaopei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+C">Chao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wei Chu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 14 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15575" title="Abstract">arXiv:2309.15575</a> (replaced) [<a href="/pdf/2309.15575" title="Download PDF">pdf</a>, <a href="/format/2309.15575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidence-based Visual Dispersal for Few-shot Unsupervised Domain  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yizhe Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as ICCV 2023 poster (<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15617" title="Abstract">arXiv:2309.15617</a> (replaced) [<a href="/pdf/2309.15617" title="Download PDF">pdf</a>, <a href="/format/2309.15617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RapidEarth: A Search-by-Classification Engine for Large-Scale Geospatial  Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%BClf%2C+C">Christian L&#xfc;lf</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+D+M+L">Denis Mayr Lima Martins</a>, 
<a href="/search/cs?searchtype=author&query=Salles%2C+M+A+V">Marcos Antonio Vaz Salles</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yongluan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gieseke%2C+F">Fabian Gieseke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15660" title="Abstract">arXiv:2309.15660</a> (replaced) [<a href="/pdf/2309.15660" title="Download PDF">pdf</a>, <a href="/format/2309.15660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Frequency Containment Reserve Provision from Battery Hybridized  Hydropower Plants: Theory and Experimental Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gerini%2C+F">Francesco Gerini</a>, 
<a href="/search/eess?searchtype=author&query=Vagnoni%2C+E">Elena Vagnoni</a>, 
<a href="/search/eess?searchtype=author&query=Seydoux%2C+M">Martin Seydoux</a>, 
<a href="/search/eess?searchtype=author&query=Cherkaoui%2C+R">Rachid Cherkaoui</a>, 
<a href="/search/eess?searchtype=author&query=Paolone%2C+M">Mario Paolone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to PSCC2024, Power Systems Computation Conference, Paris, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15730" title="Abstract">arXiv:2309.15730</a> (replaced) [<a href="/pdf/2309.15730" title="Download PDF">pdf</a>, <a href="/format/2309.15730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal graph models fail to capture global temporal dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daniluk%2C+M">Micha&#x142; Daniluk</a>, 
<a href="/search/cs?searchtype=author&query=D%C4%85browski%2C+J">Jacek D&#x105;browski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16163" title="Abstract">arXiv:2309.16163</a> (replaced) [<a href="/pdf/2309.16163" title="Download PDF">pdf</a>, <a href="/format/2309.16163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doppler Time-of-Flight Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juhyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jarosz%2C+W">Wojciech Jarosz</a>, 
<a href="/search/cs?searchtype=author&query=Gkioulekas%2C+I">Ioannis Gkioulekas</a>, 
<a href="/search/cs?searchtype=author&query=Pediredla%2C+A">Adithya Pediredla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 28 Figures, SIGGRAPH Asia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16396" title="Abstract">arXiv:2309.16396</a> (replaced) [<a href="/pdf/2309.16396" title="Download PDF">pdf</a>, <a href="/format/2309.16396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Document-level Relation Extraction (2016-2023)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delaunay%2C+J">Julien Delaunay</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T+H+H">Thi Hong Hanh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Gallardo%2C+C">Carlos-Emiliano Gonz&#xe1;lez-Gallardo</a>, 
<a href="/search/cs?searchtype=author&query=Bordea%2C+G">Georgeta Bordea</a>, 
<a href="/search/cs?searchtype=author&query=Sidere%2C+N">Nicolas Sidere</a>, 
<a href="/search/cs?searchtype=author&query=Doucet%2C+A">Antoine Doucet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16414" title="Abstract">arXiv:2309.16414</a> (replaced) [<a href="/pdf/2309.16414" title="Download PDF">pdf</a>, <a href="/format/2309.16414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Metzen%2C+J+H">Jan Hendrik Metzen</a>, 
<a href="/search/cs?searchtype=author&query=Saranrittichai%2C+P">Piyapat Saranrittichai</a>, 
<a href="/search/cs?searchtype=author&query=Mummadi%2C+C+K">Chaithanya Kumar Mummadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16585" title="Abstract">arXiv:2309.16585</a> (replaced) [<a href="/pdf/2309.16585" title="Download PDF">pdf</a>, <a href="/format/2309.16585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-to-3D using Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zilong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://gsgen3d.github.io.">this https URL</a> Code: <a href="https://github.com/gsgen3d/gsgen">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16633" title="Abstract">arXiv:2309.16633</a> (replaced) [<a href="/pdf/2309.16633" title="Download PDF">pdf</a>, <a href="/ps/2309.16633" title="Download PostScript">ps</a>, <a href="/format/2309.16633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixup Your Own Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yilei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zijian Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chongyao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wangchunshu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+H">Juan Helen Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors equally contributed to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16671" title="Abstract">arXiv:2309.16671</a> (replaced) [<a href="/pdf/2309.16671" title="Download PDF">pdf</a>, <a href="/format/2309.16671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying CLIP Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Saining Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X+E">Xiaoqing Ellen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Po-Yao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Howes%2C+R">Russell Howes</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vasu Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shang-Wen Li</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+G">Gargi Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Feichtenhofer%2C+C">Christoph Feichtenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages. arXiv admin note: text overlap with <a href="/abs/2103.00020">arXiv:2103.00020</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item370">Cross-lists</a></li>
<li><a href="#item412">Replacements</a></li>
</ul>
<small>[ total of 639 entries:  <b>1-639</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2310">2310</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
