<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu 28 Dec 23  to  Fri 29 Dec 23, announced Mon,  1 Jan 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item197">Cross-lists</a></li>
<li><a href="#item218">Replacements</a></li>
</ul>
<small>[ total of 348 entries:  <b>1-348</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon,  1 Jan 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17251" title="Abstract">arXiv:2312.17251</a> [<a href="/pdf/2312.17251" title="Download PDF">pdf</a>, <a href="/ps/2312.17251" title="Download PostScript">ps</a>, <a href="/format/2312.17251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic segmentation of SEM images of lower bainitic and tempered  martensitic steels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bie%2C+X">Xiaohan Bie</a>, 
<a href="/search/cs?searchtype=author&query=Arthanari%2C+M">Manoj Arthanari</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+E+B">Evelin Barbosa de Melo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juancheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Stephen Yue</a>, 
<a href="/search/cs?searchtype=author&query=Brahimi%2C+S">Salim Brahimi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jun Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study employs deep learning techniques to segment scanning electron
microscope images, enabling a quantitative analysis of carbide precipitates in
lower bainite and tempered martensite steels with comparable strength.
Following segmentation, carbides are investigated, and their volume percentage,
size distribution, and orientations are probed within the image dataset. Our
findings reveal that lower bainite and tempered martensite exhibit comparable
volume percentages of carbides, albeit with a more uniform distribution of
carbides in tempered martensite. Carbides in lower bainite demonstrate a
tendency for better alignment than those in tempered martensite, aligning with
the observations of other researchers. However, both microstructures display a
scattered carbide orientation, devoid of any discernible pattern. Comparative
analysis of aspect ratios and sizes of carbides in lower bainite and tempered
martensite unveils striking similarities. The deep learning model achieves an
impressive pixelwise accuracy of 98.0% in classifying carbide/iron matrix at
the individual pixel level. The semantic segmentation derived from deep
learning extends its applicability to the analysis of secondary phases in
various materials, offering a time-efficient, versatile AI-powered workflow for
quantitative microstructure analysis.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17253" title="Abstract">arXiv:2312.17253</a> [<a href="/pdf/2312.17253" title="Download PDF">pdf</a>, <a href="/ps/2312.17253" title="Download PostScript">ps</a>, <a href="/format/2312.17253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based Sentiment Classification: A Comparative Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kayed%2C+M">Mohamed Kayed</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Mabrouk%2C+A">Alhassan Mabrouk</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, 2020, vol. 8, p. 85616-85638
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, Deep Learning (DL) approaches have been applied to solve the
Sentiment Classification (SC) problem, which is a core task in reviews mining
or Sentiment Analysis (SA). The performances of these approaches are affected
by different factors. This paper addresses these factors and classifies them
into three categories: data preparation based factors, feature representation
based factors and the classification techniques based factors. The paper is a
comprehensive literature-based survey that compares the performance of more
than 100 DL-based SC approaches by using 21 public datasets of reviews given by
customers within three specific application domains (products, movies and
restaurants). These 21 datasets have different characteristics
(balanced/imbalanced, size, etc.) to give a global vision for our study. The
comparison explains how the proposed factors quantitatively affect the
performance of the studied DL-based SC approaches.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17254" title="Abstract">arXiv:2312.17254</a> [<a href="/pdf/2312.17254" title="Download PDF">pdf</a>, <a href="/format/2312.17254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faithful Model Evaluation for Model-Based Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goyal%2C+P">Palash Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Rahul Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Statistical significance testing is used in natural language processing (NLP)
to determine whether the results of a study or experiment are likely to be due
to chance or if they reflect a genuine relationship. A key step in significance
testing is the estimation of confidence interval which is a function of sample
variance. Sample variance calculation is straightforward when evaluating
against ground truth. However, in many cases, a metric model is often used for
evaluation. For example, to compare toxicity of two large language models, a
toxicity classifier is used for evaluation. Existing works usually do not
consider the variance change due to metric model errors, which can lead to
wrong conclusions. In this work, we establish the mathematical foundation of
significance testing for model-based metrics. With experiments on public
benchmark datasets and a production system, we show that considering metric
model errors to calculate sample variances for model-based metrics changes the
conclusions in certain experiments.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17256" title="Abstract">arXiv:2312.17256</a> [<a href="/pdf/2312.17256" title="Download PDF">pdf</a>, <a href="/ps/2312.17256" title="Download PostScript">ps</a>, <a href="/format/2312.17256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Bytes to Biases: Investigating the Cultural Self-Perception of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Messner%2C+W">Wolfgang Messner</a>, 
<a href="/search/cs?searchtype=author&query=Greene%2C+T">Tatum Greene</a>, 
<a href="/search/cs?searchtype=author&query=Matalone%2C+J">Josephine Matalone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 tables, 4 figures; Online Supplement: 10 pages, 5 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are able to engage in natural-sounding
conversations with humans, showcasing unprecedented capabilities for
information retrieval and automated decision support. They have disrupted
human-technology interaction and the way businesses operate. However,
technologies based on generative artificial intelligence (GenAI) are known to
hallucinate, misinform, and display biases introduced by the massive datasets
on which they are trained. Existing research indicates that humans may
unconsciously internalize these biases, which can persist even after they stop
using the programs. This study explores the cultural self-perception of LLMs by
prompting ChatGPT (OpenAI) and Bard (Google) with value questions derived from
the GLOBE project. The findings reveal that their cultural self-perception is
most closely aligned with the values of English-speaking countries and
countries characterized by sustained economic competitiveness. Recognizing the
cultural biases of LLMs and understanding how they work is crucial for all
members of society because one does not want the black box of artificial
intelligence to perpetuate bias in humans, who might, in turn, inadvertently
create and train even more biased algorithms.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17257" title="Abstract">arXiv:2312.17257</a> [<a href="/pdf/2312.17257" title="Download PDF">pdf</a>, <a href="/format/2312.17257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving Large Language Model Assistant with Long-Term Conditional  Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+R">Ruifeng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Ziqiang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rapid development of large language models, AI assistants like
ChatGPT have widely entered people's works and lives. In this paper, we present
an evolving large language model assistant that utilizes verbal long-term
memory. It focuses on preserving the knowledge and experience from the history
dialogue between the user and AI assistant, which can be applied to future
dialogue for generating a better response. The model generates a set of records
for each finished dialogue and stores them in the memory. In later usage, given
a new user input, the model uses it to retrieve its related memory to improve
the quality of the response. To find the best form of memory, we explore
different ways of constructing the memory and propose a new memorizing
mechanism called conditional memory to solve the problems in previous methods.
We also investigate the retrieval and usage of memory in the generation
process. The assistant uses GPT-4 as the backbone and we evaluate it on three
constructed test datasets focusing on different abilities required by an AI
assistant with long-term memory.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17258" title="Abstract">arXiv:2312.17258</a> [<a href="/pdf/2312.17258" title="Download PDF">pdf</a>, <a href="/ps/2312.17258" title="Download PostScript">ps</a>, <a href="/format/2312.17258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flying By ML -- CNN Inversion of Affine Transforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Warren%2C+L">L. Van Warren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper describes a machine learning method to automate reading of cockpit
gauges, using a CNN to invert affine transformations and deduce aircraft states
from instrument images. Validated with synthetic images of a turn-and-bank
indicator, this research introduces methods such as generating datasets from a
single image, the 'Clean Training Principle' for optimal noise-free training,
and CNN interpolation for continuous value predictions from categorical data.
It also offers insights into hyperparameter optimization and ML system software
engineering.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17259" title="Abstract">arXiv:2312.17259</a> [<a href="/pdf/2312.17259" title="Download PDF">pdf</a>, <a href="/ps/2312.17259" title="Download PostScript">ps</a>, <a href="/format/2312.17259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Working Memory for Large Language Model Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nan Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jianchuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruiqiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yuzhen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Si Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Ming Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have achieved impressive linguistic
capabilities. However, a key limitation persists in their lack of human-like
memory faculties. LLMs exhibit constrained memory retention across sequential
interactions, hindering complex reasoning. This paper explores the potential of
applying cognitive psychology's working memory frameworks, to enhance LLM
architecture. The limitations of traditional LLM memory designs are analyzed,
including their isolation of distinct dialog episodes and lack of persistent
memory links. To address this, an innovative model is proposed incorporating a
centralized Working Memory Hub and Episodic Buffer access to retain memories
across episodes. This architecture aims to provide greater continuity for
nuanced contextual reasoning during intricate tasks and collaborative
scenarios. While promising, further research is required into optimizing
episodic memory encoding, storage, prioritization, retrieval, and security.
Overall, this paper provides a strategic blueprint for developing LLM agents
with more sophisticated, human-like memory capabilities, highlighting memory
mechanisms as a vital frontier in artificial general intelligence.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17260" title="Abstract">arXiv:2312.17260</a> [<a href="/pdf/2312.17260" title="Download PDF">pdf</a>, <a href="/format/2312.17260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimePillars: Temporally-Recurrent 3D LiDAR Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calvo%2C+E+L">Ernesto Lozano Calvo</a>, 
<a href="/search/cs?searchtype=author&query=Taveira%2C+B">Bernardo Taveira</a>, 
<a href="/search/cs?searchtype=author&query=Kahl%2C+F">Fredrik Kahl</a>, 
<a href="/search/cs?searchtype=author&query=Gustafsson%2C+N">Niklas Gustafsson</a>, 
<a href="/search/cs?searchtype=author&query=Larsson%2C+J">Jonathan Larsson</a>, 
<a href="/search/cs?searchtype=author&query=Tonderski%2C+A">Adam Tonderski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Object detection applied to LiDAR point clouds is a relevant task in
robotics, and particularly in autonomous driving. Single frame methods,
predominant in the field, exploit information from individual sensor scans.
Recent approaches achieve good performance, at relatively low inference time.
Nevertheless, given the inherent high sparsity of LiDAR data, these methods
struggle in long-range detection (e.g. 200m) which we deem to be critical in
achieving safe automation. Aggregating multiple scans not only leads to a
denser point cloud representation, but it also brings time-awareness to the
system, and provides information about how the environment is changing.
Solutions of this kind, however, are often highly problem-specific, demand
careful data processing, and tend not to fulfil runtime requirements. In this
context we propose TimePillars, a temporally-recurrent object detection
pipeline which leverages the pillar representation of LiDAR data across time,
respecting hardware integration efficiency constraints, and exploiting the
diversity and long-range information of the novel Zenseact Open Dataset (ZOD).
Through experimentation, we prove the benefits of having recurrency, and show
how basic building blocks are enough to achieve robust and efficient results.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17261" title="Abstract">arXiv:2312.17261</a> [<a href="/pdf/2312.17261" title="Download PDF">pdf</a>, <a href="/format/2312.17261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-Based Multi-Object Smoothing with Decoupled Data Association  and Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pinto%2C+J">Juliano Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Hess%2C+G">Georg Hess</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yuxuan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wymeersch%2C+H">Henk Wymeersch</a>, 
<a href="/search/cs?searchtype=author&query=Svensson%2C+L">Lennart Svensson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-object tracking (MOT) is the task of estimating the state trajectories
of an unknown and time-varying number of objects over a certain time window.
Several algorithms have been proposed to tackle the multi-object smoothing
task, where object detections can be conditioned on all the measurements in the
time window. However, the best-performing methods suffer from intractable
computational complexity and require approximations, performing suboptimally in
complex settings. Deep learning based algorithms are a possible venue for
tackling this issue but have not been applied extensively in settings where
accurate multi-object models are available and measurements are
low-dimensional. We propose a novel DL architecture specifically tailored for
this setting that decouples the data association task from the smoothing task.
We compare the performance of the proposed smoother to the state-of-the-art in
different tasks of varying difficulty and provide, to the best of our
knowledge, the first comparison between traditional Bayesian trackers and DL
trackers in the smoothing problem setting.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17262" title="Abstract">arXiv:2312.17262</a> [<a href="/pdf/2312.17262" title="Download PDF">pdf</a>, <a href="/format/2312.17262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Classification of Teaching Activities from University Lecture  Recordings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sapena%2C+O">Oscar Sapena</a>, 
<a href="/search/cs?searchtype=author&query=Onaindia%2C+E">Eva Onaindia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Appl. Sci. 2022, 12, 4785
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The way of understanding online higher education has greatly changed due to
the worldwide pandemic situation. Teaching is undertaken remotely, and the
faculty incorporate lecture audio recordings as part of the teaching material.
This new online teaching-learning setting has largely impacted university
classes. While online teaching technology that enriches virtual classrooms has
been abundant over the past two years, the same has not occurred in supporting
students during online learning. {To overcome this limitation, our aim is to
work toward enabling students to easily access the piece of the lesson
recording in which the teacher explains a theoretical concept, solves an
exercise, or comments on organizational issues of the course. To that end, we
present a multimodal classification algorithm that identifies the type of
activity that is being carried out at any time of the lesson by using a
transformer-based language model that exploits features from the audio file and
from the automated lecture transcription. The experimental results will show
that some academic activities are more easily identifiable with the audio
signal while resorting to the text transcription is needed to identify others.
All in all, our contribution aims to recognize the academic activities of a
teacher during a lesson.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17263" title="Abstract">arXiv:2312.17263</a> [<a href="/pdf/2312.17263" title="Download PDF">pdf</a>, <a href="/format/2312.17263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TACIT: A Target-Agnostic Feature Disentanglement Framework for  Cross-Domain Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Rui Song</a>, 
<a href="/search/cs?searchtype=author&query=Giunchiglia%2C+F">Fausto Giunchiglia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingji Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+M">Mingjie Tian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Cross-domain text classification aims to transfer models from label-rich
source domains to label-poor target domains, giving it a wide range of
practical applications. Many approaches promote cross-domain generalization by
capturing domain-invariant features. However, these methods rely on unlabeled
samples provided by the target domains, which renders the model ineffective
when the target domain is agnostic. Furthermore, the models are easily
disturbed by shortcut learning in the source domain, which also hinders the
improvement of domain generalization ability. To solve the aforementioned
issues, this paper proposes TACIT, a target domain agnostic feature
disentanglement framework which adaptively decouples robust and unrobust
features by Variational Auto-Encoders. Additionally, to encourage the
separation of unrobust features from robust features, we design a feature
distillation task that compels unrobust features to approximate the output of
the teacher. The teacher model is trained with a few easy samples that are easy
to carry potential unknown shortcuts. Experimental results verify that our
framework achieves comparable results to state-of-the-art baselines while
utilizing only source domain data.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17264" title="Abstract">arXiv:2312.17264</a> [<a href="/pdf/2312.17264" title="Download PDF">pdf</a>, <a href="/format/2312.17264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESGReveal: An LLM-based approach for extracting structured data from ESG  reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yi Zou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Mengying Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhongjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhu Deng</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">ZongXiong Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zihan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shiming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">HongXiang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenwen Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">ESGReveal is an innovative method proposed for efficiently extracting and
analyzing Environmental, Social, and Governance (ESG) data from corporate
reports, catering to the critical need for reliable ESG information retrieval.
This approach utilizes Large Language Models (LLM) enhanced with Retrieval
Augmented Generation (RAG) techniques. The ESGReveal system includes an ESG
metadata module for targeted queries, a preprocessing module for assembling
databases, and an LLM agent for data extraction. Its efficacy was appraised
using ESG reports from 166 companies across various sectors listed on the Hong
Kong Stock Exchange in 2022, ensuring comprehensive industry and market
capitalization representation. Utilizing ESGReveal unearthed significant
insights into ESG reporting with GPT-4, demonstrating an accuracy of 76.9% in
data extraction and 83.7% in disclosure analysis, which is an improvement over
baseline models. This highlights the framework's capacity to refine ESG data
analysis precision. Moreover, it revealed a demand for reinforced ESG
disclosures, with environmental and social data disclosures standing at 69.5%
and 57.2%, respectively, suggesting a pursuit for more corporate transparency.
While current iterations of ESGReveal do not process pictorial information, a
functionality intended for future enhancement, the study calls for continued
research to further develop and compare the analytical capabilities of various
LLMs. In summary, ESGReveal is a stride forward in ESG data processing,
offering stakeholders a sophisticated tool to better evaluate and advance
corporate sustainability efforts. Its evolution is promising in promoting
transparency in corporate reporting and aligning with broader sustainable
development aims.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17265" title="Abstract">arXiv:2312.17265</a> [<a href="/pdf/2312.17265" title="Download PDF">pdf</a>, <a href="/format/2312.17265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3bc;$-Net: ConvNext-Based U-Nets for Cosmic Muon Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+L+X+J">Li Xin Jed Lim</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Ziming Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV); Instrumentation and Detectors (physics.ins-det)

</div>
<p class="mathjax">Muon scattering tomography utilises muons, typically originating from cosmic
rays to image the interiors of dense objects. However, due to the low flux of
cosmic ray muons at sea-level and the highly complex interactions that muons
display when travelling through matter, existing reconstruction algorithms
often suffer from low resolution and high noise. In this work, we develop a
novel two-stage deep learning algorithm, $\mu$-Net, consisting of an MLP to
predict the muon trajectory and a ConvNeXt-based U-Net to convert the
scattering points into voxels. $\mu$-Net achieves a state-of-the-art
performance of 17.14 PSNR at the dosage of 1024 muons, outperforming
traditional reconstruction algorithms such as the point of closest approach
algorithm and maximum likelihood and expectation maximisation algorithm.
Furthermore, we find that our method is robust to various corruptions such as
inaccuracies in the muon momentum or a limited detector resolution. We also
generate and publicly release the first large-scale dataset that maps muon
detections to voxels. We hope that our research will spark further
investigations into the potential of deep learning to revolutionise this field.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17267" title="Abstract">arXiv:2312.17267</a> [<a href="/pdf/2312.17267" title="Download PDF">pdf</a>, <a href="/format/2312.17267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Low-resource Prompt-based Relation Representation with  Multi-view Decoupling Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenghao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaoye Qu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhenyi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wenfeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dangyang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, prompt-tuning with pre-trained language models (PLMs) has
demonstrated the significantly enhancing ability of relation extraction (RE)
tasks. However, in low-resource scenarios, where the available training data is
scarce, previous prompt-based methods may still perform poorly for prompt-based
representation learning due to a superficial understanding of the relation. To
this end, we highlight the importance of learning high-quality relation
representation in low-resource scenarios for RE, and propose a novel
prompt-based relation representation method, named MVRE
(\underline{M}ulti-\underline{V}iew \underline{R}elation
\underline{E}xtraction), to better leverage the capacity of PLMs to improve the
performance of RE within the low-resource prompt-tuning paradigm. Specifically,
MVRE decouples each relation into different perspectives to encompass
multi-view relation representations for maximizing the likelihood during
relation inference. Furthermore, we also design a Global-Local loss and a
Dynamic-Initialization method for better alignment of the multi-view
relation-representing virtual words, containing the semantics of relation
labels during the optimization learning process and initialization. Extensive
experiments on three benchmark datasets show that our method can achieve
state-of-the-art in low-resource settings.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17269" title="Abstract">arXiv:2312.17269</a> [<a href="/pdf/2312.17269" title="Download PDF">pdf</a>, <a href="/format/2312.17269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational Question Answering with Reformulations over Knowledge  Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+B">Blaine Hill</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Boxin Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">conversational question answering (convQA) over knowledge graphs (KGs)
involves answering multi-turn natural language questions about information
contained in a KG. State-of-the-art methods of ConvQA often struggle with
inexplicit question-answer pairs. These inputs are easy for human beings to
understand given a conversation history, but hard for a machine to interpret,
which can degrade ConvQA performance. To address this problem, we propose a
reinforcement learning (RL) based model, CornNet, which utilizes question
reformulations generated by large language models (LLMs) to improve ConvQA
performance. CornNet adopts a teacher-student architecture where a teacher
model learns question representations using human writing reformulations, and a
student model to mimic the teacher model's output via reformulations generated
by LLMs. The learned question representation is then used by an RL model to
locate the correct answer in a KG. Extensive experimental results show that
CornNet outperforms state-of-the-art convQA models.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17270" title="Abstract">arXiv:2312.17270</a> [<a href="/pdf/2312.17270" title="Download PDF">pdf</a>, <a href="/format/2312.17270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anticipated Network Surveillance -- An extrapolated study to predict  cyber-attacks using Machine Learning and Data Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Aviral Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Thakkar%2C+D">Dhyan Thakkar</a>, 
<a href="/search/cs?searchtype=author&query=Valiveti%2C+D+S">Dr. Sharda Valiveti</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D+P">Dr. Pooja Shah</a>, 
<a href="/search/cs?searchtype=author&query=Raval%2C+D+G">Dr. Gaurang Raval</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning and data mining techniques are utiized for enhancement of
the security of any network. Researchers used machine learning for pattern
detection, anomaly detection, dynamic policy setting, etc. The methods allow
the program to learn from data and make decisions without human intervention,
consuming a huge training period and computation power. This paper discusses a
novel technique to predict an upcoming attack in a network based on several
data parameters. The dataset is continuous in real-time implementation. The
proposed model comprises dataset pre-processing, and training, followed by the
testing phase. Based on the results of the testing phase, the best model is
selected using which, event class which may lead to an attack is extracted. The
event statistics are used for attack
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17271" title="Abstract">arXiv:2312.17271</a> [<a href="/pdf/2312.17271" title="Download PDF">pdf</a>, <a href="/format/2312.17271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Zero-Trust 6GC: A Software Defined Perimeter Approach with  Dynamic Moving Target Defense Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelhay%2C+Z">Zeyad Abdelhay</a>, 
<a href="/search/cs?searchtype=author&query=Bello%2C+Y">Yahuza Bello</a>, 
<a href="/search/cs?searchtype=author&query=Refaey%2C+A">Ahmed Refaey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The upcoming Sixth Generation (6G) network is projected to grapple with a
range of security concerns, encompassing access control, authentication, secure
connections among 6G Core (6GC) entities, and trustworthiness. Classical
Virtual Private Networks (VPNs), extensively deployed in Evolved Packet Core
(EPC) network infrastructure, are notoriously susceptible to a variety of
attacks, including man-in-the-middle incursions, Domain Name System (DNS)
hijacking, Denial of Service (DoS) attacks, port scanning, and persistent
unauthorized access attempts. This paper introduces the concept of Software
Defined Perimeter (SDP) as an innovative solution, providing an alternative to
VPNs with the goal of fostering a secure zero-trust milieu within the 6G Core
networks. We capitalize on the SDP controller-based authentication and
authorization mechanisms to secure the EPC network's control and data plane
functions, conceiving an architecture that is expansible to the 6G network.
Further, we augment the SDP zero-trust capabilities via the incorporation of a
dynamic component, the Moving Target Defense (MTD). This enhances the network's
resilience against attacks targeting traditionally static network environments
established via VPNs. Following rigorous testbed analysis, our proposed
framework manifests superior resilience against DoS and port scanning attacks
when juxtaposed with traditional VPN methodologies.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17272" title="Abstract">arXiv:2312.17272</a> [<a href="/pdf/2312.17272" title="Download PDF">pdf</a>, <a href="/ps/2312.17272" title="Download PostScript">ps</a>, <a href="/format/2312.17272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating gradients in the energy landscape using rectified linear type  cost functions for efficiently solving 0/1 matrix factorization in Simulated  Annealing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konoshima%2C+M">Makiko Konoshima</a>, 
<a href="/search/cs?searchtype=author&query=Tamura%2C+H">Hirotaka Tamura</a>, 
<a href="/search/cs?searchtype=author&query=Kabashima%2C+Y">Yoshiyuki Kabashima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applied Physics (physics.app-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">The 0/1 matrix factorization defines matrix products using logical AND and OR
as product-sum operators, revealing the factors influencing various decision
processes. Instances and their characteristics are arranged in rows and
columns. Formulating matrix factorization as an energy minimization problem and
exploring it with Simulated Annealing (SA) theoretically enables finding a
minimum solution in sufficient time. However, searching for the optimal
solution in practical time becomes problematic when the energy landscape has
many plateaus with flat slopes. In this work, we propose a method to facilitate
the solution process by applying a gradient to the energy landscape, using a
rectified linear type cost function readily available in modern annealing
machines. We also propose a method to quickly obtain a solution by updating the
cost function's gradient during the search process. Numerical experiments were
conducted, confirming the method's effectiveness with both noise-free
artificial and real data.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17273" title="Abstract">arXiv:2312.17273</a> [<a href="/pdf/2312.17273" title="Download PDF">pdf</a>, <a href="/format/2312.17273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X Modality Assisting RGBT Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhaisheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haiyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Ruichao Hou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shidong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dongming Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jinde Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning robust multi-modal feature representations is critical for boosting
tracking performance. To this end, we propose a novel X Modality Assisting
Network (X-Net) to shed light on the impact of the fusion paradigm by
decoupling the visual object tracking into three distinct levels, facilitating
subsequent processing. Firstly, to tackle the feature learning hurdles stemming
from significant differences between RGB and thermal modalities, a
plug-and-play pixel-level generation module (PGM) is proposed based on
self-knowledge distillation learning, which effectively generates X modality to
bridge the gap between the dual patterns while reducing noise interference.
Subsequently, to further achieve the optimal sample feature representation and
facilitate cross-modal interactions, we propose a feature-level interaction
module (FIM) that incorporates a mixed feature interaction transformer and a
spatial-dimensional feature translation strategy. Ultimately, aiming at random
drifting due to missing instance features, we propose a flexible online
optimized strategy called the decision-level refinement module (DRM), which
contains optical flow and refinement mechanisms. Experiments are conducted on
three benchmarks to verify that the proposed X-Net outperforms state-of-the-art
trackers.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17274" title="Abstract">arXiv:2312.17274</a> [<a href="/pdf/2312.17274" title="Download PDF">pdf</a>, <a href="/ps/2312.17274" title="Download PostScript">ps</a>, <a href="/format/2312.17274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RefineNet: Enhancing Text-to-Image Conversion with High-Resolution and  Detail Accuracy through Hierarchical Transformers and Progressive Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+F">Fan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this research, we introduce RefineNet, a novel architecture designed to
address resolution limitations in text-to-image conversion systems. We explore
the challenges of generating high-resolution images from textual descriptions,
focusing on the trade-offs between detail accuracy and computational
efficiency. RefineNet leverages a hierarchical Transformer combined with
progressive and conditional refinement techniques, outperforming existing
models in producing detailed and high-quality images. Through extensive
experiments on diverse datasets, we demonstrate RefineNet's superiority in
clarity and resolution, particularly in complex image categories like animals,
plants, and human faces. Our work not only advances the field of image-to-text
conversion but also opens new avenues for high-fidelity image generation in
various applications.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17276" title="Abstract">arXiv:2312.17276</a> [<a href="/pdf/2312.17276" title="Download PDF">pdf</a>, <a href="/format/2312.17276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PanGu-$&#x3c0;$: Enhancing Language Model Architectures via Nonlinearity  Compensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yehui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Ying Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xutao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hailin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Zheyuan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangcheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Sinan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qinghua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent trend of large language models (LLMs) is to increase the scale of
both model size (\aka the number of parameters) and dataset to achieve better
generative ability, which is definitely proved by a lot of work such as the
famous GPT and Llama. However, large models often involve massive computational
costs, and practical applications cannot afford such high prices. However, the
method of constructing a strong model architecture for LLMs is rarely
discussed. We first analyze the state-of-the-art language model architectures
and observe the feature collapse problem. Based on the theoretical analysis, we
propose that the nonlinearity is also very important for language models, which
is usually studied in convolutional neural networks for vision tasks. The
series informed activation function is then introduced with tiny calculations
that can be ignored, and an augmented shortcut is further used to enhance the
model nonlinearity. We then demonstrate that the proposed approach is
significantly effective for enhancing the model nonlinearity through carefully
designed ablations; thus, we present a new efficient model architecture for
establishing modern, namely, PanGu-$\pi$. Experiments are then conducted using
the same dataset and training strategy to compare PanGu-$\pi$ with
state-of-the-art LLMs. The results show that PanGu-$\pi$-7B can achieve a
comparable performance to that of benchmarks with about 10\% inference
speed-up, and PanGu-$\pi$-1B can achieve state-of-the-art performance in terms
of accuracy and efficiency. In addition, we have deployed PanGu-$\pi$-7B in the
high-value domains of finance and law, developing an LLM named YunShan for
practical application. The results show that YunShan can surpass other models
with similar scales on benchmarks.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17278" title="Abstract">arXiv:2312.17278</a> [<a href="/pdf/2312.17278" title="Download PDF">pdf</a>, <a href="/ps/2312.17278" title="Download PostScript">ps</a>, <a href="/format/2312.17278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Conducting Advanced Text Analytics Information  Systems Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ampel%2C+B+M">Benjamin M. Ampel</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chi-Heng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">James Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hsinchun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The exponential growth of digital content has generated massive textual
datasets, necessitating advanced analytical approaches. Large Language Models
(LLMs) have emerged as tools capable of processing and extracting insights from
massive unstructured textual datasets. However, how to leverage LLMs for
text-based Information Systems (IS) research is currently unclear. To assist IS
research in understanding how to operationalize LLMs, we propose a Text
Analytics for Information Systems Research (TAISR) framework. Our proposed
framework provides detailed recommendations grounded in IS and LLM literature
on how to conduct meaningful text-based IS research. We conducted three case
studies in business intelligence using our TAISR framework to demonstrate its
application across several IS research contexts. We also outline potential
challenges and limitations in adopting LLMs for IS. By offering a systematic
approach and evidence of its utility, our TAISR framework contributes to future
IS research streams looking to incorporate powerful LLMs for text analytics.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17279" title="Abstract">arXiv:2312.17279</a> [<a href="/pdf/2312.17279" title="Download PDF">pdf</a>, <a href="/format/2312.17279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stateful FastConformer with Cache-based Inference for Streaming  Automatic Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noroozi%2C+V">Vahid Noroozi</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+S">Somshubra Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ankur Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Balam%2C+J">Jagadeesh Balam</a>, 
<a href="/search/cs?searchtype=author&query=Ginsburg%2C+B">Boris Ginsburg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Shorter version accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we propose an efficient and accurate streaming speech
recognition model based on the FastConformer architecture. We adapted the
FastConformer architecture for streaming applications through: (1) constraining
both the look-ahead and past contexts in the encoder, and (2) introducing an
activation caching mechanism to enable the non-autoregressive encoder to
operate autoregressively during inference. The proposed model is thoughtfully
designed in a way to eliminate the accuracy disparity between the train and
inference time which is common for many streaming models. Furthermore, our
proposed encoder works with various decoder configurations including
Connectionist Temporal Classification (CTC) and RNN-Transducer (RNNT) decoders.
Additionally, we introduced a hybrid CTC/RNNT architecture which utilizes a
shared encoder with both a CTC and RNNT decoder to boost the accuracy and save
computation. We evaluate the proposed model on LibriSpeech dataset and a
multi-domain large scale dataset and demonstrate that it can achieve better
accuracy with lower latency and inference time compared to a conventional
buffered streaming model baseline. We also showed that training a model with
multiple latencies can achieve better accuracy than single latency models while
it enables us to support multiple latencies with a single model. Our
experiments also showed the hybrid architecture would not only speedup the
convergence of the CTC decoder but also improves the accuracy of streaming
models compared to single decoder models.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17281" title="Abstract">arXiv:2312.17281</a> [<a href="/pdf/2312.17281" title="Download PDF">pdf</a>, <a href="/ps/2312.17281" title="Download PostScript">ps</a>, <a href="/format/2312.17281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revolutionizing Personalized Voice Synthesis: The Journey towards  Emotional and Individual Authenticity with DIVSE (Dynamic Individual Voice  Synthesis Engine)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+F">Fan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This comprehensive paper delves into the forefront of personalized voice
synthesis within artificial intelligence (AI), spotlighting the Dynamic
Individual Voice Synthesis Engine (DIVSE). DIVSE represents a groundbreaking
leap in text-to-voice (TTS) technology, uniquely focusing on adapting and
personalizing voice outputs to match individual vocal characteristics. The
research underlines the gap in current AI-generated voices, which, while
technically advanced, fall short in replicating the unique individuality and
expressiveness intrinsic to human speech. It outlines the challenges and
advancements in personalized voice synthesis, emphasizing the importance of
emotional expressiveness, accent and dialect variability, and capturing
individual voice traits. The architecture of DIVSE is meticulously detailed,
showcasing its three core components: Voice Characteristic Learning Module
(VCLM), Emotional Tone and Accent Adaptation Module (ETAAM), and Dynamic Speech
Synthesis Engine (DSSE). The innovative approach of DIVSE lies in its adaptive
learning capability, which evolves over time to tailor voice outputs to
specific user traits. The paper presents a rigorous experimental setup,
utilizing accepted datasets and personalization metrics like Mean Opinion Score
(MOS) and Emotional Alignment Score, to validate DIVSE's superiority over
mainstream models. The results depict a clear advancement in achieving higher
personalization and emotional resonance in AI-generated voices.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17282" title="Abstract">arXiv:2312.17282</a> [<a href="/pdf/2312.17282" title="Download PDF">pdf</a>, <a href="/ps/2312.17282" title="Download PostScript">ps</a>, <a href="/format/2312.17282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear energy harvesting system with multiple stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Han%2C+Y">Yanwei Han</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 Pages, 29 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">The nonlinear energy harvesting systems of the forced vibration with an
electron-mechanical coupling are widely used to capture ambient vibration
energy and convert mechanical energy into electrical energy. However, the
nonlinear response mechanism of the friction induced vibration (FIV) energy
harvesting system with multiple stability and stick-slip motion is still
unclear. In the current paper, a novel nonlinear energy harvesting model with
multiple stability of single-, double- and triple-well potential is proposed
based on V-shaped structure spring and the belt conveying system. The dynamic
equations for the energy harvesting system with multiple stability and
self-excited friction are established by using Euler-Lagrangian equations.
Secondly, the nonlinear restoring force, friction force, and potential energy
surfaces for static characteristics of the energy harvesting system are
obtained to show the nonlinear varying stiffness, multiple equilibrium points,
discontinuous behaviors and multiple well response. Then, the equilibrium
surface of bifurcation sets of the autonomous system is given to show the
third-order quasi zero stiffness (QZS3), fifth-order quasi zero stiffness
(QZS5), double well (DW) and triple well (TW). Furthermore, the response
amplitudes of charge, current, voltage and power of the forced
electron-mechanical coupled vibration system for QZS3, QZS5, DW and TW are
analyzed by using the numerically solution. Finally, a prototype of FIV energy
harvesting system is manufactured and the experimental system is setup. The
experimental work of static restoring force, damping force and electrical
output are well agreeable with the numerical results, which testified the
proposed FIV energy harvesting model.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17283" title="Abstract">arXiv:2312.17283</a> [<a href="/pdf/2312.17283" title="Download PDF">pdf</a>, <a href="/ps/2312.17283" title="Download PostScript">ps</a>, <a href="/format/2312.17283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Parsing: An Automated Parsing Framework for Extracting  Design Semantics from E-commerce Creatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guandong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the industrial e-commerce landscape, creative designs such as banners and
posters are ubiquitous. Extracting structured semantic information from
creative e-commerce design materials (manuscripts crafted by designers) to
obtain design semantics represents a core challenge in the realm of intelligent
design. In this paper, we propose a comprehensive automated framework for
intelligently parsing creative materials. This framework comprises material
recognition, preprocess, smartname, and label layers. The material recognition
layer consolidates various detection and recognition interfaces, covering
business aspects including detection of auxiliary areas within creative
materials and layer-level detection, alongside label identification.
Algorithmically, it encompasses a variety of coarse-to-fine methods such as
Cascade RCNN, GFL, and other models. The preprocess layer involves filtering
creative layers and grading creative materials. The smartname layer achieves
intelligent naming for creative materials, while the label layer covers
multi-level tagging for creative materials, enabling tagging at different
hierarchical levels. Intelligent parsing constitutes a complete parsing
framework that significantly aids downstream processes such as intelligent
creation, creative optimization, and material library construction. Within the
practical business applications at Suning, it markedly enhances the exposure,
circulation, and click-through rates of creative materials, expediting the
closed-loop production of creative materials and yielding substantial benefits.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17284" title="Abstract">arXiv:2312.17284</a> [<a href="/pdf/2312.17284" title="Download PDF">pdf</a>, <a href="/format/2312.17284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Decision Making in Engineering System Design: A Deep Q-Learning  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giahi%2C+R">Ramin Giahi</a>, 
<a href="/search/cs?searchtype=author&query=MacKenzie%2C+C+A">Cameron A. MacKenzie</a>, 
<a href="/search/cs?searchtype=author&query=Bijari%2C+R">Reyhaneh Bijari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Systems and Control (eess.SY)

</div>
<p class="mathjax">Engineering system design, viewed as a decision-making process, faces
challenges due to complexity and uncertainty. In this paper, we present a
framework proposing the use of the Deep Q-learning algorithm to optimize the
design of engineering systems. We outline a step-by-step framework for
optimizing engineering system designs. The goal is to find policies that
maximize the output of a simulation model given multiple sources of
uncertainties. The proposed algorithm handles linear and non-linear multi-stage
stochastic problems, where decision variables are discrete, and the objective
function and constraints are assessed via a Monte Carlo simulation. We
demonstrate the effectiveness of our proposed framework by solving two
engineering system design problems in the presence of multiple uncertainties,
such as price and demand.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17285" title="Abstract">arXiv:2312.17285</a> [<a href="/pdf/2312.17285" title="Download PDF">pdf</a>, <a href="/format/2312.17285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Distributed Representations of Concepts in Deep Neural  Networks without Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">Wonjoon Chang</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+D">Dahee Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaesik Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI2024. First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding intermediate representations of the concepts learned by deep
learning classifiers is indispensable for interpreting general model behaviors.
Existing approaches to reveal learned concepts often rely on human supervision,
such as pre-defined concept sets or segmentation processes. In this paper, we
propose a novel unsupervised method for discovering distributed representations
of concepts by selecting a principal subset of neurons. Our empirical findings
demonstrate that instances with similar neuron activation states tend to share
coherent concepts. Based on the observations, the proposed method selects
principal neurons that construct an interpretable region, namely a Relaxed
Decision Region (RDR), encompassing instances with coherent concepts in the
feature space. It can be utilized to identify unlabeled subclasses within data
and to detect the causes of misclassifications. Furthermore, the applicability
of our method across various layers discloses distinct distributed
representations over the layers, which provides deeper insights into the
internal mechanisms of the deep learning model.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17286" title="Abstract">arXiv:2312.17286</a> [<a href="/pdf/2312.17286" title="Download PDF">pdf</a>, <a href="/format/2312.17286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative study of clustering models for multivariate time series from  connected medical devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Courrier%2C+V">Violaine Courrier</a> (MODAL), 
<a href="/search/cs?searchtype=author&query=Biernacki%2C+C">Christophe Biernacki</a> (MODAL), 
<a href="/search/cs?searchtype=author&query=Preda%2C+C">Cristian Preda</a> (MODAL), 
<a href="/search/cs?searchtype=author&query=Vittrant%2C+B">Benjamin Vittrant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in French language. EGC 2024 - 24{\`e}me Conf{\'e}rence Francophone sur l'Extraction et Gestion des Connaissances, Jan 2024, Dijon (France), France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In healthcare, patient data is often collected as multivariate time series,
providing a comprehensive view of a patient's health status over time. While
this data can be sparse, connected devices may enhance its frequency. The goal
is to create patient profiles from these time series. In the absence of labels,
a predictive model can be used to predict future values while forming a latent
cluster space, evaluated based on predictive performance. We compare two models
on Withing's datasets, M AGMAC LUST which clusters entire time series and
DGM${}^2$ which allows the group affiliation of an individual to change over
time (dynamic clustering).
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17289" title="Abstract">arXiv:2312.17289</a> [<a href="/pdf/2312.17289" title="Download PDF">pdf</a>, <a href="/format/2312.17289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Content Self-Detection for Transformer-based Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caiado%2C+A+J+A">Ant&#xf4;nio Junior Alves Caiado</a>, 
<a href="/search/cs?searchtype=author&query=Hahsler%2C+M">Michael Hahsler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">$ $The usage of generative artificial intelligence (AI) tools based on large
language models, including ChatGPT, Bard, and Claude, for text generation has
many exciting applications with the potential for phenomenal productivity
gains. One issue is authorship attribution when using AI tools. This is
especially important in an academic setting where the inappropriate use of
generative AI tools may hinder student learning or stifle research by creating
a large amount of automatically generated derivative work. Existing plagiarism
detection systems can trace the source of submitted text but are not yet
equipped with methods to accurately detect AI-generated text. This paper
introduces the idea of direct origin detection and evaluates whether generative
AI systems can recognize their output and distinguish it from human-written
texts. We argue why current transformer-based models may be able to self-detect
their own generated text and perform a small empirical study using zero-shot
learning to investigate if that is the case. Results reveal varying
capabilities of AI systems to identify their generated text. Google's Bard
model exhibits the largest capability of self-detection with an accuracy of
94\%, followed by OpenAI's ChatGPT with 83\%. On the other hand, Anthropic's
Claude model seems to be not able to self-detect.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17292" title="Abstract">arXiv:2312.17292</a> [<a href="/pdf/2312.17292" title="Download PDF">pdf</a>, <a href="/ps/2312.17292" title="Download PostScript">ps</a>, <a href="/format/2312.17292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effect of dimensionality change on the bias of word embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rai%2C+R+R">Rohit Raj Rai</a>, 
<a href="/search/cs?searchtype=author&query=Awekar%2C+A">Amit Awekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the Young Research Symposium Track of ACM CODS-COMADS 2024. 2 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Word embedding methods (WEMs) are extensively used for representing text
data. The dimensionality of these embeddings varies across various tasks and
implementations. The effect of dimensionality change on the accuracy of the
downstream task is a well-explored question. However, how the dimensionality
change affects the bias of word embeddings needs to be investigated. Using the
English Wikipedia corpus, we study this effect for two static (Word2Vec and
fastText) and two context-sensitive (ElMo and BERT) WEMs. We have two
observations. First, there is a significant variation in the bias of word
embeddings with the dimensionality change. Second, there is no uniformity in
how the dimensionality change affects the bias of word embeddings. These
factors should be considered while selecting the dimensionality of word
embeddings.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17294" title="Abstract">arXiv:2312.17294</a> [<a href="/pdf/2312.17294" title="Download PDF">pdf</a>, <a href="/format/2312.17294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GitAgent: Facilitating Autonomous Agent with GitHub by Tool Extension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+B">Bohan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+X">Xin Cong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Heyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Pan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yujia Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yining Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yaxi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yukun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">While Large Language Models (LLMs) like ChatGPT and GPT-4 have demonstrated
exceptional proficiency in natural language processing, their efficacy in
addressing complex, multifaceted tasks remains limited. A growing area of
research focuses on LLM-based agents equipped with external tools capable of
performing diverse tasks. However, existing LLM-based agents only support a
limited set of tools which is unable to cover a diverse range of user queries,
especially for those involving expertise domains. It remains a challenge for
LLM-based agents to extend their tools autonomously when confronted with
various user queries. As GitHub has hosted a multitude of repositories which
can be seen as a good resource for tools, a promising solution is that
LLM-based agents can autonomously integrate the repositories in GitHub
according to the user queries to extend their tool set. In this paper, we
introduce GitAgent, an agent capable of achieving the autonomous tool extension
from GitHub. GitAgent follows a four-phase procedure to incorporate
repositories and it can learn human experience by resorting to GitHub
Issues/PRs to solve problems encountered during the procedure. Experimental
evaluation involving 30 user queries demonstrates GitAgent's effectiveness,
achieving a 69.4% success rate on average.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17295" title="Abstract">arXiv:2312.17295</a> [<a href="/pdf/2312.17295" title="Download PDF">pdf</a>, <a href="/format/2312.17295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing watermarks for large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wouters%2C+B">Bram Wouters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages; preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">With the rise of large language models (LLMs) and concerns about potential
misuse, watermarks for generative LLMs have recently attracted much attention.
An important aspect of such watermarks is the trade-off between their
identifiability and their impact on the quality of the generated text. This
paper introduces a systematic approach to this trade-off in terms of a
multi-objective optimization problem. For a large class of robust, efficient
watermarks, the associated Pareto optimal solutions are identified and shown to
outperform the currently default watermark.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17296" title="Abstract">arXiv:2312.17296</a> [<a href="/pdf/2312.17296" title="Download PDF">pdf</a>, <a href="/format/2312.17296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Packing in LLM Training Improves Long Context Utilization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Staniszewski%2C+K">Konrad Staniszewski</a>, 
<a href="/search/cs?searchtype=author&query=Tworkowski%2C+S">Szymon Tworkowski</a>, 
<a href="/search/cs?searchtype=author&query=Jaszczur%2C+S">Sebastian Jaszczur</a>, 
<a href="/search/cs?searchtype=author&query=Michalewski%2C+H">Henryk Michalewski</a>, 
<a href="/search/cs?searchtype=author&query=Kuci%C5%84ski%2C+%C5%81">&#x141;ukasz Kuci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Mi%C5%82o%C5%9B%2C+P">Piotr Mi&#x142;o&#x15b;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advances in long-context Large Language Models (LCLMs) have generated
significant interest, especially in applications such as querying scientific
research papers. However, their potential is often limited by inadequate
context utilization. We identify the absence of long-range semantic
dependencies in typical training data as a primary hindrance. To address this,
we delve into the benefits of frequently incorporating related documents into
training inputs. Using the inherent directory structure of code data as a
source of training examples, we demonstrate improvements in perplexity, even
for tasks unrelated to coding. Building on these findings, but with a broader
focus, we introduce Structured Packing for Long Context (SPLiCe). SPLiCe is an
innovative method for creating training examples by using a retrieval method to
collate the most mutually relevant documents into a single training context.
Our results indicate that \method{} enhances model performance and can be used
to train large models to utilize long contexts better. We validate our results
by training a large $3$B model, showing both perplexity improvements and better
long-context performance on downstream tasks.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17300" title="Abstract">arXiv:2312.17300</a> [<a href="/pdf/2312.17300" title="Download PDF">pdf</a>, <a href="/format/2312.17300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Intrusion Detection with Domain-Invariant Representation  Learning in Latent Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+P">Padmaksha Roy</a>, 
<a href="/search/cs?searchtype=author&query=Cody%2C+T">Tyler Cody</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+H">Himanshu Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Kevin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Domain generalization focuses on leveraging knowledge from multiple related
domains with ample training data and labels to enhance inference on unseen
in-distribution (IN) and out-of-distribution (OOD) domains. In our study, we
introduce a two-phase representation learning technique using multi-task
learning. This approach aims to cultivate a latent space from features spanning
multiple domains, encompassing both native and cross-domains, to amplify
generalization to IN and OOD territories. Additionally, we attempt to
disentangle the latent space by minimizing the mutual information between the
prior and latent space, effectively de-correlating spurious feature
correlations. Collectively, the joint optimization will facilitate
domain-invariant feature learning. We assess the model's efficacy across
multiple cybersecurity datasets, using standard classification metrics on both
unseen IN and OOD sets, and juxtapose the results with contemporary domain
generalization methods.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17301" title="Abstract">arXiv:2312.17301</a> [<a href="/pdf/2312.17301" title="Download PDF">pdf</a>, <a href="/format/2312.17301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainability-Based Adversarial Attack on Graphs Through Edge  Perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chanda%2C+D">Dibaloke Chanda</a>, 
<a href="/search/cs?searchtype=author&query=Gheshlaghi%2C+S+H">Saba Heidari Gheshlaghi</a>, 
<a href="/search/cs?searchtype=author&query=Soltani%2C+N+Y">Nasim Yahya Soltani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the success of graph neural networks (GNNs) in various domains, they
exhibit susceptibility to adversarial attacks. Understanding these
vulnerabilities is crucial for developing robust and secure applications. In
this paper, we investigate the impact of test time adversarial attacks through
edge perturbations which involve both edge insertions and deletions. A novel
explainability-based method is proposed to identify important nodes in the
graph and perform edge perturbation between these nodes. The proposed method is
tested for node classification with three different architectures and datasets.
The results suggest that introducing edges between nodes of different classes
has higher impact as compared to removing edges among nodes within the same
class.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17306" title="Abstract">arXiv:2312.17306</a> [<a href="/pdf/2312.17306" title="Download PDF">pdf</a>, <a href="/format/2312.17306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Flossing: Improving Gradient Descent through Dynamic Control of  Jacobians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engelken%2C+R">Rainer Engelken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 16 figures, accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Chaotic Dynamics (nlin.CD); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Training recurrent neural networks (RNNs) remains a challenge due to the
instability of gradients across long time horizons, which can lead to exploding
and vanishing gradients. Recent research has linked these problems to the
values of Lyapunov exponents for the forward-dynamics, which describe the
growth or shrinkage of infinitesimal perturbations. Here, we propose gradient
flossing, a novel approach to tackling gradient instability by pushing Lyapunov
exponents of the forward dynamics toward zero during learning. We achieve this
by regularizing Lyapunov exponents through backpropagation using differentiable
linear algebra. This enables us to "floss" the gradients, stabilizing them and
thus improving network training. We demonstrate that gradient flossing controls
not only the gradient norm but also the condition number of the long-term
Jacobian, facilitating multidimensional error feedback propagation. We find
that applying gradient flossing prior to training enhances both the success
rate and convergence speed for tasks involving long time horizons. For
challenging tasks, we show that gradient flossing during training can further
increase the time horizon that can be bridged by backpropagation through time.
Moreover, we demonstrate the effectiveness of our approach on various RNN
architectures and tasks of variable temporal complexity. Additionally, we
provide a simple implementation of our gradient flossing algorithm that can be
used in practice. Our results indicate that gradient flossing via regularizing
Lyapunov exponents can significantly enhance the effectiveness of RNN training
and mitigate the exploding and vanishing gradient problem.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17324" title="Abstract">arXiv:2312.17324</a> [<a href="/pdf/2312.17324" title="Download PDF">pdf</a>, <a href="/format/2312.17324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Scalable Generation of Realistic Test Data for Duplicate  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panse%2C+F">Fabian Panse</a>, 
<a href="/search/cs?searchtype=author&query=Wingerath%2C+W">Wolfram Wingerath</a>, 
<a href="/search/cs?searchtype=author&query=Wollmer%2C+B">Benjamin Wollmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Due to the increasing volume, volatility, and diversity of data in virtually
all areas of our lives, the ability to detect duplicates in potentially linked
data sources is more important than ever before. However, while research is
already intensively engaged in adapting duplicate detection algorithms to the
changing circumstances, existing test data generators are still designed for
small -- mostly relational -- datasets and can thus fulfill their intended task
only to a limited extent. In this report, we present our ongoing research on a
novel approach for test data generation that -- in contrast to existing
solutions -- is able to produce large test datasets with complex schemas and
more realistic error patterns while being easy to use for inexperienced users.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17329" title="Abstract">arXiv:2312.17329</a> [<a href="/pdf/2312.17329" title="Download PDF">pdf</a>, <a href="/format/2312.17329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PINN surrogate of Li-ion battery models for parameter inference. Part I:  Implementation and multi-fidelity hierarchies for the single-particle model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassanaly%2C+M">Malik Hassanaly</a>, 
<a href="/search/cs?searchtype=author&query=Weddle%2C+P+J">Peter J. Weddle</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+R+N">Ryan N. King</a>, 
<a href="/search/cs?searchtype=author&query=De%2C+S">Subhayan De</a>, 
<a href="/search/cs?searchtype=author&query=Doostan%2C+A">Alireza Doostan</a>, 
<a href="/search/cs?searchtype=author&query=Randall%2C+C+R">Corey R. Randall</a>, 
<a href="/search/cs?searchtype=author&query=Dufek%2C+E+J">Eric J. Dufek</a>, 
<a href="/search/cs?searchtype=author&query=Colclasure%2C+A+M">Andrew M. Colclasure</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K">Kandler Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">To plan and optimize energy storage demands that account for Li-ion battery
aging dynamics, techniques need to be developed to diagnose battery internal
states accurately and rapidly. This study seeks to reduce the computational
resources needed to determine a battery's internal states by replacing
physics-based Li-ion battery models -- such as the single-particle model (SPM)
and the pseudo-2D (P2D) model -- with a physics-informed neural network (PINN)
surrogate. The surrogate model makes high-throughput techniques, such as
Bayesian calibration, tractable to determine battery internal parameters from
voltage responses. This manuscript is the first of a two-part series that
introduces PINN surrogates of Li-ion battery models for parameter inference
(i.e., state-of-health diagnostics). In this first part, a method is presented
for constructing a PINN surrogate of the SPM. A multi-fidelity hierarchical
training, where several neural nets are trained with multiple physics-loss
fidelities is shown to significantly improve the surrogate accuracy when only
training on the governing equation residuals. The implementation is made
available in a companion repository (https://github.com/NREL/pinnstripes). The
techniques used to develop a PINN surrogate of the SPM are extended in Part II
for the PINN surrogate for the P2D battery model, and explore the Bayesian
calibration capabilities of both surrogates.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17330" title="Abstract">arXiv:2312.17330</a> [<a href="/pdf/2312.17330" title="Download PDF">pdf</a>, <a href="/format/2312.17330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Count What You Want: Exemplar Identification and Few-shot Counting of  Human Actions in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yifeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+D">Duc Duy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L">Lam Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Cuong Pham</a>, 
<a href="/search/cs?searchtype=author&query=Hoai%2C+M">Minh Hoai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper addresses the task of counting human actions of interest using
sensor data from wearable devices. We propose a novel exemplar-based framework,
allowing users to provide exemplars of the actions they want to count by
vocalizing predefined sounds ''one'', ''two'', and ''three''. Our method first
localizes temporal positions of these utterances from the audio sequence. These
positions serve as the basis for identifying exemplars representing the action
class of interest. A similarity map is then computed between the exemplars and
the entire sensor data sequence, which is further fed into a density estimation
module to generate a sequence of estimated density values. Summing these
density values provides the final count. To develop and evaluate our approach,
we introduce a diverse and realistic dataset consisting of real-world data from
37 subjects and 50 action categories, encompassing both sensor and audio data.
The experiments on this dataset demonstrate the viability of the proposed
method in counting instances of actions from new classes and subjects that were
not part of the training data. On average, the discrepancy between the
predicted count and the ground truth value is 7.47, significantly lower than
the errors of the frequency-based and transformer-based methods. Our project,
code and dataset can be found at https://github.com/cvlab-stonybrook/ExRAC.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17334" title="Abstract">arXiv:2312.17334</a> [<a href="/pdf/2312.17334" title="Download PDF">pdf</a>, <a href="/format/2312.17334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Image Restoration through Removing Degradations in Textual  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jingbo Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+D">Dongwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongsheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce a new perspective for improving image restoration
by removing degradation in the textual representations of a given degraded
image. Intuitively, restoration is much easier on text modality than image one.
For example, it can be easily conducted by removing degradation-related words
while keeping the content-aware words. Hence, we combine the advantages of
images in detail description and ones of text in degradation removal to perform
restoration. To address the cross-modal assistance, we propose to map the
degraded images into textual representations for removing the degradations, and
then convert the restored textual representations into a guidance image for
assisting image restoration. In particular, We ingeniously embed an
image-to-text mapper and text restoration module into CLIP-equipped
text-to-image models to generate the guidance. Then, we adopt a simple
coarse-to-fine approach to dynamically inject multi-scale information from
guidance to image restoration networks. Extensive experiments are conducted on
various image restoration tasks, including deblurring, dehazing, deraining, and
denoising, and all-in-one image restoration. The results showcase that our
method outperforms state-of-the-art ones across all these tasks. The codes and
models are available at \url{https://github.com/mrluin/TextualDegRemoval}.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17336" title="Abstract">arXiv:2312.17336</a> [<a href="/pdf/2312.17336" title="Download PDF">pdf</a>, <a href="/format/2312.17336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PINN surrogate of Li-ion battery models for parameter inference. Part  II: Regularization and application of the pseudo-2D model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassanaly%2C+M">Malik Hassanaly</a>, 
<a href="/search/cs?searchtype=author&query=Weddle%2C+P+J">Peter J. Weddle</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+R+N">Ryan N. King</a>, 
<a href="/search/cs?searchtype=author&query=De%2C+S">Subhayan De</a>, 
<a href="/search/cs?searchtype=author&query=Doostan%2C+A">Alireza Doostan</a>, 
<a href="/search/cs?searchtype=author&query=Randall%2C+C+R">Corey R. Randall</a>, 
<a href="/search/cs?searchtype=author&query=Dufek%2C+E+J">Eric J. Dufek</a>, 
<a href="/search/cs?searchtype=author&query=Colclasure%2C+A+M">Andrew M. Colclasure</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K">Kandler Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Bayesian parameter inference is useful to improve Li-ion battery diagnostics
and can help formulate battery aging models. However, it is computationally
intensive and cannot be easily repeated for multiple cycles, multiple operating
conditions, or multiple replicate cells. To reduce the computational cost of
Bayesian calibration, numerical solvers for physics-based models can be
replaced with faster surrogates. A physics-informed neural network (PINN) is
developed as a surrogate for the pseudo-2D (P2D) battery model calibration. For
the P2D surrogate, additional training regularization was needed as compared to
the PINN single-particle model (SPM) developed in Part I. Both the PINN SPM and
P2D surrogate models are exercised for parameter inference and compared to data
obtained from a direct numerical solution of the governing equations. A
parameter inference study highlights the ability to use these PINNs to
calibrate scaling parameters for the cathode Li diffusion and the anode
exchange current density. By realizing computational speed-ups of 2250x for the
P2D model, as compared to using standard integrating methods, the PINN
surrogates enable rapid state-of-health diagnostics. In the low-data
availability scenario, the testing error was estimated to 2mV for the SPM
surrogate and 10mV for the P2D surrogate which could be mitigated with
additional data.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17337" title="Abstract">arXiv:2312.17337</a> [<a href="/pdf/2312.17337" title="Download PDF">pdf</a>, <a href="/format/2312.17337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Nature: Datasets and Models for Analyzing Nature-Related  Disclosures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schimanski%2C+T">Tobias Schimanski</a>, 
<a href="/search/cs?searchtype=author&query=Senni%2C+C+C">Chiara Colesanti Senni</a>, 
<a href="/search/cs?searchtype=author&query=Gostlow%2C+G">Glen Gostlow</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jingwei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tingyu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Leippold%2C+M">Markus Leippold</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; General Economics (econ.GN)

</div>
<p class="mathjax">Nature is an amorphous concept. Yet, it is essential for the planet's
well-being to understand how the economy interacts with it. To address the
growing demand for information on corporate nature disclosure, we provide
datasets and classifiers to detect nature communication by companies. We ground
our approach in the guidelines of the Taskforce on Nature-related Financial
Disclosures (TNFD). Particularly, we focus on the specific dimensions of water,
forest, and biodiversity. For each dimension, we create an expert-annotated
dataset with 2,200 text samples and train classifier models. Furthermore, we
show that nature communication is more prevalent in hotspot areas and directly
effected industries like agriculture and utilities. Our approach is the first
to respond to calls to assess corporate nature communication on a large scale.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17338" title="Abstract">arXiv:2312.17338</a> [<a href="/pdf/2312.17338" title="Download PDF">pdf</a>, <a href="/format/2312.17338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unmasking information manipulation: A quantitative approach to detecting  Copy-pasta, Rewording, and Translation on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Richard%2C+M">Manon Richard</a>, 
<a href="/search/cs?searchtype=author&query=Giordani%2C+L">Lisa Giordani</a>, 
<a href="/search/cs?searchtype=author&query=Brokate%2C+C">Cristian Brokate</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%A9nard%2C+J">Jean Li&#xe9;nard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">This study proposes a comprehensive methodology for identifying three
techniques utilized in foreign-operated information manipulation campaigns:
Copy-Pasta, Rewording, and Translation. Our approach, dubbed the
``$3\Delta$-space duplicate methodology'', quantifies the semantic, grapheme,
and language aspects of messages. Computing pairwise distances within these
dimensions enables detection of abnormally close messages that are likely part
of a coordinated campaign. We validate our approach using a synthetic dataset
generated with ChatGPT and DeepL, further applying it to a real-world dataset
on Venezuelan actors from Twitter Transparency. Our method successfully
identifies all three types of inauthentic duplicates in the synthetic dataset,
and is able to uncover inauthentic duplicates across political, commercial, and
entertainment contexts in the Twitter dataset. The distinct focus on clustered
alterations to messages, rather than individual messages, makes our approach
efficient and effective at detecting large-scale instances of textual
manipulation, including AI-generated ones. Moreover, our method offers a robust
tool for identifying translated content, overlooked in previous research. This
research also represents the first comprehensive analysis of copy-pasta
detection, providing a reliable technique for tracking duplicate textual
content across social networks.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17340" title="Abstract">arXiv:2312.17340</a> [<a href="/pdf/2312.17340" title="Download PDF">pdf</a>, <a href="/ps/2312.17340" title="Download PostScript">ps</a>, <a href="/format/2312.17340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assisted Path Planning for a UGV-UAV Team Through a Stochastic Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhadoriya%2C+A+S">Abhay Singh Bhadoriya</a>, 
<a href="/search/cs?searchtype=author&query=Rathinam%2C+S">Sivakumar Rathinam</a>, 
<a href="/search/cs?searchtype=author&query=Darbha%2C+S">Swaroop Darbha</a>, 
<a href="/search/cs?searchtype=author&query=Casbeer%2C+D+W">David W. Casbeer</a>, 
<a href="/search/cs?searchtype=author&query=Manyam%2C+S+G">Satyanarayana G. Manyam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this article, we consider a multi-agent path planning problem in a
stochastic environment. The environment, which can be an urban road network, is
represented by a graph where the travel time for selected road segments
(impeded edges) is a random variable because of traffic congestion. An unmanned
ground vehicle (UGV) wishes to travel from a starting location to a destination
while minimizing the arrival time at the destination. UGV can traverse through
an impeded edge but the true travel time is only realized at the end of that
edge. This implies that the UGV can potentially get stuck in an impeded edge
with high travel time. A support vehicle, such as an unmanned aerial vehicle
(UAV) is simultaneously deployed from its starting position to assist the UGV
by inspecting and realizing the true cost of impeded edges. With the updated
information from UAV, UGV can efficiently reroute its path to the destination.
The UGV does not wait at any time until it reaches the destination. The UAV is
permitted to terminate its path at any vertex. The goal is then to develop an
online algorithm to determine efficient paths for the UGV and the UAV based on
the current information so that the UGV reaches the destination in minimum
time. We refer to this problem as Stochastic Assisted Path Planning (SAPP). We
present Dynamic $k$-Shortest Path Planning (D*KSPP) algorithm for the UGV
planning and Rural Postman Problem (RPP) formulation for the UAV planning. Due
to the scalability challenges of RPP, we also present a heuristic based
Priority Assignment Algorithm (PAA) for the UAV planning. Computational results
are presented to corroborate the effectiveness of the proposed algorithm to
solve SAPP.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17342" title="Abstract">arXiv:2312.17342</a> [<a href="/pdf/2312.17342" title="Download PDF">pdf</a>, <a href="/format/2312.17342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SentinelLMs: Encrypted Input Adaptation and Fine-tuning of Language  Models for Private and Secure Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Abhijit Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingda Li</a>, 
<a href="/search/cs?searchtype=author&query=Deo%2C+S">Soham Deo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and to appear in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper addresses the privacy and security concerns associated with deep
neural language models, which serve as crucial components in various modern
AI-based applications. These models are often used after being pre-trained and
fine-tuned for specific tasks, with deployment on servers accessed through the
internet. However, this introduces two fundamental risks: (a) the transmission
of user inputs to the server via the network gives rise to interception
vulnerabilities, and (b) privacy concerns emerge as organizations that deploy
such models store user data with restricted context. To address this, we
propose a novel method to adapt and fine-tune transformer-based language models
on passkey-encrypted user-specific text. The original pre-trained language
model first undergoes a quick adaptation (without any further pre-training)
with a series of irreversible transformations applied to the tokenizer and
token embeddings. This enables the model to perform inference on encrypted
inputs while preventing reverse engineering of text from model parameters and
intermediate outputs. After adaptation, models are fine-tuned on encrypted
versions of existing training datasets. Experimental evaluation employing
adapted versions of renowned models (e.g., BERT, RoBERTa) across established
benchmark English and multilingual datasets for text classification and
sequence labeling shows that encrypted models achieve performance parity with
their original counterparts. This serves to safeguard performance, privacy, and
security cohesively.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17343" title="Abstract">arXiv:2312.17343</a> [<a href="/pdf/2312.17343" title="Download PDF">pdf</a>, <a href="/format/2312.17343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AQUALLM: Audio Question Answering Data Generation Using Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behera%2C+S+R">Swarup Ranjan Behera</a>, 
<a href="/search/cs?searchtype=author&query=Injeti%2C+K+M">Krishna Mohan Injeti</a>, 
<a href="/search/cs?searchtype=author&query=Patibandla%2C+J+S+K">Jaya Sai Kiran Patibandla</a>, 
<a href="/search/cs?searchtype=author&query=Pokala%2C+P+K">Praveen Kumar Pokala</a>, 
<a href="/search/cs?searchtype=author&query=Pailla%2C+B+R">Balakrishna Reddy Pailla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio Question Answering (AQA) constitutes a pivotal task in which machines
analyze both audio signals and natural language questions to produce precise
natural language answers. The significance of possessing high-quality, diverse,
and extensive AQA datasets cannot be overstated when aiming for the precision
of an AQA system. While there has been notable focus on developing accurate and
efficient AQA models, the creation of high-quality, diverse, and extensive
datasets for the specific task at hand has not garnered considerable attention.
To address this challenge, this work makes several contributions. We introduce
a scalable AQA data generation pipeline, denoted as the AQUALLM framework,
which relies on Large Language Models (LLMs). This framework utilizes existing
audio-caption annotations and incorporates state-of-the-art LLMs to generate
expansive, high-quality AQA datasets. Additionally, we present three extensive
and high-quality benchmark datasets for AQA, contributing significantly to the
progression of AQA research. AQA models trained on the proposed datasets set
superior benchmarks compared to the existing state-of-the-art. Moreover, models
trained on our datasets demonstrate enhanced generalizability when compared to
models trained using human-annotated AQA data. Code and datasets will be
accessible on GitHub~\footnote{\url{https://github.com/swarupbehera/AQUALLM}}.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17345" title="Abstract">arXiv:2312.17345</a> [<a href="/pdf/2312.17345" title="Download PDF">pdf</a>, <a href="/format/2312.17345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3VL: using Trees to teach Vision &amp; Language models compositional  concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yellinek%2C+N">Nir Yellinek</a>, 
<a href="/search/cs?searchtype=author&query=Karlinsky%2C+L">Leonid Karlinsky</a>, 
<a href="/search/cs?searchtype=author&query=Giryes%2C+R">Raja Giryes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-Language models (VLMs) have proved effective at aligning image and
text representations, producing superior zero-shot results when transferred to
many downstream tasks. However, these representations suffer some key
shortcomings in Compositional Language Concepts (CLC) understanding such as
recognizing objects' attributes, states, and relations between different
objects. Moreover, VLMs typically have poor interpretability, making it
challenging to debug and mitigate compositional-understanding failures. In this
work, we introduce the Tree-augmented Vision-Language (3VL) model architecture
and training technique accompanied by our proposed Anchor inference method and
Differential Relevance (DiRe) interpretability tool. By expanding the text of
an arbitrary image-text pair into a hierarchical tree structure using language
analysis tools, 3VL allows inducing this structure into the visual
representation learned by the model, enhancing its interpretability and
compositional reasoning. Additionally, we show how Anchor, a simple technique
for text unification, can be employed to filter nuisance factors while
increasing CLC understanding performance, e.g., on the fundamental VL-Checklist
benchmark. We also exhibit how DiRe, which performs a differential comparison
between VLM relevancy maps, enables us to generate compelling visualizations of
the reasons for a model's success or failure.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17346" title="Abstract">arXiv:2312.17346</a> [<a href="/pdf/2312.17346" title="Download PDF">pdf</a>, <a href="/format/2312.17346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dennis Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J+Y">Jerry Yao-Chieh Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijian Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present STanHop-Net (Sparse Tandem Hopfield Network) for multivariate time
series prediction with memory-enhanced capabilities. At the heart of our
approach is STanHop, a novel Hopfield-based neural network block, which
sparsely learns and stores both temporal and cross-series representations in a
data-dependent fashion. In essence, STanHop sequentially learn temporal
representation and cross-series representation using two tandem sparse Hopfield
layers. In addition, StanHop incorporates two additional external memory
modules: a Plug-and-Play module and a Tune-and-Play module for train-less and
task-aware memory-enhancements, respectively. They allow StanHop-Net to swiftly
respond to certain sudden events. Methodologically, we construct the
StanHop-Net by stacking STanHop blocks in a hierarchical fashion, enabling
multi-resolution feature extraction with resolution-specific sparsity.
Theoretically, we introduce a sparse extension of the modern Hopfield model
(Generalized Sparse Modern Hopfield Model) and show that it endows a tighter
memory retrieval error compared to the dense counterpart without sacrificing
memory capacity. Empirically, we validate the efficacy of our framework on both
synthetic and real-world settings.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17348" title="Abstract">arXiv:2312.17348</a> [<a href="/pdf/2312.17348" title="Download PDF">pdf</a>, <a href="/format/2312.17348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A randomized algorithm to solve reduced rank operator regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turri%2C+G">Giacomo Turri</a>, 
<a href="/search/cs?searchtype=author&query=Kostic%2C+V">Vladimir Kostic</a>, 
<a href="/search/cs?searchtype=author&query=Novelli%2C+P">Pietro Novelli</a>, 
<a href="/search/cs?searchtype=author&query=Pontil%2C+M">Massimiliano Pontil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present and analyze an algorithm designed for addressing vector-valued
regression problems involving possibly infinite-dimensional input and output
spaces. The algorithm is a randomized adaptation of reduced rank regression, a
technique to optimally learn a low-rank vector-valued function (i.e. an
operator) between sampled data via regularized empirical risk minimization with
rank constraints. We propose Gaussian sketching techniques both for the primal
and dual optimization objectives, yielding Randomized Reduced Rank Regression
(R4) estimators that are efficient and accurate. For each of our R4 algorithms
we prove that the resulting regularized empirical risk is, in expectation
w.r.t. randomness of a sketch, arbitrarily close to the optimal value when
hyper-parameteres are properly tuned. Numerical expreriments illustrate the
tightness of our bounds and show advantages in two distinct scenarios: (i)
solving a vector-valued regression problem using synthetic and large-scale
neuroscience datasets, and (ii) regressing the Koopman operator of a nonlinear
stochastic dynamical system.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17349" title="Abstract">arXiv:2312.17349</a> [<a href="/pdf/2312.17349" title="Download PDF">pdf</a>, <a href="/format/2312.17349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Model as an Annotator: Unsupervised Context-aware Quality  Phrase Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Y">Yuan Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junjie Wu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Knowledge-Based Systems 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Phrase mining is a fundamental text mining task that aims to identify quality
phrases from context. Nevertheless, the scarcity of extensive gold labels
datasets, demanding substantial annotation efforts from experts, renders this
task exceptionally challenging. Furthermore, the emerging, infrequent, and
domain-specific nature of quality phrases presents further challenges in
dealing with this task. In this paper, we propose LMPhrase, a novel
unsupervised context-aware quality phrase mining framework built upon large
pre-trained language models (LMs). Specifically, we first mine quality phrases
as silver labels by employing a parameter-free probing technique called
Perturbed Masking on the pre-trained language model BERT (coined as Annotator).
In contrast to typical statistic-based or distantly-supervised methods, our
silver labels, derived from large pre-trained language models, take into
account rich contextual information contained in the LMs. As a result, they
bring distinct advantages in preserving informativeness, concordance, and
completeness of quality phrases. Secondly, training a discriminative span
prediction model heavily relies on massive annotated data and is likely to face
the risk of overfitting silver labels. Alternatively, we formalize phrase
tagging task as the sequence generation problem by directly fine-tuning on the
Sequence-to-Sequence pre-trained language model BART with silver labels (coined
as Generator). Finally, we merge the quality phrases from both the Annotator
and Generator as the final predictions, considering their complementary nature
and distinct characteristics. Extensive experiments show that our LMPhrase
consistently outperforms all the existing competitors across two different
granularity phrase mining tasks, where each task is tested on two different
domain datasets.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17351" title="Abstract">arXiv:2312.17351</a> [<a href="/pdf/2312.17351" title="Download PDF">pdf</a>, <a href="/format/2312.17351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Local Network Structure Critically Impacts Epidemic Spread  and Interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eldaghar%2C+O">Omar Eldaghar</a>, 
<a href="/search/cs?searchtype=author&query=Mahoney%2C+M+W">Michael W. Mahoney</a>, 
<a href="/search/cs?searchtype=author&query=Gleich%2C+D+F">David F. Gleich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Network epidemic simulation holds the promise of enabling fine-grained
understanding of epidemic behavior, beyond that which is possible with
coarse-grained compartmental models. Key inputs to these epidemic simulations
are the networks themselves. However, empirical measurements and samples of
realistic interaction networks typically display properties that are
challenging to capture with popular synthetic models of networks. Our empirical
results show that epidemic spread behavior is very sensitive to a subtle but
ubiquitous form of multi-scale local structure that is not present in common
baseline models, including (but not limited to) uniform random graph models
(Erdos-Renyi), random configuration models (Chung-Lu), etc. Such structure is
not necessary to reproduce very simple network statistics, such as degree
distributions or triangle closing probabilities. However, we show that this
multi-scale local structure impacts, critically, the behavior of more complex
network properties, in particular the effect of interventions such as
quarantining; and it enables epidemic spread to be halted in realistic
interaction networks, even when it cannot be halted in simple synthetic models.
Key insights from our analysis include how epidemics on networks with
widespread multi-scale local structure are easier to mitigate, as well as
characterizing which nodes are ultimately not likely to be infected. We
demonstrate that this structure results from more than just local triangle
structure in the network, and we illustrate processes based on homophily or
social influence and random walks that suggest how this multi-scale local
structure arises.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17353" title="Abstract">arXiv:2312.17353</a> [<a href="/pdf/2312.17353" title="Download PDF">pdf</a>, <a href="/format/2312.17353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Auto-Modeling of Formal Verification for NextG Protocols: A  Multimodal cross- and self-attention Large Language Model Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jingda Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Ying Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces Auto-modeling of Formal Verification with Real-world
Prompting for 5G and NextG protocols (AVRE), a novel system designed for the
formal verification of Next Generation (NextG) communication protocols,
addressing the increasing complexity and scalability challenges in network
protocol design and verification. Utilizing Large Language Models (LLMs), AVRE
transforms protocol descriptions into dependency graphs and formal models,
efficiently resolving ambiguities and capturing design intent. The system
integrates a transformer model with LLMs to autonomously establish quantifiable
dependency relationships through cross- and self-attention mechanisms. Enhanced
by iterative feedback from the HyFuzz experimental platform, AVRE significantly
advances the accuracy and relevance of formal verification in complex
communication protocols, offering a groundbreaking approach to validating
sophisticated communication systems. We compare CAL's performance with
state-of-the-art LLM-based models and traditional time sequence models,
demonstrating its superiority in accuracy and robustness, achieving an accuracy
of 95.94\% and an AUC of 0.98. This NLP-based approach enables, for the first
time, the creation of exploits directly from design documents, making
remarkable progress in scalable system verification and validation.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17355" title="Abstract">arXiv:2312.17355</a> [<a href="/pdf/2312.17355" title="Download PDF">pdf</a>, <a href="/format/2312.17355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Duck&#x27;s Brain: Training and Inference of Neural Networks in Modern  Database Engines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCle%2C+M+E">Maximilian E. Sch&#xfc;le</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+T">Thomas Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Kemper%2C+A">Alfons Kemper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Although database systems perform well in data access and manipulation, their
relational model hinders data scientists from formulating machine learning
algorithms in SQL. Nevertheless, we argue that modern database systems perform
well for machine learning algorithms expressed in relational algebra. To
overcome the barrier of the relational model, this paper shows how to transform
data into a relational representation for training neural networks in SQL: We
first describe building blocks for data transformation, model training and
inference in SQL-92 and their counterparts using an extended array data type.
Then, we compare the implementation for model training and inference using
array data types to the one using a relational representation in SQL-92 only.
The evaluation in terms of runtime and memory consumption proves the
suitability of modern database systems for matrix algebra, although specialised
array data types perform better than matrices in relational representation.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17356" title="Abstract">arXiv:2312.17356</a> [<a href="/pdf/2312.17356" title="Download PDF">pdf</a>, <a href="/format/2312.17356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can you See me? On the Visibility of NOPs against Android Malware  Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soi%2C+D">Diego Soi</a>, 
<a href="/search/cs?searchtype=author&query=Maiorca%2C+D">Davide Maiorca</a>, 
<a href="/search/cs?searchtype=author&query=Giacinto%2C+G">Giorgio Giacinto</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+H">Harel Berger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Android malware still represents the most significant threat to mobile
systems. While Machine Learning systems are increasingly used to identify these
threats, past studies have revealed that attackers can bypass these detection
mechanisms by making subtle changes to Android applications, such as adding
specific API calls. These modifications are often referred to as No OPerations
(NOP), which ideally should not alter the semantics of the program. However,
many NOPs can be spotted and eliminated by refining the app analysis process.
This paper proposes a visibility metric that assesses the difficulty in
spotting NOPs and similar non-operational codes. We tested our metric on a
state-of-the-art, opcode-based deep learning system for Android malware
detection. We implemented attacks on the feature and problem spaces and
calculated their visibility according to our metric. The attained results show
an intriguing trade-off between evasion efficacy and detectability: our metric
can be valuable to ensure the real effectiveness of an adversarial attack, also
serving as a useful aid to develop better defenses.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17358" title="Abstract">arXiv:2312.17358</a> [<a href="/pdf/2312.17358" title="Download PDF">pdf</a>, <a href="/format/2312.17358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Introduction to Adaptive Software Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nia%2C+M+A">Mehran Alidoost Nia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper presents the adaptive software security model, an innovative
approach integrating the MAPE-K loop and the Software Development Life Cycle
(SDLC). It proactively embeds security policies throughout development,
reducing vulnerabilities from different levels of software engineering. Three
primary contributions-MAPE-K integration, SDLC embedding, and analytical
insights-converge to create a comprehensive approach for strengthening software
systems against security threats. This research represents a paradigm shift,
adapting security measures with agile software development and ensuring
continuous improvement in the face of evolving threats. The model emerges as a
robust solution, addressing the crucial need for adaptive software security
strategies in modern software development. We analytically discuss the
advantages of the proposed model.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17361" title="Abstract">arXiv:2312.17361</a> [<a href="/pdf/2312.17361" title="Download PDF">pdf</a>, <a href="/format/2312.17361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Learning in 4D: a Quaternion-valued Laplacian to Enhance Spectral  GCNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiorini%2C+S">Stefano Fiorini</a>, 
<a href="/search/cs?searchtype=author&query=Coniglio%2C+S">Stefano Coniglio</a>, 
<a href="/search/cs?searchtype=author&query=Ciavotta%2C+M">Michele Ciavotta</a>, 
<a href="/search/cs?searchtype=author&query=Messina%2C+E">Enza Messina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce QuaterGCN, a spectral Graph Convolutional Network (GCN) with
quaternion-valued weights at whose core lies the Quaternionic Laplacian, a
quaternion-valued Laplacian matrix by whose proposal we generalize two
widely-used Laplacian matrices: the classical Laplacian (defined for undirected
graphs) and the complex-valued Sign-Magnetic Laplacian (proposed to handle
digraphs with weights of arbitrary sign). In addition to its generality, our
Quaternionic Laplacian is the only Laplacian to completely preserve the
topology of a digraph, as it can handle graphs and digraphs containing
antiparallel pairs of edges (digons) of different weights without reducing them
to a single (directed or undirected) edge as done with other Laplacians.
Experimental results show the superior performance of QuaterGCN compared to
other state-of-the-art GCNs, particularly in scenarios where the information
the digons carry is crucial to successfully address the task at hand.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17364" title="Abstract">arXiv:2312.17364</a> [<a href="/pdf/2312.17364" title="Download PDF">pdf</a>, <a href="/ps/2312.17364" title="Download PostScript">ps</a>, <a href="/format/2312.17364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomness Requirements and Asymmetries in Nash Equilibria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orzech%2C+E">Edan Orzech</a>, 
<a href="/search/cs?searchtype=author&query=Rinard%2C+M">Martin Rinard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In general, Nash equilibria in normal-form games may require players to play
(probabilistically) mixed strategies. We define a measure of the complexity of
finite probability distributions and study the complexity required to play NEs
in finite two player $n\times n$ games with rational payoffs. Our central
results show that there exist games in which there is an exponential vs. linear
gap in the complexity of the mixed distributions that the two players play at
(the unique) NE. This gap induces gaps in the amount of space required to
represent and sample from the corresponding distributions using known
state-of-the-art sampling algorithms. We also establish upper and lower bounds
on the complexity of any NE in the games that we study. These results highlight
(i) the nontriviality of the assumption that players can any mixed strategy and
(ii) the disparities in resources that players may require to play NEs in the
games that we study.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17369" title="Abstract">arXiv:2312.17369</a> [<a href="/pdf/2312.17369" title="Download PDF">pdf</a>, <a href="/format/2312.17369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SANIA: Polyak-type Optimization Framework Leads to Scale Invariant  Stochastic Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdukhakimov%2C+F">Farshed Abdukhakimov</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+C">Chulu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Kamzolov%2C+D">Dmitry Kamzolov</a>, 
<a href="/search/cs?searchtype=author&query=Gower%2C+R">Robert Gower</a>, 
<a href="/search/cs?searchtype=author&query=Tak%C3%A1%C4%8D%2C+M">Martin Tak&#xe1;&#x10d;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Adaptive optimization methods are widely recognized as among the most popular
approaches for training Deep Neural Networks (DNNs). Techniques such as Adam,
AdaGrad, and AdaHessian utilize a preconditioner that modifies the search
direction by incorporating information about the curvature of the objective
function. However, despite their adaptive characteristics, these methods still
require manual fine-tuning of the step-size. This, in turn, impacts the time
required to solve a particular problem. This paper presents an optimization
framework named SANIA to tackle these challenges. Beyond eliminating the need
for manual step-size hyperparameter settings, SANIA incorporates techniques to
address poorly scaled or ill-conditioned problems. We also explore several
preconditioning methods, including Hutchinson's method, which approximates the
Hessian diagonal of the loss function. We conclude with an extensive empirical
examination of the proposed techniques across classification tasks, covering
both convex and non-convex contexts.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17370" title="Abstract">arXiv:2312.17370</a> [<a href="/pdf/2312.17370" title="Download PDF">pdf</a>, <a href="/format/2312.17370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seqnature: Extracting Network Fingerprints from Packet Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varmarken%2C+J">Janus Varmarken</a>, 
<a href="/search/cs?searchtype=author&query=Trimananda%2C+R">Rahmadi Trimananda</a>, 
<a href="/search/cs?searchtype=author&query=Markopoulou%2C+A">Athina Markopoulou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This paper proposes a general network fingerprinting framework, Seqnature,
that uses packet sequences as its basic data unit and that makes it simple to
implement any fingerprinting technique that can be formulated as a problem of
identifying packet exchanges that consistently occur when the fingerprinted
event is triggered. We demonstrate the versatility of Seqnature by using it to
implement five different fingerprinting techniques, as special cases of the
framework, which broadly fall into two categories: (i) fingerprinting
techniques that consider features of each individual packet in a packet
sequence, e.g., size and direction; and (ii) fingerprinting techniques that
only consider stream-wide features, specifically what Internet endpoints are
contacted. We illustrate how Seqnature facilitates comparisons of the relative
performance of different fingerprinting techniques by applying the five
fingerprinting techniques to datasets from the literature. The results confirm
findings in prior work, for example that endpoint information alone is
insufficient to differentiate between individual events on Internet of Things
devices, but also show that smart TV app fingerprints based exclusively on
endpoint information are not as distinct as previously reported.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17372" title="Abstract">arXiv:2312.17372</a> [<a href="/pdf/2312.17372" title="Download PDF">pdf</a>, <a href="/format/2312.17372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond PID Controllers: PPO with Neuralized PID Policy for Proton Beam  Intensity Control in Mu2e
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J+Y">Jerry Yao-Chieh Hu</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A">Aakaash Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Thieme%2C+M">Mattson Thieme</a>, 
<a href="/search/cs?searchtype=author&query=Nagaslaev%2C+V">Vladimir Nagaslaev</a>, 
<a href="/search/cs?searchtype=author&query=Austin%2C+M">Mark Austin</a>, 
<a href="/search/cs?searchtype=author&query=Arnold%2C+J">Jeremy Arnold</a>, 
<a href="/search/cs?searchtype=author&query=Berlioz%2C+J">Jose Berlioz</a>, 
<a href="/search/cs?searchtype=author&query=Hanlet%2C+P">Pierrick Hanlet</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+A">Aisha Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Nicklaus%2C+D">Dennis Nicklaus</a>, 
<a href="/search/cs?searchtype=author&query=Mitrevski%2C+J">Jovan Mitrevski</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+J+M+S">Jason Michael St.John</a>, 
<a href="/search/cs?searchtype=author&query=Pradhan%2C+G">Gauri Pradhan</a>, 
<a href="/search/cs?searchtype=author&query=Saewert%2C+A">Andrea Saewert</a>, 
<a href="/search/cs?searchtype=author&query=Seiya%2C+K">Kiyomi Seiya</a>, 
<a href="/search/cs?searchtype=author&query=Schupbach%2C+B">Brian Schupbach</a>, 
<a href="/search/cs?searchtype=author&query=Thurman-Keup%2C+R">Randy Thurman-Keup</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+N">Nhan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Rui Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ogrenci%2C+S">Seda Ogrenci</a>, 
<a href="/search/cs?searchtype=author&query=Shuping%2C+A+M">Alexis Maya-Isabelle Shuping</a>, 
<a href="/search/cs?searchtype=author&query=Hazelwood%2C+K">Kyle Hazelwood</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, accepted at NeurIPS 2023 ML4Phy Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Accelerator Physics (physics.acc-ph)

</div>
<p class="mathjax">We introduce a novel Proximal Policy Optimization (PPO) algorithm aimed at
addressing the challenge of maintaining a uniform proton beam intensity
delivery in the Muon to Electron Conversion Experiment (Mu2e) at Fermi National
Accelerator Laboratory (Fermilab). Our primary objective is to regulate the
spill process to ensure a consistent intensity profile, with the ultimate goal
of creating an automated controller capable of providing real-time feedback and
calibration of the Spill Regulation System (SRS) parameters on a millisecond
timescale. We treat the Mu2e accelerator system as a Markov Decision Process
suitable for Reinforcement Learning (RL), utilizing PPO to reduce bias and
enhance training stability. A key innovation in our approach is the integration
of a neuralized Proportional-Integral-Derivative (PID) controller into the
policy function, resulting in a significant improvement in the Spill Duty
Factor (SDF) by 13.6%, surpassing the performance of the current PID controller
baseline by an additional 1.6%. This paper presents the preliminary offline
results based on a differentiable simulator of the Mu2e accelerator. It paves
the groundwork for real-time implementations and applications, representing a
crucial step towards automated proton beam intensity control for the Mu2e
experiment.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17373" title="Abstract">arXiv:2312.17373</a> [<a href="/pdf/2312.17373" title="Download PDF">pdf</a>, <a href="/format/2312.17373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A non-intrusive neural-network based gradient algorithm for parameter  estimation in non-stationary elasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frei%2C+S">Stefan Frei</a>, 
<a href="/search/math?searchtype=author&query=Reichle%2C+J">Jan Reichle</a>, 
<a href="/search/math?searchtype=author&query=Volkwein%2C+S">Stefan Volkwein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We present a non-intrusive gradient algorithm for parameter estimation
problems in non-stationary elasticity. To avoid multiple (and potentially
expensive) solutions of the underlying partial differential equation (PDE), we
approximate the PDE solver by a neural network within the gradient algorithm.
The network is trained offline for a given set of parameters. The algorithm is
applied to an unsteady linear-elastic contact problem; its convergence and
approximation properties are investigated numerically.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17376" title="Abstract">arXiv:2312.17376</a> [<a href="/pdf/2312.17376" title="Download PDF">pdf</a>, <a href="/ps/2312.17376" title="Download PostScript">ps</a>, <a href="/format/2312.17376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein Distributionally Robust Regret-Optimal Control in the  Infinite-Horizon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kargin%2C+T">Taylan Kargin</a>, 
<a href="/search/eess?searchtype=author&query=Hajar%2C+J">Joudi Hajar</a>, 
<a href="/search/eess?searchtype=author&query=Malik%2C+V">Vikrant Malik</a>, 
<a href="/search/eess?searchtype=author&query=Hassibi%2C+B">Babak Hassibi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to L4DC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We investigate the Distributionally Robust Regret-Optimal (DR-RO) control of
discrete-time linear dynamical systems with quadratic cost over an infinite
horizon. Regret is the difference in cost obtained by a causal controller and a
clairvoyant controller with access to future disturbances. We focus on the
infinite-horizon framework, which results in stability guarantees. In this DR
setting, the probability distribution of the disturbances resides within a
Wasserstein-2 ambiguity set centered at a specified nominal distribution. Our
objective is to identify a control policy that minimizes the worst-case
expected regret over an infinite horizon, considering all potential disturbance
distributions within the ambiguity set. In contrast to prior works, which
assume time-independent disturbances, we relax this constraint to allow for
time-correlated disturbances, thus actual distributional robustness. While we
show that the resulting optimal controller is non-rational and lacks a
finite-dimensional state-space realization, we demonstrate that it can still be
uniquely characterized by a finite dimensional parameter. Exploiting this fact,
we introduce an efficient numerical method to compute the controller in the
frequency domain using fixed-point iterations. This method circumvents the
computational bottleneck associated with the finite-horizon problem, where the
semi-definite programming (SDP) solution dimension scales with the time
horizon. Numerical experiments demonstrate the effectiveness and performance of
our framework.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17380" title="Abstract">arXiv:2312.17380</a> [<a href="/pdf/2312.17380" title="Download PDF">pdf</a>, <a href="/ps/2312.17380" title="Download PostScript">ps</a>, <a href="/format/2312.17380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factoring sparse polynomials fast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demin%2C+A">Alexander Demin</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Hoeven%2C+J">Joris van der Hoeven</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Commutative Algebra (math.AC)

</div>
<p class="mathjax">Consider a sparse polynomial in several variables given explicitly as a sum
of non-zero terms with coefficients in an effective field. In this paper, we
present several algorithms for factoring such polynomials and related tasks
(such as gcd computation, square-free factorization, content-free
factorization, and root extraction). Our methods are all based on sparse
interpolation, but follow two main lines of attack: iteration on the number of
variables and more direct reductions to the univariate or bivariate case. We
present detailed probabilistic complexity bounds in terms of the complexity of
sparse interpolation and evaluation.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17383" title="Abstract">arXiv:2312.17383</a> [<a href="/pdf/2312.17383" title="Download PDF">pdf</a>, <a href="/ps/2312.17383" title="Download PostScript">ps</a>, <a href="/format/2312.17383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hotspot Prediction of Severe Traffic Accidents in the Federal District  of Brazil
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lima%2C+V">Vinicius Lima</a>, 
<a href="/search/cs?searchtype=author&query=Byrd%2C+V">Vetria Byrd</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at The Twelfth International Conference on Smart Cities, Systems, Devices and Technologies SMART 2023 <a href="https://www.thinkmind.org/index.php?view=article">this https URL</a>&amp;articleid=smart_2023_1_60_40032
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SMART 2023 The Twelfth International Conference on Smart Systems,
  Devices and Technologies, IARIA, p. 26 - 31
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traffic accidents are one of the biggest challenges in a society where
commuting is so important. What triggers an accident can be dependent on
several subjective parameters and varies within each region, city, or country.
In the same way, it is important to understand those parameters in order to
provide a knowledge basis to support decisions regarding future cases
prevention. The literature presents several works where machine learning
algorithms are used for prediction of accidents or severity of accidents, in
which city-level datasets were used as evaluation studies. This work attempts
to add to the diversity of research, by focusing mainly on concentration of
accidents and how machine learning can be used to predict hotspots. This
approach demonstrated to be a useful technique for authorities to understand
nuances of accident concentration behavior. For the first time, data from the
Federal District of Brazil collected from forensic traffic accident analysts
were used and combined with data from local weather conditions to predict
hotspots of collisions. Out of the five algorithms we considered, two had good
performance: Multi-layer Perceptron and Random Forest, with the latter being
the best one at 98% accuracy. As a result, we identify that weather parameters
are not as important as the accident location, demonstrating that local
intervention is important to reduce the number of accidents.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17394" title="Abstract">arXiv:2312.17394</a> [<a href="/pdf/2312.17394" title="Download PDF">pdf</a>, <a href="/format/2312.17394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing and Enhancing the Backward-Pass Convergence of Unrolled  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotary%2C+J">James Kotary</a>, 
<a href="/search/cs?searchtype=author&query=Christopher%2C+J">Jacob Christopher</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+M+H">My H Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Fioretto%2C+F">Ferdinando Fioretto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2301.12047">arXiv:2301.12047</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The integration of constrained optimization models as components in deep
networks has led to promising advances on many specialized learning tasks. A
central challenge in this setting is backpropagation through the solution of an
optimization problem, which often lacks a closed form. One typical strategy is
algorithm unrolling, which relies on automatic differentiation through the
entire chain of operations executed by an iterative optimization solver. This
paper provides theoretical insights into the backward pass of unrolled
optimization, showing that it is asymptotically equivalent to the solution of a
linear system by a particular iterative method. Several practical pitfalls of
unrolling are demonstrated in light of these insights, and a system called
Folded Optimization is proposed to construct more efficient backpropagation
rules from unrolled solver implementations. Experiments over various end-to-end
optimization and learning tasks demonstrate the advantages of this system both
computationally, and in terms of flexibility over various optimization problem
forms.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17396" title="Abstract">arXiv:2312.17396</a> [<a href="/pdf/2312.17396" title="Download PDF">pdf</a>, <a href="/ps/2312.17396" title="Download PostScript">ps</a>, <a href="/format/2312.17396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed-Precision Paterson--Stockmeyer Method for Evaluating Polynomials  of Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+X">Xiaobo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Paterson--Stockmeyer method is an evaluation scheme for matrix
polynomials with scalar coefficients that arise in many state-of-the-art
algorithms based on polynomial or rational approximation, for example, those
for computing transcendental matrix functions. We derive a mixed-precision
version of the Paterson--Stockmeyer method that is particularly useful for
evaluating matrix polynomials with scalar coefficients of decaying magnitude.
The key idea is to perform computations on data of small magnitude in low
precision, and rounding error analysis is provided for the use of
lower-than-working precisions. We focus on the evaluation of the Taylor
approximants of the matrix exponential and show the applicability of our method
to the existing scaling and squaring algorithms, particularly when the norm of
the input matrix (which in practical algorithms is often scaled towards to
origin) is sufficiently small. We also demonstrate through experiments the
general applicability of our method to the computation of the polynomials from
the Pad\'e approximant of the matrix exponential and the Taylor approximant of
the matrix cosine. Numerical experiments show our mixed-precision
Paterson--Stockmeyer algorithms can be more efficient than its fixed-precision
counterpart while delivering the same level of accuracy.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17397" title="Abstract">arXiv:2312.17397</a> [<a href="/pdf/2312.17397" title="Download PDF">pdf</a>, <a href="/format/2312.17397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classifier-free graph diffusion for molecular property targeting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ninniri%2C+M">Matteo Ninniri</a>, 
<a href="/search/cs?searchtype=author&query=Podda%2C+M">Marco Podda</a>, 
<a href="/search/cs?searchtype=author&query=Bacciu%2C+D">Davide Bacciu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to GCLR workshop (AAAI '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">This work focuses on the task of property targeting: that is, generating
molecules conditioned on target chemical properties to expedite candidate
screening for novel drug and materials development. DiGress is a recent
diffusion model for molecular graphs whose distinctive feature is allowing
property targeting through classifier-based (CB) guidance. While CB guidance
may work to generate molecular-like graphs, we hint at the fact that its
assumptions apply poorly to the chemical domain. Based on this insight we
propose a classifier-free DiGress (FreeGress), which works by directly
injecting the conditioning information into the training process. CF guidance
is convenient given its less stringent assumptions and since it does not
require to train an auxiliary property regressor, thus halving the number of
trainable parameters in the model. We empirically show that our model yields up
to 79% improvement in Mean Absolute Error with respect to DiGress on property
targeting tasks on QM9 and ZINC-250k benchmarks. As an additional contribution,
we propose a simple yet powerful approach to improve chemical validity of
generated samples, based on the observation that certain chemical properties
such as molecular weight correlate with the number of atoms in molecules.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17404" title="Abstract">arXiv:2312.17404</a> [<a href="/pdf/2312.17404" title="Download PDF">pdf</a>, <a href="/format/2312.17404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Optimization with Conscious Allocation (POCA)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inman%2C+J">Joshua Inman</a>, 
<a href="/search/cs?searchtype=author&query=Khandait%2C+T">Tanmay Khandait</a>, 
<a href="/search/cs?searchtype=author&query=Pedrielli%2C+G">Giulia Pedrielli</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+L">Lalitha Sankar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the Proceeding of the 2023 Winter Simulation Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The performance of modern machine learning algorithms depends upon the
selection of a set of hyperparameters. Common examples of hyperparameters are
learning rate and the number of layers in a dense neural network. Auto-ML is a
branch of optimization that has produced important contributions in this area.
Within Auto-ML, hyperband-based approaches, which eliminate poorly-performing
configurations after evaluating them at low budgets, are among the most
effective. However, the performance of these algorithms strongly depends on how
effectively they allocate the computational budget to various hyperparameter
configurations. We present the new Parameter Optimization with Conscious
Allocation (POCA), a hyperband-based algorithm that adaptively allocates the
inputted budget to the hyperparameter configurations it generates following a
Bayesian sampling scheme. We compare POCA to its nearest competitor at
optimizing the hyperparameters of an artificial toy function and a deep neural
network and find that POCA finds strong configurations faster in both settings.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17407" title="Abstract">arXiv:2312.17407</a> [<a href="/pdf/2312.17407" title="Download PDF">pdf</a>, <a href="/ps/2312.17407" title="Download PostScript">ps</a>, <a href="/format/2312.17407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing roughness descriptors for distinct terrain surfaces in point  cloud data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Terrain surface roughness, often described abstractly, poses challenges in
quantitative characterisation with various descriptors found in the literature.
This study compares five commonly used roughness descriptors, exploring
correlations among their quantified terrain surface roughness maps across three
terrains with distinct spatial variations. Additionally, the study investigates
the impacts of spatial scales and interpolation methods on these correlations.
Dense point cloud data obtained through Light Detection and Ranging technique
are used in this study. The findings highlight both global pattern similarities
and local pattern distinctions in the derived roughness maps, emphasizing the
significance of incorporating multiple descriptors in studies where local
roughness values play a crucial role in subsequent analyses. The spatial scales
were found to have a smaller impact on rougher terrain, while interpolation
methods had minimal influence on roughness maps derived from different
descriptors.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17411" title="Abstract">arXiv:2312.17411</a> [<a href="/pdf/2312.17411" title="Download PDF">pdf</a>, <a href="/format/2312.17411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Posterior Networks for Approximately Bayesian Epistemic  Uncertainty Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roderick%2C+M">Melrose Roderick</a>, 
<a href="/search/cs?searchtype=author&query=Berkenkamp%2C+F">Felix Berkenkamp</a>, 
<a href="/search/cs?searchtype=author&query=Sheikholeslami%2C+F">Fatemeh Sheikholeslami</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+Z">Zico Kolter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In many real-world problems, there is a limited set of training data, but an
abundance of unlabeled data. We propose a new method, Generative Posterior
Networks (GPNs), that uses unlabeled data to estimate epistemic uncertainty in
high-dimensional problems. A GPN is a generative model that, given a prior
distribution over functions, approximates the posterior distribution directly
by regularizing the network towards samples from the prior. We prove
theoretically that our method indeed approximates the Bayesian posterior and
show empirically that it improves epistemic uncertainty estimation and
scalability over competing methods.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17414" title="Abstract">arXiv:2312.17414</a> [<a href="/pdf/2312.17414" title="Download PDF">pdf</a>, <a href="/format/2312.17414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-time hypervolume meshing part 1: Point insertion, geometric  predicates, and bistellar flips
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Anderson%2C+J+T">Jude T. Anderson</a>, 
<a href="/search/math?searchtype=author&query=Williams%2C+D+M">David M. Williams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 21 figures, and 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Part 1 of this paper provides a comprehensive guide to generating
unconstrained, simplicial, four-dimensional (4D), hypervolume meshes. While a
general procedure for constructing unconstrained n-dimensional Delaunay meshes
is well-known, many of the explicit implementation details are missing from the
relevant literature for cases in which n &gt;= 4. This issue is especially
critical for the case in which n = 4, as the resulting meshes have important
space-time applications. As a result, the purpose of this paper is to provide
explicit descriptions of the key components in a 4D mesh-generation algorithm:
namely, the point-insertion process, geometric predicates, element quality
metrics, and bistellar flips. This paper represents a natural continuation of
the work which was pioneered by Anderson et al. in "Surface and hypersurface
meshing techniques for space-time finite element methods", Computer-Aided
Design, 2023. In this previous paper, hypersurface meshes were generated using
a novel, trajectory-tracking procedure. In the current paper, we are interested
in generating coarse, 4D hypervolume meshes (boundary meshes) which are formed
by sequentially inserting points from an existing hypersurface mesh. In the
latter portion of this paper, we present numerical experiments which
demonstrate the viability of this approach for a simple, convex domain.
Although, our main focus is on the generation of hypervolume boundary meshes,
the techniques described in this paper are broadly applicable to a much wider
range of 4D meshing methods. We note that the more complex topics of
constrained hypervolume meshing, and boundary recovery for non-convex domains
will be covered in Part 2 of the paper.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17423" title="Abstract">arXiv:2312.17423</a> [<a href="/pdf/2312.17423" title="Download PDF">pdf</a>, <a href="/format/2312.17423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Bots: Detection and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai-Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Varol%2C+O">Onur Varol</a>, 
<a href="/search/cs?searchtype=author&query=Nwala%2C+A+C">Alexander C. Nwala</a>, 
<a href="/search/cs?searchtype=author&query=Sayyadiharikandeh%2C+M">Mohsen Sayyadiharikandeh</a>, 
<a href="/search/cs?searchtype=author&query=Ferrara%2C+E">Emilio Ferrara</a>, 
<a href="/search/cs?searchtype=author&query=Flammini%2C+A">Alessandro Flammini</a>, 
<a href="/search/cs?searchtype=author&query=Menczer%2C+F">Filippo Menczer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a draft of the chapter. The final version will be available in the Handbook of Computational Social Science edited by Taha Yasseri, forthcoming 2024, Edward Elgar Publishing Ltd. The material cannot be used for any other purpose without further permission of the publisher and is for private use only
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">While social media are a key source of data for computational social science,
their ease of manipulation by malicious actors threatens the integrity of
online information exchanges and their analysis. In this Chapter, we focus on
malicious social bots, a prominent vehicle for such manipulation. We start by
discussing recent studies about the presence and actions of social bots in
various online discussions to show their real-world implications and the need
for detection methods. Then we discuss the challenges of bot detection methods
and use Botometer, a publicly available bot detection tool, as a case study to
describe recent developments in this area. We close with a practical guide on
how to handle social bots in social media research.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17425" title="Abstract">arXiv:2312.17425</a> [<a href="/pdf/2312.17425" title="Download PDF">pdf</a>, <a href="/format/2312.17425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-based Transfer and Efficient Iterative Learning for Unbiased  Scene Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qishen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xinyu Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haonan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+P">Pengpeng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unbiased Scene Graph Generation (USGG) aims to address biased predictions in
SGG. To that end, data transfer methods are designed to convert coarse-grained
predicates into fine-grained ones, mitigating imbalanced distribution. However,
them overlook contextual relevance between transferred labels and
subject-object pairs, such as unsuitability of 'eating' for 'woman-table'.
Furthermore, they typically involve a two-stage process with significant
computational costs, starting with pre-training a model for data transfer,
followed by training from scratch using transferred labels. Thus, we introduce
a plug-and-play method named CITrans, which iteratively trains SGG models with
progressively enhanced data. First, we introduce Context-Restricted Transfer
(CRT), which imposes subject-object constraints within predicates' semantic
space to achieve fine-grained data transfer. Subsequently, Efficient Iterative
Learning (EIL) iteratively trains models and progressively generates enhanced
labels which are consistent with model's learning state, thereby accelerating
the training process. Finally, extensive experiments show that CITrans achieves
state-of-the-art and results with high efficiency.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17428" title="Abstract">arXiv:2312.17428</a> [<a href="/pdf/2312.17428" title="Download PDF">pdf</a>, <a href="/format/2312.17428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChangeNet: Multi-Temporal Asymmetric Change Detection Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Deyi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Siqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+M">Mingyuan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongtao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feng Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Change Detection (CD) has been attracting extensive interests with the
availability of bi-temporal datasets. However, due to the huge cost of
multi-temporal images acquisition and labeling, existing change detection
datasets are small in quantity, short in temporal, and low in practicability.
Therefore, a large-scale practical-oriented dataset covering wide temporal
phases is urgently needed to facilitate the community. To this end, the
ChangeNet dataset is presented especially for multi-temporal change detection,
along with the new task of ``Asymmetric Change Detection". Specifically,
ChangeNet consists of 31,000 multi-temporal images pairs, a wide range of
complex scenes from 100 cities, and 6 pixel-level annotated categories, which
is far superior to all the existing change detection datasets including
LEVIR-CD, WHU Building CD, etc.. In addition, ChangeNet contains amounts of
real-world perspective distortions in different temporal phases on the same
areas, which is able to promote the practical application of change detection
algorithms. The ChangeNet dataset is suitable for both binary change detection
(BCD) and semantic change detection (SCD) tasks. Accordingly, we benchmark the
ChangeNet dataset on six BCD methods and two SCD methods, and extensive
experiments demonstrate its challenges and great significance. The dataset is
available at https://github.com/jankyee/ChangeNet.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17429" title="Abstract">arXiv:2312.17429</a> [<a href="/pdf/2312.17429" title="Download PDF">pdf</a>, <a href="/format/2312.17429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commonsense for Zero-Shot Natural Language Video Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holla%2C+M">Meghana Holla</a>, 
<a href="/search/cs?searchtype=author&query=Lourentzou%2C+I">Ismini Lourentzou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Zero-shot Natural Language-Video Localization (NLVL) methods have exhibited
promising results in training NLVL models exclusively with raw video data by
dynamically generating video segments and pseudo-query annotations. However,
existing pseudo-queries often lack grounding in the source video, resulting in
unstructured and disjointed content. In this paper, we investigate the
effectiveness of commonsense reasoning in zero-shot NLVL. Specifically, we
present CORONET, a zero-shot NLVL framework that leverages commonsense to
bridge the gap between videos and generated pseudo-queries via a commonsense
enhancement module. CORONET employs Graph Convolution Networks (GCN) to encode
commonsense information extracted from a knowledge graph, conditioned on the
video, and cross-attention mechanisms to enhance the encoded video and
pseudo-query representations prior to localization. Through empirical
evaluations on two benchmark datasets, we demonstrate that CORONET surpasses
both zero-shot and weakly supervised baselines, achieving improvements up to
32.13% across various recall thresholds and up to 6.33% in mIoU. These results
underscore the significance of leveraging commonsense reasoning for zero-shot
NLVL.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17430" title="Abstract">arXiv:2312.17430</a> [<a href="/pdf/2312.17430" title="Download PDF">pdf</a>, <a href="/format/2312.17430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEFL: Low Entropy Client Sampling in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abebe%2C+W">Waqwoya Abebe</a>, 
<a href="/search/cs?searchtype=author&query=Munoz%2C+P">Pablo Munoz</a>, 
<a href="/search/cs?searchtype=author&query=Jannesari%2C+A">Ali Jannesari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL) is a machine learning paradigm where multiple clients
collaborate to optimize a single global model using their private data. The
global model is maintained by a central server that orchestrates the FL
training process through a series of training rounds. In each round, the server
samples clients from a client pool before sending them its latest global model
parameters for further optimization. Naive sampling strategies implement random
client sampling and fail to factor client data distributions for privacy
reasons. Hence we proposes an alternative sampling strategy by performing a
one-time clustering of clients based on their model's learned high-level
features while respecting data privacy. This enables the server to perform
stratified client sampling across clusters in every round. We show datasets of
sampled clients selected with this approach yield a low relative entropy with
respect to the global data distribution. Consequently, the FL training becomes
less noisy and significantly improves the convergence of the global model by as
much as 7.4% in some experiments. Furthermore, it also significantly reduces
the communication rounds required to achieve a target accuracy.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17431" title="Abstract">arXiv:2312.17431</a> [<a href="/pdf/2312.17431" title="Download PDF">pdf</a>, <a href="/format/2312.17431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVPatch: More Vivid Patch for Adversarial Camouflaged Attacks on Object  Detectors in the Physical World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ju Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiaosheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangbiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunlei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wenquan Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, submitted to IEEE Transactions on Information Forensics &amp; Security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent research has shown that adversarial patches can manipulate outputs
from object detection models. However, the conspicuous patterns on these
patches may draw more attention and raise suspicions among humans. Moreover,
existing works have primarily focused on the attack performance of individual
models and have neglected the generation of adversarial patches for ensemble
attacks on multiple object detection models. To tackle these concerns, we
propose a novel approach referred to as the More Vivid Patch (MVPatch), which
aims to improve the transferability and stealthiness of adversarial patches
while considering the limitations observed in prior paradigms, such as easy
identification and poor transferability. Our approach incorporates an attack
algorithm that decreases object confidence scores of multiple object detectors
by using the ensemble attack loss function, thereby enhancing the
transferability of adversarial patches. Additionally, we propose a lightweight
visual similarity measurement algorithm realized by the Compared Specified
Image Similarity (CSS) loss function, which allows for the generation of
natural and stealthy adversarial patches without the reliance on additional
generative models. Extensive experiments demonstrate that the proposed MVPatch
algorithm achieves superior attack transferability compared to similar
algorithms in both digital and physical domains, while also exhibiting a more
natural appearance. These findings emphasize the remarkable stealthiness and
transferability of the proposed MVPatch attack algorithm.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17432" title="Abstract">arXiv:2312.17432</a> [<a href="/pdf/2312.17432" title="Download PDF">pdf</a>, <a href="/format/2312.17432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Understanding with Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yunlong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+J">Jing Bi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Siting Xu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Luchuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Susan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Teng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daoan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+J">Jie An</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jingyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rongyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Vosoughi%2C+A">Ali Vosoughi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+F">Feng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianguo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenliang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">With the burgeoning growth of online video platforms and the escalating
volume of video content, the demand for proficient video understanding tools
has intensified markedly. With Large Language Models (LLMs) showcasing
remarkable capabilities in key language tasks, this survey provides a detailed
overview of the recent advancements in video understanding harnessing the power
of LLMs (Vid-LLMs). The emergent capabilities of Vid-LLMs are surprisingly
advanced, particularly their ability for open-ended spatial-temporal reasoning
combined with commonsense knowledge, suggesting a promising path for future
video understanding. We examine the unique characteristics and capabilities of
Vid-LLMs, categorizing the approaches into four main types: LLM-based Video
Agents, Vid-LLMs Pretraining, Vid-LLMs Instruction Tuning, and Hybrid Methods.
Furthermore, this survey also presents a comprehensive study of the tasks and
datasets for Vid-LLMs, along with the methodologies employed for evaluation.
Additionally, the survey explores the expansive applications of Vid-LLMs across
various domains, thereby showcasing their remarkable scalability and
versatility in addressing challenges in real-world video understanding.
Finally, the survey summarizes the limitations of existing Vid-LLMs and the
directions for future research. For more information, we recommend readers
visit the repository at
https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17440" title="Abstract">arXiv:2312.17440</a> [<a href="/pdf/2312.17440" title="Download PDF">pdf</a>, <a href="/format/2312.17440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient optimization-based trajectory planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiayu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Murgovski%2C+N">Nikolce Murgovski</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jun Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This study proposes a unified optimization-based planning framework that
addresses the precise and efficient navigation of a controlled object within a
constrained region, while contending with obstacles. We focus on handling two
collision avoidance problems, i.e., the object not colliding with obstacles and
not colliding with boundaries of the constrained region. The object or obstacle
is denoted as a union of convex polytopes and ellipsoids, and the constrained
region is denoted as an intersection of such convex sets. Using these
representations, collision avoidance can be approached by formulating explicit
constraints that separate two convex sets, or ensure that a convex set is
contained in another convex set, referred to as separating constraints and
containing constraints, respectively. We propose to use the hyperplane
separation theorem to formulate differentiable separating constraints, and
utilize the S-procedure and geometrical methods to formulate smooth containing
constraints. We state that compared to the state of the art, the proposed
formulations allow a considerable reduction in nonlinear program size and
geometry-based initialization in auxiliary variables used to formulate
collision avoidance constraints. Finally, the efficacy of the proposed unified
planning framework is evaluated in two contexts, autonomous parking in
tractor-trailer vehicles and overtaking on curved lanes. The results in both
cases exhibit an improved computational performance compared to existing
methods.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17442" title="Abstract">arXiv:2312.17442</a> [<a href="/pdf/2312.17442" title="Download PDF">pdf</a>, <a href="/format/2312.17442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Power and Temperature-Resilient Compute-In-Memory Based on  Subthreshold-FeFET
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yifei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuchu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+K">Kai Ni</a>, 
<a href="/search/cs?searchtype=author&query=Amrouch%2C+H">Hussam Amrouch</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+C">Cheng Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunxhao Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 figures, 2 tables. Accepted by Design Automation and Test in Europe (DATE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Compute-in-memory (CiM) is a promising solution for addressing the challenges
of artificial intelligence (AI) and the Internet of Things (IoT) hardware such
as 'memory wall' issue. Specifically, CiM employing nonvolatile memory (NVM)
devices in a crossbar structure can efficiently accelerate
multiply-accumulation (MAC) computation, a crucial operator in neural networks
among various AI models. Low power CiM designs are thus highly desired for
further energy efficiency optimization on AI models. Ferroelectric FET (FeFET),
an emerging device, is attractive for building ultra-low power CiM array due to
CMOS compatibility, high ION/IOFF ratio, etc. Recent studies have explored
FeFET based CiM designs that achieve low power consumption. Nevertheless,
subthreshold-operated FeFETs, where the operating voltages are scaled down to
the subthreshold region to reduce array power consumption, are particularly
vulnerable to temperature drift, leading to accuracy degradation. To address
this challenge, we propose a temperature-resilient 2T-1FeFET CiM design that
performs MAC operations reliably at subthreahold region from 0 to 85 Celsius,
while consuming ultra-low power. Benchmarked against the VGG neural network
architecture running the CIFAR-10 dataset, the proposed 2T-1FeFET CiM design
achieves 89.45% CIFAR-10 test accuracy. Compared to previous FeFET based CiM
designs, it exhibits immunity to temperature drift at an 8-bit wordlength
scale, and achieves better energy efficiency with 2866 TOPS/W.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17443" title="Abstract">arXiv:2312.17443</a> [<a href="/pdf/2312.17443" title="Download PDF">pdf</a>, <a href="/format/2312.17443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Break Out of a Pigeonhole: A Unified Framework for Examining  Miscalibration, Bias, and Stereotype in Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+Y">Yongsu Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu-Ru Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the benefits of personalizing items and information tailored to
users' needs, it has been found that recommender systems tend to introduce
biases that favor popular items or certain categories of items, and dominant
user groups. In this study, we aim to characterize the systematic errors of a
recommendation system and how they manifest in various accountability issues,
such as stereotypes, biases, and miscalibration. We propose a unified framework
that distinguishes the sources of prediction errors into a set of key measures
that quantify the various types of system-induced effects, both at the
individual and collective levels. Based on our measuring framework, we examine
the most widely adopted algorithms in the context of movie recommendation. Our
research reveals three important findings: (1) Differences between algorithms:
recommendations generated by simpler algorithms tend to be more stereotypical
but less biased than those generated by more complex algorithms. (2) Disparate
impact on groups and individuals: system-induced biases and stereotypes have a
disproportionate effect on atypical users and minority groups (e.g., women and
older users). (3) Mitigation opportunity: using structural equation modeling,
we identify the interactions between user characteristics (typicality and
diversity), system-induced effects, and miscalibration. We further investigate
the possibility of mitigating system-induced effects by oversampling
underrepresented groups and individuals, which was found to be effective in
reducing stereotypes and improving recommendation quality. Our research is the
first systematic examination of not only system-induced effects and
miscalibration but also the stereotyping issue in recommender systems.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17444" title="Abstract">arXiv:2312.17444</a> [<a href="/pdf/2312.17444" title="Download PDF">pdf</a>, <a href="/format/2312.17444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Frequency Multipliers Based on Complementary  Ferroelectric Transistors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haotian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+C">Cheng Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4mpfe%2C+T">Thomas K&#xe4;mpfe</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+K">Kai Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunzhao Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, 1 table. Accepted by Design Automation and Test in Europe (DATE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Frequency multipliers, a class of essential electronic components, play a
pivotal role in contemporary signal processing and communication systems. They
serve as crucial building blocks for generating high-frequency signals by
multiplying the frequency of an input signal. However, traditional frequency
multipliers that rely on nonlinear devices often require energy- and
area-consuming filtering and amplification circuits, and emerging designs based
on an ambipolar ferroelectric transistor require costly non-trivial
characteristic tuning or complex technology process. In this paper, we show
that a pair of standard ferroelectric field effect transistors (FeFETs) can be
used to build compact frequency multipliers without aforementioned technology
issues. By leveraging the tunable parabolic shape of the 2FeFET structures'
transfer characteristics, we propose four reconfigurable frequency multipliers,
which can switch between signal transmission and frequency doubling.
Furthermore, based on the 2FeFET structures, we propose four frequency
multipliers that realize triple, quadruple frequency modes, elucidating a
scalable methodology to generate more multiplication harmonics of the input
frequency. Performance metrics such as maximum operating frequency, power,
etc., are evaluated and compared with existing works. We also implement a
practical case of frequency modulation scheme based on the proposed
reconfigurable multipliers without additional devices. Our work provides a
novel path of scalable and reconfigurable frequency multiplier designs based on
devices that have characteristics similar to FeFETs, and show that FeFETs are a
promising candidate for signal processing and communication systems in terms of
maximum operating frequency and power.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17445" title="Abstract">arXiv:2312.17445</a> [<a href="/pdf/2312.17445" title="Download PDF">pdf</a>, <a href="/format/2312.17445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMoT: Think in State Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+J">Jie Shuai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Current prompting approach for language model inference mainly rely on
Language Model's (LLM) autonomous exploration of reasoning paths, confronts an
inevitable retracing operation when erroneous routes are encountered. This is
followed by the pursuit of alternative reasoning paths. However, humans are
adept at abstracting optimal solutions from problems, thereby facilitating
swift and precise reasoning for similar problems resolution. In light of this,
we delves into the potential of harnessing expert knowledge to enhance
problem-solving within LLMs. We introduce a novel paradigm, the State Machine
of Thought (SMoT), which employs predefined state machines to furnish LLMs with
efficient reasoning paths, thereby eliminating fruitless exploration.
Furthermore, we propose a multi-agent mechanism that assigns different
objectives to agents, aiming to enhance the accuracy of SMoT reasoning. The
experimental results, derived from an array reasoning task, reveal that SMoT
realizes an extraordinary accuracy of 95\%, surpassing the performance of the
state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17446" title="Abstract">arXiv:2312.17446</a> [<a href="/pdf/2312.17446" title="Download PDF">pdf</a>, <a href="/format/2312.17446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClST: A Convolutional Transformer Framework for Automatic Modulation  Recognition by Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+D">Dongbin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lixin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wensheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Junli Liang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">With the rapid development of deep learning (DL) in recent years, automatic
modulation recognition (AMR) with DL has achieved high accuracy. However,
insufficient training signal data in complicated channel environments and
large-scale DL models are critical factors that make DL methods difficult to
deploy in practice. Aiming to these problems, we propose a novel neural network
named convolution-linked signal transformer (ClST) and a novel knowledge
distillation method named signal knowledge distillation (SKD). The ClST is
accomplished through three primary modifications: a hierarchy of transformer
containing convolution, a novel attention mechanism named parallel
spatial-channel attention (PSCA) mechanism and a novel convolutional
transformer block named convolution-transformer projection (CTP) to leverage a
convolutional projection. The SKD is a knowledge distillation method to
effectively reduce the parameters and complexity of neural networks. We train
two lightweight neural networks using the SKD algorithm, KD-CNN and
KD-MobileNet, to meet the demand that neural networks can be used on
miniaturized devices. The simulation results demonstrate that the ClST
outperforms advanced neural networks on all datasets. Moreover, both KD-CNN and
KD-MobileNet obtain higher recognition accuracy with less network complexity,
which is very beneficial for the deployment of AMR on miniaturized
communication devices.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17448" title="Abstract">arXiv:2312.17448</a> [<a href="/pdf/2312.17448" title="Download PDF">pdf</a>, <a href="/format/2312.17448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking with Human-Intent Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiawen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Advances in perception modeling have significantly improved the performance
of object tracking. However, the current methods for specifying the target
object in the initial frame are either by 1) using a box or mask template, or
by 2) providing an explicit language description. These manners are cumbersome
and do not allow the tracker to have self-reasoning ability. Therefore, this
work proposes a new tracking task -- Instruction Tracking, which involves
providing implicit tracking instructions that require the trackers to perform
tracking automatically in video frames. To achieve this, we investigate the
integration of knowledge and reasoning capabilities from a Large
Vision-Language Model (LVLM) for object tracking. Specifically, we propose a
tracker called TrackGPT, which is capable of performing complex reasoning-based
tracking. TrackGPT first uses LVLM to understand tracking instructions and
condense the cues of what target to track into referring embeddings. The
perception component then generates the tracking results based on the
embeddings. To evaluate the performance of TrackGPT, we construct an
instruction tracking benchmark called InsTrack, which contains over one
thousand instruction-video pairs for instruction tuning and evaluation.
Experiments show that TrackGPT achieves competitive performance on referring
video object segmentation benchmarks, such as getting a new state-of the-art
performance of 66.5 $\mathcal{J}\&amp;\mathcal{F}$ on Refer-DAVIS. It also
demonstrates a superior performance of instruction tracking under new
evaluation protocols. The code and models are available at
\href{https://github.com/jiawen-zhu/TrackGPT}{https://github.com/jiawen-zhu/TrackGPT}.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17449" title="Abstract">arXiv:2312.17449</a> [<a href="/pdf/2312.17449" title="Download PDF">pdf</a>, <a href="/format/2312.17449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DB-GPT: Empowering Database Interactions with Private Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+S">Siqiao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Caigao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenhui Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangyin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongjun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianshan He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Ganglin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+D">Danrui Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Hong Yi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaodong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Faqiang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The recent breakthroughs in large language models (LLMs) are positioned to
transition many areas of software. Database technologies particularly have an
important entanglement with LLMs as efficient and intuitive database
interactions are paramount. In this paper, we present DB-GPT, a revolutionary
and production-ready project that integrates LLMs with traditional database
systems to enhance user experience and accessibility. DB-GPT is designed to
understand natural language queries, provide context-aware responses, and
generate complex SQL queries with high accuracy, making it an indispensable
tool for users ranging from novice to expert. The core innovation in DB-GPT
lies in its private LLM technology, which is fine-tuned on domain-specific
corpora to maintain user privacy and ensure data security while offering the
benefits of state-of-the-art LLMs. We detail the architecture of DB-GPT, which
includes a novel retrieval augmented generation (RAG) knowledge system, an
adaptive learning mechanism to continuously improve performance based on user
feedback and a service-oriented multi-model framework (SMMF) with powerful
data-driven agents. Our extensive experiments and user studies confirm that
DB-GPT represents a paradigm shift in database interactions, offering a more
natural, efficient, and secure way to engage with data repositories. The paper
concludes with a discussion of the implications of DB-GPT framework on the
future of human-database interaction and outlines potential avenues for further
enhancements and applications in the field. The project code is available at
https://github.com/eosphoros-ai/DB-GPT. Experience DB-GPT for yourself by
installing it with the instructions
https://github.com/eosphoros-ai/DB-GPT#install and view a concise 10-minute
video at https://www.youtube.com/watch?v=KYs4nTDzEhk.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17451" title="Abstract">arXiv:2312.17451</a> [<a href="/pdf/2312.17451" title="Download PDF">pdf</a>, <a href="/format/2312.17451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedLED: Label-Free Equipment Fault Diagnosis with Vertical Federated  Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shusen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Cong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xuebin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qing Han</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shuaijun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in IEEE Transactions on Instrumentation &amp; Measurement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Intelligent equipment fault diagnosis based on Federated Transfer Learning
(FTL) attracts considerable attention from both academia and industry. It
allows real-world industrial agents with limited samples to construct a fault
diagnosis model without jeopardizing their raw data privacy. Existing
approaches, however, can neither address the intense sample heterogeneity
caused by different working conditions of practical agents, nor the extreme
fault label scarcity, even zero, of newly deployed equipment. To address these
issues, we present FedLED, the first unsupervised vertical FTL equipment fault
diagnosis method, where knowledge of the unlabeled target domain is further
exploited for effective unsupervised model transfer. Results of extensive
experiments using data of real equipment monitoring demonstrate that FedLED
obviously outperforms SOTA approaches in terms of both diagnosis accuracy (up
to 4.13 times) and generality. We expect our work to inspire further study on
label-free equipment fault diagnosis systematically enhanced by target domain
knowledge.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17453" title="Abstract">arXiv:2312.17453</a> [<a href="/pdf/2312.17453" title="Download PDF">pdf</a>, <a href="/format/2312.17453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RHS-TRNG: A Resilient High-Speed True Random Number Generator Based on  STT-MTJ Device
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Siqing Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tiejun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Sheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lizhou Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: IEEE Transactions on Very Large Scale Integration (VLSI) Systems ( Volume: 31, Issue: 10, October 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Very Large Scale Integration (VLSI) Systems,
  vol. 31, no. 10, pp. 1578-1591, Oct. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">High-quality random numbers are very critical to many fields such as
cryptography, finance, and scientific simulation, which calls for the design of
reliable true random number generators (TRNGs). Limited by entropy source,
throughput, reliability, and system integration, existing TRNG designs are
difficult to be deployed in real computing systems to greatly accelerate target
applications. This study proposes a TRNG circuit named RHS-TRNG based on
spin-transfer torque magnetic tunnel junction (STT-MTJ). RHS-TRNG generates
resilient and high-speed random bit sequences exploiting the stochastic
switching characteristics of STT-MTJ. By circuit/system co-design, we integrate
RHS-TRNG into a RISC-V processor as an acceleration component, which is driven
by customized random number generation instructions. Our experimental results
show that a single cell of RHS-TRNG has a random bit generation speed of up to
303 Mb/s, which is the highest among existing MTJ-based TRNGs. Higher
throughput can be achieved by exploiting cell-level parallelism. RHS-TRNG also
shows strong resilience against PVT variations thanks to our designs using
bidirectional switching currents and dual generator units. In addition, our
system evaluation results using gem5 simulator suggest that the system equipped
with RHS-TRNG can achieve 3.4-12x higher performance in speeding up option
pricing programs than software implementations of random number generation.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17454" title="Abstract">arXiv:2312.17454</a> [<a href="/pdf/2312.17454" title="Download PDF">pdf</a>, <a href="/ps/2312.17454" title="Download PostScript">ps</a>, <a href="/format/2312.17454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparsity Exploitation via Joint Receive Processing and Transmit  Beamforming Design for MIMO-OFDM ISAC Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zichao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 Figures, submitted to IEEE Trans
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Integrated sensing and communication (ISAC) is widely recognized as a pivotal
enabling technique for the advancement of future wireless networks. This paper
aims to efficiently exploit the inherent sparsity of echo signals for the
multi-input-multi-output (MIMO) orthogonal frequency division multiplexing
(OFDM) based ISAC system. A novel joint receive echo processing and transmit
beamforming design is presented to achieve this goal. Specifically, we first
propose a compressive sensing (CS)-assisted estimation approach to facilitate
ISAC receive echo processing, which can not only enable accurate recovery of
target information, but also allow substantial reduction in the number of
sensing subcarriers to be sampled and processed. Then, based on the proposed
CS-assisted processing method, the associated transmit beamforming design is
formulated with the objective of maximizing the sum-rate of multiuser
communications while satisfying the transmit power budget and ensuring the
received signal-to-noise ratio (SNR) for the designated sensing subcarriers. In
order to address the formulated non-convex problem involving high-dimensional
variables, an effective iterative algorithm employing majorization minimization
(MM), fractional programming (FP), and the nonlinear equality alternative
direction method of multipliers (neADMM) with closed-form solutions has been
developed. Finally, extensive numerical simulations are conducted to verify the
effectiveness of the proposed algorithm and the superior performance of the
introduced sparsity exploitation strategy.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17461" title="Abstract">arXiv:2312.17461</a> [<a href="/pdf/2312.17461" title="Download PDF">pdf</a>, <a href="/ps/2312.17461" title="Download PostScript">ps</a>, <a href="/format/2312.17461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian radial basis functions collocation for fractional PDEs:  methodology and error analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tian%2C+X">Xiaochuan Tian</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+Y">Yixuan Wu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yanzhi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The paper introduces a new meshfree pseudospectral method based on Gaussian
radial basis functions (RBFs) collocation to solve fractional Poisson
equations. Hypergeometric functions are used to represent the fractional
Laplacian of Gaussian RBFs, enabling an efficient computation of stiffness
matrix entries. Unlike existing RBF-based methods, our approach ensures a
Toeplitz structure in the stiffness matrix with equally spaced RBF centers,
enabling efficient matrix-vector multiplications using fast Fourier transforms.
We conduct a comprehensive study on the shape parameter selection, addressing
challenges related to ill-conditioning and numerical stability. The main
contribution of our work includes rigorous stability analysis and error
estimates of the Gaussian RBF collocation method, representing a first attempt
at the rigorous analysis of RBF-based methods for fractional PDEs to the best
of our knowledge. We conduct numerical experiments to validate our analysis and
provide practical insights for implementation.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17463" title="Abstract">arXiv:2312.17463</a> [<a href="/pdf/2312.17463" title="Download PDF">pdf</a>, <a href="/format/2312.17463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out of the Ordinary: Spectrally Adapting Regression for Covariate Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eyre%2C+B">Benjamin Eyre</a>, 
<a href="/search/cs?searchtype=author&query=Creager%2C+E">Elliot Creager</a>, 
<a href="/search/cs?searchtype=author&query=Madras%2C+D">David Madras</a>, 
<a href="/search/cs?searchtype=author&query=Papyan%2C+V">Vardan Papyan</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Designing deep neural network classifiers that perform robustly on
distributions differing from the available training data is an active area of
machine learning research. However, out-of-distribution generalization for
regression-the analogous problem for modeling continuous targets-remains
relatively unexplored. To tackle this problem, we return to first principles
and analyze how the closed-form solution for Ordinary Least Squares (OLS)
regression is sensitive to covariate shift. We characterize the
out-of-distribution risk of the OLS model in terms of the eigenspectrum
decomposition of the source and target data. We then use this insight to
propose a method for adapting the weights of the last layer of a pre-trained
neural regression model to perform better on input data originating from a
different distribution. We demonstrate how this lightweight spectral adaptation
procedure can improve out-of-distribution performance for synthetic and
real-world datasets.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17468" title="Abstract">arXiv:2312.17468</a> [<a href="/pdf/2312.17468" title="Download PDF">pdf</a>, <a href="/format/2312.17468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Mitigating Dimensional Collapse of Representations in  Collaborative Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+V">Vivian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hongye Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhimeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+M">Mahashweta Das</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Contrastive Learning (CL) has shown promising performance in collaborative
filtering. The key idea is to generate augmentation-invariant embeddings by
maximizing the Mutual Information between different augmented views of the same
instance. However, we empirically observe that existing CL models suffer from
the \textsl{dimensional collapse} issue, where user/item embeddings only span a
low-dimension subspace of the entire feature space. This suppresses other
dimensional information and weakens the distinguishability of embeddings. Here
we propose a non-contrastive learning objective, named nCL, which explicitly
mitigates dimensional collapse of representations in collaborative filtering.
Our nCL aims to achieve geometric properties of \textsl{Alignment} and
\textsl{Compactness} on the embedding space. In particular, the alignment tries
to push together representations of positive-related user-item pairs, while
compactness tends to find the optimal coding length of user/item embeddings,
subject to a given distortion. More importantly, our nCL does not require data
augmentation nor negative sampling during training, making it scalable to large
datasets. Experimental results demonstrate the superiority of our nCL.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17471" title="Abstract">arXiv:2312.17471</a> [<a href="/pdf/2312.17471" title="Download PDF">pdf</a>, <a href="/format/2312.17471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Decision-Dependent Games by Learning from Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wood%2C+K">Killian Wood</a>, 
<a href="/search/eess?searchtype=author&query=Zamzam%2C+A">Ahmed Zamzam</a>, 
<a href="/search/eess?searchtype=author&query=Dall%27Anese%2C+E">Emiliano Dall&#x27;Anese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper submitted to the IEEE Open Journal of Control Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper tackles the problem of solving stochastic optimization problems
with a decision-dependent distribution in the setting of stochastic monotone
games and when the distributional dependence is unknown. A two-stage approach
is proposed, which initially involves estimating the distributional dependence
on decision variables, and subsequently optimizing over the estimated
distributional map. The paper presents guarantees for the approximation of the
cost of each agent. Furthermore, a stochastic gradient-based algorithm is
developed and analyzed for finding the Nash equilibrium in a distributed
fashion. Numerical simulations are provided for a novel electric vehicle
charging market formulation using real-world data.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17472" title="Abstract">arXiv:2312.17472</a> [<a href="/pdf/2312.17472" title="Download PDF">pdf</a>, <a href="/format/2312.17472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Once Burned, Twice Shy? The Effect of Stock Market Bubbles on Traders  that Learn by Experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haibei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>, 
<a href="/search/cs?searchtype=author&query=Grundl%2C+S">Serafin Grundl</a>, 
<a href="/search/cs?searchtype=author&query=Byrd%2C+D">David Byrd</a>, 
<a href="/search/cs?searchtype=author&query=Dwarakanath%2C+K">Kshama Dwarakanath</a>, 
<a href="/search/cs?searchtype=author&query=Balch%2C+T">Tucker Balch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We study how experience with asset price bubbles changes the trading
strategies of reinforcement learning (RL) traders and ask whether the change in
trading strategies helps to prevent future bubbles. We train the RL traders in
a multi-agent market simulation platform, ABIDES, and compare the strategies of
traders trained with and without bubble experience. We find that RL traders
without bubble experience behave like short-term momentum traders, whereas
traders with bubble experience behave like value traders. Therefore, RL traders
without bubble experience amplify bubbles, whereas RL traders with bubble
experience tend to suppress and sometimes prevent them. This finding suggests
that learning from experience is a mechanism for a boom and bust cycle where
the experience of a collapsing bubble makes future bubbles less likely for a
period of time until the memory fades and bubbles become more likely to form
again.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17473" title="Abstract">arXiv:2312.17473</a> [<a href="/pdf/2312.17473" title="Download PDF">pdf</a>, <a href="/format/2312.17473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FerKD: Surgical Label Adaptation for Efficient Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqiang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Github: <a href="https://github.com/szq0214/FKD/tree/main/FerKD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We present FerKD, a novel efficient knowledge distillation framework that
incorporates partial soft-hard label adaptation coupled with a
region-calibration mechanism. Our approach stems from the observation and
intuition that standard data augmentations, such as RandomResizedCrop, tend to
transform inputs into diverse conditions: easy positives, hard positives, or
hard negatives. In traditional distillation frameworks, these transformed
samples are utilized equally through their predictive probabilities derived
from pretrained teacher models. However, merely relying on prediction values
from a pretrained teacher, a common practice in prior studies, neglects the
reliability of these soft label predictions. To address this, we propose a new
scheme that calibrates the less-confident regions to be the context using
softened hard groundtruth labels. Our approach involves the processes of hard
regions mining + calibration. We demonstrate empirically that this method can
dramatically improve the convergence speed and final accuracy. Additionally, we
find that a consistent mixing strategy can stabilize the distributions of soft
supervision, taking advantage of the soft labels. As a result, we introduce a
stabilized SelfMix augmentation that weakens the variation of the mixed images
and corresponding soft labels through mixing similar regions within the same
image. FerKD is an intuitive and well-designed learning system that eliminates
several heuristics and hyperparameters in former FKD solution. More
importantly, it achieves remarkable improvement on ImageNet-1K and downstream
tasks. For instance, FerKD achieves 81.2% on ImageNet-1K with ResNet-50,
outperforming FKD and FunMatch by remarkable margins. Leveraging better
pre-trained weights and larger architectures, our finetuned ViT-G14 even
achieves 89.9%. Our code is available at
https://github.com/szq0214/FKD/tree/main/FerKD.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17475" title="Abstract">arXiv:2312.17475</a> [<a href="/pdf/2312.17475" title="Download PDF">pdf</a>, <a href="/format/2312.17475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EHR Interaction Between Patients and AI: NoteAid EHR Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaocheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zonghai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the AAAI2024 Workshop on AI for Education (AI4ED)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rapid advancement of Large Language Models (LLMs) and their
outstanding performance in semantic and contextual comprehension, the potential
of LLMs in specialized domains warrants exploration. This paper introduces the
NoteAid EHR Interaction Pipeline, an innovative approach developed using
generative LLMs to assist in patient education, a task stemming from the need
to aid patients in understanding Electronic Health Records (EHRs). Building
upon the NoteAid work, we designed two novel tasks from the patient's
perspective: providing explanations for EHR content that patients may not
understand and answering questions posed by patients after reading their EHRs.
We extracted datasets containing 10,000 instances from MIMIC Discharge
Summaries and 876 instances from the MADE medical notes collection,
respectively, executing the two tasks through the NoteAid EHR Interaction
Pipeline with these data. Performance data of LLMs on these tasks were
collected and constructed as the corresponding NoteAid EHR Interaction Dataset.
Through a comprehensive evaluation of the entire dataset using LLM assessment
and a rigorous manual evaluation of 64 instances, we showcase the potential of
LLMs in patient education. Besides, the results provide valuable data support
for future exploration and applications in this domain while also supplying
high-quality synthetic datasets for in-house system training.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17476" title="Abstract">arXiv:2312.17476</a> [<a href="/pdf/2312.17476" title="Download PDF">pdf</a>, <a href="/format/2312.17476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Sensitivity of LLMs&#x27; Decision-Making Capabilities:  Insights from Prompt Variation and Hyperparameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loya%2C+M">Manikanta Loya</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+D+A">Divya Anand Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Futrell%2C+R">Richard Futrell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The advancement of Large Language Models (LLMs) has led to their widespread
use across a broad spectrum of tasks including decision making. Prior studies
have compared the decision making abilities of LLMs with those of humans from a
psychological perspective. However, these studies have not always properly
accounted for the sensitivity of LLMs' behavior to hyperparameters and
variations in the prompt. In this study, we examine LLMs' performance on the
Horizon decision making task studied by Binz and Schulz (2023) analyzing how
LLMs respond to variations in prompts and hyperparameters. By experimenting on
three OpenAI language models possessing different capabilities, we observe that
the decision making abilities fluctuate based on the input prompts and
temperature settings. Contrary to previous findings language models display a
human-like exploration exploitation tradeoff after simple adjustments to the
prompt.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17478" title="Abstract">arXiv:2312.17478</a> [<a href="/pdf/2312.17478" title="Download PDF">pdf</a>, <a href="/format/2312.17478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-preserving Kernel-based methods for solving dissipative PDEs  on surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sun%2C+Z">Zhengjie Sun</a>, 
<a href="/search/math?searchtype=author&query=Ling%2C+L">Leevan Ling</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+M">Meng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we propose a general meshless structure-preserving Galerkin
method for solving dissipative PDEs on surfaces. By posing the PDE in the
variational formulation and simulating the solution in the finite-dimensional
approximation space spanned by (local) Lagrange functions generated with
positive definite kernels, we obtain a semi-discrete Galerkin equation that
inherits the energy dissipation property. The fully-discrete
structure-preserving scheme is derived with the average vector field method. We
provide a convergence analysis of the proposed method for the Allen-Cahn
equation. The numerical experiments also verify the theoretical analysis
including the convergence order and structure-preserving properties.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17479" title="Abstract">arXiv:2312.17479</a> [<a href="/pdf/2312.17479" title="Download PDF">pdf</a>, <a href="/format/2312.17479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Culturally-Attuned Moral Machines: Implicit Learning of Human Value  Systems by AI through Inverse Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+N">Nigini Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jasmine Li</a>, 
<a href="/search/cs?searchtype=author&query=Khalvati%2C+K">Koosha Khalvati</a>, 
<a href="/search/cs?searchtype=author&query=Barragan%2C+R+C">Rodolfo Cortes Barragan</a>, 
<a href="/search/cs?searchtype=author&query=Reinecke%2C+K">Katharina Reinecke</a>, 
<a href="/search/cs?searchtype=author&query=Meltzoff%2C+A+N">Andrew N. Meltzoff</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+R+P+N">Rajesh P. N. Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Constructing a universal moral code for artificial intelligence (AI) is
difficult or even impossible, given that different human cultures have
different definitions of morality and different societal norms. We therefore
argue that the value system of an AI should be culturally attuned: just as a
child raised in a particular culture learns the specific values and norms of
that culture, we propose that an AI agent operating in a particular human
community should acquire that community's moral, ethical, and cultural codes.
How AI systems might acquire such codes from human observation and interaction
has remained an open question. Here, we propose using inverse reinforcement
learning (IRL) as a method for AI agents to acquire a culturally-attuned value
system implicitly. We test our approach using an experimental paradigm in which
AI agents use IRL to learn different reward functions, which govern the agents'
moral values, by observing the behavior of different cultural groups in an
online virtual world requiring real-time decision making. We show that an AI
agent learning from the average behavior of a particular cultural group can
acquire altruistic characteristics reflective of that group's behavior, and
this learned value system can generalize to new scenarios requiring altruistic
judgments. Our results provide, to our knowledge, the first demonstration that
AI agents could potentially be endowed with the ability to continually learn
their values and norms from observing and interacting with humans, thereby
becoming attuned to the culture they are operating in.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17482" title="Abstract">arXiv:2312.17482</a> [<a href="/pdf/2312.17482" title="Download PDF">pdf</a>, <a href="/format/2312.17482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Portes%2C+J">Jacob Portes</a>, 
<a href="/search/cs?searchtype=author&query=Trott%2C+A">Alex Trott</a>, 
<a href="/search/cs?searchtype=author&query=Havens%2C+S">Sam Havens</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+D">Daniel King</a>, 
<a href="/search/cs?searchtype=author&query=Venigalla%2C+A">Abhinav Venigalla</a>, 
<a href="/search/cs?searchtype=author&query=Nadeem%2C+M">Moin Nadeem</a>, 
<a href="/search/cs?searchtype=author&query=Sardana%2C+N">Nikhil Sardana</a>, 
<a href="/search/cs?searchtype=author&query=Khudia%2C+D">Daya Khudia</a>, 
<a href="/search/cs?searchtype=author&query=Frankle%2C+J">Jonathan Frankle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Although BERT-style encoder models are heavily used in NLP research, many
researchers do not pretrain their own BERTs from scratch due to the high cost
of training. In the past half-decade since BERT first rose to prominence, many
advances have been made with other transformer architectures and training
configurations that have yet to be systematically incorporated into BERT. Here,
we introduce MosaicBERT, a BERT-style encoder architecture and training recipe
that is empirically optimized for fast pretraining. This efficient architecture
incorporates FlashAttention, Attention with Linear Biases (ALiBi), Gated Linear
Units (GLU), a module to dynamically remove padded tokens, and low precision
LayerNorm into the classic transformer encoder block. The training recipe
includes a 30% masking ratio for the Masked Language Modeling (MLM) objective,
bfloat16 precision, and vocabulary size optimized for GPU throughput, in
addition to best-practices from RoBERTa and other encoder models. When
pretrained from scratch on the C4 dataset, this base model achieves a
downstream average GLUE (dev) score of 79.6 in 1.13 hours on 8 A100 80 GB GPUs
at a cost of roughly $20. We plot extensive accuracy vs. pretraining speed
Pareto curves and show that MosaicBERT base and large are consistently Pareto
optimal when compared to a competitive BERT base and large. This empirical
speed up in pretraining enables researchers and engineers to pretrain custom
BERT-style models at low cost instead of finetune on existing generic models.
We open source our model weights and code.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17484" title="Abstract">arXiv:2312.17484</a> [<a href="/pdf/2312.17484" title="Download PDF">pdf</a>, <a href="/format/2312.17484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models  through Intervention without Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhongzhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xingwu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+X">Xianfeng Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+F">Fengzong Lian</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhanhui Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cheng-Zhong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the great success of large language models (LLMs) in various tasks,
they suffer from generating hallucinations. We introduce Truth Forest, a method
that enhances truthfulness in LLMs by uncovering hidden truth representations
using multi-dimensional orthogonal probes. Specifically, it creates multiple
orthogonal bases for modeling truth by incorporating orthogonal constraints
into the probes. Moreover, we introduce Random Peek, a systematic technique
considering an extended range of positions within the sequence, reducing the
gap between discerning and generating truth features in LLMs. By employing this
approach, we improved the truthfulness of Llama-2-7B from 40.8\% to 74.5\% on
TruthfulQA. Likewise, significant improvements are observed in fine-tuned
models. We conducted a thorough analysis of truth features using probes. Our
visualization results show that orthogonal probes capture complementary
truth-related features, forming well-defined clusters that reveal the inherent
structure of the dataset. Code: \url{https://github.com/jongjyh/trfr}
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17485" title="Abstract">arXiv:2312.17485</a> [<a href="/pdf/2312.17485" title="Download PDF">pdf</a>, <a href="/format/2312.17485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Right Prompts for the Job: Repair Code-Review Defects with Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zelin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhaogui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jialong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+P">Peng Di</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxing Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages with 1 page for references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Automatic program repair (APR) techniques have the potential to reduce manual
efforts in uncovering and repairing program defects during the code review (CR)
process. However, the limited accuracy and considerable time costs associated
with existing APR approaches hinder their adoption in industrial practice. One
key factor is the under-utilization of review comments, which provide valuable
insights into defects and potential fixes. Recent advancements in Large
Language Models (LLMs) have enhanced their ability to comprehend natural and
programming languages, enabling them to generate patches based on review
comments. This paper conducts a comprehensive investigation into the effective
utilization of LLMs for repairing CR defects. In this study, various prompts
are designed and compared across mainstream LLMs using two distinct datasets
from human reviewers and automated checkers. Experimental results demonstrate a
remarkable repair rate of 72.97% with the best prompt, highlighting a
substantial improvement in the effectiveness and practicality of automatic
repair techniques.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17487" title="Abstract">arXiv:2312.17487</a> [<a href="/pdf/2312.17487" title="Download PDF">pdf</a>, <a href="/format/2312.17487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR Odometry Survey: Recent Advancements and Remaining Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+M">Minwoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wooseong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Ayoung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Odometry is crucial for robot navigation, particularly in situations where
global positioning methods like global positioning system (GPS) are
unavailable. The main goal of odometry is to predict the robot's motion and
accurately determine its current location. Various sensors, such as wheel
encoder, inertial measurement unit (IMU), camera, radar, and Light Detection
and Ranging (LiDAR), are used for odometry in robotics. LiDAR, in particular,
has gained attention for its ability to provide rich three-dimensional (3D)
data and immunity to light variations. This survey aims to examine advancements
in LiDAR odometry thoroughly. We start by exploring LiDAR technology and then
scrutinize LiDAR odometry works, categorizing them based on their sensor
integration approaches. These approaches include methods relying solely on
LiDAR, those combining LiDAR with IMU, strategies involving multiple LiDARs,
and methods fusing LiDAR with other sensor modalities. In conclusion, we
address existing challenges and outline potential future directions in LiDAR
odometry. Additionally, we analyze public datasets and evaluation methods for
LiDAR odometry. To our knowledge, this survey is the first comprehensive
exploration of LiDAR odometry.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17488" title="Abstract">arXiv:2312.17488</a> [<a href="/pdf/2312.17488" title="Download PDF">pdf</a>, <a href="/format/2312.17488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence Minimization via Blocking Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiadong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jialu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xuemin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2302.13529">arXiv:2302.13529</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We study the influence minimization problem: given a graph $G$ and a seed set
$S$, blocking at most $b$ nodes or $b$ edges such that the influence spread of
the seed set is minimized. This is a pivotal yet underexplored aspect of
network analytics, which can limit the spread of undesirable phenomena in
networks, such as misinformation and epidemics. Given the inherent NP-hardness
of the problem under the IC and LT models, previous studies have employed
greedy algorithms and Monte Carlo Simulations for its resolution. However,
existing techniques become cost-prohibitive when applied to large networks due
to the necessity of enumerating all the candidate blockers and computing the
decrease in expected spread from blocking each of them. This significantly
restricts the practicality and effectiveness of existing methods, especially
when prompt decision-making is crucial. In this paper, we propose the
AdvancedGreedy algorithm, which utilizes a novel graph sampling technique that
incorporates the dominator tree structure. We find that AdvancedGreedy can
achieve a $(1-1/e-\epsilon)$-approximation in the problem under the LT model.
Experimental evaluations on real-life networks reveal that our proposed
algorithms exhibit a significant enhancement in efficiency, surpassing the
state-of-the-art algorithm by three orders of magnitude, while achieving high
effectiveness.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17489" title="Abstract">arXiv:2312.17489</a> [<a href="/pdf/2312.17489" title="Download PDF">pdf</a>, <a href="/ps/2312.17489" title="Download PostScript">ps</a>, <a href="/format/2312.17489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operator learning for hyperbolic partial differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+C">Christopher Wang</a>, 
<a href="/search/math?searchtype=author&query=Townsend%2C+A">Alex Townsend</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We construct the first rigorously justified probabilistic algorithm for
recovering the solution operator of a hyperbolic partial differential equation
(PDE) in two variables from input-output training pairs. The primary challenge
of recovering the solution operator of hyperbolic PDEs is the presence of
characteristics, along which the associated Green's function is discontinuous.
Therefore, a central component of our algorithm is a rank detection scheme that
identifies the approximate location of the characteristics. By combining the
randomized singular value decomposition with an adaptive hierarchical partition
of the domain, we construct an approximant to the solution operator using
$O(\Psi_\epsilon^{-1}\epsilon^{-7}\log(\Xi_\epsilon^{-1}\epsilon^{-1}))$
input-output pairs with relative error $O(\Xi_\epsilon^{-1}\epsilon)$ in the
operator norm as $\epsilon\to0$, with high probability. Here, $\Psi_\epsilon$
represents the existence of degenerate singular values of the solution
operator, and $\Xi_\epsilon$ measures the quality of the training data. Our
assumptions on the regularity of the coefficients of the hyperbolic PDE are
relatively weak given that hyperbolic PDEs do not have the ``instantaneous
smoothing effect'' of elliptic and parabolic PDEs, and our recovery rate
improves as the regularity of the coefficients increases.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17492" title="Abstract">arXiv:2312.17492</a> [<a href="/pdf/2312.17492" title="Download PDF">pdf</a>, <a href="/format/2312.17492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HEAP: Unsupervised Object Discovery and Localization with Contrastive  Grouping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jinheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+M+B">Michael Bi Mi</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+R+T">Robby T. Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised object discovery and localization aims to detect or segment
objects in an image without any supervision. Recent efforts have demonstrated a
notable potential to identify salient foreground objects by utilizing
self-supervised transformer features. However, their scopes only build upon
patch-level features within an image, neglecting region/image-level and
cross-image relationships at a broader scale. Moreover, these methods cannot
differentiate various semantics from multiple instances. To address these
problems, we introduce Hierarchical mErging framework via contrAstive grouPing
(HEAP). Specifically, a novel lightweight head with cross-attention mechanism
is designed to adaptively group intra-image patches into semantically coherent
regions based on correlation among self-supervised features. Further, to ensure
the distinguishability among various regions, we introduce a region-level
contrastive clustering loss to pull closer similar regions across images. Also,
an image-level contrastive loss is present to push foreground and background
representations apart, with which foreground objects and background are
accordingly discovered. HEAP facilitates efficient hierarchical image
decomposition, which contributes to more accurate object discovery while also
enabling differentiation among objects of various classes. Extensive
experimental results on semantic segmentation retrieval, unsupervised object
discovery, and saliency detection tasks demonstrate that HEAP achieves
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17493" title="Abstract">arXiv:2312.17493</a> [<a href="/pdf/2312.17493" title="Download PDF">pdf</a>, <a href="/format/2312.17493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Low-Rank Adaptation of Large Language Model Using  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao-Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rongyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+D">Daochen Zha</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiechao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+M">Meikang Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 figure, 22 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The surge in interest and application of large language models (LLMs) has
sparked a drive to fine-tune these models to suit specific applications, such
as finance and medical science. However, concerns regarding data privacy have
emerged, especially when multiple stakeholders aim to collaboratively enhance
LLMs using sensitive data. In this scenario, federated learning becomes a
natural choice, allowing decentralized fine-tuning without exposing raw data to
central servers. Motivated by this, we investigate how data privacy can be
ensured in LLM fine-tuning through practical federated learning approaches,
enabling secure contributions from multiple parties to enhance LLMs. Yet,
challenges arise: 1) despite avoiding raw data exposure, there is a risk of
inferring sensitive information from model outputs, and 2) federated learning
for LLMs incurs notable communication overhead. To address these challenges,
this article introduces DP-LoRA, a novel federated learning algorithm tailored
for LLMs. DP-LoRA preserves data privacy by employing a Gaussian mechanism that
adds noise in weight updates, maintaining individual data privacy while
facilitating collaborative model training. Moreover, DP-LoRA optimizes
communication efficiency via low-rank adaptation, minimizing the transmission
of updated weights during distributed training. The experimental results across
medical, financial, and general datasets using various LLMs demonstrate that
DP-LoRA effectively ensures strict privacy constraints while minimizing
communication overhead.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17494" title="Abstract">arXiv:2312.17494</a> [<a href="/pdf/2312.17494" title="Download PDF">pdf</a>, <a href="/format/2312.17494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QGFace: Quality-Guided Joint Training For Mixed-Quality Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Youzhe Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">The quality of a face crop in an image is decided by many factors such as
camera resolution, distance, and illumination condition. This makes the
discrimination of face images with different qualities a challenging problem in
realistic applications. However, most existing approaches are designed
specifically for high-quality (HQ) or low-quality (LQ) images, and the
performances would degrade for the mixed-quality images. Besides, many methods
ask for pre-trained feature extractors or other auxiliary structures to support
the training and the evaluation. In this paper, we point out that the key to
better understand both the HQ and the LQ images simultaneously is to apply
different learning methods according to their qualities. We propose a novel
quality-guided joint training approach for mixed-quality face recognition,
which could simultaneously learn the images of different qualities with a
single encoder. Based on quality partition, classification-based method is
employed for HQ data learning. Meanwhile, for the LQ images which lack identity
information, we learn them with self-supervised image-image contrastive
learning. To effectively catch up the model update and improve the
discriminability of contrastive learning in our joint training scenario, we
further propose a proxy-updated real-time queue to compose the contrastive
pairs with features from the genuine encoder. Experiments on the low-quality
datasets SCface and Tinyface, the mixed-quality dataset IJB-B, and five
high-quality datasets demonstrate the effectiveness of our proposed approach in
recognizing face images of different qualities.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17495" title="Abstract">arXiv:2312.17495</a> [<a href="/pdf/2312.17495" title="Download PDF">pdf</a>, <a href="/ps/2312.17495" title="Download PostScript">ps</a>, <a href="/format/2312.17495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Chemical Language and Molecular Graph in Multimodal Fused  Deep Learning for Drug Property Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaohua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Liangxu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+R">Rongzhi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaojun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biological Physics (physics.bio-ph); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Accurately predicting molecular properties is a challenging but essential
task in drug discovery. Recently, many mono-modal deep learning methods have
been successfully applied to molecular property prediction. However, the
inherent limitation of mono-modal learning arises from relying solely on one
modality of molecular representation, which restricts a comprehensive
understanding of drug molecules and hampers their resilience against data
noise. To overcome the limitations, we construct multimodal deep learning
models to cover different molecular representations. We convert drug molecules
into three molecular representations, SMILES-encoded vectors, ECFP
fingerprints, and molecular graphs. To process the modal information,
Transformer-Encoder, bi-directional gated recurrent units (BiGRU), and graph
convolutional network (GCN) are utilized for feature learning respectively,
which can enhance the model capability to acquire complementary and naturally
occurring bioinformatics information. We evaluated our triple-modal model on
six molecule datasets. Different from bi-modal learning models, we adopt five
fusion methods to capture the specific features and leverage the contribution
of each modal information better. Compared with mono-modal models, our
multimodal fused deep learning (MMFDL) models outperform single models in
accuracy, reliability, and resistance capability against noise. Moreover, we
demonstrate its generalization ability in the prediction of binding constants
for protein-ligand complex molecules in the refined set of PDBbind. The
advantage of the multimodal model lies in its ability to process diverse
sources of data using proper models and suitable fusion methods, which would
enhance the noise resistance of the model while obtaining data diversity.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17503" title="Abstract">arXiv:2312.17503</a> [<a href="/pdf/2312.17503" title="Download PDF">pdf</a>, <a href="/format/2312.17503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiBid: A Cross-Channel Constrained Bidding System with Budget Allocation  by Hierarchical Offline Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+H">Chi Harold Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shangqin Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiahong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zipeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yaqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qianlong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingxing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Online display advertising platforms service numerous advertisers by
providing real-time bidding (RTB) for the scale of billions of ad requests
every day. The bidding strategy handles ad requests cross multiple channels to
maximize the number of clicks under the set financial constraints, i.e., total
budget and cost-per-click (CPC), etc. Different from existing works mainly
focusing on single channel bidding, we explicitly consider cross-channel
constrained bidding with budget allocation. Specifically, we propose a
hierarchical offline deep reinforcement learning (DRL) framework called
``HiBid'', consisted of a high-level planner equipped with auxiliary loss for
non-competitive budget allocation, and a data augmentation enhanced low-level
executor for adaptive bidding strategy in response to allocated budgets.
Additionally, a CPC-guided action selection mechanism is introduced to satisfy
the cross-channel CPC constraint. Through extensive experiments on both the
large-scale log data and online A/B testing, we confirm that HiBid outperforms
six baselines in terms of the number of clicks, CPC satisfactory ratio, and
return-on-investment (ROI). We also deploy HiBid on Meituan advertising
platform to already service tens of thousands of advertisers every day.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17505" title="Abstract">arXiv:2312.17505</a> [<a href="/pdf/2312.17505" title="Download PDF">pdf</a>, <a href="/format/2312.17505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Open-Vocabulary Diffusion to Camouflaged Instance  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Tuan-Anh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+T">Duc Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+B">Binh-Son Hua</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+N+M">Nhat Minh Chung</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I+W">Ivor W. Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Sai-Kit Yeung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Text-to-image diffusion techniques have shown exceptional capability of
producing high-quality images from text descriptions. This indicates that there
exists a strong correlation between the visual and textual domains. In
addition, text-image discriminative models such as CLIP excel in image
labelling from text prompts, thanks to the rich and diverse information
available from open concepts. In this paper, we leverage these technical
advances to solve a challenging problem in computer vision: camouflaged
instance segmentation. Specifically, we propose a method built upon a
state-of-the-art diffusion model, empowered by open-vocabulary to learn
multi-scale textual-visual features for camouflaged object representations.
Such cross-domain representations are desirable in segmenting camouflaged
objects where visual cues are subtle to distinguish the objects from the
background, especially in segmenting novel objects which are not seen in
training. We also develop technically supportive components to effectively fuse
cross-domain features and engage relevant features towards respective
foreground objects. We validate our method and compare it with existing ones on
several benchmark datasets of camouflaged instance segmentation and generic
open-vocabulary instance segmentation. Experimental results confirm the
advances of our method over existing ones. We will publish our code and
pre-trained models to support future research.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17507" title="Abstract">arXiv:2312.17507</a> [<a href="/pdf/2312.17507" title="Download PDF">pdf</a>, <a href="/format/2312.17507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Actuator-Constrained Reinforcement Learning for High-Speed Quadrupedal  Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Young-Ha Shin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tae-Gyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+G">Gwanghyeon Ji</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hae-Won Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a method for achieving high-speed running of a quadruped
robot by considering the actuator torque-speed operating region in
reinforcement learning. The physical properties and constraints of the actuator
are included in the training process to reduce state transitions that are
infeasible in the real world due to motor torque-speed limitations. The gait
reward is designed to distribute motor torque evenly across all legs,
contributing to more balanced power usage and mitigating performance
bottlenecks due to single-motor saturation. Additionally, we designed a
lightweight foot to enhance the robot's agility. We observed that applying the
motor operating region as a constraint helps the policy network avoid
infeasible areas during sampling. With the trained policy, KAIST Hound, a 45 kg
quadruped robot, can run up to 6.5 m/s, which is the fastest speed among
electric motor-based quadruped robots.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17510" title="Abstract">arXiv:2312.17510</a> [<a href="/pdf/2312.17510" title="Download PDF">pdf</a>, <a href="/format/2312.17510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Database Engines via Query Plan Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ba%2C+J">Jinsheng Ba</a>, 
<a href="/search/cs?searchtype=author&query=Rigger%2C+M">Manuel Rigger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM SIGSOFT Distinguished Paper Award in The 45th International Conference on Software Engineering (ICSE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Database systems are widely used to store and query data. Test oracles have
been proposed to find logic bugs in such systems, that is, bugs that cause the
database system to compute an incorrect result. To realize a fully automated
testing approach, such test oracles are paired with a test case generation
technique; a test case refers to a database state and a query on which the test
oracle can be applied. In this work, we propose the concept of Query Plan
Guidance (QPG) for guiding automated testing towards "interesting" test cases.
SQL and other query languages are declarative. Thus, to execute a query, the
database system translates every operator in the source language to one of
potentially many so-called physical operators that can be executed; the tree of
physical operators is referred to as the query plan. Our intuition is that by
steering testing towards exploring diverse query plans, we also explore more
interesting behaviors-some of which are potentially incorrect. To this end, we
propose a mutation technique that gradually applies promising mutations to the
database state, causing the DBMS to create diverse query plans for subsequent
queries. We applied our method to three mature, widely-used, and
extensively-tested database systems-SQLite, TiDB, and CockroachDB-and found 53
unique, previously unknown bugs. Our method exercises 4.85-408.48X more unique
query plans than a naive random generation method and 7.46X more than a code
coverage guidance method. Since most database systems-including commercial
ones-expose query plans to the user, we consider QPG a generally applicable,
black-box approach and believe that the core idea could also be applied in
other contexts (e.g., to measure the quality of a test suite).
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17515" title="Abstract">arXiv:2312.17515</a> [<a href="/pdf/2312.17515" title="Download PDF">pdf</a>, <a href="/format/2312.17515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in  the Avalon Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zijing Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shunfeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shilong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code will release soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multi-agent collaboration with Large Language Models (LLMs) demonstrates
proficiency in basic tasks, yet its efficiency in more complex scenarios
remains unexplored. In gaming environments, these agents often face situations
without established coordination protocols, requiring them to make intelligent
inferences about teammates from limited data. This problem motivates the area
of ad hoc teamwork, in which an agent may potentially cooperate with a variety
of teammates to achieve a shared goal. Our study focuses on the ad hoc teamwork
problem where the agent operates in an environment driven by natural language.
Our findings reveal the potential of LLM agents in team collaboration,
highlighting issues related to hallucinations in communication. To address this
issue, we develop CodeAct, a general agent that equips LLM with enhanced memory
and code-driven reasoning, enabling the repurposing of partial information for
rapid adaptation to new teammates.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17516" title="Abstract">arXiv:2312.17516</a> [<a href="/pdf/2312.17516" title="Download PDF">pdf</a>, <a href="/format/2312.17516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust TOA-based Localization with Inaccurate Anchors for MANET
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinkai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+M">Min Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiandong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Accurate node localization is vital for mobile ad hoc networks (MANETs).
Current methods like Time of Arrival (TOA) can estimate node positions using
imprecise baseplates and achieve the Cram\'er-Rao lower bound (CRLB) accuracy.
In multi-hop MANETs, some nodes lack direct links to base anchors, depending on
neighbor nodes as dynamic anchors for chain localization. However, the dynamic
nature of MANETs challenges TOA's robustness due to the availability and
accuracy of base anchors, coupled with ranging errors. To address the issue of
cascading positioning error divergence, we first derive the CRLB for any
primary node in MANETs as a metric to tackle localization error in cascading
scenarios. Second, we propose an advanced two-step TOA method based on CRLB
which is able to approximate target node's CRLB with only local neighbor
information. Finally, simulation results confirm the robustness of our
algorithm, achieving CRLB-level accuracy for small ranging errors and
maintaining precision for larger errors compared to existing TOA methods.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17517" title="Abstract">arXiv:2312.17517</a> [<a href="/pdf/2312.17517" title="Download PDF">pdf</a>, <a href="/format/2312.17517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedded feature selection in LSTM networks with multi-objective  evolutionary ensemble learning for time series forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Espinosa%2C+R">Raquel Espinosa</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez%2C+F">Fernando Jim&#xe9;nez</a>, 
<a href="/search/cs?searchtype=author&query=Palma%2C+J">Jos&#xe9; Palma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Time series forecasting plays a crucial role in diverse fields, necessitating
the development of robust models that can effectively handle complex temporal
patterns. In this article, we present a novel feature selection method embedded
in Long Short-Term Memory networks, leveraging a multi-objective evolutionary
algorithm. Our approach optimizes the weights and biases of the LSTM in a
partitioned manner, with each objective function of the evolutionary algorithm
targeting the root mean square error in a specific data partition. The set of
non-dominated forecast models identified by the algorithm is then utilized to
construct a meta-model through stacking-based ensemble learning. Furthermore,
our proposed method provides an avenue for attribute importance determination,
as the frequency of selection for each attribute in the set of non-dominated
forecasting models reflects their significance. This attribute importance
insight adds an interpretable dimension to the forecasting process.
Experimental evaluations on air quality time series data from Italy and
southeast Spain demonstrate that our method substantially improves the
generalization ability of conventional LSTMs, effectively reducing overfitting.
Comparative analyses against state-of-the-art CancelOut and EAR-FS methods
highlight the superior performance of our approach.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17518" title="Abstract">arXiv:2312.17518</a> [<a href="/pdf/2312.17518" title="Download PDF">pdf</a>, <a href="/ps/2312.17518" title="Download PostScript">ps</a>, <a href="/format/2312.17518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The poset of binary CSS-T quantum codes and cyclic codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Camps-Moreno%2C+E">Eduardo Camps-Moreno</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+H+H">Hiram H. L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+G+L">Gretchen L. Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Ruano%2C+D">Diego Ruano</a>, 
<a href="/search/cs?searchtype=author&query=San-Jos%C3%A9%2C+R">Rodrigo San-Jos&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Soprunov%2C+I">Ivan Soprunov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">CSS-T codes were recently introduced as quantum error-correcting codes that
respect a transversal gate. A CSS-T code depends on a CSS-T pair, which is a
pair of binary codes $(C_1, C_2)$ such that $C_1$ contains $C_2$, $C_2$ is
even, and the shortening of the dual of $C_1$ with respect to the support of
each codeword of $C_2$ is self-dual. In this paper, we give new conditions to
guarantee that a pair of binary codes $(C_1, C_2)$ is a CSS-T pair. We define
the poset of CSS-T pairs and determine the minimal and maximal elements of the
poset. We provide a propagation rule for nondegenerate CSS-T codes. We applied
some main results to Reed-Muller, cyclic, and extended cyclic codes. We
characterize CSS-T pairs of cyclic codes in terms of the defining cyclotomic
cosets. We find cyclic and extended cyclic codes to obtain quantum codes with
better parameters than those in the literature.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17522" title="Abstract">arXiv:2312.17522</a> [<a href="/pdf/2312.17522" title="Download PDF">pdf</a>, <a href="/format/2312.17522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of the PromptCBLUE Shared Task in CHIP2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mosha Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Buzhou Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents an overview of the PromptCBLUE shared task
(<a href="http://cips-chip.org.cn/2023/eval1">this http URL</a>) held in the CHIP-2023 Conference. This
shared task reformualtes the CBLUE benchmark, and provide a good testbed for
Chinese open-domain or medical-domain large language models (LLMs) in general
medical natural language processing. Two different tracks are held: (a) prompt
tuning track, investigating the multitask prompt tuning of LLMs, (b) probing
the in-context learning capabilities of open-sourced LLMs. Many teams from both
the industry and academia participated in the shared tasks, and the top teams
achieved amazing test results. This paper describes the tasks, the datasets,
evaluation metrics, and the top systems for both tasks. Finally, the paper
summarizes the techniques and results of the evaluation of the various
approaches explored by the participating teams.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17524" title="Abstract">arXiv:2312.17524</a> [<a href="/pdf/2312.17524" title="Download PDF">pdf</a>, <a href="/format/2312.17524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance of Distributed File Systems on Cloud Computing Environment:  An Evaluation for Small-File Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duong%2C+T">Thanh Duong</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+Q">Quoc Luu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hung Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Various performance characteristics of distributed file systems have been
well studied. However, the performance efficiency of distributed file systems
on small-file problems with complex machine learning algorithms scenarios is
not well addressed. In addition, demands for unified storage of big data
processing and high-performance computing have been crucial. Hence, developing
a solution combining high-performance computing and big data with shared
storage is very important. This paper focuses on the performance efficiency of
distributed file systems with small-file datasets. We propose an architecture
combining both high-performance computing and big data with shared storage and
perform a series of experiments to investigate the performance of these
distributed file systems. The result of the experiments confirms the
applicability of the proposed architecture in terms of complex machine learning
algorithms.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17525" title="Abstract">arXiv:2312.17525</a> [<a href="/pdf/2312.17525" title="Download PDF">pdf</a>, <a href="/format/2312.17525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Space Exploration of Approximate Computing Techniques with a  Reinforcement Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saeedi%2C+S">Sepide Saeedi</a>, 
<a href="/search/cs?searchtype=author&query=Savino%2C+A">Alessandro Savino</a>, 
<a href="/search/cs?searchtype=author&query=Di+Carlo%2C+S">Stefano Di Carlo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 53rd Annual IEEE/IFIP International Conference on Dependable
  Systems and Networks Workshops (DSN-W), Porto, Portugal, 2023, pp. 167-170
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">Approximate Computing (AxC) techniques have become increasingly popular in
trading off accuracy for performance gains in various applications. Selecting
the best AxC techniques for a given application is challenging. Among proposed
approaches for exploring the design space, Machine Learning approaches such as
Reinforcement Learning (RL) show promising results. In this paper, we proposed
an RL-based multi-objective Design Space Exploration strategy to find the
approximate versions of the application that balance accuracy degradation and
power and computation time reduction. Our experimental results show a good
trade-off between accuracy degradation and decreased power and computation time
for some benchmarks.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17526" title="Abstract">arXiv:2312.17526</a> [<a href="/pdf/2312.17526" title="Download PDF">pdf</a>, <a href="/format/2312.17526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise-free Optimization in Early Training Steps for Image  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">MinKyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jae-Pil Heo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024. Codes are available at github.com/2minkyulee/ECO
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent deep-learning-based single image super-resolution (SISR) methods have
shown impressive performance whereas typical methods train their networks by
minimizing the pixel-wise distance with respect to a given high-resolution (HR)
image. However, despite the basic training scheme being the predominant choice,
its use in the context of ill-posed inverse problems has not been thoroughly
investigated. In this work, we aim to provide a better comprehension of the
underlying constituent by decomposing target HR images into two subcomponents:
(1) the optimal centroid which is the expectation over multiple potential HR
images, and (2) the inherent noise defined as the residual between the HR image
and the centroid. Our findings show that the current training scheme cannot
capture the ill-posed nature of SISR and becomes vulnerable to the inherent
noise term, especially during early training steps. To tackle this issue, we
propose a novel optimization method that can effectively remove the inherent
noise term in the early steps of vanilla training by estimating the optimal
centroid and directly optimizing toward the estimation. Experimental results
show that the proposed method can effectively enhance the stability of vanilla
training, leading to overall performance gain. Codes are available at
github.com/2minkyulee/ECO.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17527" title="Abstract">arXiv:2312.17527</a> [<a href="/pdf/2312.17527" title="Download PDF">pdf</a>, <a href="/ps/2312.17527" title="Download PostScript">ps</a>, <a href="/format/2312.17527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Template-Free Invariant Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yuan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+J+V">Jyotirmoy V. Deshmukh</a>, 
<a href="/search/cs?searchtype=author&query=Raghothaman%2C+M">Mukund Raghothaman</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S">Srivatsan Ravi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Automatic verification of concurrent programs faces state explosion due to
the exponential possible interleavings of its sequential components coupled
with large or infinite state spaces. An alternative is deductive verification,
where given a candidate invariant, we establish inductive invariance and show
that any state satisfying the invariant is also safe. However, learning
(inductive) program invariants is difficult. To this end, we propose a
data-driven procedure to synthesize program invariants, where it is assumed
that the program invariant is an expression that characterizes a (hopefully
tight) over-approximation of the reachable program states. The main ideas of
our approach are: (1) We treat a candidate invariant as a classifier separating
states observed in (sampled) program traces from those speculated to be
unreachable. (2) We develop an enumerative, template-free approach to learn
such classifiers from positive and negative examples. At its core, our
enumerative approach employs decision trees to generate expressions that do not
over-fit to the observed states (and thus generalize). (3) We employ a runtime
framework to monitor program executions that may refute the candidate
invariant; every refutation triggers a revision of the candidate invariant. Our
runtime framework can be viewed as an instance of statistical model checking,
which gives us probabilistic guarantees on the candidate invariant. We also
show that such in some cases, our counterexample-guided inductive synthesis
approach converges (in probability) to an overapproximation of the reachable
set of states. Our experimental results show that our framework excels in
learning useful invariants using only a fraction of the set of reachable states
for a wide variety of concurrent programs.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17528" title="Abstract">arXiv:2312.17528</a> [<a href="/pdf/2312.17528" title="Download PDF">pdf</a>, <a href="/ps/2312.17528" title="Download PostScript">ps</a>, <a href="/format/2312.17528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing the Role of Complex Power in Small-Signal Synchronization  Stability of Multi-Converter Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ma%2C+F">Fuyilong Ma</a>, 
<a href="/search/eess?searchtype=author&query=Xin%2C+H">Huanhai Xin</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhiyi Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Linbin Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Small-signal synchronization instability (SSI) may be triggered when a
grid-connected converter is operated in weak grids. This problem is highly
related to the active and reactive power (referred to as complex power)
generation or consumption of the converter. Such an instability phenomenon
manifests as power oscillations within the bandwidth frequency of phase-locked
loop (PLL). However, in a multi-converter power system (MCPS), it is
challenging to characterize the role of each converter's complex power in SSI
issues due to the high dimension of system dynamics. In this paper, we focus on
the impact regularity of complex power on the small-signal synchronization
stability of the MCPS. Firstly, we formulate the modeling of the MCPS and
develop a systematical stability indicator to explicitly quantify the stability
margin under various operating complex power. Then, based on the proposed
stability indicator, the "resultant force" of complex power on the stability
margin of the MCPS can be analytically characterized into a weighted summation
form. Furthermore, we elaborate on the impact of each converter's active power
and reactive power, respectively. Notably, we demonstrate the cancellation
effect between the active power generation and consumption on the stability
margin, which ultimately helps prevent SSI issues in the MCPS. The correctness
of theoretical findings is well verified by simulations results.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17530" title="Abstract">arXiv:2312.17530</a> [<a href="/pdf/2312.17530" title="Download PDF">pdf</a>, <a href="/format/2312.17530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RS-DGC: Exploring Neighborhood Statistics for Dynamic Gradient  Compression on Remote Sensing Image Interpretation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weiying Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jitao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Daixun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunsong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Distributed deep learning has recently been attracting more attention in
remote sensing (RS) applications due to the challenges posed by the increased
amount of open data that are produced daily by Earth observation programs.
However, the high communication costs of sending model updates among multiple
nodes are a significant bottleneck for scalable distributed learning. Gradient
sparsification has been validated as an effective gradient compression (GC)
technique for reducing communication costs and thus accelerating the training
speed. Existing state-of-the-art gradient sparsification methods are mostly
based on the "larger-absolute-more-important" criterion, ignoring the
importance of small gradients, which is generally observed to affect the
performance. Inspired by informative representation of manifold structures from
neighborhood information, we propose a simple yet effective dynamic gradient
compression scheme leveraging neighborhood statistics indicator for RS image
interpretation, termed RS-DGC. We first enhance the interdependence between
gradients by introducing the gradient neighborhood to reduce the effect of
random noise. The key component of RS-DGC is a Neighborhood Statistical
Indicator (NSI), which can quantify the importance of gradients within a
specified neighborhood on each node to sparsify the local gradients before
gradient transmission in each iteration. Further, a layer-wise dynamic
compression scheme is proposed to track the importance changes of each layer in
real time. Extensive downstream tasks validate the superiority of our method in
terms of intelligent interpretation of RS images. For example, we achieve an
accuracy improvement of 0.51% with more than 50 times communication compression
on the NWPU-RESISC45 dataset using VGG-19 network.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17532" title="Abstract">arXiv:2312.17532</a> [<a href="/pdf/2312.17532" title="Download PDF">pdf</a>, <a href="/format/2312.17532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Quantitative Reasoning Skills of Large Language Models through  Dimension Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuncheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qianyu He</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiaqing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Sihang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanghua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunwen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 40th IEEE International Conference on Data Engineering (ICDE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantities are distinct and critical components of texts that characterize
the magnitude properties of entities, providing a precise perspective for the
understanding of natural language, especially for reasoning tasks. In recent
years, there has been a flurry of research on reasoning tasks based on large
language models (LLMs), most of which solely focus on numerical values,
neglecting the dimensional concept of quantities with units despite its
importance. We argue that the concept of dimension is essential for precisely
understanding quantities and of great significance for LLMs to perform
quantitative reasoning. However, the lack of dimension knowledge and
quantity-related benchmarks has resulted in low performance of LLMs. Hence, we
present a framework to enhance the quantitative reasoning ability of language
models based on dimension perception. We first construct a dimensional unit
knowledge base (DimUnitKB) to address the knowledge gap in this area. We
propose a benchmark DimEval consisting of seven tasks of three categories to
probe and enhance the dimension perception skills of LLMs. To evaluate the
effectiveness of our methods, we propose a quantitative reasoning task and
conduct experiments. The experimental results show that our dimension
perception method dramatically improves accuracy (43.55%-&gt;50.67%) on
quantitative reasoning tasks compared to GPT-4.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17533" title="Abstract">arXiv:2312.17533</a> [<a href="/pdf/2312.17533" title="Download PDF">pdf</a>, <a href="/format/2312.17533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Void Shape Identification in a 2D Point Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moriya%2C+N">Netzer Moriya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We introduce a new approach for identifying and characterizing voids within
two-dimensional (2D) point distributions through the integration of Delaunay
triangulation and Voronoi diagrams, combined with a Minimal Distance Scoring
algorithm.
<br />Our methodology initiates with the computational determination of the Convex
Hull vertices within the point cloud, followed by a systematic selection of
optimal line segments, strategically chosen for their likelihood of
intersecting internal void regions. We then utilize Delaunay triangulation in
conjunction with Voronoi diagrams to ascertain the initial points for the
construction of the maximal internal curve envelope by adopting a
pseudo-recursive approach for higher-order void identification. In each
iteration, the existing collection of maximal internal curve envelope points
serves as a basis for identifying additional candidate points. This iterative
process is inherently self-converging, ensuring progressive refinement of the
void's shape with each successive computation cycle. The mathematical
robustness of this method allows for an efficient convergence to a stable
solution, reflecting both the geometric intricacies and the topological
characteristics of the voids within the point cloud.
<br />Our findings introduce a method that aims to balance geometric accuracy with
computational practicality. The approach is designed to improve the
understanding of void shapes within point clouds and suggests a potential
framework for exploring more complex, multi-dimensional data analysis.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17535" title="Abstract">arXiv:2312.17535</a> [<a href="/pdf/2312.17535" title="Download PDF">pdf</a>, <a href="/format/2312.17535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Olapa-MCoT: Enhancing the Chinese Mathematical Reasoning Capability of  LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shaojie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaobin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+C">Chengxiang Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">CoT (Chain-of-Thought) is a way to solve reasoning problems for LLMs .
Recently, many researches appear for improving the CoT capability of LLMs. In
this work, we also proposed Olapa-MCoT, which is a LLMs based on llama2-13B PLM
for finetuning and alignment learning. During the alignment training, we
proposed the SimRRHF algorithm and Incorrect Data Relearning and mainly focused
on optimizing the Chinese mathematical reasoning ability of Olapa-MCoT. The
experiment achieved significant results, with the accuracy of Chinese
mathematical reasoning up to 50%, 36% rise compared to llama2-13B. In addition,
the accuracy of English reasoning ability also increased by nearly 4%.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17538" title="Abstract">arXiv:2312.17538</a> [<a href="/pdf/2312.17538" title="Download PDF">pdf</a>, <a href="/format/2312.17538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance Guided Generative Adversarial Network for Explainable Binary  Classifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+X">Xiangyu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yue Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+W">Wei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+C">Chan-Tong Lam</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiangang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Mingfeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+T">Tong Tong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qinquan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tao Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures. This work has been submitted to the IEEE TNNLS for possible publication. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Despite the potential benefits of data augmentation for mitigating the data
insufficiency, traditional augmentation methods primarily rely on the prior
intra-domain knowledge. On the other hand, advanced generative adversarial
networks (GANs) generate inter-domain samples with limited variety. These
previous methods make limited contributions to describing the decision
boundaries for binary classification. In this paper, we propose a distance
guided GAN (DisGAN) which controls the variation degrees of generated samples
in the hyperplane space. Specifically, we instantiate the idea of DisGAN by
combining two ways. The first way is vertical distance GAN (VerDisGAN) where
the inter-domain generation is conditioned on the vertical distances. The
second way is horizontal distance GAN (HorDisGAN) where the intra-domain
generation is conditioned on the horizontal distances. Furthermore, VerDisGAN
can produce the class-specific regions by mapping the source images to the
hyperplane. Experimental results show that DisGAN consistently outperforms the
GAN-based augmentation methods with explainable binary classification. The
proposed method can apply to different classification architectures and has
potential to extend to multi-class classification.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17539" title="Abstract">arXiv:2312.17539</a> [<a href="/pdf/2312.17539" title="Download PDF">pdf</a>, <a href="/ps/2312.17539" title="Download PostScript">ps</a>, <a href="/format/2312.17539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competitive Search in the Line and the Star with Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angelopoulos%2C+S">Spyros Angelopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference version in MFCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the classic problem of searching for a hidden target in the line and
the $m$-ray star, in a setting in which the searcher has some prediction on the
hider's position. We first focus on the main metric for comparing search
strategies under predictions; namely, we give positive and negative results on
the consistency-robustness tradeoff, where the performance of the strategy is
evaluated at extreme situations in which the prediction is either error-free,
or adversarially generated, respectively. For the line, we show tight bounds
concerning this tradeoff, under the untrusted advice model, in which the
prediction is in the form of a $k$-bit string which encodes the responses to
$k$ binary queries. For the star, we give tight, and near-tight tradeoffs in
the positional and the directional models, in which the prediction is related
to the position of the target within the star, and to the ray on which the
target hides, respectively. Last, for all three prediction models, we show how
to generalize our study to a setting in which the performance of the strategy
is evaluated as a function of the searcher's desired tolerance to prediction
errors, both in terms of positive and inapproximability results.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17543" title="Abstract">arXiv:2312.17543</a> [<a href="/pdf/2312.17543" title="Download PDF">pdf</a>, <a href="/format/2312.17543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Efficient Universal Classifiers with Natural Language Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laurer%2C+M">Moritz Laurer</a>, 
<a href="/search/cs?searchtype=author&query=van+Atteveldt%2C+W">Wouter van Atteveldt</a>, 
<a href="/search/cs?searchtype=author&query=Casas%2C+A">Andreu Casas</a>, 
<a href="/search/cs?searchtype=author&query=Welbers%2C+K">Kasper Welbers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative Large Language Models (LLMs) have become the mainstream choice for
fewshot and zeroshot learning thanks to the universality of text generation.
Many users, however, do not need the broad capabilities of generative LLMs when
they only want to automate a classification task. Smaller BERT-like models can
also learn universal tasks, which allow them to do any text classification task
without requiring fine-tuning (zeroshot classification) or to learn new tasks
with only a few examples (fewshot), while being significantly more efficient
than generative LLMs. This paper (1) explains how Natural Language Inference
(NLI) can be used as a universal classification task that follows similar
principles as instruction fine-tuning of generative LLMs, (2) provides a
step-by-step guide with reusable Jupyter notebooks for building a universal
classifier, and (3) shares the resulting universal classifier that is trained
on 33 datasets with 389 diverse classes. Parts of the code we share has been
used to train our older zeroshot classifiers that have been downloaded more
than 55 million times via the Hugging Face Hub as of December 2023. Our new
classifier improves zeroshot performance by 9.4%.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17552" title="Abstract">arXiv:2312.17552</a> [<a href="/pdf/2312.17552" title="Download PDF">pdf</a>, <a href="/format/2312.17552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Deep Reinforcement Learning for Robust Target Tracking using  Micro Aerial Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dionigi%2C+A">Alberto Dionigi</a>, 
<a href="/search/cs?searchtype=author&query=Leomanni%2C+M">Mirko Leomanni</a>, 
<a href="/search/cs?searchtype=author&query=Saviolo%2C+A">Alessandro Saviolo</a>, 
<a href="/search/cs?searchtype=author&query=Loianno%2C+G">Giuseppe Loianno</a>, 
<a href="/search/cs?searchtype=author&query=Costante%2C+G">Gabriele Costante</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The capability to autonomously track a non-cooperative target is a key
technological requirement for micro aerial vehicles. In this paper, we propose
an output feedback control scheme based on deep reinforcement learning for
controlling a micro aerial vehicle to persistently track a flying target while
maintaining visual contact. The proposed method leverages relative position
data for control, relaxing the assumption of having access to full state
information which is typical of related approaches in literature. Moreover, we
exploit classical robustness indicators in the learning process through domain
randomization to increase the robustness of the learned policy. Experimental
results validate the proposed approach for target tracking, demonstrating high
performance and robustness with respect to mass mismatches and control delays.
The resulting nonlinear controller significantly outperforms a standard
model-based design in numerous off-nominal scenarios.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17553" title="Abstract">arXiv:2312.17553</a> [<a href="/pdf/2312.17553" title="Download PDF">pdf</a>, <a href="/format/2312.17553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fully Automated Pipeline Using Swin Transformers for Deep  Learning-Based Blood Segmentation on Head CT Scans After Aneurysmal  Subarachnoid Hemorrhage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia%2C+S+G">Sergio Garcia Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Cepeda%2C+S">Santiago Cepeda</a>, 
<a href="/search/cs?searchtype=author&query=Arrese%2C+I">Ignacio Arrese</a>, 
<a href="/search/cs?searchtype=author&query=Sarabia%2C+R">Rosario Sarabia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Background: Accurate volumetric assessment of spontaneous subarachnoid
hemorrhage (SAH) is a labor-intensive task performed with current manual and
semiautomatic methods that might be relevant for its clinical and prognostic
implications. In the present research, we sought to develop and validate an
artificial intelligence-driven, fully automated blood segmentation tool for SAH
patients via noncontrast computed tomography (NCCT) scans employing a
transformer-based Swin UNETR architecture. Methods: We retrospectively analyzed
NCCT scans from patients with confirmed aneurysmal subarachnoid hemorrhage
(aSAH) utilizing the Swin UNETR for segmentation. The performance of the
proposed method was evaluated against manually segmented ground truth data
using metrics such as Dice score, intersection over union (IoU), the volumetric
similarity index (VSI), the symmetric average surface distance (SASD), and
sensitivity and specificity. A validation cohort from an external institution
was included to test the generalizability of the model. Results: The model
demonstrated high accuracy with robust performance metrics across the internal
and external validation cohorts. Notably, it achieved high Dice coefficient
(0.873), IoU (0.810), VSI (0.840), sensitivity (0.821) and specificity (0.996)
values and a low SASD (1.866), suggesting proficiency in segmenting blood in
SAH patients. The model's efficiency was reflected in its processing speed,
indicating potential for real-time applications. Conclusions: Our Swin
UNETR-based model offers significant advances in the automated segmentation of
blood after aSAH on NCCT images. Despite the computational intensity, the model
operates effectively on standard hardware with a user-friendly interface,
facilitating broader clinical adoption. Further validation across diverse
datasets is warranted to confirm its clinical reliability.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17555" title="Abstract">arXiv:2312.17555</a> [<a href="/pdf/2312.17555" title="Download PDF">pdf</a>, <a href="/format/2312.17555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher Order Model Checking in Isabelle for Human Centric Infrastructure  Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamm%C3%BCller%2C+F">Florian Kamm&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1803.06494">arXiv:1803.06494</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">In this paper we present an efficient approach to implementing model checking
in the Higher Order Logic (HOL) of Isabelle. This is a non-trivial task since
model checking is restricted to finite state sets. By restricting our scope to
considering security attacks, we achieve an efficient executable specification
of a model checking algorithm for attack trees. We provide the existing
background, the necessary theory and illustrate its application. Theory and
application are fully formalized in Isabelle thus providing an executable model
checking algorithm.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17558" title="Abstract">arXiv:2312.17558</a> [<a href="/pdf/2312.17558" title="Download PDF">pdf</a>, <a href="/format/2312.17558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed convergence detection based on global residual error under  asynchronous iterations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Magoul%C3%A8s%2C+F">Fr&#xe9;d&#xe9;ric Magoul&#xe8;s</a>, 
<a href="/search/cs?searchtype=author&query=Gbikpi-Benissan%2C+G">Guillaume Gbikpi-Benissan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Convergence of classical parallel iterations is detected by performing a
reduction operation at each iteration in order to compute a residual error
relative to a potential solution vector. To efficiently run asynchronous
iterations, blocking communication requests are avoided, which makes it hard to
isolate and handle any global vector. While some termination protocols were
proposed for asynchronous iterations, only very few of them are based on global
residual computation and guarantee effective convergence. But the most
effective and efficient existing solutions feature two reduction operations,
which constitutes an important factor of termination delay. In this paper, we
present new, non-intrusive, protocols to compute a residual error under
asynchronous iterations, requiring only one reduction operation. Various
communication models show that some heuristics can even be introduced and
formally evaluated. Extensive experiments with up to 5600 processor cores
confirm the practical effectiveness and efficiency of our approach.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17560" title="Abstract">arXiv:2312.17560</a> [<a href="/pdf/2312.17560" title="Download PDF">pdf</a>, <a href="/ps/2312.17560" title="Download PostScript">ps</a>, <a href="/format/2312.17560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertain research country rankings. Should we continue producing  uncertain rankings?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodriguez-Navarro%2C+A">Alonso Rodriguez-Navarro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Information Retrieval (cs.IR); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Citation based country rankings consistently categorize Japan as a developing
country, even in those from the most reputed institutions. This categorization
challenges the credibility of such rankings, considering Japan elevated
scientific standing. In most cases, these rankings use percentile indicators
and are accurate if country citations fit an ideal model of distribution, but
they can be misleading in cases of deviations. The ideal model implies a
lognormal citation distribution and a power law citation based double rank: in
the global and country lists. This report conducts a systematic examination of
deviations from the ideal model and their consequential impact on evaluations.
The study evaluates six selected countries across three scientifically relevant
topics and utilizes Leiden Ranking assessments of over 300 universities. The
findings reveal three types of deviations from the lognormal citation
distribution: i deviations in the extreme upper tail; ii inflated lower tails;
and iii deflated lower part of the distributions. These deviations stem from
structural differences among research systems that are prevalent and have the
potential to mislead evaluations across all research levels. Consequently,
reliable evaluations must consider these deviations. Otherwise, while some
countries and institutions will be correctly evaluated, failure to identify
deviations in each specific country or institution will render uncertain
evaluations. For reliable assessments, future research evaluations of countries
and institutions must identify deviations from the ideal model.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17561" title="Abstract">arXiv:2312.17561</a> [<a href="/pdf/2312.17561" title="Download PDF">pdf</a>, <a href="/format/2312.17561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Informative Rays Selection for Few-Shot Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orsingher%2C+M">Marco Orsingher</a>, 
<a href="/search/cs?searchtype=author&query=Dell%27Eva%2C+A">Anthony Dell&#x27;Eva</a>, 
<a href="/search/cs?searchtype=author&query=Zani%2C+P">Paolo Zani</a>, 
<a href="/search/cs?searchtype=author&query=Medici%2C+P">Paolo Medici</a>, 
<a href="/search/cs?searchtype=author&query=Bertozzi%2C+M">Massimo Bertozzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at VISAPP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural Radiance Fields (NeRF) have recently emerged as a powerful method for
image-based 3D reconstruction, but the lengthy per-scene optimization limits
their practical usage, especially in resource-constrained settings. Existing
approaches solve this issue by reducing the number of input views and
regularizing the learned volumetric representation with either complex losses
or additional inputs from other modalities. In this paper, we present KeyNeRF,
a simple yet effective method for training NeRF in few-shot scenarios by
focusing on key informative rays. Such rays are first selected at camera level
by a view selection algorithm that promotes baseline diversity while
guaranteeing scene coverage, then at pixel level by sampling from a probability
distribution based on local image entropy. Our approach performs favorably
against state-of-the-art methods, while requiring minimal changes to existing
NeRF codebases.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17575" title="Abstract">arXiv:2312.17575</a> [<a href="/pdf/2312.17575" title="Download PDF">pdf</a>, <a href="/format/2312.17575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAD-compatible structural shape optimization with a movable B&#xe9;zier  tetrahedral mesh
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+J">Jorge L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Anitescu%2C+C">Cosmin Anitescu</a>, 
<a href="/search/cs?searchtype=author&query=Rabczuk%2C+T">Timon Rabczuk</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Methods in Applied Mechanics and Engineering, Volume 367,
  2020, 113066
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This paper presents the development of a complete CAD-compatible framework
for structural shape optimization in 3D. The boundaries of the domain are
described using NURBS while the interior is discretized with B\'ezier
tetrahedra. The tetrahedral mesh is obtained from the mesh generator software
Gmsh. A methodology to reconstruct the NURBS surfaces from the triangular faces
of the boundary mesh is presented. The description of the boundary is used for
the computation of the analytical sensitivities with respect to the control
points employed in surface design. Further, the mesh is updated at each
iteration of the structural optimization process by a pseudo-elastic moving
mesh method. In this procedure, the existing mesh is deformed to match the
updated surface and therefore reduces the need for remeshing. Numerical
examples are presented to test the performance of the proposed method. The use
of the movable mesh technique results in a considerable decrease in the
computational effort for the numerical examples.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17581" title="Abstract">arXiv:2312.17581</a> [<a href="/pdf/2312.17581" title="Download PDF">pdf</a>, <a href="/ps/2312.17581" title="Download PostScript">ps</a>, <a href="/format/2312.17581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Action-Item-Driven Summarization of Long Meeting Transcripts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golia%2C+L">Logan Golia</a>, 
<a href="/search/cs?searchtype=author&query=Kalita%2C+J">Jugal Kalita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted into International Conference on Natural Language Processing and Information Retrieval (NLPIR 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The increased prevalence of online meetings has significantly enhanced the
practicality of a model that can automatically generate the summary of a given
meeting. This paper introduces a novel and effective approach to automate the
generation of meeting summaries. Current approaches to this problem generate
general and basic summaries, considering the meeting simply as a long dialogue.
However, our novel algorithms can generate abstractive meeting summaries that
are driven by the action items contained in the meeting transcript. This is
done by recursively generating summaries and employing our action-item
extraction algorithm for each section of the meeting in parallel. All of these
sectional summaries are then combined and summarized together to create a
coherent and action-item-driven summary. In addition, this paper introduces
three novel methods for dividing up long transcripts into topic-based sections
to improve the time efficiency of our algorithm, as well as to resolve the
issue of large language models (LLMs) forgetting long-term dependencies. Our
pipeline achieved a BERTScore of 64.98 across the AMI corpus, which is an
approximately 4.98% increase from the current state-of-the-art result produced
by a fine-tuned BART (Bidirectional and Auto-Regressive Transformers) model.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17582" title="Abstract">arXiv:2312.17582</a> [<a href="/pdf/2312.17582" title="Download PDF">pdf</a>, <a href="/format/2312.17582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Darwin3: A large-scale neuromorphic chip with a Novel ISA and On-Chip  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+D">De Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaofei Jin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shichun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yitao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xundong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Youneng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fangchao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huajin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaolei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Peng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+G">Gang Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) are gaining increasing attention for their
biological plausibility and potential for improved computational efficiency. To
match the high spatial-temporal dynamics in SNNs, neuromorphic chips are highly
desired to execute SNNs in hardware-based neuron and synapse circuits directly.
This paper presents a large-scale neuromorphic chip named Darwin3 with a novel
instruction set architecture(ISA), which comprises 10 primary instructions and
a few extended instructions. It supports flexible neuron model programming and
local learning rule designs. The Darwin3 chip architecture is designed in a
mesh of computing nodes with an innovative routing algorithm. We used a
compression mechanism to represent synaptic connections, significantly reducing
memory usage. The Darwin3 chip supports up to 2.35 million neurons, making it
the largest of its kind in neuron scale. The experimental results showed that
code density was improved up to 28.3x in Darwin3, and neuron core fan-in and
fan-out were improved up to 4096x and 3072x by connection compression compared
to the physical memory depth. Our Darwin3 chip also provided memory saving
between 6.8X and 200.8X when mapping convolutional spiking neural networks
(CSNN) onto the chip, demonstrating state-of-the-art performance in accuracy
and latency compared to other neuromorphic chips.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17583" title="Abstract">arXiv:2312.17583</a> [<a href="/pdf/2312.17583" title="Download PDF">pdf</a>, <a href="/format/2312.17583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the Performance of DeepReach on High-Dimensional Systems  through Optimizing Activation Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+T">Tianhao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">With the continuous advancement in autonomous systems, it becomes crucial to
provide robust safety guarantees for safety-critical systems. Hamilton-Jacobi
Reachability Analysis is a formal verification method that guarantees
performance and safety for dynamical systems and is widely applicable to
various tasks and challenges. Traditionally, reachability problems are solved
by using grid-based methods, whose computational and memory cost scales
exponentially with the dimensionality of the system. To overcome this
challenge, DeepReach, a deep learning-based approach that approximately solves
high-dimensional reachability problems, is proposed and has shown lots of
promise. In this paper, we aim to improve the performance of DeepReach on
high-dimensional systems by exploring different choices of activation
functions. We first run experiments on a 3D system as a proof of concept. Then
we demonstrate the effectiveness of our approach on a 9D multi-vehicle
collision problem.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17584" title="Abstract">arXiv:2312.17584</a> [<a href="/pdf/2312.17584" title="Download PDF">pdf</a>, <a href="/format/2312.17584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable and Explainable Machine Learning Methods for Predictive  Process Monitoring: A Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehdiyev%2C+N">Nijat Mehdiyev</a>, 
<a href="/search/cs?searchtype=author&query=Majlatow%2C+M">Maxim Majlatow</a>, 
<a href="/search/cs?searchtype=author&query=Fettke%2C+P">Peter Fettke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper presents a systematic literature review (SLR) on the
explainability and interpretability of machine learning (ML) models within the
context of predictive process mining, using the PRISMA framework. Given the
rapid advancement of artificial intelligence (AI) and ML systems, understanding
the "black-box" nature of these technologies has become increasingly critical.
Focusing specifically on the domain of process mining, this paper delves into
the challenges of interpreting ML models trained with complex business process
data. We differentiate between intrinsically interpretable models and those
that require post-hoc explanation techniques, providing a comprehensive
overview of the current methodologies and their applications across various
application domains. Through a rigorous bibliographic analysis, this research
offers a detailed synthesis of the state of explainability and interpretability
in predictive process mining, identifying key trends, challenges, and future
directions. Our findings aim to equip researchers and practitioners with a
deeper understanding of how to develop and implement more trustworthy,
transparent, and effective intelligent systems for predictive process
analytics.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17587" title="Abstract">arXiv:2312.17587</a> [<a href="/pdf/2312.17587" title="Download PDF">pdf</a>, <a href="/format/2312.17587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tool for the Procedural Generation of Shaders using Interactive  Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sasso%2C+E">Elio Sasso</a>, 
<a href="/search/cs?searchtype=author&query=Loiacono%2C+D">Daniele Loiacono</a>, 
<a href="/search/cs?searchtype=author&query=Lanzi%2C+P+L">Pier Luca Lanzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/PierLucaLanzi/Procedural-Generation-of-Shaders-Using-Interactive-Evolutionary-Algorithms/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a tool for exploring the design space of shaders using an
interactive evolutionary algorithm integrated with the Unity editor, a
well-known commercial tool for video game development. Our framework leverages
the underlying graph-based representation of recent shader editors and
interactive evolution to allow designers to explore several visual options
starting from an existing shader. Our framework encodes the graph
representation of a current shader as a chromosome used to seed the evolution
of a shader population. It applies graph-based recombination and mutation with
a set of heuristics to create feasible shaders. The framework is an extension
of the Unity editor; thus, designers with little knowledge of evolutionary
computation (and shader programming) can interact with the underlying
evolutionary engine using the same visual interface used for working on game
scenes.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17591" title="Abstract">arXiv:2312.17591</a> [<a href="/pdf/2312.17591" title="Download PDF">pdf</a>, <a href="/format/2312.17591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Faithful Explanations for Text Classification with Robustness  Improvement and Explanation Guided Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongfang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Baotian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingcai Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Feature attribution methods highlight the important input tokens as
explanations to model predictions, which have been widely applied to deep
neural networks towards trustworthy AI. However, recent works show that
explanations provided by these methods face challenges of being faithful and
robust. In this paper, we propose a method with Robustness improvement and
Explanation Guided training towards more faithful EXplanations (REGEX) for text
classification. First, we improve model robustness by input gradient
regularization technique and virtual adversarial training. Secondly, we use
salient ranking to mask noisy tokens and maximize the similarity between model
attention and feature attribution, which can be seen as a self-training
procedure without importing other external information. We conduct extensive
experiments on six datasets with five attribution methods, and also evaluate
the faithfulness in the out-of-domain setting. The results show that REGEX
improves fidelity metrics of explanations in all settings and further achieves
consistent gains based on two randomization tests. Moreover, we show that using
highlight explanations produced by REGEX to train select-then-predict models
results in comparable task performance to the end-to-end method.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17593" title="Abstract">arXiv:2312.17593</a> [<a href="/pdf/2312.17593" title="Download PDF">pdf</a>, <a href="/ps/2312.17593" title="Download PostScript">ps</a>, <a href="/format/2312.17593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VR interaction for efficient virtual manufacturing: mini map for  multi-user VR navigation platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Huizhong Cao</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%B6derlund%2C+H">Henrik S&#xf6;derlund</a>, 
<a href="/search/cs?searchtype=author&query=Despeisse%2C+M">M&#xe9;lanie Despeisse</a>, 
<a href="/search/cs?searchtype=author&query=Rivera%2C+F+G">Francisco Garcia Rivera</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+B">Bj&#xf6;rn Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Over the past decade, the value and potential of VR applications in
manufacturing have gained significant attention in accordance with the rise of
Industry 4.0 and beyond. Its efficacy in layout planning, virtual design
reviews, and operator training has been well-established in previous studies.
However, many functional requirements and interaction parameters of VR for
manufacturing remain ambiguously defined. One area awaiting exploration is
spatial recognition and learning, crucial for understanding navigation within
the virtual manufacturing system and processing spatial data. This is
particularly vital in multi-user VR applications where participants' spatial
awareness in the virtual realm significantly influences the efficiency of
meetings and design reviews. This paper investigates the interaction parameters
of multi-user VR, focusing on interactive positioning maps for virtual factory
layout planning and exploring the user interaction design of digital maps as
navigation aid. A literature study was conducted in order to establish
frequently used technics and interactive maps from the VR gaming industry.
Multiple demonstrators of different interactive maps provide a comprehensive
A/B test which were implemented into a VR multi-user platform using the Unity
game engine. Five different prototypes of interactive maps were tested,
evaluated and graded by the 20 participants and 40 validated data streams
collected. The most efficient interaction design of interactive maps is thus
analyzed and discussed in the study.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17595" title="Abstract">arXiv:2312.17595</a> [<a href="/pdf/2312.17595" title="Download PDF">pdf</a>, <a href="/ps/2312.17595" title="Download PostScript">ps</a>, <a href="/format/2312.17595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the current applications and potential of extended reality for  environmental sustainability in manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Huizhong Cao</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%B6derlund%2C+H">Henrik S&#xf6;derlund</a>, 
<a href="/search/cs?searchtype=author&query=Derspeisse%2C+M">M&#xe9;lanie Derspeisse</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+B">Bj&#xf6;rn Johansson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, Eco Design Conference 2023, Japan, Nara
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In response to the transformation towards Industry 5.0, there is a growing
call for manufacturing systems that prioritize environmental sustainability,
alongside the emerging application of digital tools. Extended Reality (XR) -
including Virtual Reality (VR), Augmented Reality (AR) and Mixed Reality (MR) -
is one of the technologies identified as an enabler for Industry 5.0. XR could
potentially also be a driver for more sustainable manufacturing: however, its
potential environmental benefits have received limited attention. This paper
aims to explore the current manufacturing applications and research within the
field of XR technology connected to the environmental sustainability principle.
The objectives of this paper are two-fold: (1) Identify the currently explored
use cases of XR technology in literature and research, addressing environmental
sustainability in manufacturing; (2) Provide guidance and references for
industry and companies to use cases, toolboxes, methodologies, and workflows
for implementing XR in environmental sustainable manufacturing practices. Based
on the categorization of sustainability indicators, developed by the National
Institute of Standards and Technology (NIST), the authors analyzed and mapped
the current literature, with criteria of pragmatic XR use cases for
manufacturing. The exploration resulted in a mapping of the current
applications and use cases of XR technology within manufacturing that has the
potential to drive environmental sustainability. The results are presented as
stated use-cases with reference to the literature, contributing as guidance and
inspiration for future researchers or implementations in industry, using XR as
a driver for environmental sustainability. Furthermore, the authors open up the
discussion for future work and research to increase the attention of XR as a
driver for environmental sustainability.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17601" title="Abstract">arXiv:2312.17601</a> [<a href="/pdf/2312.17601" title="Download PDF">pdf</a>, <a href="/ps/2312.17601" title="Download PostScript">ps</a>, <a href="/format/2312.17601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Tyranny of Possibilities in the Design of Task-Oriented LLM Systems:  A Scoping Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhamani%2C+D">Dhruv Dhamani</a>, 
<a href="/search/cs?searchtype=author&query=Maher%2C+M+L">Mary Lou Maher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures. Work-in-progress draft published to gather feedback. Please reach out with comments, if any
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This scoping survey focuses on our current understanding of the design space
for task-oriented LLM systems and elaborates on definitions and relationships
among the available design parameters. The paper begins by defining a minimal
task-oriented LLM system and exploring the design space of such systems through
a thought experiment contemplating the performance of diverse LLM system
configurations (involving single LLMs, single LLM-based agents, and multiple
LLM-based agent systems) on a complex software development task and
hypothesizes the results. We discuss a pattern in our results and formulate
them into three conjectures. While these conjectures may be partly based on
faulty assumptions, they provide a starting point for future research. The
paper then surveys a select few design parameters: covering and organizing
research in LLM augmentation, prompting techniques, and uncertainty estimation,
and discussing their significance. The paper notes the lack of focus on
computational and energy efficiency in evaluating research in these areas. Our
survey findings provide a basis for developing the concept of linear and
non-linear contexts, which we define and use to enable an agent-centric
projection of prompting techniques providing a lens through which prompting
techniques can be viewed as multi-agent systems. The paper discusses the
implications of this lens, for the cross-pollination of research between LLM
prompting and LLM-based multi-agent systems; and also, for the generation of
synthetic training data based on existing prompting techniques in research. In
all, the scoping survey presents seven conjectures that can help guide future
research efforts.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17605" title="Abstract">arXiv:2312.17605</a> [<a href="/pdf/2312.17605" title="Download PDF">pdf</a>, <a href="/format/2312.17605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Task and Motion Planning using Object-centric Abstractions of  Motion Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agostini%2C+A">Alejandro Agostini</a>, 
<a href="/search/cs?searchtype=author&query=Piater%2C+J">Justus Piater</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In task and motion planning (TAMP), the ambiguity and underdetermination of
abstract descriptions used by task planning methods make it difficult to
characterize physical constraints needed to successfully execute a task. The
usual approach is to overlook such constraints at task planning level and to
implement expensive sub-symbolic geometric reasoning techniques that perform
multiple calls on unfeasible actions, plan corrections, and re-planning until a
feasible solution is found. We propose an alternative TAMP approach that
unifies task and motion planning into a single heuristic search. Our approach
is based on an object-centric abstraction of motion constraints that permits
leveraging the computational efficiency of off-the-shelf AI heuristic search to
yield physically feasible plans. These plans can be directly transformed into
object and motion parameters for task execution without the need of intensive
sub-symbolic geometric reasoning.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17606" title="Abstract">arXiv:2312.17606</a> [<a href="/pdf/2312.17606" title="Download PDF">pdf</a>, <a href="/format/2312.17606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Control Strategy for Quadruped Robots in Actuator Degradation  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Wentao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+H">Hang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 14 figures, in proceeding of DAI'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quadruped robots have strong adaptability to extreme environments but may
also experience faults. Once these faults occur, robots must be repaired before
returning to the task, reducing their practical feasibility. One prevalent
concern among these faults is actuator degradation, stemming from factors like
device aging or unexpected operational events. Traditionally, addressing this
problem has relied heavily on intricate fault-tolerant design, which demands
deep domain expertise from developers and lacks generalizability.
Learning-based approaches offer effective ways to mitigate these limitations,
but a research gap exists in effectively deploying such methods on real-world
quadruped robots. This paper introduces a pioneering teacher-student framework
rooted in reinforcement learning, named Actuator Degradation Adaptation
Transformer (ADAPT), aimed at addressing this research gap. This framework
produces a unified control strategy, enabling the robot to sustain its
locomotion and perform tasks despite sudden joint actuator faults, relying
exclusively on its internal sensors. Empirical evaluations on the Unitree A1
platform validate the deployability and effectiveness of Adapt on real-world
quadruped robots, and affirm the robustness and practicality of our approach.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17611" title="Abstract">arXiv:2312.17611</a> [<a href="/pdf/2312.17611" title="Download PDF">pdf</a>, <a href="/format/2312.17611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P2M2-Net: Part-Aware Prompt-Guided Multimodal Point Cloud Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Linlian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tieru Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Rui Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Best Poster Award of CAD/Graphics 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Inferring missing regions from severely occluded point clouds is highly
challenging. Especially for 3D shapes with rich geometry and structure details,
inherent ambiguities of the unknown parts are existing. Existing approaches
either learn a one-to-one mapping in a supervised manner or train a generative
model to synthesize the missing points for the completion of 3D point cloud
shapes. These methods, however, lack the controllability for the completion
process and the results are either deterministic or exhibiting uncontrolled
diversity. Inspired by the prompt-driven data generation and editing, we
propose a novel prompt-guided point cloud completion framework, coined
P2M2-Net, to enable more controllable and more diverse shape completion. Given
an input partial point cloud and a text prompt describing the part-aware
information such as semantics and structure of the missing region, our
Transformer-based completion network can efficiently fuse the multimodal
features and generate diverse results following the prompt guidance. We train
the P2M2-Net on a new large-scale PartNet-Prompt dataset and conduct extensive
experiments on two challenging shape completion benchmarks. Quantitative and
qualitative results show the efficacy of incorporating prompts for more
controllable part-aware point cloud completion and generation. Code and data
are available at https://github.com/JLU-ICL/P2M2-Net.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17612" title="Abstract">arXiv:2312.17612</a> [<a href="/pdf/2312.17612" title="Download PDF">pdf</a>, <a href="/format/2312.17612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bespoke Approximation of Multiplication-Accumulation and Activation  Targeting Printed Multilayer Perceptrons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afentaki%2C+F">Florentia Afentaki</a>, 
<a href="/search/cs?searchtype=author&query=Saglam%2C+G">Gurol Saglam</a>, 
<a href="/search/cs?searchtype=author&query=Kokkinis%2C+A">Argyris Kokkinis</a>, 
<a href="/search/cs?searchtype=author&query=Siozios%2C+K">Kostas Siozios</a>, 
<a href="/search/cs?searchtype=author&query=Zervakis%2C+G">Georgios Zervakis</a>, 
<a href="/search/cs?searchtype=author&query=Tahoori%2C+M+B">Mehdi B Tahoori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the IEEE/ACM International Conference on Computer Aided Design (ICCAD) 2023, San Francisco, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Printed Electronics (PE) feature distinct and remarkable characteristics that
make them a prominent technology for achieving true ubiquitous computing. This
is particularly relevant in application domains that require conformal and
ultra-low cost solutions, which have experienced limited penetration of
computing until now. Unlike silicon-based technologies, PE offer unparalleled
features such as non-recurring engineering costs, ultra-low manufacturing cost,
and on-demand fabrication of conformal, flexible, non-toxic, and stretchable
hardware. However, PE face certain limitations due to their large feature
sizes, that impede the realization of complex circuits, such as machine
learning classifiers. In this work, we address these limitations by leveraging
the principles of Approximate Computing and Bespoke (fully-customized) design.
We propose an automated framework for designing ultra-low power Multilayer
Perceptron (MLP) classifiers which employs, for the first time, a holistic
approach to approximate all functions of the MLP's neurons: multiplication,
accumulation, and activation. Through comprehensive evaluation across various
MLPs of varying size, our framework demonstrates the ability to enable
battery-powered operation of even the most intricate MLP architecture examined,
significantly surpassing the current state of the art.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17615" title="Abstract">arXiv:2312.17615</a> [<a href="/pdf/2312.17615" title="Download PDF">pdf</a>, <a href="/format/2312.17615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Shot Multi-Rate Pruning of Graph Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahbi%2C+H">Hichem Sahbi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2212.09415">arXiv:2212.09415</a>, <a href="/abs/2305.19343">arXiv:2305.19343</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we devise a novel lightweight Graph Convolutional Network
(GCN) design dubbed as Multi-Rate Magnitude Pruning (MRMP) that jointly trains
network topology and weights. Our method is variational and proceeds by
aligning the weight distribution of the learned networks with an a priori
distribution. In the one hand, this allows implementing any fixed pruning rate,
and also enhancing the generalization performances of the designed lightweight
GCNs. In the other hand, MRMP achieves a joint training of multiple GCNs, on
top of shared weights, in order to extrapolate accurate networks at any
targeted pruning rate without retraining their weights. Extensive experiments
conducted on the challenging task of skeleton-based recognition show a
substantial gain of our lightweight GCNs particularly at very high pruning
regimes.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17617" title="Abstract">arXiv:2312.17617</a> [<a href="/pdf/2312.17617" title="Download PDF">pdf</a>, <a href="/format/2312.17617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Generative Information Extraction: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Derong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wenjun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Information extraction (IE) aims to extract structural knowledge (such as
entities, relations, and events) from plain natural language texts. Recently,
generative Large Language Models (LLMs) have demonstrated remarkable
capabilities in text understanding and generation, allowing for generalization
across various domains and tasks. As a result, numerous works have been
proposed to harness abilities of LLMs and offer viable solutions for IE tasks
based on a generative paradigm. To conduct a comprehensive systematic review
and exploration of LLM efforts for IE tasks, in this study, we survey the most
recent advancements in this field. We first present an extensive overview by
categorizing these works in terms of various IE subtasks and learning
paradigms, then we empirically analyze the most advanced methods and discover
the emerging trend of IE tasks with LLMs. Based on thorough review conducted,
we identify several insights in technique and promising research directions
that deserve further exploration in future studies. We maintain a public
repository and consistently update related resources at:
\url{https://github.com/quqxui/Awesome-LLM4IE-Papers}.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17624" title="Abstract">arXiv:2312.17624</a> [<a href="/pdf/2312.17624" title="Download PDF">pdf</a>, <a href="/format/2312.17624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XAI for In-hospital Mortality Prediction via Multimodal ICU Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingqiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yancheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+F">Fengxiang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17625" title="Abstract">arXiv:2312.17625</a> [<a href="/pdf/2312.17625" title="Download PDF">pdf</a>, <a href="/format/2312.17625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic $((1+&#x3b5;)\ln n)$-Approximation Algorithms for Minimum Set  Cover and Dominating Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solomon%2C+S">Shay Solomon</a>, 
<a href="/search/cs?searchtype=author&query=Uzrad%2C+A">Amitai Uzrad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract truncated to fit arXiv limits; full version of a STOC'23 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The minimum set cover (MSC) problem admits two classic algorithms: a greedy
$\ln n$-approximation and a primal-dual $f$-approximation, where $n$ is the
universe size and $f$ is the maximum frequency of an element. Both algorithms
are simple and efficient, and remarkably -- one cannot improve these
approximations under hardness results by more than a factor of $(1+\epsilon)$,
for any constant $\epsilon &gt; 0$.
<br />In their pioneering work, Gupta et al. [STOC'17] showed that the greedy
algorithm can be dynamized to achieve $O(\log n)$-approximation with update
time $O(f \log n)$. Building on this result, Hjuler et al. [STACS'18] dynamized
the greedy minimum dominating set (MDS) algorithm, achieving a similar
approximation with update time $O(\Delta \log n)$ (the analog of $O(f \log
n)$), albeit for unweighted instances. The approximations of both algorithms,
which are the state-of-the-art, exceed the static $\ln n$-approximation by a
rather large constant factor. In sharp contrast, the current best dynamic
primal-dual MSC algorithms achieve fast update times together with an
approximation that exceeds the static $f$-approximation by a factor of (at
most) $1+\epsilon$, for any $\epsilon &gt; 0$.
<br />This paper aims to bridge the gap between the best approximation factor of
the dynamic greedy MSC and MDS algorithms and the static $\ln n$ bound. We
present dynamic algorithms for weighted greedy MSC and MDS with approximation
$(1+\epsilon)\ln n$ for any $\epsilon &gt; 0$, while achieving the same update
time (ignoring dependencies on $\epsilon$) of the best previous algorithms
(with approximation significantly larger than $\ln n$). Moreover, [...]
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17626" title="Abstract">arXiv:2312.17626</a> [<a href="/pdf/2312.17626" title="Download PDF">pdf</a>, <a href="/ps/2312.17626" title="Download PostScript">ps</a>, <a href="/format/2312.17626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Fixed Parameter Tractable Algorithms for Counting Markov  Equivalence Classes with Special Skeletons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V+S">Vidya Sagar Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The structure of Markov equivalence classes (MECs) of causal DAGs has been
studied extensively. A natural question in this regard is to algorithmically
find the number of MECs with a given skeleton. Until recently, the known
results for this problem were in the setting of very special graphs (such as
paths, cycles, and star graphs). More recently, a fixed-parameter tractable
(FPT) algorithm was given for this problem which, given an input graph $G$,
counts the number of MECs with the skeleton $G$ in $O(n(2^{O(d^4k^4)} + n^2))$
time, where $n$, $d$, and $k$, respectively, are the numbers of nodes, the
degree, and the treewidth of $G$.
<br />We give a faster FPT algorithm that solves the problem in $O(n(2^{O(d^2k^2)}
+ n^2))$ time when the input graph is chordal. Additionally, we show that the
runtime can be further improved to polynomial time when the input graph $G$ is
a tree.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17633" title="Abstract">arXiv:2312.17633</a> [<a href="/pdf/2312.17633" title="Download PDF">pdf</a>, <a href="/ps/2312.17633" title="Download PostScript">ps</a>, <a href="/format/2312.17633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Arrow of Time in Music -- Revisiting the Temporal Structure of Music  with Distinguishability and Unique Orientability as the Anchor Point
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qi Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Driven by the term "the arrow of time" as a general topic, the article
develops a musical discussion by referring to the etymological origin of the
term: philosophy (epistemology) and physics (thermodynamics). In particular,
the article explores two specific conditions: distinguishability and unique
orientability, from which the article derives respective musical propositions
and case studies. For the distinguishability condition, the article focuses on
the "recurrence" in music and tries to interpret Bach's Christmas Oratorio from
the perspective of "birth/resurrection". For the unique orientability
condition, the article discusses the process of delaying the climax, thereby
proposing "AB-AAB left-replication" model, implying an organicist view by
treating the temporal structure of music (e.g. form) as the product of a
dynamic process: organic growth.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17634" title="Abstract">arXiv:2312.17634</a> [<a href="/pdf/2312.17634" title="Download PDF">pdf</a>, <a href="/format/2312.17634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing Flying Explorer for Autonomous Digital Modelling in Wild  Unknowns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+N+Z+Y">Naizhong Zhang. Yaoqiang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yangwen Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Peiqi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kewei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hanwen Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work presents an innovative solution for robotic odometry, path planning
and exploration in wild unknown environments, focusing on digital modelling.
The approach uses a minimum cost formulation with pseudo-randomly generated
objectives, integrating multi-path planning and evaluation, with emphasis on
full coverage of unknown maps based on feasible boundaries of interest. The
evaluation carried out on a robotic platform with a lightweight 3D LiDAR sensor
model, assesses the consistency and efficiency in exploring completely unknown
subterranean-like areas. The algorithm allows for dynamic changes to the
desired target and behaviour. At the same time, the paper details the design of
AREX, highlighting its robust localisation, mapping and efficient exploration
target selection capabilities, with a focus on continuity in exploration
direction for increased efficiency and reduced odometry errors. The real-time,
high-precision environmental perception module is identified as critical for
accurate obstacle avoidance and exploration boundary identification.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17640" title="Abstract">arXiv:2312.17640</a> [<a href="/pdf/2312.17640" title="Download PDF">pdf</a>, <a href="/format/2312.17640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision-focused predictions via pessimistic bilevel optimization: a  computational study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bucarey%2C+V">V&#xed;ctor Bucarey</a>, 
<a href="/search/cs?searchtype=author&query=Calder%C3%B3n%2C+S">Sophia Calder&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz%2C+G">Gonzalo Mu&#xf1;oz</a>, 
<a href="/search/cs?searchtype=author&query=Semet%2C+F">Frederic Semet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Dealing with uncertainty in optimization parameters is an important and
longstanding challenge. Typically, uncertain parameters are predicted
accurately, and then a deterministic optimization problem is solved. However,
the decisions produced by this so-called \emph{predict-then-optimize} procedure
can be highly sensitive to uncertain parameters. In this work, we contribute to
recent efforts in producing \emph{decision-focused} predictions, i.e., to build
predictive models that are constructed with the goal of minimizing a
\emph{regret} measure on the decisions taken with them. We formulate the exact
expected regret minimization as a pessimistic bilevel optimization model. Then,
using duality arguments, we reformulate it as a non-convex quadratic
optimization problem. Finally, we show various computational techniques to
achieve tractability. We report extensive computational results on
shortest-path instances with uncertain cost vectors. Our results indicate that
our approach can improve training performance over the approach of Elmachtoub
and Grigas (2022), a state-of-the-art method for decision-focused learning.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17641" title="Abstract">arXiv:2312.17641</a> [<a href="/pdf/2312.17641" title="Download PDF">pdf</a>, <a href="/format/2312.17641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoD2T:Model-Data-Driven Motion-Static Object Tracking Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+W">Wu Di</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liu Bo</a>, 
<a href="/search/cs?searchtype=author&query=Xingle%2C+Z">Zhang Xingle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The domain of Multi-Object Tracking (MOT) is of paramount significance within
the realm of video analysis. However, both traditional methodologies and deep
learning-based approaches within this domain exhibit inherent limitations. Deep
learning methods driven exclusively by data exhibit challenges in accurately
discerning the motion states of objects, while traditional methods relying on
comprehensive mathematical models may suffer from suboptimal tracking
precision. To address these challenges, we introduce the Model-Data-Driven
Motion-Static Object Tracking Method (MoD2T). We propose a novel architecture
that adeptly amalgamates traditional mathematical modeling with deep
learning-based MOT frameworks, thereby effectively mitigating the limitations
associated with sole reliance on established methodologies or advanced deep
learning techniques. MoD2T's fusion of mathematical modeling and deep learning
augments the precision of object motion determination, consequently enhancing
tracking accuracy. Our empirical experiments robustly substantiate MoD2T's
efficacy across a diverse array of scenarios, including UAV aerial surveillance
and street-level tracking. To assess MoD2T's proficiency in discerning object
motion states, we introduce MVF1 metric. This novel performance metric is
designed to measure the accuracy of motion state classification, providing a
comprehensive evaluation of MoD2T's performance. Meticulous experiments
substantiate the rationale behind MVF1's formulation. To provide a
comprehensive assessment of MoD2T's performance, we meticulously annotate
diverse datasets and subject MoD2T to rigorous testing. The achieved MVF1
scores, which measure the accuracy of motion state classification, are
particularly noteworthy in scenarios marked by minimal or mild camera motion,
with values of 0.774 on the KITTI dataset, 0.521 on MOT17, and 0.827 on UAVDT.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17642" title="Abstract">arXiv:2312.17642</a> [<a href="/pdf/2312.17642" title="Download PDF">pdf</a>, <a href="/ps/2312.17642" title="Download PostScript">ps</a>, <a href="/format/2312.17642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research on the Laws of Multimodal Perception and Cognition from a  Cross-cultural Perspective -- Taking Overseas Chinese Gardens as an Example
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xueqi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuhan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sirui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yijun Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 figures,1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This study aims to explore the complex relationship between perceptual and
cognitive interactions in multimodal data analysis,with a specific emphasis on
spatial experience design in overseas Chinese gardens. It is found that
evaluation content and images on social media can reflect individuals' concerns
and sentiment responses, providing a rich data base for cognitive research that
contains both sentimental and image-based cognitive information. Leveraging
deep learning techniques, we analyze textual and visual data from social media,
thereby unveiling the relationship between people's perceptions and sentiment
cognition within the context of overseas Chinese gardens. In addition, our
study introduces a multi-agent system (MAS)alongside AI agents. Each agent
explores the laws of aesthetic cognition through chat scene simulation combined
with web search. This study goes beyond the traditional approach of translating
perceptions into sentiment scores, allowing for an extension of the research
methodology in terms of directly analyzing texts and digging deeper into
opinion data. This study provides new perspectives for understanding aesthetic
experience and its impact on architecture and landscape design across diverse
cultural contexts, which is an essential contribution to the field of cultural
communication and aesthetic understanding.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17643" title="Abstract">arXiv:2312.17643</a> [<a href="/pdf/2312.17643" title="Download PDF">pdf</a>, <a href="/format/2312.17643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> b-it-bots RoboCup@Work Team Description Paper 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+K">Kevin Patel</a>, 
<a href="/search/cs?searchtype=author&query=Kalagaturu%2C+V">Vamsi Kalagaturu</a>, 
<a href="/search/cs?searchtype=author&query=Mannava%2C+V">Vivek Mannava</a>, 
<a href="/search/cs?searchtype=author&query=Selvaraju%2C+R">Ravisankar Selvaraju</a>, 
<a href="/search/cs?searchtype=author&query=Shinde%2C+S">Shubham Shinde</a>, 
<a href="/search/cs?searchtype=author&query=Bakaraniya%2C+D">Dharmin Bakaraniya</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+D">Deebul Nair</a>, 
<a href="/search/cs?searchtype=author&query=Wasil%2C+M">Mohammad Wasil</a>, 
<a href="/search/cs?searchtype=author&query=Thoduka%2C+S">Santosh Thoduka</a>, 
<a href="/search/cs?searchtype=author&query=Awaad%2C+I">Iman Awaad</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+S">Sven Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Hochgeschwender%2C+N">Nico Hochgeschwender</a>, 
<a href="/search/cs?searchtype=author&query=Pl%C3%B6ger%2C+P+G">Paul G. Pl&#xf6;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents the b-it-bots RoboCup@Work team and its current hardware
and functional architecture for the KUKA youBot robot. We describe the
underlying software framework and the developed capabilities required for
operating in industrial environments including features such as reliable and
precise navigation, flexible manipulation, robust object recognition and task
planning. New developments include an approach to grasp vertical objects,
placement of objects by considering the empty space on a workstation, and the
process of porting our code to ROS2.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17648" title="Abstract">arXiv:2312.17648</a> [<a href="/pdf/2312.17648" title="Download PDF">pdf</a>, <a href="/format/2312.17648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Modality Gap for Visual Grounding with Effecitve Cross-modal  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenhui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xueyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Beihu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuting Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">YingYing Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Visual grounding aims to align visual information of specific regions of
images with corresponding natural language expressions. Current visual
grounding methods leverage pre-trained visual and language backbones separately
to obtain visual features and linguistic features. Although these two types of
features are then fused via delicately designed networks, the heterogeneity of
the features makes them inapplicable for multi-modal reasoning. This problem
arises from the domain gap between the single-modal pre-training backbone used
in current visual grounding methods, which can hardly be overcome by the
traditional end-to-end training method. To alleviate this, our work proposes an
Empowering pre-trained model for Visual Grounding (EpmVG) framework, which
distills a multimodal pre-trained model to guide the visual grounding task.
EpmVG is based on a novel cross-modal distillation mechanism, which can
effectively introduce the consistency information of images and texts in the
pre-trained model, to reduce the domain gap existing in the backbone networks,
thereby improving the performance of the model in the visual grounding task.
Extensive experiments are carried out on five conventionally used datasets, and
results demonstrate that our method achieves better performance than
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17649" title="Abstract">arXiv:2312.17649</a> [<a href="/pdf/2312.17649" title="Download PDF">pdf</a>, <a href="/format/2312.17649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Effects of Sparse Attention on Cross-Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlatt%2C+F">Ferdinand Schlatt</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%B6be%2C+M">Maik Fr&#xf6;be</a>, 
<a href="/search/cs?searchtype=author&query=Hagen%2C+M">Matthias Hagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ECIR'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Cross-encoders are effective passage and document re-rankers but less
efficient than other neural or classic retrieval models. A few previous studies
have applied windowed self-attention to make cross-encoders more efficient.
However, these studies did not investigate the potential and limits of
different attention patterns or window sizes. We close this gap and
systematically analyze how token interactions can be reduced without harming
the re-ranking effectiveness. Experimenting with asymmetric attention and
different window sizes, we find that the query tokens do not need to attend to
the passage or document tokens for effective re-ranking and that very small
window sizes suffice. In our experiments, even windows of 4 tokens still yield
effectiveness on par with previous cross-encoders while reducing the memory
requirements to at most 78% / 41% and being 1% / 43% faster at inference time
for passages / documents.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17650" title="Abstract">arXiv:2312.17650</a> [<a href="/pdf/2312.17650" title="Download PDF">pdf</a>, <a href="/format/2312.17650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grasping, Part Identification, and Pose Refinement in One Shot with a  Tactile Gripper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+J+X">Joyce Xin-Yan Lim</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quang-Cuong Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The rise in additive manufacturing comes with unique opportunities and
challenges. Rapid changes to part design and massive part customization
distinctive to 3D-Print (3DP) can be easily achieved. Customized parts that are
unique, yet exhibit similar features such as dental moulds, shoe insoles, or
engine vanes could be industrially manufactured with 3DP. However, the
opportunity for massive part customization comes with unique challenges for the
existing production paradigm of robotics applications, as the current robotics
paradigm for part identification and pose refinement is repetitive, where
data-driven and object-dependent approaches are often used. Thus, a bottleneck
exists in robotics applications for 3DP parts where massive customization is
involved, as it is difficult for feature-based deep learning approaches to
distinguish between similar parts such as shoe insoles belonging to different
people. As such, we propose a method that augments patterns on 3DP parts so
that grasping, part identification, and pose refinement can be executed in one
shot with a tactile gripper. We also experimentally evaluate our approach from
three perspectives, including real insertion tasks that mimic robotic sorting
and packing, and achieved excellent classification results, a high insertion
success rate of 95%, and a sub-millimeter pose refinement accuracy.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17653" title="Abstract">arXiv:2312.17653</a> [<a href="/pdf/2312.17653" title="Download PDF">pdf</a>, <a href="/format/2312.17653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LARP: Language-Agent Role Play for Open-World Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhilan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Ji Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Language agents have shown impressive problem-solving skills within defined
settings and brief timelines. Yet, with the ever-evolving complexities of
open-world simulations, there's a pressing need for agents that can flexibly
adapt to complex environments and consistently maintain a long-term memory to
ensure coherent actions. To bridge the gap between language agents and
open-world games, we introduce Language Agent for Role-Playing (LARP), which
includes a cognitive architecture that encompasses memory processing and a
decision-making assistant, an environment interaction module with a
feedback-driven learnable action space, and a postprocessing method that
promotes the alignment of various personalities. The LARP framework refines
interactions between users and agents, predefined with unique backgrounds and
personalities, ultimately enhancing the gaming experience in open-world
contexts. Furthermore, it highlights the diverse uses of language models in a
range of areas such as entertainment, education, and various simulation
scenarios. The project page is released at https://miao-ai-lab.github.io/LARP/.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17655" title="Abstract">arXiv:2312.17655</a> [<a href="/pdf/2312.17655" title="Download PDF">pdf</a>, <a href="/format/2312.17655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Point Cloud Forecasting enables Scalable Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zetong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In contrast to extensive studies on general vision, pre-training for scalable
visual autonomous driving remains seldom explored. Visual autonomous driving
applications require features encompassing semantics, 3D geometry, and temporal
information simultaneously for joint perception, prediction, and planning,
posing dramatic challenges for pre-training. To resolve this, we bring up a new
pre-training task termed as visual point cloud forecasting - predicting future
point clouds from historical visual input. The key merit of this task captures
the synergic learning of semantics, 3D structures, and temporal dynamics. Hence
it shows superiority in various downstream tasks. To cope with this new
problem, we present ViDAR, a general model to pre-train downstream visual
encoders. It first extracts historical embeddings by the encoder. These
representations are then transformed to 3D geometric space via a novel Latent
Rendering operator for future point cloud prediction. Experiments show
significant gain in downstream tasks, e.g., 3.1% NDS on 3D detection, ~10%
error reduction on motion forecasting, and ~15% less collision rate on
planning.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17659" title="Abstract">arXiv:2312.17659</a> [<a href="/pdf/2312.17659" title="Download PDF">pdf</a>, <a href="/format/2312.17659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solar Radiation Prediction in the UTEQ based on Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Troncoso%2C+J+A">Jordy Anchundia Troncoso</a>, 
<a href="/search/cs?searchtype=author&query=Quijije%2C+%C3%81+T">&#xc1;ngel Torres Quijije</a>, 
<a href="/search/cs?searchtype=author&query=Oviedo%2C+B">Byron Oviedo</a>, 
<a href="/search/cs?searchtype=author&query=Zambrano-Vega%2C+C">Cristian Zambrano-Vega</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This research explores the effectiveness of various Machine Learning (ML)
models used to predicting solar radiation at the Central Campus of the State
Technical University of Quevedo (UTEQ). The data was obtained from a
pyranometer, strategically located in a high area of the campus. This
instrument continuously recorded solar irradiance data since 2020, offering a
comprehensive dataset encompassing various weather conditions and temporal
variations. After a correlation analysis, temperature and the time of day were
identified as the relevant meteorological variables that influenced the solar
irradiance. Different machine learning algorithms such as Linear Regression,
K-Nearest Neighbors, Decision Tree, and Gradient Boosting were compared using
the evaluation metrics Mean Squared Error (MSE), Root Mean Squared Error
(RMSE), Mean Absolute Error (MAE), and the Coefficient of Determination
($R^2$). The study revealed that Gradient Boosting Regressor exhibited superior
performance, closely followed by the Random Forest Regressor. These models
effectively captured the non-linear patterns in solar radiation, as evidenced
by their low MSE and high $R^2$ values. With the aim of assess the performance
of our ML models, we developed a web-based tool for the Solar Radiation
Forecasting in the UTEQ available at
<a href="http://https://solarradiationforecastinguteq.streamlit.app/.">this http URL</a> The results
obtained demonstrate the effectiveness of our ML models in solar radiation
prediction and contribute a practical utility in real-time solar radiation
forecasting, aiding in efficient solar energy management.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17660" title="Abstract">arXiv:2312.17660</a> [<a href="/pdf/2312.17660" title="Download PDF">pdf</a>, <a href="/format/2312.17660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normalization of Lithuanian Text Using Regular Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasparaitis%2C+P">Pijus Kasparaitis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Text Normalization is an integral part of any text-to-speech synthesis
system. In a natural language text, there are elements such as numbers, dates,
abbreviations, etc. that belong to other semiotic classes. They are called
non-standard words (NSW) and need to be expanded into ordinary words. For this
purpose, it is necessary to identify the semiotic class of each NSW. The
taxonomy of semiotic classes adapted to the Lithuanian language is presented in
the work. Sets of rules are created for detecting and expanding NSWs based on
regular expressions. Experiments with three completely different data sets were
performed and the accuracy was assessed. Causes of errors are explained and
recommendations are given for the development of text normalization rules.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17661" title="Abstract">arXiv:2312.17661</a> [<a href="/pdf/2312.17661" title="Download PDF">pdf</a>, <a href="/format/2312.17661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Data and results are available at: <a href="https://github.com/EternityYW/Gemini-Commonsense-Evaluation/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The burgeoning interest in Multimodal Large Language Models (MLLMs), such as
OpenAI's GPT-4V(ision), has significantly impacted both academic and industrial
realms. These models enhance Large Language Models (LLMs) with advanced visual
understanding capabilities, facilitating their application in a variety of
multimodal tasks. Recently, Google introduced Gemini, a cutting-edge MLLM
designed specifically for multimodal integration. Despite its advancements,
preliminary benchmarks indicate that Gemini lags behind GPT models in
commonsense reasoning tasks. However, this assessment, based on a limited
dataset (i.e., HellaSWAG), does not fully capture Gemini's authentic
commonsense reasoning potential. To address this gap, our study undertakes a
thorough evaluation of Gemini's performance in complex reasoning tasks that
necessitate the integration of commonsense knowledge across modalities. We
carry out a comprehensive analysis of 12 commonsense reasoning datasets,
ranging from general to domain-specific tasks. This includes 11 datasets
focused solely on language, as well as one that incorporates multimodal
elements. Our experiments across four LLMs and two MLLMs demonstrate Gemini's
competitive commonsense reasoning capabilities. Additionally, we identify
common challenges faced by current LLMs and MLLMs in addressing commonsense
problems, underscoring the need for further advancements in enhancing the
commonsense reasoning abilities of these models.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17663" title="Abstract">arXiv:2312.17663</a> [<a href="/pdf/2312.17663" title="Download PDF">pdf</a>, <a href="/format/2312.17663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape-IoU: More Accurate Metric considering Bounding Box Shape and Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuaijie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As an important component of the detector localization branch, bounding box
regression loss plays a significant role in object detection tasks. The
existing bounding box regression methods usually consider the geometric
relationship between the GT box and the predicted box, and calculate the loss
by using the relative position and shape of the bounding boxes, while ignoring
the influence of inherent properties such as the shape and scale of the
bounding boxes on bounding box regression. In order to make up for the
shortcomings of existing research, this article proposes a bounding box
regression method that focuses on the shape and scale of the bounding box
itself. Firstly, we analyzed the regression characteristics of the bounding
boxes and found that the shape and scale factors of the bounding boxes
themselves will have an impact on the regression results. Based on the above
conclusions, we propose the Shape IoU method, which can calculate the loss by
focusing on the shape and scale of the bounding box itself, thereby making the
bounding box regression more accurate. Finally, we validated our method through
a large number of comparative experiments, which showed that our method can
effectively improve detection performance and outperform existing methods,
achieving state-of-the-art performance in different detection tasks.Code is
available at https://github.com/malagoutou/Shape-IoU
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17664" title="Abstract">arXiv:2312.17664</a> [<a href="/pdf/2312.17664" title="Download PDF">pdf</a>, <a href="/ps/2312.17664" title="Download PostScript">ps</a>, <a href="/format/2312.17664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast interpolation of sparse multivariate polynomials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Hoeven%2C+J">Joris van der Hoeven</a>, 
<a href="/search/cs?searchtype=author&query=Lecerf%2C+G">Gr&#xe9;goire Lecerf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Commutative Algebra (math.AC)

</div>
<p class="mathjax">Consider a sparse multivariate polynomial f with integer coefficients. Assume
that f is represented as a "modular black box polynomial", e.g. via an
algorithm to evaluate f at arbitrary integer points, modulo arbitrary positive
integers. The problem of sparse interpolation is to recover f in its usual
sparse representation, as a sum of coefficients times monomials. For the first
time we present a quasi-optimal algorithm for this task.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17666" title="Abstract">arXiv:2312.17666</a> [<a href="/pdf/2312.17666" title="Download PDF">pdf</a>, <a href="/format/2312.17666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Strategization and Trustworthy Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cen%2C+S+H">Sarah H. Cen</a>, 
<a href="/search/cs?searchtype=author&query=Ilyas%2C+A">Andrew Ilyas</a>, 
<a href="/search/cs?searchtype=author&query=Madry%2C+A">Aleksander Madry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Many human-facing algorithms -- including those that power recommender
systems or hiring decision tools -- are trained on data provided by their
users. The developers of these algorithms commonly adopt the assumption that
the data generating process is exogenous: that is, how a user reacts to a given
prompt (e.g., a recommendation or hiring suggestion) depends on the prompt and
not on the algorithm that generated it. For example, the assumption that a
person's behavior follows a ground-truth distribution is an exogeneity
assumption. In practice, when algorithms interact with humans, this assumption
rarely holds because users can be strategic. Recent studies document, for
example, TikTok users changing their scrolling behavior after learning that
TikTok uses it to curate their feed, and Uber drivers changing how they accept
and cancel rides in response to changes in Uber's algorithm.
<br />Our work studies the implications of this strategic behavior by modeling the
interactions between a user and their data-driven platform as a repeated,
two-player game. We first find that user strategization can actually help
platforms in the short term. We then show that it corrupts platforms' data and
ultimately hurts their ability to make counterfactual decisions. We connect
this phenomenon to user trust, and show that designing trustworthy algorithms
can go hand in hand with accurate estimation. Finally, we provide a
formalization of trustworthiness that inspires potential interventions.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17667" title="Abstract">arXiv:2312.17667</a> [<a href="/pdf/2312.17667" title="Download PDF">pdf</a>, <a href="/ps/2312.17667" title="Download PostScript">ps</a>, <a href="/format/2312.17667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIJack: Security and Privacy Risk Simulator for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+H">Hideaki Takahashi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper introduces AIJack, an open-source library designed to assess
security and privacy risks associated with the training and deployment of
machine learning models. Amid the growing interest in big data and AI,
advancements in machine learning research and business are accelerating.
However, recent studies reveal potential threats, such as the theft of training
data and the manipulation of models by malicious attackers. Therefore, a
comprehensive understanding of machine learning's security and privacy
vulnerabilities is crucial for the safe integration of machine learning into
real-world products. AIJack aims to address this need by providing a library
with various attack and defense methods through a unified API. The library is
publicly available on GitHub (https://github.com/Koukyosyumei/AIJack).
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17668" title="Abstract">arXiv:2312.17668</a> [<a href="/pdf/2312.17668" title="Download PDF">pdf</a>, <a href="/format/2312.17668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vocalics in Human-Drone Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lieser%2C+M">Marc Lieser</a>, 
<a href="/search/cs?searchtype=author&query=Schwanecke%2C+U">Ulrich Schwanecke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">As the presence of flying robots continues to grow in both commercial and
private sectors, it necessitates an understanding of appropriate methods for
nonverbal interaction with humans. While visual cues, such as gestures
incorporated into trajectories, are more apparent and thoroughly researched,
acoustic cues have remained unexplored, despite their potential to enhance
human-drone interaction. Given that additional audiovisual and sensory
equipment is not always desired or practicable, and flight noise often masks
potential acoustic communication in rotary-wing drones, such as through a
loudspeaker, the rotors themselves offer potential for nonverbal communication.
In this paper, quadrotor trajectories are augmented by acoustic information
that does not visually affect the flight, but adds audible information that
significantly facilitates distinctiveness. A user study (N=192) demonstrates
that sonically augmenting the trajectories of two aerial gestures makes them
more easily distinguishable. This enhancement contributes to human-drone
interaction through onboard means, particularly in situations where the human
cannot see or look at the drone.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17670" title="Abstract">arXiv:2312.17670</a> [<a href="/pdf/2312.17670" title="Download PDF">pdf</a>, <a href="/format/2312.17670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking the CoW with the TopCoW Challenge: Topology-Aware  Anatomical Segmentation of the Circle of Willis for CTA and MRA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Musio%2C+F">Fabio Musio</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yihui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Juchler%2C+N">Norman Juchler</a>, 
<a href="/search/cs?searchtype=author&query=Paetzold%2C+J+C">Johannes C. Paetzold</a>, 
<a href="/search/cs?searchtype=author&query=Al-Maskari%2C+R">Rami Al-Maskari</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6her%2C+L">Luciano H&#xf6;her</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H+B">Hongwei Bran Li</a>, 
<a href="/search/cs?searchtype=author&query=Hamamci%2C+I+E">Ibrahim Ethem Hamamci</a>, 
<a href="/search/cs?searchtype=author&query=Sekuboyina%2C+A">Anjany Sekuboyina</a>, 
<a href="/search/cs?searchtype=author&query=Shit%2C+S">Suprosanna Shit</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Houjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Waldmannstetter%2C+D">Diana Waldmannstetter</a>, 
<a href="/search/cs?searchtype=author&query=Kofler%2C+F">Florian Kofler</a>, 
<a href="/search/cs?searchtype=author&query=Navarro%2C+F">Fernando Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Menten%2C+M">Martin Menten</a>, 
<a href="/search/cs?searchtype=author&query=Ezhov%2C+I">Ivan Ezhov</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Vos%2C+I">Iris Vos</a>, 
<a href="/search/cs?searchtype=author&query=Ruigrok%2C+Y">Ynte Ruigrok</a>, 
<a href="/search/cs?searchtype=author&query=Velthuis%2C+B">Birgitta Velthuis</a>, 
<a href="/search/cs?searchtype=author&query=Kuijf%2C+H">Hugo Kuijf</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4mmerli%2C+J">Julien H&#xe4;mmerli</a>, 
<a href="/search/cs?searchtype=author&query=Wurster%2C+C">Catherine Wurster</a>, 
<a href="/search/cs?searchtype=author&query=Bijlenga%2C+P">Philippe Bijlenga</a>, 
<a href="/search/cs?searchtype=author&query=Westphal%2C+L">Laura Westphal</a>, 
<a href="/search/cs?searchtype=author&query=Bisschop%2C+J">Jeroen Bisschop</a>, 
<a href="/search/cs?searchtype=author&query=Colombo%2C+E">Elisa Colombo</a>, 
<a href="/search/cs?searchtype=author&query=Baazaoui%2C+H">Hakim Baazaoui</a>, 
<a href="/search/cs?searchtype=author&query=Makmur%2C+A">Andrew Makmur</a>, 
<a href="/search/cs?searchtype=author&query=Hallinan%2C+J">James Hallinan</a>, 
<a href="/search/cs?searchtype=author&query=Wiestler%2C+B">Bene Wiestler</a>, 
<a href="/search/cs?searchtype=author&query=Kirschke%2C+J+S">Jan S. Kirschke</a>, 
<a href="/search/cs?searchtype=author&query=Wiest%2C+R">Roland Wiest</a>, 
<a href="/search/cs?searchtype=author&query=Montagnon%2C+E">Emmanuel Montagnon</a>, 
<a href="/search/cs?searchtype=author&query=Letourneau-Guillon%2C+L">Laurent Letourneau-Guillon</a>, 
<a href="/search/cs?searchtype=author&query=Galdran%2C+A">Adrian Galdran</a>, 
<a href="/search/cs?searchtype=author&query=Galati%2C+F">Francesco Galati</a>, 
<a href="/search/cs?searchtype=author&query=Falcetta%2C+D">Daniele Falcetta</a>, 
<a href="/search/cs?searchtype=author&query=Zuluaga%2C+M+A">Maria A. Zuluaga</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chaolong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haoran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zehan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ra%2C+S">Sinyoung Ra</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jongyun Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyunjin Park</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wodzinski%2C+M">Marek Wodzinski</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+H">Henning M&#xfc;ller</a>,  et al. (33 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 11 figures, 9 tables. Summary Paper for the MICCAI TopCoW 2023 Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">The Circle of Willis (CoW) is an important network of arteries connecting
major circulations of the brain. Its vascular architecture is believed to
affect the risk, severity, and clinical outcome of serious neuro-vascular
diseases. However, characterizing the highly variable CoW anatomy is still a
manual and time-consuming expert task. The CoW is usually imaged by two
angiographic imaging modalities, magnetic resonance angiography (MRA) and
computed tomography angiography (CTA), but there exist limited public datasets
with annotations on CoW anatomy, especially for CTA. Therefore we organized the
TopCoW Challenge in 2023 with the release of an annotated CoW dataset and
invited submissions worldwide for the CoW segmentation task, which attracted
over 140 registered participants from four continents. TopCoW dataset was the
first public dataset with voxel-level annotations for CoW's 13 vessel
components, made possible by virtual-reality (VR) technology. It was also the
first dataset with paired MRA and CTA from the same patients. TopCoW challenge
aimed to tackle the CoW characterization problem as a multiclass anatomical
segmentation task with an emphasis on topological metrics. The top performing
teams managed to segment many CoW components to Dice scores around 90%, but
with lower scores for communicating arteries and rare variants. There were also
topological mistakes for predictions with high Dice scores. Additional
topological analysis revealed further areas for improvement in detecting
certain CoW components and matching CoW variant's topology accurately. TopCoW
represented a first attempt at benchmarking the CoW anatomical segmentation
task for MRA and CTA, both morphologically and topologically.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17673" title="Abstract">arXiv:2312.17673</a> [<a href="/pdf/2312.17673" title="Download PDF">pdf</a>, <a href="/format/2312.17673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jatmo: Prompt Injection Defense by Task-Specific Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piet%2C+J">Julien Piet</a>, 
<a href="/search/cs?searchtype=author&query=Alrashed%2C+M">Maha Alrashed</a>, 
<a href="/search/cs?searchtype=author&query=Sitawarin%2C+C">Chawin Sitawarin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zeming Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+E">Elizabeth Sun</a>, 
<a href="/search/cs?searchtype=author&query=Alomair%2C+B">Basel Alomair</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+D">David Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) are attracting significant research attention
due to their instruction-following abilities, allowing users and developers to
leverage LLMs for a variety of tasks. However, LLMs are vulnerable to
prompt-injection attacks: a class of attacks that hijack the model's
instruction-following abilities, changing responses to prompts to undesired,
possibly malicious ones. In this work, we introduce Jatmo, a method for
generating task-specific models resilient to prompt-injection attacks. Jatmo
leverages the fact that LLMs can only follow instructions once they have
undergone instruction tuning. It harnesses a teacher instruction-tuned model to
generate a task-specific dataset, which is then used to fine-tune a base model
(i.e., a non-instruction-tuned model). Jatmo only needs a task prompt and a
dataset of inputs for the task: it uses the teacher model to generate outputs.
For situations with no pre-existing datasets, Jatmo can use a single example,
or in some cases none at all, to produce a fully synthetic dataset. Our
experiments on six tasks show that Jatmo models provide the same quality of
outputs on their specific task as standard LLMs, while being resilient to
prompt injections. The best attacks succeeded in less than 0.5% of cases
against our models, versus over 90% success rate against GPT-3.5-Turbo. We
release Jatmo at https://github.com/wagner-group/prompt-injection-defense.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17674" title="Abstract">arXiv:2312.17674</a> [<a href="/pdf/2312.17674" title="Download PDF">pdf</a>, <a href="/format/2312.17674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QoE-oriented Dependent Task Scheduling under Multi-dimensional QoS  Constraints over Distributed Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xuwei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhipeng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Ning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lianfen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianbin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Task scheduling as an effective strategy can improve application performance
on computing resource-limited devices over distributed networks. However,
existing evaluation mechanisms fail to depict the complexity of diverse
applications, which involve dependencies among tasks, computing resource
requirements, and multi-dimensional quality of service (QoS) constraints.
Furthermore, traditional QoS-oriented task scheduling strategies struggle to
meet the performance requirements without considering differences in
satisfaction and acceptance of application, leading application failures and
resource wastage. To tackle these issues, a quality of experience (QoE) cost
model is designed to evaluate application completion, depicting the
relationship among application satisfaction, communications, and computing
resources in the distributed networks. Specifically, considering the
sensitivity and preference of QoS, we model the different dimensional QoS
degradation cost functions for dependent tasks, which are then integrated into
the QoE cost model. Based on the QoE model, the dependent task scheduling
problem is formulated as the minimization of overall QoE cost, aiming to
improve the application performance in the distributed networks, which is
proven Np-hard. Moreover, a heuristic Hierarchical Multi-queue Task Scheduling
Algorithm (HMTSA) is proposed to address the QoE-oriented task scheduling
problem among multiple dependent tasks, which utilizes hierarchical multiple
queues to determine the optimal task execution order and location according to
different dimensional QoS priorities. Finally, extensive experiments
demonstrate that the proposed algorithm can significantly improve the
satisfaction of applications.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17677" title="Abstract">arXiv:2312.17677</a> [<a href="/pdf/2312.17677" title="Download PDF">pdf</a>, <a href="/format/2312.17677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Fuzzing for Fuzz Driver Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yunlong Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuxuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Writing high-quality fuzz drivers is time-consuming and requires a deep
understanding of the library. However, the performance of the state-of-the-art
automatic fuzz driver generation techniques leaves a lot to be desired. Fuzz
drivers, which are learned from consumer code, can reach deep states but are
restricted to their external inputs. On the other hand, interpretative fuzzing
can explore most APIs but requires numerous attempts in a vast search space. We
propose PromptFuzz, a coverage-guided fuzzer for prompt fuzzing that
iteratively generates fuzz drivers to explore undiscovered library code. To
explore API usage in fuzz drivers during prompt fuzzing, we proposed several
key techniques: instructive program generation, erroneous program sanitization,
coverage-guided prompt mutation, and constrained fuzzer fusion. We implemented
PromptFuzz and evaluated its effectiveness on 14 real-world libraries,
comparing it against OSS-Fuzz and the state-of-the-art fuzz driver generation
solution (i.e., Hopper). The experiment results demonstrate that the fuzz
drivers generated by PromptFuzz achieve higher branch coverage that is 1.61
times greater than that of OSS-Fuzz and 1.67 times greater than that of Hopper.
In addition, the fuzz drivers generated by PromptFuzz successfully detect 33
true bugs out of a total of 44 crashes, which were previously unknown, and 27
of these bugs have been confirmed by the respective communities.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17679" title="Abstract">arXiv:2312.17679</a> [<a href="/pdf/2312.17679" title="Download PDF">pdf</a>, <a href="/format/2312.17679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation for Supervised Graph Outlier Detection with Latent  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kay Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hengrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ziqing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under review. Package available at <a href="https://pypi.org/project/godm/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph outlier detection is a prominent task of research and application in
the realm of graph neural networks. It identifies the outlier nodes that
exhibit deviation from the majority in the graph. One of the fundamental
challenges confronting supervised graph outlier detection algorithms is the
prevalent issue of class imbalance, where the scarcity of outlier instances
compared to normal instances often results in suboptimal performance.
Conventional methods mitigate the imbalance by reweighting instances in the
estimation of the loss function, assigning higher weights to outliers and lower
weights to inliers. Nonetheless, these strategies are prone to overfitting and
underfitting, respectively. Recently, generative models, especially diffusion
models, have demonstrated their efficacy in synthesizing high-fidelity images.
Despite their extraordinary generation quality, their potential in data
augmentation for supervised graph outlier detection remains largely
underexplored.
<br />To bridge this gap, we introduce GODM, a novel data augmentation for
mitigating class imbalance in supervised Graph Outlier detection with latent
Diffusion Models. Specifically, our proposed method consists of three key
components: (1) Variantioanl Encoder maps the heterogeneous information
inherent within the graph data into a unified latent space. (2) Graph Generator
synthesizes graph data that are statistically similar to real outliers from
latent space, and (3) Latent Diffusion Model learns the latent space
distribution of real organic data by iterative denoising. Extensive experiments
conducted on multiple datasets substantiate the effectiveness and efficiency of
GODM. The case study further demonstrated the generation quality of our
synthetic data. To foster accessibility and reproducibility, we encapsulate
GODM into a plug-and-play package and release it at the Python Package Index
(PyPI).
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17681" title="Abstract">arXiv:2312.17681</a> [<a href="/pdf/2312.17681" title="Download PDF">pdf</a>, <a href="/format/2312.17681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+F">Feng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jialiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Licheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kunpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yinan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+I">Ishan Misra</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia-Bin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Marculescu%2C+D">Diana Marculescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://jeff-liangf.github.io/projects/flowvid/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Diffusion models have transformed the image-to-image (I2I) synthesis and are
now permeating into videos. However, the advancement of video-to-video (V2V)
synthesis has been hampered by the challenge of maintaining temporal
consistency across video frames. This paper proposes a consistent V2V synthesis
framework by jointly leveraging spatial conditions and temporal optical flow
clues within the source video. Contrary to prior methods that strictly adhere
to optical flow, our approach harnesses its benefits while handling the
imperfection in flow estimation. We encode the optical flow via warping from
the first frame and serve it as a supplementary reference in the diffusion
model. This enables our model for video synthesis by editing the first frame
with any prevalent I2I models and then propagating edits to successive frames.
Our V2V model, FlowVid, demonstrates remarkable properties: (1) Flexibility:
FlowVid works seamlessly with existing I2I models, facilitating various
modifications, including stylization, object swaps, and local edits. (2)
Efficiency: Generation of a 4-second video with 30 FPS and 512x512 resolution
takes only 1.5 minutes, which is 3.1x, 7.2x, and 10.5x faster than CoDeF,
Rerender, and TokenFlow, respectively. (3) High-quality: In user studies, our
FlowVid is preferred 45.7% of the time, outperforming CoDeF (3.5%), Rerender
(10.2%), and TokenFlow (40.4%).
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17682" title="Abstract">arXiv:2312.17682</a> [<a href="/pdf/2312.17682" title="Download PDF">pdf</a>, <a href="/ps/2312.17682" title="Download PostScript">ps</a>, <a href="/format/2312.17682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Idiom Recognition for a Minimalist Functional Array Language  using Equality Saturation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+der+Cruysse%2C+J">Jonathan Van der Cruysse</a>, 
<a href="/search/cs?searchtype=author&query=Dubach%2C+C">Christophe Dubach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Accelerating programs is typically done by recognizing code idioms matching
high-performance libraries or hardware interfaces. However, recognizing such
idioms automatically is challenging. The idiom recognition machinery is
difficult to write and requires expert knowledge. In addition, slight
variations in the input program might hide the idiom and defeat the recognizer.
<br />This paper advocates for the use of a minimalist functional array language
supporting a small, but expressive, set of operators. The minimalist design
leads to a tiny sets of rewrite rules, which encode the language semantics.
Crucially, the same minimalist language is also used to encode idioms. This
removes the need for hand-crafted analysis passes, or for having to learn a
complex domain-specific language to define the idioms.
<br />Coupled with equality saturation, this approach is able to match the core
functions from the BLAS and PyTorch libraries on a set of computational
kernels. Compared to reference C kernel implementations, the approach produces
a geometric mean speedup of 1.46x for C programs using BLAS, when generating
such programs from the high-level minimalist language.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17683" title="Abstract">arXiv:2312.17683</a> [<a href="/pdf/2312.17683" title="Download PDF">pdf</a>, <a href="/ps/2312.17683" title="Download PostScript">ps</a>, <a href="/format/2312.17683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Malware Detection in IOT Systems Using Machine Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrban%2C+A">Ali Mehrban</a>, 
<a href="/search/cs?searchtype=author&query=Ahadian%2C+P">Pegah Ahadian</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Wireless &amp; Mobile Networks (IJWMN),
  Vol.15, No.6, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Malware detection in IoT environments necessitates robust methodologies. This
study introduces a CNN-LSTM hybrid model for IoT malware identification and
evaluates its performance against established methods. Leveraging K-fold
cross-validation, the proposed approach achieved 95.5% accuracy, surpassing
existing methods. The CNN algorithm enabled superior learning model
construction, and the LSTM classifier exhibited heightened accuracy in
classification. Comparative analysis against prevalent techniques demonstrated
the efficacy of the proposed model, highlighting its potential for enhancing
IoT security. The study advocates for future exploration of SVMs as
alternatives, emphasizes the need for distributed detection strategies, and
underscores the importance of predictive analyses for a more powerful IOT
security. This research serves as a platform for developing more resilient
security measures in IoT ecosystems.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17686" title="Abstract">arXiv:2312.17686</a> [<a href="/pdf/2312.17686" title="Download PDF">pdf</a>, <a href="/format/2312.17686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Vision Transformers meet Bipartite Matching for efficient  single-stage Action Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ntinou%2C+I">Ioanna Ntinou</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+E">Enrique Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Tzimiropoulos%2C+G">Georgios Tzimiropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Action Localization is a challenging problem that combines detection and
recognition tasks, which are often addressed separately. State-of-the-art
methods rely on off-the-shelf bounding box detections pre-computed at high
resolution and propose transformer models that focus on the classification task
alone. Such two-stage solutions are prohibitive for real-time deployment. On
the other hand, single-stage methods target both tasks by devoting part of the
network (generally the backbone) to sharing the majority of the workload,
compromising performance for speed. These methods build on adding a DETR head
with learnable queries that, after cross- and self-attention can be sent to
corresponding MLPs for detecting a person's bounding box and action. However,
DETR-like architectures are challenging to train and can incur in big
complexity.
<br />In this paper, we observe that a straight bipartite matching loss can be
applied to the output tokens of a vision transformer. This results in a
backbone + MLP architecture that can do both tasks without the need of an extra
encoder-decoder head and learnable queries. We show that a single MViT-S
architecture trained with bipartite matching to perform both tasks surpasses
the same MViT-S when trained with RoI align on pre-computed bounding boxes.
With a careful design of token pooling and the proposed training pipeline, our
MViTv2-S model achieves +3 mAP on AVA2.2. w.r.t. the two-stage counterpart.
Code and models will be released after paper revision.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17689" title="Abstract">arXiv:2312.17689</a> [<a href="/pdf/2312.17689" title="Download PDF">pdf</a>, <a href="/format/2312.17689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple client-side encryption of personal information with Web Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Falda%2C+M">Marco Falda</a>, 
<a href="/search/cs?searchtype=author&query=Grassi%2C+A">Angela Grassi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The HTTPS protocol has enforced a higher level of robustness to several
attacks; however, it is not easy to set up the required certificates on
intranets, nor is it effective in the case the server confidentiality is not
reliable, as in the case of cloud services, or it could be compromised. A
simple method is proposed to encrypt the data on the client side, using Web
Assembly. It never transfers data to the server as clear text. Searching fields
in the server is made possible by an encoding scheme that ensures a stable
prefix correspondence between ciphertext and plaintext. The method has been
developed for a semantic medical database, and allows accessing personal data
using an additional password while maintaining non-sensitive information in
clear form. Web Assembly has been chosen to guarantee the fast and efficient
execution of encrypting/decrypting operations and because of its characteristic
of producing modules that are very robust against reverse engineering. The code
is available at https://github.com/mfalda/client-encdec.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17698" title="Abstract">arXiv:2312.17698</a> [<a href="/pdf/2312.17698" title="Download PDF">pdf</a>, <a href="/format/2312.17698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fixed-stress type splitting method for nonlinear poroelasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kraus%2C+J">Johannes Kraus</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+K">Kundan Kumar</a>, 
<a href="/search/math?searchtype=author&query=Lymbery%2C+M">Maria Lymbery</a>, 
<a href="/search/math?searchtype=author&query=Radu%2C+F+A">Florin Adrian Radu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we consider a nonlinear poroelasticity model that describes the
quasi-static mechanical behaviour of a fluid-saturated porous medium whose
permeability depends on the divergence of the displacement. Such nonlinear
models are typically used to study biological structures like tissues, organs,
cartilage and bones, which are known for a nonlinear dependence of their
permeability/hydraulic conductivity on solid dilation.
<br />We formulate (extend to the present situation) one of the most popular
splitting schemes, namely the fixed-stress split method for the iterative
solution of the coupled problem. The method is proven to converge linearly for
sufficiently small time steps under standard assumptions. The error contraction
factor then is strictly less than one, independent of the Lam\'{e} parameters,
Biot and storage coefficients if the hydraulic conductivity is a strictly
positive, bounded and Lipschitz-continuous function.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17704" title="Abstract">arXiv:2312.17704</a> [<a href="/pdf/2312.17704" title="Download PDF">pdf</a>, <a href="/ps/2312.17704" title="Download PostScript">ps</a>, <a href="/format/2312.17704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TuPy-E: detecting hate speech in Brazilian Portuguese social media with  a novel dataset and comprehensive analysis of models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+F">Felipe Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Reis%2C+V">Victoria Reis</a>, 
<a href="/search/cs?searchtype=author&query=Ebecken%2C+N">Nelson Ebecken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media has become integral to human interaction, providing a platform
for communication and expression. However, the rise of hate speech on these
platforms poses significant risks to individuals and communities. Detecting and
addressing hate speech is particularly challenging in languages like Portuguese
due to its rich vocabulary, complex grammar, and regional variations. To
address this, we introduce TuPy-E, the largest annotated Portuguese corpus for
hate speech detection. TuPy-E leverages an open-source approach, fostering
collaboration within the research community. We conduct a detailed analysis
using advanced techniques like BERT models, contributing to both academic
understanding and practical applications
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17708" title="Abstract">arXiv:2312.17708</a> [<a href="/pdf/2312.17708" title="Download PDF">pdf</a>, <a href="/ps/2312.17708" title="Download PostScript">ps</a>, <a href="/format/2312.17708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The six ways to build trust and reduce privacy concern in a Central Bank  Digital Currency (CBDC)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zarifis%2C+A">Alex Zarifis</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xusen Cheng</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Zarifis A., Ktoridou D., Efthymiou L. &amp; Cheng X. (ed.) Business
  digital transformation: Selected cases from industry leaders (2023), London:
  Palgrave Macmillan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Central Bank Digital Currencies (CBDCs) have been implemented by only a
handful of countries, but they are being explored by many more. CBDCs are
digital currencies issued and backed by a central bank. Consumer trust can
encourage or discourage the adoption of this currency, which is also a payment
system and a technology. This research attempts to understand consumer trust in
CBDCs so that the development and adoption stages are more effective and
satisfying for all the stakeholders.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17710" title="Abstract">arXiv:2312.17710</a> [<a href="/pdf/2312.17710" title="Download PDF">pdf</a>, <a href="/format/2312.17710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principled Gradient-based Markov Chain Monte Carlo for Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Li Du</a>, 
<a href="/search/cs?searchtype=author&query=Amini%2C+A">Afra Amini</a>, 
<a href="/search/cs?searchtype=author&query=Hennigen%2C+L+T">Lucas Torroba Hennigen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X+V">Xinyan Velocity Yu</a>, 
<a href="/search/cs?searchtype=author&query=Eisner%2C+J">Jason Eisner</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Holden Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent papers have demonstrated the possibility of energy-based text
generation by adapting gradient-based sampling algorithms, a paradigm of MCMC
algorithms that promises fast convergence. However, as we show in this paper,
previous attempts on this approach to text generation all fail to sample
correctly from the target language model distributions. To address this
limitation, we consider the problem of designing text samplers that are
faithful, meaning that they have the target text distribution as its limiting
distribution. We propose several faithful gradient-based sampling algorithms to
sample from the target energy-based text distribution correctly, and study
their theoretical properties. Through experiments on various forms of text
generation, we demonstrate that faithful samplers are able to generate more
fluent text while adhering to the control objectives better.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17713" title="Abstract">arXiv:2312.17713</a> [<a href="/pdf/2312.17713" title="Download PDF">pdf</a>, <a href="/ps/2312.17713" title="Download PostScript">ps</a>, <a href="/format/2312.17713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quick Primer on Machine Learning in Wireless Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mismar%2C+F+B">Faris B. Mismar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This is a first draft of a quick primer on the use of Python (and relevant
libraries) to build a wireless communication prototype that supports
multiple-input and multiple-output (MIMO) systems with orthogonal frequency
division multiplexing (OFDM) in addition to some machine learning use cases.
This primer is intended to empower researchers with a means to efficiently
create simulations. This draft is aligned with the syllabus of a graduate
course we created to be taught in Fall 2022 and we aspire to update this draft
occasionally based on feedback from the larger research community.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17722" title="Abstract">arXiv:2312.17722</a> [<a href="/pdf/2312.17722" title="Download PDF">pdf</a>, <a href="/ps/2312.17722" title="Download PostScript">ps</a>, <a href="/format/2312.17722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Experimental Study of Satisfaction Response: Evaluation of Online  Collaborative Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xusen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianqing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zarifis%2C+A">Alex Zarifis</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Review of Research in Open and Distributed Learning
  (2016), vol.17, no.1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">On the one hand, a growing amount of research discusses support for improving
online collaborative learning quality, and many indicators are focused to
assess its success. On the other hand, thinkLets for designing reputable and
valuable collaborative processes have been developed for more than ten years.
However, few studies try to apply thinkLets to online collaborative learning.
This paper introduces thinkLets to online collaborative learning and
experimentally tests its effectiveness with participants' responses on their
satisfaction. Yield Shift Theory (YST), a causal theory explaining inner
satisfaction, is adopted. In the experiment, 113 students from Universities in
Beijing, China are chosen as a sample. They were divided into two groups,
collaborating online in a simulated class. Then, YST in student groups under
online collaborative learning is validated, a comparison study of online
collaborative learning with and without thinkLets is implemented, and the
satisfaction response of participants are analyzed. As a result of this
comparison, YST is proved applicable in this context, and satisfaction is
higher in online collaborative learning with thinkLets.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17726" title="Abstract">arXiv:2312.17726</a> [<a href="/pdf/2312.17726" title="Download PDF">pdf</a>, <a href="/ps/2312.17726" title="Download PostScript">ps</a>, <a href="/format/2312.17726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Effectiveness and Efficiency of Interactive Application  Security Testing (IAST) and Runtime Application Self-Protection (RASP) Tools  in a Large Java-based System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seth%2C+A">Aishwarya Seth</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Saikath Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Elder%2C+S">Sarah Elder</a>, 
<a href="/search/cs?searchtype=author&query=Zahan%2C+N">Nusrat Zahan</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+L">Laurie Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Security resources are scarce, and practitioners need guidance in the
effective and efficient usage of techniques and tools available in the
cybersecurity industry. Two emerging tool types, Interactive Application
Security Testing (IAST) and Runtime Application Self-Protection (RASP), have
not been thoroughly evaluated against well-established counterparts such as
Dynamic Application Security Testing (DAST) and Static Application Security
Testing (SAST). The goal of this research is to aid practitioners in making
informed choices about the use of Interactive Application Security Testing
(IAST) and Runtime Application Self-Protection (RASP) tools through an analysis
of their effectiveness and efficiency in comparison with different
vulnerability detection and prevention techniques and tools. We apply IAST and
RASP on OpenMRS, an open-source Java-based online application. We compare the
efficiency and effectiveness of IAST and RASP with techniques applied on
OpenMRS in prior work. We measure efficiency and effectiveness in terms of the
number and type of vulnerabilities detected and prevented per hour. Our study
shows IAST performed relatively well compared to other techniques, performing
second-best in both efficiency and effectiveness. IAST detected eight Top-10
OWASP security risks compared to nine by SMPT and seven for EMPT, DAST, and
SAST. IAST found more vulnerabilities than SMPT. The efficiency of IAST (2.14
VpH) is second to only EMPT (2.22 VpH). These findings imply that our study
benefited from using IAST when conducting black-box security testing. In the
context of a large, enterprise-scale web application such as OpenMRS, RASP does
not replace vulnerability detection, while IAST is a powerful tool that
complements other techniques.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17731" title="Abstract">arXiv:2312.17731</a> [<a href="/pdf/2312.17731" title="Download PDF">pdf</a>, <a href="/format/2312.17731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MURP: Multi-Agent Ultra-Wideband Relative Pose Estimation with  Constrained Communications in 3D Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fishberg%2C+A">Andrew Fishberg</a>, 
<a href="/search/cs?searchtype=author&query=Quiter%2C+B">Brian Quiter</a>, 
<a href="/search/cs?searchtype=author&query=How%2C+J+P">Jonathan P. How</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Inter-agent relative localization is critical for many multi-robot systems
operating in the absence of external positioning infrastructure or prior
environmental knowledge. We propose a novel inter-agent relative 3D pose
estimation system where each participating agent is equipped with several
ultra-wideband (UWB) ranging tags. Prior work typically supplements noisy UWB
range measurements with additional continuously transmitted data, such as
odometry, leading to potential scaling issues with increased team size and/or
decreased communication network capability. By equipping each agent with
multiple UWB antennas, our approach addresses these concerns by using only
locally collected UWB range measurements, a priori state constraints, and
detections of when said constraints are violated. Leveraging our learned mean
ranging bias correction, we gain a 19% positional error improvement giving us
experimental mean absolute position and heading errors of 0.24m and 9.5 degrees
respectively. When compared to other state-of-the-art approaches, our work
demonstrates improved performance over similar systems, while remaining
competitive with methods that have significantly higher communication costs.
Additionally, we make our datasets available.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17738" title="Abstract">arXiv:2312.17738</a> [<a href="/pdf/2312.17738" title="Download PDF">pdf</a>, <a href="/format/2312.17738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed Graphical Neural Network for Power System State  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ngo%2C+Q">Quang-Ha Ngo</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+B+L+H">Bang L. H. Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Vu%2C+T+V">Tuyen V. Vu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jianhua Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Ngo%2C+T">Tuan Ngo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 17 figures, journal accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">State estimation is highly critical for accurately observing the dynamic
behavior of the power grids and minimizing risks from cyber threats. However,
existing state estimation methods encounter challenges in accurately capturing
power system dynamics, primarily because of limitations in encoding the grid
topology and sparse measurements. This paper proposes a physics-informed
graphical learning state estimation method to address these limitations by
leveraging both domain physical knowledge and a graph neural network (GNN). We
employ a GNN architecture that can handle the graph-structured data of power
systems more effectively than traditional data-driven methods. The
physics-based knowledge is constructed from the branch current formulation,
making the approach adaptable to both transmission and distribution systems.
The validation results of three IEEE test systems show that the proposed method
can achieve lower mean square error more than 20% than the conventional
methods.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17742" title="Abstract">arXiv:2312.17742</a> [<a href="/pdf/2312.17742" title="Download PDF">pdf</a>, <a href="/format/2312.17742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Vision from Models Rivals Learning Vision from Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yonglong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lijie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Katabi%2C+D">Dina Katabi</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+D">Dilip Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Isola%2C+P">Phillip Isola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/google-research/syn-rep-learn">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce SynCLR, a novel approach for learning visual representations
exclusively from synthetic images and synthetic captions, without any real
data. We synthesize a large dataset of image captions using LLMs, then use an
off-the-shelf text-to-image model to generate multiple images corresponding to
each synthetic caption. We perform visual representation learning on these
synthetic images via contrastive learning, treating images sharing the same
caption as positive pairs. The resulting representations transfer well to many
downstream tasks, competing favorably with other general-purpose visual
representation learners such as CLIP and DINO v2 in image classification tasks.
Furthermore, in dense prediction tasks such as semantic segmentation, SynCLR
outperforms previous self-supervised methods by a significant margin, e.g.,
improving over MAE and iBOT by 6.2 and 4.3 mIoU on ADE20k for ViT-B/16.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17748" title="Abstract">arXiv:2312.17748</a> [<a href="/pdf/2312.17748" title="Download PDF">pdf</a>, <a href="/format/2312.17748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> K-PERM: Personalized Response Generation Using Dynamic Knowledge  Retrieval and Persona-Adaptive Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raj%2C+K">Kanak Raj</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>, 
<a href="/search/cs?searchtype=author&query=Gaur%2C+M">Manas Gaur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Personalizing conversational agents can enhance the quality of conversations
and increase user engagement. However, they often lack external knowledge to
appropriately tend to a user's persona. This is particularly crucial for
practical applications like mental health support, nutrition planning,
culturally sensitive conversations, or reducing toxic behavior in
conversational agents. To enhance the relevance and comprehensiveness of
personalized responses, we propose using a two-step approach that involves (1)
selectively integrating user personas and (2) contextualizing the response with
supplementing information from a background knowledge source. We develop K-PERM
(Knowledge-guided PErsonalization with Reward Modulation), a dynamic
conversational agent that combines these elements. K-PERM achieves
state-of-the-art performance on the popular FoCus dataset, containing
real-world personalized conversations concerning global landmarks. We show that
using responses from K-PERM can improve performance in state-of-the-art LLMs
(GPT 3.5) by 10.5%, highlighting the impact of K-PERM for personalizing
chatbots.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon,  1 Jan 24</h3>
<dl>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.11144" title="Abstract">arXiv:2110.11144</a> (cross-list from eess.AS) [<a href="/pdf/2110.11144" title="Download PDF">pdf</a>, <a href="/format/2110.11144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RCT: Random Consistency Training for Semi-supervised Sound Event  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shao%2C+N">Nian Shao</a>, 
<a href="/search/eess?searchtype=author&query=Loweimi%2C+E">Erfan Loweimi</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaofei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint for interspeech 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Sound event detection (SED), as a core module of acoustic environmental
analysis, suffers from the problem of data deficiency. The integration of
semi-supervised learning (SSL) largely mitigates such problem while bringing no
extra annotation budget. This paper researches on several core modules of SSL,
and introduces a random consistency training (RCT) strategy. First, a
self-consistency loss is proposed to fuse with the teacher-student model to
stabilize the training. Second, a hard mixup data augmentation is proposed to
account for the additive property of sounds. Third, a random augmentation
scheme is applied to flexibly combine different types of data augmentations.
Experiments show that the proposed strategy outperform other widely-used
strategies.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15676" title="Abstract">arXiv:2312.15676</a> (cross-list from eess.IV) [<a href="/pdf/2312.15676" title="Download PDF">pdf</a>, <a href="/format/2312.15676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse-view CT Reconstruction with 3D Gaussian Volumetric Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yingtai Li</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+X">Xueming Fu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Shang Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+R">Ruiyang Jin</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+S+K">S. Kevin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Sparse-view CT is a promising strategy for reducing the radiation dose of
traditional CT scans, but reconstructing high-quality images from incomplete
and noisy data is challenging. Recently, 3D Gaussian has been applied to model
complex natural scenes, demonstrating fast convergence and better rendering of
novel views compared to implicit neural representations (INRs). Taking
inspiration from the successful application of 3D Gaussians in natural scene
modeling and novel view synthesis, we investigate their potential for
sparse-view CT reconstruction. We leverage prior information from the
filtered-backprojection reconstructed image to initialize the Gaussians; and
update their parameters via comparing difference in the projection space.
Performance is further enhanced by adaptive density control. Compared to INRs,
3D Gaussians benefit more from prior information to explicitly bypass learning
in void spaces and allocate the capacity efficiently, accelerating convergence.
3D Gaussians also efficiently learn high-frequency details. Trained in a
self-supervised manner, 3D Gaussians avoid the need for large-scale paired
data. Our experiments on the AAPM-Mayo dataset demonstrate that 3D Gaussians
can provide superior performance compared to INR-based methods. This work is in
progress, and the code will be publicly available.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16341" title="Abstract">arXiv:2312.16341</a> (cross-list from stat.ML) [<a href="/pdf/2312.16341" title="Download PDF">pdf</a>, <a href="/format/2312.16341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Power of Federated Learning in Federated Contextual  Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shi%2C+C">Chengshuai Shi</a>, 
<a href="/search/stat?searchtype=author&query=Zhou%2C+R">Ruida Zhou</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+K">Kun Yang</a>, 
<a href="/search/stat?searchtype=author&query=Shen%2C+C">Cong Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version appeared in the Multi-Agent Security Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Federated learning (FL) has demonstrated great potential in revolutionizing
distributed machine learning, and tremendous efforts have been made to extend
it beyond the original focus on supervised learning. Among many directions,
federated contextual bandits (FCB), a pivotal integration of FL and sequential
decision-making, has garnered significant attention in recent years. Despite
substantial progress, existing FCB approaches have largely employed their
tailored FL components, often deviating from the canonical FL framework.
Consequently, even renowned algorithms like FedAvg remain under-utilized in
FCB, let alone other FL advancements. Motivated by this disconnection, this
work takes one step towards building a tighter relationship between the
canonical FL study and the investigations on FCB. In particular, a novel FCB
design, termed FedIGW, is proposed to leverage a regression-based CB algorithm,
i.e., inverse gap weighting. Compared with existing FCB approaches, the
proposed FedIGW design can better harness the entire spectrum of FL
innovations, which is concretely reflected as (1) flexible incorporation of
(both existing and forthcoming) FL protocols; (2) modularized plug-in of FL
analyses in performance guarantees; (3) seamless integration of FL appendages
(such as personalization, robustness, and privacy). We substantiate these
claims through rigorous theoretical analyses and empirical evaluations.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17255" title="Abstract">arXiv:2312.17255</a> (cross-list from eess.AS) [<a href="/pdf/2312.17255" title="Download PDF">pdf</a>, <a href="/format/2312.17255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-channel speech enhancement using learnable loss mixup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chang%2C+O">Oscar Chang</a>, 
<a href="/search/eess?searchtype=author&query=Tran%2C+D+N">Dung N. Tran</a>, 
<a href="/search/eess?searchtype=author&query=Koishida%2C+K">Kazuhito Koishida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Generalization remains a major problem in supervised learning of
single-channel speech enhancement. In this work, we propose learnable loss
mixup (LLM), a simple and effortless training diagram, to improve the
generalization of deep learning-based speech enhancement models. Loss mixup, of
which learnable loss mixup is a special variant, optimizes a mixture of the
loss functions of random sample pairs to train a model on virtual training data
constructed from these pairs of samples. In learnable loss mixup, by
conditioning on the mixed data, the loss functions are mixed using a non-linear
mixing function automatically learned via neural parameterization. Our
experimental results on the VCTK benchmark show that learnable loss mixup
achieves 3.26 PESQ, outperforming the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17266" title="Abstract">arXiv:2312.17266</a> (cross-list from eess.IV) [<a href="/pdf/2312.17266" title="Download PDF">pdf</a>, <a href="/ps/2312.17266" title="Download PostScript">ps</a>, <a href="/format/2312.17266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic laminectomy cutting plane planning based on artificial  intelligence in robot assisted laminectomy surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhuofu Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yonghong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chengxia Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shanshan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+X">Xiongkang Song</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+X">Xuquan Ji</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+S">Shuai Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhong%2C+W">Woquan Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+L">Lei Hu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+W">Weishi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">Objective: This study aims to use artificial intelligence to realize the
automatic planning of laminectomy, and verify the method. Methods: We propose a
two-stage approach for automatic laminectomy cutting plane planning. The first
stage was the identification of key points. 7 key points were manually marked
on each CT image. The Spatial Pyramid Upsampling Network (SPU-Net) algorithm
developed by us was used to accurately locate the 7 key points. In the second
stage, based on the identification of key points, a personalized coordinate
system was generated for each vertebra. Finally, the transverse and
longitudinal cutting planes of laminectomy were generated under the coordinate
system. The overall effect of planning was evaluated. Results: In the first
stage, the average localization error of the SPU-Net algorithm for the seven
key points was 0.65mm. In the second stage, a total of 320 transverse cutting
planes and 640 longitudinal cutting planes were planned by the algorithm. Among
them, the number of horizontal plane planning effects of grade A, B, and C were
318(99.38%), 1(0.31%), and 1(0.31%), respectively. The longitudinal planning
effects of grade A, B, and C were 622(97.18%), 1(0.16%), and 17(2.66%),
respectively. Conclusions: In this study, we propose a method for automatic
surgical path planning of laminectomy based on the localization of key points
in CT images. The results showed that the method achieved satisfactory results.
More studies are needed to confirm the reliability of this approach in the
future.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17290" title="Abstract">arXiv:2312.17290</a> (cross-list from eess.IV) [<a href="/pdf/2312.17290" title="Download PDF">pdf</a>, <a href="/format/2312.17290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Convolution Neural Networks with Long-Short Time Memory Layers  to Predict Parkinson&#x27;s Disease Progression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Frasca%2C+M">Maria Frasca</a>, 
<a href="/search/eess?searchtype=author&query=La+Torre%2C+D">Davide La Torre</a>, 
<a href="/search/eess?searchtype=author&query=Cutica%2C+I">Ilaria Cutica</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Parkinson's disease is a neurological condition that occurs in nearly 1% of
the world's population. The disease is manifested by a drop in dopamine
production, symptoms are cognitive and behavioural and include a wide range of
personality changes, depressive disorders, memory problems, and emotional
dysregulation, which can occur as the disease progresses. Early diagnosis and
accurate staging of the disease are essential to apply the appropriate
therapeutic approaches to slow cognitive and motor decline.
<br />Currently, there is not a single blood test or biomarker available to
diagnose Parkinson's disease. Magnetic resonance imaging has been used for the
past three decades to diagnose and distinguish between PD and other
neurological conditions. However, in recent years new possibilities have
arisen: several AI algorithms have been developed to increase the precision and
accuracy of differential diagnosis of PD at an early stage.
<br />To our knowledge, no AI tools have been designed to identify the stage of
progression. This paper aims to fill this gap. Using the "Parkinson's
Progression Markers Initiative" dataset, which reports the patient's MRI and an
indication of the disease stage, we developed a model to identify the level of
progression. The images and the associated scores were used for training and
assessing different deep-learning models. Our analysis distinguished four
distinct disease progression levels based on a standard scale (Hoehn and Yah
scale). The final architecture consists of the cascading of a 3DCNN network,
adopted to reduce and extract the spatial characteristics of the RMI for
efficient training of the successive LSTM layers, aiming at modelling the
temporal dependencies among the data.
<br />Our results show that the proposed 3DCNN + LSTM model achieves
state-of-the-art results by classifying the elements with 91.90\% as macro
averaged OVR AUC on four classes
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17293" title="Abstract">arXiv:2312.17293</a> (cross-list from eess.IV) [<a href="/pdf/2312.17293" title="Download PDF">pdf</a>, <a href="/format/2312.17293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3bc;$GUIDE: a framework for microstructure imaging via generalized  uncertainty-driven inference using deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jallais%2C+M">Ma&#xeb;liss Jallais</a>, 
<a href="/search/eess?searchtype=author&query=Palombo%2C+M">Marco Palombo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">This work proposes $\mu$GUIDE: a general Bayesian framework to estimate
posterior distributions of tissue microstructure parameters from any given
biophysical model or MRI signal representation, with exemplar demonstration in
diffusion-weighted MRI. Harnessing a new deep learning architecture for
automatic signal feature selection combined with simulation-based inference and
efficient sampling of the posterior distributions, $\mu$GUIDE bypasses the high
computational and time cost of conventional Bayesian approaches and does not
rely on acquisition constraints to define model-specific summary statistics.
The obtained posterior distributions allow to highlight degeneracies present in
the model definition and quantify the uncertainty and ambiguity of the
estimated parameters.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17298" title="Abstract">arXiv:2312.17298</a> (cross-list from hep-ph) [<a href="/pdf/2312.17298" title="Download PDF">pdf</a>, <a href="/ps/2312.17298" title="Download PostScript">ps</a>, <a href="/format/2312.17298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical fits to inclusive electron-carbon scattering data obtained by  deep-learning methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Kowal%2C+B+E">Beata E. Kowal</a>, 
<a href="/search/hep-ph?searchtype=author&query=Graczyk%2C+K+M">Krzysztof M. Graczyk</a>, 
<a href="/search/hep-ph?searchtype=author&query=Ankowski%2C+A+M">Artur M. Ankowski</a>, 
<a href="/search/hep-ph?searchtype=author&query=Banerjee%2C+R+D">Rwik Dharmapal Banerjee</a>, 
<a href="/search/hep-ph?searchtype=author&query=Prasad%2C+H">Hemant Prasad</a>, 
<a href="/search/hep-ph?searchtype=author&query=Sobczyk%2C+J+T">Jan T. Sobczyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures; supplemental materials contain full list of plots; fits are available from repository: <a href="https://github.com/bekowal/CarbonElectronNeuralNetwork">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Nuclear Experiment (nucl-ex); Nuclear Theory (nucl-th)

</div>
<p class="mathjax">Employing the neural network framework, we obtain empirical fits to the
electron-scattering cross section for carbon over a broad kinematic region,
extending from the quasielastic peak, through resonance excitation, to the
onset of deep-inelastic scattering. We consider two different methods of
obtaining such model-independent parametrizations and the corresponding
uncertainties: based on the NNPDF approach [J. High Energy Phys. 2002, 062],
and on the Monte Carlo dropout. In our analysis, the $\chi^2$ function defines
the loss function, including point-to-point uncertainties and considering the
systematic normalization uncertainties for each independent set of
measurements. Our statistical approaches lead to fits of comparable quality and
similar uncertainties of the order of $7\%$ and $12\%$ for the first and the
second approaches, respectively. To test these models, we compare their
predictions to a~test dataset, excluded from the training process, a~dataset
lying beyond the covered kinematic region, and theoretical predictions obtained
within the spectral function approach. The predictions of both models agree
with experimental measurements and the theoretical predictions. However, the
first statistical approach shows better interpolation and extrapolation
abilities than the one based on the dropout algorithm.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17344" title="Abstract">arXiv:2312.17344</a> (cross-list from math.DS) [<a href="/pdf/2312.17344" title="Download PDF">pdf</a>, <a href="/format/2312.17344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Self-Composite Approach Towards Structural Understanding of  Boolean Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kim%2C+J">Jongrae Kim</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+W">Woojeong Lee</a>, 
<a href="/search/math?searchtype=author&query=Cho%2C+K">Kwang-Hyun Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Systems and Control (eess.SY); Molecular Networks (q-bio.MN)

</div>
<p class="mathjax">Boolean networks have been widely used in many areas of science and
engineering to represent various dynamical behaviour. In systems biology, they
became useful tools to study the dynamical characteristics of large-scale
biomolecular networks and there have been a number of studies to develop
efficient ways of finding steady states or cycles of Boolean network models. On
the other hand, there has been little attention to analyzing the dynamic
properties of the network structure itself. Here, we present a systematic way
to study such properties by introducing a recursive self-composite of the logic
update rules. Of note, we found that all Boolean update rules actually have
repeated logic structures underneath. This repeated nature of Boolean networks
reveals interesting algebraic properties embedded in the networks. We found
that each converged logic leads to the same states, called kernel states. As a
result, the longest-length period of states cycle turns out to be equal to the
number of converged logics in the logic cycle. Based on this, we propose a
leaping and filling algorithm to avoid any possible large string explosions
during the self-composition procedures. Finally, we demonstrate how the
proposed approach can be used to reveal interesting hidden properties using
Boolean network examples of a simple network with a long feedback structure, a
T-cell receptor network and a cancer network.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17350" title="Abstract">arXiv:2312.17350</a> (cross-list from physics.app-ph) [<a href="/pdf/2312.17350" title="Download PDF">pdf</a>, <a href="/format/2312.17350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Damage Rate Laws and Failure Statistics for Lumped Coupled-Field Systems  via Averaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Roy%2C+A">Arjun Roy</a>, 
<a href="/search/physics?searchtype=author&query=Cusumano%2C+J+P">Joseph P. Cusumano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Systems and Control (eess.SY)

</div>
<p class="mathjax">We study the non-linear dynamics and failure statistics of a coupled-field
fatigue damage evolution model. We develop a methodology to derive averaged
damage evolution rate laws from such models. We show that such rate laws reduce
life-cycle simulation times by orders of magnitude and permit dynamical systems
analysis of long-time behavior, including failure time statistics. We use the
averaged damage rate laws to study 1 DOF and 2 DOF damage evolution models. We
identify parameter regimes in which the systems behave like a brittle material
and show that the relative variability for failure times is high for such
cases. We also use the averaged rate laws to construct damage evolution phase
portraits for the 2 DOF system and use insights derived from them to understand
failure time and location statistics. We show that, for brittle materials, as
the relative variability in failure time increases, the variability in failure
location decreases.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17382" title="Abstract">arXiv:2312.17382</a> (cross-list from astro-ph.EP) [<a href="/pdf/2312.17382" title="Download PDF">pdf</a>, <a href="/format/2312.17382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovery of Small Ultra-short-period Planets Orbiting KG Dwarfs in  Kepler Survey Using GPU Phase Folding and Deep Learning Detection System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Wang%2C+K">Kaitlyn Wang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ge%2C+J">Jian Ge</a>, 
<a href="/search/astro-ph?searchtype=author&query=Willis%2C+K">Kevin Willis</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wang%2C+K">Kevin Wang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Zhao%2C+Y">Yinan Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 40 figures; To be published in the Monthly Notices of the Royal Astronomical Society (MNRAS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Since the discovery of the first hot Jupiter orbiting a solar-type star, 51
Peg, in 1995, more than 4000 exoplanets have been identified using various
observational techniques. The formation process of these sub-Earths remains
elusive, and acquiring additional samples is essential for investigating this
unique population. In our study, we employ a novel GPU Phase Folding algorithm
combined with a Convolutional Neural Network, termed the GPFC method, on Kepler
photometry data. This method enhances the transit search speed significantly
over the traditional Box-fitting Least Squares method, allowing a complete
search of the known KOI photometry data within hours using a commercial GPU
card. To date, we have identified five promising sub-Earth short-period
candidates: K00446.c, K01821.b, K01522.c, K03404.b, and K04978.b. A closer
analysis reveals the following characteristics: K00446.c orbits a K dwarf on a
0.645091-day period. With a radius of $0.461R_\oplus$, it ranks as the second
smallest USP discovered to date. K01821.b is a sub-Earth with a radius of
$0.648R_\oplus$, orbiting a G dwarf over a 0.91978-day period. It is the second
smallest USP among all confirmed USPs orbiting G dwarfs in the NASA Archive.
K01522.c has a radius of $0.704 R_\oplus$ and completes an orbit around a
Sun-like G dwarf in 0.64672 days; K03404.b, with a radius of $0.738 R_\oplus$,
orbits a G dwarf on a 0.68074-day period; and K04978.b, with its planetary
radius of $0.912 R_\oplus$, orbits a G dwarf, completing an orbit every 0.94197
days. Three of our finds, K01821.b, K01522.c and K03404.b, rank as the smallest
planets among all confirmed USPs orbiting G dwarfs in the Kepler dataset. The
discovery of these small exoplanets underscores the promising capability of the
GPFC method for searching for small, new transiting exoplanets in photometry
data from Kepler, TESS, and future space transit missions.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17390" title="Abstract">arXiv:2312.17390</a> (cross-list from quant-ph) [<a href="/pdf/2312.17390" title="Download PDF">pdf</a>, <a href="/ps/2312.17390" title="Download PostScript">ps</a>, <a href="/format/2312.17390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Hamiltonian Learning for the Fermi-Hubbard Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ni%2C+H">Hongkang Ni</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+H">Haoya Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ying%2C+L">Lexing Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work proposes a protocol for Fermionic Hamiltonian learning. For the
Hubbard model defined on a bounded-degree graph, the Heisenberg-limited scaling
is achieved while allowing for state preparation and measurement errors. To
achieve $\epsilon$-accurate estimation for all parameters, only
$\tilde{\mathcal{O}}(\epsilon^{-1})$ total evolution time is needed, and the
constant factor is independent of the system size. Moreover, our method only
involves simple one or two-site Fermionic manipulations, which is desirable for
experiment implementation.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17420" title="Abstract">arXiv:2312.17420</a> (cross-list from stat.ME) [<a href="/pdf/2312.17420" title="Download PDF">pdf</a>, <a href="/format/2312.17420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Consistency Tests for Gaussian Mixture Filters using Normalized  Deviation Squared Statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ahmed%2C+N">Nisar Ahmed</a>, 
<a href="/search/stat?searchtype=author&query=Burks%2C+L">Luke Burks</a>, 
<a href="/search/stat?searchtype=author&query=Cabral%2C+K">Kailah Cabral</a>, 
<a href="/search/stat?searchtype=author&query=Rose%2C+A+B">Alyssa Bekai Rose</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures; initial manuscript submitted for review to 2024 American Control Conference (ACC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO); Systems and Control (eess.SY); Applications (stat.AP)

</div>
<p class="mathjax">We consider the problem of evaluating dynamic consistency in discrete time
probabilistic filters that approximate stochastic system state densities with
Gaussian mixtures. Dynamic consistency means that the estimated probability
distributions correctly describe the actual uncertainties. As such, the problem
of consistency testing naturally arises in applications with regards to
estimator tuning and validation. However, due to the general complexity of the
density functions involved, straightforward approaches for consistency testing
of mixture-based estimators have remained challenging to define and implement.
This paper derives a new exact result for Gaussian mixture consistency testing
within the framework of normalized deviation squared (NDS) statistics. It is
shown that NDS test statistics for generic multivariate Gaussian mixture models
exactly follow mixtures of generalized chi-square distributions, for which
efficient computational tools are available. The accuracy and utility of the
resulting consistency tests are numerically demonstrated on static and dynamic
mixture estimation examples.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17450" title="Abstract">arXiv:2312.17450</a> (cross-list from quant-ph) [<a href="/pdf/2312.17450" title="Download PDF">pdf</a>, <a href="/format/2312.17450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Fragility or Robustness Under Quantum Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Laracuente%2C+N">Nicholas Laracuente</a>, 
<a href="/search/quant-ph?searchtype=author&query=Smith%2C+G">Graeme Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 1 figure, presented at Beyond IID 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Quantum states naturally decay under noise. Many earlier works have
quantified and demonstrated lower bounds on the decay rate, showing exponential
decay in a wide variety of contexts. Here we study the converse question: are
there uniform upper bounds on the ratio of post-noise to initial information
quantities when noise is sufficiently weak?
<br />In several scenarios, including classical, we find multiplicative converse
bounds. However, this is not always the case. Even for simple noise such as
qubit dephasing or depolarizing, mutual information may fall by an unbounded
factor under arbitrarily weak noise. As an application, we find families of
channels with non-zero private capacity despite arbitrarily high probability of
transmitting an arbitrarily good copy of the input to the environment.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17506" title="Abstract">arXiv:2312.17506</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.17506" title="Download PDF">pdf</a>, <a href="/format/2312.17506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A graph neural network-based model with Out-of-Distribution Robustness  for enhancing Antiretroviral Therapy Outcome Prediction for HIV-1
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Di+Teodoro%2C+G">Giulia Di Teodoro</a>, 
<a href="/search/q-bio?searchtype=author&query=Siciliano%2C+F">Federico Siciliano</a>, 
<a href="/search/q-bio?searchtype=author&query=Guarrasi%2C+V">Valerio Guarrasi</a>, 
<a href="/search/q-bio?searchtype=author&query=Vandamme%2C+A">Anne-Mieke Vandamme</a>, 
<a href="/search/q-bio?searchtype=author&query=Ghisetti%2C+V">Valeria Ghisetti</a>, 
<a href="/search/q-bio?searchtype=author&query=S%C3%B6nnerborg%2C+A">Anders S&#xf6;nnerborg</a>, 
<a href="/search/q-bio?searchtype=author&query=Zazzi%2C+M">Maurizio Zazzi</a>, 
<a href="/search/q-bio?searchtype=author&query=Silvestri%2C+F">Fabrizio Silvestri</a>, 
<a href="/search/q-bio?searchtype=author&query=Palagi%2C+L">Laura Palagi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Predicting the outcome of antiretroviral therapies for HIV-1 is a pressing
clinical challenge, especially when the treatment regimen includes drugs for
which limited effectiveness data is available. This scarcity of data can arise
either due to the introduction of a new drug to the market or due to limited
use in clinical settings. To tackle this issue, we introduce a novel joint
fusion model, which combines features from a Fully Connected (FC) Neural
Network and a Graph Neural Network (GNN). The FC network employs tabular data
with a feature vector made up of viral mutations identified in the most recent
genotypic resistance test, along with the drugs used in therapy. Conversely,
the GNN leverages knowledge derived from Stanford drug-resistance mutation
tables, which serve as benchmark references for deducing in-vivo treatment
efficacy based on the viral genetic sequence, to build informative graphs. We
evaluated these models' robustness against Out-of-Distribution drugs in the
test set, with a specific focus on the GNN's role in handling such scenarios.
Our comprehensive analysis demonstrates that the proposed model consistently
outperforms the FC model, especially when considering Out-of-Distribution
drugs. These results underscore the advantage of integrating Stanford scores in
the model, thereby enhancing its generalizability and robustness, but also
extending its utility in real-world applications with limited data
availability. This research highlights the potential of our approach to inform
antiretroviral therapy outcome prediction and contribute to more informed
clinical decisions.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17508" title="Abstract">arXiv:2312.17508</a> (cross-list from eess.AS) [<a href="/pdf/2312.17508" title="Download PDF">pdf</a>, <a href="/ps/2312.17508" title="Download PostScript">ps</a>, <a href="/format/2312.17508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-based Interactive Disentangling Network for Instance-level  Emotional Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yun Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+L">Lingxiao Yang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Lai%2C+J">Jian-Huang Lai</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+X">Xiaohua Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by INTERSPEECH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD)

</div>
<p class="mathjax">Emotional Voice Conversion aims to manipulate a speech according to a given
emotion while preserving non-emotion components. Existing approaches cannot
well express fine-grained emotional attributes. In this paper, we propose an
Attention-based Interactive diseNtangling Network (AINN) that leverages
instance-wise emotional knowledge for voice conversion. We introduce a
two-stage pipeline to effectively train our network: Stage I utilizes
inter-speech contrastive learning to model fine-grained emotion and
intra-speech disentanglement learning to better separate emotion and content.
In Stage II, we propose to regularize the conversion with a multi-view
consistency mechanism. This technique helps us transfer fine-grained emotion
and maintain speech content. Extensive experiments show that our AINN
outperforms state-of-the-arts in both objective and subjective metrics.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17531" title="Abstract">arXiv:2312.17531</a> (cross-list from math.OC) [<a href="/pdf/2312.17531" title="Download PDF">pdf</a>, <a href="/ps/2312.17531" title="Download PostScript">ps</a>, <a href="/format/2312.17531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Constraints on Lie groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Stratoglou%2C+E">E. Stratoglou</a>, 
<a href="/search/math?searchtype=author&query=Simoes%2C+A+A">A. Anahory Simoes</a>, 
<a href="/search/math?searchtype=author&query=Bloch%2C+A">A. Bloch</a>, 
<a href="/search/math?searchtype=author&query=Colombo%2C+L">L. Colombo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Mathematical Physics (math-ph)

</div>
<p class="mathjax">This paper studies virtual constraints on Lie groups. Virtual constraints are
invariant relations imposed on a control system via feedback. In this work, we
introduce the notion of \textit{virtual constraints on Lie groups}, in
particular, \textit{virtual nonholonomic constraints on Lie groups}, in a
geometric framework. More precisely, this object is a controlled invariant
subspace associated with an affine connection mechanical control system on the
Lie algebra associated with the Lie group which is the configuration space of
the system. We demonstrate the existence and uniqueness of a control law
defining a virtual nonholonomic constraint and we characterize the trajectories
of the closed-loop system as solutions of a mechanical system associated with
an induced constrained connection. Moreover, we characterize the reduced
dynamics for nonholonomic systems in terms of virtual nonholonomic constraints,
i.e., we characterize when can we obtain reduced nonholonomic dynamics from
virtual nonholonomic constraints. We illustrate the theory with some examples
and present simulation results for an application.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17569" title="Abstract">arXiv:2312.17569</a> (cross-list from math.OC) [<a href="/pdf/2312.17569" title="Download PDF">pdf</a>, <a href="/format/2312.17569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the complexity of a maintenance problem for hierarchical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schulz%2C+A+S">Andreas S. Schulz</a>, 
<a href="/search/math?searchtype=author&query=Telha%2C+C">Claudio Telha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">We prove that a maintenance problem on frequency-constrained maintenance jobs
with a hierarchical structure is integer-factorization hard. This result holds
even on simple systems with just two components to maintain. As a corollary, we
provide a first hardness result for Levi et al.'s modular maintenance
scheduling problem (Naval Research Logistics 61, 472-488, 2014).
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17579" title="Abstract">arXiv:2312.17579</a> (cross-list from eess.IV) [<a href="/pdf/2312.17579" title="Download PDF">pdf</a>, <a href="/format/2312.17579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-based Low-rank Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yousefi%2C+B">Bardia Yousefi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the author version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The early detection of breast abnormalities is a matter of critical
significance. Notably, infrared thermography has emerged as a valuable tool in
breast cancer screening and clinical breast examination (CBE). Measuring
heterogeneous thermal patterns is the key to incorporating computational
dynamic thermography, which can be achieved by matrix factorization techniques.
These approaches focus on extracting the predominant thermal patterns from the
entire thermal sequence. Yet, the task of singling out the dominant image that
effectively represents the prevailing temporal changes remains a challenging
pursuit within the field of computational thermography. In this context, we
propose applying James-Stein for eigenvector (JSE) and Weibull embedding
approaches, as two novel strategies in response to this challenge. The primary
objective is to create a low-dimensional (LD) representation of the thermal
data stream. This LD approximation serves as the foundation for extracting
thermomics and training a classification model with optimized hyperparameters,
for early breast cancer detection. Furthermore, we conduct a comparative
analysis of various embedding adjuncts to matrix factorization methods. The
results of the proposed method indicate an enhancement in the projection of the
predominant basis vector, yielding classification accuracy of 81.7% (+/-5.2%)
using Weibull embedding, which outperformed other embedding approaches we
proposed previously. In comparison analysis, Sparse PCT and Deep SemiNMF showed
the highest accuracies having 80.9% and 78.6%, respectively. These findings
suggest that JSE and Weibull embedding techniques substantially help preserve
crucial thermal patterns as a biomarker leading to improved CBE and enabling
the very early detection of breast cancer.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17630" title="Abstract">arXiv:2312.17630</a> (cross-list from math.CO) [<a href="/pdf/2312.17630" title="Download PDF">pdf</a>, <a href="/ps/2312.17630" title="Download PostScript">ps</a>, <a href="/format/2312.17630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Total Matching and Subdeterminants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ferrarini%2C+L">Luca Ferrarini</a>, 
<a href="/search/math?searchtype=author&query=Fiorini%2C+S">Samuel Fiorini</a>, 
<a href="/search/math?searchtype=author&query=Kober%2C+S">Stefan Kober</a>, 
<a href="/search/math?searchtype=author&query=Yuditsky%2C+Y">Yelena Yuditsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">In the total matching problem, one is given a graph $G$ with weights on the
vertices and edges. The goal is to find a maximum weight set of vertices and
edges that is the non-incident union of a stable set and a matching.
<br />We consider the natural formulation of the problem as an integer program
(IP), with variables corresponding to vertices and edges. Let $M = M(G)$ denote
the constraint matrix of this IP. We define $\Delta(G)$ as the maximum absolute
value of the determinant of a square submatrix of $M$.
<br />We show that the total matching problem can be solved in strongly polynomial
time provided $\Delta(G) \leq \Delta$ for some constant $\Delta \in
\mathbb{Z}_{\ge 1}$. We also show that the problem of computing $\Delta(G)$
admits an FPT algorithm. We also establish further results on $\Delta(G)$ when
$G$ is a forest.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17675" title="Abstract">arXiv:2312.17675</a> (cross-list from math.CO) [<a href="/pdf/2312.17675" title="Download PDF">pdf</a>, <a href="/format/2312.17675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending simple monotone drawings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kyn%C4%8Dl%2C+J">Jan Kyn&#x10d;l</a>, 
<a href="/search/math?searchtype=author&query=Soukup%2C+J">Jan Soukup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We prove the following variant of Levi's Enlargement Lemma: for an arbitrary
arrangement $\mathcal{A}$ of $x$-monotone pseudosegments in the plane and a
pair of points $a,b$ with distinct $x$-coordinates and not on the same
pseudosegment, there exists a simple $x$-monotone curve with endpoints $a,b$
that intersects every curve of $\mathcal{A}$ at most once. As a consequence,
every simple monotone drawing of a graph can be extended to a simple monotone
drawing of a complete graph. We also show that extending an arrangement of
cylindrically monotone pseudosegments is not always possible; in fact, the
corresponding decision problem is NP-hard.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon,  1 Jan 24</h3>
<dl>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1605.00167" title="Abstract">arXiv:1605.00167</a> (replaced) [<a href="/e-print/1605.00167" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating Nash Equilibrium Via Multilinear Minimax
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalantari%2C+B">Bahman Kalantari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Error in correct relationship between minimax and maximin. superseded by <a href="/abs/1809.01717">arXiv:1809.01717v3</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1803.00679" title="Abstract">arXiv:1803.00679</a> (replaced) [<a href="/pdf/1803.00679" title="Download PDF">pdf</a>, <a href="/format/1803.00679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrices with Gaussian noise: optimal estimates for singular subspace  perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=O%27Rourke%2C+S">Sean O&#x27;Rourke</a>, 
<a href="/search/stat?searchtype=author&query=Vu%2C+V">Van Vu</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+K">Ke Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final version. Accepted by IEEE Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1809.01717" title="Abstract">arXiv:1809.01717</a> (replaced) [<a href="/pdf/1809.01717" title="Download PDF">pdf</a>, <a href="/ps/1809.01717" title="Download PostScript">ps</a>, <a href="/format/1809.01717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating Bimatrix Nash Equilibrium Via Trilinear Minimax
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalantari%2C+B">Bahman Kalantari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures, This version corrects an error in the relationship between minimax and maximin. supersedes <a href="/abs/1605.00167">arXiv:1605.00167</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.12251" title="Abstract">arXiv:2002.12251</a> (replaced) [<a href="/e-print/2002.12251" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Finding Tangles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Firman%2C+O">Oksana Firman</a>, 
<a href="/search/cs?searchtype=author&query=Kindermann%2C+P">Philipp Kindermann</a>, 
<a href="/search/cs?searchtype=author&query=Klemz%2C+B">Boris Klemz</a>, 
<a href="/search/cs?searchtype=author&query=Ravsky%2C+A">Alexander Ravsky</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+A">Alexander Wolff</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+J">Johannes Zink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been superseded by <a href="/abs/2312.16213">arXiv:2312.16213</a> (merged from <a href="/abs/1901.06548">arXiv:1901.06548</a> and this paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.11598" title="Abstract">arXiv:2105.11598</a> (replaced) [<a href="/pdf/2105.11598" title="Download PDF">pdf</a>, <a href="/format/2105.11598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Space Exploration For Planning Initial Benthic AUV Surveys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shields%2C+J">Jackson Shields</a>, 
<a href="/search/cs?searchtype=author&query=Pizarro%2C+O">Oscar Pizarro</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+S+B">Stefan B. Williams</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Field Robotics (2023), 3, 652-686
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.03585" title="Abstract">arXiv:2110.03585</a> (replaced) [<a href="/pdf/2110.03585" title="Download PDF">pdf</a>, <a href="/format/2110.03585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Charge or to Sell? EV Pack Useful Life Estimation via LSTMs, CNNs,  and Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bosello%2C+M">Michael Bosello</a>, 
<a href="/search/cs?searchtype=author&query=Falcomer%2C+C">Carlo Falcomer</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+C">Claudio Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Pau%2C+G">Giovanni Pau</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Energies. 2023; 16(6):2837
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.13369" title="Abstract">arXiv:2110.13369</a> (replaced) [<a href="/pdf/2110.13369" title="Download PDF">pdf</a>, <a href="/format/2110.13369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Order in Chaos: Consensus on Feature Attributions in the  Rashomon Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laberge%2C+G">Gabriel Laberge</a>, 
<a href="/search/cs?searchtype=author&query=Pequignot%2C+Y">Yann Pequignot</a>, 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+A">Alexandre Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Khomh%2C+F">Foutse Khomh</a>, 
<a href="/search/cs?searchtype=author&query=Marchand%2C+M">Mario Marchand</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research, 2023, vol. 24, no 364, p.
  1-50
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.13646" title="Abstract">arXiv:2111.13646</a> (replaced) [<a href="/pdf/2111.13646" title="Download PDF">pdf</a>, <a href="/ps/2111.13646" title="Download PostScript">ps</a>, <a href="/format/2111.13646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimension Reduction with Prior Information for Knowledge Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bui%2C+A+T">Anh Tuan Bui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Article accepted for publication in IEEE Transactions on Pattern Analysis and Machine Intelligence, 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.02220" title="Abstract">arXiv:2112.02220</a> (replaced) [<a href="/pdf/2112.02220" title="Download PDF">pdf</a>, <a href="/format/2112.02220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capacity Results for Multiple-Input Multiple-Output Optical Wireless  Communication With Per-Antenna Intensity Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ru-Han Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jia-Ning Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.02057" title="Abstract">arXiv:2202.02057</a> (replaced) [<a href="/pdf/2202.02057" title="Download PDF">pdf</a>, <a href="/format/2202.02057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grid-Forming and Spatially Distributed Control Design of Dynamic Virtual  Power Plants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=H%C3%A4berle%2C+V">Verena H&#xe4;berle</a>, 
<a href="/search/eess?searchtype=author&query=Tayyebi%2C+A">Ali Tayyebi</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+X">Xiuqiang He</a>, 
<a href="/search/eess?searchtype=author&query=Prieto-Araujo%2C+E">Eduardo Prieto-Araujo</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.08579" title="Abstract">arXiv:2203.08579</a> (replaced) [<a href="/pdf/2203.08579" title="Download PDF">pdf</a>, <a href="/format/2203.08579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Oversampling in RBF Least-Squares Collocation Method of Lines  for Surface Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+M">Meng Chen</a>, 
<a href="/search/math?searchtype=author&query=Ling%2C+L">Leevan Ling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.11444" title="Abstract">arXiv:2204.11444</a> (replaced) [<a href="/pdf/2204.11444" title="Download PDF">pdf</a>, <a href="/format/2204.11444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Pruned Networks with Linear Over-parameterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yu Qian</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoshuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hufei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jue Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.10019" title="Abstract">arXiv:2205.10019</a> (replaced) [<a href="/pdf/2205.10019" title="Download PDF">pdf</a>, <a href="/format/2205.10019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Translating Hanja Historical Documents to Contemporary Korean and  English
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Son%2C+J">Juhee Son</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiho Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+H">Haneul Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Bak%2C+J">JinYeong Bak</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+A">Alice Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP Findings 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11152" title="Abstract">arXiv:2205.11152</a> (replaced) [<a href="/pdf/2205.11152" title="Download PDF">pdf</a>, <a href="/format/2205.11152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-lingual Lifelong Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%27hamdi%2C+M">Meryem M&#x27;hamdi</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=May%2C+J">Jonathan May</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-Ready Version of this paper published at ACL 2023 (<a href="https://aclanthology.org/2023.acl-long.217/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11638" title="Abstract">arXiv:2205.11638</a> (replaced) [<a href="/pdf/2205.11638" title="Download PDF">pdf</a>, <a href="/format/2205.11638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DOGE-Train: Discrete Optimization on GPU with End-to-end Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbas%2C+A">Ahmed Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Swoboda%2C+P">Paul Swoboda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. Alert before printing: pg. 16-20 only contain per instance results, can possibly be skipped
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.05767" title="Abstract">arXiv:2208.05767</a> (replaced) [<a href="/pdf/2208.05767" title="Download PDF">pdf</a>, <a href="/format/2208.05767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Model-Based Offline Reinforcement Learning with  Near-Optimal Sample Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Laixi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Y">Yuejie Chi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04648" title="Abstract">arXiv:2209.04648</a> (replaced) [<a href="/pdf/2209.04648" title="Download PDF">pdf</a>, <a href="/format/2209.04648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoreDeep: Improving Crack Detection Algorithms Using Width Stochasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+R+K">Ram Krishna Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Achara%2C+A">Akshit Achara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08298" title="Abstract">arXiv:2210.08298</a> (replaced) [<a href="/pdf/2210.08298" title="Download PDF">pdf</a>, <a href="/ps/2210.08298" title="Download PostScript">ps</a>, <a href="/format/2210.08298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Myhill-Nerode Theorem for Higher-Dimensional Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fahrenberg%2C+U">Uli Fahrenberg</a>, 
<a href="/search/cs?searchtype=author&query=Ziemia%C5%84ski%2C+K">Krzysztof Ziemia&#x144;ski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13785" title="Abstract">arXiv:2210.13785</a> (replaced) [<a href="/pdf/2210.13785" title="Download PDF">pdf</a>, <a href="/format/2210.13785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Estimating the Bayes Rule for Gaussian Mixture Models with a  Specified Missing-Data Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lyu%2C+Z">Ziyang Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16257" title="Abstract">arXiv:2210.16257</a> (replaced) [<a href="/pdf/2210.16257" title="Download PDF">pdf</a>, <a href="/format/2210.16257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Math Word Problems via Cooperative Reasoning induced Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+R">Ruyi Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACL 2023 Main Conference; Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01032" title="Abstract">arXiv:2211.01032</a> (replaced) [<a href="/pdf/2211.01032" title="Download PDF">pdf</a>, <a href="/format/2211.01032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Embeddings of Graphs: The Expected Number of Faces in Most Graphs  is Logarithmic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Loth%2C+J+C">Jesse Campion Loth</a>, 
<a href="/search/math?searchtype=author&query=Halasz%2C+K">Kevin Halasz</a>, 
<a href="/search/math?searchtype=author&query=Masa%C5%99%C3%ADk%2C+T">Tom&#xe1;&#x161; Masa&#x159;&#xed;k</a>, 
<a href="/search/math?searchtype=author&query=Mohar%2C+B">Bojan Mohar</a>, 
<a href="/search/math?searchtype=author&query=%C5%A0%C3%A1mal%2C+R">Robert &#x160;&#xe1;mal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 35th ACM-SIAM Symposium on Discrete Algorithms (SODA 2024). 55 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03131" title="Abstract">arXiv:2212.03131</a> (replaced) [<a href="/pdf/2212.03131" title="Download PDF">pdf</a>, <a href="/format/2212.03131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainability as statistical inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Senetaire%2C+H+H+J">Hugo Henri Joseph Senetaire</a>, 
<a href="/search/cs?searchtype=author&query=Garreau%2C+D">Damien Garreau</a>, 
<a href="/search/cs?searchtype=author&query=Frellsen%2C+J">Jes Frellsen</a>, 
<a href="/search/cs?searchtype=author&query=Mattei%2C+P">Pierre-Alexandre Mattei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 22 figures, published at ICLR 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40th International Conference on Machine
  Learning, PMLR 202:30584-30612, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05081" title="Abstract">arXiv:2212.05081</a> (replaced) [<a href="/pdf/2212.05081" title="Download PDF">pdf</a>, <a href="/format/2212.05081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAIR AI Models in High Energy Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Duarte%2C+J">Javier Duarte</a>, 
<a href="/search/hep-ex?searchtype=author&query=Li%2C+H">Haoyang Li</a>, 
<a href="/search/hep-ex?searchtype=author&query=Roy%2C+A">Avik Roy</a>, 
<a href="/search/hep-ex?searchtype=author&query=Zhu%2C+R">Ruike Zhu</a>, 
<a href="/search/hep-ex?searchtype=author&query=Huerta%2C+E+A">E. A. Huerta</a>, 
<a href="/search/hep-ex?searchtype=author&query=Diaz%2C+D">Daniel Diaz</a>, 
<a href="/search/hep-ex?searchtype=author&query=Harris%2C+P">Philip Harris</a>, 
<a href="/search/hep-ex?searchtype=author&query=Kansal%2C+R">Raghav Kansal</a>, 
<a href="/search/hep-ex?searchtype=author&query=Katz%2C+D+S">Daniel S. Katz</a>, 
<a href="/search/hep-ex?searchtype=author&query=Kavoori%2C+I+H">Ishaan H. Kavoori</a>, 
<a href="/search/hep-ex?searchtype=author&query=Kindratenko%2C+V+V">Volodymyr V. Kindratenko</a>, 
<a href="/search/hep-ex?searchtype=author&query=Mokhtar%2C+F">Farouk Mokhtar</a>, 
<a href="/search/hep-ex?searchtype=author&query=Neubauer%2C+M+S">Mark S. Neubauer</a>, 
<a href="/search/hep-ex?searchtype=author&query=Park%2C+S+E">Sang Eon Park</a>, 
<a href="/search/hep-ex?searchtype=author&query=Quinnan%2C+M">Melissa Quinnan</a>, 
<a href="/search/hep-ex?searchtype=author&query=Rusack%2C+R">Roger Rusack</a>, 
<a href="/search/hep-ex?searchtype=author&query=Zhao%2C+Z">Zhizhen Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 figures, 10 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mach. Learn.: Sci. Technol. 4 (2023) 045062
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09611" title="Abstract">arXiv:2212.09611</a> (replaced) [<a href="/pdf/2212.09611" title="Download PDF">pdf</a>, <a href="/format/2212.09611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Prompts for Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yaru Hao</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Z">Zewen Chi</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Li Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS-23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11247" title="Abstract">arXiv:2212.11247</a> (replaced) [<a href="/pdf/2212.11247" title="Download PDF">pdf</a>, <a href="/format/2212.11247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Count-Free Weisfeiler--Leman and Group Isomorphism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collins%2C+N+A">Nathaniel A. Collins</a>, 
<a href="/search/cs?searchtype=author&query=Levet%2C+M">Michael Levet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2112.11487">arXiv:2112.11487</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Logic in Computer Science (cs.LO); Group Theory (math.GR)

</div>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09456" title="Abstract">arXiv:2302.09456</a> (replaced) [<a href="/pdf/2302.09456" title="Download PDF">pdf</a>, <a href="/format/2302.09456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Offline Policy Evaluation with Predictive Error  Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Runzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Uehara%2C+M">Masatoshi Uehara</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wen Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03983" title="Abstract">arXiv:2303.03983</a> (replaced) [<a href="/pdf/2303.03983" title="Download PDF">pdf</a>, <a href="/ps/2303.03983" title="Download PostScript">ps</a>, <a href="/format/2303.03983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-World Choreographic Programming: Full-Duplex Asynchrony and  Interoperability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lugovi%C4%87%2C+L">Lovro Lugovi&#x107;</a> (University of Southern Denmark, Denmark), 
<a href="/search/cs?searchtype=author&query=Montesi%2C+F">Fabrizio Montesi</a> (University of Southern Denmark, Denmark)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 2, Article 8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10442" title="Abstract">arXiv:2304.10442</a> (replaced) [<a href="/pdf/2304.10442" title="Download PDF">pdf</a>, <a href="/format/2304.10442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing Neural Networks with Knapsack Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorski%2C+Y">Yakir Gorski</a>, 
<a href="/search/cs?searchtype=author&query=Jevnisek%2C+A">Amir Jevnisek</a>, 
<a href="/search/cs?searchtype=author&query=Avidan%2C+S">Shai Avidan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10658" title="Abstract">arXiv:2304.10658</a> (replaced) [<a href="/pdf/2304.10658" title="Download PDF">pdf</a>, <a href="/format/2304.10658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear to multi-linear algebra and systems using tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pandey%2C+D">Divyanshu Pandey</a>, 
<a href="/search/eess?searchtype=author&query=Venugopal%2C+A">Adithya Venugopal</a>, 
<a href="/search/eess?searchtype=author&query=Leib%2C+H">Harry Leib</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08892" title="Abstract">arXiv:2305.08892</a> (replaced) [<a href="/pdf/2305.08892" title="Download PDF">pdf</a>, <a href="/format/2305.08892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Photonic Reservoir Computer Based on Frequency Multiplexing with  Fully Analog Connection Between Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lupo%2C+A">Alessandro Lupo</a>, 
<a href="/search/cs?searchtype=author&query=Picco%2C+E">Enrico Picco</a>, 
<a href="/search/cs?searchtype=author&query=Zajnulina%2C+M">Marina Zajnulina</a>, 
<a href="/search/cs?searchtype=author&query=Massar%2C+S">Serge Massar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Optica 10, 1478-1485 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Applied Physics (physics.app-ph); Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19505" title="Abstract">arXiv:2305.19505</a> (replaced) [<a href="/pdf/2305.19505" title="Download PDF">pdf</a>, <a href="/format/2305.19505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M3ICRO: Machine Learning-Enabled Compact Photonic Tensor Core based on  PRogrammable Multi-Operand Multimode Interference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiaqi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chenghao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zixuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R+T">Ray T. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+D+Z">David Z. Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages. Accepted to APL Machine Learning 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Machine Learning (cs.LG); Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00037" title="Abstract">arXiv:2306.00037</a> (replaced) [<a href="/pdf/2306.00037" title="Download PDF">pdf</a>, <a href="/format/2306.00037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BotArtist: Twitter bot detection Machine Learning model based on Twitter  suspension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shevtsov%2C+A">Alexander Shevtsov</a>, 
<a href="/search/cs?searchtype=author&query=Antonakaki%2C+D">Despoina Antonakaki</a>, 
<a href="/search/cs?searchtype=author&query=Lamprou%2C+I">Ioannis Lamprou</a>, 
<a href="/search/cs?searchtype=author&query=Pratikakis%2C+P">Polyvios Pratikakis</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+S">Sotiris Ioannidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00355" title="Abstract">arXiv:2306.00355</a> (replaced) [<a href="/pdf/2306.00355" title="Download PDF">pdf</a>, <a href="/format/2306.00355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CERT: Finding Performance Issues in Database Systems Through the Lens of  Cardinality Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ba%2C+J">Jinsheng Ba</a>, 
<a href="/search/cs?searchtype=author&query=Rigger%2C+M">Manuel Rigger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 46th International Conference on Software Engineering (ICSE'24), Lisbon, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04712" title="Abstract">arXiv:2306.04712</a> (replaced) [<a href="/pdf/2306.04712" title="Download PDF">pdf</a>, <a href="/format/2306.04712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Earth Mover&#x27;s Distance for Data Compression at the  High-Luminosity LHC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Shenoy%2C+R">Rohan Shenoy</a>, 
<a href="/search/hep-ex?searchtype=author&query=Duarte%2C+J">Javier Duarte</a>, 
<a href="/search/hep-ex?searchtype=author&query=Herwig%2C+C">Christian Herwig</a>, 
<a href="/search/hep-ex?searchtype=author&query=Hirschauer%2C+J">James Hirschauer</a>, 
<a href="/search/hep-ex?searchtype=author&query=Noonan%2C+D">Daniel Noonan</a>, 
<a href="/search/hep-ex?searchtype=author&query=Pierini%2C+M">Maurizio Pierini</a>, 
<a href="/search/hep-ex?searchtype=author&query=Tran%2C+N">Nhan Tran</a>, 
<a href="/search/hep-ex?searchtype=author&query=Suarez%2C+C+M">Cristina Mantilla Suarez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mach. Learn.: Sci. Technol. 4 (2023) 045058
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); Instrumentation and Detectors (physics.ins-det)

</div>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06391" title="Abstract">arXiv:2306.06391</a> (replaced) [<a href="/pdf/2306.06391" title="Download PDF">pdf</a>, <a href="/ps/2306.06391" title="Download PostScript">ps</a>, <a href="/format/2306.06391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Design Principles of the Elixir Type System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castagna%2C+G">Giuseppe Castagna</a> (IRIF - Universit&#xe9; Paris Cit&#xe9; - CNRS, France), 
<a href="/search/cs?searchtype=author&query=Duboc%2C+G">Guillaume Duboc</a> (IRIF - Universit&#xe9; Paris Cit&#xe9; - CNRS, France / Remote Technology, France), 
<a href="/search/cs?searchtype=author&query=Valim%2C+J">Jos&#xe9; Valim</a> (Dashbit, Poland)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 2, Article 4
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06791" title="Abstract">arXiv:2306.06791</a> (replaced) [<a href="/pdf/2306.06791" title="Download PDF">pdf</a>, <a href="/format/2306.06791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Save Mobile Crowdsourcing from Cheap-talk: A Game Theoretic Learning  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+S">Shugang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+L">Lingjie Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06874" title="Abstract">arXiv:2306.06874</a> (replaced) [<a href="/pdf/2306.06874" title="Download PDF">pdf</a>, <a href="/format/2306.06874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chou%2C+S">Sheng-Yen Chou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+T">Tsung-Yi Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023, NeurIPS 2023 BUGS Workshop Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09012" title="Abstract">arXiv:2306.09012</a> (replaced) [<a href="/pdf/2306.09012" title="Download PDF">pdf</a>, <a href="/format/2306.09012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Yes, we CANN: Constrained Approximate Nearest Neighbors for local  feature-based visual localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aiger%2C+D">Dror Aiger</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+A">Andr&#xe9; Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Lynen%2C+S">Simon Lynen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV23 camera-ready + appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11980" title="Abstract">arXiv:2306.11980</a> (replaced) [<a href="/pdf/2306.11980" title="Download PDF">pdf</a>, <a href="/format/2306.11980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-based Smart Reply (LSR): Enhancing Collaborative Performance with  ChatGPT-mediated Smart Reply System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bastola%2C+A">Ashish Bastola</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hembree%2C+J">Judsen Hembree</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+P">Pooja Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+E">Emma Dixon</a>, 
<a href="/search/cs?searchtype=author&query=Razi%2C+A">Abolfazl Razi</a>, 
<a href="/search/cs?searchtype=author&query=McNeese%2C+N">Nathan McNeese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12073" title="Abstract">arXiv:2306.12073</a> (replaced) [<a href="/pdf/2306.12073" title="Download PDF">pdf</a>, <a href="/format/2306.12073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroCLIP: Neuromorphic Data Understanding by CLIP and SNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yufei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhe Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12183" title="Abstract">arXiv:2306.12183</a> (replaced) [<a href="/pdf/2306.12183" title="Download PDF">pdf</a>, <a href="/ps/2306.12183" title="Download PostScript">ps</a>, <a href="/format/2306.12183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crouzeix&#x27;s conjecture for classes of matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=O%27Loughlin%2C+R">Ryan O&#x27;Loughlin</a>, 
<a href="/search/math?searchtype=author&query=Virtanen%2C+J">Jani Virtanen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06166" title="Abstract">arXiv:2307.06166</a> (replaced) [<a href="/pdf/2307.06166" title="Download PDF">pdf</a>, <a href="/format/2307.06166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Vision-Language Models be a Good Guesser? Exploring VLMs for Times  and Location Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gengyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yurui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kerui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07227" title="Abstract">arXiv:2307.07227</a> (replaced) [<a href="/pdf/2307.07227" title="Download PDF">pdf</a>, <a href="/ps/2307.07227" title="Download PostScript">ps</a>, <a href="/format/2307.07227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Short-Packet Communications via UAV-Enabled Mobile Relaying:  Joint Resource Optimization and 3D Trajectory Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mamaghani%2C+M+T">Milad Tatar Mamaghani</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiangyun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Swindlehurst%2C+A+L">A. Lee Swindlehurst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 double-column pages, 8 figures. To appear in IEEE Transactions on Wireless Communications. This is an extended version of our work presented at the 2023 IEEE GlobeCom <a href="/abs/2310.05142">arXiv:2310.05142</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08866" title="Abstract">arXiv:2307.08866</a> (replaced) [<a href="/pdf/2307.08866" title="Download PDF">pdf</a>, <a href="/format/2307.08866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Data-Driven Prediction in a Building Control Hierarchy: A Case  Study of Demand Response in Switzerland
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shi%2C+J">Jicheng Shi</a>, 
<a href="/search/eess?searchtype=author&query=Lian%2C+Y">Yingzhao Lian</a>, 
<a href="/search/eess?searchtype=author&query=Salzmann%2C+C">Christophe Salzmann</a>, 
<a href="/search/eess?searchtype=author&query=Jones%2C+C+N">Colin N. Jones</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09822" title="Abstract">arXiv:2307.09822</a> (replaced) [<a href="/pdf/2307.09822" title="Download PDF">pdf</a>, <a href="/format/2307.09822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Siamese-based Verification System for Open-set Architecture  Attribution of Synthetic Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abady%2C+L">Lydia Abady</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tondi%2C+B">Benedetta Tondi</a>, 
<a href="/search/cs?searchtype=author&query=Barni%2C+M">Mauro Barni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01566" title="Abstract">arXiv:2308.01566</a> (replaced) [<a href="/pdf/2308.01566" title="Download PDF">pdf</a>, <a href="/format/2308.01566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Slate Policy Optimization: Going Beyond Plackett-Luce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakhi%2C+O">Otmane Sakhi</a>, 
<a href="/search/cs?searchtype=author&query=Rohde%2C+D">David Rohde</a>, 
<a href="/search/cs?searchtype=author&query=Chopin%2C+N">Nicolas Chopin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Transactions on Machine Learning Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02946" title="Abstract">arXiv:2308.02946</a> (replaced) [<a href="/e-print/2308.02946" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the expected efficiency of branch and bound for the asymmetric TSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frieze%2C+A">Alan Frieze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There is a bug in the proof of Lemma 9
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03580" title="Abstract">arXiv:2308.03580</a> (replaced) [<a href="/pdf/2308.03580" title="Download PDF">pdf</a>, <a href="/format/2308.03580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing the Underlying Patterns: Investigating Dataset Similarity,  Performance, and Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Achara%2C+A">Akshit Achara</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+R+K">Ram Krishna Pandey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06605" title="Abstract">arXiv:2308.06605</a> (replaced) [<a href="/pdf/2308.06605" title="Download PDF">pdf</a>, <a href="/format/2308.06605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Exascale Computation for Turbomachinery Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuhang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weiqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiahuan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guangwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jifa Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tingwei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+F">Fangfang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xiaojing Lv</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanyue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiaoyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+G">Guocheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tucker%2C+P">Paul Tucker</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+S+A+E">Steven A.E. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shirui Luo</a>, 
<a href="/search/cs?searchtype=author&query=Koric%2C+S">Seid Koric</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weimin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SC23, November, 2023, Denver, CO., USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08806" title="Abstract">arXiv:2308.08806</a> (replaced) [<a href="/pdf/2308.08806" title="Download PDF">pdf</a>, <a href="/format/2308.08806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-distillation Regularized Connectionist Temporal Classification Loss  for Text Recognition: A Simple Yet Effective Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+N">Ning Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+M">Minghui Liao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongshuai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Min Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ziyin Zhang and Ning Lu are co-first authors. Accepted by AAAI2024. Repo: <a href="https://github.com/zzyhlyoko/DCTC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11234" title="Abstract">arXiv:2308.11234</a> (replaced) [<a href="/pdf/2308.11234" title="Download PDF">pdf</a>, <a href="/format/2308.11234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Harabor%2C+D">Daniel Harabor</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Stuckey%2C+P+J">Peter J. Stuckey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper was accepted for publication at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12880" title="Abstract">arXiv:2308.12880</a> (replaced) [<a href="/pdf/2308.12880" title="Download PDF">pdf</a>, <a href="/format/2308.12880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-stage feature decorrelation constraints for improving CNN  classification performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qiuyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zu%2C+X">Xuewen Zu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengfei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14840" title="Abstract">arXiv:2308.14840</a> (replaced) [<a href="/pdf/2308.14840" title="Download PDF">pdf</a>, <a href="/format/2308.14840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying and Mitigating the Security Risks of Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barrett%2C+C">Clark Barrett</a>, 
<a href="/search/cs?searchtype=author&query=Boyd%2C+B">Brad Boyd</a>, 
<a href="/search/cs?searchtype=author&query=Burzstein%2C+E">Elie Burzstein</a>, 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Brad Chen</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jihye Choi</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+A+R">Amrita Roy Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Christodorescu%2C+M">Mihai Christodorescu</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+A">Anupam Datta</a>, 
<a href="/search/cs?searchtype=author&query=Feizi%2C+S">Soheil Feizi</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+K">Kathleen Fisher</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T">Tatsunori Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Hendrycks%2C+D">Dan Hendrycks</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Somesh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Daniel Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kerschbaum%2C+F">Florian Kerschbaum</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+E">Eric Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+J">John Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Ramzan%2C+Z">Zulfikar Ramzan</a>, 
<a href="/search/cs?searchtype=author&query=Shams%2C+K">Khawaja Shams</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>, 
<a href="/search/cs?searchtype=author&query=Taly%2C+A">Ankur Taly</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diyi Yang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Foundations and Trends in Privacy and Security 6 (2023) 1-52
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00361" title="Abstract">arXiv:2309.00361</a> (replaced) [<a href="/pdf/2309.00361" title="Download PDF">pdf</a>, <a href="/ps/2309.00361" title="Download PostScript">ps</a>, <a href="/format/2309.00361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified and Scalable Algorithm Framework of User-Defined Temporal  $(k,\mathcal{X})$-Core Query
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Ming Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junyong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuanyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+T">Tieyun Qian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengchi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J+X">Jeffrey Xu Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2301.03770">arXiv:2301.03770</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02609" title="Abstract">arXiv:2309.02609</a> (replaced) [<a href="/pdf/2309.02609" title="Download PDF">pdf</a>, <a href="/format/2309.02609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directionality-Aware Mixture Model Parallel Sampling for Efficient  Linear Parameter Varying Dynamical System Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sunan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Haihui Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Figueroa%2C+N">Nadia Figueroa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08153" title="Abstract">arXiv:2309.08153</a> (replaced) [<a href="/pdf/2309.08153" title="Download PDF">pdf</a>, <a href="/format/2309.08153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tune the pretrained ATST model for sound event detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shao%2C+N">Nian Shao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xian Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaofei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, camera-ready version for ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15293" title="Abstract">arXiv:2309.15293</a> (replaced) [<a href="/pdf/2309.15293" title="Download PDF">pdf</a>, <a href="/format/2309.15293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum diffusion reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berrueta%2C+T+A">Thomas A. Berrueta</a>, 
<a href="/search/cs?searchtype=author&query=Pinosky%2C+A">Allison Pinosky</a>, 
<a href="/search/cs?searchtype=author&query=Murphey%2C+T+D">Todd D. Murphey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The PDF file contains the collated main text and supplementary information. For supplementary movies, see <a href="https://www.youtube.com/playlist?list=PLO5AGPa3klrCTSO-t7HZsVNQinHXFQmn9">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15427" title="Abstract">arXiv:2309.15427</a> (replaced) [<a href="/pdf/2309.15427" title="Download PDF">pdf</a>, <a href="/format/2309.15427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Prompting with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yijun Tian</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Huan Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ziqing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Panpan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15792" title="Abstract">arXiv:2309.15792</a> (replaced) [<a href="/pdf/2309.15792" title="Download PDF">pdf</a>, <a href="/format/2309.15792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Block-Matching Algorithm using Dissimilarity Measure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Mart%C3%ADnez-Felipe%2C+M">M. Mart&#xed;nez-Felipe</a>, 
<a href="/search/quant-ph?searchtype=author&query=Montiel-P%C3%A9rez%2C+J">J. Montiel-P&#xe9;rez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Onofre%2C+V">V. Onofre</a>, 
<a href="/search/quant-ph?searchtype=author&query=Maldonado-Romo%2C+A">A. Maldonado-Romo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Young%2C+R">Ricky Young</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00426" title="Abstract">arXiv:2310.00426</a> (replaced) [<a href="/pdf/2310.00426" title="Download PDF">pdf</a>, <a href="/format/2310.00426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PixArt-$&#x3b1;$: Fast Training of Diffusion Transformer for  Photorealistic Text-to-Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junsong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jincheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chongjian Ge</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lewei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongdao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+J">James Kwok</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://pixart-alpha.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04693" title="Abstract">arXiv:2310.04693</a> (replaced) [<a href="/pdf/2310.04693" title="Download PDF">pdf</a>, <a href="/format/2310.04693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness-enhanced Uplift Modeling with Adversarial Feature  Desensitization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zexu Sun</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bowei He</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Ming Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiakai Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dugang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04706" title="Abstract">arXiv:2310.04706</a> (replaced) [<a href="/pdf/2310.04706" title="Download PDF">pdf</a>, <a href="/format/2310.04706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Imitation Learning with Variational Counterfactual Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bowei He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zexu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chen Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06958" title="Abstract">arXiv:2310.06958</a> (replaced) [<a href="/pdf/2310.06958" title="Download PDF">pdf</a>, <a href="/format/2310.06958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing the robustness of modern no-reference image- and video-quality  metrics to adversarial attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antsiferova%2C+A">Anastasia Antsiferova</a>, 
<a href="/search/cs?searchtype=author&query=Abud%2C+K">Khaled Abud</a>, 
<a href="/search/cs?searchtype=author&query=Gushchin%2C+A">Aleksandr Gushchin</a>, 
<a href="/search/cs?searchtype=author&query=Shumitskaya%2C+E">Ekaterina Shumitskaya</a>, 
<a href="/search/cs?searchtype=author&query=Lavrushkin%2C+S">Sergey Lavrushkin</a>, 
<a href="/search/cs?searchtype=author&query=Vatolin%2C+D">Dmitriy Vatolin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09336" title="Abstract">arXiv:2310.09336</a> (replaced) [<a href="/pdf/2310.09336" title="Download PDF">pdf</a>, <a href="/format/2310.09336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Abilities Emerge Multiplicatively: Exploring Diffusion  Models on a Synthetic Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Okawa%2C+M">Maya Okawa</a>, 
<a href="/search/cs?searchtype=author&query=Lubana%2C+E+S">Ekdeep Singh Lubana</a>, 
<a href="/search/cs?searchtype=author&query=Dick%2C+R+P">Robert P. Dick</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+H">Hidenori Tanaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10483" title="Abstract">arXiv:2310.10483</a> (replaced) [<a href="/pdf/2310.10483" title="Download PDF">pdf</a>, <a href="/format/2310.10483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passive Inference Attacks on Split Learning via Adversarial  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaochen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xinjian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuncheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yangfan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiaokui Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ooi%2C+B+C">Beng Chin Ooi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12732" title="Abstract">arXiv:2310.12732</a> (replaced) [<a href="/pdf/2310.12732" title="Download PDF">pdf</a>, <a href="/ps/2310.12732" title="Download PostScript">ps</a>, <a href="/format/2310.12732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming the compression limit of the individualsequence (zero order  empirical entropy) using the Set Shaping Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koch%2C+A">Aida Koch</a>, 
<a href="/search/cs?searchtype=author&query=Petit%2C+A">Alix Petit</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+C">Christian Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Vdberg%2C+A">Adrain Vdberg</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+L">Logan Lewis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15400" title="Abstract">arXiv:2310.15400</a> (replaced) [<a href="/pdf/2310.15400" title="Download PDF">pdf</a>, <a href="/format/2310.15400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A practical approach to computing Lyapunov exponents of renewal and  delay equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Breda%2C+D">Dimitri Breda</a>, 
<a href="/search/math?searchtype=author&query=Liessi%2C+D">Davide Liessi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematical Biosciences and Engineering 21:1 (2024), pp.
  1249-1269
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15959" title="Abstract">arXiv:2310.15959</a> (replaced) [<a href="/pdf/2310.15959" title="Download PDF">pdf</a>, <a href="/format/2310.15959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoteChat: A Dataset of Synthetic Doctor-Patient Conversations  Conditioned on Clinical Notes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zonghai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huixue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rumeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yucheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16210" title="Abstract">arXiv:2310.16210</a> (replaced) [<a href="/pdf/2310.16210" title="Download PDF">pdf</a>, <a href="/format/2310.16210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sea-Land-Cloud Segmentation in Satellite Hyperspectral Imagery by Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Justo%2C+J+A">Jon Alvarez Justo</a>, 
<a href="/search/cs?searchtype=author&query=Garrett%2C+J+L">Joseph L. Garrett</a>, 
<a href="/search/cs?searchtype=author&query=Georgescu%2C+M">Mariana-Iuliana Georgescu</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Llorente%2C+J">Jesus Gonzalez-Llorente</a>, 
<a href="/search/cs?searchtype=author&query=Ionescu%2C+R+T">Radu Tudor Ionescu</a>, 
<a href="/search/cs?searchtype=author&query=Johansen%2C+T+A">Tor Arne Johansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Remote Sensing, Satellite Imagery, Hyperspectral Imaging, Deep Learning, Segmentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16379" title="Abstract">arXiv:2310.16379</a> (replaced) [<a href="/pdf/2310.16379" title="Download PDF">pdf</a>, <a href="/format/2310.16379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating General-Purpose AI with Psychometrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Liming Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez-Orallo%2C+J">Jose Hernandez-Orallo</a>, 
<a href="/search/cs?searchtype=author&query=Stillwell%2C+D">David Stillwell</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Luning Sun</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17189" title="Abstract">arXiv:2310.17189</a> (replaced) [<a href="/pdf/2310.17189" title="Download PDF">pdf</a>, <a href="/format/2310.17189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Iterative Refinement with Diffusion Models for Video Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+T">Tao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaoyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+T">Te Tao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shao-Lun Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17878" title="Abstract">arXiv:2310.17878</a> (replaced) [<a href="/pdf/2310.17878" title="Download PDF">pdf</a>, <a href="/format/2310.17878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sublinear-Time Spectral Clustering Oracle with Improved Preprocessing  Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+R">Ranran Shen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Pan Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at NeurIPS'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18131" title="Abstract">arXiv:2310.18131</a> (replaced) [<a href="/pdf/2310.18131" title="Download PDF">pdf</a>, <a href="/format/2310.18131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Video Gaze Estimation via Capturing Head-face-eye  Spatial-temporal Interaction Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yiran Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenzheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguo Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yang Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by IEEE Signal Processing Letters. The code has been released at <a href="https://github.com/zgchen33/MCGaze">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01043" title="Abstract">arXiv:2311.01043</a> (replaced) [<a href="/pdf/2311.01043" title="Download PDF">pdf</a>, <a href="/format/2311.01043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4Drive: A Survey of Large Language Models for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaosong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> GitHub Repo: <a href="https://github.com/Thinklab-SJTU/Awesome-LLM4AD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02856" title="Abstract">arXiv:2311.02856</a> (replaced) [<a href="/pdf/2311.02856" title="Download PDF">pdf</a>, <a href="/ps/2311.02856" title="Download PostScript">ps</a>, <a href="/format/2311.02856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Hotplug Caching Schemes Using PDAs and t-Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajput%2C+C">Charul Rajput</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+B+S">B. Sundar Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Definition 5 has been made precise. 11 pages, no figures or tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04688" title="Abstract">arXiv:2311.04688</a> (replaced) [<a href="/pdf/2311.04688" title="Download PDF">pdf</a>, <a href="/format/2311.04688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Server Private Information Retrieval Protocols With Codes Over  Rings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodur%2C+%C5%9E">&#x15e;eyma Bodur</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Moro%2C+E">Edgar Mart&#xed;nez-Moro</a>, 
<a href="/search/cs?searchtype=author&query=Ruano%2C+D">Diego Ruano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05813" title="Abstract">arXiv:2311.05813</a> (replaced) [<a href="/pdf/2311.05813" title="Download PDF">pdf</a>, <a href="/format/2311.05813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feasibility Analysis and Regularity Characterization of Distributionally  Robust Safe Stabilizing Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mestres%2C+P">Pol Mestres</a>, 
<a href="/search/math?searchtype=author&query=Long%2C+K">Kehan Long</a>, 
<a href="/search/math?searchtype=author&query=Atanasov%2C+N">Nikolay Atanasov</a>, 
<a href="/search/math?searchtype=author&query=Cort%C3%A9s%2C+J">Jorge Cort&#xe9;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07027" title="Abstract">arXiv:2311.07027</a> (replaced) [<a href="/pdf/2311.07027" title="Download PDF">pdf</a>, <a href="/format/2311.07027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust softmax aggregation on blockchain based federated learning with  convergence guarantee
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huiyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07745" title="Abstract">arXiv:2311.07745</a> (replaced) [<a href="/pdf/2311.07745" title="Download PDF">pdf</a>, <a href="/format/2311.07745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplifying Complex Observation Models in Continuous POMDP Planning with  Probabilistic Guarantees and Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lev-Yehudi%2C+I">Idan Lev-Yehudi</a>, 
<a href="/search/cs?searchtype=author&query=Barenboim%2C+M">Moran Barenboim</a>, 
<a href="/search/cs?searchtype=author&query=Indelman%2C+V">Vadim Indelman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11443" title="Abstract">arXiv:2311.11443</a> (replaced) [<a href="/pdf/2311.11443" title="Download PDF">pdf</a>, <a href="/format/2311.11443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking Complete Finite Prefixes To High Level, Symbolically
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=W%C3%BCrdemann%2C+N">Nick W&#xfc;rdemann</a>, 
<a href="/search/cs?searchtype=author&query=Chatain%2C+T">Thomas Chatain</a>, 
<a href="/search/cs?searchtype=author&query=Haar%2C+S">Stefan Haar</a>, 
<a href="/search/cs?searchtype=author&query=Panneke%2C+L">Lukas Panneke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a revised and extended version of "Nick W\"urdemann, Thomas Chatain, Stefan Haar: Taking Complete Finite Prefixes to High Level, Symbolically. Petri Nets 2023: 123-144"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12475" title="Abstract">arXiv:2311.12475</a> (replaced) [<a href="/pdf/2311.12475" title="Download PDF">pdf</a>, <a href="/format/2311.12475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhayaThaiBERT: Enhancing a Pretrained Thai Language Model with  Unassimilated Loanwords
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sriwirote%2C+P">Panyut Sriwirote</a>, 
<a href="/search/cs?searchtype=author&query=Thapiang%2C+J">Jalinee Thapiang</a>, 
<a href="/search/cs?searchtype=author&query=Timtong%2C+V">Vasan Timtong</a>, 
<a href="/search/cs?searchtype=author&query=Rutherford%2C+A+T">Attapol T. Rutherford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> revised to fix formatting error, content unchanged
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15562" title="Abstract">arXiv:2311.15562</a> (replaced) [<a href="/pdf/2311.15562" title="Download PDF">pdf</a>, <a href="/format/2311.15562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Authentic Visual Question Answering Dataset from Online  Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chongyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Codella%2C+N">Noel Codella</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gurari%2C+D">Danna Gurari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17812" title="Abstract">arXiv:2311.17812</a> (replaced) [<a href="/pdf/2311.17812" title="Download PDF">pdf</a>, <a href="/format/2311.17812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAP: Domain-aware Prompt Learning for Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wansen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youkai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Quanjun Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages. arXiv admin note: substantial text overlap with <a href="/abs/2309.03661">arXiv:2309.03661</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18628" title="Abstract">arXiv:2311.18628</a> (replaced) [<a href="/pdf/2311.18628" title="Download PDF">pdf</a>, <a href="/format/2311.18628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight Clustering Framework for Unsupervised Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheung%2C+Y+S+J">Yau Shing Jonathan Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lihe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18829" title="Abstract">arXiv:2311.18829</a> (replaced) [<a href="/pdf/2311.18829" title="Download PDF">pdf</a>, <a href="/format/2311.18829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jianmin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+W">Wenming Weng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruoyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dacheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q+D+Z">Qi Dai Zhiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+K">Kai Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chuanxin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Baining Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://wangyanhui666.github.io/MicroCinema.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00028" title="Abstract">arXiv:2312.00028</a> (replaced) [<a href="/pdf/2312.00028" title="Download PDF">pdf</a>, <a href="/format/2312.00028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructive Representation of Functions in $N$-Dimensional Sobolev  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jagt%2C+D+S">Declan S. Jagt</a>, 
<a href="/search/math?searchtype=author&query=Peet%2C+M+M">Matthew M. Peet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01652" title="Abstract">arXiv:2312.01652</a> (replaced) [<a href="/pdf/2312.01652" title="Download PDF">pdf</a>, <a href="/format/2312.01652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Expressive Power of Behavior Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hangyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuhang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Changjun Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01728" title="Abstract">arXiv:2312.01728</a> (replaced) [<a href="/pdf/2312.01728" title="Download PDF">pdf</a>, <a href="/format/2312.01728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImputeFormer: Low Rankness-Induced Transformers for Generalizable  Spatiotemporal Imputation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+T">Tong Nie</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+G">Guoyang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yuewen Mei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02008" title="Abstract">arXiv:2312.02008</a> (replaced) [<a href="/pdf/2312.02008" title="Download PDF">pdf</a>, <a href="/format/2312.02008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Behavior Retrieval: Retrieval-Augmented Policy Training for  Cooperative Manipulation by Mobile Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuroki%2C+S">So Kuroki</a>, 
<a href="/search/cs?searchtype=author&query=Nishimura%2C+M">Mai Nishimura</a>, 
<a href="/search/cs?searchtype=author&query=Kozuno%2C+T">Tadashi Kozuno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03022" title="Abstract">arXiv:2312.03022</a> (replaced) [<a href="/pdf/2312.03022" title="Download PDF">pdf</a>, <a href="/format/2312.03022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph  Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hongbin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+H">Honghao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Aijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wei Hua</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+W">Weiqiang Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress; 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03644" title="Abstract">arXiv:2312.03644</a> (replaced) [<a href="/pdf/2312.03644" title="Download PDF">pdf</a>, <a href="/format/2312.03644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MACCA: Offline Multi-agent Reinforcement Learning with Causal Credit  Assignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yudi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Biwei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04772" title="Abstract">arXiv:2312.04772</a> (replaced) [<a href="/pdf/2312.04772" title="Download PDF">pdf</a>, <a href="/ps/2312.04772" title="Download PostScript">ps</a>, <a href="/format/2312.04772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remembering to Be Fair: On Non-Markovian Fairness in Sequential Decision  Making (Preliminary Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alamdari%2C+P+A">Parand A. Alamdari</a>, 
<a href="/search/cs?searchtype=author&query=Klassen%2C+T+Q">Toryn Q. Klassen</a>, 
<a href="/search/cs?searchtype=author&query=Creager%2C+E">Elliot Creager</a>, 
<a href="/search/cs?searchtype=author&query=McIlraith%2C+S+A">Sheila A. McIlraith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06172" title="Abstract">arXiv:2312.06172</a> (replaced) [<a href="/pdf/2312.06172" title="Download PDF">pdf</a>, <a href="/format/2312.06172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling SQL Query Hardness Parsing for Text-to-SQL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jiawen Yi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guo Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06261" title="Abstract">arXiv:2312.06261</a> (replaced) [<a href="/pdf/2312.06261" title="Download PDF">pdf</a>, <a href="/format/2312.06261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Foundation Models for Prognostics and Health Management in  Industrial Cyber-Physical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruonan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanhu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Te Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09085" title="Abstract">arXiv:2312.09085</a> (replaced) [<a href="/pdf/2312.09085" title="Download PDF">pdf</a>, <a href="/format/2312.09085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Earth is Flat because...: Investigating LLMs&#x27; Belief towards  Misinformation via Persuasive Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rongwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+S">Brian S. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shujian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weiyan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhixuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09395" title="Abstract">arXiv:2312.09395</a> (replaced) [<a href="/pdf/2312.09395" title="Download PDF">pdf</a>, <a href="/ps/2312.09395" title="Download PostScript">ps</a>, <a href="/format/2312.09395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Incorporating Researcher Safety into Information Integrity  Research Ethics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schafer%2C+J+S">Joseph S. Schafer</a>, 
<a href="/search/cs?searchtype=author&query=Starbird%2C+K">Kate Starbird</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, presented at the pluralism@CSCW workshop at ACM CSCW 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09869" title="Abstract">arXiv:2312.09869</a> (replaced) [<a href="/pdf/2312.09869" title="Download PDF">pdf</a>, <a href="/format/2312.09869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning in Online Principal-Agent Interactions: The Power of Menus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Minbiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Albert%2C+M">Michael Albert</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haifeng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09951" title="Abstract">arXiv:2312.09951</a> (replaced) [<a href="/pdf/2312.09951" title="Download PDF">pdf</a>, <a href="/ps/2312.09951" title="Download PostScript">ps</a>, <a href="/format/2312.09951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Alon-Tarsi Number of Some Line and Total graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Prajnanaswaroopa%2C+S">S. Prajnanaswaroopa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10201" title="Abstract">arXiv:2312.10201</a> (replaced) [<a href="/pdf/2312.10201" title="Download PDF">pdf</a>, <a href="/format/2312.10201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARAT: Contrastive Feature Reconstruction and Aggregation for  Multi-modal Multi-label Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Cheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Ke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Lidan Shou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10687" title="Abstract">arXiv:2312.10687</a> (replaced) [<a href="/pdf/2312.10687" title="Download PDF">pdf</a>, <a href="/format/2312.10687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MM-TTS: Multi-modal Prompt based Style Transfer for Expressive  Text-to-Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guan%2C+W">Wenhao Guan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yishuang Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+H">Hukai Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jiayan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Lingyan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+Q">Qingyang Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10997" title="Abstract">arXiv:2312.10997</a> (replaced) [<a href="/pdf/2312.10997" title="Download PDF">pdf</a>, <a href="/format/2312.10997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Augmented Generation for Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yunfan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kangxiang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jinliu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+Y">Yuxi Bi</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiawei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haofen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ongoing Work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12450" title="Abstract">arXiv:2312.12450</a> (replaced) [<a href="/pdf/2312.12450" title="Download PDF">pdf</a>, <a href="/format/2312.12450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can It Edit? Evaluating the Ability of Large Language Models to Follow  Code Editing Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cassano%2C+F">Federico Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Luisa Li</a>, 
<a href="/search/cs?searchtype=author&query=Sethi%2C+A">Akul Sethi</a>, 
<a href="/search/cs?searchtype=author&query=Shinn%2C+N">Noah Shinn</a>, 
<a href="/search/cs?searchtype=author&query=Brennan-Jones%2C+A">Abby Brennan-Jones</a>, 
<a href="/search/cs?searchtype=author&query=Lozhkov%2C+A">Anton Lozhkov</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C+J">Carolyn Jane Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13156" title="Abstract">arXiv:2312.13156</a> (replaced) [<a href="/pdf/2312.13156" title="Download PDF">pdf</a>, <a href="/format/2312.13156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AccidentGPT: Accident Analysis and Prevention from V2X Environmental  Perception with Multi-modal Large Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lening Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yilong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Han Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Daocheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhiyong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuesong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanchu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Helai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinhai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13490" title="Abstract">arXiv:2312.13490</a> (replaced) [<a href="/pdf/2312.13490" title="Download PDF">pdf</a>, <a href="/ps/2312.13490" title="Download PostScript">ps</a>, <a href="/format/2312.13490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimension-Accuracy Tradeoffs in Contrastive Embeddings for Triplets,  Terminals &amp; Top-k Nearest Neighbors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatziafratis%2C+V">Vaggos Chatziafratis</a>, 
<a href="/search/cs?searchtype=author&query=Indyk%2C+P">Piotr Indyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract shortened for arxiv
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14199" title="Abstract">arXiv:2312.14199</a> (replaced) [<a href="/pdf/2312.14199" title="Download PDF">pdf</a>, <a href="/format/2312.14199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Report on 2023 CyberTraining PI Meeting, 26-27 September 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fox%2C+G">Geoffrey Fox</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+M+P">Mary P Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+S">Sajal Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Brazil%2C+M">Marisa Brazil</a>, 
<a href="/search/cs?searchtype=author&query=Gasparini%2C+N+M">Nicole M Gasparini</a>, 
<a href="/search/cs?searchtype=author&query=Merwade%2C+V+M">Venkatesh Mohan Merwade</a>, 
<a href="/search/cs?searchtype=author&query=Neeman%2C+H+J">Henry J. Neeman</a>, 
<a href="/search/cs?searchtype=author&query=Carver%2C+J">Jeff Carver</a>, 
<a href="/search/cs?searchtype=author&query=Casanova%2C+H">Henri Casanova</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+V">Vipin Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Colbry%2C+D">Dirk Colbry</a>, 
<a href="/search/cs?searchtype=author&query=Crosby%2C+L">Lonnie Crosby</a>, 
<a href="/search/cs?searchtype=author&query=Dewan%2C+P">Prasun Dewan</a>, 
<a href="/search/cs?searchtype=author&query=Eisma%2C+J">Jessica Eisma</a>, 
<a href="/search/cs?searchtype=author&query=Gasparini%2C+N+M">Nicole M Gasparini</a>, 
<a href="/search/cs?searchtype=author&query=Irfan%2C+A">Ahmed Irfan</a>, 
<a href="/search/cs?searchtype=author&query=Kaehey%2C+K">Kate Kaehey</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qianqian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zhen Ni</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+S">Sushil Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Qasem%2C+A">Apan Qasem</a>, 
<a href="/search/cs?searchtype=author&query=Saule%2C+E">Erik Saule</a>, 
<a href="/search/cs?searchtype=author&query=Sundaravadivel%2C+P">Prabha Sundaravadivel</a>, 
<a href="/search/cs?searchtype=author&query=Tomko%2C+K">Karen Tomko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 3 main sections and 2 Appendix sections, 2 figures, 19 tables; updated version: author corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14213" title="Abstract">arXiv:2312.14213</a> (replaced) [<a href="/pdf/2312.14213" title="Download PDF">pdf</a>, <a href="/format/2312.14213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reinforcement-Learning-Based Multiple-Column Selection Strategy for  Column Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yuan%2C+H">Haofeng Yuan</a>, 
<a href="/search/math?searchtype=author&query=Fang%2C+L">Lichang Fang</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+S">Shiji Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14769" title="Abstract">arXiv:2312.14769</a> (replaced) [<a href="/pdf/2312.14769" title="Download PDF">pdf</a>, <a href="/ps/2312.14769" title="Download PostScript">ps</a>, <a href="/format/2312.14769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model (LLM) Bias Index -- LLMBI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oketunji%2C+A+F">Abiodun Finbarrs Oketunji</a>, 
<a href="/search/cs?searchtype=author&query=Anas%2C+M">Muhammad Anas</a>, 
<a href="/search/cs?searchtype=author&query=Saina%2C+D">Deepthi Saina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14937" title="Abstract">arXiv:2312.14937</a> (replaced) [<a href="/pdf/2312.14937" title="Download PDF">pdf</a>, <a href="/format/2312.14937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yi-Hua Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yang-Tian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xiaoyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code link: <a href="https://github.com/yihua7/SC-GS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15166" title="Abstract">arXiv:2312.15166</a> (replaced) [<a href="/pdf/2312.15166" title="Download PDF">pdf</a>, <a href="/format/2312.15166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective  Depth Up-Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dahyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanjun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sanghoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonsung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wonho Song</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yunsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeonwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yungi Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyeonju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jihoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+C">Changbae Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Seonghoon Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sukyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyunbyung Park</a>, 
<a href="/search/cs?searchtype=author&query=Gim%2C+G">Gyoungjin Gim</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+M">Mikyoung Cha</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hwalsuk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sunghun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16033" title="Abstract">arXiv:2312.16033</a> (replaced) [<a href="/pdf/2312.16033" title="Download PDF">pdf</a>, <a href="/format/2312.16033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Algorithm for Embedded Order Dependency Validation (Extended  Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramos%2C+A">Alejandro Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Uemura%2C+T">Takuya Uemura</a>, 
<a href="/search/cs?searchtype=author&query=Amagata%2C+D">Daichi Amagata</a>, 
<a href="/search/cs?searchtype=author&query=Shirai%2C+R">Ryo Shirai</a>, 
<a href="/search/cs?searchtype=author&query=Hara%2C+T">Takahiro Hara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16160" title="Abstract">arXiv:2312.16160</a> (replaced) [<a href="/pdf/2312.16160" title="Download PDF">pdf</a>, <a href="/format/2312.16160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SymmPI: Predictive Inference for Data with Group Symmetries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dobriban%2C+E">Edgar Dobriban</a>, 
<a href="/search/stat?searchtype=author&query=Yu%2C+M">Mengxin Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16374" title="Abstract">arXiv:2312.16374</a> (replaced) [<a href="/pdf/2312.16374" title="Download PDF">pdf</a>, <a href="/format/2312.16374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Factoscope: Uncovering LLMs&#x27; Factual Discernment through Inner  States Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jinwen He</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yujia Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chengan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16391" title="Abstract">arXiv:2312.16391</a> (replaced) [<a href="/pdf/2312.16391" title="Download PDF">pdf</a>, <a href="/format/2312.16391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Spatial Temporal Consistency of Joint Visual Tactile Perception  in VR Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fuqiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kehan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Z">Zhuoyi Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by the IEEE Haptic Symposium 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16486" title="Abstract">arXiv:2312.16486</a> (replaced) [<a href="/pdf/2312.16486" title="Download PDF">pdf</a>, <a href="/format/2312.16486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PanGu-Draw: Advancing Resource-Efficient Text-to-Image Synthesis with  Time-Decoupled Training and Reusable Coop-Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guansong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanfan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+M">Minzhe Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yihan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zeyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16571" title="Abstract">arXiv:2312.16571</a> (replaced) [<a href="/pdf/2312.16571" title="Download PDF">pdf</a>, <a href="/format/2312.16571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRSDet: Learning to Generate Local Reverse Samples for Few-shot Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hefei Mei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Taijin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shiyuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Heqian Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lanxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minjian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanman Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongliang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16576" title="Abstract">arXiv:2312.16576</a> (replaced) [<a href="/pdf/2312.16576" title="Download PDF">pdf</a>, <a href="/format/2312.16576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relative Entropy for Quantum Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+Z">Zishuo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, comments welcome, contact information updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operator Algebras (math.OA)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph); Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16578" title="Abstract">arXiv:2312.16578</a> (replaced) [<a href="/pdf/2312.16578" title="Download PDF">pdf</a>, <a href="/format/2312.16578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modality Affinity Inference for Weakly Supervised 3D Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qingyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16581" title="Abstract">arXiv:2312.16581</a> (replaced) [<a href="/pdf/2312.16581" title="Download PDF">pdf</a>, <a href="/format/2312.16581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-time Autoencoders for Regular and Irregular Time Series  Imputation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wi%2C+H">Hyowon Wi</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Yehjin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a WSDM'24 full paper (oral presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16735" title="Abstract">arXiv:2312.16735</a> (replaced) [<a href="/pdf/2312.16735" title="Download PDF">pdf</a>, <a href="/format/2312.16735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flock: A Low-Cost Streaming Query Engine on FaaS Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+G">Gang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A">Amol Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Abadi%2C+D+J">Daniel J. Abadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A mirror of portions of Gang's PhD thesis. Not yet revised; read at your own discretion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16805" title="Abstract">arXiv:2312.16805</a> (replaced) [<a href="/pdf/2312.16805" title="Download PDF">pdf</a>, <a href="/format/2312.16805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DarkShot: Lighting Dark Images with Low-Compute and High-Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jiazhang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qiuping Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yangxing Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16818" title="Abstract">arXiv:2312.16818</a> (replaced) [<a href="/pdf/2312.16818" title="Download PDF">pdf</a>, <a href="/ps/2312.16818" title="Download PostScript">ps</a>, <a href="/format/2312.16818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Difficulties in Dynamic Analysis of Drone Firmware and Its Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yejun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kwangsoo Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungjoo Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16837" title="Abstract">arXiv:2312.16837</a> (replaced) [<a href="/pdf/2312.16837" title="Download PDF">pdf</a>, <a href="/format/2312.16837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionGAN3D: Boosting Text-guided 3D Generation and Domain Adaption  by Combining 3D GANs and Diffusion Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Biwen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Mengyang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Miaomiao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16850" title="Abstract">arXiv:2312.16850</a> (replaced) [<a href="/pdf/2312.16850" title="Download PDF">pdf</a>, <a href="/format/2312.16850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accent-VITS:accent transfer for end-to-end TTS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Linhan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongmao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinfa Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Ziqian Ning</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Pengcheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NCMMSC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16887" title="Abstract">arXiv:2312.16887</a> (replaced) [<a href="/pdf/2312.16887" title="Download PDF">pdf</a>, <a href="/format/2312.16887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Scoring of Cognition Drawings: Assessing the Quality of  Machine-Based Scores Against a Gold Standard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bethmann%2C+A">Arne Bethmann</a>, 
<a href="/search/stat?searchtype=author&query=Aoki%2C+M">Marina Aoki</a>, 
<a href="/search/stat?searchtype=author&query=Hunsicker%2C+C">Charlotte Hunsicker</a>, 
<a href="/search/stat?searchtype=author&query=Weileder%2C+C">Claudia Weileder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16963" title="Abstract">arXiv:2312.16963</a> (replaced) [<a href="/pdf/2312.16963" title="Download PDF">pdf</a>, <a href="/format/2312.16963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FFCA-Net: Stereo Image Compression via Fast Cascade Alignment of Side  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xia%2C+Y">Yichong Xia</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yujun Huang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haoqian Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17023" title="Abstract">arXiv:2312.17023</a> (replaced) [<a href="/pdf/2312.17023" title="Download PDF">pdf</a>, <a href="/format/2312.17023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensorial structure of the lifting doctrine in constructive domain  theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sterling%2C+J">Jonathan Sterling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed typographical errors, etc
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17025" title="Abstract">arXiv:2312.17025</a> (replaced) [<a href="/pdf/2312.17025" title="Download PDF">pdf</a>, <a href="/format/2312.17025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experiential Co-Learning of Software-Developing Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yufan Dang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weize Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17044" title="Abstract">arXiv:2312.17044</a> (replaced) [<a href="/pdf/2312.17044" title="Download PDF">pdf</a>, <a href="/format/2312.17044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Length Extrapolation of Transformers: A Survey from the Perspective of  Position Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaocheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiachong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17118" title="Abstract">arXiv:2312.17118</a> (replaced) [<a href="/pdf/2312.17118" title="Download PDF">pdf</a>, <a href="/format/2312.17118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Sparse 3D Panoptic Occupancy Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haisong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zetong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix some typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17133" title="Abstract">arXiv:2312.17133</a> (replaced) [<a href="/pdf/2312.17133" title="Download PDF">pdf</a>, <a href="/format/2312.17133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARTrackV2: Prompting Autoregressive Tracker Where to Look and How to  Describe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yifan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zeyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yihong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xing Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17142" title="Abstract">arXiv:2312.17142</a> (replaced) [<a href="/pdf/2312.17142" title="Download PDF">pdf</a>, <a href="/format/2312.17142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamGaussian4D: Generative 4D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiawei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaxiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+A">Ang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Gang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Project page is at <a href="https://jiawei-ren.github.io/projects/dreamgaussian4d">this https URL</a> Code is at <a href="https://github.com/jiawei-ren/dreamgaussian4d">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item197">Cross-lists</a></li>
<li><a href="#item218">Replacements</a></li>
</ul>
<small>[ total of 348 entries:  <b>1-348</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
