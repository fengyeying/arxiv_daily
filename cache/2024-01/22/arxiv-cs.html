<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu 18 Jan 24  to  Fri 19 Jan 24, announced Mon, 22 Jan 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item292">Cross-lists</a></li>
<li><a href="#item338">Replacements</a></li>
</ul>
<small>[ total of 519 entries:  <b>1-519</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon, 22 Jan 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10236" title="Abstract">arXiv:2401.10236</a> [<a href="/pdf/2401.10236" title="Download PDF">pdf</a>, <a href="/format/2401.10236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MORCIC: Model Order Reduction Techniques for Electromagnetic Models of  Integrated Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Garyfallou%2C+D">Dimitrios Garyfallou</a>, 
<a href="/search/math?searchtype=author&query=Stefanou%2C+A">Athanasios Stefanou</a>, 
<a href="/search/math?searchtype=author&query=Giamouzis%2C+C">Christos Giamouzis</a>, 
<a href="/search/math?searchtype=author&query=Antoniadis%2C+M">Moschos Antoniadis</a>, 
<a href="/search/math?searchtype=author&query=Chararas%2C+G">Georgios Chararas</a>, 
<a href="/search/math?searchtype=author&query=Chatzis%2C+K">Konstantinos Chatzis</a>, 
<a href="/search/math?searchtype=author&query=Samaras%2C+D">Dimitris Samaras</a>, 
<a href="/search/math?searchtype=author&query=Themeli%2C+R">Rafaela Themeli</a>, 
<a href="/search/math?searchtype=author&query=Michailidis%2C+A">Anastasios Michailidis</a>, 
<a href="/search/math?searchtype=author&query=Gogolou%2C+V">Vasiliki Gogolou</a>, 
<a href="/search/math?searchtype=author&query=Zachos%2C+N">Nikos Zachos</a>, 
<a href="/search/math?searchtype=author&query=Evmorfopoulos%2C+N">Nestor Evmorfopoulos</a>, 
<a href="/search/math?searchtype=author&query=Noulis%2C+T">Thomas Noulis</a>, 
<a href="/search/math?searchtype=author&query=Pavlidis%2C+V+F">Vasilis F. Pavlidis</a>, 
<a href="/search/math?searchtype=author&query=Hatzopoulos%2C+A">Alkiviadis Hatzopoulos</a>, 
<a href="/search/math?searchtype=author&query=Chatzineofytou%2C+E">Elpida Chatzineofytou</a>, 
<a href="/search/math?searchtype=author&query=Moisiadis%2C+Y">Yiannis Moisiadis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2311.08478">arXiv:2311.08478</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Hardware Architecture (cs.AR); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Model order reduction (MOR) is crucial for the design process of integrated
circuits. Specifically, the vast amount of passive RLCk elements in
electromagnetic models extracted from physical layouts exacerbates the
extraction time, the storage requirements, and, most critically, the
post-layout simulation time of the analyzed circuits. The MORCIC project aims
to overcome this problem by proposing new MOR techniques that perform better
than commercial tools. Experimental evaluation on several analog and
mixed-signal circuits with millions of elements indicates that the proposed
methods lead to x5.5 smaller ROMs while maintaining similar accuracy compared
to golden ROMs provided by ANSYS RaptorX.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10239" title="Abstract">arXiv:2401.10239</a> [<a href="/pdf/2401.10239" title="Download PDF">pdf</a>, <a href="/format/2401.10239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed zonotopes: a set representation suitable for unbounded systems and  its application to set-based state estimation and active fault diagnosis of  descriptor systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rego%2C+B+S">Brenner S. Rego</a>, 
<a href="/search/eess?searchtype=author&query=Raimondo%2C+D+M">Davide M. Raimondo</a>, 
<a href="/search/eess?searchtype=author&query=Raffo%2C+G+V">Guilherme V. Raffo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures. arXiv admin note: substantial text overlap with <a href="/abs/2306.07369">arXiv:2306.07369</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">This paper proposes new methods for set-based state estimation and active
fault diagnosis (AFD) of linear descriptor systems. In contrast to simple set
representations, such as intervals, ellipsoids, and zonotopes, linear static
constraints on the state variables, typical of descriptor systems, can be
directly incorporated in the mathematical description of constrained zonotopes.
Thanks to this feature, set-based methods using constrained zonotopes, as
proposed in previous works, could provide less conservative enclosures.
However, an enclosure on the states was assumed to be known for all $k \geq 0$.
Such assumption is violated in the case of unstable descriptor systems. In this
context, this paper proposes a new representation for unbounded sets, which
allows to develop methods for state estimation and tube-based AFD of stable and
unstable linear descriptor systems. The new set representation inherits most of
the properties of constrained zonotopes, including efficient complexity
reduction methods, while allowing to describe different classes of sets, such
as strips, hyperplanes, and the entire $n$-dimensional Euclidean space. The
advantages of the proposed approaches with respect to constrained zonotope
methods are highlighted in numerical examples.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10241" title="Abstract">arXiv:2401.10241</a> [<a href="/pdf/2401.10241" title="Download PDF">pdf</a>, <a href="/format/2401.10241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero Bubble Pipeline Parallelism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+P">Penghui Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xinyi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guangxing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Min Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pipeline parallelism is one of the key components for large-scale distributed
training, yet its efficiency suffers from pipeline bubbles which were deemed
inevitable. In this work, we introduce a scheduling strategy that, to our
knowledge, is the first to successfully achieve zero pipeline bubbles under
synchronous training semantics. The key idea behind this improvement is to
split the backward computation into two parts, one that computes gradient for
the input and another that computes for the parameters. Based on this idea, we
handcraft novel pipeline schedules that significantly outperform the baseline
methods. We further develop an algorithm that automatically finds an optimal
schedule based on specific model configuration and memory limit. Additionally,
to truly achieve zero bubble, we introduce a novel technique to bypass
synchronizations during the optimizer step. Experimental evaluations show that
our method outperforms the 1F1B schedule up to 23% in throughput under a
similar memory limit. This number can be further pushed to 31% when the memory
constraint is relaxed. We believe our results mark a major step forward in
harnessing the true potential of pipeline parallelism. We open sourced our
implementation based on the popular Megatron-LM repository on
https://github.com/sail-sg/zero-bubble-pipeline-parallelism.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10242" title="Abstract">arXiv:2401.10242</a> [<a href="/pdf/2401.10242" title="Download PDF">pdf</a>, <a href="/format/2401.10242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DanceMeld: Unraveling Dance Phrases with Hierarchical Latent Codes for  Music-to-Dance Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Li Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In the realm of 3D digital human applications, music-to-dance presents a
challenging task. Given the one-to-many relationship between music and dance,
previous methods have been limited in their approach, relying solely on
matching and generating corresponding dance movements based on music rhythm. In
the professional field of choreography, a dance phrase consists of several
dance poses and dance movements. Dance poses composed of a series of basic
meaningful body postures, while dance movements can reflect dynamic changes
such as the rhythm, melody, and style of dance. Taking inspiration from these
concepts, we introduce an innovative dance generation pipeline called
DanceMeld, which comprising two stages, i.e., the dance decouple stage and the
dance generation stage. In the decouple stage, a hierarchical VQ-VAE is used to
disentangle dance poses and dance movements in different feature space levels,
where the bottom code represents dance poses, and the top code represents dance
movements. In the generation stage, we utilize a diffusion model as a prior to
model the distribution and generate latent codes conditioned on music features.
We have experimentally demonstrated the representational capabilities of top
code and bottom code, enabling the explicit decoupling expression of dance
poses and dance movements. This disentanglement not only provides control over
motion details, styles, and rhythm but also facilitates applications such as
dance style transfer and dance unit editing. Our approach has undergone
qualitative and quantitative experiments on the AIST++ dataset, demonstrating
its superiority over other methods.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10244" title="Abstract">arXiv:2401.10244</a> [<a href="/pdf/2401.10244" title="Download PDF">pdf</a>, <a href="/ps/2401.10244" title="Download PostScript">ps</a>, <a href="/format/2401.10244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge graph driven recommendation model of graph neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Siwei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">A new graph neural network-based recommendation model called KGLN, which
leverages Knowledge Graph (KG) information, was developed to enhance the
accuracy and effectiveness of personalized recommendations. This model begins
by using a single-layer neural network to merge individual node features in the
graph. It then adjusts the aggregation weights of neighboring entities by
incorporating influence factors. The model evolves from a single layer to
multiple layers through iteration, enabling entities to access extensive
multi-order associated entity information. The final step involves integrating
features of entities and users to produce a recommendation score. The model's
performance was evaluated by comparing its effects on various aggregation
methods and influence factors. In tests using the MovieLen-1M and Book-Crossing
datasets, KGLN showed an AUC (Area Under the ROC curve) improvement of 0.3% to
5.9% and 1.1% to 8.2%, respectively, over established benchmark methods like
LibFM, DeepFM, Wide&amp;Deep, and RippleNet.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10245" title="Abstract">arXiv:2401.10245</a> [<a href="/pdf/2401.10245" title="Download PDF">pdf</a>, <a href="/format/2401.10245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Train Small, Model Big: Scalable Physics Simulators via Reduced Order  Modeling and Domain Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+S+W">Seung Whan Chung</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Youngsoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+P">Pratanu Roy</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+T">Thomas Moore</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+T">Thomas Roy</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T+Y">Tiras Y. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+Y">Du Y. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+C">Christopher Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Duoss%2C+E+B">Eric B. Duoss</a>, 
<a href="/search/cs?searchtype=author&query=Baker%2C+S+E">Sarah E. Baker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 12 figures. Submitted to Computer Methods in Applied Mechanics and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Numerous cutting-edge scientific technologies originate at the laboratory
scale, but transitioning them to practical industry applications is a
formidable challenge. Traditional pilot projects at intermediate scales are
costly and time-consuming. An alternative, the E-pilot, relies on high-fidelity
numerical simulations, but even these simulations can be computationally
prohibitive at larger scales. To overcome these limitations, we propose a
scalable, physics-constrained reduced order model (ROM) method. ROM identifies
critical physics modes from small-scale unit components, projecting governing
equations onto these modes to create a reduced model that retains essential
physics details. We also employ Discontinuous Galerkin Domain Decomposition
(DG-DD) to apply ROM to unit components and interfaces, enabling the
construction of large-scale global systems without data at such large scales.
This method is demonstrated on the Poisson and Stokes flow equations, showing
that it can solve equations about $15 - 40$ times faster with only $\sim$ $1\%$
relative error. Furthermore, ROM takes one order of magnitude less memory than
the full order model, enabling larger scale predictions at a given memory
limitation.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10246" title="Abstract">arXiv:2401.10246</a> [<a href="/pdf/2401.10246" title="Download PDF">pdf</a>, <a href="/format/2401.10246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Performance Computing in Battery Development: From Pore Scale to  Continuum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kellers%2C+B">Benjamin Kellers</a>, 
<a href="/search/cs?searchtype=author&query=Lautenschlaeger%2C+M+P">Martin P. Lautenschlaeger</a>, 
<a href="/search/cs?searchtype=author&query=Weinmiller%2C+J">Julius Weinmiller</a>, 
<a href="/search/cs?searchtype=author&query=Krumbein%2C+L">Lukas Krumbein</a>, 
<a href="/search/cs?searchtype=author&query=Hein%2C+S">Simon Hein</a>, 
<a href="/search/cs?searchtype=author&query=Danner%2C+T">Timo Danner</a>, 
<a href="/search/cs?searchtype=author&query=Latz%2C+A">Arnulf Latz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">An application for high-performance computing (HPC) is shown that is relevant
in the field of battery development. Simulations of electrolyte wetting and
flow are conducted using pore network models (PNM) and the lattice Boltzmann
method (LBM), while electrochemical simulations are conducted using the tool
BEST. All aforementioned software packages show an appropriate scaling
behavior. A workflow for optimizing battery performance by improving the
filling of battery components is presented. A special focus is given to the
unwanted side effect of gas entrapment encountered during filling. It is also
known to adversely affect the electrochemical performance of batteries and can
be partially prevented by appropriate microstructure design such as electrode
perforation.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10247" title="Abstract">arXiv:2401.10247</a> [<a href="/pdf/2401.10247" title="Download PDF">pdf</a>, <a href="/format/2401.10247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolution Chromatography of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Juno Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Yong-Hyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+J">Junghyo Jo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models generate high-resolution images through iterative stochastic
processes. In particular, the denoising method is one of the most popular
approaches that predicts the noise in samples and denoises it at each time
step. It has been commonly observed that the resolution of generated samples
changes over time, starting off blurry and coarse, and becoming sharper and
finer. In this paper, we introduce "resolution chromatography" that indicates
the signal generation rate of each resolution, which is very helpful concept to
mathematically explain this coarse-to-fine behavior in generation process, to
understand the role of noise schedule, and to design time-dependent modulation.
Using resolution chromatography, we determine which resolution level becomes
dominant at a specific time step, and experimentally verify our theory with
text-to-image diffusion models. We also propose some direct applications
utilizing the concept: upscaling pre-trained models to higher resolutions and
time-dependent prompt composing. Our theory not only enables a better
understanding of numerous pre-existing techniques for manipulating image
generation, but also suggests the potential for designing better noise
schedules.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10249" title="Abstract">arXiv:2401.10249</a> [<a href="/pdf/2401.10249" title="Download PDF">pdf</a>, <a href="/ps/2401.10249" title="Download PostScript">ps</a>, <a href="/format/2401.10249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building a Reusable and Extensible Automatic Compiler Infrastructure for  Reconfigurable Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zang%2C+Z">Zhenya Zang</a>, 
<a href="/search/cs?searchtype=author&query=Dolinsky%2C+U">Uwe Dolinsky</a>, 
<a href="/search/cs?searchtype=author&query=Ghiglio%2C+P">Pietro Ghiglio</a>, 
<a href="/search/cs?searchtype=author&query=Cherubin%2C+S">Stefano Cherubin</a>, 
<a href="/search/cs?searchtype=author&query=Goli%2C+M">Mehdi Goli</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shufan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 33rd International Conference on Field-Programmable Logic and Applications (FPL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Multi-Level Intermediate Representation (MLIR) is gaining increasing
attention in reconfigurable hardware communities due to its capability to
represent various abstract levels for software compilers. This project aims to
be the first to provide an end-to-end framework that leverages open-source,
cross-platform compilation technology to generate MLIR from SYCL. Additionally,
it aims to explore a lowering pipeline that converts MLIR to RTL using
open-source hardware intermediate representation (IR) and compilers.
Furthermore, it aims to couple the generated hardware module with the host CPU
using vendor-specific crossbars. Our preliminary results demonstrated the
feasibility of lowering customized MLIR to RTL, thus paving the way for an
end-to-end compilation.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10250" title="Abstract">arXiv:2401.10250</a> [<a href="/pdf/2401.10250" title="Download PDF">pdf</a>, <a href="/format/2401.10250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectrum Sharing through Marketplaces for O-RAN based Non-Terrestrial  and Terrestrial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jinho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bohai Li</a>, 
<a href="/search/cs?searchtype=author&query=Homssi%2C+B+A">Bassel Al Homssi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jihong Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seung-Lyun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Non-terrestrial networks (NTNs), including low Earth orbit (LEO) satellites,
are expected to play a pivotal role in achieving global coverage for
Internet-of-Things (IoT) applications in sixth-generation (6G) systems.
Although specific frequency bands have been identified for satellite use in
NTNs, persistent challenges arise due to the limited availability of spectrum
resources. The coexistence of multiple systems, including terrestrial networks
(TNs), sharing these frequencies, presents a technically challenging yet
feasible solution. Furthermore, the effective management and regulation of such
coexistence should be under the purview of regional authorities. To facilitate
efficient spectrum sharing among various systems, including NTNs and TNs,
adopting open architectures is desirable, allowing for the seamless exchange of
key information for spectrum sharing. Therefore, it is essential to consider
open radio access networks (O-RAN) for future NTNs and TNs. In addition to
O-RAN, the establishment of spectrum marketplaces, enabling different operators
to trade their spectrum and dynamic resource allocation information, is
necessary. In this article, we highlight the role of spectrum marketplaces and
discuss a few examples.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10251" title="Abstract">arXiv:2401.10251</a> [<a href="/pdf/2401.10251" title="Download PDF">pdf</a>, <a href="/format/2401.10251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Terrestrial Network (NTN): a Novel Alternate Fractional Programming  for the Downlink Channels Power Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M">Mahfuzur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+Z">Zoheb Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Reed%2C+J+H">Jeffrey H. Reed</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjia Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Non-terrestrial network (NTN) communication has garnered considerable
attention from government entities, industries, and academia in recent times.
NTN networks encompass a variety of systems, including Low Earth Orbit (LEO)
satellites, Medium Earth Orbit (MEO) satellites, Geostationary Earth Orbit
(GEO) satellites, High Altitude Platforms (HAPS), and Low Altitude Platforms
(LAPS). Furthermore, the deployment of high-throughput satellites (HTS/VHTS) in
the GEO space has gained momentum. While LEO and MEO satellites offer
advantages such as low latency and reduced launching costs compared to GEO
satellites, this study focuses on GEO satellites due to their stationary nature
and broader coverage. In traditional cellular networks, each user equipment
(UE) is allocated at least one resource block (RB), which is not shared with
other UEs. However, in NTN communications, where the coverage area is
extensive, dedicating an RB to only one UE is an inefficient utilization of
radio resources. To address this challenge, fractional programming (FP),
cognitive radio, and rate splitting multiple access (RSMA) are existing
technologies. This paper aims to maximize spectral efficiency, average RBG
rate, and sum rate for GEO satellite systems. However, achieving this objective
involves dealing with a non-convex, NP-hard problem, as it requires the
logarithmic sum of different fractions. Finding a global solution to such an
NP-hard problem presents significant challenges. This paper introduces a novel
alternate fractional programming algorithm specifically designed to tackle
these complex NP-hard problems in the context of GEO NTN cellular networks. By
employing this innovative approach, the study seeks to contribute to the
optimization of NTN communication systems, enabling efficient resource
allocation and improved network performance.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10252" title="Abstract">arXiv:2401.10252</a> [<a href="/pdf/2401.10252" title="Download PDF">pdf</a>, <a href="/ps/2401.10252" title="Download PostScript">ps</a>, <a href="/format/2401.10252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Beam-Segmenting Polar Format Algorithm Based on Double PCS for Video  SAR Persistent Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiawei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shaowen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Ping Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yiming Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video synthetic aperture radar (SAR) is attracting more attention in recent
years due to its abilities of high resolution, high frame rate and advantages
in continuous observation. Generally, the polar format algorithm (PFA) is an
efficient algorithm for spotlight mode video SAR. However, in the process of
PFA, the wavefront curvature error (WCE) limits the imaging scene size and the
2-D interpolation affects the efficiency. To solve the aforementioned problems,
a beam-segmenting PFA based on principle of chirp scaling (PCS), called
BS-PCS-PFA, is proposed for video SAR imaging, which has the capability of
persistent imaging for different carrier frequencies video SAR. Firstly, an
improved PCS applicable to video SAR PFA is proposed to replace the 2-D
interpolation and the coarse image in the ground output coordinate system
(GOCS) is obtained. As for the distortion or defocus existing in the coarse
image, a novel sub-block imaging method based on beam-segmenting fast filtering
is proposed to segment the image into multiple sub-beam data, whose distortion
and defocus can be ignored when the equivalent size of sub-block is smaller
than the distortion negligible region. Through processing the sub-beam data and
mosaicking the refocused subimages, the full image in GOCS without distortion
and defocus is obtained. Moreover, a three-step MoCo method is applied to the
algorithm for the adaptability to the actual irregular trajectories. The
proposed method can significantly expand the effective scene size of PFA, and
the better operational efficiency makes it more suitable for video SAR imaging.
The feasibility of the algorithm is verified by the experimental data.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10253" title="Abstract">arXiv:2401.10253</a> [<a href="/pdf/2401.10253" title="Download PDF">pdf</a>, <a href="/format/2401.10253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid-Task Meta-Learning: A Graph Neural Network Approach for Scalable  and Transferable Bandwidth Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+X">Xin Hao</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+C">Changyang She</a>, 
<a href="/search/cs?searchtype=author&query=Yeoh%2C+P+L">Phee Lep Yeoh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Vucetic%2C+B">Branka Vucetic</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yonghui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we develop a deep learning-based bandwidth allocation policy
that is: 1) scalable with the number of users and 2) transferable to different
communication scenarios, such as non-stationary wireless channels, different
quality-of-service (QoS) requirements, and dynamically available resources. To
support scalability, the bandwidth allocation policy is represented by a graph
neural network (GNN), with which the number of training parameters does not
change with the number of users. To enable the generalization of the GNN, we
develop a hybrid-task meta-learning (HML) algorithm that trains the initial
parameters of the GNN with different communication scenarios during
meta-training. Next, during meta-testing, a few samples are used to fine-tune
the GNN with unseen communication scenarios. Simulation results demonstrate
that our HML approach can improve the initial performance by $8.79\%$, and
sampling efficiency by $73\%$, compared with existing benchmarks. After
fine-tuning, our near-optimal GNN-based policy can achieve close to the same
reward with much lower inference complexity compared to the optimal policy
obtained using iterative optimization.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10254" title="Abstract">arXiv:2401.10254</a> [<a href="/pdf/2401.10254" title="Download PDF">pdf</a>, <a href="/ps/2401.10254" title="Download PostScript">ps</a>, <a href="/format/2401.10254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Frame: Single and mutilple video summarization method with  user-defined length
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalkhorani%2C+V+A">Vahid Ahmadi Kalkhorani</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guanqun Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Ting Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Video smmarization is a crucial method to reduce the time of videos which
reduces the spent time to watch/review a long video. This apporach has became
more important as the amount of publisehed video is increasing everyday. A
single or multiple videos can be summarized into a relatively short video using
various of techniques from multimodal audio-visual techniques, to natural
language processing approaches. Audiovisual techniques may be used to recognize
significant visual events and pick the most important parts, while NLP
techniques can be used to evaluate the audio transcript and extract the main
sentences (timestamps) and corresponding video frames from the original video.
Another approach is to use the best of both domain. Meaning that we can use
audio-visual cues as well as video transcript to extract and summarize the
video. In this paper, we combine a variety of NLP techniques (extractive and
contect-based summarizers) with video processing techniques to convert a long
video into a single relatively short video. We design this toll in a way that
user can specify the relative length of the summarized video. We have also
explored ways of summarizing and concatenating multiple videos into a single
short video which will help having most important concepts from the same
subject in a single short video. Out approach shows that video summarizing is a
difficult but significant work, with substantial potential for further research
and development, and it is possible thanks to the development of NLP models.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10256" title="Abstract">arXiv:2401.10256</a> [<a href="/pdf/2401.10256" title="Download PDF">pdf</a>, <a href="/ps/2401.10256" title="Download PostScript">ps</a>, <a href="/format/2401.10256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active headrest combined with a depth camera-based ear-positioning  system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuteng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haowen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Haishan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhibin Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Active headrests can reduce low-frequency noise around ears based on active
noise control (ANC) system. Both the control system using fixed control filters
and the remote microphone-based adaptive control system provide good noise
reduction performance when the head is in the original position. However, their
performance degrades significantly when the head is in motion. In this paper, a
human ear-positioning system based on the depth camera is introduced to address
this problem. The system uses RTMpose model to estimate the two-dimensional
(2D) positions of the ears in the color frame, and then derives the
corresponding three-dimensional (3D) coordinates in the depth frame with a
depth camera. Experimental results show that the ear-positioning system can
effectively track the movement of ears, and the broadband noise reduction
performance of the active headrest combined with the system is significantly
improved when the human head is translating or rotating.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10257" title="Abstract">arXiv:2401.10257</a> [<a href="/pdf/2401.10257" title="Download PDF">pdf</a>, <a href="/format/2401.10257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum Design Helps Spiking Neural Networks to Classify Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chenxi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Moxian Song</a>, 
<a href="/search/cs?searchtype=author&query=Can%2C+D">Derun Can</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Shenda Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) have a greater potential for modeling time
series data than Artificial Neural Networks (ANNs), due to their inherent
neuron dynamics and low energy consumption. However, it is difficult to
demonstrate their superiority in classification accuracy, because current
efforts mainly focus on designing better network structures. In this work,
enlighten by brain-inspired science, we find that, not only the structure but
also the learning process should be human-like. To achieve this, we investigate
the power of Curriculum Learning (CL) on SNNs by designing a novel method named
CSNN with two theoretically guaranteed mechanisms: The active-to-dormant
training order makes the curriculum similar to that of human learning and
suitable for spiking neurons; The value-based regional encoding makes the
neuron activity to mimic the brain memory when learning sequential data.
Experiments on multiple time series sources including simulated, sensor,
motion, and healthcare demonstrate that CL has a more positive effect on SNNs
than ANNs with about twice the accuracy change, and CSNN can increase about 3%
SNNs' accuracy by improving network sparsity, neuron firing status, anti-noise
ability, and convergence speed.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10262" title="Abstract">arXiv:2401.10262</a> [<a href="/pdf/2401.10262" title="Download PDF">pdf</a>, <a href="/format/2401.10262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Null Space Properties of Neural Networks with Applications to Image  Steganography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Short%2C+K+M">Kevin M. Short</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper explores the null space properties of neural networks. We extend
the null space definition from linear to nonlinear maps and discuss the
presence of a null space in neural networks. The null space of a given neural
network can tell us the part of the input data that makes no contribution to
the final prediction so that we can use it to trick the neural network. This
reveals an inherent weakness in neural networks that can be exploited. One
application described here leads to a method of image steganography. Through
experiments on image datasets such as MNIST, we show that we can use null space
components to force the neural network to choose a selected hidden image class,
even though the overall image can be made to look like a completely different
image. We conclude by showing comparisons between what a human viewer would
see, and the part of the image that the neural network is actually using to
make predictions and, hence, show that what the neural network ``sees'' is
completely different than what we would expect.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10264" title="Abstract">arXiv:2401.10264</a> [<a href="/pdf/2401.10264" title="Download PDF">pdf</a>, <a href="/ps/2401.10264" title="Download PostScript">ps</a>, <a href="/format/2401.10264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Transparent Learning Analytics for Individualized Support  through Auto-detection of Engagement in Face-to-Face Collaborative Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Suraworachet%2C+W">Wannapon Suraworachet</a>, 
<a href="/search/cs?searchtype=author&query=Cukurova%2C+M">Mutlu Cukurova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Using learning analytics to investigate and support collaborative learning
has been explored for many years. Recently, automated approaches with various
artificial intelligence approaches have provided promising results for
modelling and predicting student engagement and performance in collaborative
learning tasks. However, due to the lack of transparency and interpretability
caused by the use of "black box" approaches in learning analytics design and
implementation, guidance for teaching and learning practice may become a
challenge. On the one hand, the black box created by machine learning
algorithms and models prevents users from obtaining educationally meaningful
learning and teaching suggestions. On the other hand, focusing on group and
cohort level analysis only can make it difficult to provide specific support
for individual students working in collaborative groups. This paper proposes a
transparent approach to automatically detect student's individual engagement in
the process of collaboration. The results show that the proposed approach can
reflect student's individual engagement and can be used as an indicator to
distinguish students with different collaborative learning challenges
(cognitive, behavioural and emotional) and learning outcomes. The potential of
the proposed collaboration analytics approach for scaffolding collaborative
learning practice in face-to-face contexts is discussed and future research
suggestions are provided.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10265" title="Abstract">arXiv:2401.10265</a> [<a href="/pdf/2401.10265" title="Download PDF">pdf</a>, <a href="/format/2401.10265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Best Time for an Update: Risk-Sensitive Minimization of Age-Based  Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Sombre%2C+W">Wanja de Sombre</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+A">Andrea Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Aurzada%2C+F">Frank Aurzada</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+A">Anja Klein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Popular methods to quantify transmitted data quality are the Age of
Information (AoI), the Query Age of Information (QAoI), and the Age of
Incorrect Information (AoII). We consider these metrics in a point-to-point
wireless communication system, where the transmitter monitors a process and
sends status updates to a receiver. The challenge is to decide on the best time
for an update, balancing the transmission energy and the age-based metric at
the receiver. Due to the inherent risk of high age-based metric values causing
complications such as unstable system states, we introduce the new concept of
risky states to denote states with high age-based metric. We use this new
notion of risky states to quantify and minimize this risk of experiencing high
age-based metrics by directly deriving the frequency of risky states as a novel
risk-metric. Building on this foundation, we introduce two risk-sensitive
strategies for AoI, QAoI and AoII. The first strategy uses system knowledge,
i.e., channel quality and packet arrival probability, to find an optimal
strategy that transmits when the age-based metric exceeds a tunable threshold.
A lower threshold leads to higher risk-sensitivity. The second strategy uses an
enhanced Q-learning approach and balances the age-based metric, the
transmission energy and the frequency of risky states without requiring
knowledge about the system. Numerical results affirm our risk-sensitive
strategies' high effectiveness.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10266" title="Abstract">arXiv:2401.10266</a> [<a href="/pdf/2401.10266" title="Download PDF">pdf</a>, <a href="/format/2401.10266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Condition Monitoring of Industrial Plants: An Overview of  Methodologies and Uncertainty Management Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahang%2C+M">Maryam Ahang</a>, 
<a href="/search/cs?searchtype=author&query=Charter%2C+T">Todd Charter</a>, 
<a href="/search/cs?searchtype=author&query=Ogunfowora%2C+O">Oluwaseyi Ogunfowora</a>, 
<a href="/search/cs?searchtype=author&query=Khadivi%2C+M">Maziyar Khadivi</a>, 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+M">Mostafa Abbasi</a>, 
<a href="/search/cs?searchtype=author&query=Najjaran%2C+H">Homayoun Najjaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">Condition monitoring plays a significant role in the safety and reliability
of modern industrial systems. Artificial intelligence (AI) approaches are
gaining attention from academia and industry as a growing subject in industrial
applications and as a powerful way of identifying faults. This paper provides
an overview of intelligent condition monitoring and fault detection and
diagnosis methods for industrial plants with a focus on the open-source
benchmark Tennessee Eastman Process (TEP). In this survey, the most popular and
state-of-the-art deep learning (DL) and machine learning (ML) algorithms for
industrial plant condition monitoring, fault detection, and diagnosis are
summarized and the advantages and disadvantages of each algorithm are studied.
Challenges like imbalanced data, unlabelled samples and how deep learning
models can handle them are also covered. Finally, a comparison of the
accuracies and specifications of different algorithms utilizing the Tennessee
Eastman Process (TEP) is conducted. This research will be beneficial for both
researchers who are new to the field and experts, as it covers the literature
on condition monitoring and state-of-the-art methods alongside the challenges
and possible solutions to them.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10267" title="Abstract">arXiv:2401.10267</a> [<a href="/pdf/2401.10267" title="Download PDF">pdf</a>, <a href="/format/2401.10267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperSense: Accelerating Hyper-Dimensional Computing for Intelligent  Sensor Data Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Sanggeon Yun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Masukawa%2C+R">Ryozo Masukawa</a>, 
<a href="/search/cs?searchtype=author&query=Barkam%2C+H+E">Hamza Errahmouni Barkam</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+A">Andrew Ding</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenjun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Rezvani%2C+A">Arghavan Rezvani</a>, 
<a href="/search/cs?searchtype=author&query=Angizi%2C+S">Shaahin Angizi</a>, 
<a href="/search/cs?searchtype=author&query=Imani%2C+M">Mohsen Imani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Introducing HyperSense, our co-designed hardware and software system
efficiently controls Analog-to-Digital Converter (ADC) modules' data generation
rate based on object presence predictions in sensor data. Addressing challenges
posed by escalating sensor quantities and data rates, HyperSense reduces
redundant digital data using energy-efficient low-precision ADC, diminishing
machine learning system costs. Leveraging neurally-inspired HyperDimensional
Computing (HDC), HyperSense analyzes real-time raw low-precision sensor data,
offering advantages in handling noise, memory-centricity, and real-time
learning.
<br />Our proposed HyperSense model combines high-performance software for object
detection with real-time hardware prediction, introducing the novel concept of
Intelligent Sensor Control. Comprehensive software and hardware evaluations
demonstrate our solution's superior performance, evidenced by the highest Area
Under the Curve (AUC) and sharpest Receiver Operating Characteristic (ROC)
curve among lightweight models. Hardware-wise, our FPGA-based domain-specific
accelerator tailored for HyperSense achieves a 5.6x speedup compared to YOLOv4
on NVIDIA Jetson Orin while showing up to 92.1% energy saving compared to the
conventional system. These results underscore HyperSense's effectiveness and
efficiency, positioning it as a promising solution for intelligent sensing and
real-time data processing across diverse applications.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10268" title="Abstract">arXiv:2401.10268</a> [<a href="/pdf/2401.10268" title="Download PDF">pdf</a>, <a href="/ps/2401.10268" title="Download PostScript">ps</a>, <a href="/format/2401.10268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The complementary contributions of academia and industry to AI research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Lizhen Liang</a> (Syracuse University), 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+H">Han Zhuang</a> (Northeastern University), 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a> (Stanford University), 
<a href="/search/cs?searchtype=author&query=Acuna%2C+D+E">Daniel E. Acuna</a> (University of Colorado at Boulder)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Artificial intelligence (AI) has seen tremendous development in industry and
academia. However, striking recent advances by industry have stunned the world,
inviting a fresh perspective on the role of academic research in this field.
Here, we characterize the impact and type of AI produced by both environments
over the last 25 years and establish several patterns. We find that articles
published by teams consisting exclusively of industry researchers tend to get
greater attention, with a higher chance of being highly cited and
citation-disruptive, and several times more likely to produce state-of-the-art
models. In contrast, we find that exclusively academic teams publish the bulk
of AI research and tend to produce higher novelty work, with single papers
having several times higher likelihood of being unconventional and atypical.
The respective impact-novelty advantages of industry and academia are robust to
controls for subfield, team size, seniority, and prestige. We find that
academic-industry collaborations struggle to replicate the novelty of academic
teams and tend to look similar to industry teams. Together, our findings
identify the unique and nearly irreplaceable contributions that both academia
and industry make toward the healthy progress of AI.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10269" title="Abstract">arXiv:2401.10269</a> [<a href="/pdf/2401.10269" title="Download PDF">pdf</a>, <a href="/ps/2401.10269" title="Download PostScript">ps</a>, <a href="/format/2401.10269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Multi-Sensor Multi-Target Tracking Using Possibility Labeled  Multi-Bernoulli Filter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Han Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C">Chenbao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Houssineau%2C+J">Jeremie Houssineau</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhirun Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Methodology (stat.ME)

</div>
<p class="mathjax">With the increasing complexity of multiple target tracking scenes, a single
sensor may not be able to effectively monitor a large number of targets.
Therefore, it is imperative to extend the single-sensor technique to
Multi-Sensor Multi-Target Tracking (MSMTT) for enhanced functionality. Typical
MSMTT methods presume complete randomness of all uncertain components, and
therefore effective solutions such as the random finite set filter and
covariance intersection method have been derived to conduct the MSMTT task.
However, the presence of epistemic uncertainty, arising from incomplete
information, is often disregarded within the context of MSMTT. This paper
develops an innovative possibility Labeled Multi-Bernoulli (LMB) Filter based
on the labeled Uncertain Finite Set (UFS) theory. The LMB filter inherits the
high robustness of the possibility generalized labeled multi-Bernoulli filter
with simplified computational complexity. The fusion of LMB UFSs is derived and
adapted to develop a robust MSMTT scheme. Simulation results corroborate the
superior performance exhibited by the proposed approach in comparison to
typical probabilistic methods.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10270" title="Abstract">arXiv:2401.10270</a> [<a href="/pdf/2401.10270" title="Download PDF">pdf</a>, <a href="/ps/2401.10270" title="Download PostScript">ps</a>, <a href="/format/2401.10270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Migrating Birds Optimization-Based Feature Selection for Text  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaya%2C+C">Cem Kaya</a>, 
<a href="/search/cs?searchtype=author&query=Kilimci%2C+Z+H">Zeynep Hilal Kilimci</a>, 
<a href="/search/cs?searchtype=author&query=Uysal%2C+M">Mitat Uysal</a>, 
<a href="/search/cs?searchtype=author&query=Kaya%2C+M">Murat Kaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This research introduces a novel approach, MBO-NB, that leverages Migrating
Birds Optimization (MBO) coupled with Naive Bayes as an internal classifier to
address feature selection challenges in text classification having large number
of features. Focusing on computational efficiency, we preprocess raw data using
the Information Gain algorithm, strategically reducing the feature count from
an average of 62221 to 2089. Our experiments demonstrate MBO-NB's superior
effectiveness in feature reduction compared to other existing techniques,
emphasizing an increased classification accuracy. The successful integration of
Naive Bayes within MBO presents a well-rounded solution. In individual
comparisons with Particle Swarm Optimization (PSO), MBO-NB consistently
outperforms by an average of 6.9% across four setups. This research offers
valuable insights into enhancing feature selection methods, providing a
scalable and effective solution for text classification
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10271" title="Abstract">arXiv:2401.10271</a> [<a href="/pdf/2401.10271" title="Download PDF">pdf</a>, <a href="/format/2401.10271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Querying Triadic Concepts through Partial or Complete Matching of  Triples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruas%2C+P+H+B">Pedro Henrique B. Ruas</a>, 
<a href="/search/cs?searchtype=author&query=Missaoui%2C+R">Rokia Missaoui</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+M+H">Mohamed Hamza Ibrahim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we introduce a new method for querying triadic concepts
through partial or complete matching of triples using an inverted index, to
retrieve already computed triadic concepts that contain a set of terms in their
extent, intent, and/or modus. As opposed to the approximation approach
described in Ananias, this method (i) does not need to keep the initial triadic
context or its three dyadic counterparts, (ii) avoids the application of
derivation operators on the triple components through context exploration, and
(iii) eliminates the requirement for a factorization phase to get triadic
concepts as the answer to one-dimensional queries. Additionally, our solution
introduces a novel metric for ranking the retrieved triadic concepts based on
their similarity to a given query. Lastly, an empirical study is primarily done
to illustrate the effectiveness and scalability of our approach against the
approximation one. Our solution not only showcases superior efficiency, but
also highlights a better scalability, making it suitable for big data
scenarios.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10272" title="Abstract">arXiv:2401.10272</a> [<a href="/pdf/2401.10272" title="Download PDF">pdf</a>, <a href="/format/2401.10272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Source Collaborative Gradient Discrepancy Minimization for  Federated Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yikang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yahong Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated Domain Generalization aims to learn a domain-invariant model from
multiple decentralized source domains for deployment on unseen target domain.
Due to privacy concerns, the data from different source domains are kept
isolated, which poses challenges in bridging the domain gap. To address this
issue, we propose a Multi-source Collaborative Gradient Discrepancy
Minimization (MCGDM) method for federated domain generalization. Specifically,
we propose intra-domain gradient matching between the original images and
augmented images to avoid overfitting the domain-specific information within
isolated domains. Additionally, we propose inter-domain gradient matching with
the collaboration of other domains, which can further reduce the domain shift
across decentralized domains. Combining intra-domain and inter-domain gradient
matching, our method enables the learned model to generalize well on unseen
domains. Furthermore, our method can be extended to the federated domain
adaptation task by fine-tuning the target model on the pseudo-labeled target
domain. The extensive experiments on federated domain generalization and
adaptation indicate that our method outperforms the state-of-the-art methods
significantly.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10273" title="Abstract">arXiv:2401.10273</a> [<a href="/pdf/2401.10273" title="Download PDF">pdf</a>, <a href="/ps/2401.10273" title="Download PostScript">ps</a>, <a href="/format/2401.10273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revolutionizing Pharma: Unveiling the AI and LLM Trends in the  Pharmaceutical Industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yu Han</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jingwen Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This document offers a critical overview of the emerging trends and
significant advancements in artificial intelligence (AI) within the
pharmaceutical industry. Detailing its application across key operational
areas, including research and development, animal testing, clinical trials,
hospital clinical stages, production, regulatory affairs, quality control and
other supporting areas, the paper categorically examines AI's role in each
sector. Special emphasis is placed on cutting-edge AI technologies like machine
learning algorithms and their contributions to various aspects of
pharmaceutical operations. Through this comprehensive analysis, the paper
highlights the transformative potential of AI in reshaping the pharmaceutical
industry's future.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10274" title="Abstract">arXiv:2401.10274</a> [<a href="/pdf/2401.10274" title="Download PDF">pdf</a>, <a href="/ps/2401.10274" title="Download PostScript">ps</a>, <a href="/format/2401.10274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Assisted Dual-Stage Evolutionary Optimization of Large-Scale  Crude Oil Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wei Du</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guo Yu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Renchu He</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wenli Du</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the scaling up of crude oil scheduling in modern refineries, large-scale
crude oil scheduling problems (LSCOSPs) emerge with thousands of binary
variables and non-linear constraints, which are challenging to be optimized by
traditional optimization methods. To solve LSCOSPs, we take the practical crude
oil scheduling from a marine-access refinery as an example and start with
modeling LSCOSPs from crude unloading, transportation, crude distillation unit
processing, and inventory management of intermediate products. On the basis of
the proposed model, a dual-stage evolutionary algorithm driven by heuristic
rules (denoted by DSEA/HR) is developed, where the dual-stage search mechanism
consists of global search and local refinement. In the global search stage, we
devise several heuristic rules based on the empirical operating knowledge to
generate a well-performing initial population and accelerate convergence in the
mixed variables space. In the local refinement stage, a repair strategy is
proposed to move the infeasible solutions towards feasible regions by further
optimizing the local continuous variables. During the whole evolutionary
process, the proposed dual-stage framework plays a crucial role in balancing
exploration and exploitation. Experimental results have shown that DSEA/HR
outperforms the state-of-the-art and widely-used mathematical programming
methods and metaheuristic algorithms on LSCOSP instances within a reasonable
time.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10279" title="Abstract">arXiv:2401.10279</a> [<a href="/pdf/2401.10279" title="Download PDF">pdf</a>, <a href="/ps/2401.10279" title="Download PostScript">ps</a>, <a href="/format/2401.10279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A systematic review of geospatial location embedding approaches in large  language models: A path to spatial AI systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tucker%2C+S">Sean Tucker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures, 3 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Geospatial Location Embedding (GLE) helps a Large Language Model (LLM)
assimilate and analyze spatial data. GLE emergence in Geospatial Artificial
Intelligence (GeoAI) is precipitated by the need for deeper geospatial
awareness in our complex contemporary spaces and the success of LLMs in
extracting deep meaning in Generative AI. We searched Google Scholar, Science
Direct, and arXiv for papers on geospatial location embedding and LLM and
reviewed articles focused on gaining deeper spatial "knowing" through LLMs. We
screened 304 titles, 30 abstracts, and 18 full-text papers that reveal four GLE
themes - Entity Location Embedding (ELE), Document Location Embedding (DLE),
Sequence Location Embedding (SLE), and Token Location Embedding (TLE).
Synthesis is tabular and narrative, including a dialogic conversation between
"Space" and "LLM." Though GLEs aid spatial understanding by superimposing
spatial data, they emphasize the need to advance in the intricacies of spatial
modalities and generalized reasoning. GLEs signal the need for a Spatial
Foundation/Language Model (SLM) that embeds spatial knowing within the model
architecture. The SLM framework advances Spatial Artificial Intelligence
Systems (SPAIS), establishing a Spatial Vector Space (SVS) that maps to
physical space. The resulting spatially imbued Language Model is unique. It
simultaneously represents actual space and an AI-capable space, paving the way
for AI native geo storage, analysis, and multi-modality as the basis for
Spatial Artificial Intelligence Systems (SPAIS).
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10286" title="Abstract">arXiv:2401.10286</a> [<a href="/pdf/2401.10286" title="Download PDF">pdf</a>, <a href="/format/2401.10286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Top in Chinese Data Processing: English Code Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Linghan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaojun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jiayuan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Yue Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Gang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongwei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While the alignment between tasks and training corpora is a fundamental
consensus in the application of language models, our series of experiments and
the metrics we designed reveal that code-based Large Language Models (LLMs)
significantly outperform models trained on data that is closely matched to the
tasks in non-coding Chinese tasks. Moreover, in tasks high sensitivity to
Chinese hallucinations, models exhibiting fewer linguistic features of the
Chinese language achieve better performance. Our experimental results can be
easily replicated in Chinese data processing tasks, such as preparing data for
Retrieval-Augmented Generation (RAG), by simply replacing the base model with a
code-based model. Additionally, our research offers a distinct perspective for
discussion on the philosophical "Chinese Room" thought experiment.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10287" title="Abstract">arXiv:2401.10287</a> [<a href="/pdf/2401.10287" title="Download PDF">pdf</a>, <a href="/format/2401.10287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Source Fermionic Neural Networks with Ionic Charge Initialization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pranesh%2C+S">Shai Pranesh</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+V">Venkat Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Ramsundar%2C+B">Bharath Ramsundar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 3rd Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Finding accurate solutions to the electronic Schr\"odinger equation plays an
important role in discovering important molecular and material energies and
characteristics. Consequently, solving systems with large numbers of electrons
has become increasingly important. Variational Monte Carlo (VMC) methods,
especially those approximated through deep neural networks, are promising in
this regard. In this paper, we aim to integrate one such model called the
FermiNet, a post-Hartree-Fock (HF) Deep Neural Network (DNN) model, into a
standard and widely used open source library, DeepChem. We also propose novel
initialization techniques to overcome the difficulties associated with the
assignment of excess or lack of electrons for ions.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10288" title="Abstract">arXiv:2401.10288</a> [<a href="/pdf/2401.10288" title="Download PDF">pdf</a>, <a href="/format/2401.10288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLAN: A Contrastive Learning based Novelty Detection Framework for Human  Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunju Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongman Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In ambient assisted living, human activity recognition from time series
sensor data mainly focuses on predefined activities, often overlooking new
activity patterns. We propose CLAN, a two-tower contrastive learning-based
novelty detection framework with diverse types of negative pairs for human
activity recognition. It is tailored to challenges with human activity
characteristics, including the significance of temporal and frequency features,
complex activity dynamics, shared features across activities, and sensor
modality variations. The framework aims to construct invariant representations
of known activity robust to the challenges. To generate suitable negative
pairs, it selects data augmentation methods according to the temporal and
frequency characteristics of each dataset. It derives the key representations
against meaningless dynamics by contrastive and classification losses-based
representation learning and score function-based novelty detection that
accommodate dynamic numbers of the different types of augmented samples. The
proposed two-tower model extracts the representations in terms of time and
frequency, mutually enhancing expressiveness for distinguishing between new and
known activities, even when they share common features. Experiments on four
real-world human activity datasets show that CLAN surpasses the best
performance of existing novelty detection methods, improving by 8.3%, 13.7%,
and 53.3% in AUROC, balanced accuracy, and FPR@TPR0.95 metrics respectively.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10289" title="Abstract">arXiv:2401.10289</a> [<a href="/pdf/2401.10289" title="Download PDF">pdf</a>, <a href="/ps/2401.10289" title="Download PostScript">ps</a>, <a href="/format/2401.10289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and development of opto-neural processors for simulation of  neural networks trained in image detection for potential implementation in  hybrid robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shetty%2C+S">Sanjana Shetty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Neural networks have been employed for a wide range of processing
applications like image processing, motor control, object detection and many
others. Living neural networks offer advantages of lower power consumption,
faster processing, and biological realism. Optogenetics offers high spatial and
temporal control over biological neurons and presents potential in training
live neural networks. This work proposes a simulated living neural network
trained indirectly by backpropagating STDP based algorithms using precision
activation by optogenetics achieving accuracy comparable to traditional neural
network training algorithms.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10290" title="Abstract">arXiv:2401.10290</a> [<a href="/pdf/2401.10290" title="Download PDF">pdf</a>, <a href="/format/2401.10290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Prediction of Geomagnetic Storms by Machine Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+I">Iris Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Geomagnetic storms (GS) occur when solar winds disrupt Earth's magnetosphere.
GS can cause severe damages to satellites, power grids, and communication
infrastructures. Estimate of direct economic impacts of a large scale GS
exceeds $40 billion a day in the US. Early prediction is critical in preventing
and minimizing the hazards. However, current methods either predict several
hours ahead but fail to identify all types of GS, or make predictions within
short time, e.g., one hour ahead of the occurrence. This work aims to predict
all types of geomagnetic storms reliably and as early as possible using big
data and machine learning algorithms. By fusing big data collected from
multiple ground stations in the world on different aspects of solar
measurements and using Random Forests regression with feature selection and
downsampling on minor geomagnetic storm instances (which carry majority of the
data), we are able to achieve an accuracy of 82.55% on data collected in 2021
when making early predictions three hours in advance. Given that important
predictive features such as historic Kp indices are measured every 3 hours and
their importance decay quickly with the amount of time in advance, an early
prediction of 3 hours ahead of time is believed to be close to the practical
limit.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10294" title="Abstract">arXiv:2401.10294</a> [<a href="/pdf/2401.10294" title="Download PDF">pdf</a>, <a href="/format/2401.10294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Group-Level DP Guarantees for DP-SGD with Sampling via Mixture of  Gaussians Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+A">Arun Ganesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We give a procedure for computing group-level $(\epsilon, \delta)$-DP
guarantees for DP-SGD, when using Poisson sampling or fixed batch size
sampling. Up to discretization errors in the implementation, the DP guarantees
computed by this procedure are tight (assuming we release every intermediate
iterate).
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10299" title="Abstract">arXiv:2401.10299</a> [<a href="/pdf/2401.10299" title="Download PDF">pdf</a>, <a href="/ps/2401.10299" title="Download PostScript">ps</a>, <a href="/format/2401.10299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An attempt to generate new bridge types from latent space of generative  flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Through examples of coordinate and probability transformation between
different distributions, the basic principle of normalizing flow is introduced
in a simple and concise manner. From the perspective of the distribution of
random variable function, the essence of probability transformation is
explained, and the scaling factor Jacobian determinant of probability
transformation is introduced. Treating the dataset as a sample from the
population, obtaining normalizing flow is essentially through sampling surveys
to statistically infer the numerical features of the population, and then the
loss function is established by using the maximum likelihood estimation method.
This article introduces how normalizing flow cleverly solves the two major
application challenges of high-dimensional matrix determinant calculation and
neural network reversible transformation. Using symmetric structured image
dataset of three-span beam bridge, arch bridge, cable-stayed bridge and
suspension bridge, constructing and training normalizing flow based on the Glow
API in the TensorFlow Probability library. The model can smoothly transform the
complex distribution of the bridge dataset into a standard normal distribution,
and from the obtained latent space sampling, it can generate new bridge types
that are different from the training dataset.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10300" title="Abstract">arXiv:2401.10300</a> [<a href="/pdf/2401.10300" title="Download PDF">pdf</a>, <a href="/format/2401.10300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hierarchical Framework with Spatio-Temporal Consistency Learning for  Emergence Detection in Complex Adaptive Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xin Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiahai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Emergence, a global property of complex adaptive systems (CASs) constituted
by interactive agents, is prevalent in real-world dynamic systems, e.g.,
network-level traffic congestions. Detecting its formation and evaporation
helps to monitor the state of a system, allowing to issue a warning signal for
harmful emergent phenomena. Since there is no centralized controller of CAS,
detecting emergence based on each agent's local observation is desirable but
challenging. Existing works are unable to capture emergence-related spatial
patterns, and fail to model the nonlinear relationships among agents. This
paper proposes a hierarchical framework with spatio-temporal consistency
learning to solve these two problems by learning the system representation and
agent representations, respectively. Especially, spatio-temporal encoders are
tailored to capture agents' nonlinear relationships and the system's complex
evolution. Representations of the agents and the system are learned by
preserving the intrinsic spatio-temporal consistency in a self-supervised
manner. Our method achieves more accurate detection than traditional methods
and deep learning methods on three datasets with well-known yet hard-to-detect
emergent behaviors. Notably, our hierarchical framework is generic, which can
employ other deep learning methods for agent-level and system-level detection.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10302" title="Abstract">arXiv:2401.10302</a> [<a href="/pdf/2401.10302" title="Download PDF">pdf</a>, <a href="/format/2401.10302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Quantum Solvers in Production: how to succeed in the NISQ era?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osaba%2C+E">Eneko Osaba</a>, 
<a href="/search/cs?searchtype=author&query=Villar-Rodriguez%2C+E">Esther Villar-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Gomez-Tejedor%2C+A">Aitor Gomez-Tejedor</a>, 
<a href="/search/cs?searchtype=author&query=Oregi%2C+I">Izaskun Oregi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Hybrid quantum computing is considered the present and the future within the
field of quantum computing. Far from being a passing fad, this trend cannot be
considered just a stopgap to address the limitations of NISQ-era devices. The
foundations linking both computing paradigms will remain robust over time.
Despite buoyant research activity, the challenges in hybrid computing are still
countless, ranging from the proper characterization of current solvers to the
establishment of appropriate methodologies for the design and fair evaluation
of hybrid algorithms. The contribution of this work is twofold: first, we
describe and categorize some of the most frequently used hybrid solvers,
resorting to two different taxonomies recently published in the literature.
Secondly, we put a special focus on two solvers that are currently deployed in
real production and that have demonstrated to be near the real industry. These
solvers are the LeapHybridBQMSampler contained in D-Wave's Hybrid Solver
Service and Quantagonia's Hybrid Solver. We analyze the performance of both
hybrid methods using as benchmarks four well-known combinatorial optimization
problems: the Traveling Salesman Problem, Vehicle Routing Problem, Bin Packing
Problem, and Maximum Cut Problem. Thanks to the contributions presented in this
paper, the reader gains insight into the performance of those hybridization
strategies nowadays in production and close to the industrial markets.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10304" title="Abstract">arXiv:2401.10304</a> [<a href="/pdf/2401.10304" title="Download PDF">pdf</a>, <a href="/format/2401.10304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Readiness of Scientific Data for a Fair and Transparent Use in  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giner-Miguelez%2C+J">Joan Giner-Miguelez</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+A">Abel G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Cabot%2C+J">Jordi Cabot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Digital Libraries (cs.DL)

</div>
<p class="mathjax">To ensure the fairness and trustworthiness of machine learning (ML) systems,
recent legislative initiatives and relevant research in the ML community have
pointed out the need to document the data used to train ML models. Besides,
data-sharing practices in many scientific domains have evolved in recent years
for reproducibility purposes. In this sense, the adoption of these practices by
academic institutions has encouraged researchers to publish their data and
technical documentation in peer-reviewed publications such as data papers. In
this study, we analyze how this scientific data documentation meets the needs
of the ML community and regulatory bodies for its use in ML technologies. We
examine a sample of 4041 data papers of different domains, assessing their
completeness and coverage of the requested dimensions, and trends in recent
years, putting special emphasis on the most and least documented dimensions. As
a result, we propose a set of recommendation guidelines for data creators and
scientific data publishers to increase their data's preparedness for its
transparent and fairer use in ML technologies.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10310" title="Abstract">arXiv:2401.10310</a> [<a href="/pdf/2401.10310" title="Download PDF">pdf</a>, <a href="/format/2401.10310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical Algorithm Design for Deep Learning under Societal and  Judicial Constraints: The Algorithmic Transparency Requirement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boche%2C+H">Holger Boche</a>, 
<a href="/search/cs?searchtype=author&query=Fono%2C+A">Adalbert Fono</a>, 
<a href="/search/cs?searchtype=author&query=Kutyniok%2C+G">Gitta Kutyniok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC)

</div>
<p class="mathjax">Deep learning still has drawbacks in terms of trustworthiness, which
describes a comprehensible, fair, safe, and reliable method. To mitigate the
potential risk of AI, clear obligations associated to trustworthiness have been
proposed via regulatory guidelines, e.g., in the European AI Act. Therefore, a
central question is to what extent trustworthy deep learning can be realized.
Establishing the described properties constituting trustworthiness requires
that the factors influencing an algorithmic computation can be retraced, i.e.,
the algorithmic implementation is transparent. Motivated by the observation
that the current evolution of deep learning models necessitates a change in
computing technology, we derive a mathematical framework which enables us to
analyze whether a transparent implementation in a computing model is feasible.
We exemplarily apply our trustworthiness framework to analyze deep learning
approaches for inverse problems in digital and analog computing models
represented by Turing and Blum-Shub-Smale Machines, respectively. Based on
previous results, we find that Blum-Shub-Smale Machines have the potential to
establish trustworthy solvers for inverse problems under fairly general
conditions, whereas Turing machines cannot guarantee trustworthiness to the
same degree.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10313" title="Abstract">arXiv:2401.10313</a> [<a href="/pdf/2401.10313" title="Download PDF">pdf</a>, <a href="/format/2401.10313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hacking Predictors Means Hacking Cars: Using Sensitivity Analysis to  Identify Trajectory Prediction Vulnerabilities for Autonomous Driving  Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gibson%2C+M">Marsalis Gibson</a>, 
<a href="/search/cs?searchtype=author&query=Babazadeh%2C+D">David Babazadeh</a>, 
<a href="/search/cs?searchtype=author&query=Tomlin%2C+C">Claire Tomlin</a>, 
<a href="/search/cs?searchtype=author&query=Sastry%2C+S">Shankar Sastry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 1 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">Adversarial attacks on learning-based trajectory predictors have already been
demonstrated. However, there are still open questions about the effects of
perturbations on trajectory predictor inputs other than state histories, and
how these attacks impact downstream planning and control. In this paper, we
conduct a sensitivity analysis on two trajectory prediction models,
Trajectron++ and AgentFormer. We observe that between all inputs, almost all of
the perturbation sensitivities for Trajectron++ lie only within the most recent
state history time point, while perturbation sensitivities for AgentFormer are
spread across state histories over time. We additionally demonstrate that,
despite dominant sensitivity on state history perturbations, an undetectable
image map perturbation made with the Fast Gradient Sign Method can induce large
prediction error increases in both models. Even though image maps may
contribute slightly to the prediction output of both models, this result
reveals that rather than being robust to adversarial image perturbations,
trajectory predictors are susceptible to image attacks. Using an
optimization-based planner and example perturbations crafted from sensitivity
results, we show how this vulnerability can cause a vehicle to come to a sudden
stop from moderate driving speeds.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10314" title="Abstract">arXiv:2401.10314</a> [<a href="/pdf/2401.10314" title="Download PDF">pdf</a>, <a href="/format/2401.10314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LangProp: A code optimization framework using Language Models applied to  driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishida%2C+S">Shu Ishida</a>, 
<a href="/search/cs?searchtype=author&query=Corrado%2C+G">Gianluca Corrado</a>, 
<a href="/search/cs?searchtype=author&query=Fedoseev%2C+G">George Fedoseev</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+H">Hudson Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+L">Lloyd Russell</a>, 
<a href="/search/cs?searchtype=author&query=Shotton%2C+J">Jamie Shotton</a>, 
<a href="/search/cs?searchtype=author&query=Henriques%2C+J+F">Jo&#xe3;o F. Henriques</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+A">Anthony Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">LangProp is a framework for iteratively optimizing code generated by large
language models (LLMs) in a supervised/reinforcement learning setting. While
LLMs can generate sensible solutions zero-shot, the solutions are often
sub-optimal. Especially for code generation tasks, it is likely that the
initial code will fail on certain edge cases. LangProp automatically evaluates
the code performance on a dataset of input-output pairs, as well as catches any
exceptions, and feeds the results back to the LLM in the training loop, so that
the LLM can iteratively improve the code it generates. By adopting a metric-
and data-driven training paradigm for this code optimization procedure, one
could easily adapt findings from traditional machine learning techniques such
as imitation learning, DAgger, and reinforcement learning. We demonstrate the
first proof of concept of automated code optimization for autonomous driving in
CARLA, showing that LangProp can generate interpretable and transparent driving
policies that can be verified and improved in a metric- and data-driven way.
Our code will be open-sourced and is available at
https://github.com/shuishida/LangProp.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10315" title="Abstract">arXiv:2401.10315</a> [<a href="/pdf/2401.10315" title="Download PDF">pdf</a>, <a href="/format/2401.10315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Processing and Transmission Energy Optimization for ISAC in  Cell-Free Massive MIMO with URLLC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behdad%2C+Z">Zinat Behdad</a>, 
<a href="/search/cs?searchtype=author&query=Demir%2C+%C3%96+T">&#xd6;zlem Tu&#x11f;fe Demir</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+K+W">Ki Won Sung</a>, 
<a href="/search/cs?searchtype=author&query=Cavdar%2C+C">Cicek Cavdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures. arXiv admin note: text overlap with <a href="/abs/2401.10133">arXiv:2401.10133</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we explore the concept of integrated sensing and communication
(ISAC) within a downlink cell-free massive MIMO (multiple-input
multiple-output) system featuring multi-static sensing and users requiring
ultra-reliable low-latency communications (URLLC). Our focus involves the
formulation of two non-convex algorithms that jointly solve power and
blocklength allocation for end-to-end (E2E) minimization. The objectives are to
jointly minimize sensing/communication processing and transmission energy
consumption, while simultaneously meeting the requirements for sensing and
URLLC. To address the inherent non-convexity of these optimization problems, we
utilize techniques such as the Feasible Point Pursuit - Successive Convex
Approximation (FPP-SCA), Concave-Convex Programming (CCP), and fractional
programming. We conduct a comparative analysis of the performance of these
algorithms in ISAC scenarios and against a URLLC-only scenario where sensing is
not integrated. Our numerical results highlight the superior performance of the
E2E energy minimization algorithm, especially in scenarios without sensing
capability. Additionally, our study underscores the increasing prominence of
energy consumption associated with sensing processing tasks as the number of
sensing receive access points rises. Furthermore, the results emphasize that a
higher sensing signal-to-interference-plus-noise ratio threshold is associated
with an escalation in E2E energy consumption, thereby narrowing the performance
gap between the two proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10316" title="Abstract">arXiv:2401.10316</a> [<a href="/pdf/2401.10316" title="Download PDF">pdf</a>, <a href="/format/2401.10316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving One-class Recommendation with Multi-tasking on Various  Preference Intensities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+C">Chu-Jen Shao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hao-Ming Fu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pu-Jen Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RecSys 2020 (ACM Conference on Recommender Systems 2020)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> RecSys 2020: Proceedings of the 14th ACM Conference on Recommender
  Systems, Pages 498 to 502
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the one-class recommendation problem, it's required to make
recommendations basing on users' implicit feedback, which is inferred from
their action and inaction. Existing works obtain representations of users and
items by encoding positive and negative interactions observed from training
data. However, these efforts assume that all positive signals from implicit
feedback reflect a fixed preference intensity, which is not realistic.
Consequently, representations learned with these methods usually fail to
capture informative entity features that reflect various preference
intensities.
<br />In this paper, we propose a multi-tasking framework taking various preference
intensities of each signal from implicit feedback into consideration.
Representations of entities are required to satisfy the objective of each
subtask simultaneously, making them more robust and generalizable. Furthermore,
we incorporate attentive graph convolutional layers to explore high-order
relationships in the user-item bipartite graph and dynamically capture the
latent tendencies of users toward the items they interact with. Experimental
results show that our method performs better than state-of-the-art methods by a
large margin on three large-scale real-world benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10337" title="Abstract">arXiv:2401.10337</a> [<a href="/pdf/2401.10337" title="Download PDF">pdf</a>, <a href="/format/2401.10337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise Contrastive Estimation-based Matching Framework for Low-resource  Security Attack Pattern Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Srndic%2C+N">Nedim Srndic</a>, 
<a href="/search/cs?searchtype=author&query=Neth%2C+A">Alexander Neth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at EACL 2024, in ARR October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Tactics, Techniques and Procedures (TTPs) represent sophisticated attack
patterns in the cybersecurity domain, described encyclopedically in textual
knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP
mapping, is an important and challenging task. Conventional learning approaches
often target the problem in the classical multi-class or multilabel
classification setting. This setting hinders the learning ability of the model
due to a large number of classes (i.e., TTPs), the inevitable skewness of the
label distribution and the complex hierarchical structure of the label space.
We formulate the problem in a different learning paradigm, where the assignment
of a text to a TTP label is decided by the direct semantic similarity between
the two, thus reducing the complexity of competing solely over the large
labeling space. To that end, we propose a neural matching architecture with an
effective sampling-based learn-to-compare mechanism, facilitating the learning
process of the matching model despite constrained resources.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10338" title="Abstract">arXiv:2401.10338</a> [<a href="/pdf/2401.10338" title="Download PDF">pdf</a>, <a href="/ps/2401.10338" title="Download PostScript">ps</a>, <a href="/format/2401.10338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MELODY: Robust Semi-Supervised Hybrid Model for Entity-Level Online  Anomaly Detection with Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jingchao Ni</a>, 
<a href="/search/cs?searchtype=author&query=Guinet%2C+G">Gauthier Guinet</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peihong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Callot%2C+L">Laurent Callot</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+A">Andrey Kan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In large IT systems, software deployment is a crucial process in online
services as their code is regularly updated. However, a faulty code change may
degrade the target service's performance and cause cascading outages in
downstream services. Thus, software deployments should be comprehensively
monitored, and their anomalies should be detected timely. In this paper, we
study the problem of anomaly detection for deployments. We begin by identifying
the challenges unique to this anomaly detection problem, which is at
entity-level (e.g., deployments), relative to the more typical problem of
anomaly detection in multivariate time series (MTS). The unique challenges
include the heterogeneity of deployments, the low latency tolerance, the
ambiguous anomaly definition, and the limited supervision. To address them, we
propose a novel framework, semi-supervised hybrid Model for Entity-Level Online
Detection of anomalY (MELODY). MELODY first transforms the MTS of different
entities to the same feature space by an online feature extractor, then uses a
newly proposed semi-supervised deep one-class model for detecting anomalous
entities. We evaluated MELODY on real data of cloud services with 1.2M+ time
series. The relative F1 score improvement of MELODY over the state-of-the-art
methods ranges from 7.6% to 56.5%. The user evaluation suggests MELODY is
suitable for monitoring deployments in large online systems.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10341" title="Abstract">arXiv:2401.10341</a> [<a href="/pdf/2401.10341" title="Download PDF">pdf</a>, <a href="/format/2401.10341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ELRT: Efficient Low-Rank Training for Compact Convolutional Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yang Sui</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Miao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yu Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jinqi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+H">Huy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Bo Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Low-rank compression, a popular model compression technique that produces
compact convolutional neural networks (CNNs) with low rankness, has been
well-studied in the literature. On the other hand, low-rank training, as an
alternative way to train low-rank CNNs from scratch, has been exploited little
yet. Unlike low-rank compression, low-rank training does not need pre-trained
full-rank models, and the entire training phase is always performed on the
low-rank structure, bringing attractive benefits for practical applications.
However, the existing low-rank training solutions still face several
challenges, such as a considerable accuracy drop and/or still needing to update
full-size models during the training. In this paper, we perform a systematic
investigation on low-rank CNN training. By identifying the proper low-rank
format and performance-improving strategy, we propose ELRT, an efficient
low-rank training solution for high-accuracy, high-compactness, low-rank CNN
models. Our extensive evaluation results for training various CNNs on different
datasets demonstrate the effectiveness of ELRT.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10352" title="Abstract">arXiv:2401.10352</a> [<a href="/pdf/2401.10352" title="Download PDF">pdf</a>, <a href="/format/2401.10352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Cultural Nuances in Dialogue Agents through Cultural Value  Surveys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Min Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hershcovich%2C+D">Daniel Hershcovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16pages, 7 figures, EACL 2024 main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The cultural landscape of interactions with dialogue agents is a compelling
yet relatively unexplored territory. It's clear that various sociocultural
aspects -- from communication styles and beliefs to shared metaphors and
knowledge -- profoundly impact these interactions. To delve deeper into this
dynamic, we introduce cuDialog, a first-of-its-kind benchmark for dialogue
generation with a cultural lens. We also develop baseline models capable of
extracting cultural attributes from dialogue exchanges, with the goal of
enhancing the predictive accuracy and quality of dialogue agents. To
effectively co-learn cultural understanding and multi-turn dialogue
predictions, we propose to incorporate cultural dimensions with dialogue
encoding features. Our experimental findings highlight that incorporating
cultural value surveys boosts alignment with references and cultural markers,
demonstrating its considerable influence on personalization and dialogue
quality. To facilitate further exploration in this exciting domain, we publish
our benchmark publicly accessible at https://github.com/yongcaoplus/cuDialog.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10353" title="Abstract">arXiv:2401.10353</a> [<a href="/pdf/2401.10353" title="Download PDF">pdf</a>, <a href="/format/2401.10353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inconsistent dialogue responses and how to recover from them
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lifeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linfeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+H">Haitao Mi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in EACL 2024. Code and dataset available at <a href="https://github.com/mianzhang/CIDER">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">One critical issue for chat systems is to stay consistent about preferences,
opinions, beliefs and facts of itself, which has been shown a difficult
problem. In this work, we study methods to assess and bolster utterance
consistency of chat systems. A dataset is first developed for studying the
inconsistencies, where inconsistent dialogue responses, explanations of the
inconsistencies, and recovery utterances are authored by annotators. This
covers the life span of inconsistencies, namely introduction, understanding,
and resolution. Building on this, we introduce a set of tasks centered on
dialogue consistency, specifically focused on its detection and resolution. Our
experimental findings indicate that our dataset significantly helps the
progress in identifying and resolving conversational inconsistencies, and
current popular large language models like ChatGPT which are good at resolving
inconsistencies however still struggle with detection.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10354" title="Abstract">arXiv:2401.10354</a> [<a href="/pdf/2401.10354" title="Download PDF">pdf</a>, <a href="/format/2401.10354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards providing reliable job completion time predictions using PCS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faisal%2C+A+B">Abdullah Bin Faisal</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+N">Noah Martin</a>, 
<a href="/search/cs?searchtype=author&query=Bashir%2C+H+M">Hafiz Mohsin Bashir</a>, 
<a href="/search/cs?searchtype=author&query=Lamelas%2C+S">Swaminathan Lamelas</a>, 
<a href="/search/cs?searchtype=author&query=Dogar%2C+F+R">Fahad R. Dogar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper we build a case for providing job completion time predictions
to cloud users, similar to the delivery date of a package or arrival time of a
booked ride. Our analysis reveals that providing predictability can come at the
expense of performance and fairness. Existing cloud scheduling systems optimize
for extreme points in the trade-off space, making them either extremely
unpredictable or impractical.
<br />To address this challenge, we present PCS, a new scheduling framework that
aims to provide predictability while balancing other traditional objectives.
The key idea behind PCS is to use Weighted-Fair-Queueing (WFQ) and find a
suitable configuration of different WFQ parameters (e.g., class weights) that
meets specific goals for predictability. It uses a simulation-aided search
strategy, to efficiently discover WFQ configurations that lie on the Pareto
front of the trade-off space between these objectives. We implement and
evaluate PCS in the context of DNN job scheduling on GPUs. Our evaluation, on a
small scale GPU testbed and larger-scale simulations, shows that PCS can
provide accurate completion time estimates while marginally compromising on
performance and fairness.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10357" title="Abstract">arXiv:2401.10357</a> [<a href="/pdf/2401.10357" title="Download PDF">pdf</a>, <a href="/format/2401.10357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring User Interface Accessibility for Color Blind Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jamil%2C+A">Amaan Jamil</a>, 
<a href="/search/cs?searchtype=author&query=Denes%2C+G">Gyorgy Denes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, submitted to MDPI Computers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Color vision deficiency (CVD, color blindness) is the failure or decreased
ability to distinguish between colors under normal lighting conditions. There
are over 300 million people worldwide with CVD, including approx. 1 in 12 men
(8%) and 1 in 250 women (0.5%). CVD can limit a user's ability to interact with
websites and software packages that are otherwise basic commodities. User
interface designers have taken various approaches to tackle the issue with some
interfaces offering a high contrast mode, and others integrating color-blind
awareness into their website design process. The Web Content Accessibility
Guidelines (WCAG) outline some best practices for maintaining accessibility
that have been adopted and recommended by several governments; however, it is
currently uncertain how this impacts perceived user functionality and if this
could result in a reduced aesthetic look. In our work, we present a subjective
user study to measure the loss of functionality and aesthetics as potentially
seen by CVD observers for 20 popular websites and software packages. As
recruiting participants with CVD is non-trivial, we developed a
simulation-based pipeline instead for our full-reference mean opinion score
experiment, which as far as we know is a novelty in the field. Our results show
that relative aesthetics and functionality correlate positively and that an
operating-system-wide high contrast mode can reduce both aesthetics and
functionality for CVD users. Finally, we propose a AAA--A classification of the
interfaces we analyzed.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10359" title="Abstract">arXiv:2401.10359</a> [<a href="/pdf/2401.10359" title="Download PDF">pdf</a>, <a href="/format/2401.10359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keeping Deep Learning Models in Check: A History-Based Approach to  Mitigate Overfitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Rajbahadur%2C+G+K">Gopi Krishnan Rajbahadur</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dayi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Bezemer%2C+C">Cor-Paul Bezemer</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Z">Zhen Ming</a> (Jack)
<a href="/search/cs?searchtype=author&query=Jiang">Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In software engineering, deep learning models are increasingly deployed for
critical tasks such as bug detection and code review. However, overfitting
remains a challenge that affects the quality, reliability, and trustworthiness
of software systems that utilize deep learning models. Overfitting can be (1)
prevented (e.g., using dropout or early stopping) or (2) detected in a trained
model (e.g., using correlation-based approaches). Both overfitting detection
and prevention approaches that are currently used have constraints (e.g.,
requiring modification of the model structure, and high computing resources).
In this paper, we propose a simple, yet powerful approach that can both detect
and prevent overfitting based on the training history (i.e., validation
losses). Our approach first trains a time series classifier on training
histories of overfit models. This classifier is then used to detect if a
trained model is overfit. In addition, our trained classifier can be used to
prevent overfitting by identifying the optimal point to stop a model's
training. We evaluate our approach on its ability to identify and prevent
overfitting in real-world samples. We compare our approach against
correlation-based detection approaches and the most commonly used prevention
approach (i.e., early stopping). Our approach achieves an F1 score of 0.91
which is at least 5% higher than the current best-performing non-intrusive
overfitting detection approach. Furthermore, our approach can stop training to
avoid overfitting at least 32% of the times earlier than early stopping and has
the same or a better rate of returning the best model.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10360" title="Abstract">arXiv:2401.10360</a> [<a href="/pdf/2401.10360" title="Download PDF">pdf</a>, <a href="/ps/2401.10360" title="Download PostScript">ps</a>, <a href="/format/2401.10360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Excuse me, sir? Your language model is leaking (information)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zamir%2C+O">Or Zamir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a cryptographic method to hide an arbitrary secret payload in
the response of a Large Language Model (LLM). A secret key is required to
extract the payload from the model's response, and without the key it is
provably impossible to distinguish between the responses of the original LLM
and the LLM that hides a payload. In particular, the quality of generated text
is not affected by the payload. Our approach extends a recent result of Christ,
Gunn and Zamir (2023) who introduced an undetectable watermarking scheme for
LLMs.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10361" title="Abstract">arXiv:2401.10361</a> [<a href="/pdf/2401.10361" title="Download PDF">pdf</a>, <a href="/format/2401.10361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Federated Learning in Multi-hop Cluster-Based VANETs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=HaghighiFard%2C+M+S">M. Saeid HaghighiFard</a>, 
<a href="/search/cs?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">The usage of federated learning (FL) in Vehicular Ad hoc Networks (VANET) has
garnered significant interest in research due to the advantages of reducing
transmission overhead and protecting user privacy by communicating local
dataset gradients instead of raw data. However, implementing FL in VANETs faces
challenges, including limited communication resources, high vehicle mobility,
and the statistical diversity of data distributions. In order to tackle these
issues, this paper introduces a novel framework for hierarchical federated
learning (HFL) over multi-hop clustering-based VANET. The proposed method
utilizes a weighted combination of the average relative speed and cosine
similarity of FL model parameters as a clustering metric to consider both data
diversity and high vehicle mobility. This metric ensures convergence with
minimum changes in cluster heads while tackling the complexities associated
with non-independent and identically distributed (non-IID) data scenarios.
Additionally, the framework includes a novel mechanism to manage seamless
transitions of cluster heads (CHs), followed by transferring the most recent FL
model parameter to the designated CH. Furthermore, the proposed approach
considers the option of merging CHs, aiming to reduce their count and,
consequently, mitigate associated overhead. Through extensive simulations, the
proposed hierarchical federated learning over clustered VANET has been
demonstrated to improve accuracy and convergence time significantly while
maintaining an acceptable level of packet overhead compared to previously
proposed clustering algorithms and non-clustered VANET.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10363" title="Abstract">arXiv:2401.10363</a> [<a href="/pdf/2401.10363" title="Download PDF">pdf</a>, <a href="/ps/2401.10363" title="Download PostScript">ps</a>, <a href="/format/2401.10363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verification and Enforcement of Strong State-Based Opacity for  Discrete-Event Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kuize Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiwu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 20 figures, partial results in Section 3 were presented at IEEE Conference on Decision and Control, 2022. arXiv admin note: text overlap with <a href="/abs/2204.04698">arXiv:2204.04698</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">In this paper, we investigate the verification and enforcement of strong
state-based opacity (SBO) in discrete-event systems modeled as
partially-observed (nondeterministic) finite-state automata, including strong
K-step opacity (K-SSO), strong current-state opacity (SCSO), strong
initial-state opacity (SISO), and strong infinite-step opacity (Inf-SSO). They
are stronger versions of four widely-studied standard opacity notions,
respectively. We firstly propose a new notion of K-SSO, and then we construct a
concurrent-composition structure that is a variant of our previously-proposed
one to verify it. Based on this structure, a verification algorithm for the
proposed notion of K-SSO is designed. Also, an upper bound on K in the proposed
K-SSO is derived. Secondly, we propose a distinctive opacity-enforcement
mechanism that has better scalability than the existing ones (such as
supervisory control). The basic philosophy of this new mechanism is choosing a
subset of controllable transitions to disable before an original system starts
to run in order to cut off all its runs that violate a notion of strong SBO of
interest. Accordingly, the algorithms for enforcing the above-mentioned four
notions of strong SBO are designed using the proposed two
concurrent-composition structures. In particular, the designed algorithm for
enforcing Inf-SSO has lower time complexity than the existing one in the
literature, and does not depend on any assumption. Finally, we illustrate the
applications of the designed algorithms using examples.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10364" title="Abstract">arXiv:2401.10364</a> [<a href="/pdf/2401.10364" title="Download PDF">pdf</a>, <a href="/ps/2401.10364" title="Download PostScript">ps</a>, <a href="/format/2401.10364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using LLM such as ChatGPT for Designing and Implementing a RISC  Processor: Execution,Challenges and Limitations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hossain%2C+S">Shadeeb Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Gohil%2C+A">Aayush Gohil</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Software Engineering (cs.SE)

</div>
<p class="mathjax">This paper discusses the feasibility of using Large Language Models LLM for
code generation with a particular application in designing an RISC. The paper
also reviews the associated steps such as parsing, tokenization, encoding,
attention mechanism, sampling the tokens and iterations during code generation.
The generated code for the RISC components is verified through testbenches and
hardware implementation on a FPGA board. Four metric parameters Correct output
on the first iteration, Number of errors embedded in the code, Number of trials
required to achieve the code and Failure to generate the code after three
iterations, are used to compare the efficiency of using LLM in programming. In
all the cases, the generated code had significant errors and human intervention
was always required to fix the bugs. LLM can therefore be used to complement a
programmer code design.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10367" title="Abstract">arXiv:2401.10367</a> [<a href="/pdf/2401.10367" title="Download PDF">pdf</a>, <a href="/format/2401.10367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> gFaaS: Enabling Generic Functions in Serverless Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chadha%2C+M">Mohak Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Wieland%2C+P">Paul Wieland</a>, 
<a href="/search/cs?searchtype=author&query=Gerndt%2C+M">Michael Gerndt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE SANER 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">With the advent of AWS Lambda in 2014, Serverless Computing, particularly
Function-as-a-Service (FaaS), has witnessed growing popularity across various
application domains. FaaS enables an application to be decomposed into
fine-grained functions that are executed on a FaaS platform. It offers several
advantages such as no infrastructure management, a pay-per-use billing policy,
and on-demand fine-grained autoscaling. However, despite its advantages,
developers today encounter various challenges while adopting FaaS solutions
that reduce productivity. These include FaaS platform lock-in, support for
diverse function deployment parameters, and diverse interfaces for interacting
with FaaS platforms. To address these challenges, we present gFaaS, a novel
framework that facilitates the holistic development and management of functions
across diverse FaaS platforms. Our framework enables the development of generic
functions in multiple programming languages that can be seamlessly deployed
across different platforms without modifications. Results from our experiments
demonstrate that gFaaS functions perform similarly to native platform-specific
functions across various scenarios. A video demonstrating the functioning of
gFaaS is available from https://youtu.be/STbb6ykJFf0.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10368" title="Abstract">arXiv:2401.10368</a> [<a href="/pdf/2401.10368" title="Download PDF">pdf</a>, <a href="/format/2401.10368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HRL-TSCH: A Hierarchical Reinforcement Learning-based TSCH Scheduler for  IIoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jurado-Lasso%2C+F+F">F. Fernando Jurado-Lasso</a>, 
<a href="/search/cs?searchtype=author&query=Orfanidis%2C+C">Charalampos Orfanidis</a>, 
<a href="/search/cs?searchtype=author&query=Jurado%2C+J+F">J. F. Jurado</a>, 
<a href="/search/cs?searchtype=author&query=Fafoutis%2C+X">Xenofon Fafoutis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, 3 tables, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The Industrial Internet of Things (IIoT) demands adaptable Networked Embedded
Systems (NES) for optimal performance. Combined with recent advances in
Artificial Intelligence (AI), tailored solutions can be developed to meet
specific application requirements. This study introduces HRL-TSCH, an approach
rooted in Hierarchical Reinforcement Learning (HRL), to devise Time Slotted
Channel Hopping (TSCH) schedules provisioning IIoT demand. HRL-TSCH employs
dual policies: one at a higher level for TSCH schedule link management, and
another at a lower level for timeslot and channel assignments. The proposed RL
agents address a multi-objective problem, optimizing throughput, power
efficiency, and network delay based on predefined application requirements.
Simulation experiments demonstrate HRL-TSCH superiority over existing
state-of-art approaches, effectively achieving an optimal balance between
throughput, power consumption, and delay, thereby enhancing IIoT network
performance.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10369" title="Abstract">arXiv:2401.10369</a> [<a href="/pdf/2401.10369" title="Download PDF">pdf</a>, <a href="/format/2401.10369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motorway: Seamless high speed BFT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giridharan%2C+N">Neil Giridharan</a>, 
<a href="/search/cs?searchtype=author&query=Suri-Payer%2C+F">Florian Suri-Payer</a>, 
<a href="/search/cs?searchtype=author&query=Abraham%2C+I">Ittai Abraham</a>, 
<a href="/search/cs?searchtype=author&query=Alvisi%2C+L">Lorenzo Alvisi</a>, 
<a href="/search/cs?searchtype=author&query=Crooks%2C+N">Natacha Crooks</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Today's practical, high performance Byzantine Fault Tolerant (BFT) consensus
protocols operate in the partial synchrony model. However, existing protocols
are often inefficient when networks are indeed partially synchronous. They
obtain either low latency during synchrony or robust recovery from periods of
asynchrony. At one end, traditional, view-based BFT protocols optimize for
latency in the sunny-network case, but when faced with periods of asynchrony
are subject to performance degradations (hangovers) that can last beyond the
return to synchrony. At the other end, modern DAG-based BFT protocols recover
gracefully from asynchrony, but exhibit lackluster latency during synchronous
intervals. To close the gap, this work presents Motorway, a novel
high-throughput BFT protocol that offers both low latency and seamless recovery
from periods of asynchrony. Motorway combines a highly parallel asynchronous
data dissemination layer with a low-latency, partially synchronous consensus
mechanism to construct an efficient consensus protocol for partial synchrony.
Motorway (i) avoids the hangovers incurred by traditional BFT protocols and
(ii) matches the throughput of state of the art DAG-BFT protocols while
reducing latency by 2.1x, matching the latency of traditional BFT protocols.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10371" title="Abstract">arXiv:2401.10371</a> [<a href="/pdf/2401.10371" title="Download PDF">pdf</a>, <a href="/format/2401.10371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Langevin Unlearning: A New Perspective of Noisy Gradient Descent for  Machine Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chien%2C+E">Eli Chien</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine unlearning has raised significant interest with the adoption of laws
ensuring the ``right to be forgotten''. Researchers have provided a
probabilistic notion of approximate unlearning under a similar definition of
Differential Privacy (DP), where privacy is defined as statistical
indistinguishability to retraining from scratch. We propose Langevin
unlearning, an unlearning framework based on noisy gradient descent with
privacy guarantees for approximate unlearning problems. Langevin unlearning
unifies the DP learning process and the privacy-certified unlearning process
with many algorithmic benefits. These include approximate certified unlearning
for non-convex problems, complexity saving compared to retraining, sequential
and batch unlearning for multiple unlearning requests. We verify the
practicality of Langevin unlearning by studying its privacy-utility-complexity
trade-off via experiments on benchmark datasets, and also demonstrate its
superiority against gradient-decent-plus-output-perturbation based approximate
unlearning.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10372" title="Abstract">arXiv:2401.10372</a> [<a href="/pdf/2401.10372" title="Download PDF">pdf</a>, <a href="/format/2401.10372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MutaBot: A Mutation Testing Approach for Chatbots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Urrico%2C+M+F">Michael Ferdinando Urrico</a>, 
<a href="/search/cs?searchtype=author&query=Clerissi%2C+D">Diego Clerissi</a>, 
<a href="/search/cs?searchtype=author&query=Mariani%2C+L">Leonardo Mariani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mutation testing is a technique aimed at assessing the effectiveness of test
suites by seeding artificial faults into programs. Although available for many
platforms and languages, no mutation testing tool is currently available for
conversational chatbots, which represent an increasingly popular solution to
design systems that can interact with users through a natural language
interface. Note that since conversations must be explicitly engineered by the
developers of conversational chatbots, these systems are exposed to specific
types of faults not supported by existing mutation testing tools.
<br />In this paper, we present MutaBot, a mutation testing tool for conversational
chatbots. MutaBot addresses mutations at multiple levels, including
conversational flows, intents, and contexts. We designed the tool to
potentially target multiple platforms, while we implemented initial support for
Google Dialogflow chatbots. We assessed the tool with three Dialogflow chatbots
and test cases generated with Botium, revealing weaknesses in the test suites.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10375" title="Abstract">arXiv:2401.10375</a> [<a href="/pdf/2401.10375" title="Download PDF">pdf</a>, <a href="/format/2401.10375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vulnerabilities of Foundation Model Integrated Federated Learning Under  Adversarial Threats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Chen Wu and Xi Li are equal contribution. The corresponding author is Jiaqi Wang
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) addresses critical issues in machine learning related
to data privacy and security, yet suffering from data insufficiency and
imbalance under certain circumstances. The emergence of foundation models (FMs)
offers potential solutions to the limitations of existing FL frameworks, e.g.,
by generating synthetic data for model initialization. However, due to the
inherent safety concerns of FMs, integrating FMs into FL could introduce new
risks, which remains largely unexplored. To address this gap, we conduct the
first investigation on the vulnerability of FM integrated FL (FM-FL) under
adversarial threats. Based on a unified framework of FM-FL, we introduce a
novel attack strategy that exploits safety issues of FM to compromise FL client
models. Through extensive experiments with well-known models and benchmark
datasets in both image and text domains, we reveal the high susceptibility of
the FM-FL to this new threat under various FL configurations. Furthermore, we
find that existing FL defense strategies offer limited protection against this
novel attack approach. This research highlights the critical need for enhanced
security measures in FL in the era of FMs.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10376" title="Abstract">arXiv:2401.10376</a> [<a href="/pdf/2401.10376" title="Download PDF">pdf</a>, <a href="/format/2401.10376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAC Code Rate-Profile Design Using Search-Constrained Optimization  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moradi%2C+M">Mohsen Moradi</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+D+G+M">David G. M. Mitchell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we introduce a novel rate-profile design based on
search-constrained optimization techniques to assess the performance of
polarization-adjusted convolutional (PAC) codes under Fano (sequential)
decoding. The results demonstrate that the resulting PAC code offers much
reduced computational complexity compared to a construction based on a
conventional genetic algorithm without a performance loss in error-correction
performance. As the fitness function of our algorithm, we propose an adaptive
successive cancellation list decoding algorithm to determine the weight
distribution of the rate profiles. The simulation results indicate that, for a
PAC(256, 128) code, only 8% of the population requires that their fitness
function be evaluated with a large list size. This represents an improvement of
almost 92% over a conventional evolutionary algorithm. For a PAC(64, 32) code,
this improvement is about 99%. We also plotted the performance of the high-rate
PAC(128, 105) and PAC(64, 51) codes, and the results show that they exhibit
superior performance compared to other algorithms.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10379" title="Abstract">arXiv:2401.10379</a> [<a href="/pdf/2401.10379" title="Download PDF">pdf</a>, <a href="/ps/2401.10379" title="Download PostScript">ps</a>, <a href="/format/2401.10379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agricultural Object Detection with You Look Only Once (YOLO) Algorithm:  A Bibliometric and Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badgujar%2C+C+M">Chetan M Badgujar</a>, 
<a href="/search/cs?searchtype=author&query=Poulose%2C+A">Alwin Poulose</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+H">Hao Gan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Vision is a major component in several digital technologies and tools used in
agriculture. The object detector, You Look Only Once (YOLO), has gained
popularity in agriculture in a relatively short span due to its
state-of-the-art performance. YOLO offers real-time detection with good
accuracy and is implemented in various agricultural tasks, including
monitoring, surveillance, sensing, automation, and robotics. The research and
application of YOLO in agriculture are accelerating rapidly but are fragmented
and multidisciplinary. Moreover, the performance characteristics (i.e.,
accuracy, speed, computation) of the object detector influence the rate of
technology implementation and adoption in agriculture. Thus, the study aims to
collect extensive literature to document and critically evaluate the advances
and application of YOLO for agricultural object recognition. First, we
conducted a bibliometric review of 257 articles to understand the scholarly
landscape of YOLO in agricultural domain. Secondly, we conducted a systematic
review of 30 articles to identify current knowledge, gaps, and modifications in
YOLO for specific agricultural tasks. The study critically assesses and
summarizes the information on YOLO's end-to-end learning approach, including
data acquisition, processing, network modification, integration, and
deployment. We also discussed task-specific YOLO algorithm modification and
integration to meet the agricultural object or environment-specific challenges.
In general, YOLO-integrated digital tools and technologies show the potential
for real-time, automated monitoring, surveillance, and object handling to
reduce labor, production cost, and environmental impact while maximizing
resource efficiency. The study provides detailed documentation and
significantly advances the existing knowledge on applying YOLO in agriculture,
which can greatly benefit the scientific community.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10382" title="Abstract">arXiv:2401.10382</a> [<a href="/pdf/2401.10382" title="Download PDF">pdf</a>, <a href="/format/2401.10382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Node Placement and Path Planning for Improved Area Coverage in Mixed  Wireless Sensor Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumari%2C+S">Survi Kumari</a>, 
<a href="/search/cs?searchtype=author&query=Srirangarajan%2C+S">Seshan Srirangarajan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">For the large-scale monitoring of a physical phenomena using a wireless
sensor network (WSN), a large number of static and/or mobile sensor nodes are
required, resulting in higher deployment cost. In this work, we develop an
efficient algorithm that can employ a small number of static nodes together
with a set of mobile nodes for improved area coverage. An efficient deployment
of static nodes and guided mobility of the mobile nodes is critical for
maximizing the area coverage. To this end, we propose three mixed integer
linear programming (MILP) formulations. The first formulation efficiently
deploys a set of static nodes and the other two formulations plan the path of a
set of mobile nodes so as to maximize the area coverage and minimize the total
number of movements required to achieve the desired coverage. We present
extensive performance evaluation of the proposed algorithms and its comparison
with benchmark approaches. The simulation results demonstrate the superior
performance of the proposed algorithms for different network sizes and number
of static and mobile nodes.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10383" title="Abstract">arXiv:2401.10383</a> [<a href="/pdf/2401.10383" title="Download PDF">pdf</a>, <a href="/format/2401.10383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paschalidis%2C+P">Phevos Paschalidis</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Runyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Na Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we formulate the multi-agent graph bandit problem as a
multi-agent extension of the graph bandit problem introduced by Zhang,
Johansson, and Li [CISS 57, 1-6 (2023)]. In our formulation, $N$ cooperative
agents travel on a connected graph $G$ with $K$ nodes. Upon arrival at each
node, agents observe a random reward drawn from a node-dependent probability
distribution. The reward of the system is modeled as a weighted sum of the
rewards the agents observe, where the weights capture the decreasing marginal
reward associated with multiple agents sampling the same node at the same time.
We propose an Upper Confidence Bound (UCB)-based learning algorithm,
Multi-G-UCB, and prove that its expected regret over $T$ steps is bounded by
$O(N\log(T)[\sqrt{KT} + DK])$, where $D$ is the diameter of graph $G$. Lastly,
we numerically test our algorithm by comparing it to alternative methods.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10385" title="Abstract">arXiv:2401.10385</a> [<a href="/pdf/2401.10385" title="Download PDF">pdf</a>, <a href="/format/2401.10385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation of Solution Operators for High-dimensional PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gaby%2C+N">Nathan Gaby</a>, 
<a href="/search/math?searchtype=author&query=Ye%2C+X">Xiaojing Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 page appendix, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a finite-dimensional control-based method to approximate solution
operators for evolutional partial differential equations (PDEs), particularly
in high-dimensions. By employing a general reduced-order model, such as a deep
neural network, we connect the evolution of the model parameters with
trajectories in a corresponding function space. Using the computational
technique of neural ordinary differential equation, we learn the control over
the parameter space such that from any initial starting point, the controlled
trajectories closely approximate the solutions to the PDE. Approximation
accuracy is justified for a general class of second-order nonlinear PDEs.
Numerical results are presented for several high-dimensional PDEs, including
real-world applications to solving Hamilton-Jacobi-Bellman equations. These are
demonstrated to show the accuracy and efficiency of the proposed method.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10386" title="Abstract">arXiv:2401.10386</a> [<a href="/pdf/2401.10386" title="Download PDF">pdf</a>, <a href="/format/2401.10386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noninvasive Acute Compartment Syndrome Diagnosis Using Random Forest  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hweij%2C+Z+A">Zaina Abu Hweij</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+F">Florence Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sophie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Acute compartment syndrome (ACS) is an orthopedic emergency, caused by
elevated pressure within a muscle compartment, that leads to permanent tissue
damage and eventually death. Diagnosis of ACS relies heavily on
patient-reported symptoms, a method that is clinically unreliable and often
supplemented with invasive intracompartmental pressure measurements. This study
proposes a continuous, objective, noninvasive diagnostic for ACS. The device
detects ACS through a random forest machine learning model that uses pressure
readings from force-sensitive resistors (FSRs) placed on the skin. The final
diagnosis is exported real-time to a web application via Bluetooth. To validate
the diagnostic, a data set containing FSR measurements and the corresponding
simulated intracompartmental pressure was created. The diagnostic achieved an
accuracy, on par to the invasive gold standard, of 97%. The device excelled in
key performance metrics including precision, sensitivity, and F1 score.
Manufactured for 73 USD, our device may be an economic alternative to
needle-based diagnostics. These results demonstrate the potential of
noninvasive ACS diagnostics to meet clinical standards and enhance patient
care.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10387" title="Abstract">arXiv:2401.10387</a> [<a href="/pdf/2401.10387" title="Download PDF">pdf</a>, <a href="/format/2401.10387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bypassing a Reactive Jammer via NOMA-Based Transmissions in Critical  Missions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amini%2C+M">Mohammadreza Amini</a>, 
<a href="/search/cs?searchtype=author&query=Asemian%2C+G">Ghazal Asemian</a>, 
<a href="/search/cs?searchtype=author&query=Kulhandjian%2C+M">Michel Kulhandjian</a>, 
<a href="/search/cs?searchtype=author&query=Kantarci%2C+B">Burak Kantarci</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amours%2C+C">Claude D&#x27;Amours</a>, 
<a href="/search/cs?searchtype=author&query=Erol-Kantarci%2C+M">Melike Erol-Kantarci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures, IEEE International Conference on Communications (ICC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Wireless networks can be vulnerable to radio jamming attacks. The quality of
service under a jamming attack is not guaranteed and the service requirements
such as reliability, latency, and effective rate, specifically in
mission-critical military applications, can be deeply affected by the jammer's
actions. This paper analyzes the effect of a reactive jammer. Particularly,
reliability, average transmission delay, and the effective sum rate (ESR) for a
NOMA-based scheme with finite blocklength transmissions are mathematically
derived taking the detection probability of the jammer into account.
Furthermore, the effect of UEs' allocated power and blocklength on the network
metrics is explored. Contrary to the existing literature, results show that gNB
can mitigate the impact of reactive jamming by decreasing transmit power,
making the transmissions covert at the jammer side. Finally, an optimization
problem is formulated to maximize the ESR under reliability, delay, and
transmit power constraints. It is shown that by adjusting the allocated
transmit power to UEs by gNB, the gNB can bypass the jammer effect to fulfill
the 0.99999 reliability and the latency of 5ms without the need for packet
re-transmission.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10390" title="Abstract">arXiv:2401.10390</a> [<a href="/pdf/2401.10390" title="Download PDF">pdf</a>, <a href="/ps/2401.10390" title="Download PostScript">ps</a>, <a href="/format/2401.10390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Interplay Between Network Metrics and Performance of Mobile Edge  Offloading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moshiri%2C+P+F">Parisa Fard Moshiri</a>, 
<a href="/search/cs?searchtype=author&query=Simsek%2C+M">Murat Simsek</a>, 
<a href="/search/cs?searchtype=author&query=Kantarci%2C+B">Burak Kantarci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, IEEE International Conference on Communications (ICC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Multi-Access Edge Computing (MEC) emerged as a viable computing allocation
method that facilitates offloading tasks to edge servers for efficient
processing. The integration of MEC with 5G, referred to as 5G-MEC, provides
real-time processing and data-driven decision-making in close proximity to the
user. The 5G-MEC has gained significant recognition in task offloading as an
essential tool for applications that require low delay. Nevertheless, few
studies consider the dropped task ratio metric. Disregarding this metric might
possibly undermine system efficiency. In this paper, the dropped task ratio and
delay has been minimized in a realistic 5G-MEC task offloading scenario
implemented in NS3. We utilize Mixed Integer Linear Programming (MILP) and
Genetic Algorithm (GA) to optimize delay and dropped task ratio. We examined
the effect of the number of tasks and users on the dropped task ratio and
delay. Compared to two traditional offloading schemes, First Come First Serve
(FCFS) and Shortest Task First (STF), our proposed method effectively works in
5G-MEC task offloading scenario. For MILP, the dropped task ratio and delay has
been minimized by 20% and 2ms compared to GA.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10393" title="Abstract">arXiv:2401.10393</a> [<a href="/pdf/2401.10393" title="Download PDF">pdf</a>, <a href="/format/2401.10393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catastrophic Interference is Mitigated in Naturalistic Power-Law  Learning Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+A">Atith Gandhi</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R+S">Raj Sanjay Shah</a>, 
<a href="/search/cs?searchtype=author&query=Marupudi%2C+V">Vijay Marupudi</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+S">Sashank Varma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural networks often suffer from catastrophic interference (CI): performance
on previously learned tasks drops off significantly when learning a new task.
This contrasts strongly with humans, who can sequentially learn new tasks
without appreciably forgetting previous tasks. Prior work has explored various
techniques for mitigating CI such as regularization, rehearsal, generative
replay, and distillation methods. The current work takes a different approach,
one guided by cognitive science research showing that in naturalistic
environments, the probability of encountering a task decreases as a power-law
of the time since it was last performed. We argue that a realistic evaluation
of techniques for the mitigation of CI should be performed in simulated
naturalistic learning environments. Thus, we evaluate the extent of mitigation
of CI when training simple rehearsal-based methods in power-law environments
similar to the ones humans face. Our work explores this novel rehearsal-based
approach for a domain-incremental task: learning permutations in the MNIST
task. We compare our rehearsal environment with other baselines to show its
efficacy in promoting continual learning. Additionally, we investigate whether
this environment shows forward facilitation, i.e., faster learning of later
tasks. Next, we explore the robustness of our learning environment to the
number of tasks, model size, and amount of data rehearsed after each task.
Notably, our results show that the performance is comparable or superior to
that of models trained using popular regularization methods and also to
rehearsals in non-power-law environments. The benefits of this training
paradigm include simplicity and the lack of a need for extra neural circuitry.
In addition, because our method is orthogonal to other methods, future research
can combine training in power-law environments with other continual learning
mechanisms.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10394" title="Abstract">arXiv:2401.10394</a> [<a href="/pdf/2401.10394" title="Download PDF">pdf</a>, <a href="/format/2401.10394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution Consistency based Self-Training for Graph Neural Networks  with Sparse Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fali Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Suhang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Few-shot node classification poses a significant challenge for Graph Neural
Networks (GNNs) due to insufficient supervision and potential distribution
shifts between labeled and unlabeled nodes. Self-training has emerged as a
widely popular framework to leverage the abundance of unlabeled data, which
expands the training set by assigning pseudo-labels to selected unlabeled
nodes. Efforts have been made to develop various selection strategies based on
confidence, information gain, etc. However, none of these methods takes into
account the distribution shift between the training and testing node sets. The
pseudo-labeling step may amplify this shift and even introduce new ones,
hindering the effectiveness of self-training. Therefore, in this work, we
explore the potential of explicitly bridging the distribution shift between the
expanded training set and test set during self-training. To this end, we
propose a novel Distribution-Consistent Graph Self-Training (DC-GST) framework
to identify pseudo-labeled nodes that are both informative and capable of
redeeming the distribution discrepancy and formulate it as a differentiable
optimization task. A distribution-shift-aware edge predictor is further adopted
to augment the graph and increase the model's generalizability in assigning
pseudo labels. We evaluate our proposed method on four publicly available
benchmark datasets and extensive experiments demonstrate that our framework
consistently outperforms state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10397" title="Abstract">arXiv:2401.10397</a> [<a href="/pdf/2401.10397" title="Download PDF">pdf</a>, <a href="/format/2401.10397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing and Mitigating Bias for Vulnerable Classes: Towards Balanced  Representation in Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katare%2C+D">Dewant Katare</a>, 
<a href="/search/cs?searchtype=author&query=Noguero%2C+D+S">David Solans Noguero</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Souneil Park</a>, 
<a href="/search/cs?searchtype=author&query=Kourtellis%2C+N">Nicolas Kourtellis</a>, 
<a href="/search/cs?searchtype=author&query=Janssen%2C+M">Marijn Janssen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+A+Y">Aaron Yi Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The accuracy and fairness of perception systems in autonomous driving are
crucial, particularly for vulnerable road users. Mainstream research has looked
into improving the performance metrics for classification accuracy. However,
the hidden traits of bias inheritance in the AI models, class imbalances and
disparities in the datasets are often overlooked. In this context, our study
examines the class imbalances for vulnerable road users by focusing on class
distribution analysis, performance evaluation, and bias impact assessment. We
identify the concern of imbalances in class representation, leading to
potential biases in detection accuracy. Utilizing popular CNN models and Vision
Transformers (ViTs) with the nuScenes dataset, our performance evaluation
reveals detection disparities for underrepresented classes. We propose a
methodology for model optimization and bias mitigation, which includes data
augmentation, resampling, and metric-specific learning. Using the proposed
mitigation approaches, we see improvement in IoU(%) and NDS(%) metrics from
71.3 to 75.6 and 80.6 to 83.7 respectively, for the CNN model. Similarly, for
ViT, we observe improvement in IoU and NDS metrics from 74.9 to 79.2 and 83.8
to 87.1 respectively. This research contributes to developing more reliable
models and datasets, enhancing inclusiveness for minority classes.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10402" title="Abstract">arXiv:2401.10402</a> [<a href="/pdf/2401.10402" title="Download PDF">pdf</a>, <a href="/format/2401.10402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing the Invisible: Video Frame Restoration through Siamese  Masked Conditional Variational Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yongchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Richard Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the domain of computer vision, the restoration of missing information in
video frames is a critical challenge, particularly in applications such as
autonomous driving and surveillance systems. This paper introduces the Siamese
Masked Conditional Variational Autoencoder (SiamMCVAE), leveraging a siamese
architecture with twin encoders based on vision transformers. This innovative
design enhances the model's ability to comprehend lost content by capturing
intrinsic similarities between paired frames. SiamMCVAE proficiently
reconstructs missing elements in masked frames, effectively addressing issues
arising from camera malfunctions through variational inferences. Experimental
results robustly demonstrate the model's effectiveness in restoring missing
information, thus enhancing the resilience of computer vision systems. The
incorporation of Siamese Vision Transformer (SiamViT) encoders in SiamMCVAE
exemplifies promising potential for addressing real-world challenges in
computer vision, reinforcing the adaptability of autonomous systems in dynamic
environments.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10404" title="Abstract">arXiv:2401.10404</a> [<a href="/pdf/2401.10404" title="Download PDF">pdf</a>, <a href="/format/2401.10404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inflation with Diffusion: Efficient Temporal Adaptation for  Text-to-Video Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+J">Jinoo Baek</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Keyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tov%2C+O">Omer Tov</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hongliang Fei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV'24 workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose an efficient diffusion-based text-to-video super-resolution (SR)
tuning approach that leverages the readily learned capacity of pixel level
image diffusion model to capture spatial information for video generation. To
accomplish this goal, we design an efficient architecture by inflating the
weightings of the text-to-image SR model into our video generation framework.
Additionally, we incorporate a temporal adapter to ensure temporal coherence
across video frames. We investigate different tuning approaches based on our
inflated architecture and report trade-offs between computational costs and
super-resolution quality. Empirical evaluation, both quantitative and
qualitative, on the Shutterstock video dataset, demonstrates that our approach
is able to perform text-to-video SR generation with good visual quality and
temporal consistency. To evaluate temporal coherence, we also present
visualizations in video format in
https://drive.google.com/drive/folders/1YVc-KMSJqOrEUdQWVaI-Yfu8Vsfu_1aO?usp=sharing .
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10405" title="Abstract">arXiv:2401.10405</a> [<a href="/pdf/2401.10405" title="Download PDF">pdf</a>, <a href="/format/2401.10405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private and Adversarially Robust Machine Learning: An  Empirical Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakkar%2C+J">Janvi Thakkar</a>, 
<a href="/search/cs?searchtype=author&query=Zizzo%2C+G">Giulio Zizzo</a>, 
<a href="/search/cs?searchtype=author&query=Maffeis%2C+S">Sergio Maffeis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at PPAI-24: The 5th AAAI Workshop on Privacy-Preserving Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Malicious adversaries can attack machine learning models to infer sensitive
information or damage the system by launching a series of evasion attacks.
Although various work addresses privacy and security concerns, they focus on
individual defenses, but in practice, models may undergo simultaneous attacks.
This study explores the combination of adversarial training and differentially
private training to defend against simultaneous attacks. While
differentially-private adversarial training, as presented in DP-Adv,
outperforms the other state-of-the-art methods in performance, it lacks formal
privacy guarantees and empirical validation. Thus, in this work, we benchmark
the performance of this technique using a membership inference attack and
empirically show that the resulting approach is as private as non-robust
private models. This work also highlights the need to explore privacy
guarantees in dynamic training paradigms.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10407" title="Abstract">arXiv:2401.10407</a> [<a href="/pdf/2401.10407" title="Download PDF">pdf</a>, <a href="/format/2401.10407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning High-Quality and General-Purpose Phrase Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lihu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Varoquaux%2C+G">Ga&#xeb;l Varoquaux</a>, 
<a href="/search/cs?searchtype=author&query=Suchanek%2C+F+M">Fabian M. Suchanek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Phrase representations play an important role in data science and natural
language processing, benefiting various tasks like Entity Alignment, Record
Linkage, Fuzzy Joins, and Paraphrase Classification. The current
state-of-the-art method involves fine-tuning pre-trained language models for
phrasal embeddings using contrastive learning. However, we have identified
areas for improvement. First, these pre-trained models tend to be unnecessarily
complex and require to be pre-trained on a corpus with context sentences.
Second, leveraging the phrase type and morphology gives phrase representations
that are both more precise and more flexible. We propose an improved framework
to learn phrase representations in a context-free fashion. The framework
employs phrase type classification as an auxiliary task and incorporates
character-level information more effectively into the phrase representation.
Furthermore, we design three granularities of data augmentation to increase the
diversity of training samples. Our experiments across a wide range of tasks
show that our approach generates superior phrase embeddings compared to
previous methods while requiring a smaller model size. The code is available at
\faGithub~ \url{https://github.com/tigerchen52/PEARL} \end{abstract}
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10409" title="Abstract">arXiv:2401.10409</a> [<a href="/pdf/2401.10409" title="Download PDF">pdf</a>, <a href="/ps/2401.10409" title="Download PostScript">ps</a>, <a href="/format/2401.10409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Session Abstract Machine (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caires%2C+L">Lu&#xed;s Caires</a>, 
<a href="/search/cs?searchtype=author&query=Toninho%2C+B">Bernardo Toninho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Version of ESOP paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">We build on a fine-grained analysis of session-based interaction as provided
by the linear logic typing disciplines to introduce the SAM, an abstract
machine for mechanically executing session-typed processes. A remarkable
feature of the SAM's design is its ability to naturally segregate and
coordinate sequential with concurrent session behaviours. In particular,
implicitly sequential parts of session programs may be efficiently executed by
deterministic sequential application of SAM transitions, amenable to
compilation, and without concurrent synchronisation mechanisms. We provide an
intuitive discussion of the SAM structure and its underlying design, and state
and prove its correctness for executing programs in a session calculus
corresponding to full classical linear logic CLL. We also discuss extensions
and applications of the SAM to the execution of linear and session-based
programming languages.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10415" title="Abstract">arXiv:2401.10415</a> [<a href="/pdf/2401.10415" title="Download PDF">pdf</a>, <a href="/format/2401.10415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Model Summarizers Adapt to Diverse Scientific  Communication Goals?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+M">Marcio Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+S+B">Shay B. Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we investigate the controllability of large language models
(LLMs) on scientific summarization tasks. We identify key stylistic and content
coverage factors that characterize different types of summaries such as paper
reviews, abstracts, and lay summaries. By controlling stylistic features, we
find that non-fine-tuned LLMs outperform humans in the MuP review generation
task, both in terms of similarity to reference summaries and human preferences.
Also, we show that we can improve the controllability of LLMs with
keyword-based classifier-free guidance (CFG) while achieving lexical overlap
comparable to strong fine-tuned baselines on arXiv and PubMed. However, our
results also indicate that LLMs cannot consistently generate long summaries
with more than 8 sentences. Furthermore, these models exhibit limited capacity
to produce highly abstractive lay summaries. Although LLMs demonstrate strong
generic summarization competency, sophisticated content control without costly
fine-tuning remains an open problem for domain-specific applications.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10416" title="Abstract">arXiv:2401.10416</a> [<a href="/pdf/2401.10416" title="Download PDF">pdf</a>, <a href="/format/2401.10416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DataViz3D: An Novel Method Leveraging Online Holographic Modeling for  Extensive Dataset Preprocessing and Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jinli Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">DataViz3D is an innovative online software that transforms complex datasets
into interactive 3D spatial models using holographic technology. This tool
enables users to generate scatter plot within a 3D space, accurately mapped to
the XYZ coordinates of the dataset, providing a vivid and intuitive
understanding of the spatial relationships inherent in the data. DataViz3D's
user friendly interface makes advanced 3D modeling and holographic
visualization accessible to a wide range of users, fostering new opportunities
for collaborative research and education across various disciplines.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10417" title="Abstract">arXiv:2401.10417</a> [<a href="/pdf/2401.10417" title="Download PDF">pdf</a>, <a href="/format/2401.10417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSR: Spatial Sequential Hybrid Architecture for Latency Throughput  Tradeoff in Transformer Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Jinming Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoping Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shixin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+A+K">Alex K. Jones</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jingtong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peipei Zhou</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2024 ACM/SIGDA International Symposium on Field Programmable Gate
  Arrays (FPGA '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">With the increase in the computation intensity of the chip, the mismatch
between computation layer shapes and the available computation resource
significantly limits the utilization of the chip. Driven by this observation,
prior works discuss spatial accelerators or dataflow architecture to maximize
the throughput. However, using spatial accelerators could potentially increase
the execution latency. In this work, we first systematically investigate two
execution models: (1) sequentially (temporally) launch one monolithic
accelerator, and (2) spatially launch multiple accelerators. From the
observations, we find that there is a latency throughput tradeoff between these
two execution models, and combining these two strategies together can give us a
more efficient latency throughput Pareto front. To achieve this, we propose
spatial sequential architecture (SSR) and SSR design automation framework to
explore both strategies together when deploying deep learning inference. We use
the 7nm AMD Versal ACAP VCK190 board to implement SSR accelerators for four
end-to-end transformer-based deep learning models. SSR achieves average
throughput gains of 2.53x, 35.71x, and 14.20x under different batch sizes
compared to the 8nm Nvidia GPU A10G, 16nm AMD FPGAs ZCU102, and U250. The
average energy efficiency gains are 8.51x, 6.75x, and 21.22x, respectively.
Compared with the sequential-only solution and spatial-only solution on VCK190,
our spatial-sequential-hybrid solutions achieve higher throughput under the
same latency requirement and lower latency under the same throughput
requirement. We also use SSR analytical models to demonstrate how to use SSR to
optimize solutions on other computing platforms, e.g., 14nm Intel Stratix 10
NX.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10418" title="Abstract">arXiv:2401.10418</a> [<a href="/pdf/2401.10418" title="Download PDF">pdf</a>, <a href="/format/2401.10418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hazard resistance-based spatiotemporal risk analysis for distribution  network outages during hurricanes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+L">Luo Xu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+N">Ning Lin</a>, 
<a href="/search/eess?searchtype=author&query=Xi%2C+D">Dazhi Xi</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+K">Kairui Feng</a>, 
<a href="/search/eess?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Blackouts in recent decades show an increasing prevalence of power outages
due to extreme weather events such as hurricanes. Precisely assessing the
spatiotemporal outages in distribution networks, the most vulnerable part of
power systems, is critical to enhance power system resilience. The Sequential
Monte Carlo (SMC) simulation method is widely used for spatiotemporal risk
analysis of power systems during extreme weather hazards. However, it is found
here that the SMC method can lead to large errors by directly applying the
fragility function or failure probability of system components in
time-sequential analysis, particularly overestimating damages under evolving
hazards with high-frequency sampling. To address this issue, a novel hazard
resistance-based spatiotemporal risk analysis (HRSRA) method is proposed. This
method converts the time-varying failure probability of a component into a
hazard resistance as a time-invariant value during the simulation of evolving
hazards. The proposed HRSRA provides an adaptive framework for incorporating
high-spatiotemporal-resolution meteorology models into power outage
simulations. By leveraging the geographic information system data of the power
system and a physics-based hurricane wind field model, the superiority of the
proposed method is validated using real-world time-series power outage data
from Puerto Rico during Hurricane Fiona 2022.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10420" title="Abstract">arXiv:2401.10420</a> [<a href="/pdf/2401.10420" title="Download PDF">pdf</a>, <a href="/format/2401.10420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Nested Rollout Policy Adaptation with Limited Repetitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cazenave%2C+T">Tristan Cazenave</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Generalized Nested Rollout Policy Adaptation (GNRPA) is a Monte Carlo search
algorithm for optimizing a sequence of choices. We propose to improve on GNRPA
by avoiding too deterministic policies that find again and again the same
sequence of choices. We do so by limiting the number of repetitions of the best
sequence found at a given level. Experiments show that it improves the
algorithm for three different combinatorial problems: Inverse RNA Folding, the
Traveling Salesman Problem with Time Windows and the Weak Schur problem.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10422" title="Abstract">arXiv:2401.10422</a> [<a href="/pdf/2401.10422" title="Download PDF">pdf</a>, <a href="/format/2401.10422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Analysis of Macro Usage for Portability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pappas%2C+B">Brent Pappas</a>, 
<a href="/search/cs?searchtype=author&query=Gazzillo%2C+P">Paul Gazzillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages. 4 figures. 2 tables. To appear in the 2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE '24), April 14-20, 2024, Lisbon, Portugal. See <a href="https://zenodo.org/doi/10.5281/zenodo.7783131">this https URL</a> for the latest version of the artifact associated with this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">C is an unsafe language. Researchers have been developing tools to port C to
safer languages such as Rust, Checked C, or Go. Existing tools, however, resort
to preprocessing the source file first, then porting the resulting code,
leaving barely recognizable code that loses macro abstractions. To preserve
macro usage, porting tools need analyses that understand macro behavior to port
to equivalent constructs. But macro semantics differ from typical functions,
precluding simple syntactic transformations to port them. We introduce the
first comprehensive framework for analyzing the portability of macro usage. We
decompose macro behavior into 26 fine-grained properties and implement a
program analysis tool, called Maki, that identifies them in real-world code
with 94% accuracy. We apply Maki to 21 programs containing a total of 86,199
macro definitions. We found that real-world macros are much more portable than
previously known. More than a third (37%) are easy-to-port, and Maki provides
hints for porting more complicated macros. We find, on average, 2x more
easy-to-port macros and up to 7x more in the best case compared to prior work.
Guided by Maki's output, we found and hand-ported macros in four real-world
programs. We submitted patches to Linux maintainers that transform eleven
macros, nine of which have been accepted.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10423" title="Abstract">arXiv:2401.10423</a> [<a href="/pdf/2401.10423" title="Download PDF">pdf</a>, <a href="/format/2401.10423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verification under TSO with an infinite Data Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdulla%2C+P+A">Parosh Aziz Abdulla</a>, 
<a href="/search/cs?searchtype=author&query=Atig%2C+M+F">Mohamed Faouzi Atig</a>, 
<a href="/search/cs?searchtype=author&query=Furbach%2C+F">Florian Furbach</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Shashwat Garg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">We examine verification of concurrent programs under the total store ordering
(TSO) semantics used by the x86 architecture. In our model, threads manipulate
variables over infinite domains and they can check whether variables are
related for a range of relations. We show that, in general, the control state
reachability problem is undecidable. This result is derived through a reduction
from the state reachability problem of lossy channel systems with data (which
is known to be undecidable). In the light of this undecidability, we turn our
attention to a more tractable variant of the reachability problem.
Specifically, we study context bounded runs, which provide an
under-approximation of the program behavior by limiting the possible
interactions between processes. A run consists of a number of contexts, with
each context representing a sequence of steps where a only single designated
thread is active. We prove that the control state reachability problem under
bounded context switching is PSPACE complete.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10428" title="Abstract">arXiv:2401.10428</a> [<a href="/pdf/2401.10428" title="Download PDF">pdf</a>, <a href="/ps/2401.10428" title="Download PostScript">ps</a>, <a href="/format/2401.10428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Learning through the Lens of Dynamical Invariants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ushveridze%2C+A">Alex Ushveridze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This paper proposes a novel perspective on learning, positing it as the
pursuit of dynamical invariants -- data combinations that remain constant or
exhibit minimal change over time as a system evolves. This concept is
underpinned by both informational and physical principles, rooted in the
inherent properties of these invariants. Firstly, their stability makes them
ideal for memorization and integration into associative networks, forming the
basis of our knowledge structures. Secondly, the predictability of these stable
invariants makes them valuable sources of usable energy, quantifiable as kTln2
per bit of accurately predicted information. This energy can be harnessed to
explore new transformations, rendering learning systems energetically
autonomous and increasingly effective. Such systems are driven to continuously
seek new data invariants as energy sources. The paper further explores several
meta-architectures of autonomous, self-propelled learning agents that utilize
predictable information patterns as a source of usable energy.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10431" title="Abstract">arXiv:2401.10431</a> [<a href="/pdf/2401.10431" title="Download PDF">pdf</a>, <a href="/format/2401.10431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Prior for Monte Carlo Search by Replaying Solutions to  Combinatorial Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cazenave%2C+T">Tristan Cazenave</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Monte Carlo Search gives excellent results in multiple difficult
combinatorial problems. Using a prior to perform non uniform playouts during
the search improves a lot the results compared to uniform playouts. Handmade
heuristics tailored to the combinatorial problem are often used as priors. We
propose a method to automatically compute a prior. It uses statistics on solved
problems. It is a simple and general method that incurs no computational cost
at playout time and that brings large performance gains. The method is applied
to three difficult combinatorial problems: Latin Square Completion, Kakuro, and
Inverse RNA Folding.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10432" title="Abstract">arXiv:2401.10432</a> [<a href="/pdf/2401.10432" title="Download PDF">pdf</a>, <a href="/format/2401.10432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A2Q+: Improving Accumulator-Aware Weight Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colbert%2C+I">Ian Colbert</a>, 
<a href="/search/cs?searchtype=author&query=Pappalardo%2C+A">Alessandro Pappalardo</a>, 
<a href="/search/cs?searchtype=author&query=Petri-Koenig%2C+J">Jakoba Petri-Koenig</a>, 
<a href="/search/cs?searchtype=author&query=Umuroglu%2C+Y">Yaman Umuroglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Performance (cs.PF)

</div>
<p class="mathjax">Quantization techniques commonly reduce the inference costs of neural
networks by restricting the precision of weights and activations. Recent
studies show that also reducing the precision of the accumulator can further
improve hardware efficiency at the risk of numerical overflow, which introduces
arithmetic errors that can degrade model accuracy. To avoid numerical overflow
while maintaining accuracy, recent work proposed accumulator-aware quantization
(A2Q), a quantization-aware training method that constrains model weights
during training to safely use a target accumulator bit width during inference.
Although this shows promise, we demonstrate that A2Q relies on an overly
restrictive constraint and a sub-optimal weight initialization strategy that
each introduce superfluous quantization error. To address these shortcomings,
we introduce: (1) an improved bound that alleviates accumulator constraints
without compromising overflow avoidance; and (2) a new strategy for
initializing quantized weights from pre-trained floating-point checkpoints. We
combine these contributions with weight normalization to introduce A2Q+. We
support our analysis with experiments that show A2Q+ significantly improves the
trade-off between accumulator bit width and model accuracy and characterize new
trade-offs that arise as a consequence of accumulator constraints.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10440" title="Abstract">arXiv:2401.10440</a> [<a href="/pdf/2401.10440" title="Download PDF">pdf</a>, <a href="/format/2401.10440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking the Curse of Multilinguality with Cross-lingual Expert Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blevins%2C+T">Terra Blevins</a>, 
<a href="/search/cs?searchtype=author&query=Limisiewicz%2C+T">Tomasz Limisiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Gururangan%2C+S">Suchin Gururangan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Margaret Li</a>, 
<a href="/search/cs?searchtype=author&query=Gonen%2C+H">Hila Gonen</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite their popularity in non-English NLP, multilingual language models
often underperform monolingual ones due to inter-language competition for model
parameters. We propose Cross-lingual Expert Language Models (X-ELM), which
mitigate this competition by independently training language models on subsets
of the multilingual corpus. This process specializes X-ELMs to different
languages while remaining effective as a multilingual ensemble. Our experiments
show that when given the same compute budget, X-ELM outperforms jointly trained
multilingual models across all considered languages and that these gains
transfer to downstream tasks. X-ELM provides additional benefits over
performance improvements: new experts can be iteratively added, adapting X-ELM
to new languages without catastrophic forgetting. Furthermore, training is
asynchronous, reducing the hardware requirements for multilingual training and
democratizing multilingual modeling.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10442" title="Abstract">arXiv:2401.10442</a> [<a href="/pdf/2401.10442" title="Download PDF">pdf</a>, <a href="/format/2401.10442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path Choice Matters for Clear Attribution in Path Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Borui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenzhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Rigorousness and clarity are both essential for interpretations of DNNs to
engender human trust. Path methods are commonly employed to generate rigorous
attributions that satisfy three axioms. However, the meaning of attributions
remains ambiguous due to distinct path choices. To address the ambiguity, we
introduce \textbf{Concentration Principle}, which centrally allocates high
attributions to indispensable features, thereby endowing aesthetic and
sparsity. We then present \textbf{SAMP}, a model-agnostic interpreter, which
efficiently searches the near-optimal path from a pre-defined set of
manipulation paths. Moreover, we propose the infinitesimal constraint (IC) and
momentum strategy (MS) to improve the rigorousness and optimality.
Visualizations show that SAMP can precisely reveal DNNs by pinpointing salient
image pixels. We also perform quantitative experiments and observe that our
method significantly outperforms the counterparts. Code:
https://github.com/zbr17/SAMP.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10443" title="Abstract">arXiv:2401.10443</a> [<a href="/pdf/2401.10443" title="Download PDF">pdf</a>, <a href="/format/2401.10443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automated Driving Violation Cause Analysis in Scenario-Based  Testing for Autonomous Driving Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Ziwen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huai%2C+Y">Yuqi Huai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntianyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+J">Joshua Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q+A">Qi Alfred Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The rapid advancement of Autonomous Vehicles (AVs), exemplified by companies
like Waymo and Cruise offering 24/7 paid taxi services, highlights the
paramount importance of ensuring AVs' compliance with various policies, such as
safety regulations, traffic rules, and mission directives. Despite significant
progress in the development of Autonomous Driving System (ADS) testing tools,
there has been a notable absence of research on attributing the causes of
driving violations. Counterfactual causality analysis has emerged as a
promising approach for identifying the root cause of program failures. While it
has demonstrated effectiveness in pinpointing error-inducing inputs, its direct
application to the AV context to determine which computation result, generated
by which component, serves as the root cause poses a considerable challenge. A
key obstacle lies in our inability to straightforwardly eliminate the influence
of a specific internal message to establish the causal relationship between the
output of each component and a system-level driving violation.
<br />In this work, we propose a novel driving violation cause analysis (DVCA)
tool. We design idealized component substitutes to enable counterfactual
analysis of ADS components by leveraging the unique opportunity provided by the
simulation. We evaluate our tool on a benchmark with real bugs and injected
faults. The results show that our tool can achieve perfect component-level
attribution accuracy (100%) and almost (&gt;98%) perfect message-level accuracy.
Our tool can reduce the debugging scope from hundreds of complicated
interdependent messages to one single computation result generated by one
component.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10444" title="Abstract">arXiv:2401.10444</a> [<a href="/pdf/2401.10444" title="Download PDF">pdf</a>, <a href="/ps/2401.10444" title="Download PostScript">ps</a>, <a href="/format/2401.10444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can A Cognitive Architecture Fundamentally Enhance LLMs? Or Vice Versa?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ron Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The paper discusses what is needed to address the limitations of current
LLM-centered AI systems. The paper argues that incorporating insights from
human cognition and psychology, as embodied by a computational cognitive
architecture, can help develop systems that are more capable, more reliable,
and more human-like. It emphasizes the importance of the dual-process
architecture and the hybrid neuro-symbolic approach in addressing the
limitations of current LLMs. In the opposite direction, the paper also
highlights the need for an overhaul of computational cognitive architectures to
better reflect advances in AI and computing technology. Overall, the paper
advocates for a multidisciplinary, mutually beneficial approach towards
developing better models both for AI and for understanding the human mind.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10446" title="Abstract">arXiv:2401.10446</a> [<a href="/pdf/2401.10446" title="Download PDF">pdf</a>, <a href="/format/2401.10446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Efficient Learners of Noise-Robust Speech  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuchen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C+H">Chao-Han Huck Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chng%2C+E">EnSiong Chng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024, Spotlight top 5%, 24 pages. This work will be open sourced at: <a href="https://github.com/YUCHEN005/RobustGER">this https URL</a> under MIT license
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent advances in large language models (LLMs) have promoted generative
error correction (GER) for automatic speech recognition (ASR), which leverages
the rich linguistic knowledge and powerful reasoning ability of LLMs to improve
recognition results. The latest work proposes a GER benchmark with HyPoradise
dataset to learn the mapping from ASR N-best hypotheses to ground-truth
transcription by efficient LLM finetuning, which shows great effectiveness but
lacks specificity on noise-robust ASR. In this work, we extend the benchmark to
noisy conditions and investigate if we can teach LLMs to perform denoising for
GER just like what robust ASR do}, where one solution is introducing noise
information as a conditioner into LLM. However, directly incorporating noise
embeddings from audio encoder could harm the LLM tuning due to cross-modality
gap. To this end, we propose to extract a language-space noise embedding from
the N-best list to represent the noise conditions of source speech, which can
promote the denoising process in GER. Furthermore, in order to enhance its
representation ability of audio noise, we design a knowledge distillation (KD)
approach via mutual information estimation to distill the real noise
information in audio embeddings to our language embedding. Experiments on
various latest LLMs demonstrate our approach achieves a new breakthrough with
up to 53.9% correction improvement in terms of word error rate while with
limited training data. Analysis shows that our language-space noise embedding
can well represent the noise conditions of source speech, under which
off-the-shelf LLMs show strong ability of language-space denoising.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10447" title="Abstract">arXiv:2401.10447</a> [<a href="/pdf/2401.10447" title="Download PDF">pdf</a>, <a href="/format/2401.10447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Training Strategies and Model Robustness of Low-Rank  Adaptation for Language Modeling in Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C+H">Chao-Han Huck Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+T">Tuan Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+S">Sungho Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Kolehmainen%2C+J">Jari Kolehmainen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+R">Roger Ren</a>, 
<a href="/search/cs?searchtype=author&query=Filimonov%2C+D">Denis Filimonov</a>, 
<a href="/search/cs?searchtype=author&query=Shivakumar%2C+P+G">Prashanth G. Shivakumar</a>, 
<a href="/search/cs?searchtype=author&query=Gandhe%2C+A">Ankur Gandhe</a>, 
<a href="/search/cs?searchtype=author&query=Rastow%2C+A">Ariya Rastow</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bulyko%2C+I">Ivan Bulyko</a>, 
<a href="/search/cs?searchtype=author&query=Stolcke%2C+A">Andreas Stolcke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The use of low-rank adaptation (LoRA) with frozen pretrained language models
(PLMs) has become increasing popular as a mainstream, resource-efficient
modeling approach for memory-constrained hardware. In this study, we first
explore how to enhance model performance by introducing various LoRA training
strategies, achieving relative word error rate reductions of 3.50\% on the
public Librispeech dataset and of 3.67\% on an internal dataset in the
messaging domain. To further characterize the stability of LoRA-based
second-pass speech recognition models, we examine robustness against input
perturbations. These perturbations are rooted in homophone replacements and a
novel metric called N-best Perturbation-based Rescoring Robustness (NPRR), both
designed to measure the relative degradation in the performance of rescoring
models. Our experimental results indicate that while advanced variants of LoRA,
such as dynamic rank-allocated LoRA, lead to performance degradation in
$1$-best perturbation, they alleviate the degradation in $N$-best perturbation.
This finding is in comparison to fully-tuned models and vanilla LoRA tuning
baselines, suggesting that a comprehensive selection is needed when using
LoRA-based adaptation for compute-cost savings and robust language modeling.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10451" title="Abstract">arXiv:2401.10451</a> [<a href="/pdf/2401.10451" title="Download PDF">pdf</a>, <a href="/format/2401.10451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-assisted Stochastic Capacity Expansion Planning: A Bayesian  Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Brenner%2C+A">Aron Brenner</a>, 
<a href="/search/eess?searchtype=author&query=Khorramfar%2C+R">Rahman Khorramfar</a>, 
<a href="/search/eess?searchtype=author&query=Mallapragada%2C+D">Dharik Mallapragada</a>, 
<a href="/search/eess?searchtype=author&query=Amin%2C+S">Saurabh Amin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Solving large-scale capacity expansion problems (CEPs) is central to
cost-effective decarbonization of regional-scale energy systems. To ensure the
intended outcomes of CEPs, modeling uncertainty due to weather-dependent
variable renewable energy (VRE) supply and energy demand becomes crucially
important. However, the resulting stochastic optimization models are often less
computationally tractable than their deterministic counterparts. Here, we
propose a learning-assisted approximate solution method to tractably solve
two-stage stochastic CEPs. Our method identifies low-cost planning decisions by
constructing and solving a sequence of tractable temporally aggregated
surrogate problems. We adopt a Bayesian optimization approach to searching the
space of time series aggregation hyperparameters and compute approximate
solutions that minimize costs on a validation set of supply-demand projections.
Importantly, we evaluate solved planning outcomes on a held-out set of test
projections. We apply our approach to generation and transmission expansion
planning for a joint power-gas system spanning New England. We show that our
approach yields an estimated cost savings of up to 3.8% in comparison to
benchmark time series aggregation approaches.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10458" title="Abstract">arXiv:2401.10458</a> [<a href="/pdf/2401.10458" title="Download PDF">pdf</a>, <a href="/format/2401.10458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Unlearning: A Contrastive Approach to Machine Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H+k">Hong kyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiuchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Li Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Machine unlearning aims to eliminate the influence of a subset of training
samples (i.e., unlearning samples) from a trained model. Effectively and
efficiently removing the unlearning samples without negatively impacting the
overall model performance is still challenging. In this paper, we propose a
contrastive unlearning framework, leveraging the concept of representation
learning for more effective unlearning. It removes the influence of unlearning
samples by contrasting their embeddings against the remaining samples so that
they are pushed away from their original classes and pulled toward other
classes. By directly optimizing the representation space, it effectively
removes the influence of unlearning samples while maintaining the
representations learned from the remaining samples. Experiments on a variety of
datasets and models on both class unlearning and sample unlearning showed that
contrastive unlearning achieves the best unlearning effects and efficiency with
the lowest performance loss compared with the state-of-the-art algorithms.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10460" title="Abstract">arXiv:2401.10460</a> [<a href="/pdf/2401.10460" title="Download PDF">pdf</a>, <a href="/format/2401.10460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra-lightweight Neural Differential DSP Vocoder For High Quality  Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Prabhav Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Koehler%2C+T">Thilo Koehler</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Z">Zhiping Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Serai%2C+P">Prashant Serai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qing He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Neural vocoders model the raw audio waveform and synthesize high-quality
audio, but even the highly efficient ones, like MB-MelGAN and LPCNet, fail to
run real-time on a low-end device like a smartglass. A pure digital signal
processing (DSP) based vocoder can be implemented via lightweight fast Fourier
transforms (FFT), and therefore, is a magnitude faster than any neural vocoder.
A DSP vocoder often gets a lower audio quality due to consuming over-smoothed
acoustic model predictions of approximate representations for the vocal tract.
In this paper, we propose an ultra-lightweight differential DSP (DDSP) vocoder
that uses a jointly optimized acoustic model with a DSP vocoder, and learns
without an extracted spectral feature for the vocal tract. The model achieves
audio quality comparable to neural vocoders with a high average MOS of 4.36
while being efficient as a DSP vocoder. Our C++ implementation, without any
hardware-specific optimization, is at 15 MFLOPS, surpasses MB-MelGAN by 340
times in terms of FLOPS, and achieves a vocoder-only RTF of 0.003 and overall
RTF of 0.044 while running single-threaded on a 2GHz Intel Xeon CPU.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10461" title="Abstract">arXiv:2401.10461</a> [<a href="/pdf/2401.10461" title="Download PDF">pdf</a>, <a href="/format/2401.10461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Robustly Reconstruct Low-light Dynamic Scenes from Spike  Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liwen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Ziluo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mianzhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As a neuromorphic sensor with high temporal resolution, spike camera can
generate continuous binary spike streams to capture per-pixel light intensity.
We can use reconstruction methods to restore scene details in high-speed
scenarios. However, due to limited information in spike streams, low-light
scenes are difficult to effectively reconstruct. In this paper, we propose a
bidirectional recurrent-based reconstruction framework, including a
Light-Robust Representation (LR-Rep) and a fusion module, to better handle such
extreme conditions. LR-Rep is designed to aggregate temporal information in
spike streams, and a fusion module is utilized to extract temporal features.
Additionally, we have developed a reconstruction benchmark for high-speed
low-light scenes. Light sources in the scenes are carefully aligned to
real-world conditions. Experimental results demonstrate the superiority of our
method, which also generalizes well to real spike streams. Related codes and
proposed datasets will be released after publication.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10463" title="Abstract">arXiv:2401.10463</a> [<a href="/pdf/2401.10463" title="Download PDF">pdf</a>, <a href="/format/2401.10463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical Data Size of Language Models from a Grokking Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xuekai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouhan Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We explore the critical data size in language models, a threshold that marks
a fundamental shift from quick memorization to slow generalization. We
formalize the phase transition under the grokking configuration into the Data
Efficiency Hypothesis and identify data insufficiency, sufficiency, and surplus
regimes in language models training dynamics. We develop a grokking
configuration to reproduce grokking on simplistic language models stably by
rescaling initialization and weight decay. We show that generalization occurs
only when language models reach a critical size. We analyze grokking across
sample-wise and model-wise, verifying the proposed data efficiency hypothesis.
Our experiments reveal smoother phase transitions occurring at the critical
dataset size for language datasets. As the model size increases, this critical
point also becomes larger, indicating that larger models require more data. Our
results deepen the understanding of language model training, offering a novel
perspective on the role of data in the learning mechanism of language models.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10464" title="Abstract">arXiv:2401.10464</a> [<a href="/pdf/2401.10464" title="Download PDF">pdf</a>, <a href="/format/2401.10464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhotoScout: Synthesis-Powered Multi-Modal Image Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barnaby%2C+C">Celeste Barnaby</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiaochu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dillig%2C+I">Isil Dillig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Due to the availability of increasingly large amounts of visual data, there
is a growing need for tools that can help users find relevant images. While
existing tools can perform image retrieval based on similarity or metadata,
they fall short in scenarios that necessitate semantic reasoning about the
content of the image. This paper explores a new multi-modal image search
approach that allows users to conveniently specify and perform semantic image
search tasks. With our tool, PhotoScout, the user interactively provides
natural language descriptions, positive and negative examples, and object tags
to specify their search tasks. Under the hood, PhotoScout is powered by a
program synthesis engine that generates visual queries in a domain-specific
language and executes the synthesized program to retrieve the desired images.
In a study with 25 participants, we observed that PhotoScout allows users to
perform image retrieval tasks more accurately and with less manual effort.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10465" title="Abstract">arXiv:2401.10465</a> [<a href="/pdf/2401.10465" title="Download PDF">pdf</a>, <a href="/format/2401.10465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven grapheme-to-phoneme representations for a lexicon-free  text-to-speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Abhinav Garg</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Khyalia%2C+S">Sushil Khyalia</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chanwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Gowda%2C+D">Dhananjaya Gowda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Grapheme-to-Phoneme (G2P) is an essential first step in any modern,
high-quality Text-to-Speech (TTS) system. Most of the current G2P systems rely
on carefully hand-crafted lexicons developed by experts. This poses a two-fold
problem. Firstly, the lexicons are generated using a fixed phoneme set,
usually, ARPABET or IPA, which might not be the most optimal way to represent
phonemes for all languages. Secondly, the man-hours required to produce such an
expert lexicon are very high. In this paper, we eliminate both of these issues
by using recent advances in self-supervised learning to obtain data-driven
phoneme representations instead of fixed representations. We compare our
lexicon-free approach against strong baselines that utilize a well-crafted
lexicon. Furthermore, we show that our data-driven lexicon-free method performs
as good or even marginally better than the conventional rule-based or
lexicon-based neural G2Ps in terms of Mean Opinion Score (MOS) while using no
prior language lexicon or phoneme set, i.e. no linguistic expertise.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10467" title="Abstract">arXiv:2401.10467</a> [<a href="/pdf/2401.10467" title="Download PDF">pdf</a>, <a href="/format/2401.10467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Backdoors for Mixed Integer Programs with Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Junyang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Taoan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dilkina%2C+B">Bistra Dilkina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Many real-world problems can be efficiently modeled as Mixed Integer Programs
(MIPs) and solved with the Branch-and-Bound method. Prior work has shown the
existence of MIP backdoors, small sets of variables such that prioritizing
branching on them when possible leads to faster running times. However, finding
high-quality backdoors that improve running times remains an open question.
Previous work learns to estimate the relative solver speed of randomly sampled
backdoors through ranking and then decide whether to use it. In this paper, we
utilize the Monte-Carlo tree search method to collect backdoors for training,
rather than relying on random sampling, and adapt a contrastive learning
framework to train a Graph Attention Network model to predict backdoors. Our
method, evaluated on four common MIP problem domains, demonstrates performance
improvements over both Gurobi and previous models.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10469" title="Abstract">arXiv:2401.10469</a> [<a href="/pdf/2401.10469" title="Download PDF">pdf</a>, <a href="/format/2401.10469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stable Matching Assignment for Cancer Treatment Centers using Survival  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seidi%2C+N">Navid Seidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The treatment of cancer is one of the most discussed issues in the realm of
contemporary public health research. One of the primary concerns of both the
general public and the government is the development of the most effective
cancer treatment at the most affordable price. This is due to the fact that the
number of persons diagnosed with cancer increases on an annual basis. Within
the scope of this project, we propose the development of a system for the
recommendation of treatment centers. This system would initially select
patients who posed a higher risk value, and then it would recommend the most
appropriate cancer treatment center for those patients based on their income
and the location where they lived using a stable matching algorithm.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10470" title="Abstract">arXiv:2401.10470</a> [<a href="/pdf/2401.10470" title="Download PDF">pdf</a>, <a href="/ps/2401.10470" title="Download PostScript">ps</a>, <a href="/format/2401.10470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape enumerators of self-dual NRT codes over finite fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Runxuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We use invariant theory of finite groups to study shape enumerators of
self-dual linear codes in a finite NRT metric space. We provide a new approach
that avoids applying Molien's formula to compute all possible shape
enumerators. Enhancing existing methods, we describe the shape enumerators of
all self-dual NRT codes over an arbitrary finite field.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10471" title="Abstract">arXiv:2401.10471</a> [<a href="/pdf/2401.10471" title="Download PDF">pdf</a>, <a href="/format/2401.10471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepEdit: Knowledge Editing as Decoding with Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We develop a new perspective of knowledge editing for large language models
(LLMs) as decoding with constraints. We propose DeepEdit (Depth-first Search
based Progressive Decoding for Knowledge Editing), a neuro-symbolic method that
improves knowledge editing with better coherence of reasoning, relevance to the
question, and awareness of updated knowledge. DeepEdit can be flexibly applied
to all black-box LLMs: it does not require any access to the model parameters,
representations, or output vocabulary distributions. DeepEdit progressively
produces the high-quality reasoning steps towards effective knowledge editing.
It utilizes a depth-first search to revise the LLMs' output, which improves the
output's informativeness to the input question and awareness of the updated
knowledge. Qualitatively, DeepEdit effectively controls LLMs to produce more
succinct reasoning in accord with knowledge editing. Quantitatively, DeepEdit
yields significant gains on MQuaKE, a challenging multi-hop question-answering
dataset with knowledge editing. We release the source code at
https://github.com/wangywUST/DeepEdit.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10472" title="Abstract">arXiv:2401.10472</a> [<a href="/pdf/2401.10472" title="Download PDF">pdf</a>, <a href="/format/2401.10472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Name Tagging Under Domain Shift via Metric Learning for Life Sciences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingyun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Karisani%2C+P">Payam Karisani</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Name tagging is a key component of Information Extraction (IE), particularly
in scientific domains such as biomedicine and chemistry, where large language
models (LLMs), e.g., ChatGPT, fall short. We investigate the applicability of
transfer learning for enhancing a name tagging model trained in the biomedical
domain (the source domain) to be used in the chemical domain (the target
domain). A common practice for training such a model in a few-shot learning
setting is to pretrain the model on the labeled source data, and then, to
finetune it on a hand-full of labeled target examples. In our experiments we
observed that such a model is prone to mis-labeling the source entities, which
can often appear in the text, as the target entities. To alleviate this
problem, we propose a model to transfer the knowledge from the source domain to
the target domain, however, at the same time, to project the source entities
and target entities into separate regions of the feature space. This diminishes
the risk of mis-labeling the source entities as the target entities. Our model
consists of two stages: 1) entity grouping in the source domain, which
incorporates knowledge from annotated events to establish relations between
entities, and 2) entity discrimination in the target domain, which relies on
pseudo labeling and contrastive learning to enhance discrimination between the
entities in the two domains. We carry out our extensive experiments across
three source and three target datasets, and demonstrate that our method
outperforms the baselines, in some scenarios by 5\% absolute value.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10474" title="Abstract">arXiv:2401.10474</a> [<a href="/pdf/2401.10474" title="Download PDF">pdf</a>, <a href="/format/2401.10474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LDReg: Local Dimensionality Regularized Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hanxun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Campello%2C+R+J+G+B">Ricardo J. G. B. Campello</a>, 
<a href="/search/cs?searchtype=author&query=Erfani%2C+S+M">Sarah Monazam Erfani</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xingjun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Houle%2C+M+E">Michael E. Houle</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+J">James Bailey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Representations learned via self-supervised learning (SSL) can be susceptible
to dimensional collapse, where the learned representation subspace is of
extremely low dimensionality and thus fails to represent the full data
distribution and modalities. Dimensional collapse also known as the
"underfilling" phenomenon is one of the major causes of degraded performance on
downstream tasks. Previous work has investigated the dimensional collapse
problem of SSL at a global level. In this paper, we demonstrate that
representations can span over high dimensional space globally, but collapse
locally. To address this, we propose a method called $\textit{local
dimensionality regularization (LDReg)}$. Our formulation is based on the
derivation of the Fisher-Rao metric to compare and optimize local distance
distributions at an asymptotically small radius for each data point. By
increasing the local intrinsic dimensionality, we demonstrate through a range
of experiments that LDReg improves the representation quality of SSL. The
results also show that LDReg can regularize dimensionality at both local and
global levels.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10475" title="Abstract">arXiv:2401.10475</a> [<a href="/pdf/2401.10475" title="Download PDF">pdf</a>, <a href="/format/2401.10475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CBVS: A Large-Scale Chinese Image-Text Benchmark for Real-World Short  Video Search Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+X">Xiangshuo Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaozhe Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cihang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Vision-Language Models pre-trained on large-scale image-text datasets have
shown superior performance in downstream tasks such as image retrieval. Most of
the images for pre-training are presented in the form of open domain
common-sense visual elements. Differently, video covers in short video search
scenarios are presented as user-originated contents that provide important
visual summaries of videos. In addition, a portion of the video covers come
with manually designed cover texts that provide semantic complements. In order
to fill in the gaps in short video cover data, we establish the first
large-scale cover-text benchmark for Chinese short video search scenarios.
Specifically, we release two large-scale datasets CBVS-5M/10M to provide short
video covers, and the manual fine-labeling dataset CBVS-20K to provide real
user queries, which serves as an image-text benchmark test in the Chinese short
video search field. To integrate the semantics of cover text in the case of
modality missing, we propose UniCLIP where cover texts play a guiding role
during training, however are not relied upon by inference. Extensive evaluation
on CBVS-20K demonstrates the excellent performance of our proposal. UniCLIP has
been deployed to Tencent's online video search systems with hundreds of
millions of visits and achieved significant gains. The complete dataset, code
and checkpoints will be available upon release.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10476" title="Abstract">arXiv:2401.10476</a> [<a href="/pdf/2401.10476" title="Download PDF">pdf</a>, <a href="/ps/2401.10476" title="Download PostScript">ps</a>, <a href="/format/2401.10476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quickly Determining Who Won an Election
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hellerstein%2C+L">Lisa Hellerstein</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Naifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Schewior%2C+K">Kevin Schewior</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of ITCS 2024 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">This paper considers elections in which voters choose one candidate each,
independently according to known probability distributions. A candidate
receiving a strict majority (absolute or relative, depending on the version)
wins. After the voters have made their choices, each vote can be inspected to
determine which candidate received that vote. The time (or cost) to inspect
each of the votes is known in advance. The task is to (possibly adaptively)
determine the order in which to inspect the votes, so as to minimize the
expected time to determine which candidate has won the election. We design
polynomial-time constant-factor approximation algorithms for both the
absolute-majority and the relative-majority version. Both algorithms are based
on a two-phase approach. In the first phase, the algorithms reduce the number
of relevant candidates to $O(1)$, and in the second phase they utilize
techniques from the literature on stochastic function evaluation to handle the
remaining candidates. In the case of absolute majority, we show that the same
can be achieved with only two rounds of adaptivity.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10478" title="Abstract">arXiv:2401.10478</a> [<a href="/pdf/2401.10478" title="Download PDF">pdf</a>, <a href="/format/2401.10478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Budgeted Online Model Selection and Fine-Tuning via Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghari%2C+P+M">Pouya M. Ghari</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yanning Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Transactions on Machine Learning Research (TMLR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Online model selection involves selecting a model from a set of candidate
models 'on the fly' to perform prediction on a stream of data. The choice of
candidate models henceforth has a crucial impact on the performance. Although
employing a larger set of candidate models naturally leads to more flexibility
in model selection, this may be infeasible in cases where prediction tasks are
performed on edge devices with limited memory. Faced with this challenge, the
present paper proposes an online federated model selection framework where a
group of learners (clients) interacts with a server with sufficient memory such
that the server stores all candidate models. However, each client only chooses
to store a subset of models that can be fit into its memory and performs its
own prediction task using one of the stored models. Furthermore, employing the
proposed algorithm, clients and the server collaborate to fine-tune models to
adapt them to a non-stationary environment. Theoretical analysis proves that
the proposed algorithm enjoys sub-linear regret with respect to the best model
in hindsight. Experiments on real datasets demonstrate the effectiveness of the
proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10480" title="Abstract">arXiv:2401.10480</a> [<a href="/pdf/2401.10480" title="Download PDF">pdf</a>, <a href="/format/2401.10480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+P">Peiwen Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shaoxiong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Boyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinglin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Self-consistency (SC) has been a widely used decoding strategy for
chain-of-thought reasoning. Despite bringing significant performance
improvements across a variety of multi-step reasoning tasks, it is a high-cost
method that requires multiple sampling with the preset size. In this paper, we
propose a simple and scalable sampling process, \textbf{E}arly-Stopping
\textbf{S}elf-\textbf{C}onsistency (ESC), to greatly reduce the cost of SC
without sacrificing performance. On this basis, one control scheme for ESC is
further derivated to dynamically choose the performance-cost balance for
different tasks and models. To demonstrate ESC's effectiveness, we conducted
extensive experiments on three popular categories of reasoning tasks:
arithmetic, commonsense and symbolic reasoning over language models with
varying scales. The empirical results show that ESC reduces the average number
of sampling of chain-of-thought reasoning by a significant margin on six
benchmarks, including MATH (-33.8%), GSM8K (-80.1%), StrategyQA (-76.8%),
CommonsenseQA (-78.5%), Coin Flip (-84.2%) and Last Letters (-67.4%), while
attaining comparable performances.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10484" title="Abstract">arXiv:2401.10484</a> [<a href="/pdf/2401.10484" title="Download PDF">pdf</a>, <a href="/format/2401.10484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Scalability in Recommender Systems through Lottery Ticket  Hypothesis and Knowledge Distillation-based Neural Network Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%2C+R">Rajaram R</a>, 
<a href="/search/cs?searchtype=author&query=Bharadhwaj%2C+M">Manoj Bharadhwaj</a>, 
<a href="/search/cs?searchtype=author&query=VS%2C+V">Vasan VS</a>, 
<a href="/search/cs?searchtype=author&query=Pervin%2C+N">Nargis Pervin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in WITS 2023 as a workshop paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
<p class="mathjax">This study introduces an innovative approach aimed at the efficient pruning
of neural networks, with a particular focus on their deployment on edge
devices. Our method involves the integration of the Lottery Ticket Hypothesis
(LTH) with the Knowledge Distillation (KD) framework, resulting in the
formulation of three distinct pruning models. These models have been developed
to address scalability issue in recommender systems, whereby the complexities
of deep learning models have hindered their practical deployment. With
judicious application of the pruning techniques, we effectively curtail the
power consumption and model dimensions without compromising on accuracy.
Empirical evaluation has been performed using two real world datasets from
diverse domains against two baselines. Gratifyingly, our approaches yielded a
GPU computation-power reduction of up to 66.67%. Notably, our study contributes
to the field of recommendation system by pioneering the application of LTH and
KD.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10487" title="Abstract">arXiv:2401.10487</a> [<a href="/pdf/2401.10487" title="Download PDF">pdf</a>, <a href="/format/2401.10487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Dense Retrieval: Memory Can Be a Burden
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+P">Peiwen Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinglin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shaoxiong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Boyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024 main
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EACL 2024 main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Generative Retrieval (GR), autoregressively decoding relevant document
identifiers given a query, has been shown to perform well under the setting of
small-scale corpora. By memorizing the document corpus with model parameters,
GR implicitly achieves deep interaction between query and document. However,
such a memorizing mechanism faces three drawbacks: (1) Poor memory accuracy for
fine-grained features of documents; (2) Memory confusion gets worse as the
corpus size increases; (3) Huge memory update costs for new documents. To
alleviate these problems, we propose the Generative Dense Retrieval (GDR)
paradigm. Specifically, GDR first uses the limited memory volume to achieve
inter-cluster matching from query to relevant document clusters.
Memorizing-free matching mechanism from Dense Retrieval (DR) is then introduced
to conduct fine-grained intra-cluster matching from clusters to relevant
documents. The coarse-to-fine process maximizes the advantages of GR's deep
interaction and DR's scalability. Besides, we design a cluster identifier
constructing strategy to facilitate corpus memory and a cluster-adaptive
negative sampling strategy to enhance the intra-cluster mapping ability.
Empirical results show that GDR obtains an average of 3.0 R@100 improvement on
NQ dataset under multiple settings and has better scalability.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10490" title="Abstract">arXiv:2401.10490</a> [<a href="/pdf/2401.10490" title="Download PDF">pdf</a>, <a href="/format/2401.10490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization Error Guaranteed Auto-Encoder-Based Nonlinear Model  Reduction for Operator Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dahal%2C+B">Biraj Dahal</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+R">Rongjie Lai</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wenjing Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Many physical processes in science and engineering are naturally represented
by operators between infinite-dimensional function spaces. The problem of
operator learning, in this context, seeks to extract these physical processes
from empirical data, which is challenging due to the infinite or high
dimensionality of data. An integral component in addressing this challenge is
model reduction, which reduces both the data dimensionality and problem size.
In this paper, we utilize low-dimensional nonlinear structures in model
reduction by investigating Auto-Encoder-based Neural Network (AENet). AENet
first learns the latent variables of the input data and then learns the
transformation from these latent variables to corresponding output data. Our
numerical experiments validate the ability of AENet to accurately learn the
solution operator of nonlinear partial differential equations. Furthermore, we
establish a mathematical and statistical estimation theory that analyzes the
generalization error of AENet. Our theoretical framework shows that the sample
complexity of training AENet is intricately tied to the intrinsic dimension of
the modeled process, while also demonstrating the remarkable resilience of
AENet to noise.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10491" title="Abstract">arXiv:2401.10491</a> [<a href="/pdf/2401.10491" title="Download PDF">pdf</a>, <a href="/format/2401.10491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Fusion of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fanqi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While training large language models (LLMs) from scratch can generate models
with distinct functionalities and strengths, it comes at significant costs and
may result in redundant capabilities. Alternatively, a cost-effective and
compelling approach is to merge existing pre-trained LLMs into a more potent
model. However, due to the varying architectures of these LLMs, directly
blending their weights is impractical. In this paper, we introduce the notion
of knowledge fusion for LLMs, aimed at combining the capabilities of existing
LLMs and transferring them into a single LLM. By leveraging the generative
distributions of source LLMs, we externalize their collective knowledge and
unique strengths, thereby potentially elevating the capabilities of the target
model beyond those of any individual source LLM. We validate our approach using
three popular LLMs with different architectures--Llama-2, MPT, and
OpenLLaMA--across various benchmarks and tasks. Our findings confirm that the
fusion of LLMs can improve the performance of the target model across a range
of capabilities such as reasoning, commonsense, and code generation. Our code,
model weights, and data are public at
\url{https://github.com/fanqiwan/FuseLLM}.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10495" title="Abstract">arXiv:2401.10495</a> [<a href="/pdf/2401.10495" title="Download PDF">pdf</a>, <a href="/ps/2401.10495" title="Download PostScript">ps</a>, <a href="/format/2401.10495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Layering via Conditional Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feigenbaum%2C+I">Itai Feigenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Arpit%2C+D">Devansh Arpit</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Heinecke%2C+S">Shelby Heinecke</a>, 
<a href="/search/cs?searchtype=author&query=Niebles%2C+J+C">Juan Carlos Niebles</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Weiran Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Savarese%2C+S">Silvio Savarese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Causal discovery aims to recover information about an unobserved causal graph
from the observable data it generates. Layerings are orderings of the variables
which place causes before effects. In this paper, we provide ways to recover
layerings of a graph by accessing the data via a conditional entropy oracle,
when distributions are discrete. Our algorithms work by repeatedly removing
sources or sinks from the graph. Under appropriate assumptions and
conditioning, we can separate the sources or sinks from the remainder of the
nodes by comparing their conditional entropy to the unconditional entropy of
their noise. Our algorithms are provably correct and run in worst-case
quadratic time. The main assumptions are faithfulness and injective noise, and
either known noise entropies or weakly monotonically increasing noise entropies
along directed paths. In addition, we require one of either a very mild
extension of faithfulness, or strictly monotonically increasing noise
entropies, or expanding noise injectivity to include an additional single
argument in the structural functions.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10498" title="Abstract">arXiv:2401.10498</a> [<a href="/pdf/2401.10498" title="Download PDF">pdf</a>, <a href="/format/2401.10498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Probabilistic Optimal Power Flow Assessment Using an Adaptive  Stochastic Spectral Embedding Surrogate Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiaoting Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jingyu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiaozhe Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE International Conference on Circuits and Systems (ISCAS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents an adaptive stochastic spectral embedding (ASSE) method
to solve the probabilistic AC optimal power flow (AC-OPF), a critical aspect of
power system operation. The proposed method can efficiently and accurately
estimate the probabilistic characteristics of AC-OPF solutions. An adaptive
domain partition strategy and expansion coefficient calculation algorithm are
integrated to enhance its performance. Numerical studies on a 9-bus system
demonstrate that the proposed ASSE method offers accurate and fast evaluations
compared to the Monte Carlo simulations. A comparison with a sparse polynomial
chaos expansion method, an existing surrogate model, further demonstrates its
efficacy in accurately assessing the responses with strongly local behaviors.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10501" title="Abstract">arXiv:2401.10501</a> [<a href="/pdf/2401.10501" title="Download PDF">pdf</a>, <a href="/ps/2401.10501" title="Download PostScript">ps</a>, <a href="/format/2401.10501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing medical vision-language contrastive learning via  inter-matching relation modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+M">Mingyuan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Fulham%2C+M">Michael Fulham</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D+D">David Dagan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+L">Lei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinman Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Medical image representations can be learned through medical vision-language
contrastive learning (mVLCL) where medical imaging reports are used as weak
supervision through image-text alignment. These learned image representations
can be transferred to and benefit various downstream medical vision tasks such
as disease classification and segmentation. Recent mVLCL methods attempt to
align image sub-regions and the report keywords as local-matchings. However,
these methods aggregate all local-matchings via simple pooling operations while
ignoring the inherent relations between them. These methods therefore fail to
reason between local-matchings that are semantically related, e.g.,
local-matchings that correspond to the disease word and the location word
(semantic-relations), and also fail to differentiate such clinically important
local-matchings from others that correspond to less meaningful words, e.g.,
conjunction words (importance-relations). Hence, we propose a mVLCL method that
models the inter-matching relations between local-matchings via a
relation-enhanced contrastive learning framework (RECLF). In RECLF, we
introduce a semantic-relation reasoning module (SRM) and an importance-relation
reasoning module (IRM) to enable more fine-grained report supervision for image
representation learning. We evaluated our method using four public benchmark
datasets on four downstream tasks, including segmentation, zero-shot
classification, supervised classification, and cross-modal retrieval. Our
results demonstrated the superiority of our RECLF over the state-of-the-art
mVLCL methods with consistent improvements across single-modal and cross-modal
tasks. These results suggest that our RECLF, by modelling the inter-matching
relations, can learn improved medical image representations with better
generalization capabilities.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10504" title="Abstract">arXiv:2401.10504</a> [<a href="/pdf/2401.10504" title="Download PDF">pdf</a>, <a href="/ps/2401.10504" title="Download PostScript">ps</a>, <a href="/format/2401.10504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multi-dimensional analysis of usage counts, Mendeley readership, and  citations for journal and conference papers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+W">Wencan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhichao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Costas%2C+R">Rodrigo Costas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">This study analyzed 16,799 journal papers and 98,773 conference papers
published by IEEE Xplore in 2016 to investigate the relationships among usage
counts, Mendeley readership, and citations through descriptive, regression, and
mediation analyses. Differences in the relationship among these metrics between
journal and conference papers are also studied. Results showed that there is no
significant difference between journal and conference papers in the
distribution patterns and accumulation rates of the three metrics. However, the
correlation coefficients of the interrelationships between the three metrics
were lower in conference papers compared to journal papers. Secondly, funding,
international collaboration, and open access are positively associated with all
three metrics, except for the case of funding on the usage metrics of
conference papers. Furthermore, early Mendeley readership is a better predictor
of citations than early usage counts and performs better for journal papers.
Finally, we reveal that early Mendeley readership partially mediates between
early usage counts and citation counts in the journal and conference papers.
The main difference is that conference papers rely more on the direct effect of
early usage counts on citations. This study contributes to expanding the
existing knowledge on the relationships among usage counts, Mendeley
readership, and citations in journal and conference papers, providing new
insights into the relationship between the three metrics through mediation
analysis.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10506" title="Abstract">arXiv:2401.10506</a> [<a href="/pdf/2401.10506" title="Download PDF">pdf</a>, <a href="/format/2401.10506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuren Mao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yijiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+Y">Yu Mi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yunjun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+D">Dongfang Lou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jinshu Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
<p class="mathjax">Text-to-SQL, which provides zero-code interface for operating relational
databases, has gained much attention in financial analysis; because, financial
professionals may not well-skilled in SQL programming. However, until now,
there is no practical Text-to-SQL benchmark dataset for financial analysis, and
existing Text-to-SQL methods have not considered the unique characteristics of
databases in financial applications, such as commonly existing wide tables. To
address these issues, we collect a practical Text-to-SQL benchmark dataset and
propose a model-agnostic Large Language Model (LLMs)-based Text-to-SQL
framework for financial analysis. The benchmark dataset, BULL, is collected
from the practical financial analysis business of Hundsun Technologies Inc.,
including databases for fund, stock, and macro economy. Besides, the proposed
LLMs-based Text-to-SQL framework, FinSQL, provides a systematic treatment for
financial Text-to-SQL from the perspectives of prompt construction,
parameter-efficient fine-tuning and output calibration. Extensive experimental
results on BULL demonstrate that FinSQL achieves the state-of-the-art
Text-to-SQL performance at a small cost; furthermore, FinSQL can bring up to
36.64% performance improvement in scenarios requiring few-shot cross-database
model transfer.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10510" title="Abstract">arXiv:2401.10510</a> [<a href="/pdf/2401.10510" title="Download PDF">pdf</a>, <a href="/format/2401.10510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A match made in consistency heaven: when large language models meet  evolutionary algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wang Chao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiaxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingling Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuyuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A perspective article under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pre-trained large language models (LLMs) have powerful capabilities for
generating creative natural text. Evolutionary algorithms (EAs) can discover
diverse solutions to complex real-world problems. Motivated by the common
collective and directionality of text sequence generation and evolution, this
paper illustrates the strong consistency of LLMs and EAs, which includes
multiple one-to-one key characteristics: token embedding and genotype-phenotype
mapping, position encoding and fitness shaping, position embedding and
selection, attention and crossover, feed-forward neural network and mutation,
model training and parameter update, and multi-task learning and
multi-objective optimization. Based on this consistency perspective, existing
coupling studies are analyzed, including evolutionary fine-tuning and
LLM-enhanced EAs. Leveraging these insights, we outline a fundamental roadmap
for future research in coupling LLMs and EAs, while highlighting key challenges
along the way. The consistency not only reveals the evolution mechanism behind
LLMs but also facilitates the development of evolved artificial agents that
approach or surpass biological organisms.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10511" title="Abstract">arXiv:2401.10511</a> [<a href="/pdf/2401.10511" title="Download PDF">pdf</a>, <a href="/format/2401.10511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GMC-IQA: Exploiting Global-correlation and Mean-opinion Consistency for  No-reference Image Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zewen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Juan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chunfeng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Weiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junxian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youqun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Congxuan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to the subjective nature of image quality assessment (IQA), assessing
which image has better quality among a sequence of images is more reliable than
assigning an absolute mean opinion score for an image. Thus, IQA models are
evaluated by global correlation consistency (GCC) metrics like PLCC and SROCC,
rather than mean opinion consistency (MOC) metrics like MAE and MSE. However,
most existing methods adopt MOC metrics to define their loss functions, due to
the infeasible computation of GCC metrics during training. In this work, we
construct a novel loss function and network to exploit Global-correlation and
Mean-opinion Consistency, forming a GMC-IQA framework. Specifically, we propose
a novel GCC loss by defining a pairwise preference-based rank estimation to
solve the non-differentiable problem of SROCC and introducing a queue mechanism
to reserve previous data to approximate the global results of the whole data.
Moreover, we propose a mean-opinion network, which integrates diverse opinion
features to alleviate the randomness of weight learning and enhance the model
robustness. Experiments indicate that our method outperforms SOTA methods on
multiple authentic datasets with higher accuracy and generalization. We also
adapt the proposed loss to various networks, which brings better performance
and more stable training.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10512" title="Abstract">arXiv:2401.10512</a> [<a href="/pdf/2401.10512" title="Download PDF">pdf</a>, <a href="/format/2401.10512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Color Invariance through Image-Level Ensemble Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yunpeng Gong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaquan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lifei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Min Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the field of computer vision, the persistent presence of color bias,
resulting from fluctuations in real-world lighting and camera conditions,
presents a substantial challenge to the robustness of models. This issue is
particularly pronounced in complex wide-area surveillance scenarios, such as
person re-identification and industrial dust segmentation, where models often
experience a decline in performance due to overfitting on color information
during training, given the presence of environmental variations. Consequently,
there is a need to effectively adapt models to cope with the complexities of
camera conditions. To address this challenge, this study introduces a learning
strategy named Random Color Erasing, which draws inspiration from ensemble
learning. This strategy selectively erases partial or complete color
information in the training data without disrupting the original image
structure, thereby achieving a balanced weighting of color features and other
features within the neural network. This approach mitigates the risk of
overfitting and enhances the model's ability to handle color variation, thereby
improving its overall robustness. The approach we propose serves as an ensemble
learning strategy, characterized by robust interpretability. A comprehensive
analysis of this methodology is presented in this paper. Across various tasks
such as person re-identification and semantic segmentation, our approach
consistently improves strong baseline methods. Notably, in comparison to
existing methods that prioritize color robustness, our strategy significantly
enhances performance in cross-domain scenarios. The code available at
\url{https://github.com/layumi/Person\_reID\_baseline\_pytorch/blob/master/random\_erasing.py}
or \url{https://github.com/finger-monkey/Data-Augmentation}.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10515" title="Abstract">arXiv:2401.10515</a> [<a href="/pdf/2401.10515" title="Download PDF">pdf</a>, <a href="/format/2401.10515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Pathways in Coevolutionary Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sipper%2C+M">Moshe Sipper</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+J+H">Jason H. Moore</a>, 
<a href="/search/cs?searchtype=author&query=Urbanowicz%2C+R+J">Ryan J. Urbanowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2206.13509">arXiv:2206.13509</a>, <a href="/abs/2206.15409">arXiv:2206.15409</a>, <a href="/abs/2206.12707">arXiv:2206.12707</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> W. Banzhaf et al. (eds.), Genetic Programming Theory and Practice
  XVII, Genetic and Evolutionary Computation, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The simultaneous evolution of two or more species with coupled fitness --
coevolution -- has been put to good use in the field of evolutionary
computation. Herein, we present two new forms of coevolutionary algorithms,
which we have recently designed and applied with success. OMNIREP is a
cooperative coevolutionary algorithm that discovers both a representation and
an encoding for solving a particular problem of interest. SAFE is a
commensalistic coevolutionary algorithm that maintains two coevolving
populations: a population of candidate solutions and a population of candidate
objective functions needed to measure solution quality during evolution.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10516" title="Abstract">arXiv:2401.10516</a> [<a href="/pdf/2401.10516" title="Download PDF">pdf</a>, <a href="/format/2401.10516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Episodic Reinforcement Learning with Expanded State-reward Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Dayang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunlong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAMAS'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Empowered by deep neural networks, deep reinforcement learning (DRL) has
demonstrated tremendous empirical successes in various domains, including
games, health care, and autonomous driving. Despite these advancements, DRL is
still identified as data-inefficient as effective policies demand vast numbers
of environmental samples. Recently, episodic control (EC)-based model-free DRL
methods enable sample efficiency by recalling past experiences from episodic
memory. However, existing EC-based methods suffer from the limitation of
potential misalignment between the state and reward spaces for neglecting the
utilization of (past) retrieval states with extensive information, which
probably causes inaccurate value estimation and degraded policy performance. To
tackle this issue, we introduce an efficient EC-based DRL framework with
expanded state-reward space, where the expanded states used as the input and
the expanded rewards used in the training both contain historical and current
information. To be specific, we reuse the historical states retrieved by EC as
part of the input states and integrate the retrieved MC-returns into the
immediate reward in each interactive transition. As a result, our method is
able to simultaneously achieve the full utilization of retrieval information
and the better evaluation of state values by a Temporal Difference (TD) loss.
Empirical results on challenging Box2d and Mujoco tasks demonstrate the
superiority of our method over a recent sibling method and common baselines.
Further, we also verify our method's effectiveness in alleviating Q-value
overestimation by additional experiments of Q-value comparison.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10518" title="Abstract">arXiv:2401.10518</a> [<a href="/pdf/2401.10518" title="Download PDF">pdf</a>, <a href="/format/2401.10518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-temporal Forecasting for Regions without Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xinyu Su</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jianzhong Qi</a>, 
<a href="/search/cs?searchtype=author&query=Tanin%2C+E">Egemen Tanin</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yanchuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sarvi%2C+M">Majid Sarvi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EDBT2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Spatial-temporal forecasting plays an important role in many real-world
applications, such as traffic forecasting, air pollutant forecasting,
crowd-flow forecasting, and so on. State-of-the-art spatial-temporal
forecasting models take data-driven approaches and rely heavily on data
availability. Such models suffer from accuracy issues when data is incomplete,
which is common in reality due to the heavy costs of deploying and maintaining
sensors for data collection. A few recent studies attempted to address the
issue of incomplete data. They typically assume some data availability in a
region of interest either for a short period or at a few locations. In this
paper, we further study spatial-temporal forecasting for a region of interest
without any historical observations, to address scenarios such as unbalanced
region development, progressive deployment of sensors or lack of open data. We
propose a model named STSM for the task. The model takes a contrastive
learning-based approach to learn spatial-temporal patterns from adjacent
regions that have recorded data. Our key insight is to learn from the locations
that resemble those in the region of interest, and we propose a selective
masking strategy to enable the learning. As a result, our model outperforms
adapted state-of-the-art models, reducing errors consistently over both traffic
and air pollutant forecasting tasks. The source code is available at
https://github.com/suzy0223/STSM.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10519" title="Abstract">arXiv:2401.10519</a> [<a href="/pdf/2401.10519" title="Download PDF">pdf</a>, <a href="/format/2401.10519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Wind-Aware Path Planning Method for UAV-Asisted Bridge Inspection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jian Xu</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+H">Hua Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In response to the gap in considering wind conditions in the bridge
inspection using unmanned aerial vehicle (UAV) , this paper proposes a path
planning method for UAVs that takes into account the influence of wind, based
on the simulated annealing algorithm. The algorithm considers the wind factors,
including the influence of different wind speeds and directions at the same
time on the path planning of the UAV. Firstly, An environment model is
constructed specifically for UAV bridge inspection, taking into account the
various objective functions and constraint conditions of UAVs. A more
sophisticated and precise mathematical model is then developed based on this
environmental model to enable efficient and effective UAV path planning.
Secondly, the bridge separation planning model is applied in a novel way, and a
series of parameters are simulated, including the adjustment of the initial
temperature value. The experimental results demonstrate that, compared with
traditional local search algorithms, the proposed method achieves a cost
reduction of 30.05\% and significantly improves effectiveness. Compared to path
planning methods that do not consider wind factors, the proposed approach
yields more realistic and practical results for UAV applications, as
demonstrated by its improved effectiveness in simulations. These findings
highlight the value of our method in facilitating more accurate and efficient
UAV path planning in wind-prone environments.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10521" title="Abstract">arXiv:2401.10521</a> [<a href="/pdf/2401.10521" title="Download PDF">pdf</a>, <a href="/format/2401.10521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-lingual Editing in Multilingual Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beniwal%2C+H">Himanshu Beniwal</a>, 
<a href="/search/cs?searchtype=author&query=D%2C+K+N">Kowsik Nandagopan D</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Mayank Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The training of large language models (LLMs) necessitates substantial data
and computational resources, and updating outdated LLMs entails significant
efforts and resources. While numerous model editing techniques (METs) have
emerged to efficiently update model outputs without retraining, their
effectiveness in multilingual LLMs, where knowledge is stored in diverse
languages, remains an underexplored research area. This research paper
introduces the cross-lingual model editing (\textbf{XME}) paradigm, wherein a
fact is edited in one language, and the subsequent update propagation is
observed across other languages. To investigate the XME paradigm, we conducted
experiments using BLOOM, mBERT, and XLM-RoBERTa using the two writing scripts:
\textit{Latin} (English, French, and Spanish) and \textit{Indic} (Hindi,
Gujarati, and Bengali). The results reveal notable performance limitations of
state-of-the-art METs under the XME setting, mainly when the languages involved
belong to two distinct script families. These findings highlight the need for
further research and development of XME techniques to address these challenges.
For more comprehensive information, the dataset used in this research and the
associated code are publicly available at the following
URL\url{https://github.com/lingo-iitgn/XME}.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10522" title="Abstract">arXiv:2401.10522</a> [<a href="/pdf/2401.10522" title="Download PDF">pdf</a>, <a href="/ps/2401.10522" title="Download PostScript">ps</a>, <a href="/format/2401.10522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FARe: Fault-Aware GNN Training on ReRAM-based PIM Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhingra%2C+P">Pratyush Dhingra</a>, 
<a href="/search/cs?searchtype=author&query=Ogbogu%2C+C">Chukwufumnanya Ogbogu</a>, 
<a href="/search/cs?searchtype=author&query=Joardar%2C+B+K">Biresh Kumar Joardar</a>, 
<a href="/search/cs?searchtype=author&query=Doppa%2C+J+R">Janardhan Rao Doppa</a>, 
<a href="/search/cs?searchtype=author&query=Kalyanaraman%2C+A">Ananth Kalyanaraman</a>, 
<a href="/search/cs?searchtype=author&query=Pande%2C+P+P">Partha Pratim Pande</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted to the conference DATE (Design, Automation and Test in Europe) - 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Resistive random-access memory (ReRAM)-based processing-in-memory (PIM)
architecture is an attractive solution for training Graph Neural Networks
(GNNs) on edge platforms. However, the immature fabrication process and limited
write endurance of ReRAMs make them prone to hardware faults, thereby limiting
their widespread adoption for GNN training. Further, the existing
fault-tolerant solutions prove inadequate for effectively training GNNs in the
presence of faults. In this paper, we propose a fault-aware framework referred
to as FARe that mitigates the effect of faults during GNN training. FARe
outperforms existing approaches in terms of both accuracy and timing overhead.
Experimental results demonstrate that FARe framework can restore GNN test
accuracy by 47.6% on faulty ReRAM hardware with a ~1% timing overhead compared
to the fault-free counterpart.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10525" title="Abstract">arXiv:2401.10525</a> [<a href="/pdf/2401.10525" title="Download PDF">pdf</a>, <a href="/format/2401.10525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focaler-IoU: More Focused Intersection over Union Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuaijie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2312.17663">arXiv:2312.17663</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Bounding box regression plays a crucial role in the field of object
detection, and the positioning accuracy of object detection largely depends on
the loss function of bounding box regression. Existing researchs improve
regression performance by utilizing the geometric relationship between bounding
boxes, while ignoring the impact of difficult and easy sample distribution on
bounding box regression. In this article, we analyzed the impact of difficult
and easy sample distribution on regression results, and then proposed
Focaler-IoU, which can improve detector performance in different detection
tasks by focusing on different regression samples. Finally, comparative
experiments were conducted using existing advanced detectors and regression
methods for different detection tasks, and the detection performance was
further improved by using the method proposed in this paper.Code is available
at \url{https://github.com/malagoutou/Focaler-IoU}.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10526" title="Abstract">arXiv:2401.10526</a> [<a href="/pdf/2401.10526" title="Download PDF">pdf</a>, <a href="/format/2401.10526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On mitigating stability-plasticity dilemma in CLIP-guided image morphing  via geodesic distillation loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+Y">Yeongtak Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Saehyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+U">Uiwon Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sungroh Yoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale language-vision pre-training models, such as CLIP, have achieved
remarkable text-guided image morphing results by leveraging several
unconditional generative models. However, existing CLIP-guided image morphing
methods encounter difficulties when morphing photorealistic images.
Specifically, existing guidance fails to provide detailed explanations of the
morphing regions within the image, leading to misguidance. In this paper, we
observed that such misguidance could be effectively mitigated by simply using a
proper regularization loss. Our approach comprises two key components: 1) a
geodesic cosine similarity loss that minimizes inter-modality features (i.e.,
image and text) on a projected subspace of CLIP space, and 2) a latent
regularization loss that minimizes intra-modality features (i.e., image and
image) on the image manifold. By replacing the na\"ive directional CLIP loss in
a drop-in replacement manner, our method achieves superior morphing results on
both images and videos for various benchmarks, including CLIP-inversion.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10527" title="Abstract">arXiv:2401.10527</a> [<a href="/pdf/2401.10527" title="Download PDF">pdf</a>, <a href="/ps/2401.10527" title="Download PostScript">ps</a>, <a href="/format/2401.10527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new approach to the Berlekamp-Massey-Sakata Algorithm. Improving  Locator Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernal%2C+J+J">Jos&#xe9; Joaqu&#xed;n Bernal</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%B3n%2C+J+J">Juan Jacobo Sim&#xf3;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Trans. Inform. Theory. Vol. 67(1), 2021, 268-281
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We study the problem of the computation of Groebner basis for the ideal of
linear recurring relations of a doubly periodic array. We find a set of indexes
such that, along with some conditions, guarantees that the set of polynomials
obtained at the last iteration in the Berlekamp-Massey-Sakata algorithm is
exactly a Groebner basis for the mentioned ideal. Then, we apply these results
to improve locator decoding in abelian codes.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10529" title="Abstract">arXiv:2401.10529</a> [<a href="/pdf/2401.10529" title="Download PDF">pdf</a>, <a href="/format/2401.10529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mementos: A Comprehensive Benchmark for Multimodal Large Language Model  Reasoning over Image Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongjin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuancheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+F">Feihong He</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jaehong Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Taixi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bertasius%2C+G">Gedas Bertasius</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huaxiu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 23 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multimodal Large Language Models (MLLMs) have demonstrated proficiency in
handling a variety of visual-language tasks. However, current MLLM benchmarks
are predominantly designed to evaluate reasoning based on static information
about a single image, and the ability of modern MLLMs to extrapolate from image
sequences, which is essential for understanding our ever-changing world, has
been less investigated. To address this challenge, this paper introduces
Mementos, a new benchmark designed to assess MLLMs' sequential image reasoning
abilities. Mementos features 4,761 diverse image sequences with varying
lengths. We also employ a GPT-4 assisted method to evaluate MLLM reasoning
performance. Through a careful evaluation of nine recent MLLMs on Mementos,
including GPT-4V and Gemini, we find that they struggle to accurately describe
dynamic information about given image sequences, often leading to
hallucinations/misrepresentations of objects and their corresponding behaviors.
Our quantitative analysis and case studies identify three key factors impacting
MLLMs' sequential image reasoning: the correlation between object and
behavioral hallucinations, the influence of cooccurring behaviors, and the
compounding impact of behavioral hallucinations. Our dataset is available at
https://github.com/umd-huang-lab/Mementos.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10530" title="Abstract">arXiv:2401.10530</a> [<a href="/pdf/2401.10530" title="Download PDF">pdf</a>, <a href="/format/2401.10530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NWPU-MOC: A Benchmark for Fine-grained Multi-category Object Counting in  Aerial Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liangliang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object counting is a hot topic in computer vision, which aims to estimate the
number of objects in a given image. However, most methods only count objects of
a single category for an image, which cannot be applied to scenes that need to
count objects with multiple categories simultaneously, especially in aerial
scenes. To this end, this paper introduces a Multi-category Object Counting
(MOC) task to estimate the numbers of different objects (cars, buildings,
ships, etc.) in an aerial image. Considering the absence of a dataset for this
task, a large-scale Dataset (NWPU-MOC) is collected, consisting of 3,416 scenes
with a resolution of 1024 $\times$ 1024 pixels, and well-annotated using 14
fine-grained object categories. Besides, each scene contains RGB and Near
Infrared (NIR) images, of which the NIR spectrum can provide richer
characterization information compared with only the RGB spectrum. Based on
NWPU-MOC, the paper presents a multi-spectrum, multi-category object counting
framework, which employs a dual-attention module to fuse the features of RGB
and NIR and subsequently regress multi-channel density maps corresponding to
each object category. In addition, to modeling the dependency between different
channels in the density map with each object category, a spatial contrast loss
is designed as a penalty for overlapping predictions at the same spatial
position. Experimental results demonstrate that the proposed method achieves
state-of-the-art performance compared with some mainstream counting algorithms.
The dataset, code and models are publicly available at
https://github.com/lyongo/NWPU-MOC.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10531" title="Abstract">arXiv:2401.10531</a> [<a href="/pdf/2401.10531" title="Download PDF">pdf</a>, <a href="/format/2401.10531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lessons Learned from Designing an Open-Source Automated Feedback System  for STEM Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steinert%2C+S">Steffen Steinert</a>, 
<a href="/search/cs?searchtype=author&query=Krupp%2C+L">Lars Krupp</a>, 
<a href="/search/cs?searchtype=author&query=Avila%2C+K+E">Karina E. Avila</a>, 
<a href="/search/cs?searchtype=author&query=Janssen%2C+A+S">Anke S. Janssen</a>, 
<a href="/search/cs?searchtype=author&query=Ruf%2C+V">Verena Ruf</a>, 
<a href="/search/cs?searchtype=author&query=Dzsotjan%2C+D">David Dzsotjan</a>, 
<a href="/search/cs?searchtype=author&query=De+Schryver%2C+C">Christian De Schryver</a>, 
<a href="/search/cs?searchtype=author&query=Karolus%2C+J">Jakob Karolus</a>, 
<a href="/search/cs?searchtype=author&query=Ruzika%2C+S">Stefan Ruzika</a>, 
<a href="/search/cs?searchtype=author&query=Joisten%2C+K">Karen Joisten</a>, 
<a href="/search/cs?searchtype=author&query=Lukowicz%2C+P">Paul Lukowicz</a>, 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+J">Jochen Kuhn</a>, 
<a href="/search/cs?searchtype=author&query=Wehn%2C+N">Norbert Wehn</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCchemann%2C+S">Stefan K&#xfc;chemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Physics Education (physics.ed-ph)

</div>
<p class="mathjax">As distance learning becomes increasingly important and artificial
intelligence tools continue to advance, automated systems for individual
learning have attracted significant attention. However, the scarcity of
open-source online tools that are capable of providing personalized feedback
has restricted the widespread implementation of research-based feedback
systems. In this work, we present RATsApp, an open-source automated feedback
system (AFS) that incorporates research-based features such as formative
feedback. The system focuses on core STEM competencies such as mathematical
competence, representational competence, and data literacy. It also allows
lecturers to monitor students' progress. We conducted a survey based on the
technology acceptance model (TAM2) among a set of students (N=64). Our findings
confirm the applicability of the TAM2 framework, revealing that factors such as
the relevance of the studies, output quality, and ease of use significantly
influence the perceived usefulness. We also found a linear relation between the
perceived usefulness and the intention to use, which in turn is a significant
predictor of the frequency of use. Moreover, the formative feedback feature of
RATsApp received positive feedback, indicating its potential as an educational
tool. Furthermore, as an open-source platform, RATsApp encourages public
contributions to its ongoing development, fostering a collaborative approach to
improve educational tools.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10535" title="Abstract">arXiv:2401.10535</a> [<a href="/pdf/2401.10535" title="Download PDF">pdf</a>, <a href="/format/2401.10535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The &quot;Colonial Impulse&quot; of Natural Language Processing: An Audit of  Bengali Sentiment Analysis Tools and Their Identity-based Biases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+D">Dipto Das</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+S">Shion Guha</a>, 
<a href="/search/cs?searchtype=author&query=Brubaker%2C+J">Jed Brubaker</a>, 
<a href="/search/cs?searchtype=author&query=Semaan%2C+B">Bryan Semaan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">While colonization has sociohistorically impacted people's identities across
various dimensions, those colonial values and biases continue to be perpetuated
by sociotechnical systems. One category of sociotechnical systems--sentiment
analysis tools--can also perpetuate colonial values and bias, yet less
attention has been paid to how such tools may be complicit in perpetuating
coloniality, although they are often used to guide various practices (e.g.,
content moderation). In this paper, we explore potential bias in sentiment
analysis tools in the context of Bengali communities that have experienced and
continue to experience the impacts of colonialism. Drawing on identity
categories most impacted by colonialism amongst local Bengali communities, we
focused our analytic attention on gender, religion, and nationality. We
conducted an algorithmic audit of all sentiment analysis tools for Bengali,
available on the Python package index (PyPI) and GitHub. Despite similar
semantic content and structure, our analyses showed that in addition to
inconsistencies in output from different tools, Bengali sentiment analysis
tools exhibit bias between different identity categories and respond
differently to different ways of identity expression. Connecting our findings
with colonially shaped sociocultural structures of Bengali communities, we
discuss the implications of downstream bias of sentiment analysis tools.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10536" title="Abstract">arXiv:2401.10536</a> [<a href="/pdf/2401.10536" title="Download PDF">pdf</a>, <a href="/format/2401.10536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech Swin-Transformer: Exploring a Hierarchical Transformer with  Shifted Windows for Speech Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+H">Hailun Lian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B">Bj&#xf6;rn Schuller</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+Y">Yuan Zong</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenming Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Swin-Transformer has demonstrated remarkable success in computer vision by
leveraging its hierarchical feature representation based on Transformer. In
speech signals, emotional information is distributed across different scales of
speech features, e.\,g., word, phrase, and utterance. Drawing above
inspiration, this paper presents a hierarchical speech Transformer with shifted
windows to aggregate multi-scale emotion features for speech emotion
recognition (SER), called Speech Swin-Transformer. Specifically, we first
divide the speech spectrogram into segment-level patches in the time domain,
composed of multiple frame patches. These segment-level patches are then
encoded using a stack of Swin blocks, in which a local window Transformer is
utilized to explore local inter-frame emotional information across frame
patches of each segment patch. After that, we also design a shifted window
Transformer to compensate for patch correlations near the boundaries of segment
patches. Finally, we employ a patch merging operation to aggregate
segment-level emotional features for hierarchical speech representation by
expanding the receptive field of Transformer from frame-level to segment-level.
Experimental results demonstrate that our proposed Speech Swin-Transformer
outperforms the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10537" title="Abstract">arXiv:2401.10537</a> [<a href="/pdf/2401.10537" title="Download PDF">pdf</a>, <a href="/format/2401.10537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Position-Aware Implicit Neural Network for Real-World Face  Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jianlong Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face inpainting requires the model to have a precise global understanding of
the facial position structure. Benefiting from the powerful capabilities of
deep learning backbones, recent works in face inpainting have achieved decent
performance in ideal setting (square shape with $512px$). However, existing
methods often produce a visually unpleasant result, especially in the
position-sensitive details (e.g., eyes and nose), when directly applied to
arbitrary-shaped images in real-world scenarios. The visually unpleasant
position-sensitive details indicate the shortcomings of existing methods in
terms of position information processing capability. In this paper, we propose
an \textbf{I}mplicit \textbf{N}eural \textbf{I}npainting \textbf{N}etwork
(IN$^2$) to handle arbitrary-shape face images in real-world scenarios by
explicit modeling for position information. Specifically, a downsample
processing encoder is proposed to reduce information loss while obtaining the
global semantic feature. A neighbor hybrid attention block is proposed with a
hybrid attention mechanism to improve the facial understanding ability of the
model without restricting the shape of the input. Finally, an implicit neural
pyramid decoder is introduced to explicitly model position information and
bridge the gap between low-resolution features and high-resolution output.
Extensive experiments demonstrate the superiority of the proposed method in
real-world face inpainting task.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10538" title="Abstract">arXiv:2401.10538</a> [<a href="/pdf/2401.10538" title="Download PDF">pdf</a>, <a href="/ps/2401.10538" title="Download PostScript">ps</a>, <a href="/format/2401.10538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deterministic Simple $(1+\varepsilon)&#x394;$-Edge-Coloring in  Near-Linear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elkin%2C+M">Michael Elkin</a>, 
<a href="/search/cs?searchtype=author&query=Khuzman%2C+A">Ariel Khuzman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the edge-coloring problem in simple $n$-vertex $m$-edge graphs with
maximum degree $\Delta$. This is one of the most classical and fundamental
graph-algorithmic problems. Vizing's celebrated theorem provides
$(\Delta+1)$-edge-coloring in $O(m\cdot n)$ deterministic time. This running
time was improved to $O\left(m\cdot\min\left\{\Delta\cdot\log n,
\sqrt{n}\right\}\right)$. It is also well-known that
$3\left\lceil\frac{\Delta}{2}\right\rceil$-edge-coloring can be computed in
$O(m\cdot\log\Delta)$ time deterministically. Duan et al. devised a randomized
$(1+\varepsilon)\Delta$-edge-coloring algorithm with running time
$O\left(m\cdot\frac{\log^6 n}{\varepsilon^2}\right)$. It was however open if
there exists a deterministic near-linear time algorithm for this basic problem.
We devise a simple deterministic $(1+\varepsilon)\Delta$-edge-coloring
algorithm with running time $O\left(m\cdot\frac{\log n}{\varepsilon}\right)$.
We also devise a randomized $(1+\varepsilon)\Delta$-edge-coloring algorithm
with running time $O(m\cdot(\varepsilon^{-18}+\log(\varepsilon\cdot\Delta)))$.
For $\varepsilon\geq\frac{1}{\log^{1/18}\Delta}$, this running time is
$O(m\cdot\log\Delta)$.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10539" title="Abstract">arXiv:2401.10539</a> [<a href="/pdf/2401.10539" title="Download PDF">pdf</a>, <a href="/format/2401.10539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality-Diversity Algorithms Can Provably Be Helpful for Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+K">Ke Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ren-Jian Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Quality-Diversity (QD) algorithms are a new type of Evolutionary Algorithms
(EAs), aiming to find a set of high-performing, yet diverse solutions. They
have found many successful applications in reinforcement learning and robotics,
helping improve the robustness in complex environments. Furthermore, they often
empirically find a better overall solution than traditional search algorithms
which explicitly search for a single highest-performing solution. However,
their theoretical analysis is far behind, leaving many fundamental questions
unexplored. In this paper, we try to shed some light on the optimization
ability of QD algorithms via rigorous running time analysis. By comparing the
popular QD algorithm MAP-Elites with $(\mu+1)$-EA (a typical EA focusing on
finding better objective values only), we prove that on two NP-hard problem
classes with wide applications, i.e., monotone approximately submodular
maximization with a size constraint, and set cover, MAP-Elites can achieve the
(asymptotically) optimal polynomial-time approximation ratio, while
$(\mu+1)$-EA requires exponential expected time on some instances. This
provides theoretical justification for that QD algorithms can be helpful for
optimization, and discloses that the simultaneous search for high-performing
solutions with diverse behaviors can provide stepping stones to good overall
solutions and help avoid local optima.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10541" title="Abstract">arXiv:2401.10541</a> [<a href="/pdf/2401.10541" title="Download PDF">pdf</a>, <a href="/format/2401.10541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I-SplitEE: Image classification in Split Computing DNNs with Early Exits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bajpai%2C+D+J">Divya Jyoti Bajpai</a>, 
<a href="/search/cs?searchtype=author&query=Jaiswal%2C+A">Aastha Jaiswal</a>, 
<a href="/search/cs?searchtype=author&query=Hanawal%2C+M+K">Manjesh Kumar Hanawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in proceedings of IEEE International Conference on Communications 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The recent advances in Deep Neural Networks (DNNs) stem from their
exceptional performance across various domains. However, their inherent large
size hinders deploying these networks on resource-constrained devices like
edge, mobile, and IoT platforms. Strategies have emerged, from partial cloud
computation offloading (split computing) to integrating early exits within DNN
layers. Our work presents an innovative unified approach merging early exits
and split computing. We determine the 'splitting layer', the optimal depth in
the DNN for edge device computations, and whether to infer on edge device or be
offloaded to the cloud for inference considering accuracy, computational
efficiency, and communication costs. Also, Image classification faces diverse
environmental distortions, influenced by factors like time of day, lighting,
and weather. To adapt to these distortions, we introduce I-SplitEE, an online
unsupervised algorithm ideal for scenarios lacking ground truths and with
sequential data. Experimental validation using Caltech-256 and Cifar-10
datasets subjected to varied distortions showcases I-SplitEE's ability to
reduce costs by a minimum of 55% with marginal performance degradation of at
most 5%.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10544" title="Abstract">arXiv:2401.10544</a> [<a href="/pdf/2401.10544" title="Download PDF">pdf</a>, <a href="/format/2401.10544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AAT: Adapting Audio Transformer for Various Acoustics Recognition Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shaojian Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version for ICASSP 2024, Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently, Transformers have been introduced into the field of acoustics
recognition. They are pre-trained on large-scale datasets using methods such as
supervised learning and semi-supervised learning, demonstrating robust
generality--It fine-tunes easily to downstream tasks and shows more robust
performance. However, the predominant fine-tuning method currently used is
still full fine-tuning, which involves updating all parameters during training.
This not only incurs significant memory usage and time costs but also
compromises the model's generality. Other fine-tuning methods either struggle
to address this issue or fail to achieve matching performance. Therefore, we
conducted a comprehensive analysis of existing fine-tuning methods and proposed
an efficient fine-tuning approach based on Adapter tuning, namely AAT. The core
idea is to freeze the audio Transformer model and insert extra learnable
Adapters, efficiently acquiring downstream task knowledge without compromising
the model's original generality. Extensive experiments have shown that our
method achieves performance comparable to or even superior to full fine-tuning
while optimizing only 7.118% of the parameters. It also demonstrates
superiority over other fine-tuning methods.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10545" title="Abstract">arXiv:2401.10545</a> [<a href="/pdf/2401.10545" title="Download PDF">pdf</a>, <a href="/format/2401.10545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Biases in ChatGPT-based Recommender Systems: Provider  Fairness, Temporal Stability, and Recency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deldjoo%2C+Y">Yashar Deldjoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This study explores the nuanced capabilities and inherent biases of
Recommender Systems using Large Language Models (RecLLMs), with a focus on
ChatGPT-based systems. It studies into the contrasting behaviors of generative
models and traditional collaborative filtering models in movie recommendations.
The research primarily investigates prompt design strategies and their impact
on various aspects of recommendation quality, including accuracy, provider
fairness, diversity, stability, genre dominance, and temporal freshness
(recency).
<br />Our experimental analysis reveals that the introduction of specific 'system
roles' and 'prompt strategies' in RecLLMs significantly influences their
performance. For instance, role-based prompts enhance fairness and diversity in
recommendations, mitigating popularity bias. We find that while GPT-based
models do not always match the performance of CF baselines, they exhibit a
unique tendency to recommend newer and more diverse movie genres. Notably,
GPT-based models tend to recommend more recent films, particularly those
released post-2000, and show a preference for genres like \sq{Drama} and
Comedy, and Romance (compared to CF Action, Adventure) presumably due to the
RecLLMs' training on varied data sets, which allows them to capture recent
trends and discussions more effectively than CF models. Interestingly, our
results demonstrate that the 'Simple' and 'Chain of Thought (COT)' paradigms
yield the highest accuracy. These findings imply the potential of combining
these strategies with scenarios that favor more recent content, thereby
offering a more balanced and up-to-date recommendation experience. This study
contributes significantly to the understanding of emerging RecLLMs,
particularly in the context of harms and biases within these systems.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10546" title="Abstract">arXiv:2401.10546</a> [<a href="/pdf/2401.10546" title="Download PDF">pdf</a>, <a href="/ps/2401.10546" title="Download PostScript">ps</a>, <a href="/format/2401.10546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-order BDF convolution quadrature for stochastic fractional  evolution equations driven by integrated additive noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+M">Minghua Chen</a>, 
<a href="/search/math?searchtype=author&query=Shi%2C+J">Jiankang Shi</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+Z">Zhen Song</a>, 
<a href="/search/math?searchtype=author&query=Yan%2C+Y">Yubin Yan</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Z">Zhi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The numerical analysis of stochastic time fractional evolution equations
presents considerable challenges due to the limited regularity of the model
caused by the nonlocal operator and the presence of noise.
<br />The existing time-stepping methods exhibit a significantly low order
convergence rate. In this work, we introduce a smoothing technique and develop
the novel high-order schemes for solving the linear stochastic fractional
evolution equations driven by integrated additive noise. Our approach involves
regularizing the additive noise through an $m$-fold integral-differential
calculus, and discretizing the equation using the $k$-step BDF convolution
quadrature. This novel method, which we refer to as the ID$m$-BDF$k$ method, is
able to achieve higher-order convergence in solving the stochastic models. Our
theoretical analysis reveals that the convergence rate of the ID$2$-BDF2 method
is $O(\tau^{\alpha + \gamma -1/2})$ for $1&lt; \alpha + \gamma \leq 5/2$, and
$O(\tau^{2})$ for $5/2&lt; \alpha + \gamma &lt;3$, where $\alpha \in (1, 2)$ and
$\gamma \in (0, 1)$ denote the time fractional order and the order of the
integrated noise, respectively. Furthermore, this convergence rate could be
improved to $O(\tau^{\alpha + \gamma -1/2})$ for any $\alpha \in (1, 2)$ and
$\gamma \in (0, 1)$, if we employ the ID$3$-BDF3 method. The argument could be
easily extended to the subdiffusion model with $\alpha \in (0, 1)$. Numerical
examples are provided to support and complement the theoretical findings.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10547" title="Abstract">arXiv:2401.10547</a> [<a href="/pdf/2401.10547" title="Download PDF">pdf</a>, <a href="/format/2401.10547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhoGAD: Graph-based Anomaly Behavior Detection with Persistent Homology  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Ziqi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haoyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">A multitude of toxic online behaviors, ranging from network attacks to
anonymous traffic and spam, have severely disrupted the smooth operation of
networks. Due to the inherent sender-receiver nature of network behaviors,
graph-based frameworks are commonly used for detecting anomalous behaviors.
However, in real-world scenarios, the boundary between normal and anomalous
behaviors tends to be ambiguous. The local heterophily of graphs interferes
with the detection, and existing methods based on nodes or edges introduce
unwanted noise into representation results, thereby impacting the effectiveness
of detection. To address these issues, we propose PhoGAD, a graph-based anomaly
detection framework. PhoGAD leverages persistent homology optimization to
clarify behavioral boundaries. Building upon this, the weights of adjacent
edges are designed to mitigate the effects of local heterophily. Subsequently,
to tackle the noise problem, we conduct a formal analysis and propose a
disentangled representation-based explicit embedding method, ultimately
achieving anomaly behavior detection. Experiments on intrusion, traffic, and
spam datasets verify that PhoGAD has surpassed the performance of
state-of-the-art (SOTA) frameworks in detection efficacy. Notably, PhoGAD
demonstrates robust detection even with diminished anomaly proportions,
highlighting its applicability to real-world scenarios. The analysis of
persistent homology demonstrates its effectiveness in capturing the topological
structure formed by normal edge features. Additionally, ablation experiments
validate the effectiveness of the innovative mechanisms integrated within
PhoGAD.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10549" title="Abstract">arXiv:2401.10549</a> [<a href="/pdf/2401.10549" title="Download PDF">pdf</a>, <a href="/format/2401.10549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified View Imputation and Feature Selection Learning for Incomplete  Multi-view Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yanyong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zongxin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+F">Fengmao Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Although multi-view unsupervised feature selection (MUFS) is an effective
technology for reducing dimensionality in machine learning, existing methods
cannot directly deal with incomplete multi-view data where some samples are
missing in certain views. These methods should first apply predetermined values
to impute missing data, then perform feature selection on the complete dataset.
Separating imputation and feature selection processes fails to capitalize on
the potential synergy where local structural information gleaned from feature
selection could guide the imputation, thereby improving the feature selection
performance in turn. Additionally, previous methods only focus on leveraging
samples' local structure information, while ignoring the intrinsic locality of
the feature space. To tackle these problems, a novel MUFS method, called
UNified view Imputation and Feature selectIon lEaRning (UNIFIER), is proposed.
UNIFIER explores the local structure of multi-view data by adaptively learning
similarity-induced graphs from both the sample and feature spaces. Then,
UNIFIER dynamically recovers the missing views, guided by the sample and
feature similarity graphs during the feature selection procedure. Furthermore,
the half-quadratic minimization technique is used to automatically weight
different instances, alleviating the impact of outliers and unreliable restored
data. Comprehensive experimental results demonstrate that UNIFIER outperforms
other state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10553" title="Abstract">arXiv:2401.10553</a> [<a href="/pdf/2401.10553" title="Download PDF">pdf</a>, <a href="/ps/2401.10553" title="Download PostScript">ps</a>, <a href="/format/2401.10553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-set cubical categories and their formalisation with a proof  assistant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malbos%2C+P">Philippe Malbos</a>, 
<a href="/search/cs?searchtype=author&query=Massacrier%2C+T">Tanguy Massacrier</a>, 
<a href="/search/cs?searchtype=author&query=Struth%2C+G">Georg Struth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)

</div>
<p class="mathjax">We introduce a single-set axiomatisation of cubical $\omega$-categories,
including connections and inverses. We justify these axioms by establishing a
series of equivalences between the category of single-set cubical
$\omega$-categories, and their variants with connections and inverses, and the
corresponding cubical $\omega$-categories. We also report on the formalisation
of cubical $\omega$-categories with the Isabelle/HOL proof assistant, which has
been instrumental in finding the single-set axioms.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10556" title="Abstract">arXiv:2401.10556</a> [<a href="/pdf/2401.10556" title="Download PDF">pdf</a>, <a href="/format/2401.10556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbol as Points: Panoptic Symbol Spotting via Point-based  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenlong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qizhi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">This work studies the problem of panoptic symbol spotting, which is to spot
and parse both countable object instances (windows, doors, tables, etc.) and
uncountable stuff (wall, railing, etc.) from computer-aided design (CAD)
drawings. Existing methods typically involve either rasterizing the vector
graphics into images and using image-based methods for symbol spotting, or
directly building graphs and using graph neural networks for symbol
recognition. In this paper, we take a different approach, which treats graphic
primitives as a set of 2D points that are locally connected and use point cloud
segmentation methods to tackle it. Specifically, we utilize a point transformer
to extract the primitive features and append a mask2former-like spotting head
to predict the final output. To better use the local connection information of
primitives and enhance their discriminability, we further propose the attention
with connection module (ACM) and contrastive connection learning scheme (CCL).
Finally, we propose a KNN interpolation mechanism for the mask attention module
of the spotting head to better handle primitive mask downsampling, which is
primitive-level in contrast to pixel-level for the image. Our approach, named
SymPoint, is simple yet effective, outperforming recent state-of-the-art method
GAT-CADNet by an absolute increase of 9.6% PQ and 10.4% RQ on the FloorPlanCAD
dataset. The source code and models will be available at
https://github.com/nicehuster/SymPoint.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10557" title="Abstract">arXiv:2401.10557</a> [<a href="/pdf/2401.10557" title="Download PDF">pdf</a>, <a href="/format/2401.10557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deep learning initialized iterative method for Navier-Stokes Darcy  model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+J">Jianguo Huang</a>, 
<a href="/search/math?searchtype=author&query=Peng%2C+H">Hui Peng</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+H">Haohao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A deep learning initialized iterative (Int-Deep) method is developed for
numerically solving Navier-Stokes Darcy model. For this purpose, Newton
iterative method is mentioned for solving the relative finite element
discretized problem. It is proved that this method converges quadratically with
the convergence rate independent of the finite element mesh size under certain
standard conditions. Later on, a deep learning algorithm is proposed for
solving this nonlinear coupled problem. Following the ideas of an earlier work
by Huang, Wang and Yang (2020), an Int-Deep algorithm is constructed for the
previous problem in order to further improve the computational efficiency. A
series of numerical examples are reported to confirm that the Int-Deep
algorithm converges to the true solution rapidly and is robust with respect to
the physical parameters in the model.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10559" title="Abstract">arXiv:2401.10559</a> [<a href="/pdf/2401.10559" title="Download PDF">pdf</a>, <a href="/format/2401.10559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OrchMoE: Efficient Multi-Adapter Learning with Task-Skill Synergy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+K">Kaixiang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Cong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">We advance the field of Parameter-Efficient Fine-Tuning (PEFT) with our novel
multi-adapter method, OrchMoE, which capitalizes on modular skill architecture
for enhanced forward transfer in neural networks. Unlike prior models that
depend on explicit task identification inputs, OrchMoE automatically discerns
task categories, streamlining the learning process. This is achieved through an
integrated mechanism comprising an Automatic Task Classification module and a
Task-Skill Allocation module, which collectively deduce task-specific
classifications and tailor skill allocation matrices. Our extensive evaluations
on the 'Super Natural Instructions' dataset, featuring 1,600 diverse
instructional tasks, indicate that OrchMoE substantially outperforms comparable
multi-adapter baselines in terms of both performance and sample utilization
efficiency, all while operating within the same parameter constraints. These
findings suggest that OrchMoE offers a significant leap forward in multi-task
learning efficiency.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10560" title="Abstract">arXiv:2401.10560</a> [<a href="/pdf/2401.10560" title="Download PDF">pdf</a>, <a href="/format/2401.10560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360ORB-SLAM: A Visual SLAM System for Panoramic Images with Depth  Completion Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yichen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yiqi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guodao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianhua Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To enhance the performance and effect of AR/VR applications and visual
assistance and inspection systems, visual simultaneous localization and mapping
(vSLAM) is a fundamental task in computer vision and robotics. However,
traditional vSLAM systems are limited by the camera's narrow field-of-view,
resulting in challenges such as sparse feature distribution and lack of dense
depth information. To overcome these limitations, this paper proposes a
360ORB-SLAM system for panoramic images that combines with a depth completion
network. The system extracts feature points from the panoramic image, utilizes
a panoramic triangulation module to generate sparse depth information, and
employs a depth completion network to obtain a dense panoramic depth map.
Experimental results on our novel panoramic dataset constructed based on Carla
demonstrate that the proposed method achieves superior scale accuracy compared
to existing monocular SLAM methods and effectively addresses the challenges of
feature association and scale ambiguity. The integration of the depth
completion network enhances system stability and mitigates the impact of
dynamic elements on SLAM performance.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10564" title="Abstract">arXiv:2401.10564</a> [<a href="/pdf/2401.10564" title="Download PDF">pdf</a>, <a href="/format/2401.10564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dream360: Diverse and Immersive Outdoor Virtual Scene Creation via  Transformer-Based 360 Image Outpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+H">Hao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zidong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haonan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Tae-Kyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+P">Pan Hui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, accepted to IEEE VR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">360 images, with a field-of-view (FoV) of 180x360, provide immersive and
realistic environments for emerging virtual reality (VR) applications, such as
virtual tourism, where users desire to create diverse panoramic scenes from a
narrow FoV photo they take from a viewpoint via portable devices. It thus
brings us to a technical challenge: `How to allow the users to freely create
diverse and immersive virtual scenes from a narrow FoV image with a specified
viewport?' To this end, we propose a transformer-based 360 image outpainting
framework called Dream360, which can generate diverse, high-fidelity, and
high-resolution panoramas from user-selected viewports, considering the
spherical properties of 360 images. Compared with existing methods, e.g., [3],
which primarily focus on inputs with rectangular masks and central locations
while overlooking the spherical property of 360 images, our Dream360 offers
higher outpainting flexibility and fidelity based on the spherical
representation. Dream360 comprises two key learning stages: (I) codebook-based
panorama outpainting via Spherical-VQGAN (S-VQGAN), and (II) frequency-aware
refinement with a novel frequency-aware consistency loss. Specifically, S-VQGAN
learns a sphere-specific codebook from spherical harmonic (SH) values,
providing a better representation of spherical data distribution for scene
modeling. The frequency-aware refinement matches the resolution and further
improves the semantic consistency and visual fidelity of the generated results.
Our Dream360 achieves significantly lower Frechet Inception Distance (FID)
scores and better visual fidelity than existing methods. We also conducted a
user study involving 15 participants to interactively evaluate the quality of
the generated results in VR, demonstrating the flexibility and superiority of
our Dream360 framework.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10566" title="Abstract">arXiv:2401.10566</a> [<a href="/pdf/2401.10566" title="Download PDF">pdf</a>, <a href="/format/2401.10566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Multi-Modal Density Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%A9sz%C3%A1ros%2C+A">Anna M&#xe9;sz&#xe1;ros</a>, 
<a href="/search/cs?searchtype=author&query=Schumann%2C+J+F">Julian F. Schumann</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>, 
<a href="/search/cs?searchtype=author&query=Zgonnikov%2C+A">Arkady Zgonnikov</a>, 
<a href="/search/cs?searchtype=author&query=Kober%2C+J">Jens Kober</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Development of multi-modal, probabilistic prediction models has lead to a
need for comprehensive evaluation metrics. While several metrics can
characterize the accuracy of machine-learned models (e.g., negative
log-likelihood, Jensen-Shannon divergence), these metrics typically operate on
probability densities. Applying them to purely sample-based prediction models
thus requires that the underlying density function is estimated. However,
common methods such as kernel density estimation (KDE) have been demonstrated
to lack robustness, while more complex methods have not been evaluated in
multi-modal estimation problems. In this paper, we present ROME (RObust
Multi-modal density Estimator), a non-parametric approach for density
estimation which addresses the challenge of estimating multi-modal, non-normal,
and highly correlated distributions. ROME utilizes clustering to segment a
multi-modal set of samples into multiple uni-modal ones and then combines
simple KDE estimates obtained for individual clusters in a single multi-modal
estimate. We compared our approach to state-of-the-art methods for density
estimation as well as ablations of ROME, showing that it not only outperforms
established methods but is also more robust to a variety of distributions. Our
results demonstrate that ROME can overcome the issues of over-fitting and
over-smoothing exhibited by other estimators, promising a more robust
evaluation of probabilistic machine learning models.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10567" title="Abstract">arXiv:2401.10567</a> [<a href="/pdf/2401.10567" title="Download PDF">pdf</a>, <a href="/ps/2401.10567" title="Download PostScript">ps</a>, <a href="/format/2401.10567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-training from Self-memory in Data-to-text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ta%2C+H">Hoang-Thang Ta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper introduces a novel training model, self-training from self-memory
(STSM) in data-to-text generation (DTG), allowing the model to self-train on
subsets, including self-memory as outputs inferred directly from the trained
models and/or the new data. The quality of self-memory is validated by two
models, data-to-text (D2T) and text-to-data (T2D), by two pre-defined
conditions: (1) the appearance of all source values in the outputs of the D2T
model and (2) the ability to convert back to source data in the outputs in the
T2D model. We utilize a greedy algorithm to generate shorter D2T outputs if
they contain all source values. Subsequently, we use the T2D model to confirm
that these outputs can capture input relationships by demonstrating their
capacity to convert text back into data. With 30% of the dataset, we can train
the D2T model with a competitive performance compared to full training in the
same setup. We experiment with our model on two datasets, E2E NLG and DART.
STSM offers the D2T model a generalization capability from its subset memory
while reducing training data volume. Ultimately, we anticipate that this paper
will contribute to continual learning solutions that adapt to new training
data, incorporating it as a form of self-memory in DTG tasks. The curated
dataset is publicly available at: https://github.com/hoangthangta/STSM.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10568" title="Abstract">arXiv:2401.10568</a> [<a href="/pdf/2401.10568" title="Download PDF">pdf</a>, <a href="/format/2401.10568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CivRealm: A Learning and Reasoning Odyssey in Civilization for  Decision-Making Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+S">Siyuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yexin Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangyu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bangcheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+P">Pring Wong</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yifan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The generalization of decision-making agents encompasses two fundamental
elements: learning from past experiences and reasoning in novel contexts.
However, the predominant emphasis in most interactive environments is on
learning, often at the expense of complexity in reasoning. In this paper, we
introduce CivRealm, an environment inspired by the Civilization game.
Civilization's profound alignment with human history and society necessitates
sophisticated learning, while its ever-changing situations demand strong
reasoning to generalize. Particularly, CivRealm sets up an
imperfect-information general-sum game with a changing number of players; it
presents a plethora of complex features, challenging the agent to deal with
open-ended stochastic environments that require diplomacy and negotiation
skills. Within CivRealm, we provide interfaces for two typical agent types:
tensor-based agents that focus on learning, and language-based agents that
emphasize reasoning. To catalyze further research, we present initial results
for both paradigms. The canonical RL-based agents exhibit reasonable
performance in mini-games, whereas both RL- and LLM-based agents struggle to
make substantial progress in the full game. Overall, CivRealm stands as a
unique learning and reasoning challenge for decision-making agents. The code is
available at https://github.com/bigai-ai/civrealm.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10578" title="Abstract">arXiv:2401.10578</a> [<a href="/pdf/2401.10578" title="Download PDF">pdf</a>, <a href="/format/2401.10578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Shape Completion on Unseen Categories:A Weakly-supervised Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lintai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D shapes captured by scanning devices are often incomplete due to occlusion.
3D shape completion methods have been explored to tackle this limitation.
However, most of these methods are only trained and tested on a subset of
categories, resulting in poor generalization to unseen categories. In this
paper, we introduce a novel weakly-supervised framework to reconstruct the
complete shapes from unseen categories. We first propose an end-to-end
prior-assisted shape learning network that leverages data from the seen
categories to infer a coarse shape. Specifically, we construct a prior bank
consisting of representative shapes from the seen categories. Then, we design a
multi-scale pattern correlation module for learning the complete shape of the
input by analyzing the correlation between local patterns within the input and
the priors at various scales. In addition, we propose a self-supervised shape
refinement model to further refine the coarse shape. Considering the shape
variability of 3D objects across categories, we construct a category-specific
prior bank to facilitate shape refinement. Then, we devise a voxel-based
partial matching loss and leverage the partial scans to drive the refinement
process. Extensive experimental results show that our approach is superior to
state-of-the-art methods by a large margin.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10580" title="Abstract">arXiv:2401.10580</a> [<a href="/pdf/2401.10580" title="Download PDF">pdf</a>, <a href="/format/2401.10580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PHOENIX: Open-Source Language Adaption for Direct Preference  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uhlig%2C+M">Matthias Uhlig</a>, 
<a href="/search/cs?searchtype=author&query=Schacht%2C+S">Sigurd Schacht</a>, 
<a href="/search/cs?searchtype=author&query=Barkur%2C+S+K">Sudarshan Kamath Barkur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models have gained immense importance in recent years and have
demonstrated outstanding results in solving various tasks. However, despite
these achievements, many questions remain unanswered in the context of large
language models. Besides the optimal use of the models for inference and the
alignment of the results to the desired specifications, the transfer of models
to other languages is still an underdeveloped area of research. The recent
publication of models such as Llama-2 and Zephyr has provided new insights into
architectural improvements and the use of human feedback. However, insights
into adapting these techniques to other languages remain scarce. In this paper,
we build on latest improvements and apply the Direct Preference
Optimization(DPO) approach to the German language. The model is available at
https://huggingface.co/DRXD1000/Phoenix.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10582" title="Abstract">arXiv:2401.10582</a> [<a href="/pdf/2401.10582" title="Download PDF">pdf</a>, <a href="/format/2401.10582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Kubernetes&#x27; Image Pull Implementation to Deny Node  Availability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knob%2C+L+A+D">Luis Augusto Dias Knob</a>, 
<a href="/search/cs?searchtype=author&query=Franzil%2C+M">Matteo Franzil</a>, 
<a href="/search/cs?searchtype=author&query=Siracusa%2C+D">Domenico Siracusa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Kubernetes (K8s) has grown in popularity over the past few years to become
the de-facto standard for container orchestration in cloud-native environments.
While research is not new to topics such as containerization and access control
security, the Application Programming Interface (API) interactions between K8s
and its runtime interfaces have not been studied thoroughly. In particular, the
CRI-API is responsible for abstracting the container runtime, managing the
creation and lifecycle of containers along with the downloads of the respective
images. However, this decoupling of concerns and the abstraction of the
container runtime renders K8s unaware of the status of the downloading process
of the container images, obstructing the monitoring of the resources allocated
to such process. In this paper, we discuss how this lack of status information
can be exploited as a Denial of Service attack in a K8s cluster. We show that
such attacks can generate up to 95% average CPU usage, prevent downloading new
container images, and increase I/O and network usage for a potentially
unlimited amount of time. Finally, we propose two possible mitigation
strategies: one, implemented as a stopgap solution, and another, requiring more
radical architectural changes in the relationship between K8s and the CRI-API.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10584" title="Abstract">arXiv:2401.10584</a> [<a href="/pdf/2401.10584" title="Download PDF">pdf</a>, <a href="/ps/2401.10584" title="Download PostScript">ps</a>, <a href="/format/2401.10584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast winning strategies for the attacker in eternal domination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bagan%2C+G">Guillaume Bagan</a>, 
<a href="/search/cs?searchtype=author&query=Bousquet%2C+N">Nicolas Bousquet</a>, 
<a href="/search/cs?searchtype=author&query=Oijid%2C+N">Nacim Oijid</a>, 
<a href="/search/cs?searchtype=author&query=Pierron%2C+T">Th&#xe9;o Pierron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Dominating sets in graphs are often used to model some monitoring of the
graph: guards are posted on the vertices of the dominating set, and they can
thus react to attacks occurring on the unguarded vertices by moving there
(yielding a new set of guards, which may not be dominating anymore). A
dominating set is eternal if it can endlessly resist to attacks. From the
attacker's perspective, if we are given a non-eternal dominating set, the
question is to determine how fast can we provoke an attack that cannot be
handled by a neighboring guard. We investigate this question from a
computational complexity point of view, by showing that this question is
PSPACE-hard, even for graph classes where finding a minimum eternal dominating
set is in P. We then complement this result by giving polynomial time
algorithms for cographs and trees, and showing a connection with tree-depth for
the latter. We also investigate the problem from a parameterized complexity
perspective, mainly considering two parameters: the number of guards and the
number of steps.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10586" title="Abstract">arXiv:2401.10586</a> [<a href="/pdf/2401.10586" title="Download PDF">pdf</a>, <a href="/format/2401.10586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PuriDefense: Randomized Local Implicit Adversarial Purification for  Defending Black-box Query-based Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Ping Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qingchuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingfu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Black-box query-based attacks constitute significant threats to Machine
Learning as a Service (MLaaS) systems since they can generate adversarial
examples without accessing the target model's architecture and parameters.
Traditional defense mechanisms, such as adversarial training, gradient masking,
and input transformations, either impose substantial computational costs or
compromise the test accuracy of non-adversarial inputs. To address these
challenges, we propose an efficient defense mechanism, PuriDefense, that
employs random patch-wise purifications with an ensemble of lightweight
purification models at a low level of inference cost. These models leverage the
local implicit function and rebuild the natural image manifold. Our theoretical
analysis suggests that this approach slows down the convergence of query-based
attacks by incorporating randomness into purifications. Extensive experiments
on CIFAR-10 and ImageNet validate the effectiveness of our proposed
purifier-based defense mechanism, demonstrating significant improvements in
robustness against query-based attacks.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10588" title="Abstract">arXiv:2401.10588</a> [<a href="/pdf/2401.10588" title="Download PDF">pdf</a>, <a href="/format/2401.10588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGL: Dynamic Global-Local Prompt Tuning for Text-Video Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiangpeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Linchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024, Code will be available at <a href="https://github.com/knightyxp/DGL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-video retrieval is a critical multi-modal task to find the most relevant
video for a text query. Although pretrained models like CLIP have demonstrated
impressive potential in this area, the rising cost of fully finetuning these
models due to increasing model size continues to pose a problem. To address
this challenge, prompt tuning has emerged as an alternative. However, existing
works still face two problems when adapting pretrained image-text models to
downstream video-text tasks: (1) The visual encoder could only encode
frame-level features and failed to extract global-level general video
information. (2) Equipping the visual and text encoder with separated prompts
failed to mitigate the visual-text modality gap. To this end, we propose DGL, a
cross-modal Dynamic prompt tuning method with Global-Local video attention. In
contrast to previous prompt tuning methods, we employ the shared latent space
to generate local-level text and frame prompts that encourage inter-modal
interaction. Furthermore, we propose modeling video in a global-local attention
mechanism to capture global video information from the perspective of prompt
tuning. Extensive experiments reveal that when only 0.67% parameters are tuned,
our cross-modal prompt tuning strategy DGL outperforms or is comparable to
fully finetuning methods on MSR-VTT, VATEX, LSMDC, and ActivityNet datasets.
Code will be available at https://github.com/knightyxp/DGL
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10589" title="Abstract">arXiv:2401.10589</a> [<a href="/pdf/2401.10589" title="Download PDF">pdf</a>, <a href="/format/2401.10589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Soft Conflict Pseudo Boolean Constraint on MaxSAT Local  Search Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jiongzhi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chu-Min Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kun He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">MaxSAT is an optimization version of the famous NP-complete Satisfiability
problem (SAT). Algorithms for MaxSAT mainly include complete solvers and local
search incomplete solvers. In many complete solvers, once a better solution is
found, a Soft conflict Pseudo Boolean (SPB) constraint will be generated to
enforce the algorithm to find better solutions. In many local search
algorithms, clause weighting is a key technique for effectively guiding the
search directions. In this paper, we propose to transfer the SPB constraint
into the clause weighting system of the local search method, leading the
algorithm to better solutions. We further propose an adaptive clause weighting
strategy that breaks the tradition of using constant values to adjust clause
weights. Based on the above methods, we propose a new local search algorithm
called SPB-MaxSAT that provides new perspectives for clause weighting on MaxSAT
local search solvers. Extensive experiments demonstrate the excellent
performance of the proposed methods.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10590" title="Abstract">arXiv:2401.10590</a> [<a href="/pdf/2401.10590" title="Download PDF">pdf</a>, <a href="/format/2401.10590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarially Robust Signed Graph Contrastive Learning from Balance  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jialong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+X">Xing Ai</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yuni Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kai Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Signed graphs consist of edges and signs, which can be separated into
structural information and balance-related information, respectively. Existing
signed graph neural networks (SGNNs) typically rely on balance-related
information to generate embeddings. Nevertheless, the emergence of recent
adversarial attacks has had a detrimental impact on the balance-related
information. Similar to how structure learning can restore unsigned graphs,
balance learning can be applied to signed graphs by improving the balance
degree of the poisoned graph. However, this approach encounters the challenge
"Irreversibility of Balance-related Information" - while the balance degree
improves, the restored edges may not be the ones originally affected by
attacks, resulting in poor defense effectiveness. To address this challenge, we
propose a robust SGNN framework called Balance Augmented-Signed Graph
Contrastive Learning (BA-SGCL), which combines Graph Contrastive Learning
principles with balance augmentation techniques. Experimental results
demonstrate that BA-SGCL not only enhances robustness against existing
adversarial attacks but also achieves superior performance on link sign
prediction task across various datasets.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10601" title="Abstract">arXiv:2401.10601</a> [<a href="/pdf/2401.10601" title="Download PDF">pdf</a>, <a href="/format/2401.10601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influential Slot and Tag Selection in Billboard Advertisement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+D">Dildar Ali</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+T">Tejash Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Suman Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+Y">Yamuna Prasad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB)

</div>
<p class="mathjax">The selection of influential billboard slots remains an important problem in
billboard advertisements. Existing studies on this problem have not considered
the case of context-specific influence probability. To bridge this gap, in this
paper, we introduce the Context Dependent Influential Billboard Slot Selection
Problem. First, we show that the problem is NP-hard. We also show that the
influence function holds the bi-monotonicity, bi-submodularity, and
non-negativity properties. We propose an orthant-wise Stochastic Greedy
approach to solve this problem. We show that this method leads to a constant
factor approximation guarantee. Subsequently, we propose an orthant-wise
Incremental and Lazy Greedy approach. In a generic sense, this is a method for
maximizing a bi-submodular function under the cardinality constraint, which may
also be of independent interest. We analyze the performance guarantee of this
algorithm as well as time and space complexity. The proposed solution
approaches have been implemented with real-world billboard and trajectory
datasets. We compare the performance of our method with many baseline methods,
and the results are reported. Our proposed orthant-wise stochastic greedy
approach leads to significant results when the parameters are set properly with
reasonable computational overhead.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10603" title="Abstract">arXiv:2401.10603</a> [<a href="/pdf/2401.10603" title="Download PDF">pdf</a>, <a href="/format/2401.10603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZnTrack -- Data as Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zills%2C+F">Fabian Zills</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fer%2C+M">Moritz Sch&#xe4;fer</a>, 
<a href="/search/cs?searchtype=author&query=Tovey%2C+S">Samuel Tovey</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4stner%2C+J">Johannes K&#xe4;stner</a>, 
<a href="/search/cs?searchtype=author&query=Holm%2C+C">Christian Holm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures, 2MB PDF
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The past decade has seen tremendous breakthroughs in computation and there is
no indication that this will slow any time soon. Machine learning, large-scale
computing resources, and increased industry focus have resulted in rising
investments in computer-driven solutions for data management, simulations, and
model generation. However, with this growth in computation has come an even
larger expansion of data and with it, complexity in data storage, sharing, and
tracking. In this work, we introduce ZnTrack, a Python-driven data versioning
tool. ZnTrack builds upon established version control systems to provide a
user-friendly and easy-to-use interface for tracking parameters in experiments,
designing workflows, and storing and sharing data. From this ability to reduce
large datasets to a simple Python script emerges the concept of Data as Code, a
core component of the work presented here and an undoubtedly important concept
as the age of computation continues to evolve. ZnTrack offers an open-source,
FAIR data compatible Python package to enable users to harness these concepts
of the future.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10607" title="Abstract">arXiv:2401.10607</a> [<a href="/pdf/2401.10607" title="Download PDF">pdf</a>, <a href="/format/2401.10607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use of topical and temporal profiles and their hybridisation for  content-based recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Campos%2C+L+M">Luis M. de Campos</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Luna%2C+J+M">Juan M. Fern&#xe1;ndez-Luna</a>, 
<a href="/search/cs?searchtype=author&query=Huete%2C+J+F">Juan F. Huete</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In the context of content-based recommender systems, the aim of this paper is
to determine how better profiles can be built and how these affect the
recommendation process based on the incorporation of temporality, i.e. the
inclusion of time in the recommendation process, and topicality, i.e. the
representation of texts associated with users and items using topics and their
combination. The main contribution of the paper is to present two different
ways of hybridising these two dimensions and to evaluate and compare them with
other alternatives.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10608" title="Abstract">arXiv:2401.10608</a> [<a href="/pdf/2401.10608" title="Download PDF">pdf</a>, <a href="/format/2401.10608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M2ORT: Many-To-One Regression Transformer for Spatial Transcriptomics  Prediction from Histopathology Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiuju Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+S">Shuyi Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yen-Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lanfen Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">The advancement of Spatial Transcriptomics (ST) has facilitated the
spatially-aware profiling of gene expressions based on histopathology images.
Although ST data offers valuable insights into the micro-environment of tumors,
its acquisition cost remains expensive. Therefore, directly predicting the ST
expressions from digital pathology images is desired. Current methods usually
adopt existing regression backbones for this task, which ignore the inherent
multi-scale hierarchical data structure of digital pathology images. To address
this limit, we propose M2ORT, a many-to-one regression Transformer that can
accommodate the hierarchical structure of the pathology images through a
decoupled multi-scale feature extractor. Different from traditional models that
are trained with one-to-one image-label pairs, M2ORT accepts multiple pathology
images of different magnifications at a time to jointly predict the gene
expressions at their corresponding common ST spot, aiming at learning a
many-to-one relationship through training. We have tested M2ORT on three public
ST datasets and the experimental results show that M2ORT can achieve
state-of-the-art performance with fewer parameters and floating-point
operations (FLOPs). The code is available at:
https://github.com/Dootmaan/M2ORT/.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10611" title="Abstract">arXiv:2401.10611</a> [<a href="/pdf/2401.10611" title="Download PDF">pdf</a>, <a href="/format/2401.10611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Publication venue recommendation using profiles based on clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Campos%2C+L+M">Luis M. de Campos</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Luna%2C+J+M">Juan M. Fern&#xe1;ndez-Luna</a>, 
<a href="/search/cs?searchtype=author&query=Huete%2C+J+F">Juan F. Huete</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In this paper we study the venue recommendation problem in order to help
researchers to identify a journal or conference to submit a given paper. A
common approach to tackle this problem is to build profiles defining the scope
of each venue. Then, these profiles are compared against the target paper. In
our approach we will study how clustering techniques can be used to construct
topic-based profiles and use an Information Retrieval based approach to obtain
the final recommendations. Additionally, we will explore how the use of
authorship, representing a complementary piece of information, helps to improve
the recommendations.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10614" title="Abstract">arXiv:2401.10614</a> [<a href="/pdf/2401.10614" title="Download PDF">pdf</a>, <a href="/ps/2401.10614" title="Download PostScript">ps</a>, <a href="/format/2401.10614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-Oriented Multiple Access Connectivity for Networked Intelligent  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agheli%2C+P">Pouya Agheli</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>, 
<a href="/search/cs?searchtype=author&query=Kountouris%2C+M">Marios Kountouris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">We design a self-decision goal-oriented multiple access scheme, where sensing
agents observe a common event and individually decide to communicate the
event's attributes to the monitoring agents, to satisfy a certain goal.
Decisions are based on the usefulness of contents, which are generated under
uniform, change- and semantics-aware content acquisition, as well as statistics
and contents of other agents. We obtain optimal activation probabilities and
threshold criteria for decision-making under all schemes, maximizing a grade of
effectiveness metric. Combined with a semantics-aware acquisition scheme, the
self-decision scheme offers, on average, 29.52% higher effectiveness, 25.13%
fewer drop-offs, and 67.21% fewer transmissions.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10617" title="Abstract">arXiv:2401.10617</a> [<a href="/pdf/2401.10617" title="Download PDF">pdf</a>, <a href="/format/2401.10617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LDA-based Term Profiles for Expert Finding in a Political Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Campos%2C+L+M">Luis M. de Campos</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Luna%2C+J+M">Juan M. Fern&#xe1;ndez-Luna</a>, 
<a href="/search/cs?searchtype=author&query=Huete%2C+J+F">Juan F. Huete</a>, 
<a href="/search/cs?searchtype=author&query=Redondo-Exp%C3%B3sito%2C+L">Luis Redondo-Exp&#xf3;sito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">A common task in many political institutions (i.e. Parliament) is to find
politicians who are experts in a particular field. In order to tackle this
problem, the first step is to obtain politician profiles which include their
interests, and these can be automatically learned from their speeches. As a
politician may have various areas of expertise, one alternative is to use a set
of subprofiles, each of which covers a different subject. In this study, we
propose a novel approach for this task by using latent Dirichlet allocation
(LDA) to determine the main underlying topics of each political speech, and to
distribute the related terms among the different topic-based subprofiles. With
this objective, we propose the use of fifteen distance and similarity measures
to automatically determine the optimal number of topics discussed in a
document, and to demonstrate that every measure converges into five strategies:
Euclidean, Dice, Sorensen, Cosine and Overlap. Our experimental results showed
that the scores of the different accuracy metrics of the proposed strategies
tended to be higher than those of the baselines for expert recommendation
tasks, and that the use of an appropriate number of topics has proved relevant.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10619" title="Abstract">arXiv:2401.10619</a> [<a href="/pdf/2401.10619" title="Download PDF">pdf</a>, <a href="/format/2401.10619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A model-based framework for controlling activated sludge plants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Neto%2C+O+B+L">Otacilio B. L. Neto</a>, 
<a href="/search/eess?searchtype=author&query=Mulas%2C+M">Michela Mulas</a>, 
<a href="/search/eess?searchtype=author&query=Corona%2C+F">Francesco Corona</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 31 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This work presents a general framework for the advanced control of a common
class of activated sludge plants (ASPs). Based on a dynamic model of the
process and plant sensors and actuators, we design and configure a highly
customisable Output Model-Predictive Controller (Output MPC) for the flexible
operation of ASPs as water resource recovery facilities. The controller
consists of a i) Moving-Horizon Estimator for determining the state of the
process, from plant measurements, and ii) a Model-Predictive Controller for
determining the optimal actions to attain high-level operational goals. The
Output MPC can be configured to satisfy the technological limits of the plant
equipment, as well as operational desiderata defined by plant personnel. We
consider exemplary problems and show that the framework is able to control ASPs
for tasks of practical relevance, ranging from wastewater treatment subject to
normative limits, to the production of an effluent with varying nitrogen
content, and energy recovery.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10620" title="Abstract">arXiv:2401.10620</a> [<a href="/pdf/2401.10620" title="Download PDF">pdf</a>, <a href="/format/2401.10620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polytopic Autoencoders with Smooth Clustering for Reduced-order  Modelling of Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heiland%2C+J">Jan Heiland</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yongho Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Dynamical Systems (math.DS)

</div>
<p class="mathjax">With the advancement of neural networks, there has been a notable increase,
both in terms of quantity and variety, in research publications concerning the
application of autoencoders to reduced-order models. We propose a polytopic
autoencoder architecture that includes a lightweight nonlinear encoder, a
convex combination decoder, and a smooth clustering network. Supported by
several proofs, the model architecture ensures that all reconstructed states
lie within a polytope, accompanied by a metric indicating the quality of the
constructed polytopes, referred to as polytope error. Additionally, it offers a
minimal number of convex coordinates for polytopic linear-parameter varying
systems while achieving acceptable reconstruction errors compared to proper
orthogonal decomposition (POD). To validate our proposed model, we conduct
simulations involving two flow scenarios with the incompressible Navier-Stokes
equation. Numerical results demonstrate the guaranteed properties of the model,
low reconstruction errors compared to POD, and the improvement in error using a
clustering network.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10627" title="Abstract">arXiv:2401.10627</a> [<a href="/pdf/2401.10627" title="Download PDF">pdf</a>, <a href="/format/2401.10627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Key to Kindness: Reducing Toxicity In Online Discourse Through Proactive  Content Moderation in a Mobile Keyboard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warner%2C+M">Mark Warner</a>, 
<a href="/search/cs?searchtype=author&query=Strohmayer%2C+A">Angelika Strohmayer</a>, 
<a href="/search/cs?searchtype=author&query=Higgs%2C+M">Matthew Higgs</a>, 
<a href="/search/cs?searchtype=author&query=Rafiq%2C+H">Husnain Rafiq</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liying Yang</a>, 
<a href="/search/cs?searchtype=author&query=Coventry%2C+L">Lynne Coventry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Growing evidence shows that proactive content moderation supported by AI can
help improve online discourse. However, we know little about designing these
systems, how design impacts efficacy and user experience, and how people
perceive proactive moderation across public and private platforms. We developed
a mobile keyboard with built-in proactive content moderation which we tested
(N=575) within a semi-functional simulation of a public and private
communication platform. Where toxic content was detected, we used different
interventions that embedded three design factors: timing, friction, and the
presentation of the AI model output. We found moderation to be effective,
regardless of the design. However, friction was a source of annoyance while
prompts with no friction that occurred during typing were more effective.
Follow-up interviews highlight the differences in how these systems are
perceived across public and private platforms, and how they can offer more than
moderation by acting as educational and communication support tools.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10629" title="Abstract">arXiv:2401.10629</a> [<a href="/pdf/2401.10629" title="Download PDF">pdf</a>, <a href="/ps/2401.10629" title="Download PostScript">ps</a>, <a href="/format/2401.10629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Critical Reflection on the Use of Toxicity Detection Algorithms in  Proactive Content Moderation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warner%2C+M">Mark Warner</a>, 
<a href="/search/cs?searchtype=author&query=Strohmayer%2C+A">Angelika Strohmayer</a>, 
<a href="/search/cs?searchtype=author&query=Higgs%2C+M">Matthew Higgs</a>, 
<a href="/search/cs?searchtype=author&query=Coventry%2C+L">Lynne Coventry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Toxicity detection algorithms, originally designed with reactive content
moderation in mind, are increasingly being deployed into proactive end-user
interventions to moderate content. Through a socio-technical lens and focusing
on contexts in which they are applied, we explore the use of these algorithms
in proactive moderation systems. Placing a toxicity detection algorithm in an
imagined virtual mobile keyboard, we critically explore how such algorithms
could be used to proactively reduce the sending of toxic content. We present
findings from design workshops conducted with four distinct stakeholder groups
and find concerns around how contextual complexities may exasperate
inequalities around content moderation processes. Whilst only specific user
groups are likely to directly benefit from these interventions, we highlight
the potential for other groups to misuse them to circumvent detection, validate
and gamify hate, and manipulate algorithmic models to exasperate harm.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10632" title="Abstract">arXiv:2401.10632</a> [<a href="/pdf/2401.10632" title="Download PDF">pdf</a>, <a href="/format/2401.10632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interventional Fairness on Partially Known Causal Graphs: A Constrained  Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+A">Aoqi Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Susan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Mingming Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Fair machine learning aims to prevent discrimination against individuals or
sub-populations based on sensitive attributes such as gender and race. In
recent years, causal inference methods have been increasingly used in fair
machine learning to measure unfairness by causal effects. However, current
methods assume that the true causal graph is given, which is often not true in
real-world applications. To address this limitation, this paper proposes a
framework for achieving causal fairness based on the notion of interventions
when the true causal graph is partially known. The proposed approach involves
modeling fair prediction using a Partially Directed Acyclic Graph (PDAG),
specifically, a class of causal DAGs that can be learned from observational
data combined with domain knowledge. The PDAG is used to measure causal
fairness, and a constrained optimization problem is formulated to balance
between fairness and accuracy. Results on both simulated and real-world
datasets demonstrate the effectiveness of this method.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10634" title="Abstract">arXiv:2401.10634</a> [<a href="/pdf/2401.10634" title="Download PDF">pdf</a>, <a href="/format/2401.10634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Construction of Multi-faceted User Profiles using Text  Clustering and its Application to Expert Recommendation and Filtering  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Campos%2C+L+M">Luis M. de Campos</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Luna%2C+J+M">Juan M. Fern&#xe1;ndez-Luna</a>, 
<a href="/search/cs?searchtype=author&query=Huete%2C+J+F">Juan F. Huete</a>, 
<a href="/search/cs?searchtype=author&query=Redondo-Exp%C3%B3sito%2C+L">Luis Redondo-Exp&#xf3;sito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In the information age we are living in today, not only are we interested in
accessing multimedia objects such as documents, videos, etc. but also in
searching for professional experts, people or celebrities, possibly for
professional needs or just for fun. Information access systems need to be able
to extract and exploit various sources of information (usually in text format)
about such individuals, and to represent them in a suitable way usually in the
form of a profile. In this article, we tackle the problems of profile-based
expert recommendation and document filtering from a machine learning
perspective by clustering expert textual sources to build profiles and capture
the different hidden topics in which the experts are interested. The experts
will then be represented by means of multi-faceted profiles. Our experiments
show that this is a valid technique to improve the performance of expert
finding and document filtering.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10636" title="Abstract">arXiv:2401.10636</a> [<a href="/pdf/2401.10636" title="Download PDF">pdf</a>, <a href="/format/2401.10636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catch the Butterfly: Peeking into the Terms and Conflicts among SPDX  Licenses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gaofei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuqing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, accepted by SANER2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The widespread adoption of third-party libraries (TPLs) in software
development has accelerated the creation of modern software. However, this
convenience comes with potential legal risks. Developers may inadvertently
violate the licenses of TPLs, leading to legal issues. While existing studies
have explored software licenses and potential incompatibilities, these studies
often focus on a limited set of licenses or rely on low-quality license data,
which may affect their conclusions. To address this gap, there is a need for a
high-quality license dataset that encompasses a broad range of mainstream
licenses to help developers navigate the complex landscape of software
licenses, avoid potential legal pitfalls, and guide solutions for managing
license compliance and compatibility in software development. To this end, we
conduct the first work to understand the mainstream software licenses based on
term granularity and obtain a high-quality dataset of 453 SPDX licenses with
well-labeled terms and conflicts. Specifically, we first conduct a differential
analysis of the mainstream platforms to understand the terms and attitudes of
each license. Next, we propose a standardized set of license terms to capture
and label existing mainstream licenses with high quality. Moreover, we include
copyleft conflicts and conclude the three major types of license conflicts
among the 453 SPDX licenses. Based on these, we carry out two empirical studies
to reveal the concerns and threats from the perspectives of both licensors and
licensees. One study provides an in-depth analysis of the similarities,
differences, and conflicts among SPDX licenses, revisits the usage and
conflicts of licenses in the NPM ecosystem, and draws conclusions that differ
from previous work. Our studies reveal some insightful findings and disclose
relevant analytical data, which set the stage for further research.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10638" title="Abstract">arXiv:2401.10638</a> [<a href="/pdf/2401.10638" title="Download PDF">pdf</a>, <a href="/ps/2401.10638" title="Download PostScript">ps</a>, <a href="/format/2401.10638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurately Computing Expected Visiting Times and Stationary  Distributions in Markov Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mertens%2C+H">Hannah Mertens</a>, 
<a href="/search/cs?searchtype=author&query=Katoen%2C+J">Joost-Pieter Katoen</a>, 
<a href="/search/cs?searchtype=author&query=Quatmann%2C+T">Tim Quatmann</a>, 
<a href="/search/cs?searchtype=author&query=Winkler%2C+T">Tobias Winkler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Probability (math.PR)

</div>
<p class="mathjax">We study the accurate and efficient computation of the expected number of
times each state is visited in discrete- and continuous-time Markov chains. To
obtain sound accuracy guarantees efficiently, we lift interval iteration and
topological approaches known from the computation of reachability probabilities
and expected rewards. We further study applications of expected visiting times,
including the sound computation of the stationary distribution and expected
rewards conditioned on reaching multiple goal states. The implementation of our
methods in the probabilistic model checker Storm scales to large systems with
millions of states. Our experiments on the quantitative verification benchmark
set show that the computation of stationary distributions via expected visiting
times consistently outperforms existing approaches - sometimes by several
orders of magnitude.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10640" title="Abstract">arXiv:2401.10640</a> [<a href="/pdf/2401.10640" title="Download PDF">pdf</a>, <a href="/format/2401.10640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comprehensive study on fidelity metrics for XAI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mir%C3%B3-Nicolau%2C+M">Miquel Mir&#xf3;-Nicolau</a>, 
<a href="/search/cs?searchtype=author&query=Jaume-i-Cap%C3%B3%2C+A">Antoni Jaume-i-Cap&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Moy%C3%A0-Alcover%2C+G">Gabriel Moy&#xe0;-Alcover</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The use of eXplainable Artificial Intelligence (XAI) systems has introduced a
set of challenges that need resolution. Herein, we focus on how to correctly
select an XAI method, an open questions within the field. The inherent
difficulty of this task is due to the lack of a ground truth. Several authors
have proposed metrics to approximate the fidelity of different XAI methods.
These metrics lack verification and have concerning disagreements. In this
study, we proposed a novel methodology to verify fidelity metrics, using a
well-known transparent model, namely a decision tree. This model allowed us to
obtain explanations with perfect fidelity. Our proposal constitutes the first
objective benchmark for these metrics, facilitating a comparison of existing
proposals, and surpassing existing methods. We applied our benchmark to assess
the existing fidelity metrics in two different experiments, each using public
datasets comprising 52,000 images. The images from these datasets had a size a
128 by 128 pixels and were synthetic data that simplified the training process.
All metric values, indicated a lack of fidelity, with the best one showing a 30
\% deviation from the expected values for perfect explanation. Our
experimentation led us to conclude that the current fidelity metrics are not
reliable enough to be used in real scenarios. From this finding, we deemed it
necessary to development new metrics, to avoid the detected problems, and we
recommend the usage of our proposal as a benchmark within the scientific
community to address these limitations.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10641" title="Abstract">arXiv:2401.10641</a> [<a href="/pdf/2401.10641" title="Download PDF">pdf</a>, <a href="/format/2401.10641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Effective Index for Truss-based Community Search on Large Directed  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wei Ai</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">CanHao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+T">Tao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yinghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">KeQin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Community search is a derivative of community detection that enables online
and personalized discovery of communities and has found extensive applications
in massive real-world networks. Recently, there needs to be more focus on the
community search issue within directed graphs, even though substantial research
has been carried out on undirected graphs. The recently proposed D-truss model
has achieved good results in the quality of retrieved communities. However,
existing D-truss-based work cannot perform efficient community searches on
large graphs because it consumes too many computing resources to retrieve the
maximal D-truss. To overcome this issue, we introduce an innovative merge
relation known as D-truss-connected to capture the inherent density and
cohesiveness of edges within D-truss. This relation allows us to partition all
the edges in the original graph into a series of D-truss-connected classes.
Then, we construct a concise and compact index, ConDTruss, based on
D-truss-connected. Using ConDTruss, the efficiency of maximum D-truss retrieval
will be greatly improved, making it a theoretically optimal approach.
Experimental evaluations conducted on large directed graph certificate the
effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10642" title="Abstract">arXiv:2401.10642</a> [<a href="/pdf/2401.10642" title="Download PDF">pdf</a>, <a href="/format/2401.10642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Butterfly-Core Community Search For Large Labeled Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+J">JiaYi Du</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yinghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wei Ai</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+T">Tao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">CanHao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">KeQin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Community Search (CS) aims to identify densely interconnected subgraphs
corresponding to query vertices within a graph. However, existing heterogeneous
graph-based community search methods need help identifying cross-group
communities and suffer from efficiency issues, making them unsuitable for large
graphs. This paper presents a fast community search model based on the
Butterfly-Core Community (BCC) structure for heterogeneous graphs. The Random
Walk with Restart (RWR) algorithm and butterfly degree comprehensively evaluate
the importance of vertices within communities, allowing leader vertices to be
rapidly updated to maintain cross-group cohesion. Moreover, we devised a more
efficient method for updating vertex distances, which minimizes vertex visits
and enhances operational efficiency. Extensive experiments on several
real-world temporal graphs demonstrate the effectiveness and efficiency of this
solution.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10643" title="Abstract">arXiv:2401.10643</a> [<a href="/pdf/2401.10643" title="Download PDF">pdf</a>, <a href="/ps/2401.10643" title="Download PostScript">ps</a>, <a href="/format/2401.10643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey on Deep-Learning-based Vehicle Re-Identification:  Models, Data Sets and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amiri%2C+A">Ali Amiri</a>, 
<a href="/search/cs?searchtype=author&query=Kaya%2C+A">Aydin Kaya</a>, 
<a href="/search/cs?searchtype=author&query=Keceli%2C+A+S">Ali Seydi Keceli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Vehicle re-identification (ReID) endeavors to associate vehicle images
collected from a distributed network of cameras spanning diverse traffic
environments. This task assumes paramount importance within the spectrum of
vehicle-centric technologies, playing a pivotal role in deploying Intelligent
Transportation Systems (ITS) and advancing smart city initiatives. Rapid
advancements in deep learning have significantly propelled the evolution of
vehicle ReID technologies in recent years. Consequently, undertaking a
comprehensive survey of methodologies centered on deep learning for vehicle
re-identification has become imperative and inescapable. This paper extensively
explores deep learning techniques applied to vehicle ReID. It outlines the
categorization of these methods, encompassing supervised and unsupervised
approaches, delves into existing research within these categories, introduces
datasets and evaluation criteria, and delineates forthcoming challenges and
potential research directions. This comprehensive assessment examines the
landscape of deep learning in vehicle ReID and establishes a foundation and
starting point for future works. It aims to serve as a complete reference by
highlighting challenges and emerging trends, fostering advancements and
applications in vehicle ReID utilizing deep learning models.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10646" title="Abstract">arXiv:2401.10646</a> [<a href="/pdf/2401.10646" title="Download PDF">pdf</a>, <a href="/format/2401.10646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering HWNs with Efficient Data Labeling: A Clustered Federated  Semi-Supervised Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamood%2C+M">Moqbel Hamood</a>, 
<a href="/search/cs?searchtype=author&query=Albaseer%2C+A">Abdullatif Albaseer</a>, 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+M">Mohamed Abdallah</a>, 
<a href="/search/cs?searchtype=author&query=Al-Fuqaha%2C+A">Ala Al-Fuqaha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for IEEE Wireless Communications and Networking Conference (WCNC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Clustered Federated Multitask Learning (CFL) has gained considerable
attention as an effective strategy for overcoming statistical challenges,
particularly when dealing with non independent and identically distributed (non
IID) data across multiple users. However, much of the existing research on CFL
operates under the unrealistic premise that devices have access to accurate
ground truth labels. This assumption becomes especially problematic in
hierarchical wireless networks (HWNs), where edge networks contain a large
amount of unlabeled data, resulting in slower convergence rates and increased
processing times, particularly when dealing with two layers of model
aggregation. To address these issues, we introduce a novel framework, Clustered
Federated Semi-Supervised Learning (CFSL), designed for more realistic HWN
scenarios. Our approach leverages a best-performing specialized model
algorithm, wherein each device is assigned a specialized model that is highly
adept at generating accurate pseudo-labels for unlabeled data, even when the
data stems from diverse environments. We validate the efficacy of CFSL through
extensive experiments, comparing it with existing methods highlighted in recent
literature. Our numerical results demonstrate that CFSL significantly improves
upon key metrics such as testing accuracy, labeling accuracy, and labeling
latency under varying proportions of labeled and unlabeled data while also
accommodating the non-IID nature of the data and the unique characteristics of
wireless edge networks.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10647" title="Abstract">arXiv:2401.10647</a> [<a href="/pdf/2401.10647" title="Download PDF">pdf</a>, <a href="/format/2401.10647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hazra%2C+R">Rima Hazra</a>, 
<a href="/search/cs?searchtype=author&query=Layek%2C+S">Sayan Layek</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Somnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Poria%2C+S">Soujanya Poria</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the rapidly advancing field of artificial intelligence, the concept of
Red-Teaming or Jailbreaking large language models (LLMs) has emerged as a
crucial area of study. This approach is especially significant in terms of
assessing and enhancing the safety and robustness of these models. This paper
investigates the intricate consequences of such modifications through model
editing, uncovering a complex relationship between enhancing model accuracy and
preserving its ethical integrity. Our in-depth analysis reveals a striking
paradox: while injecting accurate information is crucial for model reliability,
it can paradoxically destabilize the model's foundational framework, resulting
in unpredictable and potentially unsafe behaviors. Additionally, we propose a
benchmark dataset NicheHazardQA to investigate this unsafe behavior both within
the same and cross topical domain. This aspect of our research sheds light on
how the edits, impact the model's safety metrics and guardrails. Our findings
show that model editing serves as a cost-effective tool for topical red-teaming
by methodically applying targeted edits and evaluating the resultant model
behavior
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10648" title="Abstract">arXiv:2401.10648</a> [<a href="/pdf/2401.10648" title="Download PDF">pdf</a>, <a href="/format/2401.10648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Area Modeling using Stay Information for Large-Scale Users and Analysis  for Influence of COVID-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shoji%2C+K">Kazuyuki Shoji</a>, 
<a href="/search/cs?searchtype=author&query=Aoki%2C+S">Shunsuke Aoki</a>, 
<a href="/search/cs?searchtype=author&query=Yonezawa%2C+T">Takuro Yonezawa</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+N">Nobuo Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is an English translation of the paper published in the Transactions of the Information Processing Society of Japan (<a href="http://doi.org/10.20729/00213190">this http URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Understanding how people use area in a city can be a valuable information in
a wide range of fields, from marketing to urban planning. Area usage is subject
to change over time due to various events including seasonal shifts and
pandemics. Before the spread of smartphones, this data had been collected
through questionnaire survey. However, this is not a sustainable approach in
terms of time to results and cost. There are many existing studies on area
modeling, which characterize an area with some kind of information, using Point
of Interest (POI) or inter-area movement data. However, since POI is data that
is statically tied to space, and inter-area movement data ignores the behavior
of people within an area, existing methods are not sufficient in terms of
capturing area usage changes. In this paper, we propose a novel area modeling
method named Area2Vec, inspired by Word2Vec, which models areas based on
people's location data. This method is based on the discovery that it is
possible to characterize an area based on its usage by using people's stay
information in the area. And it is a novel method that can reflect the
dynamically changing people's behavior in an area in the modeling results. We
validated Area2vec by performing a functional classification of areas in a
district of Japan. The results show that Area2Vec can be usable in general area
analysis. We also investigated area usage changes due to COVID-19 in two
districts in Japan. We could find that COVID-19 made people refrain from
unnecessary going out, such as visiting entertainment areas.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10652" title="Abstract">arXiv:2401.10652</a> [<a href="/pdf/2401.10652" title="Download PDF">pdf</a>, <a href="/format/2401.10652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoChunk: Automated Activation Chunk for Memory-Efficient Long Sequence  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuanlei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shenggan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guangyang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiarui Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haotian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+B">Bin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziming Liu</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large deep learning models have achieved impressive performance across a
range of applications. However, their large memory requirements, including
parameter memory and activation memory, have become a significant challenge for
their practical serving. While existing methods mainly address parameter
memory, the importance of activation memory has been overlooked. Especially for
long input sequences, activation memory is expected to experience a significant
exponential growth as the length of sequences increases. In this approach, we
propose AutoChunk, an automatic and adaptive compiler system that efficiently
reduces activation memory for long sequence inference by chunk strategies. The
proposed system generates chunk plans by optimizing through multiple stages. In
each stage, the chunk search pass explores all possible chunk candidates and
the chunk selection pass identifies the optimal one. At runtime, AutoChunk
employs code generation to automatically apply chunk strategies. The
experiments demonstrate that AutoChunk can reduce over 80\% of activation
memory while maintaining speed loss within 10%, extend max sequence length by
3.2x to 11.7x, and outperform state-of-the-art methods by a large margin.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10653" title="Abstract">arXiv:2401.10653</a> [<a href="/pdf/2401.10653" title="Download PDF">pdf</a>, <a href="/format/2401.10653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attentive Fusion: A Transformer-based Approach to Multimodal Hate Speech  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandal%2C+A">Atanu Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+G">Gargi Roy</a>, 
<a href="/search/cs?searchtype=author&query=Barman%2C+A">Amit Barman</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+I">Indranil Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Naskar%2C+S+K">Sudip Kumar Naskar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in 20th International Conference on Natural Language Processing (ICON)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
<p class="mathjax">With the recent surge and exponential growth of social media usage,
scrutinizing social media content for the presence of any hateful content is of
utmost importance. Researchers have been diligently working since the past
decade on distinguishing between content that promotes hatred and content that
does not. Traditionally, the main focus has been on analyzing textual content.
However, recent research attempts have also commenced into the identification
of audio-based content. Nevertheless, studies have shown that relying solely on
audio or text-based content may be ineffective, as recent upsurge indicates
that individuals often employ sarcasm in their speech and writing. To overcome
these challenges, we present an approach to identify whether a speech promotes
hate or not utilizing both audio and textual representations. Our methodology
is based on the Transformer framework that incorporates both audio and text
sampling, accompanied by our very own layer called "Attentive Fusion". The
results of our study surpassed previous state-of-the-art techniques, achieving
an impressive macro F1 score of 0.927 on the Test Set.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10657" title="Abstract">arXiv:2401.10657</a> [<a href="/pdf/2401.10657" title="Download PDF">pdf</a>, <a href="/format/2401.10657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIMBA: Evaluating the Robustness of AI in Genomics via Feature  Importance Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skovorodnikov%2C+H">Heorhii Skovorodnikov</a>, 
<a href="/search/cs?searchtype=author&query=Alkhzaimi%2C+H">Hoda Alkhzaimi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, core code available at: <a href="https://github.com/HeorhiiS/fimba-attack">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Genomics (q-bio.GN)

</div>
<p class="mathjax">With the steady rise of the use of AI in bio-technical applications and the
widespread adoption of genomics sequencing, an increasing amount of AI-based
algorithms and tools is entering the research and production stage affecting
critical decision-making streams like drug discovery and clinical outcomes.
This paper demonstrates the vulnerability of AI models often utilized
downstream tasks on recognized public genomics datasets. We undermine model
robustness by deploying an attack that focuses on input transformation while
mimicking the real data and confusing the model decision-making, ultimately
yielding a pronounced deterioration in model performance. Further, we enhance
our approach by generating poisoned data using a variational autoencoder-based
model. Our empirical findings unequivocally demonstrate a decline in model
performance, underscored by diminished accuracy and an upswing in false
positives and false negatives. Furthermore, we analyze the resulting
adversarial samples via spectral analysis yielding conclusions for
countermeasures against such attacks.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10659" title="Abstract">arXiv:2401.10659</a> [<a href="/pdf/2401.10659" title="Download PDF">pdf</a>, <a href="/format/2401.10659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BadODD: Bangladeshi Autonomous Driving Object Detection Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baig%2C+M+N">Mirza Nihal Baig</a>, 
<a href="/search/cs?searchtype=author&query=Hajong%2C+R">Rony Hajong</a>, 
<a href="/search/cs?searchtype=author&query=Patwary%2C+M+M">Mahdi Murshed Patwary</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+S">Mohammad Shahidur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+H+A">Husne Ara Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a comprehensive dataset for object detection in diverse driving
environments across 9 districts in Bangladesh. The dataset, collected
exclusively from smartphone cameras, provided a realistic representation of
real-world scenarios, including day and night conditions. Most existing
datasets lack suitable classes for autonomous navigation on Bangladeshi roads,
making it challenging for researchers to develop models that can handle the
intricacies of road scenarios. To address this issue, the authors proposed a
new set of classes based on characteristics rather than local vehicle names.
The dataset aims to encourage the development of models that can handle the
unique challenges of Bangladeshi road scenarios for the effective deployment of
autonomous vehicles. The dataset did not consist of any online images to
simulate real-world conditions faced by autonomous vehicles. The classification
of vehicles is challenging because of the diverse range of vehicles on
Bangladeshi roads, including those not found elsewhere in the world. The
proposed classification system is scalable and can accommodate future vehicles,
making it a valuable resource for researchers in the autonomous vehicle sector.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10660" title="Abstract">arXiv:2401.10660</a> [<a href="/pdf/2401.10660" title="Download PDF">pdf</a>, <a href="/format/2401.10660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Framework to Accelerate Multilingual Language Model for  Monolingual Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jimin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gibbeum Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jaewoong Cho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in large language models have facilitated the execution
of complex language tasks, not only in English but also in non-English
languages. However, the tokenizers of most language models, such as Llama,
trained on English-centric corpora, tend to excessively fragment tokens in
non-English languages. This issue is especially pronounced in non-roman
alphabetic languages, which are often divided at a character or even Unicode
level, leading to slower text generation. To address this, our study introduces
a novel framework designed to expedite text generation in these languages. This
framework predicts larger linguistic units than those of conventional
multilingual tokenizers and is specifically tailored to the target language,
thereby reducing the number of decoding steps required. Our empirical results
demonstrate that the proposed framework increases the generation speed by a
factor of 1.9 compared to standard decoding while maintaining the performance
of a pre-trained multilingual model on monolingual tasks.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10662" title="Abstract">arXiv:2401.10662</a> [<a href="/pdf/2401.10662" title="Download PDF">pdf</a>, <a href="/format/2401.10662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-hydrostatic mesoscale atmospheric modeling by the anisotropic mesh  adaptive discontinuous Galerkin method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dolejsi%2C+V">Vit Dolejsi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We deal with non-hydrostatic mesoscale atmospheric modeling using the fully
implicit space-time discontinuous Galerkin method in combination with the
anisotropic $hp$-mesh adaptation technique. The time discontinuous
approximation allows the treatment of different meshes at different time levels
in a natural way which can significantly reduce the number of degrees of
freedom. The presented approach generates a sequence of triangular meshes
consisting of possible anisotropic elements and varying polynomial
approximation degrees such that the interpolation error is below the given
tolerance and the number of degrees of freedom at each time step is minimal. We
describe the discretization of the problem together with several implementation
issues related to the treatment of boundary conditions, algebraic solver and
adaptive choice of the size of the time steps.The computational performance of
the proposed method is demonstrated on several benchmark problems.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10664" title="Abstract">arXiv:2401.10664</a> [<a href="/pdf/2401.10664" title="Download PDF">pdf</a>, <a href="/format/2401.10664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PTPsec: Securing the Precision Time Protocol Against Time Delay Attacks  Using Cyclic Path Asymmetry Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Finkenzeller%2C+A">Andreas Finkenzeller</a>, 
<a href="/search/cs?searchtype=author&query=Butowski%2C+O">Oliver Butowski</a>, 
<a href="/search/cs?searchtype=author&query=Regnath%2C+E">Emanuel Regnath</a>, 
<a href="/search/cs?searchtype=author&query=Hamad%2C+M">Mohammad Hamad</a>, 
<a href="/search/cs?searchtype=author&query=Steinhorst%2C+S">Sebastian Steinhorst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at INFOCOM24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">High-precision time synchronization is a vital prerequisite for many modern
applications and technologies, including Smart Grids, Time-Sensitive Networking
(TSN), and 5G networks. Although the Precision Time Protocol (PTP) can
accomplish this requirement in trusted environments, it becomes unreliable in
the presence of specific cyber attacks. Mainly, time delay attacks pose the
highest threat to the protocol, enabling attackers to diverge targeted clocks
undetected. With the increasing danger of cyber attacks, especially against
critical infrastructure, there is a great demand for effective countermeasures
to secure both time synchronization and the applications that depend on it.
However, current solutions are not sufficiently capable of mitigating
sophisticated delay attacks. For example, they lack proper integration into the
PTP protocol, scalability, or sound evaluation with the required
microsecond-level accuracy. This work proposes an approach to detect and
counteract delay attacks against PTP based on cyclic path asymmetry
measurements over redundant paths. For that, we provide a method to find
redundant paths in arbitrary networks and show how this redundancy can be
exploited to reveal and mitigate undesirable asymmetries on the synchronization
path that cause the malicious clock divergence. Furthermore, we propose PTPsec,
a secure PTP protocol and its implementation based on the latest IEEE 1588-2019
standard. With PTPsec, we advance the conventional PTP to support reliable
delay attack detection and mitigation. We validate our approach on a hardware
testbed, which includes an attacker capable of performing static and
incremental delay attacks at a microsecond precision. Our experimental results
show that all attack scenarios can be reliably detected and mitigated with
minimal detection time.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10666" title="Abstract">arXiv:2401.10666</a> [<a href="/pdf/2401.10666" title="Download PDF">pdf</a>, <a href="/format/2401.10666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixNet: Towards Effective and Efficient UHD Low-Light Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhuoran Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiuyi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Wenqi Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the continuous advancement of imaging devices, the prevalence of
Ultra-High-Definition (UHD) images is rising. Although many image restoration
methods have achieved promising results, they are not directly applicable to
UHD images on devices with limited computational resources due to the
inherently high computational complexity of UHD images. In this paper, we focus
on the task of low-light image enhancement (LLIE) and propose a novel LLIE
method called MixNet, which is designed explicitly for UHD images. To capture
the long-range dependency of features without introducing excessive
computational complexity, we present the Global Feature Modulation Layer
(GFML). GFML associates features from different views by permuting the feature
maps, enabling efficient modeling of long-range dependency. In addition, we
also design the Local Feature Modulation Layer (LFML) and Feed-forward Layer
(FFL) to capture local features and transform features into a compact
representation. This way, our MixNet achieves effective LLIE with few model
parameters and low computational complexity. We conducted extensive experiments
on both synthetic and real-world datasets, and the comprehensive results
demonstrate that our proposed method surpasses the performance of current
state-of-the-art methods. The code will be available at
\url{https://github.com/zzr-idam/MixNet}.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10669" title="Abstract">arXiv:2401.10669</a> [<a href="/pdf/2401.10669" title="Download PDF">pdf</a>, <a href="/format/2401.10669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Room With an Overview: Towards Meaningful Transparency for the  Consumer Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Norval%2C+C">Chris Norval</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Jatinder Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear: C. Norval and J. Singh, "A Room With an Overview: Towards Meaningful Transparency for the Consumer Internet of Things," in IEEE Internet of Things Journal. DOI: 10.1109/JIOT.2023.3318369
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">As our physical environments become ever-more connected, instrumented and
automated, it can be increasingly difficult for users to understand what is
happening within them and why. This warrants attention; with the pervasive and
physical nature of the IoT comes risks of data misuse, privacy, surveillance,
and even physical harm. Such concerns come amid increasing calls for more
transparency surrounding technologies (in general), as a means for supporting
scrutiny and accountability.
<br />This paper explores the practical dimensions to transparency mechanisms
within the consumer IoT. That is, we consider how smart homes might be made
more meaningfully transparent, so as to support users in gaining greater
understanding, oversight, and control. Through a series of three user-centric
studies, we (i) survey prospective smart home users to gain a general
understanding of what meaningful transparency within smart homes might entail;
(ii) identify categories of user-derived requirements and design elements
(design features for supporting smart home transparency) that have been created
through two co-design workshops; and (iii) validate these through an evaluation
with an altogether new set of participants. In all, these categories of
requirements and interface design elements provide a foundation for
understanding how meaningful transparency might be achieved within smart homes,
and introduces several wider considerations for doing so.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10670" title="Abstract">arXiv:2401.10670</a> [<a href="/pdf/2401.10670" title="Download PDF">pdf</a>, <a href="/format/2401.10670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time synchronization for deterministic communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atiq%2C+M+K">Mahin K. Atiq</a>, 
<a href="/search/cs?searchtype=author&query=Muzaffar%2C+R">Raheeb Muzaffar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Deterministic communication is required for applications of several industry
verticals including manufacturing, automotive, financial, and health care, etc.
These applications rely on reliable and time-synchronized delivery of
information among the communicating devices. Therefore, large delay variations
in packet delivery or inaccuracies in time synchronization cannot be tolerated.
In particular, the industrial revolution on digitization, connectivity of
digital and physical systems, and flexible production design require
deterministic and time-synchronized communication. A network supporting
deterministic communication guarantees data delivery in a specified time with
high reliability. The IEEE 802.1 TSN task group is developing standards to
provide deterministic communication through IEEE 802 networks. The IEEE 802.1AS
standard defines time synchronization mechanism for accurate distribution of
time among the communicating devices. The time synchronization accuracy depends
on the accurate calculation of the residence time which is the time between the
ingress and the egress ports of the bridge and includes the processing,
queuing, transmission, and link latency of the timing information. This paper
discusses time synchronization mechanisms supported in current wired and
wireless integrated systems.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10674" title="Abstract">arXiv:2401.10674</a> [<a href="/pdf/2401.10674" title="Download PDF">pdf</a>, <a href="/format/2401.10674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based Embedded Intrusion Detection System for Automotive  CAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+S">Shashwat Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Wadhwa%2C+E">Eashan Wadhwa</a>, 
<a href="/search/cs?searchtype=author&query=Shanker%2C+S">Shreejith Shanker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, 8 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE 33rd International Conference on Application-specific
  Systems, Architectures and Processors (ASAP), Gothenburg, Sweden, 2022, pp.
  88-92
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Rising complexity of in-vehicle electronics is enabling new capabilities like
autonomous driving and active safety. However, rising automation also increases
risk of security threats which is compounded by lack of in-built security
measures in legacy networks like CAN, allowing attackers to observe, tamper and
modify information shared over such broadcast networks. Various intrusion
detection approaches have been proposed to detect and tackle such threats, with
machine learning models proving highly effective. However, deploying machine
learning models will require high processing power through high-end processors
or GPUs to perform them close to line rate. In this paper, we propose a hybrid
FPGA-based ECU approach that can transparently integrate IDS functionality
through a dedicated off-the-shelf hardware accelerator that implements a
deep-CNN intrusion detection model. Our results show that the proposed approach
provides an average accuracy of over 99% across multiple attack datasets with
0.64% false detection rates while consuming 94% less energy and achieving 51.8%
reduction in per-message processing latency when compared to IDS
implementations on GPUs.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10681" title="Abstract">arXiv:2401.10681</a> [<a href="/pdf/2401.10681" title="Download PDF">pdf</a>, <a href="/format/2401.10681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximizing Real-Time Video QoE via Bandwidth Sharing under Markovian  setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=George%2C+S+A">Sushi Anna George</a>, 
<a href="/search/cs?searchtype=author&query=Joseph%2C+V">Vinay Joseph</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2211.06666">arXiv:2211.06666</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We consider the problem of optimizing Quality of Experience (QoE) of clients
streaming real-time video, served by networks managed by different operators
that can share bandwidth with each other. The abundance of real-time video
traffic is evident in the popularity of applications like video conferencing
and video streaming of live events, which have increased significantly since
the recent pandemic. We model the problem as a joint optimization of resource
allocation for the clients and bandwidth sharing across the operators, with
special attention to how the resource allocation impacts clients' perceived
video quality. We propose an online policy as a solution, which involves
dynamically sharing a portion of one operator's bandwidth with another
operator. We provide strong theoretical optimality guarantees for the policy.
We also use extensive simulations to demonstrate the policy's substantial
performance improvements (of up to ninety percent), and identify insights into
key system parameters (e.g., imbalance in arrival rates or channel conditions
of the operators) that dictate the improvements.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10685" title="Abstract">arXiv:2401.10685</a> [<a href="/pdf/2401.10685" title="Download PDF">pdf</a>, <a href="/format/2401.10685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards End-to-End GPS Localization with Neural Pseudorange Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+X">Xu Weng</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+K">KV Ling</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haochen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+K">Kun Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Pseudorange errors are the root cause of localization inaccuracy in GPS.
Previous data-driven methods regress and eliminate pseudorange errors using
handcrafted intermediate labels. Unlike them, we propose an end-to-end GPS
localization framework, E2E-PrNet, to train a neural network for pseudorange
correction (PrNet) directly using the final task loss calculated with the
ground truth of GPS receiver states. The gradients of the loss with respect to
learnable parameters are backpropagated through a differentiable nonlinear
least squares optimizer to PrNet. The feasibility is verified with GPS data
collected by Android phones, showing that E2E-PrNet outperforms the
state-of-the-art end-to-end GPS localization methods.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10686" title="Abstract">arXiv:2401.10686</a> [<a href="/pdf/2401.10686" title="Download PDF">pdf</a>, <a href="/format/2401.10686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manipulating Sparse Double Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y+S">Ya Shi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper investigates the double descent phenomenon in two-layer neural
networks, focusing on the role of L1 regularization and representation
dimensions. It explores an alternative double descent phenomenon, named sparse
double descent. The study emphasizes the complex relationship between model
complexity, sparsity, and generalization, and suggests further research into
more diverse models and datasets. The findings contribute to a deeper
understanding of neural network training and optimization.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10688" title="Abstract">arXiv:2401.10688</a> [<a href="/pdf/2401.10688" title="Download PDF">pdf</a>, <a href="/ps/2401.10688" title="Download PostScript">ps</a>, <a href="/format/2401.10688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling codes: fast, robust, beyond-bound error correction for DRAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamburg%2C+M">Mike Hamburg</a>, 
<a href="/search/cs?searchtype=author&query=Linstadt%2C+E">Eric Linstadt</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+D">Danny Moore</a>, 
<a href="/search/cs?searchtype=author&query=Vogelsang%2C+T">Thomas Vogelsang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ISCA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Generalized Reed-Solomon (RS) codes are a common choice for efficient,
reliable error correction in memory and communications systems. These codes add
$2t$ extra parity symbols to a block of memory, and can efficiently and
reliably correct up to $t$ symbol errors in that block. Decoding is possible
beyond this bound, but it is imperfectly reliable and often computationally
expensive. Beyond-bound decoding is an important problem to solve for
error-correcting Dynamic Random Access Memory (DRAM). These memories are often
designed so that each access touches two extra memory devices, so that a
failure in any one device can be corrected. But system architectures
increasingly require DRAM to store metadata in addition to user data. When the
metadata replaces parity data, a single-device failure is then beyond-bound. An
error-correction system can either protect each access with a single RS code,
or divide it into several segments protected with a shorter code, usually in an
Interleaved Reed-Solomon (IRS) configuration. The full-block RS approach is
more reliable, both at correcting errors and at preventing silent data
corruption (SDC). The IRS option is faster, and is especially efficient at
beyond-bound correction of single- or double-device failures. Here we describe
a new family of "unraveling" Reed-Solomon codes that bridges the gap between
these options. Our codes are full-block generalized RS codes, but they can also
be decoded using an IRS decoder. As a result, they combine the speed and
beyond-bound correction capabilities of interleaved codes with the robustness
of full-block codes, including the ability of the latter to reliably correct
failures across multiple devices. We show that unraveling codes are an
especially good fit for high-reliability DRAM error correction.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10689" title="Abstract">arXiv:2401.10689</a> [<a href="/pdf/2401.10689" title="Download PDF">pdf</a>, <a href="/format/2401.10689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight Multi-Attack CAN Intrusion Detection System on Hybrid  FPGAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+S">Shashwat Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Shanker%2C+S">Shreejith Shanker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 6 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 32nd International Conference on Field-Programmable Logic and
  Applications (FPL) FPL 2022, 425-429
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Rising connectivity in vehicles is enabling new capabilities like connected
autonomous driving and advanced driver assistance systems (ADAS) for improving
the safety and reliability of next-generation vehicles. This increased access
to in-vehicle functions compromises critical capabilities that use legacy
invehicle networks like Controller Area Network (CAN), which has no inherent
security or authentication mechanism. Intrusion detection and mitigation
approaches, particularly using machine learning models, have shown promising
results in detecting multiple attack vectors in CAN through their ability to
generalise to new vectors. However, most deployments require dedicated
computing units like GPUs to perform line-rate detection, consuming much higher
power. In this paper, we present a lightweight multi-attack quantised machine
learning model that is deployed using Xilinx's Deep Learning Processing Unit IP
on a Zynq Ultrascale+ (XCZU3EG) FPGA, which is trained and validated using the
public CAN Intrusion Detection dataset. The quantised model detects denial of
service and fuzzing attacks with an accuracy of above 99 % and a false positive
rate of 0.07%, which are comparable to the state-of-the-art techniques in the
literature. The Intrusion Detection System (IDS) execution consumes just 2.0 W
with software tasks running on the ECU and achieves a 25 % reduction in
per-message processing latency over the state-of-the-art implementations. This
deployment allows the ECU function to coexist with the IDS with minimal changes
to the tasks, making it ideal for real-time IDS in in-vehicle systems.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10690" title="Abstract">arXiv:2401.10690</a> [<a href="/pdf/2401.10690" title="Download PDF">pdf</a>, <a href="/format/2401.10690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and  unfairness in dyadic regression models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paz-Ruza%2C+J">Jorge Paz-Ruza</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Betanzos%2C+A">Amparo Alonso-Betanzos</a>, 
<a href="/search/cs?searchtype=author&query=Guijarro-Berdi%C3%B1as%2C+B">Bertha Guijarro-Berdi&#xf1;as</a>, 
<a href="/search/cs?searchtype=author&query=Cancela%2C+B">Brais Cancela</a>, 
<a href="/search/cs?searchtype=author&query=Eiras-Franco%2C+C">Carlos Eiras-Franco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Dyadic regression models, which predict real-valued outcomes for pairs of
entities, are fundamental in many domains (e.g. predicting the rating of a user
to a product in Recommender Systems) and promising and under exploration in
many others (e.g. approximating the adequate dosage of a drug for a patient in
personalized pharmacology). In this work, we demonstrate that non-uniformity in
the observed value distributions of individual entities leads to severely
biased predictions in state-of-the-art models, skewing predictions towards the
average of observed past values for the entity and providing worse-than-random
predictive power in eccentric yet equally important cases. We show that the
usage of global error metrics like Root Mean Squared Error (RMSE) and Mean
Absolute Error (MAE) is insufficient to capture this phenomenon, which we name
eccentricity bias, and we introduce Eccentricity-Area Under the Curve (EAUC) as
a new complementary metric that can quantify it in all studied models and
datasets. We also prove the adequateness of EAUC by using naive de-biasing
corrections to demonstrate that a lower model bias correlates with a lower EAUC
and vice-versa. This work contributes a bias-aware evaluation of dyadic
regression models to avoid potential unfairness and risks in critical
real-world applications of such systems.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10691" title="Abstract">arXiv:2401.10691</a> [<a href="/pdf/2401.10691" title="Download PDF">pdf</a>, <a href="/format/2401.10691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable and Transferable Adversarial Attack for ML-Based Network  Intrusion Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hangsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongqi Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinlong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+S">Shangyuan Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiqiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jinsong Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">espite being widely used in network intrusion detection systems (NIDSs),
machine learning (ML) has proven to be highly vulnerable to adversarial
attacks. White-box and black-box adversarial attacks of NIDS have been explored
in several studies. However, white-box attacks unrealistically assume that the
attackers have full knowledge of the target NIDSs. Meanwhile, existing
black-box attacks can not achieve high attack success rate due to the weak
adversarial transferability between models (e.g., neural networks and tree
models). Additionally, neither of them explains why adversarial examples exist
and why they can transfer across models. To address these challenges, this
paper introduces ETA, an Explainable Transfer-based Black-Box Adversarial
Attack framework. ETA aims to achieve two primary objectives: 1) create
transferable adversarial examples applicable to various ML models and 2)
provide insights into the existence of adversarial examples and their
transferability within NIDSs. Specifically, we first provide a general
transfer-based adversarial attack method applicable across the entire ML space.
Following that, we exploit a unique insight based on cooperative game theory
and perturbation interpretations to explain adversarial examples and
adversarial transferability. On this basis, we propose an Important-Sensitive
Feature Selection (ISFS) method to guide the search for adversarial examples,
achieving stronger transferability and ensuring traffic-space constraints.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10695" title="Abstract">arXiv:2401.10695</a> [<a href="/pdf/2401.10695" title="Download PDF">pdf</a>, <a href="/format/2401.10695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LangBridge: Multilingual Reasoning Without Multilingual Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+D">Dongkeun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Joel Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungdong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungone Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shafayat%2C+S">Sheikh Shafayat</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minjoon Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce LangBridge, a zero-shot approach to adapt language models for
multilingual reasoning tasks without multilingual supervision. LangBridge
operates by bridging two models, each specialized in different aspects: (1) one
specialized in understanding multiple languages (e.g., mT5 encoder) and (2) one
specialized in reasoning (e.g., Orca 2). LangBridge connects the two models by
introducing minimal trainable parameters between them. Despite utilizing only
English data for training, LangBridge considerably enhances the performance of
language models on low-resource languages across mathematical reasoning,
coding, and logical reasoning. Our analysis suggests that the efficacy of
LangBridge stems from the language-agnostic characteristics of multilingual
representations. We publicly release our code and models.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10699" title="Abstract">arXiv:2401.10699</a> [<a href="/pdf/2401.10699" title="Download PDF">pdf</a>, <a href="/ps/2401.10699" title="Download PostScript">ps</a>, <a href="/format/2401.10699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Expertise in Configurable Software Systems through the Maze  of Variability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milano%2C+K">Karolina Milano</a>, 
<a href="/search/cs?searchtype=author&query=Cafeo%2C+B">Bruno Cafeo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to be published in the Proceedings of the 31st International Conference on Software Analysis, Evolution, and Reengineering (SANER'24) - ERA Track, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The understanding of source code in large-scale software systems poses a
challenge for developers. The role of expertise in source code becomes critical
for identifying developers accountable for substantial changes. However, in the
context of configurable software systems (CSS) using pre-processing and
conditional compilation, conventional expertise metrics may encounter
limitations due to the non-alignment of variability implementation with the
natural module structure. This early research study investigates the
distribution of development efforts in CSS, specifically focusing on variable
and mandatory code. It also examines the engagement of designated experts with
variable code in their assigned files. The findings provide insights into task
allocation dynamics and raise questions about the applicability of existing
metrics, laying the groundwork for alternative approaches to assess developer
expertise in handling variable code. This research aims to contribute to a
comprehensive understanding of challenges within CSS, marking initial steps
toward advancing the evaluation of expertise in this context.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10700" title="Abstract">arXiv:2401.10700</a> [<a href="/pdf/2401.10700" title="Download PDF">pdf</a>, <a href="/format/2401.10700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yinan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dongjie Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xianyuan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingjing Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024, 30pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Safe offline RL is a promising way to bypass risky online interactions
towards safe policy learning. Most existing methods only enforce soft
constraints, i.e., constraining safety violations in expectation below
thresholds predetermined. This can lead to potentially unsafe outcomes, thus
unacceptable in safety-critical scenarios. An alternative is to enforce the
hard constraint of zero violation. However, this can be challenging in offline
setting, as it needs to strike the right balance among three highly intricate
and correlated aspects: safety constraint satisfaction, reward maximization,
and behavior regularization imposed by offline datasets. Interestingly, we
discover that via reachability analysis of safe-control theory, the hard safety
constraint can be equivalently translated to identifying the largest feasible
region given the offline dataset. This seamlessly converts the original trilogy
problem to a feasibility-dependent objective, i.e., maximizing reward value
within the feasible region while minimizing safety risks in the infeasible
region. Inspired by these, we propose FISOR (FeasIbility-guided Safe Offline
RL), which allows safety constraint adherence, reward maximization, and offline
policy learning to be realized via three decoupled processes, while offering
strong safety performance and stability. In FISOR, the optimal policy for the
translated optimization problem can be derived in a special form of weighted
behavior cloning. Thus, we propose a novel energy-guided diffusion model that
does not require training a complicated time-dependent classifier to extract
the policy, greatly simplifying the training. We compare FISOR against
baselines on DSRL benchmark for safe offline RL. Evaluation results show that
FISOR is the only method that can guarantee safety satisfaction in all tasks,
while achieving top returns in most tasks.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10702" title="Abstract">arXiv:2401.10702</a> [<a href="/pdf/2401.10702" title="Download PDF">pdf</a>, <a href="/format/2401.10702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G.O.G: A Versatile Gripper-On-Gripper Design for Bimanual Cloth  Manipulation with a Single Robotic Arm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongmyoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoshuai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rojas%2C+N">Nicolas Rojas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for IEEE Robotics and Automation Letters in January 2024. Dongmyoung Lee and Wei Chen contributed equally to this research
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The manipulation of garments poses research challenges due to their
deformable nature and the extensive variability in shapes and sizes. Despite
numerous attempts by researchers to address these via approaches involving
robot perception and control, there has been a relatively limited interest in
resolving it through the co-development of robot hardware. Consequently, the
majority of studies employ off-the-shelf grippers in conjunction with dual
robot arms to enable bimanual manipulation and high dexterity. However, this
dual-arm system increases the overall cost of the robotic system as well as its
control complexity in order to tackle robot collisions and other robot
coordination issues. As an alternative approach, we propose to enable bimanual
cloth manipulation using a single robot arm via novel end effector design --
sharing dexterity skills between manipulator and gripper rather than relying
entirely on robot arm coordination. To this end, we introduce a new gripper,
called G.O.G., based on a gripper-on-gripper structure where the first gripper
independently regulates the span, up to 500mm, between its fingers which are in
turn also grippers. These finger grippers consist of a variable friction module
that enables two grasping modes: firm and sliding grasps. Household item and
cloth object benchmarks are employed to evaluate the performance of the
proposed design, encompassing both experiments on the gripper design itself and
on cloth manipulation. Experimental results demonstrate the potential of the
introduced ideas to undertake a range of bimanual cloth manipulation tasks with
a single robot arm. Supplementary material is available at
https://sites.google.com/view/gripperongripper.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10703" title="Abstract">arXiv:2401.10703</a> [<a href="/pdf/2401.10703" title="Download PDF">pdf</a>, <a href="/format/2401.10703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRAT Proofs of Unsatisfiability for SAT Modulo Monotonic Theories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+N">Nick Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+A+J">Alan J. Hu</a>, 
<a href="/search/cs?searchtype=author&query=Bayless%2C+S">Sam Bayless</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+S+M">Syed M. Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Trentin%2C+P">Patrick Trentin</a>, 
<a href="/search/cs?searchtype=author&query=Whalen%2C+M">Mike Whalen</a>, 
<a href="/search/cs?searchtype=author&query=Pike%2C+L">Lee Pike</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+J">John Backes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Generating proofs of unsatisfiability is a valuable capability of most SAT
solvers, and is an active area of research for SMT solvers. This paper
introduces the first method to efficiently generate proofs of unsatisfiability
specifically for an important subset of SMT: SAT Modulo Monotonic Theories
(SMMT), which includes many useful finite-domain theories (e.g., bit vectors
and many graph-theoretic properties) and is used in production at Amazon Web
Services. Our method uses propositional definitions of the theory predicates,
from which it generates compact Horn approximations of the definitions, which
lead to efficient DRAT proofs, leveraging the large investment the SAT
community has made in DRAT. In experiments on practical SMMT problems, our
proof generation overhead is minimal (7.41% geometric mean slowdown, 28.8%
worst-case), and we can generate and check proofs for many problems that were
previously intractable.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10708" title="Abstract">arXiv:2401.10708</a> [<a href="/pdf/2401.10708" title="Download PDF">pdf</a>, <a href="/format/2401.10708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demonstration of Cooperative Transport Interface using open-source 5G  OpenRAN and virtualised PON network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slyne%2C+F">Frank Slyne</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+K+O">Kevin O Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Dzaferagic%2C+M">Merim Dzaferagic</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+B">Bruce Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Wrzeszcz%2C+M">Marcin Wrzeszcz</a>, 
<a href="/search/cs?searchtype=author&query=Ryan%2C+B">Brendan Ryan</a>, 
<a href="/search/cs?searchtype=author&query=Power%2C+N">Niall Power</a>, 
<a href="/search/cs?searchtype=author&query=Giller%2C+R">Robin Giller</a>, 
<a href="/search/cs?searchtype=author&query=Ruffini%2C+M">Marco Ruffini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We demonstrate a real-time, converged 5G-PON through the Cooperative
Transport Interface, synchronising 5G and PON-DBA upstream schedulers. This
innovative approach, implemented using 5G and PON open network implementations,
significantly enhances network resource allocation, reducing latency.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10710" title="Abstract">arXiv:2401.10710</a> [<a href="/pdf/2401.10710" title="Download PDF">pdf</a>, <a href="/format/2401.10710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification with neural networks with quadratic decision functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frischauf%2C+L">Leon Frischauf</a>, 
<a href="/search/cs?searchtype=author&query=Scherzer%2C+O">Otmar Scherzer</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Cong Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Neural network with quadratic decision functions have been introduced as
alternatives to standard neural networks with affine linear one. They are
advantageous when the objects to be identified are of compact basic geometries
like circles, ellipsis etc. In this paper we investigate the use of such ansatz
functions for classification. In particular we test and compare the algorithm
on the MNIST dataset for classification of handwritten digits and for
classification of subspecies. We also show, that the implementation can be
based on the neural network structure in the software Tensorflow and Keras,
respectively.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10711" title="Abstract">arXiv:2401.10711</a> [<a href="/pdf/2401.10711" title="Download PDF">pdf</a>, <a href="/format/2401.10711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal  Models for Video Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+C">Chenghang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+W">Weifeng Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Video Question Answering (VideoQA) aims to answer natural language questions
based on the information observed in videos. Despite the recent success of
Large Multimodal Models (LMMs) in image-language understanding and reasoning,
they deal with VideoQA insufficiently by simply taking uniformly sampled frames
as visual inputs, which ignores question-relevant visual clues. Moreover, there
are no human annotations for question-critical timestamps in existing VideoQA
datasets. In light of this, we propose a novel weakly supervised framework to
enforce the LMMs to reason out the answers with question-critical moments as
visual inputs. Specifically, we fuse the question and answer pairs as event
descriptions to find multiple keyframes as target moments, which will be
pseudo-labels. With these pseudo-labels as additionally weak supervision, we
devise a lightweight Gaussian-based Contrastive Grounding (GCG) module. GCG
learns multiple Gaussian functions to characterize the temporal structure of
the video, and sample question-critical frames as positive moments to be the
visual inputs of LMMs. Extensive experiments on several VideoQA benchmarks
verify the effectiveness of our framework, and we achieve substantial
improvements compared to previous state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10712" title="Abstract">arXiv:2401.10712</a> [<a href="/pdf/2401.10712" title="Download PDF">pdf</a>, <a href="/format/2401.10712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q&amp;A Prompts: Discovering Rich Visual Clues through Mining  Question-Answer Prompts for VQA requiring Diverse World Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haibi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+W">Weifeng Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">With the breakthrough of multi-modal large language models, answering complex
visual questions that demand advanced reasoning abilities and world knowledge
has become a much more important testbed for developing AI models than ever.
However, equipping AI models with robust cross-modality reasoning ability
remains challenging since the cognition scheme of humans has not been
understood systematically. In this paper, we believe that if we can collect
visual clues in the given image as much as possible, we will recognize the
image more accurately, understand the question better, recall relevant
knowledge more easily, and finally reason out the answer. We discover these
rich visual clues by mining question-answer pairs in images and sending them
into multi-modal large language models as prompts. We call the proposed method
Q&amp;A Prompts. Specifically, we first use the image-answer pairs and the
corresponding questions in the training set as inputs and outputs to train a
visual question generation model. Then, we use an image tagging model to
identify various instances and send packaged image-tag pairs into the visual
question generation model to generate relevant questions with the extracted
image tags as answers. Finally, we encode these generated question-answer pairs
as prompts with a visual-aware prompting module and send them into pre-trained
multi-modal large language models to reason out the final answers. Experimental
results show that, compared with state-of-the-art methods, our Q&amp;A Prompts
achieves substantial improvements on the challenging visual question answering
datasets requiring reasoning over diverse world knowledge, such as OK-VQA and
A-OKVQA.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10716" title="Abstract">arXiv:2401.10716</a> [<a href="/pdf/2401.10716" title="Download PDF">pdf</a>, <a href="/format/2401.10716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Code Representations Enable Data-Efficient Adaptation of Code  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+M">Mayank Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yikang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Current language models tailored for code tasks often adopt the
pre-training-then-fine-tuning paradigm from natural language processing,
modeling source code as plain text. This approach, however, overlooks the
unambiguous structures inherent in programming languages. In this work, we
explore data-efficient adaptation of pre-trained code models by further
pre-training and fine-tuning them with program structures. Specifically, we
represent programs as parse trees -- also known as concrete syntax trees (CSTs)
-- and adapt pre-trained models on serialized CSTs. Although the models that we
adapt have been pre-trained only on the surface form of programs, we find that
a small amount of continual pre-training and fine-tuning on CSTs without
changing the model architecture yields improvements over the baseline approach
across various code tasks. The improvements are found to be particularly
significant when there are limited training examples, demonstrating the
effectiveness of integrating program structures with plain-text representation
even when working with backbone models that have not been pre-trained with
structures.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10724" title="Abstract">arXiv:2401.10724</a> [<a href="/pdf/2401.10724" title="Download PDF">pdf</a>, <a href="/format/2401.10724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Zero-Day Intrusion Detection System for Automotive Controller  Area Network on FPGAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+S">Shashwat Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Shanker%2C+S">Shreejith Shanker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 7 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE 34th International Conference on Application-specific
  Systems, Architectures and Processors (ASAP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Increasing automation in vehicles enabled by increased connectivity to the
outside world has exposed vulnerabilities in previously siloed automotive
networks like controller area networks (CAN). Attributes of CAN such as
broadcast-based communication among electronic control units (ECUs) that
lowered deployment costs are now being exploited to carry out active injection
attacks like denial of service (DoS), fuzzing, and spoofing attacks. Research
literature has proposed multiple supervised machine learning models deployed as
Intrusion detection systems (IDSs) to detect such malicious activity; however,
these are largely limited to identifying previously known attack vectors. With
the ever-increasing complexity of active injection attacks, detecting zero-day
(novel) attacks in these networks in real-time (to prevent propagation) becomes
a problem of particular interest. This paper presents an
unsupervised-learning-based convolutional autoencoder architecture for
detecting zero-day attacks, which is trained only on benign (attack-free) CAN
messages. We quantise the model using Vitis-AI tools from AMD/Xilinx targeting
a resource-constrained Zynq Ultrascale platform as our IDS-ECU system for
integration. The proposed model successfully achieves equal or higher
classification accuracy (&gt; 99.5%) on unseen DoS, fuzzing, and spoofing attacks
from a publicly available attack dataset when compared to the state-of-the-art
unsupervised learning-based IDSs. Additionally, by cleverly overlapping IDS
operation on a window of CAN messages with the reception, the model is able to
meet line-rate detection (0.43 ms per window) of high-speed CAN, which when
coupled with the low energy consumption per inference, makes this architecture
ideally suited for detecting zero-day attacks on critical CAN networks.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10725" title="Abstract">arXiv:2401.10725</a> [<a href="/pdf/2401.10725" title="Download PDF">pdf</a>, <a href="/ps/2401.10725" title="Download PostScript">ps</a>, <a href="/format/2401.10725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings 14th International Conference on Automated Deduction in  Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quaresma%2C+P">Pedro Quaresma</a> (University of Coimbra, Portugal), 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+Z">Zolt&#xe1;n Kov&#xe1;cs</a> (The Private University College of Education of the Diocese of Linz, Austria)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 398, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Mathematical Software (cs.MS)

</div>
<p class="mathjax">ADG is a forum to exchange ideas and views, to present research results and
progress, and to demonstrate software tools at the intersection between
geometry and automated deduction. The conference is held every two years. The
previous editions of ADG were held in Hagenberg in 2021 (online, postponed from
2020 due to COVID-19), Nanning in 2018, Strasbourg in 2016, Coimbra in 2014,
Edinburgh in 2012, Munich in 2010, Shanghai in 2008, Pontevedra in 2006,
Gainesville in 2004, Hagenberg in 2002, Zurich in 2000, Beijing in 1998, and
Toulouse in 1996.
<br />The 14th edition, ADG 2023, was held in Belgrade, Serbia, in September 20-22,
2023. This edition of ADG had an additional special focus topic, Deduction in
Education.
<br />Invited Speakers: Julien Narboux, University of Strasbourg, France
"Formalisation, arithmetization and automatisation of geometry"; Filip Mari\'c,
University of Belgrade, Serbia, "Automatization, formalization and
visualization of hyperbolic geometry"; Zlatan Magajna, University of Ljubljana,
Slovenia, "Workshop OK Geometry"
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10726" title="Abstract">arXiv:2401.10726</a> [<a href="/pdf/2401.10726" title="Download PDF">pdf</a>, <a href="/format/2401.10726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Aggregators with Practical Data-Driven Tools: Harnessing  Aggregated and Disaggregated Flexibility for Demand Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mylonas%2C+C">Costas Mylonas</a>, 
<a href="/search/eess?searchtype=author&query=Boric%2C+D">Donata Boric</a>, 
<a href="/search/eess?searchtype=author&query=Maric%2C+L+L">Leila Luttenberger Maric</a>, 
<a href="/search/eess?searchtype=author&query=Tsitsanis%2C+A">Alexandros Tsitsanis</a>, 
<a href="/search/eess?searchtype=author&query=Petrianou%2C+E">Eleftheria Petrianou</a>, 
<a href="/search/eess?searchtype=author&query=Foti%2C+M">Magda Foti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study explores the crucial interplay between aggregators and building
occupants in activating flexibility through Demand Response (DR) programs, with
a keen focus on achieving robust decarbonization and fortifying the resilience
of the energy system amidst the uncertainties presented by Renewable Energy
Sources (RES). Firstly, it introduces a methodology of optimizing aggregated
flexibility provision strategies in environments with limited data, utilizing
Discrete Fourier Transformation (DFT) and clustering techniques to identify
building occupant's activity patterns. Secondly, the study assesses the
disaggregated flexibility provision of Heating Ventilation and Air Conditioning
(HVAC) systems during DR events, employing machine learning and optimization
techniques for precise, device-level analysis. The first approach offers a
non-intrusive pathway for aggregators to provide flexibility services in
environments of a single smart meter for the whole building's consumption,
while the second approach carefully considers building occupants' thermal
comfort profiles, while maximizing flexibility in case of existence of
dedicated smart meters to the HVAC systems. Through the application of
data-driven techniques and encompassing case studies from both industrial and
residential buildings, this paper not only unveils pivotal opportunities for
aggregators in the balancing and emerging flexibility markets but also
successfully develops end-to-end practical tools for aggregators. Furthermore,
the efficacy of this tool is validated through detailed case studies,
substantiating its operational capability and contributing to the evolution of
a resilient and efficient energy system.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10727" title="Abstract">arXiv:2401.10727</a> [<a href="/pdf/2401.10727" title="Download PDF">pdf</a>, <a href="/format/2401.10727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tool-LMM: A Large Multi-Modal Model for Tool Agent Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Weixin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+H">Haonan Mai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jindi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Sixun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiaohua">Xiaohua</a> (Michael)
<a href="/search/cs?searchtype=author&query=Xuan">Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shenghua Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 9 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, the astonishing performance of large language models (LLMs) in
natural language comprehension and generation tasks triggered lots of
exploration of using them as central controllers to build agent systems.
Multiple studies focus on bridging the LLMs to external tools to extend the
application scenarios. However, the current LLMs' perceiving tool-use ability
is limited to a single text query, which may result in ambiguity in
understanding the users' real intentions. LLMs are expected to eliminate that
by perceiving the visual- or auditory-grounded instructions' information.
Therefore, in this paper, we propose Tool-LMM, a system incorporating
open-source LLMs and multi-modal encoders so that the learnt LLMs can be
conscious of multi-modal input instruction and then select the function-matched
tool correctly. To facilitate the evaluation of the model's capability, we
collect a dataset featured by consisting of multi-modal input tools from
HuggingFace. Another important feature of our dataset is that our dataset also
contains multiple potential choices for the same instruction due to the
existence of identical functions and synonymous functions, which provides more
potential solutions for the same query. The experiments reveal that our LMM is
capable of recommending appropriate tools for multi-modal instructions. Codes
and data are available at https://github.com/Tool-LMM/Tool-LMM.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10729" title="Abstract">arXiv:2401.10729</a> [<a href="/pdf/2401.10729" title="Download PDF">pdf</a>, <a href="/ps/2401.10729" title="Download PostScript">ps</a>, <a href="/format/2401.10729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Design on Undirected Series-Parallel Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+I">Ishan Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+R">Ryan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Avhan Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the single pair capacitated network design problem and the budget
constrained max flow problem on undirected series-parallel graphs. These
problems were well studied on directed series-parallel graphs, but little is
known in the context of undirected graphs. The major difference between the
cases is that the source and sink of the problem instance do not necessarily
coincide with the terminals of the underlying series-parallel graph in the
undirected case, thus creating certain complications. We provide
pseudopolynomial time algorithms to solve both of the problems and provide an
FPTAS for the budget constrained max flow problem. We also provide some
extensions, arguing important cases when the problems are polynomial-time
solvable, and describing a series-parallel gadget that captures an edge upgrade
version of the problems.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10731" title="Abstract">arXiv:2401.10731</a> [<a href="/pdf/2401.10731" title="Download PDF">pdf</a>, <a href="/format/2401.10731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Removal and Selection: Improving RGB-Infrared Object Detection via  Coarse-to-Fine Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Maoxun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xingxing Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9pages, 7figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object detection in visible (RGB) and infrared (IR) images has been widely
applied in recent years. Leveraging the complementary characteristics of RGB
and IR images, the object detector provides reliable and robust object
localization from day to night. Existing fusion strategies directly inject RGB
and IR images into convolution neural networks, leading to inferior detection
performance. Since the RGB and IR features have modality-specific noise, these
strategies will worsen the fused features along with the propagation. Inspired
by the mechanism of human brain processing multimodal information, this work
introduces a new coarse-to-fine perspective to purify and fuse two modality
features. Specifically, following this perspective, we design a Redundant
Spectrum Removal module to coarsely remove interfering information within each
modality and a Dynamic Feature Selection module to finely select the desired
features for feature fusion. To verify the effectiveness of the coarse-to-fine
fusion strategy, we construct a new object detector called Removal and
Selection Detector (RSDet). Extensive experiments on three RGB-IR object
detection datasets verify the superior performance of our method.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10733" title="Abstract">arXiv:2401.10733</a> [<a href="/pdf/2401.10733" title="Download PDF">pdf</a>, <a href="/format/2401.10733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Q&amp;A of Clinical Documents with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elgedawy%2C+R">Ran Elgedawy</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Sudarshan Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Danciu%2C+I">Ioana Danciu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Electronic health records (EHRs) house crucial patient data in clinical
notes. As these notes grow in volume and complexity, manual extraction becomes
challenging. This work introduces a natural language interface using large
language models (LLMs) for dynamic question-answering on clinical notes. Our
chatbot, powered by Langchain and transformer-based LLMs, allows users to query
in natural language, receiving relevant answers from clinical notes.
Experiments, utilizing various embedding models and advanced LLMs, show Wizard
Vicuna's superior accuracy, albeit with high compute demands. Model
optimization, including weight quantization, improves latency by approximately
48 times. Promising results indicate potential, yet challenges such as model
hallucinations and limited diverse medical case evaluations remain. Addressing
these gaps is crucial for unlocking the value in clinical notes and advancing
AI-driven clinical decision-making.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10735" title="Abstract">arXiv:2401.10735</a> [<a href="/pdf/2401.10735" title="Download PDF">pdf</a>, <a href="/format/2401.10735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Low-Frequency-Stable Higher-Order Spline-Based Integral Equation  Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nolte%2C+M">Maximilian Nolte</a>, 
<a href="/search/cs?searchtype=author&query=Torchio%2C+R">Riccardo Torchio</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6ps%2C+S">Sebastian Sch&#xf6;ps</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%B6lz%2C+J">J&#xfc;rgen D&#xf6;lz</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+F">Felix Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Ruehli%2C+A+E">Albert E. Ruehli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This contribution investigates the connection between Isogeometric Analysis
and Integral Equation methods for full-wave electromagnetic problems. The
proposed spline-based integral equation method allows for an exact
representation of the model geometry described in terms of Non-Uniform Rational
B-Splines without meshing. This is particularly useful when high accuracy is
required or when meshing is cumbersome for instance during optimization of
electric components. The Augmented Electric Field Integral Equation is adopted,
so the low-frequency breakdown is avoided. The extension to higher-order basis
functions is analyzed and the convergence rate discussed. The analogy with the
Partial Element Equivalent Circuit method for the lowest-order case is
established, allowing for a circuit interpretation while maintaining the exact
representation of geometry even for coarse discretizations. Numerical
experiments on academic and realistic test cases demonstrate the high accuracy
of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10736" title="Abstract">arXiv:2401.10736</a> [<a href="/pdf/2401.10736" title="Download PDF">pdf</a>, <a href="/format/2401.10736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey and Comparative Analysis of Security Properties of CAN  Authentication Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lotto%2C+A">Alessandro Lotto</a>, 
<a href="/search/cs?searchtype=author&query=Marchiori%2C+F">Francesco Marchiori</a>, 
<a href="/search/cs?searchtype=author&query=Brighente%2C+A">Alessandro Brighente</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Mauro Conti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The large number of Electronic Control Units (ECUs) mounted on modern cars
and their expansive communication capabilities create a substantial attack
surface for potential exploitation. Despite the evolution of automotive
technology, the continued use of the originally insecure Controller Area
Network (CAN) bus leaves in-vehicle communications inherently non-secure. In
response to the absence of standardized authentication protocols within the
automotive domain, researchers propose diverse solutions, each with unique
strengths and vulnerabilities. However, the continuous influx of new protocols
and potential oversights in meeting security requirements and essential
operational features further complicate the implementability of these
protocols. This paper comprehensively reviews and compares the 15 most
prominent authentication protocols for the CAN bus. Our analysis emphasizes
their strengths and weaknesses, evaluating their alignment with critical
security requirements for automotive authentication. Additionally, we evaluate
protocols based on essential operational criteria that contribute to ease of
implementation in predefined infrastructures, enhancing overall reliability and
reducing the probability of successful attacks. Our study reveals a prevalent
focus on defending against external attackers in existing protocols, exposing
vulnerabilities to internal threats. Notably, authentication protocols
employing hash chains, Mixed Message Authentication Codes, and asymmetric
encryption techniques emerge as the most effective approaches. Through our
comparative study, we classify the considered protocols based on their security
attributes and suitability for implementation, providing valuable insights for
future developments in the field.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10738" title="Abstract">arXiv:2401.10738</a> [<a href="/pdf/2401.10738" title="Download PDF">pdf</a>, <a href="/ps/2401.10738" title="Download PostScript">ps</a>, <a href="/format/2401.10738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Warehouse Problem with Multiple Vendors and Generalized Complementarity  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+I">Ishan Bansal</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnl%C3%BCk%2C+O">Oktay G&#xfc;nl&#xfc;k</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the warehouse problem, arising in the area of inventory management
and production planning. Here, a merchant wants to decide an optimal trading
policy that computes quantities of a single commodity to purchase, store and
sell during each time period of a finite discrete time horizon. Motivated by
recent applications in energy markets, we extend the models by Wolsey and Yaman
(2018) and Bansal and G\"unl\"uk (2023) and consider markets with multiple
vendors and a more general form of the complementarity constraints. We show
that these extensions can capture various practical conditions such as surge
pricing and discounted sales, ramp-up and ramp-down constraints and batch
pricing. We analyze the extreme points of the underlying non-linear integer
program and provide an algorithm that exactly solves the problem. Our algorithm
runs in polynomial time under reasonable practical conditions. We also show
that the absence of such conditions renders the problem NP-Hard.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10739" title="Abstract">arXiv:2401.10739</a> [<a href="/pdf/2401.10739" title="Download PDF">pdf</a>, <a href="/ps/2401.10739" title="Download PostScript">ps</a>, <a href="/format/2401.10739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-IDE Human-AI Experience in the Era of Large Language Models; A  Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sergeyuk%2C+A">Agnia Sergeyuk</a>, 
<a href="/search/cs?searchtype=author&query=Titov%2C+S">Sergey Titov</a>, 
<a href="/search/cs?searchtype=author&query=Izadi%2C+M">Maliheh Izadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted for presentation at the IDE Workshop, co-located with ICSE'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">IDEs, crucial in contemporary software development, have evolved with the
integration of AI to boost programming efficiency and decision-making. Our
focus on in-IDE Human-AI Experience delves into understanding how these AI
tools reshape the software development process, impacting productivity and code
quality. Our literature review aimed to comprehend the current state of in-IDE
Human-AI Experience research, addressing a gap in understanding the nuanced
interactions between programmers and AI assistants within IDEs. Analyzing 36
chosen papers, our study reveals three key research branches: Design, Impact,
and Quality of Interaction. This paper sheds light on trends, challenges, and
opportunities, underscoring the dynamic nature of software development. It
serves as a guide for future research and development in this field, urging the
community to explore three vital aspects of these interactions: designing
task-specific user interfaces, fostering trust, and enhancing readability.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10741" title="Abstract">arXiv:2401.10741</a> [<a href="/pdf/2401.10741" title="Download PDF">pdf</a>, <a href="/format/2401.10741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Character Recognition in Byzantine Seals with Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rageau%2C+T">Th&#xe9;ophile Rageau</a>, 
<a href="/search/cs?searchtype=author&query=Likforman-Sulem%2C+L">Laurence Likforman-Sulem</a>, 
<a href="/search/cs?searchtype=author&query=Fiandrotti%2C+A">Attilio Fiandrotti</a>, 
<a href="/search/cs?searchtype=author&query=Eyharabide%2C+V">Victoria Eyharabide</a>, 
<a href="/search/cs?searchtype=author&query=Caseau%2C+B">B&#xe9;atrice Caseau</a>, 
<a href="/search/cs?searchtype=author&query=Cheynet%2C+J">Jean-Claude Cheynet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Seals are small coin-shaped artifacts, mostly made of lead, held with strings
to seal letters. This work presents the first attempt towards automatic reading
of text on Byzantine seal images.Byzantine seals are generally decorated with
iconography on the obverse side and Greek text on the reverse side. Text may
include the sender's name, position in the Byzantine aristocracy, and elements
of prayers. Both text and iconography are precious literary sources that wait
to be exploited electronically, so the development of computerized systems for
interpreting seals images is of paramount importance. This work's contribution
is hence a deep, two-stages, character reading pipeline for transcribing
Byzantine seal images. A first deep convolutional neural network (CNN) detects
characters in the seal (character localization). A second convolutional network
reads the localized characters (character classification). Finally, a
diplomatic transcription of the seal is provided by post-processing the two
network outputs. We provide an experimental evaluation of each CNN in isolation
and both CNNs in combination. All performances are evaluated by
cross-validation. Character localization achieves a mean average precision
(mAP@0.5) greater than 0.9. Classification of characters cropped from ground
truth bounding boxes achieves Top-1 accuracy greater than 0.92. End-to-end
evaluation shows the efficiency of the proposed approach when compared to the
SoTA for similar tasks.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10744" title="Abstract">arXiv:2401.10744</a> [<a href="/pdf/2401.10744" title="Download PDF">pdf</a>, <a href="/format/2401.10744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinLLMs: A Framework for Financial Reasoning Dataset Generation with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Ziqiang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shoutai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingya Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yanlin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wenqi Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission of IEEE Transactions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large Language models (LLMs) usually rely on extensive training datasets. In
the financial domain, creating numerical reasoning datasets that include a mix
of tables and long text often involves substantial manual annotation expenses.
To address the limited data resources and reduce the annotation cost, we
introduce FinLLMs, a method for generating financial question-answering data
based on common financial formulas using Large Language Models. First, we
compile a list of common financial formulas and construct a graph based on the
variables these formulas employ. We then augment the formula set by combining
those that share identical variables as new elements. Specifically, we explore
formulas obtained by manual annotation and merge those formulas with shared
variables by traversing the constructed graph. Finally, utilizing GPT-3.5, we
generate financial question-answering data that encompasses both tabular
information and long textual content, building on the collected formula set.
Our experiments demonstrate that synthetic data generated by FinLLMs
effectively enhances the performance of several large-scale numerical reasoning
models in the financial domain, outperforming two established benchmark
financial question-answering datasets.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10745" title="Abstract">arXiv:2401.10745</a> [<a href="/pdf/2401.10745" title="Download PDF">pdf</a>, <a href="/ps/2401.10745" title="Download PostScript">ps</a>, <a href="/format/2401.10745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ethical Artificial Intelligence Principles and Guidelines for the  Governance and Utilization of Highly Advanced Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hossain%2C+S">Soaad Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+I">Syed Ishtiaque Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, accepted to workshop on Responsible Language Models (ReLM) at Association of the Advancement of Artificial Intelligence Conference (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Given the success of ChatGPT, LaMDA and other large language models (LLMs),
there has been an increase in development and usage of LLMs within the
technology sector and other sectors. While the level in which LLMs has not
reached a level where it has surpassed human intelligence, there will be a time
when it will. Such LLMs can be referred to as advanced LLMs. Currently, there
are limited usage of ethical artificial intelligence (AI) principles and
guidelines addressing advanced LLMs due to the fact that we have not reached
that point yet. However, this is a problem as once we do reach that point, we
will not be adequately prepared to deal with the aftermath of it in an ethical
and optimal way, which will lead to undesired and unexpected consequences. This
paper addresses this issue by discussing what ethical AI principles and
guidelines can be used to address highly advanced LLMs.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10747" title="Abstract">arXiv:2401.10747</a> [<a href="/pdf/2401.10747" title="Download PDF">pdf</a>, <a href="/format/2401.10747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Sentiment Analysis with Missing Modality: A  Knowledge-Transfer Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weide Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+H">Huijing Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+F">Fengmao Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multimodal sentiment analysis aims to identify the emotions expressed by
individuals through visual, language, and acoustic cues. However, most of the
existing research efforts assume that all modalities are available during both
training and testing, making their algorithms susceptible to the missing
modality scenario. In this paper, we propose a novel knowledge-transfer network
to translate between different modalities to reconstruct the missing audio
modalities. Moreover, we develop a cross-modality attention mechanism to retain
the maximal information of the reconstructed and observed modalities for
sentiment prediction. Extensive experiments on three publicly available
datasets demonstrate significant improvements over baselines and achieve
comparable results to the previous methods with complete multi-modality
supervision.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10748" title="Abstract">arXiv:2401.10748</a> [<a href="/pdf/2401.10748" title="Download PDF">pdf</a>, <a href="/format/2401.10748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast gradient-free activation maximization for neurons in spiking neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pospelov%2C+N">Nikita Pospelov</a>, 
<a href="/search/cs?searchtype=author&query=Chertkov%2C+A">Andrei Chertkov</a>, 
<a href="/search/cs?searchtype=author&query=Beketov%2C+M">Maxim Beketov</a>, 
<a href="/search/cs?searchtype=author&query=Oseledets%2C+I">Ivan Oseledets</a>, 
<a href="/search/cs?searchtype=author&query=Anokhin%2C+K">Konstantin Anokhin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural networks (NNs), both living and artificial, work due to being complex
systems of neurons, each having its own specialization. Revealing these
specializations is important for understanding NNs inner working mechanisms.
The only way to do this for a living system, the neural response of which to a
stimulus is not a known (let alone differentiable) function is to build a
feedback loop of exposing it to stimuli, the properties of which can be
iteratively varied aiming in the direction of maximal response. To test such a
loop on a living network, one should first learn how to run it quickly and
efficiently, reaching most effective stimuli (ones that maximize certain
neurons activation) in least possible number of iterations. We present a
framework with an effective design of such a loop, successfully testing it on
an artificial spiking neural network (SNN, a model that mimics the behaviour of
NNs in living brains). Our optimization method used for activation maximization
(AM) was based on low-rank tensor decomposition (Tensor Train, TT) of the
activation function's discretization over its domain the latent parameter space
of stimuli (CIFAR10-size color images, generated by either VQ-VAE or SN-GAN
from their latent description vectors, fed to the SNN). To our knowledge, the
present work is the first attempt to perform effective AM for SNNs. The source
code of our framework, MANGO (for Maximization of neural Activation via
Non-Gradient Optimization) is available on GitHub.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10749" title="Abstract">arXiv:2401.10749</a> [<a href="/pdf/2401.10749" title="Download PDF">pdf</a>, <a href="/format/2401.10749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReliCD: A Reliable Cognitive Diagnosis Framework with Confidence  Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunfei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chuan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dazhong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haiping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengshu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">During the past few decades, cognitive diagnostics modeling has attracted
increasing attention in computational education communities, which is capable
of quantifying the learning status and knowledge mastery levels of students.
Indeed, the recent advances in neural networks have greatly enhanced the
performance of traditional cognitive diagnosis models through learning the deep
representations of students and exercises. Nevertheless, existing approaches
often suffer from the issue of overconfidence in predicting students' mastery
levels, which is primarily caused by the unavoidable noise and sparsity in
realistic student-exercise interaction data, severely hindering the educational
application of diagnostic feedback. To address this, in this paper, we propose
a novel Reliable Cognitive Diagnosis(ReliCD) framework, which can quantify the
confidence of the diagnosis feedback and is flexible for different cognitive
diagnostic functions. Specifically, we first propose a Bayesian method to
explicitly estimate the state uncertainty of different knowledge concepts for
students, which enables the confidence quantification of diagnostic feedback.
In particular, to account for potential differences, we suggest modeling
individual prior distributions for the latent variables of different ability
concepts using a pre-trained model. Additionally, we introduce a logical
hypothesis for ranking confidence levels. Along this line, we design a novel
calibration loss to optimize the confidence parameters by modeling the process
of student performance prediction. Finally, extensive experiments on four
real-world datasets clearly demonstrate the effectiveness of our ReliCD
framework.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10751" title="Abstract">arXiv:2401.10751</a> [<a href="/pdf/2401.10751" title="Download PDF">pdf</a>, <a href="/format/2401.10751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EFO: the Emotion Frame Ontology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Giorgis%2C+S">Stefano De Giorgis</a>, 
<a href="/search/cs?searchtype=author&query=Gangemi%2C+A">Aldo Gangemi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">Emotions are a subject of intense debate in various disciplines. Despite the
proliferation of theories and definitions, there is still no consensus on what
emotions are, and how to model the different concepts involved when we talk
about - or categorize - them. In this paper, we propose an OWL frame-based
ontology of emotions: the Emotion Frames Ontology (EFO). EFO treats emotions as
semantic frames, with a set of semantic roles that capture the different
aspects of emotional experience. EFO follows pattern-based ontology design, and
is aligned to the DOLCE foundational ontology. EFO is used to model multiple
emotion theories, which can be cross-linked as modules in an Emotion Ontology
Network. In this paper, we exemplify it by modeling Ekman's Basic Emotions (BE)
Theory as an EFO-BE module, and demonstrate how to perform automated inferences
on the representation of emotion situations. EFO-BE has been evaluated by
lexicalizing the BE emotion frames from within the Framester knowledge graph,
and implementing a graph-based emotion detector from text. In addition, an EFO
integration of multimodal datasets, including emotional speech and emotional
face expressions, has been performed to enable further inquiry into crossmodal
emotion semantics.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10752" title="Abstract">arXiv:2401.10752</a> [<a href="/pdf/2401.10752" title="Download PDF">pdf</a>, <a href="/format/2401.10752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiCD: Change Detection in Quality-Varied Images via Hierarchical  Correlation Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+C">Chao Pang</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+X">Xingxing Weng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gui-Song Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by TGRS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Advanced change detection techniques primarily target image pairs of equal
and high quality. However, variations in imaging conditions and platforms
frequently lead to image pairs with distinct qualities: one image being
high-quality, while the other being low-quality. These disparities in image
quality present significant challenges for understanding image pairs
semantically and extracting change features, ultimately resulting in a notable
decline in performance. To tackle this challenge, we introduce an innovative
training strategy grounded in knowledge distillation. The core idea revolves
around leveraging task knowledge acquired from high-quality image pairs to
guide the model's learning process when dealing with image pairs that exhibit
differences in quality. Additionally, we develop a hierarchical correlation
distillation approach (involving self-correlation, cross-correlation, and
global correlation). This approach compels the student model to replicate the
correlations inherent in the teacher model, rather than focusing solely on
individual features. This ensures effective knowledge transfer while
maintaining the student model's training flexibility.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10753" title="Abstract">arXiv:2401.10753</a> [<a href="/pdf/2401.10753" title="Download PDF">pdf</a>, <a href="/format/2401.10753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BoolGebra: Attributed Graph-learning for Boolean Algebraic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Agnesina%2C+A">Anthony Agnesina</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Haoxing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cunxi Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DATE 2024 extended version. arXiv admin note: text overlap with <a href="/abs/2310.07846">arXiv:2310.07846</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Boolean algebraic manipulation is at the core of logic synthesis in
Electronic Design Automation (EDA) design flow. Existing methods struggle to
fully exploit optimization opportunities, and often suffer from an explosive
search space and limited scalability efficiency. This work presents BoolGebra,
a novel attributed graph-learning approach for Boolean algebraic manipulation
that aims to improve fundamental logic synthesis. BoolGebra incorporates Graph
Neural Networks (GNNs) and takes initial feature embeddings from both
structural and functional information as inputs. A fully connected neural
network is employed as the predictor for direct optimization result
predictions, significantly reducing the search space and efficiently locating
the optimization space. The experiments involve training the BoolGebra model
w.r.t design-specific and cross-design inferences using the trained model,
where BoolGebra demonstrates generalizability for cross-design inference and
its potential to scale from small, simple training datasets to large, complex
inference datasets. Finally, BoolGebra is integrated with existing synthesis
tool ABC to perform end-to-end logic minimization evaluation w.r.t SOTA
baselines.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10754" title="Abstract">arXiv:2401.10754</a> [<a href="/pdf/2401.10754" title="Download PDF">pdf</a>, <a href="/format/2401.10754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation for Traffic Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Finamore%2C+A">Alessandro Finamore</a>, 
<a href="/search/cs?searchtype=author&query=Michiardi%2C+P">Pietro Michiardi</a>, 
<a href="/search/cs?searchtype=author&query=Gallo%2C+M">Massimo Gallo</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+D">Dario Rossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear at Passive and Active Measurements (PAM), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Data Augmentation (DA) -- enriching training data by adding synthetic samples
-- is a technique widely adopted in Computer Vision (CV) and Natural Language
Processing (NLP) tasks to improve models performance. Yet, DA has struggled to
gain traction in networking contexts, particularly in Traffic Classification
(TC) tasks. In this work, we fulfill this gap by benchmarking 18 augmentation
functions applied to 3 TC datasets using packet time series as input
representation and considering a variety of training conditions. Our results
show that (i) DA can reap benefits previously unexplored with (ii)
augmentations acting on time series sequence order and masking being a better
suit for TC and (iii) simple latent space analysis can provide hints about why
augmentations have positive or negative effects.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10755" title="Abstract">arXiv:2401.10755</a> [<a href="/pdf/2401.10755" title="Download PDF">pdf</a>, <a href="/format/2401.10755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Reviewer Recommendation Based on a Hypergraph with Multiplex  Relationships
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Can Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 31st IEEE International Conference on Software Analysis, Evolution, and Reengineering (SANER)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code review is an essential component of software development, playing a
vital role in ensuring a comprehensive check of code changes. However, the
continuous influx of pull requests and the limited pool of available reviewer
candidates pose a significant challenge to the review process, making the task
of assigning suitable reviewers to each review request increasingly difficult.
To tackle this issue, we present MIRRec, a novel code reviewer recommendation
method that leverages a hypergraph with multiplex relationships. MIRRec encodes
high-order correlations that go beyond traditional pairwise connections using
degree-free hyperedges among pull requests and developers. This way, it can
capture high-order implicit connectivity and identify potential reviewers. To
validate the effectiveness of MIRRec, we conducted experiments using a dataset
comprising 48,374 pull requests from ten popular open-source software projects
hosted on GitHub. The experiment results demonstrate that MIRRec, especially
without PR-Review Commenters relationship, outperforms existing stateof-the-art
code reviewer recommendation methods in terms of ACC and MRR, highlighting its
significance in improving the code review process.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10759" title="Abstract">arXiv:2401.10759</a> [<a href="/pdf/2401.10759" title="Download PDF">pdf</a>, <a href="/format/2401.10759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactions with Prompt Problems: A New Way to Teach Programming with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prather%2C+J">James Prather</a>, 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Paul Denny</a>, 
<a href="/search/cs?searchtype=author&query=Leinonen%2C+J">Juho Leinonen</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+D+H">David H. Smith IV</a>, 
<a href="/search/cs?searchtype=author&query=Reeves%2C+B+N">Brent N. Reeves</a>, 
<a href="/search/cs?searchtype=author&query=MacNeil%2C+S">Stephen MacNeil</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+B+A">Brett A. Becker</a>, 
<a href="/search/cs?searchtype=author&query=Luxton-Reilly%2C+A">Andrew Luxton-Reilly</a>, 
<a href="/search/cs?searchtype=author&query=Amarouche%2C+T">Thezyrie Amarouche</a>, 
<a href="/search/cs?searchtype=author&query=Kimmel%2C+B">Bailey Kimmel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have upended decades of pedagogy in computing
education. Students previously learned to code through \textit{writing} many
small problems with less emphasis on code reading and comprehension. Recent
research has shown that free code generation tools powered by LLMs can solve
introductory programming problems presented in natural language with ease. In
this paper, we propose a new way to teach programming with Prompt Problems.
Students receive a problem visually, indicating how input should be transformed
to output, and must translate that to a prompt for an LLM to decipher. The
problem is considered correct when the code that is generated by the student
prompt can pass all test cases. In this paper we present the design of this
tool, discuss student interactions with it as they learn, and provide insights
into this new class of programming problems as well as the design tools that
integrate LLMs.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10765" title="Abstract">arXiv:2401.10765</a> [<a href="/pdf/2401.10765" title="Download PDF">pdf</a>, <a href="/format/2401.10765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Starlit: Privacy-Preserving Federated Learning to Enhance Financial  Fraud Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abadi%2C+A">Aydin Abadi</a>, 
<a href="/search/cs?searchtype=author&query=Doyle%2C+B">Bradley Doyle</a>, 
<a href="/search/cs?searchtype=author&query=Gini%2C+F">Francesco Gini</a>, 
<a href="/search/cs?searchtype=author&query=Guinamard%2C+K">Kieron Guinamard</a>, 
<a href="/search/cs?searchtype=author&query=Murakonda%2C+S+K">Sasi Kumar Murakonda</a>, 
<a href="/search/cs?searchtype=author&query=Liddell%2C+J">Jack Liddell</a>, 
<a href="/search/cs?searchtype=author&query=Mellor%2C+P">Paul Mellor</a>, 
<a href="/search/cs?searchtype=author&query=Murdoch%2C+S+J">Steven J. Murdoch</a>, 
<a href="/search/cs?searchtype=author&query=Naseri%2C+M">Mohammad Naseri</a>, 
<a href="/search/cs?searchtype=author&query=Page%2C+H">Hector Page</a>, 
<a href="/search/cs?searchtype=author&query=Theodorakopoulos%2C+G">George Theodorakopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Weller%2C+S">Suzanne Weller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Federated Learning (FL) is a data-minimization approach enabling
collaborative model training across diverse clients with local data, avoiding
direct data exchange. However, state-of-the-art FL solutions to identify
fraudulent financial transactions exhibit a subset of the following
limitations. They (1) lack a formal security definition and proof, (2) assume
prior freezing of suspicious customers' accounts by financial institutions
(limiting the solutions' adoption), (3) scale poorly, involving either $O(n^2)$
computationally expensive modular exponentiation (where $n$ is the total number
of financial institutions) or highly inefficient fully homomorphic encryption,
(4) assume the parties have already completed the identity alignment phase,
hence excluding it from the implementation, performance evaluation, and
security analysis, and (5) struggle to resist clients' dropouts. This work
introduces Starlit, a novel scalable privacy-preserving FL mechanism that
overcomes these limitations. It has various applications, such as enhancing
financial fraud detection, mitigating terrorism, and enhancing digital health.
We implemented Starlit and conducted a thorough performance analysis using
synthetic data from a key player in global financial transactions. The
evaluation indicates Starlit's scalability, efficiency, and accuracy.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10766" title="Abstract">arXiv:2401.10766</a> [<a href="/pdf/2401.10766" title="Download PDF">pdf</a>, <a href="/format/2401.10766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Aware Resource Allocation in Constrained Networks with Limited  User Participation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marnissi%2C+O">Ouiame Marnissi</a>, 
<a href="/search/cs?searchtype=author&query=Hammouti%2C+H+E">Hajar EL Hammouti</a>, 
<a href="/search/cs?searchtype=author&query=Bergou%2C+E+H">El Houcine Bergou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Semantic communication has gained attention as a key enabler for intelligent
and context-aware communication. However, one of the key challenges of semantic
communications is the need to tailor the resource allocation to meet the
specific requirements of semantic transmission. In this paper, we focus on
networks with limited resources where devices are constrained to transmit with
limited bandwidth and power over large distance. Specifically, we devise an
efficient strategy to select the most pertinent semantic features and
participating users, taking into account the channel quality, the transmission
time, and the recovery accuracy. To this end, we formulate an optimization
problem with the goal of selecting the most relevant and accurate semantic
features over devices while satisfying constraints on transmission time and
quality of the channel. This involves optimizing communication resources,
identifying participating users, and choosing specific semantic information for
transmission. The underlying problem is inherently complex due to its
non-convex nature and combinatorial constraints. To overcome this challenge, we
efficiently approximate the optimal solution by solving a series of integer
linear programming problems. Our numerical findings illustrate the
effectiveness and efficiency of our approach in managing semantic
communications in networks with limited resources.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10768" title="Abstract">arXiv:2401.10768</a> [<a href="/pdf/2401.10768" title="Download PDF">pdf</a>, <a href="/format/2401.10768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Hallucinations of Large Language Models via Knowledge  Consistent Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fanqi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While Large Language Models (LLMs) have proven to be exceptional on a variety
of tasks after alignment, they may still produce responses that contradict the
context or world knowledge confidently, a phenomenon known as
``hallucination''. In this paper, we demonstrate that reducing the
inconsistency between the external knowledge encapsulated in the training data
and the intrinsic knowledge inherited in the pretraining corpus could mitigate
hallucination in alignment. Specifically, we introduce a novel knowledge
consistent alignment (KCA) approach, which involves automatically formulating
examinations based on external knowledge for accessing the comprehension of
LLMs. For data encompassing knowledge inconsistency, KCA implements several
simple yet efficient strategies for processing. We illustrate the superior
performance of the proposed KCA approach in mitigating hallucinations across
six benchmarks using LLMs of different backbones and scales. Furthermore, we
confirm the correlation between knowledge inconsistency and hallucination,
signifying the effectiveness of reducing knowledge inconsistency in alleviating
hallucinations. Our code, model weights, and data are public at
\url{https://github.com/fanqiwan/KCA}.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10773" title="Abstract">arXiv:2401.10773</a> [<a href="/pdf/2401.10773" title="Download PDF">pdf</a>, <a href="/format/2401.10773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilevel lattice codes from Hurwitz integers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Souza%2C+J+G+F">Juliana G. F. Souza</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+S+I+R">Sueli I. R. Costa</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C">Cong Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This study extends the Construction $\pi_A$ lattices proposed in
\cite{huang2017construction}, to Hurwitz integers. To this, we use a modified
version of the Chinese remainder theorem applied to maximal orders. Exploiting
the isomorphism guaranteed by this theorem, we construct multilevel lattice
codes that effectively attain the Poltyrev-limit. The performance of the
proposed lattice codes is evaluated via computer simulations, showing notably
reduced computational complexity provided by the multistage decoding.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10774" title="Abstract">arXiv:2401.10774</a> [<a href="/pdf/2401.10774" title="Download PDF">pdf</a>, <a href="/format/2401.10774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medusa: Simple LLM Inference Acceleration Framework with Multiple  Decoding Heads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Tianle Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Z">Zhengyang Geng</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hongwu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dao%2C+T">Tri Dao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code for this implementation is available at <a href="https://github.com/FasterDecoding/Medusa">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The inference process in Large Language Models (LLMs) is often limited due to
the absence of parallelism in the auto-regressive decoding process, resulting
in most operations being restricted by the memory bandwidth of accelerators.
While methods such as speculative decoding have been suggested to address this
issue, their implementation is impeded by the challenges associated with
acquiring and maintaining a separate draft model. In this paper, we present
Medusa, an efficient method that augments LLM inference by adding extra
decoding heads to predict multiple subsequent tokens in parallel. Using a
tree-based attention mechanism, Medusa constructs multiple candidate
continuations and verifies them simultaneously in each decoding step. By
leveraging parallel processing, Medusa introduces only minimal overhead in
terms of single-step latency while substantially reducing the number of
decoding steps required.
<br />We present two levels of fine-tuning procedures for Medusa to meet the needs
of different use cases: Medusa-1: Medusa is directly fine-tuned on top of a
frozen backbone LLM, enabling lossless inference acceleration. Medusa-2: Medusa
is fine-tuned together with the backbone LLM, enabling better prediction
accuracy of Medusa heads and higher speedup but needing a special training
recipe that preserves the backbone model's capabilities.
<br />Moreover, we propose several extensions that improve or expand the utility of
Medusa, including a self-distillation to handle situations where no training
data is available and a typical acceptance scheme to boost the acceptance rate
while maintaining generation quality. We evaluate Medusa on models of various
sizes and training procedures. Our experiments demonstrate that Medusa-1 can
achieve over 2.2x speedup without compromising generation quality, while
Medusa-2 further improves the speedup to 2.3-3.6x.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10777" title="Abstract">arXiv:2401.10777</a> [<a href="/pdf/2401.10777" title="Download PDF">pdf</a>, <a href="/ps/2401.10777" title="Download PostScript">ps</a>, <a href="/format/2401.10777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Determination of efficiency indicators of the stand for intelligent  control of manual operations in industrial production
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sergeev%2C+A">Anton Sergeev</a>, 
<a href="/search/cs?searchtype=author&query=Minchenkov%2C+V">Victor Minchenkov</a>, 
<a href="/search/cs?searchtype=author&query=Soldatov%2C+A">Aleksei Soldatov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Systems of intelligent control of manual operations in industrial production
are being implemented in many industries nowadays. Such systems use
high-resolution cameras and computer vision algorithms to automatically track
the operator's manipulations and prevent technological errors in the assembly
process. At the same time compliance with safety regulations in the workspace
is monitored. As a result, the defect rate of manufactured products and the
number of accidents during the manual assembly of any device are decreased.
Before implementing an intelligent control system into a real production it is
necessary to calculate its efficiency. In order to do it experiments on the
stand for manual operations control systems were carried out. This paper
proposes the methodology for calculating the efficiency indicators. This
mathematical approach is based on the IoU calculation of real- and
predicted-time intervals between assembly stages. The results show high
precision in tracking the validity of manual assembly and do not depend on the
duration of the assembly process.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10778" title="Abstract">arXiv:2401.10778</a> [<a href="/pdf/2401.10778" title="Download PDF">pdf</a>, <a href="/ps/2401.10778" title="Download PostScript">ps</a>, <a href="/format/2401.10778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HaliVer: Deductive Verification and Scheduling Languages Join Forces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+den+Haak%2C+L+B">Lars B. van den Haak</a>, 
<a href="/search/cs?searchtype=author&query=Wijs%2C+A">Anton Wijs</a>, 
<a href="/search/cs?searchtype=author&query=Huisman%2C+M">Marieke Huisman</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Brand%2C+M">Mark van den Brand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">The HaliVer tool integrates deductive verification into the popular
scheduling language Halide, used for image processing pipelines and array
computations. HaliVer uses Vercors, a separation logic-based verifier, to
verify the correctness of (1) the Halide algorithms and (2) the optimised
parallel code produced by \halide when an optimisation schedule is applied to
the algorithm. This allows proving complex, optimised code correct while
reducing the effort to provide the required verification annotations. For both
approaches, the same specification is used. We evaluated the tool on several
optimised programs generated from characteristic Halide algorithms, using all
but one of the essential scheduling directives available in Halide. Without
annotation effort, Haliver proves memory safety in almost all programs. With
annotations Haliver, additionally, proves functional correctness properties. We
show that the approach is viable and reduces the manual annotation effort by an
order of magnitude.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10781" title="Abstract">arXiv:2401.10781</a> [<a href="/pdf/2401.10781" title="Download PDF">pdf</a>, <a href="/format/2401.10781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metric Dynamic Equilibrium Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Becker%2C+A">Arvid Becker</a>, 
<a href="/search/cs?searchtype=author&query=Cabalar%2C+P">Pedro Cabalar</a>, 
<a href="/search/cs?searchtype=author&query=Di%C3%A9guez%2C+M">Mart&#xed;n Di&#xe9;guez</a>, 
<a href="/search/cs?searchtype=author&query=Fari%C3%B1as%2C+L">Luis Fari&#xf1;as</a>, 
<a href="/search/cs?searchtype=author&query=Schaub%2C+T">Torsten Schaub</a>, 
<a href="/search/cs?searchtype=author&query=Schuhmann%2C+A">Anna Schuhmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.14778">arXiv:2304.14778</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In temporal extensions of Answer Set Programming (ASP) based on linear-time,
the behavior of dynamic systems is captured by sequences of states. While this
representation reflects their relative order, it abstracts away the specific
times associated with each state. In many applications, however, timing
constraints are important like, for instance, when planning and scheduling go
hand in hand. We address this by developing a metric extension of linear-time
Dynamic Equilibrium Logic, in which dynamic operators are constrained by
intervals over integers. The resulting Metric Dynamic Equilibrium Logic
provides the foundation of an ASP-based approach for specifying qualitative and
quantitative dynamic constraints. As such, it constitutes the most general
among a whole spectrum of temporal extensions of Equilibrium Logic. In detail,
we show that it encompasses Temporal, Dynamic, Metric, and regular Equilibrium
Logic, as well as its classic counterparts once the law of the excluded middle
is added.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10785" title="Abstract">arXiv:2401.10785</a> [<a href="/pdf/2401.10785" title="Download PDF">pdf</a>, <a href="/ps/2401.10785" title="Download PostScript">ps</a>, <a href="/format/2401.10785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composite learning backstepping control with guaranteed exponential  stability and robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shi%2C+T">Tian Shi</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+C">Changyun Wen</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+Y">Yongping Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Adaptive backstepping control provides a feasible solution to achieve
asymptotic tracking for mismatched uncertain nonlinear systems. However,
input-to-state stability depends on high-gain feedback generated by nonlinear
damping terms, and closed-loop exponential stability with parameter convergence
involves a stringent condition named persistent excitation (PE). This paper
proposes a composite learning backstepping control (CLBC) strategy based on
modular backstepping and high-order tuners to compensate for the transient
process of parameter estimation and achieve closed-loop exponential stability
without the nonlinear damping terms and the PE condition. A novel composite
learning mechanism that maximizes the staged exciting strength is designed for
parameter estimation, such that parameter convergence can be achieved under a
condition of interval excitation (IE) or even partial IE that is strictly
weaker than PE. An extra prediction error is employed in the adaptive law to
ensure the transient performance without nonlinear damping terms. The
exponential stability of the closed-loop system is proved rigorously under the
partial IE or IE condition. Simulations have demonstrated the effectiveness and
superiority of the proposed method in both parameter estimation and control
compared to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10786" title="Abstract">arXiv:2401.10786</a> [<a href="/pdf/2401.10786" title="Download PDF">pdf</a>, <a href="/format/2401.10786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sat2Scene: 3D Urban Scene Generation from Satellite Images with  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuoyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhaopeng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Directly generating scenes from satellite imagery offers exciting
possibilities for integration into applications like games and map services.
However, challenges arise from significant view changes and scene scale.
Previous efforts mainly focused on image or video generation, lacking
exploration into the adaptability of scene generation for arbitrary views.
Existing 3D generation works either operate at the object level or are
difficult to utilize the geometry obtained from satellite imagery. To overcome
these limitations, we propose a novel architecture for direct 3D scene
generation by introducing diffusion models into 3D sparse representations and
combining them with neural rendering techniques. Specifically, our approach
generates texture colors at the point level for a given geometry using a 3D
diffusion model first, which is then transformed into a scene representation in
a feed-forward manner. The representation can be utilized to render arbitrary
views which would excel in both single-frame quality and inter-frame
consistency. Experiments in two city-scale datasets show that our model
demonstrates proficiency in generating photo-realistic street-view image
sequences and cross-view urban scenes from satellite imagery.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10787" title="Abstract">arXiv:2401.10787</a> [<a href="/pdf/2401.10787" title="Download PDF">pdf</a>, <a href="/ps/2401.10787" title="Download PostScript">ps</a>, <a href="/format/2401.10787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Online Certificate Status Protocol with Certificate Revocation  List for Smart Grid Public Key Infrastructure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hong-Sheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhe-Yi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hsuan-Tung Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hung-Min Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Hsu et al. (2022) proposed a cryptographic scheme within the public key
infrastructure to bolster the security of smart grid meters. Their proposal
involved developing the Certificate Management over CMS mechanism to establish
Simple Certificate Enrollment Protocol and Enrollment over Secure Transport
protocol. Additionally, they implemented Online Certificate Status Protocol
(OCSP) services to independently query the status of certificates. However,
their implementation featured a single OCSP server handling all query requests.
Considering the typical scenario in smart grid PKI environments with over tens
of thousands of end-meters, we introduced a Hybrid Online Certificate Status
Protocol mechanism. This approach decreases demand of query resources from the
client to OCSP servers collaborating with Certificate Revocation Lists. Our
simulations, mimicking meter behavior, demonstrated increased efficiency,
creating a more robust architecture tailored to the smart grid meter landscape.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10790" title="Abstract">arXiv:2401.10790</a> [<a href="/pdf/2401.10790" title="Download PDF">pdf</a>, <a href="/ps/2401.10790" title="Download PostScript">ps</a>, <a href="/format/2401.10790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the Impact of Scene Level Objects on Object Detection: Towards  Quantitative Explanations of Detection Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haar%2C+L+V">Lynn Vonder Haar</a>, 
<a href="/search/cs?searchtype=author&query=Elvira%2C+T">Timothy Elvira</a>, 
<a href="/search/cs?searchtype=author&query=Newcomb%2C+L">Luke Newcomb</a>, 
<a href="/search/cs?searchtype=author&query=Ochoa%2C+O">Omar Ochoa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Although accuracy and other common metrics can provide a useful window into
the performance of an object detection model, they lack a deeper view of the
model's decision process. Regardless of the quality of the training data and
process, the features that an object detection model learns cannot be
guaranteed. A model may learn a relationship between certain background
context, i.e., scene level objects, and the presence of the labeled classes.
Furthermore, standard performance verification and metrics would not identify
this phenomenon. This paper presents a new black box explainability method for
additional verification of object detection models by finding the impact of
scene level objects on the identification of the objects within the image. By
comparing the accuracies of a model on test data with and without certain scene
level objects, the contributions of these objects to the model's performance
becomes clearer. The experiment presented here will assess the impact of
buildings and people in image context on the detection of emergency road
vehicles by a fine-tuned YOLOv8 model. A large increase in accuracy in the
presence of a scene level object will indicate the model's reliance on that
object to make its detections. The results of this research lead to providing a
quantitative explanation of the object detection model's decision process,
enabling a deeper understanding of the model's performance.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10791" title="Abstract">arXiv:2401.10791</a> [<a href="/pdf/2401.10791" title="Download PDF">pdf</a>, <a href="/format/2401.10791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early alignment in two-layer networks training is a two-edged sword
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boursier%2C+E">Etienne Boursier</a>, 
<a href="/search/cs?searchtype=author&query=Flammarion%2C+N">Nicolas Flammarion</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Training neural networks with first order optimisation methods is at the core
of the empirical success of deep learning. The scale of initialisation is a
crucial factor, as small initialisations are generally associated to a feature
learning regime, for which gradient descent is implicitly biased towards simple
solutions. This work provides a general and quantitative description of the
early alignment phase, originally introduced by Maennel et al. (2018) . For
small initialisation and one hidden ReLU layer networks, the early stage of the
training dynamics leads to an alignment of the neurons towards key directions.
This alignment induces a sparse representation of the network, which is
directly related to the implicit bias of gradient flow at convergence. This
sparsity inducing alignment however comes at the expense of difficulties in
minimising the training objective: we also provide a simple data example for
which overparameterised networks fail to converge towards global minima and
only converge to a spurious stationary point instead.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10794" title="Abstract">arXiv:2401.10794</a> [<a href="/pdf/2401.10794" title="Download PDF">pdf</a>, <a href="/format/2401.10794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning Empowered Activity-Aware Dynamic Health  Monitoring Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziqiaing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yulan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yue Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In smart healthcare, health monitoring utilizes diverse tools and
technologies to analyze patients' real-time biosignal data, enabling immediate
actions and interventions. Existing monitoring approaches were designed on the
premise that medical devices track several health metrics concurrently,
tailored to their designated functional scope. This means that they report all
relevant health values within that scope, which can result in excess resource
use and the gathering of extraneous data due to monitoring irrelevant health
metrics. In this context, we propose Dynamic Activity-Aware Health Monitoring
strategy (DActAHM) for striking a balance between optimal monitoring
performance and cost efficiency, a novel framework based on Deep Reinforcement
Learning (DRL) and SlowFast Model to ensure precise monitoring based on users'
activities. Specifically, with the SlowFast Model, DActAHM efficiently
identifies individual activities and captures these results for enhanced
processing. Subsequently, DActAHM refines health metric monitoring in response
to the identified activity by incorporating a DRL framework. Extensive
experiments comparing DActAHM against three state-of-the-art approaches
demonstrate it achieves 27.3% higher gain than the best-performing baseline
that fixes monitoring actions over timeline.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10799" title="Abstract">arXiv:2401.10799</a> [<a href="/pdf/2401.10799" title="Download PDF">pdf</a>, <a href="/format/2401.10799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel Representation Learning Technique using Graphs for Performance  Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramadan%2C+T">Tarek Ramadan</a>, 
<a href="/search/cs?searchtype=author&query=Lahiry%2C+A">Ankur Lahiry</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+T+Z">Tanzima Z. Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at 22nd International Conference on Machine Learning and Applications (ICMLA2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The performance analytics domain in High Performance Computing (HPC) uses
tabular data to solve regression problems, such as predicting the execution
time. Existing Machine Learning (ML) techniques leverage the correlations among
features given tabular datasets, not leveraging the relationships between
samples directly. Moreover, since high-quality embeddings from raw features
improve the fidelity of the downstream predictive models, existing methods rely
on extensive feature engineering and pre-processing steps, costing time and
manual effort. To fill these two gaps, we propose a novel idea of transforming
tabular performance data into graphs to leverage the advancement of Graph
Neural Network-based (GNN) techniques in capturing complex relationships
between features and samples. In contrast to other ML application domains, such
as social networks, the graph is not given; instead, we need to build it. To
address this gap, we propose graph-building methods where nodes represent
samples, and the edges are automatically inferred iteratively based on the
similarity between the features in the samples. We evaluate the effectiveness
of the generated embeddings from GNNs based on how well they make even a simple
feed-forward neural network perform for regression tasks compared to other
state-of-the-art representation learning techniques. Our evaluation
demonstrates that even with up to 25% random missing values for each dataset,
our method outperforms commonly used graph and Deep Neural Network (DNN)-based
approaches and achieves up to 61.67% &amp; 78.56% improvement in MSE loss over the
DNN baseline respectively for HPC dataset and Machine Learning Datasets.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10804" title="Abstract">arXiv:2401.10804</a> [<a href="/pdf/2401.10804" title="Download PDF">pdf</a>, <a href="/format/2401.10804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Endovascular Detection of Catheter-Thrombus Contact by Vacuum Excitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lawson%2C+J">Jared Lawson</a>, 
<a href="/search/cs?searchtype=author&query=Veliky%2C+M">Madison Veliky</a>, 
<a href="/search/cs?searchtype=author&query=Abah%2C+C+P">Colette P. Abah</a>, 
<a href="/search/cs?searchtype=author&query=Dietrich%2C+M+S">Mary S. Dietrich</a>, 
<a href="/search/cs?searchtype=author&query=Chitale%2C+R">Rohan Chitale</a>, 
<a href="/search/cs?searchtype=author&query=Simaan%2C+N">Nabil Simaan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Objective: The objective of this work is to introduce and demonstrate the
effectiveness of a novel sensing modality for contact detection between an
off-the-shelf aspiration catheter and a thrombus. Methods: A custom robotic
actuator with a pressure sensor was used to generate an oscillatory vacuum
excitation and sense the pressure inside the extracorporeal portion of the
catheter. Vacuum pressure profiles and robotic motion data were used to train a
support vector machine (SVM) classification model to detect contact between the
aspiration catheter tip and a mock thrombus. Validation consisted of benchtop
accuracy verification, as well as user study comparison to the current standard
of angiographic presentation. Results: Benchtop accuracy of the sensing
modality was shown to be 99.67%. The user study demonstrated statistically
significant improvement in identifying catheter-thrombus contact compared to
the current standard. The odds ratio of successful detection of clot contact
was 2.86 (p=0.03) when using the proposed sensory method compared to without
it. Conclusion: The results of this work indicate that the proposed sensing
modality can offer intraoperative feedback to interventionalists that can
improve their ability to detect contact between the distal tip of a catheter
and a thrombus. Significance: By offering a relatively low-cost technology that
affords off-the-shelf aspiration catheters as clot-detecting sensors,
interventionalists can improve the first-pass effect of the mechanical
thrombectomy procedure while reducing procedural times and mental burden.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10805" title="Abstract">arXiv:2401.10805</a> [<a href="/pdf/2401.10805" title="Download PDF">pdf</a>, <a href="/format/2401.10805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Visually Connect Actions and their Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peh%2C+E">Eric Peh</a>, 
<a href="/search/cs?searchtype=author&query=Parmar%2C+P">Paritosh Parmar</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+B">Basura Fernando</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">In this work, we introduce the novel concept of visually Connecting Actions
and Their Effects (CATE) in video understanding. CATE can have applications in
areas like task planning and learning from demonstration. We propose different
CATE-based task formulations, such as action selection and action
specification, where video understanding models connect actions and effects at
semantic and fine-grained levels. We observe that different formulations
produce representations capturing intuitive action properties. We also design
various baseline models for action selection and action specification. Despite
the intuitive nature of the task, we observe that models struggle, and humans
outperform them by a large margin. The study aims to establish a foundation for
future efforts, showcasing the flexibility and versatility of connecting
actions and effects in video understanding, with the hope of inspiring advanced
formulations and models.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10809" title="Abstract">arXiv:2401.10809</a> [<a href="/pdf/2401.10809" title="Download PDF">pdf</a>, <a href="/format/2401.10809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neglected Hessian component explains mysteries in Sharpness  regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dauphin%2C+Y+N">Yann N. Dauphin</a>, 
<a href="/search/cs?searchtype=author&query=Agarwala%2C+A">Atish Agarwala</a>, 
<a href="/search/cs?searchtype=author&query=Mobahi%2C+H">Hossein Mobahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent work has shown that methods like SAM which either explicitly or
implicitly penalize second order information can improve generalization in deep
learning. Seemingly similar methods like weight noise and gradient penalties
often fail to provide such benefits. We show that these differences can be
explained by the structure of the Hessian of the loss. First, we show that a
common decomposition of the Hessian can be quantitatively interpreted as
separating the feature exploitation from feature exploration. The feature
exploration, which can be described by the Nonlinear Modeling Error matrix
(NME), is commonly neglected in the literature since it vanishes at
interpolation. Our work shows that the NME is in fact important as it can
explain why gradient penalties are sensitive to the choice of activation
function. Using this insight we design interventions to improve performance. We
also provide evidence that challenges the long held equivalence of weight noise
and gradient penalties. This equivalence relies on the assumption that the NME
can be ignored, which we find does not hold for modern networks since they
involve significant feature learning. We find that regularizing feature
exploitation but not feature exploration yields performance similar to gradient
penalties.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10815" title="Abstract">arXiv:2401.10815</a> [<a href="/pdf/2401.10815" title="Download PDF">pdf</a>, <a href="/format/2401.10815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAD-DINO: Exploring Scalable Medical Image Encoders Beyond Text  Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Garc%C3%ADa%2C+F">Fernando P&#xe9;rez-Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Harshita Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Bond-Taylor%2C+S">Sam Bond-Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Bouzid%2C+K">Kenza Bouzid</a>, 
<a href="/search/cs?searchtype=author&query=Salvatelli%2C+V">Valentina Salvatelli</a>, 
<a href="/search/cs?searchtype=author&query=Ilse%2C+M">Maximilian Ilse</a>, 
<a href="/search/cs?searchtype=author&query=Bannur%2C+S">Shruthi Bannur</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+D+C">Daniel C. Castro</a>, 
<a href="/search/cs?searchtype=author&query=Schwaighofer%2C+A">Anton Schwaighofer</a>, 
<a href="/search/cs?searchtype=author&query=Lungren%2C+M+P">Matthew P. Lungren</a>, 
<a href="/search/cs?searchtype=author&query=Wetscherek%2C+M">Maria Wetscherek</a>, 
<a href="/search/cs?searchtype=author&query=Codella%2C+N">Noel Codella</a>, 
<a href="/search/cs?searchtype=author&query=Hyland%2C+S+L">Stephanie L. Hyland</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez-Valle%2C+J">Javier Alvarez-Valle</a>, 
<a href="/search/cs?searchtype=author&query=Oktay%2C+O">Ozan Oktay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Language-supervised pre-training has proven to be a valuable method for
extracting semantically meaningful features from images, serving as a
foundational element in multimodal systems within the computer vision and
medical imaging domains. However, resulting features are limited by the
information contained within the text. This is particularly problematic in
medical imaging, where radiologists' written findings focus on specific
observations; a challenge compounded by the scarcity of paired imaging-text
data due to concerns over leakage of personal health information. In this work,
we fundamentally challenge the prevailing reliance on language supervision for
learning general purpose biomedical imaging encoders. We introduce RAD-DINO, a
biomedical image encoder pre-trained solely on unimodal biomedical imaging data
that obtains similar or greater performance than state-of-the-art biomedical
language supervised models on a diverse range of benchmarks. Specifically, the
quality of learned representations is evaluated on standard imaging tasks
(classification and semantic segmentation), and a vision-language alignment
task (text report generation from images). To further demonstrate the drawback
of language supervision, we show that features from RAD-DINO correlate with
other medical records (e.g., sex or age) better than language-supervised
models, which are generally not mentioned in radiology reports. Finally, we
conduct a series of ablations determining the factors in RAD-DINO's
performance; notably, we observe that RAD-DINO's downstream performance scales
well with the quantity and diversity of training data, demonstrating that
image-only supervision is a scalable approach for training a foundational
biomedical image encoder.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10816" title="Abstract">arXiv:2401.10816</a> [<a href="/pdf/2401.10816" title="Download PDF">pdf</a>, <a href="/format/2401.10816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-Pilot for Health: Personalized Algorithmic AI Nudging to Improve  Health Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiam%2C+J">Jodi Chiam</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+A">Aloysius Lim</a>, 
<a href="/search/cs?searchtype=author&query=Nott%2C+C">Cheryl Nott</a>, 
<a href="/search/cs?searchtype=author&query=Mark%2C+N">Nicholas Mark</a>, 
<a href="/search/cs?searchtype=author&query=Teredesai%2C+A">Ankur Teredesai</a>, 
<a href="/search/cs?searchtype=author&query=Shinde%2C+S">Sunil Shinde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The ability to shape health behaviors of large populations automatically,
across wearable types and disease conditions at scale has tremendous potential
to improve global health outcomes. We designed and implemented an AI driven
platform for digital algorithmic nudging, enabled by a Graph-Neural Network
(GNN) based Recommendation System, and granular health behavior data from
wearable fitness devices. Here we describe the efficacy results of this
platform with its capabilities of personalized and contextual nudging to
$n=84,764$ individuals over a 12-week period in Singapore. We statistically
validated that participants in the target group who received such AI optimized
daily nudges increased daily physical activity like step count by 6.17% ($p =
3.09\times10^{-4}$) and weekly minutes of Moderate to Vigorous Physical
Activity (MVPA) by 7.61% ($p = 1.16\times10^{-2}$), compared to matched
participants in control group who did not receive any nudges. Further, such
nudges were very well received, with a 13.1% of nudges sent being opened (open
rate), and 11.7% of the opened nudges rated useful compared to 1.9% rated as
not useful thereby demonstrating significant improvement in population level
engagement metrics.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10819" title="Abstract">arXiv:2401.10819</a> [<a href="/pdf/2401.10819" title="Download PDF">pdf</a>, <a href="/format/2401.10819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimisation in Neurosymbolic Learning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Krieken%2C+E">Emile van Krieken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD dissertation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neurosymbolic AI aims to integrate deep learning with symbolic AI. This
integration has many promises, such as decreasing the amount of data required
to train a neural network, improving the explainability and interpretability of
answers given by models and verifying the correctness of trained systems. We
study neurosymbolic learning, where we have both data and background knowledge
expressed using symbolic languages. How do we connect the symbolic and neural
components to communicate this knowledge? One option is fuzzy reasoning, which
studies degrees of truth. For example, being tall is not a binary concept.
Instead, probabilistic reasoning studies the probability that something is true
or will happen. Our first research question studies how different forms of
fuzzy reasoning combine with learning. We find surprising results like a
connection to the Raven paradox stating we confirm "ravens are black" when we
observe a green apple. In this study, we did not use the background knowledge
when we deployed our models after training. In our second research question, we
studied how to use background knowledge in deployed models. We developed a new
neural network layer based on fuzzy reasoning. Probabilistic reasoning is a
natural fit for neural networks, which we usually train to be probabilistic.
However, they are expensive to compute and do not scale well to large tasks. In
our third research question, we study how to connect probabilistic reasoning
with neural networks by sampling to estimate averages, while in the final
research question, we study scaling probabilistic neurosymbolic learning to
much larger problems than before. Our insight is to train a neural network with
synthetic data to predict the result of probabilistic reasoning.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10820" title="Abstract">arXiv:2401.10820</a> [<a href="/pdf/2401.10820" title="Download PDF">pdf</a>, <a href="/format/2401.10820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Help Me Reflect: Leveraging Self-Reflection Interface Nudges to Enhance  Deliberativeness on Online Deliberation Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeo%2C+S+Y">Shun Yi Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+G">Gionnieve Lim</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Perrault%2C+S+T">Simon Tangi Perrault</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The deliberative potential of online platforms has been widely examined.
However, little is known about how various interface-based reflection nudges
impact the quality of deliberation. This paper presents two user studies with
12 and 120 participants, respectively, to investigate the impacts of different
reflective nudges on the quality of deliberation. In the first study, we
examined five distinct reflective nudges: persona, temporal prompts, analogies
and metaphors, cultural prompts and storytelling. Persona, temporal prompts,
and storytelling emerged as the preferred nudges for implementation on online
deliberation platforms. In the second study, we assess the impacts of these
preferred reflectors more thoroughly. Results revealed a significant positive
impact of these reflectors on deliberative quality. Specifically, persona
promotes a deliberative environment for balanced and opinionated viewpoints
while temporal prompts promote more individualised viewpoints. Our findings
suggest that the choice of reflectors can significantly influence the dynamics
and shape the nature of online discussions.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10822" title="Abstract">arXiv:2401.10822</a> [<a href="/pdf/2401.10822" title="Download PDF">pdf</a>, <a href="/format/2401.10822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ActAnywhere: Subject-Aware Video Background Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Boxiao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C+P">Chun-Hao Paul Huang</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K+K">Krishna Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L+J">Leonidas J. Guibas</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jimei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating video background that tailors to foreground subject motion is an
important problem for the movie industry and visual effects community. This
task involves synthesizing background that aligns with the motion and
appearance of the foreground subject, while also complies with the artist's
creative intention. We introduce ActAnywhere, a generative model that automates
this process which traditionally requires tedious manual efforts. Our model
leverages the power of large-scale video diffusion models, and is specifically
tailored for this task. ActAnywhere takes a sequence of foreground subject
segmentation as input and an image that describes the desired scene as
condition, to produce a coherent video with realistic foreground-background
interactions while adhering to the condition frame. We train our model on a
large-scale dataset of human-scene interaction videos. Extensive evaluations
demonstrate the superior performance of our model, significantly outperforming
baselines. Moreover, we show that ActAnywhere generalizes to diverse
out-of-distribution samples, including non-human subjects. Please visit our
project webpage at https://actanywhere.github.io.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10823" title="Abstract">arXiv:2401.10823</a> [<a href="/pdf/2401.10823" title="Download PDF">pdf</a>, <a href="/ps/2401.10823" title="Download PostScript">ps</a>, <a href="/format/2401.10823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Intelligent Surface (RIS)-Assisted Entanglement  Distribution in FSO Quantum Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chehimi%2C+M">Mahdi Chehimi</a>, 
<a href="/search/cs?searchtype=author&query=Elhattab%2C+M">Mohamed Elhattab</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>, 
<a href="/search/cs?searchtype=author&query=Vardoyan%2C+G">Gayane Vardoyan</a>, 
<a href="/search/cs?searchtype=author&query=Panigrahy%2C+N+K">Nitish K. Panigrahy</a>, 
<a href="/search/cs?searchtype=author&query=Assi%2C+C">Chadi Assi</a>, 
<a href="/search/cs?searchtype=author&query=Towsley%2C+D">Don Towsley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Quantum networks (QNs) relying on free-space optical (FSO) quantum channels
can support quantum applications in environments wherein establishing an
optical fiber infrastructure is challenging and costly. However, FSO-based QNs
require a clear line-of-sight (LoS) between users, which is challenging due to
blockages and natural obstacles. In this paper, a reconfigurable intelligent
surface (RIS)-assisted FSO-based QN is proposed as a cost-efficient framework
providing a virtual LoS between users for entanglement distribution. A novel
modeling of the quantum noise and losses experienced by quantum states over FSO
channels defined by atmospheric losses, turbulence, and pointing errors is
derived. Then, the joint optimization of entanglement distribution and RIS
placement problem is formulated, under heterogeneous entanglement rate and
fidelity constraints. This problem is solved using a simulated annealing
metaheuristic algorithm. Simulation results show that the proposed framework
effectively meets the minimum fidelity requirements of all users' quantum
applications. This is in stark contrast to baseline algorithms that lead to a
drop of at least 83% in users' end-to-end fidelities. The proposed framework
also achieves a 64% enhancement in the fairness level between users compared to
baseline rate maximizing frameworks. Finally, the weather conditions, e.g.,
rain, are observed to have a more significant effect than pointing errors and
turbulence.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10825" title="Abstract">arXiv:2401.10825</a> [<a href="/pdf/2401.10825" title="Download PDF">pdf</a>, <a href="/format/2401.10825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A survey on recent advances in named entity recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keraghel%2C+I">Imed Keraghel</a>, 
<a href="/search/cs?searchtype=author&query=Morbieu%2C+S">Stanislas Morbieu</a>, 
<a href="/search/cs?searchtype=author&query=Nadif%2C+M">Mohamed Nadif</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Named Entity Recognition seeks to extract substrings within a text that name
real-world objects and to determine their type (for example, whether they refer
to persons or organizations). In this survey, we first present an overview of
recent popular approaches, but we also look at graph- and transformer- based
methods including Large Language Models (LLMs) that have not had much coverage
in other surveys. Second, we focus on methods designed for datasets with scarce
annotations. Third, we evaluate the performance of the main NER implementations
on a variety of datasets with differing characteristics (as regards their
domain, their size, and their number of classes). We thus provide a deep
comparison of algorithms that are never considered together. Our experiments
shed some light on how the characteristics of datasets affect the behavior of
the methods that we compare.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10831" title="Abstract">arXiv:2401.10831</a> [<a href="/pdf/2401.10831" title="Download PDF">pdf</a>, <a href="/format/2401.10831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Video Transformers via Universal Concept Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kowal%2C+M">Matthew Kowal</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+A">Achal Dave</a>, 
<a href="/search/cs?searchtype=author&query=Ambrus%2C+R">Rares Ambrus</a>, 
<a href="/search/cs?searchtype=author&query=Gaidon%2C+A">Adrien Gaidon</a>, 
<a href="/search/cs?searchtype=author&query=Derpanis%2C+K+G">Konstantinos G. Derpanis</a>, 
<a href="/search/cs?searchtype=author&query=Tokmakov%2C+P">Pavel Tokmakov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">This paper studies the problem of concept-based interpretability of
transformer representations for videos. Concretely, we seek to explain the
decision-making process of video transformers based on high-level,
spatiotemporal concepts that are automatically discovered. Prior research on
concept-based interpretability has concentrated solely on image-level tasks.
Comparatively, video models deal with the added temporal dimension, increasing
complexity and posing challenges in identifying dynamic concepts over time. In
this work, we systematically address these challenges by introducing the first
Video Transformer Concept Discovery (VTCD) algorithm. To this end, we propose
an efficient approach for unsupervised identification of units of video
transformer representations - concepts, and ranking their importance to the
output of a model. The resulting concepts are highly interpretable, revealing
spatio-temporal reasoning mechanisms and object-centric representations in
unstructured video models. Performing this analysis jointly over a diverse set
of supervised and self-supervised representations, we discover that some of
these mechanism are universal in video transformers. Finally, we demonstrate
that VTCDcan be used to improve model performance for fine-grained tasks.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10833" title="Abstract">arXiv:2401.10833</a> [<a href="/pdf/2401.10833" title="Download PDF">pdf</a>, <a href="/format/2401.10833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality Requirements for Code: On the Untapped Potential in  Maintainability Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borg%2C+M">Markus Borg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the 1st Workshop on Multi-disciplinary, Open, and RElevant Requirements Engineering (MO2RE), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Quality requirements are critical for successful software engineering, with
maintainability being a key internal quality. Despite significant attention in
software metrics research, maintainability has attracted surprisingly little
focus in the Requirements Engineering (RE) community. This position paper
proposes a synergistic approach, combining code-oriented research with RE
expertise, to create meaningful industrial impact. We introduce six
illustrative use cases and propose three future research directions.
Preliminary findings indicate that the established QUPER model, designed for
setting quality targets, does not adequately address the unique aspects of
maintainability.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10834" title="Abstract">arXiv:2401.10834</a> [<a href="/pdf/2401.10834" title="Download PDF">pdf</a>, <a href="/format/2401.10834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cppless: Productive and Performant Serverless Programming in C++
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%B6ller%2C+L">Lukas M&#xf6;ller</a>, 
<a href="/search/cs?searchtype=author&query=Copik%2C+M">Marcin Copik</a>, 
<a href="/search/cs?searchtype=author&query=Calotoiu%2C+A">Alexandru Calotoiu</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The rise of serverless introduced a new class of scalable, elastic and highly
available parallel workers in the cloud. Many systems and applications benefit
from offloading computations and parallel tasks to dynamically allocated
resources. However, the developers of C++ applications found it difficult to
integrate functions due to complex deployment, lack of compatibility between
client and cloud environments, and loosely typed input and output data. To
enable single-source and efficient serverless acceleration in C++, we introduce
Cppless, an end-to-end framework for implementing serverless functions which
handles the creation, deployment, and invocation of functions. Cppless is built
on top of LLVM and requires only two compiler extensions to automatically
extract C++ function objects and deploy them to the cloud. We demonstrate that
offloading parallel computations from a C++ application to serverless workers
can provide up to 30x speedup, requiring only minor code modifications and
costing less than one cent per computation.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10837" title="Abstract">arXiv:2401.10837</a> [<a href="/pdf/2401.10837" title="Download PDF">pdf</a>, <a href="/ps/2401.10837" title="Download PostScript">ps</a>, <a href="/format/2401.10837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aerial Field Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+M">Mihir Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+B">Brady Moon</a>, 
<a href="/search/cs?searchtype=author&query=Alexis%2C+K">Kostas Alexis</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the Encyclopedia of Robotics, Springer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Aerial field robotics research represents the domain of study that aims to
equip unmanned aerial vehicles - and as it pertains to this chapter,
specifically Micro Aerial Vehicles (MAVs)- with the ability to operate in
real-life environments that present challenges to safe navigation. We present
the key elements of autonomy for MAVs that are resilient to collisions and
sensing degradation, while operating under constrained computational resources.
We overview aspects of the state of the art, outline bottlenecks to resilient
navigation autonomy, and overview the field-readiness of MAVs. We conclude with
notable contributions and discuss considerations for future research that are
essential for resilience in aerial robotics.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10838" title="Abstract">arXiv:2401.10838</a> [<a href="/pdf/2401.10838" title="Download PDF">pdf</a>, <a href="/format/2401.10838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rambler: Supporting Writing With Speech via LLM-Assisted Gist  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Susan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Warner%2C+J">Jeremy Warner</a>, 
<a href="/search/cs?searchtype=author&query=Zamfirescu-Pereira%2C+J+D">J.D. Zamfirescu-Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M+G">Matthew G. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sauhard Jain</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M+X">Michael Xuelin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lertvittayakumjorn%2C+P">Piyawat Lertvittayakumjorn</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shanqing Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+S">Shumin Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+B">Bj&#xf6;rn Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Can Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ACM CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Dictation enables efficient text input on mobile devices. However, writing
with speech can produce disfluent, wordy, and incoherent text and thus requires
heavy post-processing. This paper presents Rambler, an LLM-powered graphical
user interface that supports gist-level manipulation of dictated text with two
main sets of functions: gist extraction and macro revision. Gist extraction
generates keywords and summaries as anchors to support the review and
interaction with spoken text. LLM-assisted macro revisions allow users to
respeak, split, merge and transform dictated text without specifying precise
editing locations. Together they pave the way for interactive dictation and
revision that help close gaps between spontaneous spoken words and
well-structured writing. In a comparative study with 12 participants performing
verbal composition tasks, Rambler outperformed the baseline of a speech-to-text
editor + ChatGPT, as it better facilitates iterative revisions with enhanced
user control over the content while supporting surprisingly diverse user
strategies.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10839" title="Abstract">arXiv:2401.10839</a> [<a href="/pdf/2401.10839" title="Download PDF">pdf</a>, <a href="/format/2401.10839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holonic Learning: A Flexible Agent-based Distributed Machine Learning  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esmaeili%2C+A">Ahmad Esmaeili</a>, 
<a href="/search/cs?searchtype=author&query=Ghorrati%2C+Z">Zahra Ghorrati</a>, 
<a href="/search/cs?searchtype=author&query=Matson%2C+E+T">Eric T. Matson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Ever-increasing ubiquity of data and computational resources in the last
decade have propelled a notable transition in the machine learning paradigm
towards more distributed approaches. Such a transition seeks to not only tackle
the scalability and resource distribution challenges but also to address
pressing privacy and security concerns. To contribute to the ongoing discourse,
this paper introduces Holonic Learning (HoL), a collaborative and
privacy-focused learning framework designed for training deep learning models.
By leveraging holonic concepts, the HoL framework establishes a structured
self-similar hierarchy in the learning process, enabling more nuanced control
over collaborations through the individual model aggregation approach of each
holon, along with their intra-holon commitment and communication patterns. HoL,
in its general form, provides extensive design and flexibility potentials. For
empirical analysis and to demonstrate its effectiveness, this paper implements
HoloAvg, a special variant of HoL that employs weighted averaging for model
aggregation across all holons. The convergence of the proposed method is
validated through experiments on both IID and Non-IID settings of the standard
MNISt dataset. Furthermore, the performance behaviors of HoL are investigated
under various holarchical designs and data distribution scenarios. The
presented results affirm HoL's prowess in delivering competitive performance
particularly, in the context of the Non-IID data distribution.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10840" title="Abstract">arXiv:2401.10840</a> [<a href="/pdf/2401.10840" title="Download PDF">pdf</a>, <a href="/format/2401.10840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic Cognitive Diagnosis via Hybrid Optimization for Intelligent  Education Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Junhao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Hong Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aimin Zhou</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cognitive diagnosis assessment is a fundamental and crucial task for student
learning. It models the student-exercise interaction, and discovers the
students' proficiency levels on each knowledge attribute. In real-world
intelligent education systems, generalization and interpretability of cognitive
diagnosis methods are of equal importance. However, most existing methods can
hardly make the best of both worlds due to the complicated student-exercise
interaction. To this end, this paper proposes a symbolic cognitive
diagnosis~(SCD) framework to simultaneously enhance generalization and
interpretability. The SCD framework incorporates the symbolic tree to
explicably represent the complicated student-exercise interaction function, and
utilizes gradient-based optimization methods to effectively learn the student
and exercise parameters. Meanwhile, the accompanying challenge is that we need
to tunnel the discrete symbolic representation and continuous parameter
optimization. To address this challenge, we propose to hybridly optimize the
representation and parameters in an alternating manner. To fulfill SCD, it
alternately learns the symbolic tree by derivative-free genetic programming and
learns the student and exercise parameters via gradient-based Adam. The
extensive experimental results on various real-world datasets show the
superiority of SCD on both generalization and interpretability. The ablation
study verifies the efficacy of each ingredient in SCD, and the case study
explicitly showcases how the interpretable ability of SCD works.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10841" title="Abstract">arXiv:2401.10841</a> [<a href="/pdf/2401.10841" title="Download PDF">pdf</a>, <a href="/format/2401.10841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using LLMs to discover emerging coded antisemitic hate-speech emergence  in extremist social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kikkisetti%2C+D">Dhanush Kikkisetti</a>, 
<a href="/search/cs?searchtype=author&query=Mustafa%2C+R+U">Raza Ul Mustafa</a>, 
<a href="/search/cs?searchtype=author&query=Melillo%2C+W">Wendy Melillo</a>, 
<a href="/search/cs?searchtype=author&query=Corizzo%2C+R">Roberto Corizzo</a>, 
<a href="/search/cs?searchtype=author&query=Boukouvalas%2C+Z">Zois Boukouvalas</a>, 
<a href="/search/cs?searchtype=author&query=Gill%2C+J">Jeff Gill</a>, 
<a href="/search/cs?searchtype=author&query=Japkowicz%2C+N">Nathalie Japkowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 2 algorithms, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Online hate speech proliferation has created a difficult problem for social
media platforms. A particular challenge relates to the use of coded language by
groups interested in both creating a sense of belonging for its users and
evading detection. Coded language evolves quickly and its use varies over time.
This paper proposes a methodology for detecting emerging coded hate-laden
terminology. The methodology is tested in the context of online antisemitic
discourse. The approach considers posts scraped from social media platforms,
often used by extremist users. The posts are scraped using seed expressions
related to previously known discourse of hatred towards Jews. The method begins
by identifying the expressions most representative of each post and calculating
their frequency in the whole corpus. It filters out grammatically incoherent
expressions as well as previously encountered ones so as to focus on emergent
well-formed terminology. This is followed by an assessment of semantic
similarity to known antisemitic terminology using a fine-tuned large language
model, and subsequent filtering out of the expressions that are too distant
from known expressions of hatred. Emergent antisemitic expressions containing
terms clearly relating to Jewish topics are then removed to return only coded
expressions of hatred.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10843" title="Abstract">arXiv:2401.10843</a> [<a href="/pdf/2401.10843" title="Download PDF">pdf</a>, <a href="/format/2401.10843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training a General Spiking Neural Network with Improved Efficiency and  Minimum Latency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yunpeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Man Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renyuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) that operate in an event-driven manner and
employ binary spike representation have recently emerged as promising
candidates for energy-efficient computing. However, a cost bottleneck arises in
obtaining high-performance SNNs: training a SNN model requires a large number
of time steps in addition to the usual learning iterations, hence this limits
their energy efficiency. This paper proposes a general training framework that
enhances feature learning and activation efficiency within a limited time step,
providing a new solution for more energy-efficient SNNs. Our framework allows
SNN neurons to learn robust spike feature from different receptive fields and
update neuron states by utilizing both current stimuli and recurrence
information transmitted from other neurons. This setting continuously
complements information within a single time step. Additionally, we propose a
projection function to merge these two stimuli to smoothly optimize neuron
weights (spike firing threshold and activation). We evaluate the proposal for
both convolution and recurrent models. Our experimental results indicate
state-of-the-art visual classification tasks, including CIFAR10, CIFAR100, and
TinyImageNet.Our framework achieves 72.41% and 72.31% top-1 accuracy with only
1 time step on CIFAR100 for CNNs and RNNs, respectively. Our method reduces 10x
and 3x joule energy than a standard ANN and SNN, respectively, on CIFAR10,
without additional time steps.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10844" title="Abstract">arXiv:2401.10844</a> [<a href="/pdf/2401.10844" title="Download PDF">pdf</a>, <a href="/ps/2401.10844" title="Download PostScript">ps</a>, <a href="/format/2401.10844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Population Decoding and Imbalanced Multi-Omic Datasets For Cancer  Subtype Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kent%2C+C+T">Charles Theodore Kent</a>, 
<a href="/search/cs?searchtype=author&query=Bagheriye%2C+L">Leila Bagheriye</a>, 
<a href="/search/cs?searchtype=author&query=Kwisthout%2C+J">Johan Kwisthout</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted in BIOINFORMATICS 2024 (BIOSTEC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG); Genomics (q-bio.GN); Quantitative Methods (q-bio.QM); Applications (stat.AP)

</div>
<p class="mathjax">Recent strides in the field of neural computation has seen the adoption of
Winner Take All (WTA) circuits to facilitate the unification of hierarchical
Bayesian inference and spiking neural networks as a neurobiologically plausible
model of information processing. Current research commonly validates the
performance of these networks via classification tasks, particularly of the
MNIST dataset. However, researchers have not yet reached consensus about how
best to translate the stochastic responses from these networks into discrete
decisions, a process known as population decoding. Despite being an often
underexamined part of SNNs, in this work we show that population decoding has a
significanct impact on the classification performance of WTA networks. For this
purpose, we apply a WTA network to the problem of cancer subtype diagnosis from
multi omic data, using datasets from The Cancer Genome Atlas (TCGA). In doing
so we utilise a novel implementation of gene similarity networks, a feature
encoding technique based on Kohoens self organising map algorithm. We further
show that the impact of selecting certain population decoding methods is
amplified when facing imbalanced datasets.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10845" title="Abstract">arXiv:2401.10845</a> [<a href="/pdf/2401.10845" title="Download PDF">pdf</a>, <a href="/format/2401.10845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion Classification In Software Engineering Texts: A Comparative  Analysis of Pre-trained Transformers Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imran%2C+M+M">Mia Mohammad Imran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Emotion recognition in software engineering texts is critical for
understanding developer expressions and improving collaboration. This paper
presents a comparative analysis of state-of-the-art Pre-trained Language Models
(PTMs) for fine-grained emotion classification on two benchmark datasets from
GitHub and Stack Overflow. We evaluate six transformer models - BERT, RoBERTa,
ALBERT, DeBERTa, CodeBERT and GraphCodeBERT against the current best-performing
tool SEntiMoji. Our analysis reveals consistent improvements ranging from
1.17\% to 16.79\% in terms of macro-averaged and micro-averaged F1 scores, with
general domain models outperforming specialized ones. To further enhance PTMs,
we incorporate polarity features in attention layer during training,
demonstrating additional average gains of 1.0\% to 10.23\% over baseline PTMs
approaches. Our work provides strong evidence for the advancements afforded by
PTMs in recognizing nuanced emotions like Anger, Love, Fear, Joy, Sadness, and
Surprise in software engineering contexts. Through comprehensive benchmarking
and error analysis, we also outline scope for improvements to address
contextual gaps.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10846" title="Abstract">arXiv:2401.10846</a> [<a href="/pdf/2401.10846" title="Download PDF">pdf</a>, <a href="/format/2401.10846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Genetic Algorithm for Feature Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potter%2C+M">Michael Potter</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1z%2C+A+Y">Ayberk Yark&#x131;n Y&#x131;ld&#x131;z</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+N+M">Nishanth Marer Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Gordon%2C+C">Cameron Gordon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We empirically show that process-based Parallelism speeds up the Genetic
Algorithm (GA) for Feature Selection (FS) 2x to 25x, while additionally
increasing the Machine Learning (ML) model performance on metrics such as
F1-score, Accuracy, and Receiver Operating Characteristic Area Under the Curve
(ROC-AUC).
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10848" title="Abstract">arXiv:2401.10848</a> [<a href="/pdf/2401.10848" title="Download PDF">pdf</a>, <a href="/format/2401.10848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source-Free and Image-Only Unsupervised Domain Adaptation for Category  Level Object Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaushik%2C+P">Prakhar Kaushik</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Aayush Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Kortylewski%2C+A">Adam Kortylewski</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 9 figures, 50 tables; ICLR 2024 (Poster)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider the problem of source-free unsupervised category-level pose
estimation from only RGB images to a target domain without any access to source
domain data or 3D annotations during adaptation. Collecting and annotating
real-world 3D data and corresponding images is laborious, expensive, yet
unavoidable process, since even 3D pose domain adaptation methods require 3D
data in the target domain. We introduce 3DUDA, a method capable of adapting to
a nuisance-ridden target domain without 3D or depth data. Our key insight stems
from the observation that specific object subparts remain stable across
out-of-domain (OOD) scenarios, enabling strategic utilization of these
invariant subcomponents for effective model updates. We represent object
categories as simple cuboid meshes, and harness a generative model of neural
feature activations modeled at each mesh vertex learnt using differential
rendering. We focus on individual locally robust mesh vertex features and
iteratively update them based on their proximity to corresponding features in
the target domain even when the global pose is not correct. Our model is then
trained in an EM fashion, alternating between updating the vertex features and
the feature extractor. We show that our method simulates fine-tuning on a
global pseudo-labeled dataset under mild assumptions, which converges to the
target domain asymptotically. Through extensive empirical validation, including
a complex extreme UDA setup which combines real nuisances, synthetic noise, and
occlusion, we demonstrate the potency of our simple approach in addressing the
domain shift challenge and significantly improving pose estimation accuracy.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10849" title="Abstract">arXiv:2401.10849</a> [<a href="/pdf/2401.10849" title="Download PDF">pdf</a>, <a href="/format/2401.10849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the role of structure in a time constrained decision task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaix-Eichel%2C+N">Naomi Chaix-Eichel</a>, 
<a href="/search/cs?searchtype=author&query=Venugopal%2C+G">Gautham Venugopal</a>, 
<a href="/search/cs?searchtype=author&query=Boraud%2C+T">Thomas Boraud</a>, 
<a href="/search/cs?searchtype=author&query=Rougier%2C+N+P">Nicolas P. Rougier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">The structure of the basal ganglia is remarkably similar across a number of
species (often described in terms of direct, indirect and hyperdirect pathways)
and is deeply involved in decision making and action selection. In this
article, we are interested in exploring the role of structure when solving a
decision task while avoiding to make any strong assumption regarding the actual
structure. To do so, we exploit the echo state network paradigm that allows to
solve complex task based on a random architecture. Considering a temporal
decision task, the question is whether a specific structure allows for better
performance and if so, whether this structure shares some similarity with the
basal ganglia. Our results highlight the advantage of having a slow (direct)
and a fast (hyperdirect) pathway that allows to deal with late information
during a decision making task.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10850" title="Abstract">arXiv:2401.10850</a> [<a href="/pdf/2401.10850" title="Download PDF">pdf</a>, <a href="/format/2401.10850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements in eHealth Data Analytics through Natural Language  Processing and Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Apostol%2C+E">Elena-Simona Apostol</a>, 
<a href="/search/cs?searchtype=author&query=Truic%C4%83%2C+C">Ciprian-Octavian Truic&#x103;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The healthcare environment is commonly referred to as "information-rich" but
also "knowledge poor". Healthcare systems collect huge amounts of data from
various sources: lab reports, medical letters, logs of medical tools or
programs, medical prescriptions, etc. These massive sets of data can provide
great knowledge and information that can improve the medical services, and
overall the healthcare domain, such as disease prediction by analyzing the
patient's symptoms or disease prevention, by facilitating the discovery of
behavioral factors for diseases. Unfortunately, only a relatively small volume
of the textual eHealth data is processed and interpreted, an important factor
being the difficulty in efficiently performing Big Data operations. In the
medical field, detecting domain-specific multi-word terms is a crucial task as
they can define an entire concept with a few words. A term can be defined as a
linguistic structure or a concept, and it is composed of one or more words with
a specific meaning to a domain. All the terms of a domain create its
terminology. This chapter offers a critical study of the current, most
performant solutions for analyzing unstructured (image and textual) eHealth
data. This study also provides a comparison of the current Natural Language
Processing and Deep Learning techniques in the eHealth context. Finally, we
examine and discuss some of the current issues, and we define a set of research
directions in this area.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10852" title="Abstract">arXiv:2401.10852</a> [<a href="/pdf/2401.10852" title="Download PDF">pdf</a>, <a href="/format/2401.10852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Resource Disaggregation for HPC with Serverless Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Copik%2C+M">Marcin Copik</a>, 
<a href="/search/cs?searchtype=author&query=Chrapek%2C+M">Marcin Chrapek</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+L">Larissa Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Calotoiu%2C+A">Alexandru Calotoiu</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Aggregated HPC resources have rigid allocation systems and programming models
which struggle to adapt to diverse and changing workloads. Consequently, HPC
systems fail to efficiently use the large pools of unused memory and increase
the utilization of idle computing resources. Prior work attempted to increase
the throughput and efficiency of supercomputing systems through workload
co-location and resource disaggregation. However, these methods fall short of
providing a solution that can be applied to existing systems without major
hardware modifications and performance losses. In this paper, we improve the
utilization of supercomputers by employing the new cloud paradigm of serverless
computing. We show how serverless functions provide fine-grained access to the
resources of batch-managed cluster nodes. We present an HPC-oriented
Function-as-a-Service (FaaS) that satisfies the requirements of
high-performance applications. We demonstrate a \emph{software resource
disaggregation} approach where placing functions on unallocated and
underutilized nodes allows idle cores and accelerators to be utilized while
retaining near-native performance.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10856" title="Abstract">arXiv:2401.10856</a> [<a href="/pdf/2401.10856" title="Download PDF">pdf</a>, <a href="/format/2401.10856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cactus Representation of Minimum Cuts: Derandomize and Speed up
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhongtian He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shang-En Huang</a>, 
<a href="/search/cs?searchtype=author&query=Saranurak%2C+T">Thatchaphol Saranurak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Given an undirected weighted graph with $n$ vertices and $m$ edges, we give
the first deterministic $m^{1+o(1)}$-time algorithm for constructing the cactus
representation of \emph{all} global minimum cuts. This improves the current
$n^{2+o(1)}$-time state-of-the-art deterministic algorithm, which can be
obtained by combining ideas implicitly from three papers [Karger JACM'2000, Li
STOC'2021, and Gabow TALG'2016] The known explicitly stated deterministic
algorithm has a runtime of $\tilde{O}(mn)$ [Fleischer 1999, Nagamochi and Nakao
2000]. Using our technique, we can even speed up the fastest randomized
algorithm of [Karger and Panigrahi, SODA'2009] whose running time is at least
$\Omega(m\log^4 n)$ to $O(m\log^3 n)$.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10857" title="Abstract">arXiv:2401.10857</a> [<a href="/pdf/2401.10857" title="Download PDF">pdf</a>, <a href="/format/2401.10857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Consistency Loss for Monocular Visual Odometry with  Attention-Based Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fran%C3%A7ani%2C+A+O">Andr&#xe9; O. Fran&#xe7;ani</a>, 
<a href="/search/cs?searchtype=author&query=Maximo%2C+M+R+O+A">Marcos R. O. A. Maximo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Deep learning algorithms have driven expressive progress in many complex
tasks. The loss function is a core component of deep learning techniques,
guiding the learning process of neural networks. This paper contributes by
introducing a consistency loss for visual odometry with deep learning-based
approaches. The motion consistency loss explores repeated motions that appear
in consecutive overlapped video clips. Experimental results show that our
approach increased the performance of a model on the KITTI odometry benchmark.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10859" title="Abstract">arXiv:2401.10859</a> [<a href="/pdf/2401.10859" title="Download PDF">pdf</a>, <a href="/format/2401.10859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensembler: Combating model inversion attacks using model ensemble during  collaborative inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dancheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jinjun Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning models have exhibited remarkable performance across various
domains. Nevertheless, the burgeoning model sizes compel edge devices to
offload a significant portion of the inference process to the cloud. While this
practice offers numerous advantages, it also raises critical concerns regarding
user data privacy. In scenarios where the cloud server's trustworthiness is in
question, the need for a practical and adaptable method to safeguard data
privacy becomes imperative. In this paper, we introduce Ensembler, an
extensible framework designed to substantially increase the difficulty of
conducting model inversion attacks for adversarial parties. Ensembler leverages
model ensembling on the adversarial server, running in parallel with existing
approaches that introduce perturbations to sensitive data during colloborative
inference. Our experiments demonstrate that when combined with even basic
Gaussian noise, Ensembler can effectively shield images from reconstruction
attacks, achieving recognition levels that fall below human performance in some
strict settings, significantly outperforming baseline methods lacking the
Ensembler framework.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10862" title="Abstract">arXiv:2401.10862</a> [<a href="/pdf/2401.10862" title="Download PDF">pdf</a>, <a href="/format/2401.10862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs  Without Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+A">Adib Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Rugina%2C+I">Ileana Rugina</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Alex Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Large Language Models (LLMs) are vulnerable to `Jailbreaking' prompts, a type
of attack that can coax these models into generating harmful and illegal
content. In this paper, we show that pruning up to 20% of LLM parameters
markedly increases their resistance to such attacks without additional training
and without sacrificing their performance in standard benchmarks. Intriguingly,
we discovered that the enhanced safety observed post-pruning correlates to the
initial safety training level of the model, hinting that the effect of pruning
could be more general and may hold for other LLM behaviors beyond safety.
Additionally, we introduce a curated dataset of 225 harmful tasks across five
categories, inserted into ten different Jailbreaking prompts, showing that
pruning aids LLMs in concentrating attention on task-relevant tokens in
jailbreaking prompts. Lastly, our experiments reveal that the prominent chat
models, such as LLaMA-2 Chat, Vicuna, and Mistral Instruct exhibit high
susceptibility to jailbreaking attacks, with some categories achieving nearly
70-100% success rate. These insights underline the potential of pruning as a
generalizable approach for improving LLM safety, reliability, and potentially
other desired behaviors.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10873" title="Abstract">arXiv:2401.10873</a> [<a href="/pdf/2401.10873" title="Download PDF">pdf</a>, <a href="/format/2401.10873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An AI-Resilient Text Rendering Technique for Reading and Skimming  Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Ziwei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Arawjo%2C+I">Ian Arawjo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kenneth Li</a>, 
<a href="/search/cs?searchtype=author&query=Kummerfeld%2C+J+K">Jonathan K. Kummerfeld</a>, 
<a href="/search/cs?searchtype=author&query=Glassman%2C+E+L">Elena L. Glassman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conditionally accepted to CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Readers find text difficult to consume for many reasons. Summarization can
address some of these difficulties, but introduce others, such as omitting,
misrepresenting, or hallucinating information, which can be hard for a reader
to notice. One approach to addressing this problem is to instead modify how the
original text is rendered to make important information more salient. We
introduce Grammar-Preserving Text Saliency Modulation (GP-TSM), a text
rendering method with a novel means of identifying what to de-emphasize.
Specifically, GP-TSM uses a recursive sentence compression method to identify
successive levels of detail beyond the core meaning of a passage, which are
de-emphasized by rendering words in successively lighter but still legible gray
text. In a lab study (n=18), participants preferred GP-TSM over pre-existing
word-level text rendering methods and were able to answer GRE reading
comprehension questions more efficiently.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10877" title="Abstract">arXiv:2401.10877</a> [<a href="/pdf/2401.10877" title="Download PDF">pdf</a>, <a href="/format/2401.10877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Cadaver in the Machine: The Social Practices of Measurement and  Validation in Motion Capture Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harvey%2C+E">Emma Harvey</a>, 
<a href="/search/cs?searchtype=author&query=Sandhaus%2C+H">Hauke Sandhaus</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+A+Z">Abigail Z. Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Moss%2C+E">Emanuel Moss</a>, 
<a href="/search/cs?searchtype=author&query=Sloane%2C+M">Mona Sloane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 figures. To appear in the 2024 ACM CHI Conference on Human Factors in Computing Systems (CHI '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Motion capture systems, used across various domains, make body
representations concrete through technical processes. We argue that the
measurement of bodies and the validation of measurements for motion capture
systems can be understood as social practices. By analyzing the findings of a
systematic literature review (N=278) through the lens of social practice
theory, we show how these practices, and their varying attention to errors,
become ingrained in motion capture design and innovation over time. Moreover,
we show how contemporary motion capture systems perpetuate assumptions about
human bodies and their movements. We suggest that social practices of
measurement and validation are ubiquitous in the development of data- and
sensor-driven systems more broadly, and provide this work as a basis for
investigating hidden design assumptions and their potential negative
consequences in human-computer interaction.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10879" title="Abstract">arXiv:2401.10879</a> [<a href="/pdf/2401.10879" title="Download PDF">pdf</a>, <a href="/ps/2401.10879" title="Download PostScript">ps</a>, <a href="/format/2401.10879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accuracy Analysis of Physics-Informed Neural Networks for Approximating  the Critical SQG Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Abdo%2C+E">Elie Abdo</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+R">Ruimeng Hu</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+Q">Quyuan Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We systematically analyze the accuracy of Physics-Informed Neural Networks
(PINNs) in approximating solutions to the critical Surface Quasi-Geostrophic
(SQG) equation on two-dimensional periodic boxes. The critical SQG equation
involves advection and diffusion described by nonlocal periodic operators,
posing challenges for neural network-based methods that do not commonly exhibit
periodic boundary conditions. In this paper, we present a novel approximation
of these operators using their nonperiodic analogs based on singular integral
representation formulas and use it to perform error estimates. This idea can be
generalized to a larger class of nonlocal partial differential equations whose
solutions satisfy prescribed boundary conditions, thereby initiating a new
PINNs theory for equations with nonlocalities.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10880" title="Abstract">arXiv:2401.10880</a> [<a href="/pdf/2401.10880" title="Download PDF">pdf</a>, <a href="/format/2401.10880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynaVis: Dynamically Synthesized UI Widgets for Visualization Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaithilingam%2C+P">Priyan Vaithilingam</a>, 
<a href="/search/cs?searchtype=author&query=Glassman%2C+E+L">Elena L. Glassman</a>, 
<a href="/search/cs?searchtype=author&query=Inala%2C+J+P">Jeevana Priya Inala</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenglong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Users often rely on GUIs to edit and interact with visualizations - a
daunting task due to the large space of editing options. As a result, users are
either overwhelmed by a complex UI or constrained by a custom UI with a
tailored, fixed subset of options with limited editing flexibility. Natural
Language Interfaces (NLIs) are emerging as a feasible alternative for users to
specify edits. However, NLIs forgo the advantages of traditional GUI: the
ability to explore and repeat edits and see instant visual feedback.
<br />We introduce DynaVis, which blends natural language and dynamically
synthesized UI widgets. As the user describes an editing task in natural
language, DynaVis performs the edit and synthesizes a persistent widget that
the user can interact with to make further modifications. Study participants
(n=24) preferred DynaVis over the NLI-only interface citing ease of further
edits and editing confidence due to immediate visual feedback.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10882" title="Abstract">arXiv:2401.10882</a> [<a href="/pdf/2401.10882" title="Download PDF">pdf</a>, <a href="/format/2401.10882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement learning for question answering in programming domain  using public community scoring as a human feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorbatovski%2C+A">Alexey Gorbatovski</a>, 
<a href="/search/cs?searchtype=author&query=Kovalchuk%2C+S">Sergey Kovalchuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In this study, we investigate the enhancement of the GPT Neo 125M performance
in Community Question Answering (CQA) with a focus on programming, through the
integration of Reinforcement Learning from Human Feedback (RLHF) and the
utilization of scores from Stack Overflow. Two distinct reward model training
strategies are employed for fine-tuning with Proximal Policy Optimization
(PPO). Notably, the improvements in performance achieved through this method
are comparable to those of GPT Neo 2.7B parameter variant. Additionally, an
auxiliary scoring mechanism is introduced, which demonstrates the limitations
of conventional linguistic metrics in evaluating responses in the programming
domain. Through accurate analysis, this paper looks at the divergence between
traditional linguistic metrics and our human-preferences-based reward model,
underscoring the imperative for domain-specific evaluation methods. By
elucidating the complexities involved in applying RLHF to programming CQA and
accentuating the significance of context-aware evaluation, this study
contributes to the ongoing efforts in refining Large Language Models through
focused human feedback.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10883" title="Abstract">arXiv:2401.10883</a> [<a href="/pdf/2401.10883" title="Download PDF">pdf</a>, <a href="/ps/2401.10883" title="Download PostScript">ps</a>, <a href="/format/2401.10883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RetinaVR: Democratizing Vitreoretinal Surgery Training with a Portable  and Affordable Virtual Reality Simulator in the Metaverse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antaki%2C+F">Fares Antaki</a>, 
<a href="/search/cs?searchtype=author&query=Doucet%2C+C">C&#xe9;dryk Doucet</a>, 
<a href="/search/cs?searchtype=author&query=Milad%2C+D">Daniel Milad</a>, 
<a href="/search/cs?searchtype=author&query=Gigu%C3%A8re%2C+C">Charles-&#xc9;douard Gigu&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Ozell%2C+B">Benoit Ozell</a>, 
<a href="/search/cs?searchtype=author&query=Hammamji%2C+K">Karim Hammamji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We developed and validated RetinaVR, an affordable and immersive virtual
reality simulator for vitreoretinal surgery training, using the Meta Quest 2 VR
headset. We focused on four core fundamental skills: core vitrectomy,
peripheral shaving, membrane peeling, and endolaser application. The validation
study involved 10 novice ophthalmology residents and 10 expert vitreoretinal
surgeons. We demonstrated construct validity, as shown by the varying user
performance in a way that correlates with experimental runs, age, sex, and
expertise. RetinaVR shows promise as a portable and affordable simulator, with
potential to democratize surgical simulation access, especially in developing
countries.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10886" title="Abstract">arXiv:2401.10886</a> [<a href="/pdf/2401.10886" title="Download PDF">pdf</a>, <a href="/format/2401.10886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCENES: Subpixel Correspondence Estimation With Epipolar Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kloepfer%2C+D+A">Dominik A. Kloepfer</a>, 
<a href="/search/cs?searchtype=author&query=Henriques%2C+J+F">Jo&#xe3;o F. Henriques</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+D">Dylan Campbell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Extracting point correspondences from two or more views of a scene is a
fundamental computer vision problem with particular importance for relative
camera pose estimation and structure-from-motion. Existing local feature
matching approaches, trained with correspondence supervision on large-scale
datasets, obtain highly-accurate matches on the test sets. However, they do not
generalise well to new datasets with different characteristics to those they
were trained on, unlike classic feature extractors. Instead, they require
finetuning, which assumes that ground-truth correspondences or ground-truth
camera poses and 3D structure are available. We relax this assumption by
removing the requirement of 3D structure, e.g., depth maps or point clouds, and
only require camera pose information, which can be obtained from odometry. We
do so by replacing correspondence losses with epipolar losses, which encourage
putative matches to lie on the associated epipolar line. While weaker than
correspondence supervision, we observe that this cue is sufficient for
finetuning existing models on new data. We then further relax the assumption of
known camera poses by using pose estimates in a novel bootstrapping approach.
We evaluate on highly challenging datasets, including an indoor drone dataset
and an outdoor smartphone camera dataset, and obtain state-of-the-art results
without strong supervision.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10889" title="Abstract">arXiv:2401.10889</a> [<a href="/pdf/2401.10889" title="Download PDF">pdf</a>, <a href="/format/2401.10889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Moving People with 3D Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Rajasegaran%2C+J">Jathushan Rajasegaran</a>, 
<a href="/search/cs?searchtype=author&query=Gandelsman%2C+Y">Yossi Gandelsman</a>, 
<a href="/search/cs?searchtype=author&query=Efros%2C+A+A">Alexei A. Efros</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we present a diffusion model-based framework for animating
people from a single image for a given target 3D motion sequence. Our approach
has two core components: a) learning priors about invisible parts of the human
body and clothing, and b) rendering novel body poses with proper clothing and
texture. For the first part, we learn an in-filling diffusion model to
hallucinate unseen parts of a person given a single image. We train this model
on texture map space, which makes it more sample-efficient since it is
invariant to pose and viewpoint. Second, we develop a diffusion-based rendering
pipeline, which is controlled by 3D human poses. This produces realistic
renderings of novel poses of the person, including clothing, hair, and
plausible in-filling of unseen regions. This disentangled approach allows our
method to generate a sequence of images that are faithful to the target motion
in the 3D pose and, to the input image in terms of visual similarity. In
addition to that, the 3D control allows various synthetic camera trajectories
to render a person. Our experiments show that our method is resilient in
generating prolonged motions and varied challenging and complex poses compared
to prior methods. Please check our website for more details:
https://boyiliee.github.io/3DHM.github.io/.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10890" title="Abstract">arXiv:2401.10890</a> [<a href="/pdf/2401.10890" title="Download PDF">pdf</a>, <a href="/format/2401.10890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event detection from novel data sources: Leveraging satellite imagery  alongside GPS traces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ugurel%2C+E">Ekin Ugurel</a>, 
<a href="/search/cs?searchtype=author&query=Coenen%2C+S">Steffen Coenen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M+Z">Minda Zhou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cynthia Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Rapid identification and response to breaking events, particularly those that
pose a threat to human life such as natural disasters or conflicts, is of
paramount importance. The prevalence of mobile devices and the ubiquity of
network connectivity has generated a massive amount of temporally- and
spatially-stamped data. Numerous studies have used mobile data to derive
individual human mobility patterns for various applications. Similarly, the
increasing number of orbital satellites has made it easier to gather
high-resolution images capturing a snapshot of a geographical area in sub-daily
temporal frequency. We propose a novel data fusion methodology integrating
satellite imagery with privacy-enhanced mobile data to augment the event
inference task, whether in real-time or historical. In the absence of boots on
the ground, mobile data is able to give an approximation of human mobility,
proximity to one another, and the built environment. On the other hand,
satellite imagery can provide visual information on physical changes to the
built and natural environment. The expected use cases for our methodology
include small-scale disaster detection (i.e., tornadoes, wildfires, and floods)
in rural regions, search and rescue operation augmentation for lost hikers in
remote wilderness areas, and identification of active conflict areas and
population displacement in war-torn states. Our implementation is open-source
on GitHub: https://github.com/ekinugurel/SatMobFusion.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10891" title="Abstract">arXiv:2401.10891</a> [<a href="/pdf/2401.10891" title="Download PDF">pdf</a>, <a href="/format/2401.10891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lihe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bingyi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zilong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://depth-anything.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work presents Depth Anything, a highly practical solution for robust
monocular depth estimation. Without pursuing novel technical modules, we aim to
build a simple yet powerful foundation model dealing with any images under any
circumstances. To this end, we scale up the dataset by designing a data engine
to collect and automatically annotate large-scale unlabeled data (~62M), which
significantly enlarges the data coverage and thus is able to reduce the
generalization error. We investigate two simple yet effective strategies that
make data scaling-up promising. First, a more challenging optimization target
is created by leveraging data augmentation tools. It compels the model to
actively seek extra visual knowledge and acquire robust representations.
Second, an auxiliary supervision is developed to enforce the model to inherit
rich semantic priors from pre-trained encoders. We evaluate its zero-shot
capabilities extensively, including six public datasets and randomly captured
photos. It demonstrates impressive generalization ability. Further, through
fine-tuning it with metric depth information from NYUv2 and KITTI, new SOTAs
are set. Our better depth model also results in a better depth-conditioned
ControlNet. Our models are released at
https://github.com/LiheYoung/Depth-Anything.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon, 22 Jan 24</h3>
<dl>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02573" title="Abstract">arXiv:2307.02573</a> (cross-list from quant-ph) [<a href="/pdf/2307.02573" title="Download PDF">pdf</a>, <a href="/format/2307.02573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of a Programmable Quantum Annealer as a Random Number Generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Pelofske%2C+E">Elijah Pelofske</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum annealing (QA) is a type of analog quantum computation that is a
relaxed form of adiabatic quantum computation and uses quantum fluctuations in
order to search for ground state solutions of a programmable Ising model. Here
we present extensive experimental random number results from a D-Wave 2000Q
quantum annealer, totaling over 20 billion bits of QA measurements, which is
significantly larger than previous D-Wave QA random number generator studies.
Current quantum annealers are susceptible to noise from environmental sources
and calibration errors, and are not in general unbiased samplers. Therefore, it
is of interest to quantify whether noisy quantum annealers can effectively
function as an unbiased QRNG. The amount of data that was collected from the
quantum annealer allows a comprehensive analysis of the random bits to be
performed using the NIST SP 800-22 Rev 1a testsuite, as well as min-entropy
estimates from NIST SP 800-90B. The randomness tests show that the generated
random bits from the D-Wave 2000Q are biased, and not unpredictable random bit
sequences. With no server-side sampling post-processing, the $1$ microsecond
annealing time measurements had a min-entropy of $0.824$.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10238" title="Abstract">arXiv:2401.10238</a> (cross-list from q-fin.GN) [<a href="/pdf/2401.10238" title="Download PDF">pdf</a>, <a href="/format/2401.10238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interplay between Cryptocurrency Transactions and Online Financial  Forums
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>, 
<a href="/search/q-fin?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/q-fin?searchtype=author&query=Cancela%2C+D+C">Daniel Couto Cancela</a>, 
<a href="/search/q-fin?searchtype=author&query=Pazos%2C+A+T">Alejandro Torrado Pazos</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematics 2021, 9(4), 411;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cryptocurrencies are a type of digital money meant to provide security and
anonymity while using cryptography techniques. Although cryptocurrencies
represent a breakthrough and provide some important benefits, their usage poses
some risks that are a result of the lack of supervising institutions and
transparency. Because disinformation and volatility is discouraging for
personal investors, cryptocurrencies emerged hand-in-hand with the
proliferation of online users' communities and forums as places to share
information that can alleviate users' mistrust. This research focuses on the
study of the interplay between these cryptocurrency forums and fluctuations in
cryptocurrency values. In particular, the most popular cryptocurrency Bitcoin
(BTC) and a related active discussion community, Bitcointalk, are analyzed.
This study shows that the activity of Bitcointalk forum keeps a direct
relationship with the trend in the values of BTC, therefore analysis of this
interaction would be a perfect base to support personal investments in a
non-regulated market and, to confirm whether cryptocurrency forums show
evidences to detect abnormal behaviors in BTC values as well as to predict or
estimate these values. The experiment highlights that forum data can explain
specific events in the financial field. It also underlines the relevance of
quotes (regular mechanism to response a post) at periods: (1) when there is a
high concentration of posts around certain topics; (2) when peaks in the BTC
price are observed; and, (3) when the BTC price gradually shifts downwards and
users intend to sell.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10255" title="Abstract">arXiv:2401.10255</a> (cross-list from econ.GN) [<a href="/pdf/2401.10255" title="Download PDF">pdf</a>, <a href="/format/2401.10255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nowcasting Madagascar&#x27;s real GDP using machine learning algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Ramaharo%2C+F">Franck Ramaharo</a>, 
<a href="/search/econ?searchtype=author&query=Rasolofomanana%2C+G">Gerzhino Rasolofomanana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We investigate the predictive power of different machine learning algorithms
to nowcast Madagascar's gross domestic product (GDP). We trained popular
regression models, including linear regularized regression (Ridge, Lasso,
Elastic-net), dimensionality reduction model (principal component regression),
k-nearest neighbors algorithm (k-NN regression), support vector regression
(linear SVR), and tree-based ensemble models (Random forest and XGBoost
regressions), on 10 Malagasy quarterly macroeconomic leading indicators over
the period 2007Q1--2022Q4, and we used simple econometric models as a
benchmark. We measured the nowcast accuracy of each model by calculating the
root mean square error (RMSE), mean absolute error (MAE), and mean absolute
percentage error (MAPE). Our findings reveal that the Ensemble Model, formed by
aggregating individual predictions, consistently outperforms traditional
econometric models. We conclude that machine learning models can deliver more
accurate and timely nowcasts of Malagasy economic performance and provide
policymakers with additional guidance for data-driven decision making.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10278" title="Abstract">arXiv:2401.10278</a> (cross-list from eess.SP) [<a href="/pdf/2401.10278" title="Download PDF">pdf</a>, <a href="/format/2401.10278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EEGFormer: Towards Transferable and Interpretable Large-Scale EEG  Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yuqi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+K">Kan Ren</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+K">Kaitao Song</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yansen Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+L">Lili Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preprint version of an ongoing work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Self-supervised learning has emerged as a highly effective approach in the
fields of natural language processing and computer vision. It is also
applicable to brain signals such as electroencephalography (EEG) data, given
the abundance of available unlabeled data that exist in a wide spectrum of
real-world medical applications ranging from seizure detection to wave
analysis. The existing works leveraging self-supervised learning on EEG
modeling mainly focus on pretraining upon each individual dataset corresponding
to a single downstream task, which cannot leverage the power of abundant data,
and they may derive sub-optimal solutions with a lack of generalization.
Moreover, these methods rely on end-to-end model learning which is not easy for
humans to understand. In this paper, we present a novel EEG foundation model,
namely EEGFormer, pretrained on large-scale compound EEG data. The pretrained
model cannot only learn universal representations on EEG signals with adaptable
performance on various downstream tasks but also provide interpretable outcomes
of the useful patterns within the data. To validate the effectiveness of our
model, we extensively evaluate it on various downstream tasks and assess the
performance under different transfer settings. Furthermore, we demonstrate how
the learned model exhibits transferable anomaly detection performance and
provides valuable interpretability of the acquired patterns via self-supervised
learning.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10280" title="Abstract">arXiv:2401.10280</a> (cross-list from eess.SP) [<a href="/pdf/2401.10280" title="Download PDF">pdf</a>, <a href="/format/2401.10280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GANs for EVT Based Model Parameter Estimation in Real-time  Ultra-Reliable Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Valiahdi%2C+P">Parmida Valiahdi</a>, 
<a href="/search/eess?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">The Ultra-Reliable Low-Latency Communications (URLLC) paradigm in
sixth-generation (6G) systems heavily relies on precise channel modeling,
especially when dealing with rare and extreme events within wireless
communication channels. This paper explores a novel methodology integrating
Extreme Value Theory (EVT) and Generative Adversarial Networks (GANs) to
achieve the precise channel modeling in real-time. The proposed approach
harnesses EVT by employing the Generalized Pareto Distribution (GPD) to model
the distribution of extreme events. Subsequently, Generative Adversarial
Networks (GANs) are employed to estimate the parameters of the GPD. In contrast
to conventional GAN configurations that focus on estimating the overall
distribution, the proposed approach involves the incorporation of an additional
block within the GAN structure. This specific augmentation is designed with the
explicit purpose of directly estimating the parameters of the Generalized
Pareto Distribution (GPD). Through extensive simulations across different
sample sizes, the proposed GAN based approach consistently demonstrates
superior adaptability, surpassing Maximum Likelihood Estimation (MLE),
particularly in scenarios with limited sample sizes.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10282" title="Abstract">arXiv:2401.10282</a> (cross-list from eess.SP) [<a href="/pdf/2401.10282" title="Download PDF">pdf</a>, <a href="/format/2401.10282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioDiffusion: A Versatile Diffusion Model for Biomedical Signal  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaomin Li</a>, 
<a href="/search/eess?searchtype=author&query=Sakevych%2C+M">Mykhailo Sakevych</a>, 
<a href="/search/eess?searchtype=author&query=Atkinson%2C+G">Gentry Atkinson</a>, 
<a href="/search/eess?searchtype=author&query=Metsis%2C+V">Vangelis Metsis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning tasks involving biomedical signals frequently grapple with
issues such as limited data availability, imbalanced datasets, labeling
complexities, and the interference of measurement noise. These challenges often
hinder the optimal training of machine learning algorithms. Addressing these
concerns, we introduce BioDiffusion, a diffusion-based probabilistic model
optimized for the synthesis of multivariate biomedical signals. BioDiffusion
demonstrates excellence in producing high-fidelity, non-stationary,
multivariate signals for a range of tasks including unconditional,
label-conditional, and signal-conditional generation. Leveraging these
synthesized signals offers a notable solution to the aforementioned challenges.
Our research encompasses both qualitative and quantitative assessments of the
synthesized data quality, underscoring its capacity to bolster accuracy in
machine learning tasks tied to biomedical signals. Furthermore, when juxtaposed
with current leading time-series generative models, empirical evidence suggests
that BioDiffusion outperforms them in biomedical signal generation quality.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10283" title="Abstract">arXiv:2401.10283</a> (cross-list from eess.SP) [<a href="/pdf/2401.10283" title="Download PDF">pdf</a>, <a href="/format/2401.10283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Window Stacking Meta-Models for Clinical EEG Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yixuan Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Kandasamy%2C+R">Rohan Kandasamy</a>, 
<a href="/search/eess?searchtype=author&query=Canham%2C+L+J+W">Luke J. W. Canham</a>, 
<a href="/search/eess?searchtype=author&query=Western%2C+D">David Western</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Windowing is a common technique in EEG machine learning classification and
other time series tasks. However, a challenge arises when employing this
technique: computational expense inhibits learning global relationships across
an entire recording or set of recordings. Furthermore, the labels inherited by
windows from their parent recordings may not accurately reflect the content of
that window in isolation. To resolve these issues, we introduce a multi-stage
model architecture, incorporating meta-learning principles tailored to
time-windowed data aggregation. We further tested two distinct strategies to
alleviate these issues: lengthening the window and utilizing overlapping to
augment data. Our methods, when tested on the Temple University Hospital
Abnormal EEG Corpus (TUAB), dramatically boosted the benchmark accuracy from
89.8 percent to 99.0 percent. This breakthrough performance surpasses prior
performance projections for this dataset and paves the way for clinical
applications of machine learning solutions to EEG interpretation challenges. On
a broader and more varied dataset from the Temple University Hospital EEG
Corpus (TUEG), we attained an accuracy of 86.7%, nearing the assumed
performance ceiling set by variable inter-rater agreement on such datasets.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10284" title="Abstract">arXiv:2401.10284</a> (cross-list from eess.SP) [<a href="/pdf/2401.10284" title="Download PDF">pdf</a>, <a href="/format/2401.10284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MorpheusNet: Resource efficient sleep stage classifier for embedded  on-line systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kavoosi%2C+A">Ali Kavoosi</a>, 
<a href="/search/eess?searchtype=author&query=Mitchell%2C+M+P">Morgan P. Mitchell</a>, 
<a href="/search/eess?searchtype=author&query=Kariyawasam%2C+R">Raveen Kariyawasam</a>, 
<a href="/search/eess?searchtype=author&query=Fleming%2C+J+E">John E. Fleming</a>, 
<a href="/search/eess?searchtype=author&query=Lewis%2C+P">Penny Lewis</a>, 
<a href="/search/eess?searchtype=author&query=Johansen-Berg%2C+H">Heidi Johansen-Berg</a>, 
<a href="/search/eess?searchtype=author&query=Cagnan%2C+H">Hayriye Cagnan</a>, 
<a href="/search/eess?searchtype=author&query=Denison%2C+T">Timothy Denison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was presented at the 2023 IEEE conference on Systems, Man, and Cybernetics (SMC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Sleep Stage Classification (SSC) is a labor-intensive task, requiring experts
to examine hours of electrophysiological recordings for manual classification.
This is a limiting factor when it comes to leveraging sleep stages for
therapeutic purposes. With increasing affordability and expansion of wearable
devices, automating SSC may enable deployment of sleep-based therapies at
scale. Deep Learning has gained increasing attention as a potential method to
automate this process. Previous research has shown accuracy comparable to
manual expert scores. However, previous approaches require sizable amount of
memory and computational resources. This constrains the ability to classify in
real time and deploy models on the edge. To address this gap, we aim to provide
a model capable of predicting sleep stages in real-time, without requiring
access to external computational sources (e.g., mobile phone, cloud). The
algorithm is power efficient to enable use on embedded battery powered systems.
Our compact sleep stage classifier can be deployed on most off-the-shelf
microcontrollers (MCU) with constrained hardware settings. This is due to the
memory footprint of our approach requiring significantly fewer operations. The
model was tested on three publicly available data bases and achieved
performance comparable to the state of the art, whilst reducing model
complexity by orders of magnitude (up to 280 times smaller compared to state of
the art). We further optimized the model with quantization of parameters to 8
bits with only an average drop of 0.95% in accuracy. When implemented in
firmware, the quantized model achieves a latency of 1.6 seconds on an Arm
CortexM4 processor, allowing its use for on-line SSC-based therapies.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10285" title="Abstract">arXiv:2401.10285</a> (cross-list from eess.SP) [<a href="/pdf/2401.10285" title="Download PDF">pdf</a>, <a href="/ps/2401.10285" title="Download PostScript">ps</a>, <a href="/format/2401.10285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Brain Activity During Learning Tasks with EEG and Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cho%2C+R">Ryan Cho</a>, 
<a href="/search/eess?searchtype=author&query=Zaman%2C+M">Mobasshira Zaman</a>, 
<a href="/search/eess?searchtype=author&query=Cho%2C+K+T">Kyu Taek Cho</a>, 
<a href="/search/eess?searchtype=author&query=Hwang%2C+J">Jaejin Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">This study aimed to analyze brain activity during various STEM activities,
exploring the feasibility of classifying between different tasks. EEG brain
data from twenty subjects engaged in five cognitive tasks were collected and
segmented into 4-second clips. Power spectral densities of brain frequency
waves were then analyzed. Testing different k-intervals with XGBoost, Random
Forest, and Bagging Classifier revealed that Random Forest performed best,
achieving a testing accuracy of 91.07% at an interval size of two. When
utilizing all four EEG channels, cognitive flexibility was most recognizable.
Task-specific classification accuracy showed the right frontal lobe excelled in
mathematical processing and planning, the left frontal lobe in cognitive
flexibility and mental flexibility, and the left temporoparietal lobe in
connections. Notably, numerous connections between frontal and temporoparietal
lobes were observed during STEM activities. This study contributes to a deeper
understanding of implementing machine learning in analyzing brain activity and
sheds light on the brain's mechanisms.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10291" title="Abstract">arXiv:2401.10291</a> (cross-list from eess.SP) [<a href="/pdf/2401.10291" title="Download PDF">pdf</a>, <a href="/format/2401.10291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Post-Stroke Aphasia Via Brain Responses to Speech in a Deep  Learning Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=De+Clercq%2C+P">Pieter De Clercq</a>, 
<a href="/search/eess?searchtype=author&query=Puffay%2C+C">Corentin Puffay</a>, 
<a href="/search/eess?searchtype=author&query=Kries%2C+J">Jill Kries</a>, 
<a href="/search/eess?searchtype=author&query=Van+Hamme%2C+H">Hugo Van Hamme</a>, 
<a href="/search/eess?searchtype=author&query=Vandermosten%2C+M">Maaike Vandermosten</a>, 
<a href="/search/eess?searchtype=author&query=Francart%2C+T">Tom Francart</a>, 
<a href="/search/eess?searchtype=author&query=Vanthornhout%2C+J">Jonas Vanthornhout</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Shared first authors: De Clercq &amp; Puffay
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Aphasia, a language disorder primarily caused by a stroke, is traditionally
diagnosed using behavioral language tests. However, these tests are
time-consuming, require manual interpretation by trained clinicians, suffer
from low ecological validity, and diagnosis can be biased by comorbid motor and
cognitive problems present in aphasia. In this study, we introduce an automated
screening tool for speech processing impairments in aphasia that relies on
time-locked brain responses to speech, known as neural tracking, within a deep
learning framework. We modeled electroencephalography (EEG) responses to
acoustic, segmentation, and linguistic speech representations of a story using
convolutional neural networks trained on a large sample of healthy
participants, serving as a model for intact neural tracking of speech.
Subsequently, we evaluated our models on an independent sample comprising 26
individuals with aphasia (IWA) and 22 healthy controls. Our results reveal
decreased tracking of all speech representations in IWA. Utilizing a support
vector machine classifier with neural tracking measures as input, we
demonstrate high accuracy in aphasia detection at the individual level
(85.42\%) in a time-efficient manner (requiring 9 minutes of EEG data). Given
its high robustness, time efficiency, and generalizability to unseen data, our
approach holds significant promise for clinical applications.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10293" title="Abstract">arXiv:2401.10293</a> (cross-list from quant-ph) [<a href="/pdf/2401.10293" title="Download PDF">pdf</a>, <a href="/format/2401.10293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetry breaking in geometric quantum machine learning in the presence  of noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=T%C3%BCys%C3%BCz%2C+C">Cenk T&#xfc;ys&#xfc;z</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chang%2C+S+Y">Su Yeon Chang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Demidik%2C+M">Maria Demidik</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jansen%2C+K">Karl Jansen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vallecorsa%2C+S">Sofia Vallecorsa</a>, 
<a href="/search/quant-ph?searchtype=author&query=Grossi%2C+M">Michele Grossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures. supplementary material 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Geometric quantum machine learning based on equivariant quantum neural
networks (EQNN) recently appeared as a promising direction in quantum machine
learning. Despite the encouraging progress, the studies are still limited to
theory, and the role of hardware noise in EQNN training has never been
explored. This work studies the behavior of EQNN models in the presence of
noise. We show that certain EQNN models can preserve equivariance under Pauli
channels, while this is not possible under the amplitude damping channel. We
claim that the symmetry breaking grows linearly in the number of layers and
noise strength. We support our claims with numerical data from simulations as
well as hardware up to 64 qubits. Furthermore, we provide strategies to enhance
the symmetry protection of EQNN models in the presence of noise.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10297" title="Abstract">arXiv:2401.10297</a> (cross-list from eess.SP) [<a href="/pdf/2401.10297" title="Download PDF">pdf</a>, <a href="/format/2401.10297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Non-myopic Power Allocation in Constrained Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chowdhury%2C+A">Arindam Chowdhury</a>, 
<a href="/search/eess?searchtype=author&query=Paternain%2C+S">Santiago Paternain</a>, 
<a href="/search/eess?searchtype=author&query=Verma%2C+G">Gunjan Verma</a>, 
<a href="/search/eess?searchtype=author&query=Swami%2C+A">Ananthram Swami</a>, 
<a href="/search/eess?searchtype=author&query=Segarra%2C+S">Santiago Segarra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ASILOMAR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">We propose a learning-based framework for efficient power allocation in ad
hoc interference networks under episodic constraints. The problem of optimal
power allocation -- for maximizing a given network utility metric -- under
instantaneous constraints has recently gained significant popularity. Several
learnable algorithms have been proposed to obtain fast, effective, and
near-optimal performance. However, a more realistic scenario arises when the
utility metric has to be optimized for an entire episode under time-coupled
constraints. In this case, the instantaneous power needs to be regulated so
that the given utility can be optimized over an entire sequence of wireless
network realizations while satisfying the constraint at all times. Solving each
instance independently will be myopic as the long-term constraint cannot
modulate such a solution. Instead, we frame this as a constrained and
sequential decision-making problem, and employ an actor-critic algorithm to
obtain the constraint-aware power allocation at each step. We present
experimental analyses to illustrate the effectiveness of our method in terms of
superior episodic network-utility performance and its efficiency in terms of
time and computational complexity.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10298" title="Abstract">arXiv:2401.10298</a> (cross-list from physics.data-an) [<a href="/pdf/2401.10298" title="Download PDF">pdf</a>, <a href="/format/2401.10298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning approach to detect dynamical states from recurrence  measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Thakur%2C+D">Dheeraja Thakur</a>, 
<a href="/search/physics?searchtype=author&query=Mohan%2C+A">Athul Mohan</a>, 
<a href="/search/physics?searchtype=author&query=Ambika%2C+G">G. Ambika</a>, 
<a href="/search/physics?searchtype=author&query=Meena%2C+C">Chandrakala Meena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We integrate machine learning approaches with nonlinear time series analysis,
specifically utilizing recurrence measures to classify various dynamical states
emerging from time series. We implement three machine learning algorithms
Logistic Regression, Random Forest, and Support Vector Machine for this study.
The input features are derived from the recurrence quantification of nonlinear
time series and characteristic measures of the corresponding recurrence
networks. For training and testing we generate synthetic data from standard
nonlinear dynamical systems and evaluate the efficiency and performance of the
machine learning algorithms in classifying time series into periodic, chaotic,
hyper-chaotic, or noisy categories. Additionally, we explore the significance
of input features in the classification scheme and find that the features
quantifying the density of recurrence points are the most relevant.
Furthermore, we illustrate how the trained algorithms can successfully predict
the dynamical states of two variable stars, SX Her and AC Her from the data of
their light curves.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10305" title="Abstract">arXiv:2401.10305</a> (cross-list from eess.SP) [<a href="/pdf/2401.10305" title="Download PDF">pdf</a>, <a href="/format/2401.10305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personality Trait Inference Via Mobile Phone Sensors: A Machine Learning  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sze%2C+W+Y+S">Wun Yung Shaney Sze</a>, 
<a href="/search/eess?searchtype=author&query=Herrero%2C+M+P">Maryglen Pearl Herrero</a>, 
<a href="/search/eess?searchtype=author&query=Garriga%2C+R">Roger Garriga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study provides evidence that personality can be reliably predicted from
activity data collected through mobile phone sensors. Employing a set of well
informed indicators calculable from accelerometer records and movement
patterns, we were able to predict users' personality up to a 0.78 F1 score on a
two class problem. Given the fast growing number of data collected from mobile
phones, our novel personality indicators open the door to exciting avenues for
future research in social sciences. Our results reveal distinct behavioral
patterns that proved to be differentially predictive of big five personality
traits. They potentially enable cost effective, questionnaire free
investigation of personality related questions at an unprecedented scale.
Overall, this paper shows how a combination of rich behavioral data obtained
with smartphone sensing and the use of machine learning techniques can help to
advance personality research and can inform both practitioners and researchers
about the different behavioral patterns of personality. These findings have
practical implications for organizations harnessing mobile sensor data for
personality assessment, guiding the refinement of more precise and efficient
prediction models in the future.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10306" title="Abstract">arXiv:2401.10306</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2401.10306" title="Download PDF">pdf</a>, <a href="/format/2401.10306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-constrained convolutional neural networks for inverse problems  in spatiotemporal partial differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kelshaw%2C+D">Daniel Kelshaw</a>, 
<a href="/search/physics?searchtype=author&query=Magri%2C+L">Luca Magri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2306.04600">arXiv:2306.04600</a>, <a href="/abs/2306.10990">arXiv:2306.10990</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a physics-constrained convolutional neural network (PC-CNN) to
solve two types of inverse problems in partial differential equations (PDEs),
which are nonlinear and vary both in space and time. In the first inverse
problem, we are given data that is offset by spatially varying systematic error
(i.e., the bias, also known the epistemic uncertainty). The task is to uncover
from the biased data the true state, which is the solution of the PDE. In the
second inverse problem, we are given sparse information on the solution of a
PDE. The task is to reconstruct the solution in space with high-resolution.
First, we present the PC-CNN, which constrains the PDE with a simple
time-windowing scheme to handle sequential data. Second, we analyse the
performance of the PC-CNN for uncovering solutions from biased data. We analyse
both linear and nonlinear convection-diffusion equations, and the Navier-Stokes
equations, which govern the spatiotemporally chaotic dynamics of turbulent
flows. We find that the PC-CNN correctly recovers the true solution for a
variety of biases, which are parameterised as non-convex functions. Third, we
analyse the performance of the PC-CNN for reconstructing solutions from biased
data for the turbulent flow. We reconstruct the spatiotemporal chaotic solution
on a high-resolution grid from only 2\% of the information contained in it. For
both tasks, we further analyse the Navier-Stokes solutions. We find that the
inferred solutions have a physical spectral energy content, whereas traditional
methods, such as interpolation, do not. This work opens opportunities for
solving inverse problems with partial differential equations.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10334" title="Abstract">arXiv:2401.10334</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.10334" title="Download PDF">pdf</a>, <a href="/format/2401.10334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DrugAssist: A Large Language Model for Molecule Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ye%2C+G">Geyan Ye</a>, 
<a href="/search/q-bio?searchtype=author&query=Cai%2C+X">Xibao Cai</a>, 
<a href="/search/q-bio?searchtype=author&query=Lai%2C+H">Houtim Lai</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+X">Xing Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+J">Junhong Huang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Zeng%2C+X">Xiangxiang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Geyan Ye and Xibao Cai are equal contributors; Longyue Wang is corresponding author
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, the impressive performance of large language models (LLMs) on a
wide range of tasks has attracted an increasing number of attempts to apply
LLMs in drug discovery. However, molecule optimization, a critical task in the
drug discovery pipeline, is currently an area that has seen little involvement
from LLMs. Most of existing approaches focus solely on capturing the underlying
patterns in chemical structures provided by the data, without taking advantage
of expert feedback. These non-interactive approaches overlook the fact that the
drug discovery process is actually one that requires the integration of expert
experience and iterative refinement. To address this gap, we propose
DrugAssist, an interactive molecule optimization model which performs
optimization through human-machine dialogue by leveraging LLM's strong
interactivity and generalizability. DrugAssist has achieved leading results in
both single and multiple property optimization, simultaneously showcasing
immense potential in transferability and iterative optimization. In addition,
we publicly release a large instruction-based dataset called
MolOpt-Instructions for fine-tuning language models on molecule optimization
tasks. We have made our code and data publicly available at
https://github.com/blazerye/DrugAssist, which we hope to pave the way for
future research in LLMs' application for drug discovery.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10347" title="Abstract">arXiv:2401.10347</a> (cross-list from math.DS) [<a href="/pdf/2401.10347" title="Download PDF">pdf</a>, <a href="/format/2401.10347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Undecidability of dynamical properties of SFTs and sofic subshifts on  $\mathbb{Z}^2$ and other groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carrasco-Vargas%2C+N">Nicanor Carrasco-Vargas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Information Theory (cs.IT); Combinatorics (math.CO); Group Theory (math.GR); Logic (math.LO)

</div>
<p class="mathjax">We study the algorithmic undecidability of abstract dynamical properties for
sofic $\mathbb{Z}^{2}$-subshifts and subshifts of finite type (SFTs) on
$\mathbb{Z}^{2}$. Within the class of sofic $\mathbb{Z}^{2}$-subshifts, we
prove the undecidability of every nontrivial dynamical property. We show that
although this is not the case for $\mathbb{Z}^{2}$-SFTs, it is still possible
to establish the undecidability of a large class of dynamical properties. This
result is analogous to the Adian-Rabin undecidability theorem for group
properties. Besides dynamical properties, we consider dynamical invariants of
$\mathbb{Z}^{2}$-SFTs taking values in partially ordered sets. It is well known
that the topological entropy of a $\mathbb{Z}^{2}$-SFT can not be effectively
computed from an SFT presentation. We prove a generalization of this result to
\emph{every} dynamical invariant which is nonincreasing by factor maps, and
satisfies a mild additional technical condition. Our results are also valid for
$\Z^{d}$, $d\geq2$, and more generally for any group where determining whether
a subshift of finite type is empty is undecidable.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10348" title="Abstract">arXiv:2401.10348</a> (cross-list from q-bio.NC) [<a href="/pdf/2401.10348" title="Download PDF">pdf</a>, <a href="/format/2401.10348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring General Intelligence via Gated Graph Transformer in Functional  Connectivity Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Qu%2C+G">Gang Qu</a>, 
<a href="/search/q-bio?searchtype=author&query=Orlichenko%2C+A">Anton Orlichenko</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+J">Junqi Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+G">Gemeng Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Xiao%2C+L">Li Xiao</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+A">Aiying Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+Z">Zhengming Ding</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yu-Ping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Functional connectivity (FC) as derived from fMRI has emerged as a pivotal
tool in elucidating the intricacies of various psychiatric disorders and
delineating the neural pathways that underpin cognitive and behavioral dynamics
inherent to the human brain. While Graph Neural Networks (GNNs) offer a
structured approach to represent neuroimaging data, they are limited by their
need for a predefined graph structure to depict associations between brain
regions, a detail not solely provided by FCs. To bridge this gap, we introduce
the Gated Graph Transformer (GGT) framework, designed to predict cognitive
metrics based on FCs. Empirical validation on the Philadelphia
Neurodevelopmental Cohort (PNC) underscores the superior predictive prowess of
our model, further accentuating its potential in identifying pivotal neural
connectivities that correlate with human cognitive processes.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10355" title="Abstract">arXiv:2401.10355</a> (cross-list from eess.SP) [<a href="/pdf/2401.10355" title="Download PDF">pdf</a>, <a href="/format/2401.10355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Optimization and Machine Learning Algorithms for Structural  Anomaly Detection using Seismic Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Trapp%2C+M">Maximilian Trapp</a>, 
<a href="/search/eess?searchtype=author&query=Bogoclu%2C+C">Can Bogoclu</a>, 
<a href="/search/eess?searchtype=author&query=Nestorovi%C4%87%2C+T">Tamara Nestorovi&#x107;</a>, 
<a href="/search/eess?searchtype=author&query=Roos%2C+D">Dirk Roos</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mechanical Systems and Signal Processing, Volume 133, 2019, 106250
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">The lack of anomaly detection methods during mechanized tunnelling can cause
financial loss and deficits in drilling time. On-site excavation requires hard
obstacles to be recognized prior to drilling in order to avoid damaging the
tunnel boring machine and to adjust the propagation velocity. The efficiency of
the structural anomaly detection can be increased with intelligent optimization
techniques and machine learning. In this research, the anomaly in a simple
structure is detected by comparing the experimental measurements of the
structural vibrations with numerical simulations using parameter estimation
methods.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10356" title="Abstract">arXiv:2401.10356</a> (cross-list from math.OC) [<a href="/pdf/2401.10356" title="Download PDF">pdf</a>, <a href="/ps/2401.10356" title="Download PostScript">ps</a>, <a href="/format/2401.10356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mean Field Games for Controlling Coherent Structures in Nonlinear Fluid  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/math?searchtype=author&query=Qi%2C+D">Di Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper discusses the control of coherent structures in turbulent flows,
which has broad applications among complex systems in science and technology.
Mean field games have been proved a powerful tool and are proposed here to
control the stochastic Lagrangian tracers as players tracking the flow field.
We derive optimal control solutions for general nonlinear fluid systems using
mean field game models, and develop computational algorithms to efficiently
solve the resulting coupled forward and backward mean field system. A precise
link is established for the control of Lagrangian tracers and the scalar
vorticity field based on the functional Hamilton-Jacobi equations derived from
the mean field models. New iterative numerical strategy is then constructed to
compute the optimal solution with fast convergence. We verify the skill of the
mean field control models and illustrate their practical efficiency on a
prototype model modified from the viscous Burger's equation under various cost
functions in both deterministic and stochastic formulations. The good model
performance implies potential effectiveness of the strategy for more general
high-dimensional turbulent systems.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10370" title="Abstract">arXiv:2401.10370</a> (cross-list from q-fin.CP) [<a href="/pdf/2401.10370" title="Download PDF">pdf</a>, <a href="/format/2401.10370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Generative Modeling for Financial Time Series with Application in  VaR: A Comparative Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Ericson%2C+L">Lars Ericson</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhu%2C+X">Xuejun Zhu</a>, 
<a href="/search/q-fin?searchtype=author&query=Han%2C+X">Xusi Han</a>, 
<a href="/search/q-fin?searchtype=author&query=Fu%2C+R">Rao Fu</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+S">Shuang Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Guo%2C+S">Steve Guo</a>, 
<a href="/search/q-fin?searchtype=author&query=Hu%2C+P">Ping Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Machine Learning (cs.LG); Risk Management (q-fin.RM); Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">In the financial services industry, forecasting the risk factor distribution
conditional on the history and the current market environment is the key to
market risk modeling in general and value at risk (VaR) model in particular. As
one of the most widely adopted VaR models in commercial banks, Historical
simulation (HS) uses the empirical distribution of daily returns in a
historical window as the forecast distribution of risk factor returns in the
next day. The objectives for financial time series generation are to generate
synthetic data paths with good variety, and similar distribution and dynamics
to the original historical data. In this paper, we apply multiple existing deep
generative methods (e.g., CGAN, CWGAN, Diffusion, and Signature WGAN) for
conditional time series generation, and propose and test two new methods for
conditional multi-step time series generation, namely Encoder-Decoder CGAN and
Conditional TimeVAE. Furthermore, we introduce a comprehensive framework with a
set of KPIs to measure the quality of the generated time series for financial
modeling. The KPIs cover distribution distance, autocorrelation and
backtesting. All models (HS, parametric and neural networks) are tested on both
historical USD yield curve data and additional data simulated from GARCH and
CIR processes. The study shows that top performing models are HS, GARCH and
CWGAN models. Future research directions in this area are also discussed.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10373" title="Abstract">arXiv:2401.10373</a> (cross-list from eess.IV) [<a href="/pdf/2401.10373" title="Download PDF">pdf</a>, <a href="/format/2401.10373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonized Spatial and Spectral Learning for Robust and Generalized  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gorade%2C+V">Vandan Gorade</a>, 
<a href="/search/eess?searchtype=author&query=Mittal%2C+S">Sparsh Mittal</a>, 
<a href="/search/eess?searchtype=author&query=Jha%2C+D">Debesh Jha</a>, 
<a href="/search/eess?searchtype=author&query=Singhal%2C+R">Rekha Singhal</a>, 
<a href="/search/eess?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning has demonstrated remarkable achievements in medical image
segmentation. However, prevailing deep learning models struggle with poor
generalization due to (i) intra-class variations, where the same class appears
differently in different samples, and (ii) inter-class independence, resulting
in difficulties capturing intricate relationships between distinct objects,
leading to higher false negative cases. This paper presents a novel approach
that synergies spatial and spectral representations to enhance
domain-generalized medical image segmentation. We introduce the innovative
Spectral Correlation Coefficient objective to improve the model's capacity to
capture middle-order features and contextual long-range dependencies. This
objective complements traditional spatial objectives by incorporating valuable
spectral information. Extensive experiments reveal that optimizing this
objective with existing architectures like UNet and TransUNet significantly
enhances generalization, interpretability, and noise robustness, producing more
confident predictions. For instance, in cardiac segmentation, we observe a 0.81
pp and 1.63 pp (pp = percentage point) improvement in DSC over UNet and
TransUNet, respectively. Our interpretability study demonstrates that, in most
tasks, objectives optimized with UNet outperform even TransUNet by introducing
global contextual information alongside local details. These findings
underscore the versatility and effectiveness of our proposed method across
diverse imaging modalities and medical domains.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10396" title="Abstract">arXiv:2401.10396</a> (cross-list from eess.SP) [<a href="/pdf/2401.10396" title="Download PDF">pdf</a>, <a href="/format/2401.10396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Dict: Deep Learning-based Lossy Time Series Compressor for IoT Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jinxin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Djukic%2C+P">Petar Djukic</a>, 
<a href="/search/eess?searchtype=author&query=Kulhandjian%2C+M">Michel Kulhandjian</a>, 
<a href="/search/eess?searchtype=author&query=Kantarci%2C+B">Burak Kantarci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 13 figures, IEEE International Conference on Communications (ICC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose Deep Dict, a deep learning-based lossy time series compressor
designed to achieve a high compression ratio while maintaining decompression
error within a predefined range. Deep Dict incorporates two essential
components: the Bernoulli transformer autoencoder (BTAE) and a distortion
constraint. BTAE extracts Bernoulli representations from time series data,
reducing the size of the representations compared to conventional autoencoders.
The distortion constraint limits the prediction error of BTAE to the desired
range. Moreover, in order to address the limitations of common regression
losses such as L1/L2, we introduce a novel loss function called quantized
entropy loss (QEL). QEL takes into account the specific characteristics of the
problem, enhancing robustness to outliers and alleviating optimization
challenges. Our evaluation of Deep Dict across ten diverse time series datasets
from various domains reveals that Deep Dict outperforms state-of-the-art lossy
compressors in terms of compression ratio by a significant margin by up to
53.66%.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10400" title="Abstract">arXiv:2401.10400</a> (cross-list from math.OC) [<a href="/pdf/2401.10400" title="Download PDF">pdf</a>, <a href="/format/2401.10400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto-Calibration and Biconvex Compressive Sensing with Applications to  Parallel MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ni%2C+Y">Yuan Ni</a>, 
<a href="/search/math?searchtype=author&query=Strohmer%2C+T">Thomas Strohmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: Self-calibration, Compressive sensing, Convex optimization, Random matrices, Parallel MRI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We study an auto-calibration problem in which a transform-sparse signal is
compressive-sensed by multiple sensors in parallel with unknown sensing
parameters. The problem has an important application in pMRI reconstruction,
where explicit coil calibrations are often difficult and costly to achieve in
practice, but nevertheless a fundamental requirement for high-precision
reconstructions. Most auto-calibrated strategies result in reconstruction that
corresponds to solving a challenging biconvex optimization problem. We
transform the auto-calibrated parallel sensing as a convex optimization problem
using the idea of `lifting'. By exploiting sparsity structures in the signal
and the redundancy introduced by multiple sensors, we solve a mixed-norm
minimization problem to recover the underlying signal and the sensing
parameters simultaneously. Robust and stable recovery guarantees are derived in
the presence of noise and sparsity deficiencies in the signals. For the pMRI
application, our method provides a theoretically guaranteed approach to
self-calibrated parallel imaging to accelerate MRI acquisitions under
appropriate assumptions. Developments in MRI are discussed, and numerical
simulations using the analytical phantom and simulated coil sensitives are
presented to support our theoretical results.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10411" title="Abstract">arXiv:2401.10411</a> (cross-list from eess.AS) [<a href="/pdf/2401.10411" title="Download PDF">pdf</a>, <a href="/format/2401.10411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AGADIR: Towards Array-Geometry Agnostic Directional Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Ju Lin</a>, 
<a href="/search/eess?searchtype=author&query=Moritz%2C+N">Niko Moritz</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yiteng Huang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+R">Ruiming Xie</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+M">Ming Sun</a>, 
<a href="/search/eess?searchtype=author&query=Fuegen%2C+C">Christian Fuegen</a>, 
<a href="/search/eess?searchtype=author&query=Seide%2C+F">Frank Seide</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Wearable devices like smart glasses are approaching the compute capability to
seamlessly generate real-time closed captions for live conversations. We build
on our recently introduced directional Automatic Speech Recognition (ASR) for
smart glasses that have microphone arrays, which fuses multi-channel ASR with
serialized output training, for wearer/conversation-partner disambiguation as
well as suppression of cross-talk speech from non-target directions and noise.
<br />When ASR work is part of a broader system-development process, one may be
faced with changes to microphone geometries as system development progresses.
<br />This paper aims to make multi-channel ASR insensitive to limited variations
of microphone-array geometry. We show that a model trained on multiple similar
geometries is largely agnostic and generalizes well to new geometries, as long
as they are not too different. Furthermore, training the model this way
improves accuracy for seen geometries by 15 to 28\% relative. Lastly, we refine
the beamforming by a novel Non-Linearly Constrained Minimum Variance criterion.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10412" title="Abstract">arXiv:2401.10412</a> (cross-list from math.OC) [<a href="/pdf/2401.10412" title="Download PDF">pdf</a>, <a href="/format/2401.10412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power System Quasi-Steady State Estimation: An Echo State Network  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Intriago%2C+G">Gabriel Intriago</a>, 
<a href="/search/math?searchtype=author&query=Cevallos%2C+H">Holger Cevallos</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2023 North American Power Symposium (NAPS). Typos have been corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The operating point of a power system may change due to slow enough
variations of the power injections. Rotating machines in the bulk system can
absorb smooth changes in the dynamic states of the system. In this context, we
present a novel reservoir computing (RC) method for estimating power system
quasi-steady states. By exploiting the behavior of an RC-based recurrent neural
network, the proposed method can capture the inherent nonlinearities in the
power flow equations. Our approach is compared with traditional methods,
including least squares, Kalman filtering, and particle filtering. We
demonstrate the estimation performance for all the methods under normal
operation and sudden load change. Extensive experiments tested on the standard
IEEE 14-bus and 300-bus cases corroborate the merit of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10419" title="Abstract">arXiv:2401.10419</a> (cross-list from eess.IV) [<a href="/pdf/2401.10419" title="Download PDF">pdf</a>, <a href="/ps/2401.10419" title="Download PostScript">ps</a>, <a href="/format/2401.10419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M3BUNet: Mobile Mean Max UNet for Pancreas Segmentation on CT-Scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=juwita%2C+J">Juwita juwita</a>, 
<a href="/search/eess?searchtype=author&query=Hassan%2C+G+M">Ghulam Mubashar Hassan</a>, 
<a href="/search/eess?searchtype=author&query=Akhtar%2C+N">Naveed Akhtar</a>, 
<a href="/search/eess?searchtype=author&query=Datta%2C+A">Amitava Datta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Segmenting organs in CT scan images is a necessary process for multiple
downstream medical image analysis tasks. Currently, manual CT scan segmentation
by radiologists is prevalent, especially for organs like the pancreas, which
requires a high level of domain expertise for reliable segmentation due to
factors like small organ size, occlusion, and varying shapes. When resorting to
automated pancreas segmentation, these factors translate to limited reliable
labeled data to train effective segmentation models. Consequently, the
performance of contemporary pancreas segmentation models is still not within
acceptable ranges. To improve that, we propose M3BUNet, a fusion of MobileNet
and U-Net neural networks, equipped with a novel Mean-Max (MM) attention that
operates in two stages to gradually segment pancreas CT images from coarse to
fine with mask guidance for object detection. This approach empowers the
network to surpass segmentation performance achieved by similar network
architectures and achieve results that are on par with complex state-of-the-art
methods, all while maintaining a low parameter count. Additionally, we
introduce external contour segmentation as a preprocessing step for the coarse
stage to assist in the segmentation process through image standardization. For
the fine segmentation stage, we found that applying a wavelet decomposition
filter to create multi-input images enhances pancreas segmentation performance.
We extensively evaluate our approach on the widely known NIH pancreas dataset
and MSD pancreas dataset. Our approach demonstrates a considerable performance
improvement, achieving an average Dice Similarity Coefficient (DSC) value of up
to 89.53% and an Intersection Over Union (IOU) score of up to 81.16 for the NIH
pancreas dataset, and 88.60% DSC and 79.90% IOU for the MSD Pancreas dataset.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10429" title="Abstract">arXiv:2401.10429</a> (cross-list from math.OC) [<a href="/pdf/2401.10429" title="Download PDF">pdf</a>, <a href="/format/2401.10429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post-Processing with Projection and Rescaling Algorithms for  Semidefinite Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kanoh%2C+S">Shin-ichi Kanoh</a>, 
<a href="/search/math?searchtype=author&query=Yoshise%2C+A">Akiko Yoshise</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 78 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We propose the algorithm that solves the symmetric cone programs (SCPs) by
iteratively calling the projection and rescaling methods the algorithms for
solving exceptional cases of SCP. Although our algorithm can solve SCPs by
itself, we propose it intending to use it as a post-processing step for
interior point methods since it can solve the problems more efficiently by
using an approximate optimal (interior feasible) solution. We also conduct
numerical experiments to see the numerical performance of the proposed
algorithm when used as a post-processing step of the solvers implementing
interior point methods, using several instances where the symmetric cone is
given by a direct product of positive semidefinite cones. Numerical results
show that our algorithm can obtain approximate optimal solutions more
accurately than the solvers. When at least one of the primal and dual problems
did not have an interior feasible solution, the performance of our algorithm
was slightly reduced in terms of optimality. However, our algorithm stably
returned more accurate solutions than the solvers when the primal and dual
problems had interior feasible solutions.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10449" title="Abstract">arXiv:2401.10449</a> (cross-list from eess.AS) [<a href="/pdf/2401.10449" title="Download PDF">pdf</a>, <a href="/format/2401.10449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextualized Automatic Speech Recognition with Attention-Based Bias  Phrase Boosted Beam Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sudo%2C+Y">Yui Sudo</a>, 
<a href="/search/eess?searchtype=author&query=Shakeel%2C+M">Muhammad Shakeel</a>, 
<a href="/search/eess?searchtype=author&query=Fukumoto%2C+Y">Yosuke Fukumoto</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>, 
<a href="/search/eess?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ICASSP20224
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">End-to-end (E2E) automatic speech recognition (ASR) methods exhibit
remarkable performance. However, since the performance of such methods is
intrinsically linked to the context present in the training data, E2E-ASR
methods do not perform as desired for unseen user contexts (e.g., technical
terms, personal names, and playlists). Thus, E2E-ASR methods must be easily
contextualized by the user or developer. This paper proposes an attention-based
contextual biasing method that can be customized using an editable phrase list
(referred to as a bias list). The proposed method can be trained effectively by
combining a bias phrase index loss and special tokens to detect the bias
phrases in the input speech data. In addition, to improve the contextualization
performance during inference further, we propose a bias phrase boosted (BPB)
beam search algorithm based on the bias phrase index probability. Experimental
results demonstrate that the proposed method consistently improves the word
error rate and the character error rate of the target phrases in the bias list
on both the Librispeech-960 (English) and our in-house (Japanese) dataset,
respectively.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10453" title="Abstract">arXiv:2401.10453</a> (cross-list from eess.AS) [<a href="/pdf/2401.10453" title="Download PDF">pdf</a>, <a href="/ps/2401.10453" title="Download PostScript">ps</a>, <a href="/format/2401.10453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Room Geometry Inference from Multichannel Room Impulse Response using  Deep Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yeon%2C+I">Inmo Yeon</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+J">Jung-Woo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, Proceedings of the 24th International Congress on Acoustics
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 24th International Congress on Acoustics, ICA
  2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Room geometry inference (RGI) aims at estimating room shapes from measured
room impulse responses (RIRs) and has received lots of attention for its
importance in environment-aware audio rendering and virtual acoustic
representation of a real venue. A lot of estimation models utilizing time
difference of arrival (TDoA) or time of arrival (ToA) information in RIRs have
been proposed. However, an estimation model should be able to handle more
general features and complex relations between reflections to cope with various
room shapes and uncertainties such as the unknown number of walls. In this
study, we propose a deep neural network that can estimate various room shapes
without prior assumptions on the shape or number of walls. The proposed model
consists of three sub-networks: a feature extractor, parameter estimation, and
evaluation networks, which extract key features from RIRs, estimate parameters,
and evaluate the confidence of estimated parameters, respectively. The network
is trained by about 40,000 RIRs simulated in rooms of different shapes using a
single source and spherical microphone array and tested for rooms of unseen
shapes and dimensions. The proposed algorithm achieves almost perfect accuracy
in finding the true number of walls and shows negligible errors in room shapes.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10494" title="Abstract">arXiv:2401.10494</a> (cross-list from eess.AS) [<a href="/pdf/2401.10494" title="Download PDF">pdf</a>, <a href="/format/2401.10494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Stage Framework in Cross-Spectrum Domain for Real-Time Speech  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yuewei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+H">Huanbin Zou</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+J">Jie Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Two-stage pipeline is popular in speech enhancement tasks due to its
superiority over traditional single-stage methods. The current two-stage
approaches usually enhance the magnitude spectrum in the first stage, and
further modify the complex spectrum to suppress the residual noise and recover
the speech phase in the second stage. The above whole process is performed in
the short-time Fourier transform (STFT) spectrum domain. In this paper, we
re-implement the above second sub-process in the short-time discrete cosine
transform (STDCT) spectrum domain. The reason is that we have found STDCT
performs greater noise suppression capability than STFT. Additionally, the
implicit phase of STDCT ensures simpler and more efficient phase recovery,
which is challenging and computationally expensive in the STFT-based methods.
Therefore, we propose a novel two-stage framework called the STFT-STDCT
spectrum fusion network (FDFNet) for speech enhancement in cross-spectrum
domain. Experimental results demonstrate that the proposed FDFNet outperforms
the previous two-stage methods and also exhibits superior performance compared
to other advanced systems.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10543" title="Abstract">arXiv:2401.10543</a> (cross-list from eess.AS) [<a href="/pdf/2401.10543" title="Download PDF">pdf</a>, <a href="/format/2401.10543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual acoustic word embeddings for zero-resource languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jacobs%2C+C">Christiaan Jacobs</a>, 
<a href="/search/eess?searchtype=author&query=Kamper%2C+H">Herman Kamper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">This research addresses the challenge of developing speech applications for
zero-resource languages that lack labelled data. It specifically uses acoustic
word embedding (AWE) -- fixed-dimensional representations of variable-duration
speech segments -- employing multilingual transfer, where labelled data from
several well-resourced languages are used for pertaining. The study introduces
a new neural network that outperforms existing AWE models on zero-resource
languages. It explores the impact of the choice of well-resourced languages.
AWEs are applied to a keyword-spotting system for hate speech detection in
Swahili radio broadcasts, demonstrating robustness in real-world scenarios.
Additionally, novel semantic AWE models improve semantic query-by-example
search.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10561" title="Abstract">arXiv:2401.10561</a> (cross-list from eess.IV) [<a href="/pdf/2401.10561" title="Download PDF">pdf</a>, <a href="/format/2401.10561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAEDiff: Masked Autoencoder-enhanced Diffusion Models for Unsupervised  Anomaly Detection in Brain Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+R">Rui Xu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yunke Wang</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+B">Bo Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Unsupervised anomaly detection has gained significant attention in the field
of medical imaging due to its capability of relieving the costly pixel-level
annotation. To achieve this, modern approaches usually utilize generative
models to produce healthy references of the diseased images and then identify
the abnormalities by comparing the healthy references and the original diseased
images. Recently, diffusion models have exhibited promising potential for
unsupervised anomaly detection in medical images for their good mode coverage
and high sample quality. However, the intrinsic characteristics of the medical
images, e.g. the low contrast, and the intricate anatomical structure of the
human body make the reconstruction challenging. Besides, the global information
of medical images often remain underutilized. To address these two issues, we
propose a novel Masked Autoencoder-enhanced Diffusion Model (MAEDiff) for
unsupervised anomaly detection in brain images. The MAEDiff involves a
hierarchical patch partition. It generates healthy images by overlapping
upper-level patches and implements a mechanism based on the masked autoencoders
operating on the sub-level patches to enhance the condition on the unnoised
regions. Extensive experiments on data of tumors and multiple sclerosis lesions
demonstrate the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10623" title="Abstract">arXiv:2401.10623</a> (cross-list from quant-ph) [<a href="/pdf/2401.10623" title="Download PDF">pdf</a>, <a href="/format/2401.10623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Computing Enhanced Service Ecosystem for Simulation in  Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Maass%2C+W">Wolfgang Maass</a>, 
<a href="/search/quant-ph?searchtype=author&query=Agrawal%2C+A">Ankit Agrawal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ciani%2C+A">Alessandro Ciani</a>, 
<a href="/search/quant-ph?searchtype=author&query=Danz%2C+S">Sven Danz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Delgadillo%2C+A">Alejandro Delgadillo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ganser%2C+P">Philipp Ganser</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kienast%2C+P">Pascal Kienast</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kulig%2C+M">Marco Kulig</a>, 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6nig%2C+V">Valentina K&#xf6;nig</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rodellas-Gr%C3%A0cia%2C+N">Nil Rodellas-Gr&#xe0;cia</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rughubar%2C+R">Rivan Rughubar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schr%C3%B6der%2C+S">Stefan Schr&#xf6;der</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stautner%2C+M">Marc Stautner</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+H">Hannah Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stollenwerk%2C+T">Tobias Stollenwerk</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zeuch%2C+D">Daniel Zeuch</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wilhelm%2C+F+K">Frank K. Wilhelm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Quantum computing (QC) and machine learning (ML), taken individually or
combined into quantum-assisted ML (QML), are ascending computing paradigms
whose calculations come with huge potential for speedup, increase in precision,
and resource reductions. Likely improvements for numerical simulations in
engineering imply the possibility of a strong economic impact on the
manufacturing industry. In this project report, we propose a framework for a
quantum computing-enhanced service ecosystem for simulation in manufacturing,
consisting of various layers ranging from hardware to algorithms to service and
organizational layers. In addition, we give insight into the current state of
the art of applications research based on QC and QML, both from a scientific
and an industrial point of view. We further analyse two high-value use cases
with the aim of a quantitative evaluation of these new computing paradigms for
industrially-relevant settings.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10637" title="Abstract">arXiv:2401.10637</a> (cross-list from eess.IV) [<a href="/pdf/2401.10637" title="Download PDF">pdf</a>, <a href="/format/2401.10637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Universal Unsupervised Anomaly Detection in Medical Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bercea%2C+C+I">Cosmin I. Bercea</a>, 
<a href="/search/eess?searchtype=author&query=Wiestler%2C+B">Benedikt Wiestler</a>, 
<a href="/search/eess?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/eess?searchtype=author&query=Schnabel%2C+J+A">Julia A. Schnabel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The increasing complexity of medical imaging data underscores the need for
advanced anomaly detection methods to automatically identify diverse
pathologies. Current methods face challenges in capturing the broad spectrum of
anomalies, often limiting their use to specific lesion types in brain scans. To
address this challenge, we introduce a novel unsupervised approach, termed
\textit{Reversed Auto-Encoders (RA)}, designed to create realistic
pseudo-healthy reconstructions that enable the detection of a wider range of
pathologies. We evaluate the proposed method across various imaging modalities,
including magnetic resonance imaging (MRI) of the brain, pediatric wrist X-ray,
and chest X-ray, and demonstrate superior performance in detecting anomalies
compared to existing state-of-the-art methods. Our unsupervised anomaly
detection approach may enhance diagnostic accuracy in medical imaging by
identifying a broader range of unknown pathologies. Our code is publicly
available at: \url{https://github.com/ci-ber/RA}.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10683" title="Abstract">arXiv:2401.10683</a> (cross-list from quant-ph) [<a href="/pdf/2401.10683" title="Download PDF">pdf</a>, <a href="/format/2401.10683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuantumReservoirPy: A Software Package for Time Series Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Miao%2C+S">Stanley Miao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kulseng%2C+O+T">Ola Tangen Kulseng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stasik%2C+A">Alexander Stasik</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fuchs%2C+F+G">Franz G. Fuchs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">In recent times, quantum reservoir computing has emerged as a potential
resource for time series prediction. Hence, there is a need for a flexible
framework to test quantum circuits as nonlinear dynamical systems. We have
developed a software package to allow for quantum reservoirs to fit a common
structure, similar to that of reservoirpy which is advertised as "a python tool
designed to easily define, train and use (classical) reservoir computing
architectures". Our package results in simplified development and logical
methods of comparison between quantum reservoir architectures. Examples are
provided to demonstrate the resulting simplicity of executing quantum reservoir
computing using our software package.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10696" title="Abstract">arXiv:2401.10696</a> (cross-list from physics.soc-ph) [<a href="/pdf/2401.10696" title="Download PDF">pdf</a>, <a href="/ps/2401.10696" title="Download PostScript">ps</a>, <a href="/format/2401.10696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Methodology to assess prosumer participation in European electricity  markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Rodr%C3%ADguez-Vilches%2C+R">Rub&#xe9;n Rodr&#xed;guez-Vilches</a>, 
<a href="/search/physics?searchtype=author&query=Mart%C3%ADn-Mart%C3%ADnez%2C+F">Francisco Mart&#xed;n-Mart&#xed;nez</a>, 
<a href="/search/physics?searchtype=author&query=S%C3%A1nchez-Miralles%2C+%C3%81">&#xc1;lvaro S&#xe1;nchez-Miralles</a>, 
<a href="/search/physics?searchtype=author&query=de+la+C%C3%A1mara%2C+J+R+G">Javier Rodrigo Guti&#xe9;rrez de la C&#xe1;mara</a>, 
<a href="/search/physics?searchtype=author&query=Delgado%2C+S+M">Sergio Mu&#xf1;oz Delgado</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Renewable and Sustainable Energy Reviews Volume 191, March 2024,
  114179
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The emergence of distributed generation and the electrification of demand
have opened the possibility for prosumers to participate in electricity
markets, receiving economic benefits on their bills and contributing to the
reduction of carbon emissions, aligning with United Nations Sustainable
Development Goal 7. Consumers and prosumers can participate through implicit
and explicit demand flexibility and (collective) self-consumption. This study
analyses the potential markets in which prosumers can participate and indicates
whether these are currently open. The markets studied include day-ahead,
intraday, ancillary services, adequacy services, constraint management, and
local flexibility markets. Additionally, collective self-consumption is
analysed as a service through which prosumers can participate in the
electricity market. Previous studies are usually focused on a single market or
in a single country, making impossible a complete comparison. This analysis has
been done in Spain, Italy, Croatia, and the United Kingdom as representative
countries to obtain a methodology to assess countries' openness to prosumer
participation in electricity markets, comparing regulatory frameworks and
assigning scores based on their prosumer inclusion across various markets. This
work updates current literature reviews with the changes and a new description
of local market designs in Spain. This methodology can be used to compare other
countries' grade of openness. The results of this study show that the analysed
countries can be categorised into three groups: almost open, partially open,
and closed markets. Analysing the differences, recommendations on the following
steps to foster user participation are suggested for each group.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10709" title="Abstract">arXiv:2401.10709</a> (cross-list from eess.IV) [<a href="/pdf/2401.10709" title="Download PDF">pdf</a>, <a href="/format/2401.10709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense 3D Reconstruction Through Lidar: A Comparative Study on Ex-vivo  Porcine Tissue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Caccianiga%2C+G">Guido Caccianiga</a>, 
<a href="/search/eess?searchtype=author&query=Nubert%2C+J">Julian Nubert</a>, 
<a href="/search/eess?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>, 
<a href="/search/eess?searchtype=author&query=Kuchenbecker%2C+K+J">Katherine J. Kuchenbecker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">New sensing technologies and more advanced processing algorithms are
transforming computer-integrated surgery. While researchers are actively
investigating depth sensing and 3D reconstruction for vision-based surgical
assistance, it remains difficult to achieve real-time, accurate, and robust 3D
representations of the abdominal cavity for minimally invasive surgery. Thus,
this work uses quantitative testing on fresh ex-vivo porcine tissue to
thoroughly characterize the quality with which a 3D laser-based time-of-flight
sensor (lidar) can perform anatomical surface reconstruction. Ground-truth
surface shapes are captured with a commercial laser scanner, and the resulting
signed error fields are analyzed using rigorous statistical tools. When
compared to modern learning-based stereo matching from endoscopic images,
time-of-flight sensing demonstrates higher precision, lower processing delay,
higher frame rate, and superior robustness against sensor distance and poor
illumination. Furthermore, we report on the potential negative effect of
near-infrared light penetration on the accuracy of lidar measurements across
different tissue samples, identifying a significant measured depth offset for
muscle in contrast to fat and liver. Our findings highlight the potential of
lidar for intraoperative 3D perception and point toward new methods that
combine complementary time-of-flight and spectral imaging.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10721" title="Abstract">arXiv:2401.10721</a> (cross-list from physics.comp-ph) [<a href="/pdf/2401.10721" title="Download PDF">pdf</a>, <a href="/format/2401.10721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Model for Constructing Reaction Path from Initial to Final  States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hayashi%2C+A">Akihide Hayashi</a>, 
<a href="/search/physics?searchtype=author&query=Takamoto%2C+S">So Takamoto</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+J">Ju Li</a>, 
<a href="/search/physics?searchtype=author&query=Okanohara%2C+D">Daisuke Okanohara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Mapping out reaction pathways and their corresponding activation barriers is
a significant aspect of molecular simulation. Given their inherent complexity
and nonlinearity, even generating a initial guess of these paths remains a
challenging problem. Presented in this paper is an innovative approach that
utilizes neural networks to generate initial guess for these reaction pathways.
The proposed method is initiated by inputting the coordinates of the initial
state, followed by progressive alterations to its structure. This iterative
process culminates in the generation of the approximate representation of the
reaction path and the coordinates of the final state. The application of this
method extends to complex reaction pathways illustrated by organic reactions.
Training was executed on the Transition1x dataset, an organic reaction pathway
dataset. The results revealed generation of reactions that bore substantial
similarities with the corresponding test data. The method's flexibility allows
for reactions to be generated either to conform to predetermined conditions or
in a randomized manner.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10728" title="Abstract">arXiv:2401.10728</a> (cross-list from math.OC) [<a href="/pdf/2401.10728" title="Download PDF">pdf</a>, <a href="/ps/2401.10728" title="Download PostScript">ps</a>, <a href="/format/2401.10728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perturbation analysis of a class of composite optimization problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tang%2C+P">Peipei Tang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+C">Chengjing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we study the perturbation analysis of a class of composite
optimization problems, which is a very convenient and unified framework for
developing both theoretical and algorithmic issues of constrained optimization
problems. The underlying theme of this paper is very important in both
theoretical and computational study of optimization problems. Under some mild
assumptions on the objective function, we provide a definition of a strong
second order sufficient condition (SSOSC) for the composite optimization
problem and also prove that the following conditions are equivalent to each
other: the SSOSC and the nondegeneracy condition, the nonsingularity of
Clarke's generalized Jacobian of the nonsmooth system at a Karush-Kuhn-Tucker
(KKT) point, and the strong regularity of the KKT point. These results provide
an important way to characterize the stability of the KKT point.
<br />As for the convex composite optimization problem, which is a special case of
the general problem, we establish the equivalence between the primal/dual
second order sufficient condition and the dual/primal strict Robinson
constraint qualification, the equivalence between the primal/dual SSOSC and the
dual/primal nondegeneracy condition. Moreover, we prove that the dual
nondegeneracy condition and the nonsingularity of Clarke's generalized Jacobian
of the subproblem corresponding to the augmented Lagrangian method are also
equivalent to each other. These theoretical results lay solid foundation for
designing an efficient algorithm.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10732" title="Abstract">arXiv:2401.10732</a> (cross-list from eess.IV) [<a href="/pdf/2401.10732" title="Download PDF">pdf</a>, <a href="/format/2401.10732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the gap between image coding for machines and humans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Le%2C+N">Nam Le</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Honglei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Cricri%2C+F">Francesco Cricri</a>, 
<a href="/search/eess?searchtype=author&query=Youvalari%2C+R+G">Ramin G. Youvalari</a>, 
<a href="/search/eess?searchtype=author&query=Tavakoli%2C+H+R">Hamed Rezazadegan Tavakoli</a>, 
<a href="/search/eess?searchtype=author&query=Aksu%2C+E">Emre Aksu</a>, 
<a href="/search/eess?searchtype=author&query=Hannuksela%2C+M+M">Miska M. Hannuksela</a>, 
<a href="/search/eess?searchtype=author&query=Rahtu%2C+E">Esa Rahtu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Image Processing (ICIP),
  Bordeaux, France, 2022, pp. 3411-3415
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Image coding for machines (ICM) aims at reducing the bitrate required to
represent an image while minimizing the drop in machine vision analysis
accuracy. In many use cases, such as surveillance, it is also important that
the visual quality is not drastically deteriorated by the compression process.
Recent works on using neural network (NN) based ICM codecs have shown
significant coding gains against traditional methods; however, the decompressed
images, especially at low bitrates, often contain checkerboard artifacts. We
propose an effective decoder finetuning scheme based on adversarial training to
significantly enhance the visual quality of ICM codecs, while preserving the
machine analysis accuracy, without adding extra bitcost or parameters at the
inference phase. The results show complete removal of the checkerboard
artifacts at the negligible cost of -1.6% relative change in task performance
score. In the cases where some amount of artifacts is tolerable, such as when
machine consumption is the primary target, this technique can enhance both
pixel-fidelity and feature-fidelity scores without losing task performance.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10746" title="Abstract">arXiv:2401.10746</a> (cross-list from eess.SP) [<a href="/pdf/2401.10746" title="Download PDF">pdf</a>, <a href="/format/2401.10746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Evaluation of Euclidean Alignment with Deep Learning for  EEG Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Junqueira%2C+B">Bruna Junqueira</a>, 
<a href="/search/eess?searchtype=author&query=Aristimunha%2C+B">Bruno Aristimunha</a>, 
<a href="/search/eess?searchtype=author&query=Chevallier%2C+S">Sylvain Chevallier</a>, 
<a href="/search/eess?searchtype=author&query=de+Camargo%2C+R+Y">Raphael Y. de Camargo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages and 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Electroencephalography (EEG) signals are frequently used for various
Brain-Computer Interface (BCI) tasks. While Deep Learning (DL) techniques have
shown promising results, they are hindered by the substantial data
requirements. By leveraging data from multiple subjects, transfer learning
enables more effective training of DL models. A technique that is gaining
popularity is Euclidean Alignment (EA) due to its ease of use, low
computational complexity, and compatibility with Deep Learning models. However,
few studies evaluate its impact on the training performance of shared and
individual DL models. In this work, we systematically evaluate the effect of EA
combined with DL for decoding BCI signals. We used EA to train shared models
with data from multiple subjects and evaluated its transferability to new
subjects. Our experimental results show that it improves decoding in the target
subject by 4.33% and decreases convergence time by more than 70%. We also
trained individual models for each subject to use as a majority-voting ensemble
classifier. In this scenario, using EA improved the 3-model ensemble accuracy
by 3.7%. However, when compared to the shared model with EA, the ensemble
accuracy was 3.62% lower.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10761" title="Abstract">arXiv:2401.10761</a> (cross-list from eess.IV) [<a href="/pdf/2401.10761" title="Download PDF">pdf</a>, <a href="/format/2401.10761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NN-VVC: Versatile Video Coding boosted by self-supervisedly learned  image coding for machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ahonen%2C+J+I">Jukka I. Ahonen</a>, 
<a href="/search/eess?searchtype=author&query=Le%2C+N">Nam Le</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Honglei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Hallapuro%2C+A">Antti Hallapuro</a>, 
<a href="/search/eess?searchtype=author&query=Cricri%2C+F">Francesco Cricri</a>, 
<a href="/search/eess?searchtype=author&query=Tavakoli%2C+H+R">Hamed Rezazadegan Tavakoli</a>, 
<a href="/search/eess?searchtype=author&query=Hannuksela%2C+M+M">Miska M. Hannuksela</a>, 
<a href="/search/eess?searchtype=author&query=Rahtu%2C+E">Esa Rahtu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ISM 2023 Best paper award winner version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The recent progress in artificial intelligence has led to an ever-increasing
usage of images and videos by machine analysis algorithms, mainly neural
networks. Nonetheless, compression, storage and transmission of media have
traditionally been designed considering human beings as the viewers of the
content. Recent research on image and video coding for machine analysis has
progressed mainly in two almost orthogonal directions. The first is represented
by end-to-end (E2E) learned codecs which, while offering high performance on
image coding, are not yet on par with state-of-the-art conventional video
codecs and lack interoperability. The second direction considers using the
Versatile Video Coding (VVC) standard or any other conventional video codec
(CVC) together with pre- and post-processing operations targeting machine
analysis. While the CVC-based methods benefit from interoperability and broad
hardware and software support, the machine task performance is often lower than
the desired level, particularly in low bitrates. This paper proposes a hybrid
codec for machines called NN-VVC, which combines the advantages of an
E2E-learned image codec and a CVC to achieve high performance in both image and
video coding for machines. Our experiments show that the proposed system
achieved up to -43.20% and -26.8% Bj{\o}ntegaard Delta rate reduction over VVC
for image and video data, respectively, when evaluated on multiple different
datasets and machine vision tasks. To the best of our knowledge, this is the
first research paper showing a hybrid video codec that outperforms VVC on
multiple datasets and multiple machine vision tasks.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10800" title="Abstract">arXiv:2401.10800</a> (cross-list from physics.ao-ph) [<a href="/pdf/2401.10800" title="Download PDF">pdf</a>, <a href="/format/2401.10800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of AMOC transition probabilities using a machine learning  based rare-event algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Jacques-Dumas%2C+V">Val&#xe9;rian Jacques-Dumas</a>, 
<a href="/search/physics?searchtype=author&query=van+Westen%2C+R+M">Ren&#xe9; M. van Westen</a>, 
<a href="/search/physics?searchtype=author&query=Dijkstra%2C+H+A">Henk A. Dijkstra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Atlantic Meridional Overturning Circulation (AMOC) is an important
component of the global climate, known to be a tipping element, as it could
collapse under global warming. The main objective of this study is to compute
the probability that the AMOC collapses within a specified time window, using a
rare-event algorithm called Trajectory-Adaptive Multilevel Splitting (TAMS).
However, the efficiency and accuracy of TAMS depend on the choice of the score
function. Although the definition of the optimal score function, called
``committor function" is known, it is impossible in general to compute it a
priori. Here, we combine TAMS with a Next-Generation Reservoir Computing
technique that estimates the committor function from the data generated by the
rare-event algorithm. We test this technique in a stochastic box model of the
AMOC for which two types of transition exist, the so-called F(ast)-transitions
and S(low)-transitions. Results for the F-transtions compare favorably with
those in the literature where a physically-informed score function was used. We
show that coupling a rare-event algorithm with machine learning allows for a
correct estimation of transition probabilities, transition times, and even
transition paths for a wide range of model parameters. We then extend these
results to the more difficult problem of S-transitions in the same model. In
both cases of F- and S-transitions, we also show how the Next-Generation
Reservoir Computing technique can be interpreted to retrieve an analytical
estimate of the committor function.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10811" title="Abstract">arXiv:2401.10811</a> (cross-list from stat.ML) [<a href="/pdf/2401.10811" title="Download PDF">pdf</a>, <a href="/format/2401.10811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation Based Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Naveiro%2C+R">Roi Naveiro</a>, 
<a href="/search/stat?searchtype=author&query=Tang%2C+B">Becky Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Bayesian Optimization (BO) is a powerful method for optimizing black-box
functions by combining prior knowledge with ongoing function evaluations. BO
constructs a probabilistic surrogate model of the objective function given the
covariates, which is in turn used to inform the selection of future evaluation
points through an acquisition function. For smooth continuous search spaces,
Gaussian Processes (GPs) are commonly used as the surrogate model as they offer
analytical access to posterior predictive distributions, thus facilitating the
computation and optimization of acquisition functions. However, in complex
scenarios involving optimizations over categorical or mixed covariate spaces,
GPs may not be ideal.
<br />This paper introduces Simulation Based Bayesian Optimization (SBBO) as a
novel approach to optimizing acquisition functions that only requires
\emph{sampling-based} access to posterior predictive distributions. SBBO allows
the use of surrogate probabilistic models tailored for combinatorial spaces
with discrete variables. Any Bayesian model in which posterior inference is
carried out through Markov chain Monte Carlo can be selected as the surrogate
model in SBBO. In applications involving combinatorial optimization, we
demonstrate empirically the effectiveness of SBBO method using various choices
of surrogate models.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10874" title="Abstract">arXiv:2401.10874</a> (cross-list from hep-lat) [<a href="/pdf/2401.10874" title="Download PDF">pdf</a>, <a href="/format/2401.10874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of flow models to the generation of correlated lattice QCD  ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-lat?searchtype=author&query=Abbott%2C+R">Ryan Abbott</a>, 
<a href="/search/hep-lat?searchtype=author&query=Botev%2C+A">Aleksandar Botev</a>, 
<a href="/search/hep-lat?searchtype=author&query=Boyda%2C+D">Denis Boyda</a>, 
<a href="/search/hep-lat?searchtype=author&query=Hackett%2C+D+C">Daniel C. Hackett</a>, 
<a href="/search/hep-lat?searchtype=author&query=Kanwar%2C+G">Gurtej Kanwar</a>, 
<a href="/search/hep-lat?searchtype=author&query=Racani%C3%A8re%2C+S">S&#xe9;bastien Racani&#xe8;re</a>, 
<a href="/search/hep-lat?searchtype=author&query=Rezende%2C+D+J">Danilo J. Rezende</a>, 
<a href="/search/hep-lat?searchtype=author&query=Romero-L%C3%B3pez%2C+F">Fernando Romero-L&#xf3;pez</a>, 
<a href="/search/hep-lat?searchtype=author&query=Shanahan%2C+P+E">Phiala E. Shanahan</a>, 
<a href="/search/hep-lat?searchtype=author&query=Urban%2C+J+M">Julian M. Urban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 tables, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Lattice (hep-lat)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine-learned normalizing flows can be used in the context of lattice
quantum field theory to generate statistically correlated ensembles of lattice
gauge fields at different action parameters. This work demonstrates how these
correlations can be exploited for variance reduction in the computation of
observables. Three different proof-of-concept applications are demonstrated
using a novel residual flow architecture: continuum limits of gauge theories,
the mass dependence of QCD observables, and hadronic matrix elements based on
the Feynman-Hellmann approach. In all three cases, it is shown that statistical
uncertainties are significantly reduced when machine-learned flows are
incorporated as compared with the same calculations performed with uncorrelated
ensembles or direct reweighting.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon, 22 Jan 24</h3>
<dl>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.02950" title="Abstract">arXiv:1910.02950</a> (replaced) [<a href="/pdf/1910.02950" title="Download PDF">pdf</a>, <a href="/ps/1910.02950" title="Download PostScript">ps</a>, <a href="/format/1910.02950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumeration of Sets of Mutually Orthogonal Latin Rectangles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=J%C3%A4ger%2C+G">Gerold J&#xe4;ger</a>, 
<a href="/search/math?searchtype=author&query=Markstr%C3%B6m%2C+K">Klas Markstr&#xf6;m</a>, 
<a href="/search/math?searchtype=author&query=Shcherbak%2C+D">Denys Shcherbak</a>, 
<a href="/search/math?searchtype=author&query=%C3%96hman%2C+L">Lars-Daniel &#xd6;hman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.06451" title="Abstract">arXiv:2002.06451</a> (replaced) [<a href="/pdf/2002.06451" title="Download PDF">pdf</a>, <a href="/format/2002.06451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetric Arithmetic Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dawar%2C+A">Anuj Dawar</a>, 
<a href="/search/cs?searchtype=author&query=Wilsenach%2C+G">Gregory Wilsenach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages. Final version, to appear in Theory of Computing. A preliminary version of this work was presented at the International Colloquium on Automata, Languages and Programming (ICALP) 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.02300" title="Abstract">arXiv:2005.02300</a> (replaced) [<a href="/pdf/2005.02300" title="Download PDF">pdf</a>, <a href="/format/2005.02300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Votes Change and Committees Should (Not)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bredereck%2C+R">Robert Bredereck</a>, 
<a href="/search/cs?searchtype=author&query=Fluschnik%2C+T">Till Fluschnik</a>, 
<a href="/search/cs?searchtype=author&query=Kaczmarczyk%2C+A">Andrzej Kaczmarczyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the Proceedings of IJCAI-22
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.04907" title="Abstract">arXiv:2005.04907</a> (replaced) [<a href="/pdf/2005.04907" title="Download PDF">pdf</a>, <a href="/format/2005.04907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Multiplicity Fair Allocation Using Parametric Integer Linear  Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bredereck%2C+R">Robert Bredereck</a>, 
<a href="/search/cs?searchtype=author&query=Kaczmarczyk%2C+A">Andrzej Kaczmarczyk</a>, 
<a href="/search/cs?searchtype=author&query=Knop%2C+D">Du&#x161;an Knop</a>, 
<a href="/search/cs?searchtype=author&query=Niedermeier%2C+R">Rolf Niedermeier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages; Published in the Proceedings of ECAI-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.11292" title="Abstract">arXiv:2008.11292</a> (replaced) [<a href="/pdf/2008.11292" title="Download PDF">pdf</a>, <a href="/format/2008.11292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flip Paths Between Lattice Triangulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sims%2C+W">William Sims</a>, 
<a href="/search/cs?searchtype=author&query=Sitharam%2C+M">Meera Sitharam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages (38 with appendices), 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Discrete Applied Mathematics, Volume 341, 2023, Pages 140-163,
  ISSN 0166-218X
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.03344" title="Abstract">arXiv:2012.03344</a> (replaced) [<a href="/pdf/2012.03344" title="Download PDF">pdf</a>, <a href="/ps/2012.03344" title="Download PostScript">ps</a>, <a href="/format/2012.03344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bid-aggregation based clearing of day-ahead electricity markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feczk%C3%B3%2C+B">Botond Feczk&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Div%C3%A9nyi%2C+D">D&#xe1;niel Div&#xe9;nyi</a>, 
<a href="/search/cs?searchtype=author&query=Sleisz%2C+%C3%81">&#xc1;d&#xe1;m Sleisz</a>, 
<a href="/search/cs?searchtype=author&query=Csercsik%2C+D">D&#xe1;vid Csercsik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.10702" title="Abstract">arXiv:2103.10702</a> (replaced) [<a href="/pdf/2103.10702" title="Download PDF">pdf</a>, <a href="/format/2103.10702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClawCraneNet: Leveraging Object-level Relation for Text-based Video  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yawei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version published in <a href="https://ieeexplore.ieee.org/abstract/document/10083244">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.01061" title="Abstract">arXiv:2106.01061</a> (replaced) [<a href="/pdf/2106.01061" title="Download PDF">pdf</a>, <a href="/format/2106.01061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Cross-modal Interaction from a Top-down Perspective for  Referring Video Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianfei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Champion solution in YouTube-VOS 2021 Track 3. Extended version published in <a href="https://ieeexplore.ieee.org/abstract/document/10083244">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.06826" title="Abstract">arXiv:2109.06826</a> (replaced) [<a href="/pdf/2109.06826" title="Download PDF">pdf</a>, <a href="/format/2109.06826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Quality-Diversity Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salehi%2C+A">Achkan Salehi</a>, 
<a href="/search/cs?searchtype=author&query=Coninx%2C+A">Alexandre Coninx</a>, 
<a href="/search/cs?searchtype=author&query=Doncieux%2C+S">Stephane Doncieux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the IEEE Robotics and Automation Letters (RA-L) journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters 7.2 (2022): 4424-4431
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.10203" title="Abstract">arXiv:2109.10203</a> (replaced) [<a href="/pdf/2109.10203" title="Download PDF">pdf</a>, <a href="/format/2109.10203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized minimum 0-extension problem and discrete convexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dvorak%2C+M">Martin Dvorak</a>, 
<a href="/search/cs?searchtype=author&query=Kolmogorov%2C+V">Vladimir Kolmogorov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to "Mathematical Programming"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Metric Geometry (math.MG)

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.10891" title="Abstract">arXiv:2111.10891</a> (replaced) [<a href="/pdf/2111.10891" title="Download PDF">pdf</a>, <a href="/format/2111.10891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Restoration of Lost Audio Signals Using Machine Learning and  Latent Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cheddad%2C+Z+A">Zohra Adila Cheddad</a>, 
<a href="/search/eess?searchtype=author&query=Cheddad%2C+A">Abbas Cheddad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 Pages, 2 Tables, 8 Figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Lecture Notes in Networks and Systems, vol 822, 2024, Springer,
  Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.13926" title="Abstract">arXiv:2111.13926</a> (replaced) [<a href="/pdf/2111.13926" title="Download PDF">pdf</a>, <a href="/format/2111.13926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Variational Fokker-Planck Methods for Data Assimilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Subrahmanya%2C+A+N">Amit N Subrahmanya</a>, 
<a href="/search/math?searchtype=author&query=Popov%2C+A+A">Andrey A Popov</a>, 
<a href="/search/math?searchtype=author&query=Sandu%2C+A">Adrian Sandu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.05158" title="Abstract">arXiv:2201.05158</a> (replaced) [<a href="/pdf/2201.05158" title="Download PDF">pdf</a>, <a href="/format/2201.05158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Quantum Graph Neural Networks: An Ego-Graph Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ai%2C+X">Xing Ai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+Z">Zhihong Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sun%2C+L">Luzhe Sun</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hancock%2C+E">Edwin Hancock</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.09773" title="Abstract">arXiv:2203.09773</a> (replaced) [<a href="/pdf/2203.09773" title="Download PDF">pdf</a>, <a href="/format/2203.09773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local-Global Context Aware Transformer for Language-Guided Video  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianfei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+J">Jiaxu Miao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yawei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TPAMI. Code, data: <a href="https://github.com/leonnnop/Locater">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.14471" title="Abstract">arXiv:2203.14471</a> (replaced) [<a href="/pdf/2203.14471" title="Download PDF">pdf</a>, <a href="/format/2203.14471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UTIL: An Ultra-wideband Time-difference-of-arrival Indoor Localization  Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenda Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Goudar%2C+A">Abhishek Goudar</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+X">Xinyuan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Schoellig%2C+A+P">Angela P. Schoellig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16031" title="Abstract">arXiv:2203.16031</a> (replaced) [<a href="/pdf/2203.16031" title="Download PDF">pdf</a>, <a href="/format/2203.16031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Deep is Your Art: An Experimental Study on the Limits of Artistic  Understanding in a Single-Task, Single-Modality Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zahedi%2C+M+A">Mahan Agha Zahedi</a>, 
<a href="/search/cs?searchtype=author&query=Gholamrezaei%2C+N">Niloofar Gholamrezaei</a>, 
<a href="/search/cs?searchtype=author&query=Doboli%2C+A">Alex Doboli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.05359" title="Abstract">arXiv:2205.05359</a> (replaced) [<a href="/pdf/2205.05359" title="Download PDF">pdf</a>, <a href="/ps/2205.05359" title="Download PostScript">ps</a>, <a href="/format/2205.05359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Local Explanations of Nonlinear Models Using Animated Linear  Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Spyrison%2C+N">Nicholas Spyrison</a>, 
<a href="/search/stat?searchtype=author&query=Cook%2C+D">Dianne Cook</a>, 
<a href="/search/stat?searchtype=author&query=Biecek%2C+P">Przemyslaw Biecek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14102" title="Abstract">arXiv:2205.14102</a> (replaced) [<a href="/pdf/2205.14102" title="Download PDF">pdf</a>, <a href="/ps/2205.14102" title="Download PostScript">ps</a>, <a href="/format/2205.14102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group-level Brain Decoding with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Csaky%2C+R">Richard Csaky</a>, 
<a href="/search/cs?searchtype=author&query=Van+Es%2C+M">Mats Van Es</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+O+P">Oiwi Parker Jones</a>, 
<a href="/search/cs?searchtype=author&query=Woolrich%2C+M">Mark Woolrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Human Brain Mapping
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01409" title="Abstract">arXiv:2206.01409</a> (replaced) [<a href="/pdf/2206.01409" title="Download PDF">pdf</a>, <a href="/format/2206.01409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Parameter Search and Dynamic Model Selection for Mixed-Variable  Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hengrui Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Younghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Demmel%2C+J+W">James W. Demmel</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X+S">Xiaoye S. Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 8 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11828" title="Abstract">arXiv:2206.11828</a> (replaced) [<a href="/pdf/2206.11828" title="Download PDF">pdf</a>, <a href="/format/2206.11828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of Problems on Tree-structured Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodlaender%2C+H+L">Hans L. Bodlaender</a>, 
<a href="/search/cs?searchtype=author&query=Groenland%2C+C">Carla Groenland</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+H">Hugo Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Marcin Pilipczuk</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Micha&#x142; Pilipczuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.07067" title="Abstract">arXiv:2207.07067</a> (replaced) [<a href="/pdf/2207.07067" title="Download PDF">pdf</a>, <a href="/format/2207.07067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Method for Quantifying the Aggregate Flexibility of Plug-in  Electric Vehicle Populations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Taha%2C+F+A">Feras Al Taha</a>, 
<a href="/search/eess?searchtype=author&query=Vincent%2C+T">Tyrone Vincent</a>, 
<a href="/search/eess?searchtype=author&query=Bitar%2C+E">Eilyan Bitar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06551" title="Abstract">arXiv:2208.06551</a> (replaced) [<a href="/pdf/2208.06551" title="Download PDF">pdf</a>, <a href="/format/2208.06551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Multiple Sequence Lengths in Fast End to End Training for  Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J+C">Jia Cheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cavicchioli%2C+R">Roberto Cavicchioli</a>, 
<a href="/search/cs?searchtype=author&query=Capotondi%2C+A">Alessandro Capotondi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07626" title="Abstract">arXiv:2208.07626</a> (replaced) [<a href="/pdf/2208.07626" title="Download PDF">pdf</a>, <a href="/ps/2208.07626" title="Download PostScript">ps</a>, <a href="/format/2208.07626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic Assistance with Recommendation-Dependent Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McLaughlin%2C+B">Bryce McLaughlin</a>, 
<a href="/search/cs?searchtype=author&query=Spiess%2C+J">Jann Spiess</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09424" title="Abstract">arXiv:2208.09424</a> (replaced) [<a href="/pdf/2208.09424" title="Download PDF">pdf</a>, <a href="/format/2208.09424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Compositional Representations for Few-shot Action  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shuzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguang Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Computer Vision and Image Understanding
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00315" title="Abstract">arXiv:2209.00315</a> (replaced) [<a href="/pdf/2209.00315" title="Download PDF">pdf</a>, <a href="/format/2209.00315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient preconditioners for solving dynamical optimal transport via  interior point methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Facca%2C+E">Enrico Facca</a>, 
<a href="/search/math?searchtype=author&query=Todeschi%2C+G">Gabriele Todeschi</a>, 
<a href="/search/math?searchtype=author&query=Natale%2C+A">Andrea Natale</a>, 
<a href="/search/math?searchtype=author&query=Benzi%2C+M">Michele Benzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01175" title="Abstract">arXiv:2209.01175</a> (replaced) [<a href="/pdf/2209.01175" title="Download PDF">pdf</a>, <a href="/ps/2209.01175" title="Download PostScript">ps</a>, <a href="/format/2209.01175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intentional and serendipitous diffusion of ideas: Evidence from academic  conferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teplitskiy%2C+M">Misha Teplitskiy</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Soya Park</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+N">Neil Thompson</a>, 
<a href="/search/cs?searchtype=author&query=Karger%2C+D">David Karger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11229" title="Abstract">arXiv:2209.11229</a> (replaced) [<a href="/pdf/2209.11229" title="Download PDF">pdf</a>, <a href="/format/2209.11229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposition horizons and a characterization of stable hereditary  classes of graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braunfeld%2C+S">Samuel Braunfeld</a>, 
<a href="/search/cs?searchtype=author&query=Ne%C5%A1et%C5%99il%2C+J">Jaroslav Ne&#x161;et&#x159;il</a>, 
<a href="/search/cs?searchtype=author&query=de+Mendez%2C+P+O">Patrice Ossona de Mendez</a>, 
<a href="/search/cs?searchtype=author&query=Siebertz%2C+S">Sebastian Siebertz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02672" title="Abstract">arXiv:2210.02672</a> (replaced) [<a href="/pdf/2210.02672" title="Download PDF">pdf</a>, <a href="/format/2210.02672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Maximum-Entropy-Driven Technique for Low-Rank Orthogonal  Nonnegative Matrix Factorization with $\ell_0$-Norm sparsity Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basiri%2C+S">Salar Basiri</a>, 
<a href="/search/cs?searchtype=author&query=Salapaka%2C+S">Srinivasa Salapaka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08302" title="Abstract">arXiv:2210.08302</a> (replaced) [<a href="/pdf/2210.08302" title="Download PDF">pdf</a>, <a href="/format/2210.08302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projective Integration Methods in the Runge-Kutta Framework and the  Extension to Adaptivity in Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Koellermeier%2C+J">Julian Koellermeier</a>, 
<a href="/search/math?searchtype=author&query=Samaey%2C+G">Giovanni Samaey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09017" title="Abstract">arXiv:2210.09017</a> (replaced) [<a href="/pdf/2210.09017" title="Download PDF">pdf</a>, <a href="/ps/2210.09017" title="Download PostScript">ps</a>, <a href="/format/2210.09017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Data-Driven Moving Horizon Estimation for Linear Discrete-Time  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wolff%2C+T+M">Tobias M. Wolff</a>, 
<a href="/search/eess?searchtype=author&query=Lopez%2C+V+G">Victor G. Lopez</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11795" title="Abstract">arXiv:2210.11795</a> (replaced) [<a href="/pdf/2210.11795" title="Download PDF">pdf</a>, <a href="/format/2210.11795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoseScript: Linking 3D Human Poses and Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delmas%2C+G">Ginger Delmas</a>, 
<a href="/search/cs?searchtype=author&query=Weinzaepfel%2C+P">Philippe Weinzaepfel</a>, 
<a href="/search/cs?searchtype=author&query=Lucas%2C+T">Thomas Lucas</a>, 
<a href="/search/cs?searchtype=author&query=Moreno-Noguer%2C+F">Francesc Moreno-Noguer</a>, 
<a href="/search/cs?searchtype=author&query=Rogez%2C+G">Gr&#xe9;gory Rogez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the ECCV 2022 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07550" title="Abstract">arXiv:2211.07550</a> (replaced) [<a href="/pdf/2211.07550" title="Download PDF">pdf</a>, <a href="/ps/2211.07550" title="Download PostScript">ps</a>, <a href="/format/2211.07550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree-layout based graph classes: proper chordal graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paul%2C+C">Christophe Paul</a>, 
<a href="/search/cs?searchtype=author&query=Protopapas%2C+E">Evangelos Protopapas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12121" title="Abstract">arXiv:2211.12121</a> (replaced) [<a href="/pdf/2211.12121" title="Download PDF">pdf</a>, <a href="/ps/2211.12121" title="Download PostScript">ps</a>, <a href="/format/2211.12121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Least squares approximations in linear statistical inverse learning  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Helin%2C+T">Tapio Helin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13350" title="Abstract">arXiv:2211.13350</a> (replaced) [<a href="/pdf/2211.13350" title="Download PDF">pdf</a>, <a href="/format/2211.13350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choreographer: Learning and Adapting Skills in Imagination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazzaglia%2C+P">Pietro Mazzaglia</a>, 
<a href="/search/cs?searchtype=author&query=Verbelen%2C+T">Tim Verbelen</a>, 
<a href="/search/cs?searchtype=author&query=Dhoedt%2C+B">Bart Dhoedt</a>, 
<a href="/search/cs?searchtype=author&query=Lacoste%2C+A">Alexandre Lacoste</a>, 
<a href="/search/cs?searchtype=author&query=Rajeswar%2C+S">Sai Rajeswar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2023 (notable top 25%)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00219" title="Abstract">arXiv:2212.00219</a> (replaced) [<a href="/pdf/2212.00219" title="Download PDF">pdf</a>, <a href="/format/2212.00219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are you using test log-likelihood correctly?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Deshpande%2C+S+K">Sameer K. Deshpande</a>, 
<a href="/search/stat?searchtype=author&query=Ghosh%2C+S">Soumya Ghosh</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+T+D">Tin D. Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Broderick%2C+T">Tamara Broderick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the ICBINB Workshop at NeurIPS 2022. This version accepted at TMLR, available at <a href="https://openreview.net/forum?id=n2YifD4Dxo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Other Statistics (stat.OT)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01521" title="Abstract">arXiv:2212.01521</a> (replaced) [<a href="/pdf/2212.01521" title="Download PDF">pdf</a>, <a href="/format/2212.01521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution Fitting for Combating Mode Collapse in Generative  Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yanxiang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhiwei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+G">Guozhen Duan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Mei Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08044" title="Abstract">arXiv:2212.08044</a> (replaced) [<a href="/pdf/2212.08044" title="Download PDF">pdf</a>, <a href="/format/2212.08044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Robustness of Multimodal Image-Text Models under  Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jielin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xingjian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wenzel%2C+F">Florian Wenzel</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhiqiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Journal of Data-centric Machine Learning Research (DMLR) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09726" title="Abstract">arXiv:2212.09726</a> (replaced) [<a href="/pdf/2212.09726" title="Download PDF">pdf</a>, <a href="/format/2212.09726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Faithfulness of Abstractive Summarization by Controlling  Confounding Effect of Irrelevant Sentences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghoshal%2C+A">Asish Ghoshal</a>, 
<a href="/search/cs?searchtype=author&query=Einolghozati%2C+A">Arash Einolghozati</a>, 
<a href="/search/cs?searchtype=author&query=Arun%2C+A">Ankit Arun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lili Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gor%2C+V">Vera Gor</a>, 
<a href="/search/cs?searchtype=author&query=Mehdad%2C+Y">Yashar Mehdad</a>, 
<a href="/search/cs?searchtype=author&query=Yih%2C+S+W">Scott Wen-tau Yih</a>, 
<a href="/search/cs?searchtype=author&query=Celikyilmaz%2C+A">Asli Celikyilmaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07300" title="Abstract">arXiv:2301.07300</a> (replaced) [<a href="/pdf/2301.07300" title="Download PDF">pdf</a>, <a href="/format/2301.07300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two New Upper Bounds for the Maximum k-plex Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jiongzhi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mingming Jin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kun He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10766" title="Abstract">arXiv:2301.10766</a> (replaced) [<a href="/pdf/2301.10766" title="Download PDF">pdf</a>, <a href="/format/2301.10766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Adversarial Robustness of Camera-based 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shaoyuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zichao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Transactions on Machine Learning Research, 2024. ISSN 2835-8856
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13359" title="Abstract">arXiv:2301.13359</a> (replaced) [<a href="/pdf/2301.13359" title="Download PDF">pdf</a>, <a href="/format/2301.13359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Guoyang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinbao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiayi Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+F">Feng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06120" title="Abstract">arXiv:2302.06120</a> (replaced) [<a href="/pdf/2302.06120" title="Download PDF">pdf</a>, <a href="/format/2302.06120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge from Large-Scale Protein Contact Prediction Models Can Be  Transferred to the Data-Scarce RNA Contact Prediction Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Jian%2C+Y">Yiren Jian</a>, 
<a href="/search/q-bio?searchtype=author&query=Gao%2C+C">Chongyang Gao</a>, 
<a href="/search/q-bio?searchtype=author&query=Zeng%2C+C">Chen Zeng</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhao%2C+Y">Yunjie Zhao</a>, 
<a href="/search/q-bio?searchtype=author&query=Vosoughi%2C+S">Soroush Vosoughi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code is available at <a href="https://github.com/yiren-jian/CoT-RNA-Transfer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09648" title="Abstract">arXiv:2302.09648</a> (replaced) [<a href="/pdf/2302.09648" title="Download PDF">pdf</a>, <a href="/format/2302.09648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wrapyfi: A Python Wrapper for Integrating Robots, Sensors, and  Applications across Multiple Middleware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abawi%2C+F">Fares Abawi</a>, 
<a href="/search/cs?searchtype=author&query=Allgeuer%2C+P">Philipp Allgeuer</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Di Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at HRI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12190" title="Abstract">arXiv:2302.12190</a> (replaced) [<a href="/pdf/2302.12190" title="Download PDF">pdf</a>, <a href="/format/2302.12190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCWDST: a Minimum-Cost Weighted Directed Spanning Tree Algorithm for  Real-Time Fake News Mitigation in Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truic%C4%83%2C+C">Ciprian-Octavian Truic&#x103;</a>, 
<a href="/search/cs?searchtype=author&query=Apostol%2C+E">Elena-Simona Apostol</a>, 
<a href="/search/cs?searchtype=author&query=Nicolescu%2C+R">Radu-C&#x103;t&#x103;lin Nicolescu</a>, 
<a href="/search/cs?searchtype=author&query=Karras%2C+P">Panagiotis Karras</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, 11:125861-125873, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13854" title="Abstract">arXiv:2302.13854</a> (replaced) [<a href="/pdf/2302.13854" title="Download PDF">pdf</a>, <a href="/format/2302.13854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Neural Network Based Reverse Radio Spectrogram Search Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ma%2C+P+X">Peter Xiangyuan Ma</a>, 
<a href="/search/eess?searchtype=author&query=Croft%2C+S">Steve Croft</a>, 
<a href="/search/eess?searchtype=author&query=Lintott%2C+C">Chris Lintott</a>, 
<a href="/search/eess?searchtype=author&query=Siemion%2C+A+P+V">Andrew P. V. Siemion</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> RAS Techniques and Instruments 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02506" title="Abstract">arXiv:2303.02506</a> (replaced) [<a href="/pdf/2303.02506" title="Download PDF">pdf</a>, <a href="/format/2303.02506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prismer: A Vision-Language Model with Multi-Task Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shikun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Linxi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Johns%2C+E">Edward Johns</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiding Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at TMLR 2024. Project Page: <a href="https://shikun.io/projects/prismer">this https URL</a> Code: <a href="https://github.com/NVlabs/prismer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02901" title="Abstract">arXiv:2303.02901</a> (replaced) [<a href="/pdf/2303.02901" title="Download PDF">pdf</a>, <a href="/format/2303.02901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3b1;$-divergence Improves the Entropy Production Estimation via  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Kwon%2C+E">Euijoon Kwon</a>, 
<a href="/search/cond-mat?searchtype=author&query=Baek%2C+Y">Yongjoo Baek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03183" title="Abstract">arXiv:2303.03183</a> (replaced) [<a href="/pdf/2303.03183" title="Download PDF">pdf</a>, <a href="/ps/2303.03183" title="Download PostScript">ps</a>, <a href="/format/2303.03183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing synthetic training data for the supervised classification of  rat ultrasonic vocalizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scott%2C+K+J">K. Jack Scott</a>, 
<a href="/search/cs?searchtype=author&query=Speers%2C+L+J">Lucinda J. Speers</a>, 
<a href="/search/cs?searchtype=author&query=Bilkey%2C+D+K">David K. Bilkey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 main figures, 2 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J Acoust Soc Am 1 January 2024 155 (1)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04892" title="Abstract">arXiv:2303.04892</a> (replaced) [<a href="/pdf/2303.04892" title="Download PDF">pdf</a>, <a href="/format/2303.04892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some New Results on the Maximum Growth Factor in Gaussian Elimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Edelman%2C+A">Alan Edelman</a>, 
<a href="/search/math?searchtype=author&query=Urschel%2C+J">John Urschel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05015" title="Abstract">arXiv:2303.05015</a> (replaced) [<a href="/pdf/2303.05015" title="Download PDF">pdf</a>, <a href="/format/2303.05015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smooth and Stepwise Self-Distillation for Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jieren Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhihong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Aguiar%2C+D">Derek Aguiar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Conference on Image Processing (ICIP) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14501" title="Abstract">arXiv:2303.14501</a> (replaced) [<a href="/pdf/2303.14501" title="Download PDF">pdf</a>, <a href="/format/2303.14501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Link Prediction for Flow-Driven Spatial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wittmann%2C+B">Bastian Wittmann</a>, 
<a href="/search/cs?searchtype=author&query=Paetzold%2C+J+C">Johannes C. Paetzold</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakar%2C+C">Chinmay Prabhakar</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Menze%2C+B">Bjoern Menze</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17046" title="Abstract">arXiv:2303.17046</a> (replaced) [<a href="/pdf/2303.17046" title="Download PDF">pdf</a>, <a href="/format/2303.17046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Have it your way: Individualized Privacy Assignment for DP-SGD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boenisch%2C+F">Franziska Boenisch</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BChl%2C+C">Christopher M&#xfc;hl</a>, 
<a href="/search/cs?searchtype=author&query=Dziedzic%2C+A">Adam Dziedzic</a>, 
<a href="/search/cs?searchtype=author&query=Rinberg%2C+R">Roy Rinberg</a>, 
<a href="/search/cs?searchtype=author&query=Papernot%2C+N">Nicolas Papernot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS'2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00746" title="Abstract">arXiv:2304.00746</a> (replaced) [<a href="/pdf/2304.00746" title="Download PDF">pdf</a>, <a href="/format/2304.00746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OTS: A One-shot Learning Approach for Text Spotting in Historical  Manuscripts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenbo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+H">Hongjian Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Bing Yin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yue Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05763" title="Abstract">arXiv:2304.05763</a> (replaced) [<a href="/pdf/2304.05763" title="Download PDF">pdf</a>, <a href="/ps/2304.05763" title="Download PostScript">ps</a>, <a href="/format/2304.05763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning coordination through new actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castro%2C+S+B+S+D">Sofia B.S.D. Castro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11171" title="Abstract">arXiv:2304.11171</a> (replaced) [<a href="/pdf/2304.11171" title="Download PDF">pdf</a>, <a href="/format/2304.11171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Granular-ball computing: an efficient, robust, and interpretable  adaptive multi-granularity representation and computation method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shuyin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+X">Xiaoyu Lian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13189" title="Abstract">arXiv:2304.13189</a> (replaced) [<a href="/pdf/2304.13189" title="Download PDF">pdf</a>, <a href="/format/2304.13189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Onboard Science Instrument Autonomy for the Detection of Microscopy  Biosignatures on the Ocean Worlds Life Surveyor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Wronkiewicz%2C+M">Mark Wronkiewicz</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lee%2C+J">Jake Lee</a>, 
<a href="/search/astro-ph?searchtype=author&query=Mandrake%2C+L">Lukas Mandrake</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lightholder%2C+J">Jack Lightholder</a>, 
<a href="/search/astro-ph?searchtype=author&query=Doran%2C+G">Gary Doran</a>, 
<a href="/search/astro-ph?searchtype=author&query=Mauceri%2C+S">Steffen Mauceri</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kim%2C+T">Taewoo Kim</a>, 
<a href="/search/astro-ph?searchtype=author&query=Oborny%2C+N">Nathan Oborny</a>, 
<a href="/search/astro-ph?searchtype=author&query=Schibler%2C+T">Thomas Schibler</a>, 
<a href="/search/astro-ph?searchtype=author&query=Nadeau%2C+J">Jay Nadeau</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wallace%2C+J+K">James K. Wallace</a>, 
<a href="/search/astro-ph?searchtype=author&query=Moorjani%2C+E">Eshaan Moorjani</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lindensmith%2C+C">Chris Lindensmith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages, 18 figures, accepted by The Planetary Science Journal on 2023-10-09
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Earth and Planetary Astrophysics (astro-ph.EP); Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01120" title="Abstract">arXiv:2305.01120</a> (replaced) [<a href="/pdf/2305.01120" title="Download PDF">pdf</a>, <a href="/format/2305.01120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LST-Bench: Benchmarking Log-Structured Tables in the Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Camacho-Rodr%C3%ADguez%2C+J">Jes&#xfa;s Camacho-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Ashvin Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Gruenheid%2C+A">Anja Gruenheid</a>, 
<a href="/search/cs?searchtype=author&query=Gosalia%2C+A">Ashit Gosalia</a>, 
<a href="/search/cs?searchtype=author&query=Petculescu%2C+C">Cristian Petculescu</a>, 
<a href="/search/cs?searchtype=author&query=Aguilar-Saborit%2C+J">Josep Aguilar-Saborit</a>, 
<a href="/search/cs?searchtype=author&query=Floratou%2C+A">Avrilia Floratou</a>, 
<a href="/search/cs?searchtype=author&query=Curino%2C+C">Carlo Curino</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+R">Raghu Ramakrishnan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the ACM on Management of Data (2024) Volume 2 Issue
  1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03077" title="Abstract">arXiv:2305.03077</a> (replaced) [<a href="/pdf/2305.03077" title="Download PDF">pdf</a>, <a href="/format/2305.03077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining dark matter halo density profiles with neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Lucie-Smith%2C+L">Luisa Lucie-Smith</a>, 
<a href="/search/astro-ph?searchtype=author&query=Peiris%2C+H+V">Hiranya V. Peiris</a>, 
<a href="/search/astro-ph?searchtype=author&query=Pontzen%2C+A">Andrew Pontzen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures. Minor changes to match version accepted for publication in PRL
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. Lett. 132, 031001 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11834" title="Abstract">arXiv:2305.11834</a> (replaced) [<a href="/pdf/2305.11834" title="Download PDF">pdf</a>, <a href="/format/2305.11834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pengi: An Audio Language Model for Audio Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deshmukh%2C+S">Soham Deshmukh</a>, 
<a href="/search/eess?searchtype=author&query=Elizalde%2C+B">Benjamin Elizalde</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+R">Rita Singh</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Huaming Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. The manuscript is updated with additional experiments suggested by reviewers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13310" title="Abstract">arXiv:2305.13310</a> (replaced) [<a href="/pdf/2305.13310" title="Download PDF">pdf</a>, <a href="/format/2305.13310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matcher: Segment Anything with One Shot Using All-Purpose Feature  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Muzhi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hengtao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14402" title="Abstract">arXiv:2305.14402</a> (replaced) [<a href="/pdf/2305.14402" title="Download PDF">pdf</a>, <a href="/format/2305.14402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Speech Emotion Recognition Through Differentiable Architecture  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajapakshe%2C+T">Thejan Rajapakshe</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+R">Rajib Rana</a>, 
<a href="/search/cs?searchtype=author&query=Khalifa%2C+S">Sara Khalifa</a>, 
<a href="/search/cs?searchtype=author&query=Sisman%2C+B">Berrak Sisman</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B">Bj&#xf6;rn Schuller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00119" title="Abstract">arXiv:2306.00119</a> (replaced) [<a href="/pdf/2306.00119" title="Download PDF">pdf</a>, <a href="/format/2306.00119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Sets and Solution Paths of ReLU Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishkin%2C+A">Aaron Mishkin</a>, 
<a href="/search/cs?searchtype=author&query=Pilanci%2C+M">Mert Pilanci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor updates and corrections to clarify the role of merge/split symmetries in formation of ReLU optimal set and add missing sufficient conditions for all minimal models to have the same cardinality
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40th International Conference on Machine
  Learning, PMLR 202:24888-24924, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00168" title="Abstract">arXiv:2306.00168</a> (replaced) [<a href="/pdf/2306.00168" title="Download PDF">pdf</a>, <a href="/format/2306.00168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the Robustness of NLP Models to Domain Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calderon%2C+N">Nitay Calderon</a>, 
<a href="/search/cs?searchtype=author&query=Porat%2C+N">Naveh Porat</a>, 
<a href="/search/cs?searchtype=author&query=Ben-David%2C+E">Eyal Ben-David</a>, 
<a href="/search/cs?searchtype=author&query=Chapanin%2C+A">Alexander Chapanin</a>, 
<a href="/search/cs?searchtype=author&query=Gekhman%2C+Z">Zorik Gekhman</a>, 
<a href="/search/cs?searchtype=author&query=Oved%2C+N">Nadav Oved</a>, 
<a href="/search/cs?searchtype=author&query=Shalumov%2C+V">Vitaly Shalumov</a>, 
<a href="/search/cs?searchtype=author&query=Reichart%2C+R">Roi Reichart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07863" title="Abstract">arXiv:2306.07863</a> (replaced) [<a href="/pdf/2306.07863" title="Download PDF">pdf</a>, <a href="/format/2306.07863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Longtao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rundong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinrun Wang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024. Project page: <a href="https://ltzheng.github.io/Synapse">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08251" title="Abstract">arXiv:2306.08251</a> (replaced) [<a href="/pdf/2306.08251" title="Download PDF">pdf</a>, <a href="/format/2306.08251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GBSD: Generative Bokeh with Stage Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jieren Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhihong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Aguiar%2C+D">Derek Aguiar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short Version is accepted by International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10822" title="Abstract">arXiv:2306.10822</a> (replaced) [<a href="/pdf/2306.10822" title="Download PDF">pdf</a>, <a href="/format/2306.10822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting Deep Neural Networks with the Package innsight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Koenen%2C+N">Niklas Koenen</a>, 
<a href="/search/stat?searchtype=author&query=Wright%2C+M+N">Marvin N. Wright</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12771" title="Abstract">arXiv:2306.12771</a> (replaced) [<a href="/pdf/2306.12771" title="Download PDF">pdf</a>, <a href="/format/2306.12771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Compression of Deterministic Finite Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bille%2C+P">Philip Bille</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B8rtz%2C+I+L">Inge Li G&#xf8;rtz</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+M+R">Max Rish&#xf8;j Pedersen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16143" title="Abstract">arXiv:2306.16143</a> (replaced) [<a href="/pdf/2306.16143" title="Download PDF">pdf</a>, <a href="/format/2306.16143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative User-Experience Research for Developing Domain-specific  Natural Language Processing Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhukova%2C+A">Anastasia Zhukova</a>, 
<a href="/search/cs?searchtype=author&query=von+Sperl%2C+L">Lukas von Sperl</a>, 
<a href="/search/cs?searchtype=author&query=Matt%2C+C+E">Christian E. Matt</a>, 
<a href="/search/cs?searchtype=author&query=Gipp%2C+B">Bela Gipp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16199" title="Abstract">arXiv:2306.16199</a> (replaced) [<a href="/pdf/2306.16199" title="Download PDF">pdf</a>, <a href="/ps/2306.16199" title="Download PostScript">ps</a>, <a href="/format/2306.16199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape and parameter identification by the linear sampling method for a  restricted Fourier integral operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Audibert%2C+L">Lorenzo Audibert</a>, 
<a href="/search/math?searchtype=author&query=Meng%2C+S">Shixu Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17248" title="Abstract">arXiv:2306.17248</a> (replaced) [<a href="/pdf/2306.17248" title="Download PDF">pdf</a>, <a href="/format/2306.17248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TemperatureGAN: Generative Modeling of Regional Atmospheric Temperatures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balogun%2C+E">Emmanuel Balogun</a>, 
<a href="/search/cs?searchtype=author&query=Rajagopal%2C+R">Ram Rajagopal</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Arun Majumdar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08078" title="Abstract">arXiv:2307.08078</a> (replaced) [<a href="/pdf/2307.08078" title="Download PDF">pdf</a>, <a href="/format/2307.08078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient numerical method for multi-term time-fractional diffusion  equations with Caputo-Fabrizio derivatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fan%2C+B">Bin Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14995" title="Abstract">arXiv:2307.14995</a> (replaced) [<a href="/pdf/2307.14995" title="Download PDF">pdf</a>, <a href="/format/2307.14995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransNormerLLM: A Faster and Better Large Language Model with Improved  TransNormer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weigao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuyang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaodong Han</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunshen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+B">Baohong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. Yiran Zhong is the corresponding author. Zhen Qin, Dong Li, Weigao Sun, Weixuan Sun, Xuyang Shen contribute equally to this paper. Code is released at: <a href="https://github.com/OpenNLPLab/TransnormerLLM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15610" title="Abstract">arXiv:2307.15610</a> (replaced) [<a href="/pdf/2307.15610" title="Download PDF">pdf</a>, <a href="/format/2307.15610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trends and Topics: Characterizing Echo Chambers&#x27; Topological Stability  and In-group Attitudes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cau%2C+E">Erica Cau</a>, 
<a href="/search/cs?searchtype=author&query=Morini%2C+V">Virginia Morini</a>, 
<a href="/search/cs?searchtype=author&query=Rossetti%2C+G">Giulio Rossetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15879" title="Abstract">arXiv:2307.15879</a> (replaced) [<a href="/pdf/2307.15879" title="Download PDF">pdf</a>, <a href="/ps/2307.15879" title="Download PostScript">ps</a>, <a href="/format/2307.15879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shortest paths search method based on the projective description of  unweighted mixed graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melent%27ev%2C+V+A">V. A. Melent&#x27;ev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, in Russian language, 1 figures, 2 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02202" title="Abstract">arXiv:2308.02202</a> (replaced) [<a href="/pdf/2308.02202" title="Download PDF">pdf</a>, <a href="/format/2308.02202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: The Ghost Trilemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Sulagna Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S">Srivatsan Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+P">Paul Schmitt</a>, 
<a href="/search/cs?searchtype=author&query=Raghavan%2C+B">Barath Raghavan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages with 1 figure and 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03016" title="Abstract">arXiv:2308.03016</a> (replaced) [<a href="/pdf/2308.03016" title="Download PDF">pdf</a>, <a href="/format/2308.03016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shaping a Smarter Electromagnetic Landscape: IAB, NCR, and RIS in 5G  Standard and Future 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chao-Kai Wen</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+L">Lung-Sheng Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Shojaeifard%2C+A">Arman Shojaeifard</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+P">Pei-Kai Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kai-Kit Wong</a>, 
<a href="/search/cs?searchtype=author&query=Chae%2C+C">Chan-Byoung Chae</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 1 table. This work has been accepted to publish in IEEE Communications Standards Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03279" title="Abstract">arXiv:2308.03279</a> (replaced) [<a href="/pdf/2308.03279" title="Download PDF">pdf</a>, <a href="/format/2308.03279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniversalNER: Targeted Distillation from Large Language Models for Open  Named Entity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+H">Hoifung Poon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024. Project page: <a href="https://universal-ner.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07107" title="Abstract">arXiv:2308.07107</a> (replaced) [<a href="/pdf/2308.07107" title="Download PDF">pdf</a>, <a href="/format/2308.07107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Information Retrieval: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yutao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Huaying Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiongnan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenhan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chenlong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haonan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhicheng Dou</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated to version 2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08033" title="Abstract">arXiv:2308.08033</a> (replaced) [<a href="/pdf/2308.08033" title="Download PDF">pdf</a>, <a href="/format/2308.08033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptation for Deep Unit Test Case Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jiho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Hashtroudi%2C+S">Sepehr Hashtroudi</a>, 
<a href="/search/cs?searchtype=author&query=Hemmati%2C+H">Hadi Hemmati</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages + reference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12871" title="Abstract">arXiv:2308.12871</a> (replaced) [<a href="/pdf/2308.12871" title="Download PDF">pdf</a>, <a href="/format/2308.12871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPA: Inference Pipeline Adaptation to Achieve High Accuracy and  Cost-Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghafouri%2C+S">Saeid Ghafouri</a>, 
<a href="/search/cs?searchtype=author&query=Razavi%2C+K">Kamran Razavi</a>, 
<a href="/search/cs?searchtype=author&query=Salmani%2C+M">Mehran Salmani</a>, 
<a href="/search/cs?searchtype=author&query=Sanaee%2C+A">Alireza Sanaee</a>, 
<a href="/search/cs?searchtype=author&query=Lorido-Botran%2C+T">Tania Lorido-Botran</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Doyle%2C+J">Joseph Doyle</a>, 
<a href="/search/cs?searchtype=author&query=Jamshidi%2C+P">Pooyan Jamshidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14724" title="Abstract">arXiv:2308.14724</a> (replaced) [<a href="/pdf/2308.14724" title="Download PDF">pdf</a>, <a href="/ps/2308.14724" title="Download PostScript">ps</a>, <a href="/format/2308.14724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conceptual articles may disrupt the field of marketing: Evidence from a  GPT-assisted study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+J">Jennifer JooYeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunuk Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16902" title="Abstract">arXiv:2308.16902</a> (replaced) [<a href="/pdf/2308.16902" title="Download PDF">pdf</a>, <a href="/format/2308.16902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short Paper: Accountable Safety Implies Finality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neu%2C+J">Joachim Neu</a>, 
<a href="/search/cs?searchtype=author&query=Tas%2C+E+N">Ertem Nusret Tas</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+D">David Tse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Financial Cryptography and Data Security 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02119" title="Abstract">arXiv:2309.02119</a> (replaced) [<a href="/pdf/2309.02119" title="Download PDF">pdf</a>, <a href="/format/2309.02119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Masked 3D Diffusion Model for Video Outpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+F">Fanda Fan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chaoxu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Litong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Biao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tiezheng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuning Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chunjie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jianfeng Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02773" title="Abstract">arXiv:2309.02773</a> (replaced) [<a href="/pdf/2309.02773" title="Download PDF">pdf</a>, <a href="/format/2309.02773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Model is Secretly a Training-free Open Vocabulary Semantic  Segmenter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qingyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04452" title="Abstract">arXiv:2309.04452</a> (replaced) [<a href="/pdf/2309.04452" title="Download PDF">pdf</a>, <a href="/format/2309.04452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Postprocessing of Ensemble Weather Forecasts Using Permutation-invariant  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=H%C3%B6hlein%2C+K">Kevin H&#xf6;hlein</a>, 
<a href="/search/stat?searchtype=author&query=Schulz%2C+B">Benedikt Schulz</a>, 
<a href="/search/stat?searchtype=author&query=Westermann%2C+R">R&#xfc;diger Westermann</a>, 
<a href="/search/stat?searchtype=author&query=Lerch%2C+S">Sebastian Lerch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in press
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Artificial Intelligence for the Earth Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06023" title="Abstract">arXiv:2309.06023</a> (replaced) [<a href="/pdf/2309.06023" title="Download PDF">pdf</a>, <a href="/format/2309.06023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from History: Task-agnostic Model Contrastive Learning for  Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera Ready Version. Accepted to The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07988" title="Abstract">arXiv:2309.07988</a> (replaced) [<a href="/pdf/2309.07988" title="Download PDF">pdf</a>, <a href="/format/2309.07988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Folding Attention: Memory and Power Optimization for On-Device  Transformer-based Streaming Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+L">Liangzhen Lai</a>, 
<a href="/search/cs?searchtype=author&query=Shangguan%2C+Y">Yuan Shangguan</a>, 
<a href="/search/cs?searchtype=author&query=Iandola%2C+F+N">Forrest N. Iandola</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zhaoheng Ni</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+E">Ernie Chang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yangyang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08565" title="Abstract">arXiv:2309.08565</a> (replaced) [<a href="/pdf/2309.08565" title="Download PDF">pdf</a>, <a href="/format/2309.08565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Transferable are Attribute Controllers on Pretrained Multilingual  Translation Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Danni Liu</a>, 
<a href="/search/cs?searchtype=author&query=Niehues%2C+J">Jan Niehues</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09466" title="Abstract">arXiv:2309.09466</a> (replaced) [<a href="/pdf/2309.09466" title="Download PDF">pdf</a>, <a href="/format/2309.09466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Text-to-Image Diffusion with Soft Latent Direction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">YuTeng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jiale Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zikai Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chenxing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10444" title="Abstract">arXiv:2309.10444</a> (replaced) [<a href="/pdf/2309.10444" title="Download PDF">pdf</a>, <a href="/format/2309.10444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Iterative Enhancement for Improving Learnersourced  Multiple-Choice Question Explanations with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+Q">Qiming Bao</a>, 
<a href="/search/cs?searchtype=author&query=Leinonen%2C+J">Juho Leinonen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+A+Y">Alex Yuxuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanjun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Gendron%2C+G">Ga&#xeb;l Gendron</a>, 
<a href="/search/cs?searchtype=author&query=Pistotti%2C+T">Timothy Pistotti</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+A">Alice Huang</a>, 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Paul Denny</a>, 
<a href="/search/cs?searchtype=author&query=Witbrock%2C+M">Michael Witbrock</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamou Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11623" title="Abstract">arXiv:2309.11623</a> (replaced) [<a href="/pdf/2309.11623" title="Download PDF">pdf</a>, <a href="/ps/2309.11623" title="Download PostScript">ps</a>, <a href="/format/2309.11623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Negative Signals with Self-Attention for Sequential Music  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seshadri%2C+P">Pavan Seshadri</a>, 
<a href="/search/cs?searchtype=author&query=Knees%2C+P">Peter Knees</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 1st Workshop on Music Recommender Systems, co-located with the 17th ACM Conference on Recommender Systems (MuRS @ RecSys 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14393" title="Abstract">arXiv:2309.14393</a> (replaced) [<a href="/pdf/2309.14393" title="Download PDF">pdf</a>, <a href="/format/2309.14393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faiz%2C+A">Ahmad Faiz</a>, 
<a href="/search/cs?searchtype=author&query=Kaneda%2C+S">Sotaro Kaneda</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Osi%2C+R">Rita Osi</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Prateek Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lei Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> published in ICLR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16284" title="Abstract">arXiv:2309.16284</a> (replaced) [<a href="/pdf/2309.16284" title="Download PDF">pdf</a>, <a href="/format/2309.16284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NOMAD: Unsupervised Learning of Perceptual Embeddings for Speech  Enhancement and Non-matching Reference Audio Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ragano%2C+A">Alessandro Ragano</a>, 
<a href="/search/cs?searchtype=author&query=Skoglund%2C+J">Jan Skoglund</a>, 
<a href="/search/cs?searchtype=author&query=Hines%2C+A">Andrew Hines</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01202" title="Abstract">arXiv:2310.01202</a> (replaced) [<a href="/pdf/2310.01202" title="Download PDF">pdf</a>, <a href="/format/2310.01202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Uncertainty Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chaudhuri%2C+K">Kamalika Chaudhuri</a>, 
<a href="/search/stat?searchtype=author&query=Lopez-Paz%2C+D">David Lopez-Paz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03298" title="Abstract">arXiv:2310.03298</a> (replaced) [<a href="/pdf/2310.03298" title="Download PDF">pdf</a>, <a href="/ps/2310.03298" title="Download PostScript">ps</a>, <a href="/format/2310.03298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive  Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yi-Ping Chen</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+L">Liwei Wang</a>, 
<a href="/search/stat?searchtype=author&query=Comlek%2C+Y">Yigitcan Comlek</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+W">Wei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03320" title="Abstract">arXiv:2310.03320</a> (replaced) [<a href="/pdf/2310.03320" title="Download PDF">pdf</a>, <a href="/format/2310.03320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+B">Balasubramaniam Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+V+N">Vassilis N. Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=Rangwala%2C+H">Huzefa Rangwala</a>, 
<a href="/search/cs?searchtype=author&query=Anubhai%2C+R">Rishita Anubhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04391" title="Abstract">arXiv:2310.04391</a> (replaced) [<a href="/pdf/2310.04391" title="Download PDF">pdf</a>, <a href="/ps/2310.04391" title="Download PostScript">ps</a>, <a href="/format/2310.04391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Hierarchy of Spectral Invariants for Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arvind%2C+V">V. Arvind</a>, 
<a href="/search/cs?searchtype=author&query=Fuhlbr%C3%BCck%2C+F">Frank Fuhlbr&#xfc;ck</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6bler%2C+J">Johannes K&#xf6;bler</a>, 
<a href="/search/cs?searchtype=author&query=Verbitsky%2C+O">Oleg Verbitsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 1 diagram, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04965" title="Abstract">arXiv:2310.04965</a> (replaced) [<a href="/pdf/2310.04965" title="Download PDF">pdf</a>, <a href="/format/2310.04965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MULTISCRIPT: Multimodal Script Learning for Supporting Open Domain  Everyday Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jingyuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minqian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Ying Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lifu Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. 11 pages, 9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05492" title="Abstract">arXiv:2310.05492</a> (replaced) [<a href="/pdf/2310.05492" title="Download PDF">pdf</a>, <a href="/format/2310.05492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Abilities in Large Language Models are Affected by Supervised  Fine-tuning Data Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hongyi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Keming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Mingfeng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dayiheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06259" title="Abstract">arXiv:2310.06259</a> (replaced) [<a href="/pdf/2310.06259" title="Download PDF">pdf</a>, <a href="/format/2310.06259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modal Cognitive Consensus guided Audio-Visual Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shi%2C+Z">Zhaofeng Shi</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Q">Qingbo Wu</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+F">Fanman Meng</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+L">Linfeng Xu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hongliang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07551" title="Abstract">arXiv:2310.07551</a> (replaced) [<a href="/pdf/2310.07551" title="Download PDF">pdf</a>, <a href="/format/2310.07551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient third order tensor-oriented directional splitting for  exponential integrators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cassini%2C+F">Fabio Cassini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12955" title="Abstract">arXiv:2310.12955</a> (replaced) [<a href="/pdf/2310.12955" title="Download PDF">pdf</a>, <a href="/format/2310.12955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Offline Reinforcement Learning under Diverse Data  Corruption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Han Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiawei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Amy Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chongjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lei Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13384" title="Abstract">arXiv:2310.13384</a> (replaced) [<a href="/pdf/2310.13384" title="Download PDF">pdf</a>, <a href="/format/2310.13384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Salted Inference: Enhancing Privacy while Maintaining Efficiency of  Split Inference in Mobile Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malekzadeh%2C+M">Mohammad Malekzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Kawsar%2C+F">Fahim Kawsar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be appeared in the 25th International Workshop on Mobile Computing Systems and Applications (HotMobile 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14197" title="Abstract">arXiv:2310.14197</a> (replaced) [<a href="/pdf/2310.14197" title="Download PDF">pdf</a>, <a href="/format/2310.14197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-based Data Augmentation for Nuclei Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xinyi Yu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/eess?searchtype=author&query=Lou%2C+W">Wei Lou</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Siqi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+X">Xiang Wan</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Haofeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023, released code: <a href="https://github.com/lhaof/Nudiff">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14611" title="Abstract">arXiv:2310.14611</a> (replaced) [<a href="/pdf/2310.14611" title="Download PDF">pdf</a>, <a href="/format/2310.14611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive Monitoring against Pattern Regular Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ang%2C+Z">Zhendong Ang</a>, 
<a href="/search/cs?searchtype=author&query=Mathur%2C+U">Umang Mathur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18999" title="Abstract">arXiv:2310.18999</a> (replaced) [<a href="/pdf/2310.18999" title="Download PDF">pdf</a>, <a href="/format/2310.18999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynPoint: Dynamic Neural Point For View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaichen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jia-Xing Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Sangyun Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Kai Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Markham%2C+A">Andrew Markham</a>, 
<a href="/search/cs?searchtype=author&query=Trigoni%2C+N">Niki Trigoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20685" title="Abstract">arXiv:2310.20685</a> (replaced) [<a href="/pdf/2310.20685" title="Download PDF">pdf</a>, <a href="/format/2310.20685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRF Revisited: Fixing Quadrature Instability in Volume Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uy%2C+M+A">Mikaela Angelina Uy</a>, 
<a href="/search/cs?searchtype=author&query=Nakayama%2C+K">Kiyohiro Nakayama</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guandao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+R+K">Rahul Krishna Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L">Leonidas Guibas</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00772" title="Abstract">arXiv:2311.00772</a> (replaced) [<a href="/pdf/2311.00772" title="Download PDF">pdf</a>, <a href="/format/2311.00772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAGE: Smart home Agent with Grounded Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rivkin%2C+D">Dmitriy Rivkin</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+F">Francois Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Feriani%2C+A">Amal Feriani</a>, 
<a href="/search/cs?searchtype=author&query=Konar%2C+A">Abhisek Konar</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+A">Adam Sigal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Steve Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Greg Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03976" title="Abstract">arXiv:2311.03976</a> (replaced) [<a href="/pdf/2311.03976" title="Download PDF">pdf</a>, <a href="/format/2311.03976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Foundation Graph Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davies%2C+A+O">Alex O. Davies</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+R+W">Riku W. Green</a>, 
<a href="/search/cs?searchtype=author&query=Ajmeri%2C+N+S">Nirav S. Ajmeri</a>, 
<a href="/search/cs?searchtype=author&query=Filho%2C+T+M+S">Telmo M. Silva Filho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the NeurIPS 2023 New Frontiers in Graph Learning workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07202" title="Abstract">arXiv:2311.07202</a> (replaced) [<a href="/pdf/2311.07202" title="Download PDF">pdf</a>, <a href="/format/2311.07202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model  Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhe Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 6th Annual Learning for Dynamics &amp; Control Conference (L4DC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09868" title="Abstract">arXiv:2311.09868</a> (replaced) [<a href="/pdf/2311.09868" title="Download PDF">pdf</a>, <a href="/format/2311.09868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INTERVENOR: Prompt the Coding Ability of Large Language Models with the  Interactive Chain of Repairing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+G">Ganqu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Ge Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 19 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11809" title="Abstract">arXiv:2311.11809</a> (replaced) [<a href="/pdf/2311.11809" title="Download PDF">pdf</a>, <a href="/format/2311.11809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LogLead -- Fast and Integrated Log Loader, Enhancer, and Anomaly  Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%A4ntyl%C3%A4%2C+M">Mika M&#xe4;ntyl&#xe4;</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nyyss%C3%B6l%C3%A4%2C+J">Jesse Nyyss&#xf6;l&#xe4;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12399" title="Abstract">arXiv:2311.12399</a> (replaced) [<a href="/pdf/2311.12399" title="Download PDF">pdf</a>, <a href="/format/2311.12399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Graph Meets Large Language Model: Progress and Future  Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peisong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J+X">Jeffrey Xu Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress; 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13274" title="Abstract">arXiv:2311.13274</a> (replaced) [<a href="/pdf/2311.13274" title="Download PDF">pdf</a>, <a href="/format/2311.13274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Summarization Performance through Transformer-Based Prompt  Engineering in Automated Medical Reporting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Zandvoort%2C+D">Daphne van Zandvoort</a>, 
<a href="/search/cs?searchtype=author&query=Wiersema%2C+L">Laura Wiersema</a>, 
<a href="/search/cs?searchtype=author&query=Huibers%2C+T">Tom Huibers</a>, 
<a href="/search/cs?searchtype=author&query=van+Dulmen%2C+S">Sandra van Dulmen</a>, 
<a href="/search/cs?searchtype=author&query=Brinkkemper%2C+S">Sjaak Brinkkemper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, to be presented at HEALTHINF 2024, author contributions: research conducted and written by Daphne van Zandvoort and Laura Wiersema, research suggested and used software created by Tom Huibers, data provided and feedback provided by Sandra van Dulmen, supervision and feedback provided by Sjaak Brinkkemper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14118" title="Abstract">arXiv:2311.14118</a> (replaced) [<a href="/pdf/2311.14118" title="Download PDF">pdf</a>, <a href="/format/2311.14118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Impact of Replacing Private Cars with Autonomous Shuttles: An  Agent-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bogdoll%2C+D">Daniel Bogdoll</a>, 
<a href="/search/cs?searchtype=author&query=Karsch%2C+L">Louis Karsch</a>, 
<a href="/search/cs?searchtype=author&query=Amritzer%2C+J">Jennifer Amritzer</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6llner%2C+J+M">J. Marius Z&#xf6;llner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Daniel Bogdoll and Louis Karsch contributed equally. Accepted for publication at FISTS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15420" title="Abstract">arXiv:2311.15420</a> (replaced) [<a href="/pdf/2311.15420" title="Download PDF">pdf</a>, <a href="/ps/2311.15420" title="Download PostScript">ps</a>, <a href="/format/2311.15420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Modelling for Harmonic Current Emission in Low-Voltage Grid  Using MCReSANet with Interpretability Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+J">Jieyu Yao</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Hao Yu</a>, 
<a href="/search/eess?searchtype=author&query=Judge%2C+P">Paul Judge</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+J">Jiabin Jia</a>, 
<a href="/search/eess?searchtype=author&query=Djokic%2C+S">Sasa Djokic</a>, 
<a href="/search/eess?searchtype=author&query=P%C3%BCvi%2C+V">Verner P&#xfc;vi</a>, 
<a href="/search/eess?searchtype=author&query=Lehtonen%2C+M">Matti Lehtonen</a>, 
<a href="/search/eess?searchtype=author&query=Meyer%2C+J">Jan Meyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15497" title="Abstract">arXiv:2311.15497</a> (replaced) [<a href="/pdf/2311.15497" title="Download PDF">pdf</a>, <a href="/format/2311.15497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Image Registration: A Hybrid Approach Integrating Deep Learning  and Optimization Functions for Enhanced Precision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Araujo%2C+G">Gabriel De Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shanlin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohui Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18426" title="Abstract">arXiv:2311.18426</a> (replaced) [<a href="/pdf/2311.18426" title="Download PDF">pdf</a>, <a href="/format/2311.18426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis of Fractional Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aggarwal%2C+A">Ashwani Aggarwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 4 figures. Added additional results for smooth and convex functions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18488" title="Abstract">arXiv:2311.18488</a> (replaced) [<a href="/pdf/2311.18488" title="Download PDF">pdf</a>, <a href="/format/2311.18488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Complexity Linear Programming Based Decoding of Quantum LDPC codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javed%2C+S">Sana Javed</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Herrero%2C+F">Francisco Garcia-Herrero</a>, 
<a href="/search/cs?searchtype=author&query=Vasic%2C+B">Bane Vasic</a>, 
<a href="/search/cs?searchtype=author&query=Flanagan%2C+M+F">Mark F. Flanagan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the IEEE International Conference on Communications (ICC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00005" title="Abstract">arXiv:2312.00005</a> (replaced) [<a href="/pdf/2312.00005" title="Download PDF">pdf</a>, <a href="/format/2312.00005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NumCalc: An open source BEM code for solving acoustic scattering  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kreuzer%2C+W">Wolfgang Kreuzer</a>, 
<a href="/search/math?searchtype=author&query=Pollack%2C+K">Katharina Pollack</a>, 
<a href="/search/math?searchtype=author&query=Brinkmann%2C+F">Fabian Brinkmann</a>, 
<a href="/search/math?searchtype=author&query=Majdak%2C+P">Piotr Majdak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00067" title="Abstract">arXiv:2312.00067</a> (replaced) [<a href="/e-print/2312.00067" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting breast cancer with AI for individual risk-adjusted MRI  screening and early detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hirsch%2C+L">Lukas Hirsch</a>, 
<a href="/search/physics?searchtype=author&query=Huang%2C+Y">Yu Huang</a>, 
<a href="/search/physics?searchtype=author&query=Makse%2C+H+A">Hernan A. Makse</a>, 
<a href="/search/physics?searchtype=author&query=Martinez%2C+D+F">Danny F. Martinez</a>, 
<a href="/search/physics?searchtype=author&query=Hughes%2C+M">Mary Hughes</a>, 
<a href="/search/physics?searchtype=author&query=Eskreis-Winkler%2C+S">Sarah Eskreis-Winkler</a>, 
<a href="/search/physics?searchtype=author&query=Pinker%2C+K">Katja Pinker</a>, 
<a href="/search/physics?searchtype=author&query=Morris%2C+E">Elizabeth Morris</a>, 
<a href="/search/physics?searchtype=author&query=Parra%2C+L+C">Lucas C. Parra</a>, 
<a href="/search/physics?searchtype=author&query=Sutton%2C+E+J">Elizabeth J. Sutton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Major revisions and rewriting in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01185" title="Abstract">arXiv:2312.01185</a> (replaced) [<a href="/pdf/2312.01185" title="Download PDF">pdf</a>, <a href="/format/2312.01185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A ripple in time: a discontinuity in American history
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolpakov%2C+A">Alexander Kolpakov</a>, 
<a href="/search/cs?searchtype=author&query=Rivin%2C+I">Igor Rivin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures; GitHub repository <a href="https://github.com/sashakolpakov/ripple_in_time">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03263" title="Abstract">arXiv:2312.03263</a> (replaced) [<a href="/pdf/2312.03263" title="Download PDF">pdf</a>, <a href="/format/2312.03263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weathering Ongoing Uncertainty: Learning and Planning in a Time-Varying  Partially Observable Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puthumanaillam%2C+G">Gokul Puthumanaillam</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mehr%2C+N">Negar Mehr</a>, 
<a href="/search/cs?searchtype=author&query=Ornik%2C+M">Melkior Ornik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Page 3, fixed typo
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05225" title="Abstract">arXiv:2312.05225</a> (replaced) [<a href="/pdf/2312.05225" title="Download PDF">pdf</a>, <a href="/format/2312.05225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Spectral Methods: Self-supervised learning in the spectral domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yiheng Du</a>, 
<a href="/search/cs?searchtype=author&query=Chalapathi%2C+N">Nithin Chalapathi</a>, 
<a href="/search/cs?searchtype=author&query=Krishnapriyan%2C+A">Aditi Krishnapriyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to International Conference on Learning Representations (ICLR) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06200" title="Abstract">arXiv:2312.06200</a> (replaced) [<a href="/pdf/2312.06200" title="Download PDF">pdf</a>, <a href="/ps/2312.06200" title="Download PostScript">ps</a>, <a href="/format/2312.06200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving the Fundamental Limit of Lossless Analog Compression via  Polarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuai Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Liuquan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huazi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+W">Wen Tong</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiming Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 5 figures. This work was presented in part at the 2023 IEEE Global Communications Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06946" title="Abstract">arXiv:2312.06946</a> (replaced) [<a href="/pdf/2312.06946" title="Download PDF">pdf</a>, <a href="/format/2312.06946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WaterHE-NeRF: Water-ray Tracing Neural Radiance Fields for Underwater  Scene Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+T">Tianyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dehuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zongxin He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06955" title="Abstract">arXiv:2312.06955</a> (replaced) [<a href="/pdf/2312.06955" title="Download PDF">pdf</a>, <a href="/format/2312.06955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IA2U: A Transfer Plugin with Multi-Prior for In-Air Model to Underwater
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+Q">Qilin Gai</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kin-man Lam</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xianping Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06999" title="Abstract">arXiv:2312.06999</a> (replaced) [<a href="/pdf/2312.06999" title="Download PDF">pdf</a>, <a href="/format/2312.06999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGNet: Dynamic Gradient-guided Network with Noise Suppression for  Underwater Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zongxin He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dehuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kin-man Lam</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xianping Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07823" title="Abstract">arXiv:2312.07823</a> (replaced) [<a href="/pdf/2312.07823" title="Download PDF">pdf</a>, <a href="/format/2312.07823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Lens: Instance-Centric Semantic Alignment for Video  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meiqin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+C">Chao Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08010" title="Abstract">arXiv:2312.08010</a> (replaced) [<a href="/pdf/2312.08010" title="Download PDF">pdf</a>, <a href="/format/2312.08010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EZ-CLIP: Efficient Zeroshot Video Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+S">Shahzad Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Chanda%2C+S">Sukalpa Chanda</a>, 
<a href="/search/cs?searchtype=author&query=Rawat%2C+Y+S">Yogesh S Rawat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09234" title="Abstract">arXiv:2312.09234</a> (replaced) [<a href="/pdf/2312.09234" title="Download PDF">pdf</a>, <a href="/format/2312.09234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s do the time-warp-attend: Learning topological invariants of  dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moriel%2C+N">Noa Moriel</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+M">Matthew Ricci</a>, 
<a href="/search/cs?searchtype=author&query=Nitzan%2C+M">Mor Nitzan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09631" title="Abstract">arXiv:2312.09631</a> (replaced) [<a href="/pdf/2312.09631" title="Download PDF">pdf</a>, <a href="/format/2312.09631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Driven Interactive Query Simulations Based on Generative Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engelmann%2C+B">Bj&#xf6;rn Engelmann</a>, 
<a href="/search/cs?searchtype=author&query=Breuer%2C+T">Timo Breuer</a>, 
<a href="/search/cs?searchtype=author&query=Friese%2C+J+I">Jana Isabelle Friese</a>, 
<a href="/search/cs?searchtype=author&query=Schaer%2C+P">Philipp Schaer</a>, 
<a href="/search/cs?searchtype=author&query=Fuhr%2C+N">Norbert Fuhr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ECIR 2024 (Full Paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10401" title="Abstract">arXiv:2312.10401</a> (replaced) [<a href="/pdf/2312.10401" title="Download PDF">pdf</a>, <a href="/format/2312.10401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Dimensional Rationale in Graph Contrastive Learning from  Causal Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Q">Qirui Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangmeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Changwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fanjiang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11944" title="Abstract">arXiv:2312.11944</a> (replaced) [<a href="/pdf/2312.11944" title="Download PDF">pdf</a>, <a href="/format/2312.11944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPT Approximation using Treewidth: Capacitated Vertex Cover, Target Set  Selection and Vector Dominating Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+H">Huairui Chu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bingkai Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 figure, accepted by ISAAC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12653" title="Abstract">arXiv:2312.12653</a> (replaced) [<a href="/pdf/2312.12653" title="Download PDF">pdf</a>, <a href="/format/2312.12653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagnosis Of Takotsubo Syndrome By Robust Feature Selection From The  Complex Latent Space Of DL-based Segmentation Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zaman%2C+F+A">Fahim Ahmed Zaman</a>, 
<a href="/search/eess?searchtype=author&query=Alam%2C+W">Wahidul Alam</a>, 
<a href="/search/eess?searchtype=author&query=Roy%2C+T+K">Tarun Kanti Roy</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+A">Amanda Chang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+K">Kan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xiaodong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13110" title="Abstract">arXiv:2312.13110</a> (replaced) [<a href="/pdf/2312.13110" title="Download PDF">pdf</a>, <a href="/ps/2312.13110" title="Download PostScript">ps</a>, <a href="/format/2312.13110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training of Molecular GNNs via Conditional Boltzmann Generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koge%2C+D">Daiki Koge</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+N">Naoaki Ono</a>, 
<a href="/search/cs?searchtype=author&query=Kanaya%2C+S">Shigehiko Kanaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13486" title="Abstract">arXiv:2312.13486</a> (replaced) [<a href="/pdf/2312.13486" title="Download PDF">pdf</a>, <a href="/format/2312.13486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Learning with Versatile Loss Geometries for Fast Adaptation Using  Mirror Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yilang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingcong Li</a>, 
<a href="/search/cs?searchtype=author&query=Giannakis%2C+G+B">Georgios B. Giannakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14062" title="Abstract">arXiv:2312.14062</a> (replaced) [<a href="/pdf/2312.14062" title="Download PDF">pdf</a>, <a href="/ps/2312.14062" title="Download PostScript">ps</a>, <a href="/format/2312.14062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long term analysis of a geometric low-regularity integrator for  nonlinear Klein-Gordon equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/math?searchtype=author&query=Miao%2C+Z">Zhen Miao</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+Y">Yaolin Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15591" title="Abstract">arXiv:2312.15591</a> (replaced) [<a href="/pdf/2312.15591" title="Download PDF">pdf</a>, <a href="/format/2312.15591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Neural Graph Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiaxin Bai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15880" title="Abstract">arXiv:2312.15880</a> (replaced) [<a href="/pdf/2312.15880" title="Download PDF">pdf</a>, <a href="/format/2312.15880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KnowledgeNavigator: Leveraging Large Language Models for Enhanced  Reasoning over Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tiezheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qingwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiawei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dapeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yingyou Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16451" title="Abstract">arXiv:2312.16451</a> (replaced) [<a href="/pdf/2312.16451" title="Download PDF">pdf</a>, <a href="/format/2312.16451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization with Vital Phase Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Ingyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wooju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Myung%2C+H">Hyun Myung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16516" title="Abstract">arXiv:2312.16516</a> (replaced) [<a href="/pdf/2312.16516" title="Download PDF">pdf</a>, <a href="/format/2312.16516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConstScene: Dataset and Model for Advancing Robust Semantic Segmentation  in Construction Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salimi%2C+M">Maghsood Salimi</a>, 
<a href="/search/cs?searchtype=author&query=Loni%2C+M">Mohammad Loni</a>, 
<a href="/search/cs?searchtype=author&query=Afshar%2C+S">Sara Afshar</a>, 
<a href="/search/cs?searchtype=author&query=Cicchetti%2C+A">Antonio Cicchetti</a>, 
<a href="/search/cs?searchtype=author&query=Sirjani%2C+M">Marjan Sirjani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16826" title="Abstract">arXiv:2312.16826</a> (replaced) [<a href="/pdf/2312.16826" title="Download PDF">pdf</a>, <a href="/format/2312.16826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VOT: Revolutionizing Speaker Verification with Memory and Attention  Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hongyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,4 figures,6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00110" title="Abstract">arXiv:2401.00110</a> (replaced) [<a href="/pdf/2401.00110" title="Download PDF">pdf</a>, <a href="/format/2401.00110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Model with Perceptual Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shanchuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00368" title="Abstract">arXiv:2401.00368</a> (replaced) [<a href="/pdf/2401.00368" title="Download PDF">pdf</a>, <a href="/format/2401.00368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Text Embeddings with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaolong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linjun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Majumder%2C+R">Rangan Majumder</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 15 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01739" title="Abstract">arXiv:2401.01739</a> (replaced) [<a href="/pdf/2401.01739" title="Download PDF">pdf</a>, <a href="/ps/2401.01739" title="Download PostScript">ps</a>, <a href="/format/2401.01739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Soft Continuum Robot with Self-Controllable Variable Curvature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qiujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongmyoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhongxue Gan</a>, 
<a href="/search/cs?searchtype=author&query=Rojas%2C+N">Nicolas Rojas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accpeted for IEEE Robotics and Automation letters in January 2024, Imperial's open access research REF 2029 open access policy
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01984" title="Abstract">arXiv:2401.01984</a> (replaced) [<a href="/pdf/2401.01984" title="Download PDF">pdf</a>, <a href="/format/2401.01984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AUPIMO: Redefining Visual Anomaly Detection Benchmarks with High Speed  and Low Tolerance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertoldo%2C+J+P+C">Joao P. C. Bertoldo</a>, 
<a href="/search/cs?searchtype=author&query=Ameln%2C+D">Dick Ameln</a>, 
<a href="/search/cs?searchtype=author&query=Vaidya%2C+A">Ashwin Vaidya</a>, 
<a href="/search/cs?searchtype=author&query=Ak%C3%A7ay%2C+S">Samet Ak&#xe7;ay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This research has been conducted during Google Summer of Code 2023 (GSoC 2023) at OpenVINO (Intel). GSoC 2023 page: <a href="https://summerofcode.withgoogle.com/archive/2023/projects/SPMopugd">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02542" title="Abstract">arXiv:2401.02542</a> (replaced) [<a href="/pdf/2401.02542" title="Download PDF">pdf</a>, <a href="/format/2401.02542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Community Detection and Graph Neural Network Based Link Prediction  Approach for Scientific Literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chunjiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yikun Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shihan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaidi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yongye Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04336" title="Abstract">arXiv:2401.04336</a> (replaced) [<a href="/pdf/2401.04336" title="Download PDF">pdf</a>, <a href="/format/2401.04336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Efficient Private Neighbor Generation for Subgraph Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yiu%2C+S+M">Siu Ming Yiu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04398" title="Abstract">arXiv:2401.04398</a> (replaced) [<a href="/pdf/2401.04398" title="Download PDF">pdf</a>, <a href="/format/2401.04398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain-of-Table: Evolving Tables in the Reasoning Chain for Table  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chun-Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Eisenschlos%2C+J+M">Julian Martin Eisenschlos</a>, 
<a href="/search/cs?searchtype=author&query=Perot%2C+V">Vincent Perot</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Miculicich%2C+L">Lesly Miculicich</a>, 
<a href="/search/cs?searchtype=author&query=Fujii%2C+Y">Yasuhisa Fujii</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chen-Yu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+T">Tomas Pfister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04971" title="Abstract">arXiv:2401.04971</a> (replaced) [<a href="/pdf/2401.04971" title="Download PDF">pdf</a>, <a href="/format/2401.04971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Cross-Domain Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zitao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Weike Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Z">Zhong Ming</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05273" title="Abstract">arXiv:2401.05273</a> (replaced) [<a href="/pdf/2401.05273" title="Download PDF">pdf</a>, <a href="/format/2401.05273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INACIA: Integrating Large Language Models in Brazilian Audit Courts:  Opportunities and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pereira%2C+J">Jayr Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Assumpcao%2C+A">Andre Assumpcao</a>, 
<a href="/search/cs?searchtype=author&query=Trecenti%2C+J">Julio Trecenti</a>, 
<a href="/search/cs?searchtype=author&query=Airosa%2C+L">Luiz Airosa</a>, 
<a href="/search/cs?searchtype=author&query=Lente%2C+C">Caio Lente</a>, 
<a href="/search/cs?searchtype=author&query=Cl%C3%A9to%2C+J">Jhonatan Cl&#xe9;to</a>, 
<a href="/search/cs?searchtype=author&query=Dobins%2C+G">Guilherme Dobins</a>, 
<a href="/search/cs?searchtype=author&query=Nogueira%2C+R">Rodrigo Nogueira</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+L">Luis Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Lotufo%2C+R">Roberto Lotufo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05594" title="Abstract">arXiv:2401.05594</a> (replaced) [<a href="/pdf/2401.05594" title="Download PDF">pdf</a>, <a href="/format/2401.05594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein Distance-based Expansion of Low-Density Latent Regions for  Unknown Class Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mallick%2C+P">Prakash Mallick</a>, 
<a href="/search/cs?searchtype=author&query=Dayoub%2C+F">Feras Dayoub</a>, 
<a href="/search/cs?searchtype=author&query=Sherrah%2C+J">Jamie Sherrah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Full length pages, followed by 2 supplementary pages, total of 9 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06268" title="Abstract">arXiv:2401.06268</a> (replaced) [<a href="/pdf/2401.06268" title="Download PDF">pdf</a>, <a href="/format/2401.06268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Stochastic Model for IRS-Assisted Communication Systems Based on  the Sum-Product of Nakagami-$m$ Random Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amiriara%2C+H">Hamid Amiriara</a>, 
<a href="/search/cs?searchtype=author&query=Mirmohseni%2C+M">Mahtab Mirmohseni</a>, 
<a href="/search/cs?searchtype=author&query=Ashtiani%2C+F">Farid Ashtiani</a>, 
<a href="/search/cs?searchtype=author&query=Nasiri-Kenari%2C+M">Masoumeh Nasiri-Kenari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07106" title="Abstract">arXiv:2401.07106</a> (replaced) [<a href="/pdf/2401.07106" title="Download PDF">pdf</a>, <a href="/format/2401.07106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directed Regular and Context-Free Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganardi%2C+M">Moses Ganardi</a>, 
<a href="/search/cs?searchtype=author&query=Saglam%2C+I">Irmak Saglam</a>, 
<a href="/search/cs?searchtype=author&query=Zetzsche%2C+G">Georg Zetzsche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07312" title="Abstract">arXiv:2401.07312</a> (replaced) [<a href="/pdf/2401.07312" title="Download PDF">pdf</a>, <a href="/format/2401.07312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Nonlinear Collaboration between Human and AI Agents: A  Co-design Framework for Creative Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J+R">JiayiZhou. Renzhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Junxiu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+T">Tan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haotian Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Weiwei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingcai Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07494" title="Abstract">arXiv:2401.07494</a> (replaced) [<a href="/pdf/2401.07494" title="Download PDF">pdf</a>, <a href="/format/2401.07494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pravin%2C+P+S">P S Pravin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhe Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07567" title="Abstract">arXiv:2401.07567</a> (replaced) [<a href="/pdf/2401.07567" title="Download PDF">pdf</a>, <a href="/format/2401.07567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias-Conflict Sample Synthesis and Adversarial Removal Debias Strategy  for Temporal Sentence Grounding in Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhaobo Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yibo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+X">Xiaowen Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weigang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07961" title="Abstract">arXiv:2401.07961</a> (replaced) [<a href="/pdf/2401.07961" title="Download PDF">pdf</a>, <a href="/format/2401.07961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solution of the Probabilistic Lambert Problem: Connections with Optimal  Mass Transport, Schr&#xf6;dinger Bridge and Reaction-Diffusion PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Teter%2C+A+M+H">Alexis M.H. Teter</a>, 
<a href="/search/math?searchtype=author&query=Nodozi%2C+I">Iman Nodozi</a>, 
<a href="/search/math?searchtype=author&query=Halder%2C+A">Abhishek Halder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Mathematical Physics (math-ph); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08169" title="Abstract">arXiv:2401.08169</a> (replaced) [<a href="/pdf/2401.08169" title="Download PDF">pdf</a>, <a href="/format/2401.08169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Test for Attention Map in Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shiraishi%2C+T">Tomohiro Shiraishi</a>, 
<a href="/search/stat?searchtype=author&query=Miwa%2C+D">Daiki Miwa</a>, 
<a href="/search/stat?searchtype=author&query=Katsuoka%2C+T">Teruyuki Katsuoka</a>, 
<a href="/search/stat?searchtype=author&query=Duy%2C+V+N+L">Vo Nguyen Le Duy</a>, 
<a href="/search/stat?searchtype=author&query=Taji%2C+K">Kouichi Taji</a>, 
<a href="/search/stat?searchtype=author&query=Takeuchi%2C+I">Ichiro Takeuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42pages, 17figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08216" title="Abstract">arXiv:2401.08216</a> (replaced) [<a href="/pdf/2401.08216" title="Download PDF">pdf</a>, <a href="/format/2401.08216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient and Certified Recovery from Poisoning Attacks in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiyuan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C+W">Chee Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kwok-Yan Lam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08326" title="Abstract">arXiv:2401.08326</a> (replaced) [<a href="/pdf/2401.08326" title="Download PDF">pdf</a>, <a href="/format/2401.08326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large  Language Models in Tool Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yilong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Songyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Caishuang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sixian Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08897" title="Abstract">arXiv:2401.08897</a> (replaced) [<a href="/pdf/2401.08897" title="Download PDF">pdf</a>, <a href="/format/2401.08897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in  Variational AutoEncoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">Hee-Jun Jung</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+J">Jaehyoung Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kangil Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09149" title="Abstract">arXiv:2401.09149</a> (replaced) [<a href="/pdf/2401.09149" title="Download PDF">pdf</a>, <a href="/format/2401.09149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InternEvo: Efficient Long-sequence Large Language Model Training via  Hybrid Parallelism and Redundant Sharding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiaoling Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+D">Diandian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoteng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">YingTong Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Ting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yonggang Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peng Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09268" title="Abstract">arXiv:2401.09268</a> (replaced) [<a href="/pdf/2401.09268" title="Download PDF">pdf</a>, <a href="/format/2401.09268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chemically Motivated Simulation Problems are Efficiently Solvable by a  Quantum Computer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Schleich%2C+P">Philipp Schleich</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kristensen%2C+L+B">Lasse Bj&#xf8;rn Kristensen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Angulo%2C+J+A+C+G">Jorge A. Campos Gonzalez Angulo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Avagliano%2C+D">Davide Avagliano</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bagherimehrab%2C+M">Mohsen Bagherimehrab</a>, 
<a href="/search/quant-ph?searchtype=author&query=Aldossary%2C+A">Abdulrahman Aldossary</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gorgulla%2C+C">Christoph Gorgulla</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fitzsimons%2C+J">Joe Fitzsimons</a>, 
<a href="/search/quant-ph?searchtype=author&query=Aspuru-Guzik%2C+A">Al&#xe1;n Aspuru-Guzik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09343" title="Abstract">arXiv:2401.09343</a> (replaced) [<a href="/pdf/2401.09343" title="Download PDF">pdf</a>, <a href="/format/2401.09343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient slot labelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vlasov%2C+V">Vladimir Vlasov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09495" title="Abstract">arXiv:2401.09495</a> (replaced) [<a href="/e-print/2401.09495" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPR-NeRF: Ownership Verification meets Neural Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ong%2C+W+K">Win Kent Ong</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+K+W">Kam Woh Ng</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C+S">Chee Seng Chan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y+Z">Yi Zhe Song</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Error on the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09566" title="Abstract">arXiv:2401.09566</a> (replaced) [<a href="/pdf/2401.09566" title="Download PDF">pdf</a>, <a href="/format/2401.09566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Large Language Models with Counterfactual DPO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Butcher%2C+B">Bradley Butcher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09691" title="Abstract">arXiv:2401.09691</a> (replaced) [<a href="/pdf/2401.09691" title="Download PDF">pdf</a>, <a href="/format/2401.09691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation Learning Inputting Image Feature to Each Layer of Neural  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamane%2C+K">Koki Yamane</a>, 
<a href="/search/cs?searchtype=author&query=Sakaino%2C+S">Sho Sakaino</a>, 
<a href="/search/cs?searchtype=author&query=Tsuji%2C+T">Toshiaki Tsuji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, Accepted at AMC2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09721" title="Abstract">arXiv:2401.09721</a> (replaced) [<a href="/pdf/2401.09721" title="Download PDF">pdf</a>, <a href="/format/2401.09721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast graph-based denoising for point cloud color information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+R">Ryosuke Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Nonaka%2C+K">Keisuke Nonaka</a>, 
<a href="/search/cs?searchtype=author&query=Pavez%2C+E">Eduardo Pavez</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+T">Tatsuya Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+A">Antonio Ortega</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the proceeding of 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09740" title="Abstract">arXiv:2401.09740</a> (replaced) [<a href="/pdf/2401.09740" title="Download PDF">pdf</a>, <a href="/format/2401.09740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hijacking Attacks against Neural Networks by Analyzing Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yunjie Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huayang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lingchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peipei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shenyi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version with major polishing, compared to the Usenix Security 2024 edition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09796" title="Abstract">arXiv:2401.09796</a> (replaced) [<a href="/pdf/2401.09796" title="Download PDF">pdf</a>, <a href="/format/2401.09796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fast, Performant, Secure Distributed Training Framework For Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinggui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+A">Anda Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aihui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chaofan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024 (Federated LLM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09878" title="Abstract">arXiv:2401.09878</a> (replaced) [<a href="/pdf/2401.09878" title="Download PDF">pdf</a>, <a href="/format/2401.09878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison Benchmark for Distributed Hybrid MPC Control Methods:  Distributed Vehicle Platooning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mallick%2C+S">Samuel Mallick</a>, 
<a href="/search/eess?searchtype=author&query=Dabiri%2C+A">Azita Dabiri</a>, 
<a href="/search/eess?searchtype=author&query=De+Schutter%2C+B">Bart De Schutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures, submitted to IEEE Transactions on Control Systems Technology, code can be found at <a href="https://github.com/SamuelMallick/hybrid-vehicle-platoon/tree/paper-2023">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09885" title="Abstract">arXiv:2401.09885</a> (replaced) [<a href="/pdf/2401.09885" title="Download PDF">pdf</a>, <a href="/format/2401.09885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source Code Clone Detection Using Unsupervised Similarity Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martinez-Gil%2C+J">Jorge Martinez-Gil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication as Full Paper in the Software Quality Days 2024, Vienna, Austria
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09895" title="Abstract">arXiv:2401.09895</a> (replaced) [<a href="/pdf/2401.09895" title="Download PDF">pdf</a>, <a href="/ps/2401.09895" title="Download PostScript">ps</a>, <a href="/format/2401.09895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skeleton-Guided Instance Separation for Fine-Grained Segmentation in  Microscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chengfeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Z">Zhaoyan Ming</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lina Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xudong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+D">Dahong Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09902" title="Abstract">arXiv:2401.09902</a> (replaced) [<a href="/pdf/2401.09902" title="Download PDF">pdf</a>, <a href="/format/2401.09902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interplay between depth and width for interpolation in neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=%C3%81lvarez-L%C3%B3pez%2C+A">Antonio &#xc1;lvarez-L&#xf3;pez</a>, 
<a href="/search/math?searchtype=author&query=Slimane%2C+A+H">Arselane Hadj Slimane</a>, 
<a href="/search/math?searchtype=author&query=Zuazua%2C+E">Enrique Zuazua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures, double column
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09972" title="Abstract">arXiv:2401.09972</a> (replaced) [<a href="/pdf/2401.09972" title="Download PDF">pdf</a>, <a href="/format/2401.09972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Explain Transformers by Illuminating Important Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+A">Ao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lecue%2C+F">Freddy Lecue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+I">Irene Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10090" title="Abstract">arXiv:2401.10090</a> (replaced) [<a href="/pdf/2401.10090" title="Download PDF">pdf</a>, <a href="/format/2401.10090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modality Perturbation Synergy Attack for Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yunpeng Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhiming Luo</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yansong Qu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Min Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10110" title="Abstract">arXiv:2401.10110</a> (replaced) [<a href="/pdf/2401.10110" title="Download PDF">pdf</a>, <a href="/format/2401.10110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VIPTR: A Vision Permutable Extractor for Fast and Efficient Scene Text  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xianfu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Weixiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tongliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2205.00159">arXiv:2205.00159</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10118" title="Abstract">arXiv:2401.10118</a> (replaced) [<a href="/pdf/2401.10118" title="Download PDF">pdf</a>, <a href="/format/2401.10118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Techniques for Authenticating Quantile Digests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scala%2C+A">Alessandro Scala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, LaTeX; corrected layout problem in figure 4 caused by migration from LuaLaTex to pdfLaTex
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10150" title="Abstract">arXiv:2401.10150</a> (replaced) [<a href="/pdf/2401.10150" title="Download PDF">pdf</a>, <a href="/format/2401.10150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-Zero: Zero-Shot Moving Object Control Framework for  Diffusion-Based Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changgu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+J">Junwei Shu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lianggangxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+G">Gaoqi He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10191" title="Abstract">arXiv:2401.10191</a> (replaced) [<a href="/pdf/2401.10191" title="Download PDF">pdf</a>, <a href="/format/2401.10191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide and not forget: Ensemble of selectively trained experts in  Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rype%C5%9B%C4%87%2C+G">Grzegorz Rype&#x15b;&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Cygert%2C+S">Sebastian Cygert</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+V">Valeriya Khan</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Zieli%C5%84ski%2C+B">Bartosz Zieli&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Twardowski%2C+B">Bart&#x142;omiej Twardowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICLR 2024 (main track), code is available at: <a href="https://github.com/grypesc/SEED">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item292">Cross-lists</a></li>
<li><a href="#item338">Replacements</a></li>
</ul>
<small>[ total of 519 entries:  <b>1-519</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2401">2401</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
