<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu 11 Jan 24  to  Fri 12 Jan 24, announced Mon, 15 Jan 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item261">Cross-lists</a></li>
<li><a href="#item307">Replacements</a></li>
</ul>
<small>[ total of 466 entries:  <b>1-466</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon, 15 Jan 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06133" title="Abstract">arXiv:2401.06133</a> [<a href="/pdf/2401.06133" title="Download PDF">pdf</a>, <a href="/ps/2401.06133" title="Download PostScript">ps</a>, <a href="/format/2401.06133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The possibility of making $\$138,000$ from shredded banknote pieces  using computer vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+C+T">Chung To Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Every country must dispose of old banknotes. At the Hong Kong Monetary
Authority visitor center, visitors can buy a paperweight souvenir full of
shredded banknotes. Even though the shredded banknotes are small, by using
computer vision, it is possible to reconstruct the whole banknote like a jigsaw
puzzle. Each paperweight souvenir costs $\$100$ HKD, and it is claimed to
contain shredded banknotes equivalent to 138 complete $\$1000$ HKD banknotes.
In theory, $\$138,000$ HKD can be recovered by using computer vision. This
paper discusses the technique of collecting shredded banknote pieces and
applying a computer vision program.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06135" title="Abstract">arXiv:2401.06135</a> [<a href="/pdf/2401.06135" title="Download PDF">pdf</a>, <a href="/format/2401.06135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Distributed Neural Linear Thompson Sampling Framework to Achieve URLLC  in Industrial IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pase%2C+F">Francesco Pase</a>, 
<a href="/search/cs?searchtype=author&query=Giordani%2C+M">Marco Giordani</a>, 
<a href="/search/cs?searchtype=author&query=Cavallero%2C+S">Sara Cavallero</a>, 
<a href="/search/cs?searchtype=author&query=Schellmann%2C+M">Malte Schellmann</a>, 
<a href="/search/cs?searchtype=author&query=Eichinger%2C+J">Josef Eichinger</a>, 
<a href="/search/cs?searchtype=author&query=Verdone%2C+R">Roberto Verdone</a>, 
<a href="/search/cs?searchtype=author&query=Zorzi%2C+M">Michele Zorzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Industrial Internet of Things (IIoT) networks will provide Ultra-Reliable
Low-Latency Communication (URLLC) to support critical processes underlying the
production chains. However, standard protocols for allocating wireless
resources may not optimize the latency-reliability trade-off, especially for
uplink communication. For example, centralized grant-based scheduling can
ensure almost zero collisions, but introduces delays in the way resources are
requested by the User Equipments (UEs) and granted by the gNB. In turn,
distributed scheduling (e.g., based on random access), in which UEs
autonomously choose the resources for transmission, may lead to potentially
many collisions especially when the traffic increases. In this work we propose
DIStributed combinatorial NEural linear Thompson Sampling (DISNETS), a novel
scheduling framework that combines the best of the two worlds. By leveraging a
feedback signal from the gNB and reinforcement learning, the UEs are trained to
autonomously optimize their uplink transmissions by selecting the available
resources to minimize the number of collisions, without additional message
exchange to/from the gNB. DISNETS is a distributed, multi-agent adaptation of
the Neural Linear Thompson Sampling (NLTS) algorithm, which has been further
extended to admit multiple parallel actions. We demonstrate the superior
performance of DISNETS in addressing URLLC in IIoT scenarios compared to other
baselines.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06137" title="Abstract">arXiv:2401.06137</a> [<a href="/pdf/2401.06137" title="Download PDF">pdf</a>, <a href="/format/2401.06137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuasiNet: a neural network with trainable product layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malinovsk%C3%A1%2C+K">Krist&#xed;na Malinovsk&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Holenda%2C+S">Slavom&#xed;r Holenda</a>, 
<a href="/search/cs?searchtype=author&query=Malinovsk%C3%BD%2C+%C4%BD">&#x13d;udov&#xed;t Malinovsk&#xfd;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at International Conference on Artificial Neural Networks (ICANN) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Classical neural networks achieve only limited convergence in hard problems
such as XOR or parity when the number of hidden neurons is small. With the
motivation to improve the success rate of neural networks in these problems, we
propose a new neural network model inspired by existing neural network models
with so called product neurons and a learning rule derived from classical error
backpropagation, which elegantly solves the problem of mutually exclusive
situations. Unlike existing product neurons, which have weights that are preset
and not adaptable, our product layers of neurons also do learn. We tested the
model and compared its success rate to a classical multilayer perceptron in the
aforementioned problems as well as in other hard problems such as the two
spirals. Our results indicate that our model is clearly more successful than
the classical MLP and has the potential to be used in many tasks and
applications.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06143" title="Abstract">arXiv:2401.06143</a> [<a href="/pdf/2401.06143" title="Download PDF">pdf</a>, <a href="/format/2401.06143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redefining Recon: Bridging Gaps with UAVs, 360 degree Cameras, and  Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Surmann%2C+H">Hartmut Surmann</a>, 
<a href="/search/cs?searchtype=author&query=Digakis%2C+N">Niklas Digakis</a>, 
<a href="/search/cs?searchtype=author&query=Kremer%2C+J">Jan-Nicklas Kremer</a>, 
<a href="/search/cs?searchtype=author&query=Meine%2C+J">Julien Meine</a>, 
<a href="/search/cs?searchtype=author&query=Schulte%2C+M">Max Schulte</a>, 
<a href="/search/cs?searchtype=author&query=Voigt%2C+N">Niklas Voigt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, published at IEEE International Symposium on Safety,Security,and Rescue Robotics SSRR2023 in FUKUSHIMA, November 13-15 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of digital situational awareness during disaster situations,
accurate digital representations, like 3D models, play an indispensable role.
To ensure the safety of rescue teams, robotic platforms are often deployed to
generate these models. In this paper, we introduce an innovative approach that
synergizes the capabilities of compact Unmaned Arial Vehicles (UAVs), smaller
than 30 cm, equipped with 360 degree cameras and the advances of Neural
Radiance Fields (NeRFs). A NeRF, a specialized neural network, can deduce a 3D
representation of any scene using 2D images and then synthesize it from various
angles upon request. This method is especially tailored for urban environments
which have experienced significant destruction, where the structural integrity
of buildings is compromised to the point of barring entry-commonly observed
post-earthquakes and after severe fires. We have tested our approach through
recent post-fire scenario, underlining the efficacy of NeRFs even in
challenging outdoor environments characterized by water, snow, varying light
conditions, and reflective surfaces.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06144" title="Abstract">arXiv:2401.06144</a> [<a href="/pdf/2401.06144" title="Download PDF">pdf</a>, <a href="/format/2401.06144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DFU: scale-robust diffusion model for zero-shot super-resolution image  generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Havrilla%2C+A">Alex Havrilla</a>, 
<a href="/search/cs?searchtype=author&query=Rojas%2C+K">Kevin Rojas</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wenjing Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+M">Molei Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion generative models have achieved remarkable success in generating
images with a fixed resolution. However, existing models have limited ability
to generalize to different resolutions when training data at those resolutions
are not available. Leveraging techniques from operator learning, we present a
novel deep-learning architecture, Dual-FNO UNet (DFU), which approximates the
score operator by combining both spatial and spectral information at multiple
resolutions. Comparisons of DFU to baselines demonstrate its scalability: 1)
simultaneously training on multiple resolutions improves FID over training at
any single fixed resolution; 2) DFU generalizes beyond its training
resolutions, allowing for coherent, high-fidelity generation at
higher-resolutions with the same model, i.e. zero-shot super-resolution
image-generation; 3) we propose a fine-tuning strategy to further enhance the
zero-shot super-resolution image-generation capability of our model, leading to
a FID of 11.3 at 1.66 times the maximum training resolution on FFHQ, which no
other method can come close to achieving.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06145" title="Abstract">arXiv:2401.06145</a> [<a href="/pdf/2401.06145" title="Download PDF">pdf</a>, <a href="/format/2401.06145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minuet: Accelerating 3D Sparse Convolutions on GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiacheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Giannoula%2C+C">Christina Giannoula</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Elhoushi%2C+M">Mostafa Elhoushi</a>, 
<a href="/search/cs?searchtype=author&query=Gleeson%2C+J">James Gleeson</a>, 
<a href="/search/cs?searchtype=author&query=Pekhimenko%2C+G">Gennady Pekhimenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">Sparse Convolution (SC) is widely used for processing 3D point clouds that
are inherently sparse. Different from dense convolution, SC preserves the
sparsity of the input point cloud by only allowing outputs to specific
locations. To efficiently compute SC, prior SC engines first use hash tables to
build a kernel map that stores the necessary General Matrix Multiplication
(GEMM) operations to be executed (Map step), and then use a Gather-GEMM-Scatter
process to execute these GEMM operations (GMaS step). In this work, we analyze
the shortcomings of prior state-of-the-art SC engines, and propose Minuet, a
novel memory-efficient SC engine tailored for modern GPUs. Minuet proposes to
(i) replace the hash tables used in the Map step with a novel segmented sorting
double-traversed binary search algorithm that highly utilizes the on-chip
memory hierarchy of GPUs, (ii) use a lightweight scheme to autotune the tile
size in the Gather and Scatter operations of the GMaS step, such that to adapt
the execution to the particular characteristics of each SC layer, dataset, and
GPU architecture, and (iii) employ a padding-efficient GEMM grouping approach
that reduces both memory padding and kernel launching overheads. Our
evaluations show that Minuet significantly outperforms prior SC engines by on
average $1.74\times$ (up to $2.22\times$) for end-to-end point cloud network
executions. Our novel segmented sorting double-traversed binary search
algorithm achieves superior speedups by $15.8\times$ on average (up to
$26.8\times$) over prior SC engines in the Map step. The source code of Minuet
is publicly available at https://github.com/UofT-EcoSystem/Minuet.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06146" title="Abstract">arXiv:2401.06146</a> [<a href="/pdf/2401.06146" title="Download PDF">pdf</a>, <a href="/format/2401.06146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AAMDM: Accelerated Auto-regressive Motion Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+C">Calvin Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+G">Guanqiao Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">KangKang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+S">Sehoon Ha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Interactive motion synthesis is essential in creating immersive experiences
in entertainment applications, such as video games and virtual reality.
However, generating animations that are both high-quality and contextually
responsive remains a challenge. Traditional techniques in the game industry can
produce high-fidelity animations but suffer from high computational costs and
poor scalability. Trained neural network models alleviate the memory and speed
issues, yet fall short on generating diverse motions. Diffusion models offer
diverse motion synthesis with low memory usage, but require expensive reverse
diffusion processes. This paper introduces the Accelerated Auto-regressive
Motion Diffusion Model (AAMDM), a novel motion synthesis framework designed to
achieve quality, diversity, and efficiency all together. AAMDM integrates
Denoising Diffusion GANs as a fast Generation Module, and an Auto-regressive
Diffusion Model as a Polishing Module. Furthermore, AAMDM operates in a
lower-dimensional embedded space rather than the full-dimensional pose space,
which reduces the training complexity as well as further improves the
performance. We show that AAMDM outperforms existing methods in motion quality,
diversity, and runtime efficiency, through comprehensive quantitative analyses
and visual comparisons. We also demonstrate the effectiveness of each
algorithmic component through ablation studies.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06149" title="Abstract">arXiv:2401.06149</a> [<a href="/pdf/2401.06149" title="Download PDF">pdf</a>, <a href="/format/2401.06149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Classifier Based Generative Method for Planar Antenna Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+W">Weiping Dou</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Andrew Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Bisharat%2C+D">Dia&#x27;a Bisharat</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q+H">Qing Huo Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">To extend the antenna design on printed circuit boards (PCBs) for more
engineers of interest, we propose a simple method that models PCB antennas with
a few basic components. By taking two separate steps to decide their geometric
dimensions and positions, antenna prototypes can be facilitated with no
experience required. Random sampling statistics relate to the quality of
dimensions are used in selecting among dimension candidates. A novel
image-based classifier using a convolutional neural network (CNN) is introduced
to further determine the positions of these fixed-dimension components. Two
examples from wearable products have been chosen to examine the entire
workflow. Their final designs are realistic and their performance metrics are
not inferior to the ones designed by experienced engineers.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06152" title="Abstract">arXiv:2401.06152</a> [<a href="/pdf/2401.06152" title="Download PDF">pdf</a>, <a href="/ps/2401.06152" title="Download PostScript">ps</a>, <a href="/format/2401.06152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-Network-Based Predictive Modeling for Highly Cross-Linked Polymer  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonseok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+S">Sanggyu Chong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jihan Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">In this study, a versatile methodology for initiating polymerization from
monomers in highly cross-linked materials is investigated. As polymerization
progresses, force-field parameters undergo continuous modification due to the
formation of new chemical bonds. This dynamic process not only impacts the
atoms directly involved in bonding, but also influences the neighboring atomic
environment. Monitoring these complex changes in highly cross-linked structures
poses a challenge. To address this issue, we introduce a graph-network-based
algorithm that offers both rapid and accurate predictions. The algorithm merges
polymer construction protocols with LAMMPS, a large-scale molecular dynamics
simulation software. The adaptability of this code has been demonstrated by its
successful application to various amorphous polymers, including porous polymer
networks (PPNs), and epoxy-resins, while the algorithm has been employed for
additional tasks, such as implementing pore-piercing deformations and
calculating material properties.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06153" title="Abstract">arXiv:2401.06153</a> [<a href="/pdf/2401.06153" title="Download PDF">pdf</a>, <a href="/format/2401.06153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Optimization with k-Cluster Big Bang-Big Crunch Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yenin%2C+K+E">Kemal Erdem Yenin</a>, 
<a href="/search/cs?searchtype=author&query=Sayin%2C+R+O">Reha Oguz Sayin</a>, 
<a href="/search/cs?searchtype=author&query=Arar%2C+K">Kuzey Arar</a>, 
<a href="/search/cs?searchtype=author&query=Atalay%2C+K+K">Kadir Kaan Atalay</a>, 
<a href="/search/cs?searchtype=author&query=Stroppa%2C+F">Fabio Stroppa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-modal optimization is often encountered in engineering problems,
especially when different and alternative solutions are sought. Evolutionary
algorithms can efficiently tackle multi-modal optimization thanks to their
features such as the concept of population, exploration/exploitation, and being
suitable for parallel computation.
<br />This paper introduces a multi-modal optimization version of the Big Bang-Big
Crunch algorithm based on clustering, namely, k-BBBC. This algorithm guarantees
a complete convergence of the entire population, retrieving on average the 99\%
of local optima for a specific problem. Additionally, we introduce two
post-processing methods to (i) identify the local optima in a set of retrieved
solutions (i.e., a population), and (ii) quantify the number of correctly
retrieved optima against the expected ones (i.e., success rate).
<br />Our results show that k-BBBC performs well even with problems having a large
number of optima (tested on 379 optima) and high dimensionality (tested on 32
decision variables). When compared to other multi-modal optimization methods,
it outperforms them in terms of accuracy (in both search and objective space)
and success rate (number of correctly retrieved optima) -- especially when
elitism is applied. Lastly, we validated our proposed post-processing methods
by comparing their success rate to the actual one. Results suggest that these
methods can be used to evaluate the performance of a multi-modal optimization
algorithm by correctly identifying optima and providing an indication of
success -- without the need to know where the optima are located in the search
space.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06154" title="Abstract">arXiv:2401.06154</a> [<a href="/pdf/2401.06154" title="Download PDF">pdf</a>, <a href="/format/2401.06154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of home detection algorithms using smartphone GPS data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+R">Rajat Verma</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Shagun Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zengxiang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaowei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ukkusuri%2C+S+V">Satish V. Ukkusuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper currently under review in the journal "EPJ Data Science" (ISSN: 2193-1127); Manuscript: 24 pages (including 68 references, 7 figures, 3 tables); Supplementary material document not included
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Estimation of people's home locations using location-based services data from
smartphones is a common task in human mobility assessment. However, commonly
used home detection algorithms (HDAs) are often arbitrary and unexamined. In
this study, we review existing HDAs and examine five HDAs using eight
high-quality mobile phone geolocation datasets. These include four commonly
used HDAs as well as an HDA proposed in this work. To make quantitative
comparisons, we propose three novel metrics to assess the quality of detected
home locations and test them on eight datasets across four U.S. cities. We find
that all three metrics show a consistent rank of HDAs' performances, with the
proposed HDA outperforming the others. We infer that the temporal and spatial
continuity of the geolocation data points matters more than the overall size of
the data for accurate home detection. We also find that HDAs with high (and
similar) performance metrics tend to create results with better consistency and
closer to common expectations. Further, the performance deteriorates with
decreasing data quality of the devices, though the patterns of relative
performance persist. Finally, we show how the differences in home detection can
lead to substantial differences in subsequent inferences using two case studies
- (i) hurricane evacuation estimation, and (ii) correlation of mobility
patterns with socioeconomic status. Our work contributes to improving the
transparency of large-scale human mobility assessment applications.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06156" title="Abstract">arXiv:2401.06156</a> [<a href="/pdf/2401.06156" title="Download PDF">pdf</a>, <a href="/format/2401.06156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stochastic Approach to Classification Error Estimates in Convolutional  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peleska%2C+J">Jan Peleska</a>, 
<a href="/search/cs?searchtype=author&query=Br%C3%BCning%2C+F">Felix Br&#xfc;ning</a>, 
<a href="/search/cs?searchtype=author&query=Gleirscher%2C+M">Mario Gleirscher</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wen-ling Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This technical report presents research results achieved in the field of
verification of trained Convolutional Neural Network (CNN) used for image
classification in safety-critical applications. As running example, we use the
obstacle detection function needed in future autonomous freight trains with
Grade of Automation (GoA) 4. It is shown that systems like GoA 4 freight trains
are indeed certifiable today with new standards like ANSI/UL 4600 and ISO 21448
used in addition to the long-existing standards EN 50128 and EN 50129.
Moreover, we present a quantitative analysis of the system-level hazard rate to
be expected from an obstacle detection function. It is shown that using
sensor/perceptor fusion, the fused detection system can meet the tolerable
hazard rate deemed to be acceptable for the safety integrity level to be
applied (SIL-3). A mathematical analysis of CNN models is performed which
results in the identification of classification clusters and equivalence
classes partitioning the image input space of the CNN. These clusters and
classes are used to introduce a novel statistical testing method for
determining the residual error probability of a trained CNN and an associated
upper confidence limit. We argue that this greybox approach to CNN
verification, taking into account the CNN model's internal structure, is
essential for justifying that the statistical tests have covered the trained
CNN with its neurons and inter-layer mappings in a comprehensive way.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06157" title="Abstract">arXiv:2401.06157</a> [<a href="/pdf/2401.06157" title="Download PDF">pdf</a>, <a href="/format/2401.06157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UDEEP: Edge-based Computer Vision for In-Situ Underwater Crayfish and  Plastic Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monari%2C+D">Dennis Monari</a>, 
<a href="/search/cs?searchtype=author&query=Larkin%2C+J">Jack Larkin</a>, 
<a href="/search/cs?searchtype=author&query=Machado%2C+P">Pedro Machado</a>, 
<a href="/search/cs?searchtype=author&query=Bird%2C+J+J">Jordan J. Bird</a>, 
<a href="/search/cs?searchtype=author&query=Ihianle%2C+I+K">Isibor Kennedy Ihianle</a>, 
<a href="/search/cs?searchtype=author&query=Yahaya%2C+S+W">Salisu Wada Yahaya</a>, 
<a href="/search/cs?searchtype=author&query=Tash%2C+F+F">Farhad Fassihi Tash</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+M">Md Mahmudul Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Lotfi%2C+A">Ahmad Lotfi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Invasive signal crayfish have a detrimental impact on ecosystems. They spread
the fungal-type crayfish plague disease (Aphanomyces astaci) that is lethal to
the native white clawed crayfish, the only native crayfish species in Britain.
Invasive signal crayfish extensively burrow, causing habitat destruction,
erosion of river banks and adverse changes in water quality, while also
competing with native species for resources and leading to declines in native
populations. Moreover, pollution exacerbates the vulnerability of White-clawed
crayfish, with their populations declining by over 90% in certain English
counties, making them highly susceptible to extinction. To safeguard aquatic
ecosystems, it is imperative to address the challenges posed by invasive
species and discarded plastics in the United Kingdom's river ecosystem's. The
UDEEP platform can play a crucial role in environmental monitoring by
performing on-the-fly classification of Signal crayfish and plastic debris
while leveraging the efficacy of AI, IoT devices and the power of edge
computing (i.e., NJN). By providing accurate data on the presence, spread and
abundance of these species, the UDEEP platform can contribute to monitoring
efforts and aid in mitigating the spread of invasive species.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06159" title="Abstract">arXiv:2401.06159</a> [<a href="/pdf/2401.06159" title="Download PDF">pdf</a>, <a href="/format/2401.06159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRED: Towards a Full Rotation-Equivariance in Aerial Image Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chanho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+J">Jinsu Son</a>, 
<a href="/search/cs?searchtype=author&query=Shon%2C+H">Hyounguk Shon</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Yunho Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 38th Annual AAAI Conference on Artificial Intelligence (AAAI24),Vancouver, British Columbia, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Rotation-equivariance is an essential yet challenging property in oriented
object detection. While general object detectors naturally leverage robustness
to spatial shifts due to the translation-equivariance of the conventional CNNs,
achieving rotation-equivariance remains an elusive goal. Current detectors
deploy various alignment techniques to derive rotation-invariant features, but
still rely on high capacity models and heavy data augmentation with all
possible rotations. In this paper, we introduce a Fully Rotation-Equivariant
Oriented Object Detector (FRED), whose entire process from the image to the
bounding box prediction is strictly equivariant. Specifically, we decouple the
invariant task (object classification) and the equivariant task (object
localization) to achieve end-to-end equivariance. We represent the bounding box
as a set of rotation-equivariant vectors to implement rotation-equivariant
localization. Moreover, we utilized these rotation-equivariant vectors as
offsets in the deformable convolution, thereby enhancing the existing
advantages of spatial adaptation. Leveraging full rotation-equivariance, our
FRED demonstrates higher robustness to image-level rotation compared to
existing methods. Furthermore, we show that FRED is one step closer to non-axis
aligned learning through our experiments. Compared to state-of-the-art methods,
our proposed method delivers comparable performance on DOTA-v1.0 and
outperforms by 1.5 mAP on DOTA-v1.5, all while significantly reducing the model
parameters to 16%.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06160" title="Abstract">arXiv:2401.06160</a> [<a href="/pdf/2401.06160" title="Download PDF">pdf</a>, <a href="/ps/2401.06160" title="Download PostScript">ps</a>, <a href="/format/2401.06160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Future-proofing Education: A Prototype for Simulating Oral Examinations  Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nitze%2C+A">Andr&#xe9; Nitze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study explores the impact of Large Language Models (LLMs) in higher
education, focusing on an automated oral examination simulation using a
prototype. The design considerations of the prototype are described, and the
system is evaluated with a select group of educators and students. Technical
and pedagogical observations are discussed. The prototype proved to be
effective in simulating oral exams, providing personalized feedback, and
streamlining educators' workloads. The promising results of the prototype show
the potential for LLMs in democratizing education, inclusion of diverse student
populations, and improvement of teaching quality and efficiency.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06161" title="Abstract">arXiv:2401.06161</a> [<a href="/pdf/2401.06161" title="Download PDF">pdf</a>, <a href="/ps/2401.06161" title="Download PostScript">ps</a>, <a href="/format/2401.06161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trustworthy human-centric based Automated Decision-Making Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabrera%2C+M">Marcelino Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+C">Carlos Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Novoa-Hern%C3%A1ndez%2C+P">Pavel Novoa-Hern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Pelta%2C+D+A">David A. Pelta</a>, 
<a href="/search/cs?searchtype=author&query=Verdegay%2C+J+L">Jos&#xe9; Luis Verdegay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 Table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Automated Decision-Making Systems (ADS) have become pervasive across various
fields, activities, and occupations, to enhance performance. However, this
widespread adoption introduces potential risks, including the misuse of ADS.
Such misuse may manifest when ADS is employed in situations where it is
unnecessary or when essential requirements, conditions, and terms are
overlooked, leading to unintended consequences. This research paper presents a
thorough examination of the implications, distinctions, and ethical
considerations associated with digitalization, digital transformation, and the
utilization of ADS in contemporary society and future contexts. Emphasis is
placed on the imperative need for regulation, transparency, and ethical conduct
in the deployment of ADS.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06162" title="Abstract">arXiv:2401.06162</a> [<a href="/pdf/2401.06162" title="Download PDF">pdf</a>, <a href="/ps/2401.06162" title="Download PostScript">ps</a>, <a href="/format/2401.06162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A debiasing technique for place-based algorithmic patrol management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Einarsson%2C+A">Alexander Einarsson</a> (1), 
<a href="/search/cs?searchtype=author&query=Oestmo%2C+S">Simen Oestmo</a> (2), 
<a href="/search/cs?searchtype=author&query=Wollman%2C+L">Lester Wollman</a> (2), 
<a href="/search/cs?searchtype=author&query=Purves%2C+D">Duncan Purves</a> (3), 
<a href="/search/cs?searchtype=author&query=Jenkins%2C+R">Ryan Jenkins</a> (4) ((1) Northwestern University (2) SoundThinking Inc. (3) University of Florida (4) California Polytechnic State University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages (91 Appendix pages), 6 figures (20 supplementary figures), 14 supplementary tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, there has been a revolution in data-driven policing. With
that has come scrutiny on how bias in historical data affects algorithmic
decision making. In this exploratory work, we introduce a debiasing technique
for place-based algorithmic patrol management systems. We show that the
technique efficiently eliminates racially biased features while retaining high
accuracy in the models. Finally, we provide a lengthy list of potential future
research in the realm of fairness and data-driven policing which this work
uncovered.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06165" title="Abstract">arXiv:2401.06165</a> [<a href="/pdf/2401.06165" title="Download PDF">pdf</a>, <a href="/ps/2401.06165" title="Download PostScript">ps</a>, <a href="/format/2401.06165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation-Based Equations for Propagation Constant in Uniform or  Periodic Transmission
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yifan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bingjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Ke Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In this work, simulation-based equations to calculate propagation constant in
uniform or periodic structures (SES) are deduced and verified through
simulations in various types of structures. The modeling of those structures
are essentially based on field distributions from a driven-mode solver, and the
field distributions are used as the input parameters of the FPPS. It allows the
separation of forward and backward waves from a total wave inside such a
uniform or periodic structure, and thus it can be used to calculate the
propagation constants inside both uniform and periodic structures even with a
strong reflection. In order to test the performance and function of the FPPS,
it has been applied to a variety of typical structures, including uniform
waveguides, lossfree closed structures, lossy closed structures, and open
radiation structures, and compared with the results of eigenmode solvers,
equivalent network methods, and spectral domain integral equation methods. The
comparison shows the easy-to-use and adaptable nature of the FPPS. the FPPS.
This FPPS could be also applied to open radiating structures, and even
multi-dimensional periodic/uniform structures.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06167" title="Abstract">arXiv:2401.06167</a> [<a href="/pdf/2401.06167" title="Download PDF">pdf</a>, <a href="/format/2401.06167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Multimodal Understanding with CLIP-Based Image-to-Text  Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Che%2C+C">Chang Che</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qunwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiaxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Liqiang Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The process of transforming input images into corresponding textual
explanations stands as a crucial and complex endeavor within the domains of
computer vision and natural language processing. In this paper, we propose an
innovative ensemble approach that harnesses the capabilities of Contrastive
Language-Image Pretraining models.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06168" title="Abstract">arXiv:2401.06168</a> [<a href="/pdf/2401.06168" title="Download PDF">pdf</a>, <a href="/format/2401.06168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Game Theory Optimal Poker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sonawane%2C+P">Prathamesh Sonawane</a>, 
<a href="/search/cs?searchtype=author&query=Chheda%2C+A">Arav Chheda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Poker is in the family of imperfect information games unlike other games such
as chess, connect four, etc which are perfect information game instead. While
many perfect information games have been solved, no non-trivial imperfect
information game has been solved to date. This makes poker a great test bed for
Artificial Intelligence research. In this paper we firstly compare Game theory
optimal poker to Exploitative poker. Secondly, we discuss the intricacies of
abstraction techniques, betting models, and specific strategies employed by
successful poker bots like Tartanian[1] and Pluribus[6]. Thirdly, we also
explore 2-player vs multi-player games and the limitations that come when
playing with more players. Finally, this paper discusses the role of machine
learning and theoretical approaches in developing winning strategies and
suggests future directions for this rapidly evolving field.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06171" title="Abstract">arXiv:2401.06171</a> [<a href="/pdf/2401.06171" title="Download PDF">pdf</a>, <a href="/ps/2401.06171" title="Download PostScript">ps</a>, <a href="/format/2401.06171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Artificial Intelligence for Sustainable Agricultural  Development in Africa: Opportunities, Challenges, and Impact
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gikunda%2C+K">Kinyua Gikunda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper explores the transformative potential of artificial intelligence
(AI) in the context of sustainable agricultural development across diverse
regions in Africa. Delving into opportunities, challenges, and impact, the
study navigates through the dynamic landscape of AI applications in
agriculture. Opportunities such as precision farming, crop monitoring, and
climate-resilient practices are examined, alongside challenges related to
technological infrastructure, data accessibility, and skill gaps. The article
analyzes the impact of AI on smallholder farmers, supply chains, and inclusive
growth. Ethical considerations and policy implications are also discussed,
offering insights into responsible AI integration. By providing a nuanced
understanding, this paper contributes to the ongoing discourse on leveraging AI
for fostering sustainability in African agriculture.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06175" title="Abstract">arXiv:2401.06175</a> [<a href="/pdf/2401.06175" title="Download PDF">pdf</a>, <a href="/format/2401.06175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTAD: Tools and Benchmarks for Multivariate Time Series Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+W">Wenwei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuangbin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yichen Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuxin Su</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code and datasets are available at <a href="https://github.com/OpsPAI/MTAD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Key Performance Indicators (KPIs) are essential time-series metrics for
ensuring the reliability and stability of many software systems. They
faithfully record runtime states to facilitate the understanding of anomalous
system behaviors and provide informative clues for engineers to pinpoint the
root causes. The unprecedented scale and complexity of modern software systems,
however, make the volume of KPIs explode. Consequently, many traditional
methods of KPI anomaly detection become impractical, which serves as a catalyst
for the fast development of machine learning-based solutions in both academia
and industry. However, there is currently a lack of rigorous comparison among
these KPI anomaly detection methods, and re-implementation demands a
non-trivial effort. Moreover, we observe that different works adopt independent
evaluation processes with different metrics. Some of them may not fully reveal
the capability of a model and some are creating an illusion of progress. To
better understand the characteristics of different KPI anomaly detectors and
address the evaluation issue, in this paper, we provide a comprehensive review
and evaluation of twelve state-of-the-art methods, and propose a novel metric
called salience. Particularly, the selected methods include five traditional
machine learning-based methods and seven deep learning-based methods. These
methods are evaluated with five multivariate KPI datasets that are publicly
available. A unified toolkit with easy-to-use interfaces is also released. We
report the benchmark results in terms of accuracy, salience, efficiency, and
delay, which are of practical importance for industrial deployment. We believe
our work can contribute as a basis for future academic research and industrial
application.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06176" title="Abstract">arXiv:2401.06176</a> [<a href="/pdf/2401.06176" title="Download PDF">pdf</a>, <a href="/format/2401.06176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GOODAT: Towards Test-time Graph Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Luzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Dongxiao He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Di Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph neural networks (GNNs) have found widespread application in modeling
graph data across diverse domains. While GNNs excel in scenarios where the
testing data shares the distribution of their training counterparts (in
distribution, ID), they often exhibit incorrect predictions when confronted
with samples from an unfamiliar distribution (out-of-distribution, OOD). To
identify and reject OOD samples with GNNs, recent studies have explored graph
OOD detection, often focusing on training a specific model or modifying the
data on top of a well-trained GNN. Despite their effectiveness, these methods
come with heavy training resources and costs, as they need to optimize the
GNN-based models on training data. Moreover, their reliance on modifying the
original GNNs and accessing training data further restricts their universality.
To this end, this paper introduces a method to detect Graph Out-of-Distribution
At Test-time (namely GOODAT), a data-centric, unsupervised, and plug-and-play
solution that operates independently of training data and modifications of GNN
architecture. With a lightweight graph masker, GOODAT can learn informative
subgraphs from test samples, enabling the capture of distinct graph patterns
between OOD and ID samples. To optimize the graph masker, we meticulously
design three unsupervised objective functions based on the graph information
bottleneck principle, motivating the masker to capture compact yet informative
subgraphs for OOD detection. Comprehensive evaluations confirm that our GOODAT
method outperforms state-of-the-art benchmarks across a variety of real-world
datasets. The code is available at Github: https://github.com/Ee1s/GOODAT
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06178" title="Abstract">arXiv:2401.06178</a> [<a href="/pdf/2401.06178" title="Download PDF">pdf</a>, <a href="/ps/2401.06178" title="Download PostScript">ps</a>, <a href="/format/2401.06178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Art is Theft: Labour, Extraction, and Exploitation, Or, On the  Dangers of Stochastic Pollocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goetze%2C+T+S">Trystan S. Goetze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since the launch of applications such as DALL-E, Midjourney, and Stable
Diffusion, generative artificial intelligence has been controversial as a tool
for creating artwork. While some have presented longtermist worries about these
technologies as harbingers of fully automated futures to come, more pressing is
the impact of generative AI on creative labour in the present. Already,
business leaders have begun replacing human artistic labour with AI-generated
images. In response, the artistic community has launched a protest movement,
which argues that AI image generation is a kind of theft. This paper analyzes,
substantiates, and critiques these arguments, concluding that AI image
generators involve an unethical kind of labour theft. If correct, many other AI
applications also rely upon theft.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06184" title="Abstract">arXiv:2401.06184</a> [<a href="/pdf/2401.06184" title="Download PDF">pdf</a>, <a href="/ps/2401.06184" title="Download PostScript">ps</a>, <a href="/format/2401.06184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cyclic and Negacyclic Codes with Optimal or Best Known Minimum Distances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we construct a new family of distance-optimal binary cyclic
codes with the minimum distance $6$ and a new family of distance-optimal
quaternary cyclic codes with the minimum distance $4$. We also construct
several families of cyclic and negacyclic codes over ${\bf F}_2$, ${\bf F}_3$,
${\bf F}_4$, ${\bf F}_5$, ${\bf F}_7$ and ${\bf F}_9$ with good parameters
$n,\,k,\,d$, such that the maximal possible minimum distance $d_{max}$ of a
linear $[n, k]_q$ code is at most $d_{max} \leq d+8$. The first codes in these
families have optimal or best known minimum distances. $145$ optimal or best
known codes are constructed as cyclic codes, negacyclic codes, their shortening
codes and punctured codes. All optimal or best known codes constructed in this
paper are not equivalent to the presently best known codes. Several infinite
families of negacyclic $[n,\frac{n+1}{2}, d]_q$ codes or $[n, \frac{n}{2},
d]_q$ codes, such that their minimum distances satisfy $d\approx
O(\frac{n}{\log_q n})$, are also constructed. These are first several families
of such negacyclic codes.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06187" title="Abstract">arXiv:2401.06187</a> [<a href="/pdf/2401.06187" title="Download PDF">pdf</a>, <a href="/format/2401.06187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scissorhands: Scrub Data Influence via Connection Sensitivity in  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Harandi%2C+M">Mehrtash Harandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Machine Unlearning, Deep Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Machine unlearning has become a pivotal task to erase the influence of data
from a trained model. It adheres to recent data regulation standards and
enhances the privacy and security of machine learning applications. Most
existing machine unlearning methods perform well, however, they typically
necessitate access to the entirety of the remaining data, which might not be
feasible in certain scenarios. In this work, we present a new machine
unlearning approach Scissorhands, which operates effectively with only a subset
of the training data. Initially, Scissorhands identifies the most pertinent
parameters in the given model relative to the forgetting data via connection
sensitivity. This process involves reinitializing the most influential top-$k$
percent of these parameters, resulting in a trimmed model for erasing the
influence of the forgetting data. Subsequently, Scissorhands retrains the
trimmed model through a min-max optimization process, seeking parameters that
preserve information on the remaining data while discarding information related
to the forgetting data. Our experimental results, conducted across five
distinct datasets and utilizing both CNN and ViT, demonstrate that
Scissorhands, despite utilizing only a limited portion of the training data,
showcases competitive performance when compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06191" title="Abstract">arXiv:2401.06191</a> [<a href="/pdf/2401.06191" title="Download PDF">pdf</a>, <a href="/format/2401.06191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TriNeRFLet: A Wavelet Based Multiscale Triplane NeRF Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khatib%2C+R">Rajaei Khatib</a>, 
<a href="/search/cs?searchtype=author&query=Giryes%2C+R">Raja Giryes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> webpage link: <a href="https://rajaeekh.github.io/trinerflet-web">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, the neural radiance field (NeRF) model has gained popularity
due to its ability to recover complex 3D scenes. Following its success, many
approaches proposed different NeRF representations in order to further improve
both runtime and performance. One such example is Triplane, in which NeRF is
represented using three 2D feature planes. This enables easily using existing
2D neural networks in this framework, e.g., to generate the three planes.
Despite its advantage, the triplane representation lagged behind in its 3D
recovery quality compared to NeRF solutions. In this work, we propose
TriNeRFLet, a 2D wavelet-based multiscale triplane representation for NeRF,
which closes the 3D recovery performance gap and is competitive with current
state-of-the-art methods. Building upon the triplane framework, we also propose
a novel super-resolution (SR) technique that combines a diffusion model with
TriNeRFLet for improving NeRF resolution.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06192" title="Abstract">arXiv:2401.06192</a> [<a href="/pdf/2401.06192" title="Download PDF">pdf</a>, <a href="/ps/2401.06192" title="Download PostScript">ps</a>, <a href="/format/2401.06192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Based Simulation for Investigating Electric Vehicle Adoption  and Its Impacts on Electricity Distribution Grids and CO2 Emissions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christensen%2C+K">Kristoffer Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z+G">Zheng Grace Ma</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%B8rgensen%2C+B+N">Bo N&#xf8;rregaard J&#xf8;rgensen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In: Energy Informatics. EI.A 2023. Lecture Notes in Computer
  Science, vol 14468
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Electric vehicles are expected to significantly contribute to CO2-eq.
emissions reduction, but the increasing number of EVs also introduces
chal-lenges to the energy system, and to what extent it contributes to
achieving cli-mate goals remains unknown. Static modeling and assumption-based
simula-tions have been used for such investigation, but they cannot capture the
realistic ecosystem dynamics. To fill the gap, this paper investigates the
impacts of two adoption curves of private EVs on the electricity distribution
grids and national climate goals. This paper develops a multi-agent based
simulation with two adoption curves, the Traditional EV charging strategy,
various EV models, driv-ing patterns, and CO2-eq. emission data to capture the
full ecosystem dynamics during a long-term period from 2020 to 2032. The Danish
2030 climate goal and a Danish distribution network with 126 residential
consumers are chosen as the case study. The results show that both EV adoption
curves of 1 million and 775k EVs by 2030 will not satisfy the Danish climate
goal of reducing transport sector emissions by 30% by 2030. The results also
show that the current resi-dential electricity distribution grids cannot handle
the load from increasing EVs. The first grid overload will occur in 2031
(around 16 and 24 months later for the 1 million and 775k EVs adopted by 2030)
with a 67% share of EVs in the grid.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06194" title="Abstract">arXiv:2401.06194</a> [<a href="/pdf/2401.06194" title="Download PDF">pdf</a>, <a href="/format/2401.06194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrisisKAN: Knowledge-infused and Explainable Multimodal Attention  Network for Crisis Event Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shubham Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+N">Nandini Saini</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Suman Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+D">Debasis Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Pervasive use of social media has become the emerging source for real-time
information (like images, text, or both) to identify various events. Despite
the rapid growth of image and text-based event classification, the
state-of-the-art (SOTA) models find it challenging to bridge the semantic gap
between features of image and text modalities due to inconsistent encoding.
Also, the black-box nature of models fails to explain the model's outcomes for
building trust in high-stakes situations such as disasters, pandemic.
Additionally, the word limit imposed on social media posts can potentially
introduce bias towards specific events. To address these issues, we proposed
CrisisKAN, a novel Knowledge-infused and Explainable Multimodal Attention
Network that entails images and texts in conjunction with external knowledge
from Wikipedia to classify crisis events. To enrich the context-specific
understanding of textual information, we integrated Wikipedia knowledge using
proposed wiki extraction algorithm. Along with this, a guided cross-attention
module is implemented to fill the semantic gap in integrating visual and
textual data. In order to ensure reliability, we employ a model-specific
approach called Gradient-weighted Class Activation Mapping (Grad-CAM) that
provides a robust explanation of the predictions of the proposed model. The
comprehensive experiments conducted on the CrisisMMD dataset yield in-depth
analysis across various crisis-specific tasks and settings. As a result,
CrisisKAN outperforms existing SOTA methodologies and provides a novel view in
the domain of explainable multimodal event classification.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06195" title="Abstract">arXiv:2401.06195</a> [<a href="/pdf/2401.06195" title="Download PDF">pdf</a>, <a href="/format/2401.06195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuSpin: Design of a Reliable Edge Neuromorphic System Based on  Spintronics for Green AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+T">Soyed Tuhin Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Danouchi%2C+K">Kamal Danouchi</a>, 
<a href="/search/cs?searchtype=author&query=Prenat%2C+G">Guillaume Prenat</a>, 
<a href="/search/cs?searchtype=author&query=Anghel%2C+L">Lorena Anghel</a>, 
<a href="/search/cs?searchtype=author&query=Tahoori%2C+M+B">Mehdi B. Tahoori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Internet of Things (IoT) and smart wearable devices for personalized
healthcare will require storing and computing ever-increasing amounts of data.
The key requirements for these devices are ultra-low-power, high-processing
capabilities, autonomy at low cost, as well as reliability and accuracy to
enable Green AI at the edge. Artificial Intelligence (AI) models, especially
Bayesian Neural Networks (BayNNs) are resource-intensive and face challenges
with traditional computing architectures due to the memory wall problem.
Computing-in-Memory (CIM) with emerging resistive memories offers a solution by
combining memory blocks and computing units for higher efficiency and lower
power consumption. However, implementing BayNNs on CIM hardware, particularly
with spintronic technologies, presents technical challenges due to variability
and manufacturing defects. The NeuSPIN project aims to address these challenges
through full-stack hardware and software co-design, developing novel
algorithmic and circuit design approaches to enhance the performance,
energy-efficiency and robustness of BayNNs on sprintronic-based CIM platforms.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06196" title="Abstract">arXiv:2401.06196</a> [<a href="/pdf/2401.06196" title="Download PDF">pdf</a>, <a href="/ps/2401.06196" title="Download PostScript">ps</a>, <a href="/format/2401.06196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VW-PINNs: A volume weighting method for PDE residuals in  physics-informed neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiahao Song</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+W">Wenbo Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+F">Fei Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Physics-informed neural networks (PINNs) have shown remarkable prospects in
the solving the forward and inverse problems involving partial differential
equations (PDEs). The method embeds PDEs into the neural network by calculating
PDE loss at a series of collocation points, providing advantages such as
meshfree and more convenient adaptive sampling. However, when solving PDEs
using nonuniform collocation points, PINNs still face challenge regarding
inefficient convergence of PDE residuals or even failure. In this work, we
first analyze the ill-conditioning of the PDE loss in PINNs under nonuniform
collocation points. To address the issue, we define volume-weighted residual
and propose volume-weighted physics-informed neural networks (VW-PINNs).
Through weighting the PDE residuals by the volume that the collocation points
occupy within the computational domain, we embed explicitly the spatial
distribution characteristics of collocation points in the residual evaluation.
The fast and sufficient convergence of the PDE residuals for the problems
involving nonuniform collocation points is guaranteed. Considering the meshfree
characteristics of VW-PINNs, we also develop a volume approximation algorithm
based on kernel density estimation to calculate the volume of the collocation
points. We verify the universality of VW-PINNs by solving the forward problems
involving flow over a circular cylinder and flow over the NACA0012 airfoil
under different inflow conditions, where conventional PINNs fail; By solving
the Burgers' equation, we verify that VW-PINNs can enhance the efficiency of
existing the adaptive sampling method in solving the forward problem by 3
times, and can reduce the relative error of conventional PINNs in solving the
inverse problem by more than one order of magnitude.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06197" title="Abstract">arXiv:2401.06197</a> [<a href="/pdf/2401.06197" title="Download PDF">pdf</a>, <a href="/format/2401.06197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Deformable ConvNets: Rethinking Dynamic and Sparse Operator  for Vision Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuwen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiapeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report; Code: <a href="https://github.com/OpenGVLab/DCNv4">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Deformable Convolution v4 (DCNv4), a highly efficient and
effective operator designed for a broad spectrum of vision applications. DCNv4
addresses the limitations of its predecessor, DCNv3, with two key enhancements:
1. removing softmax normalization in spatial aggregation to enhance its dynamic
property and expressive power and 2. optimizing memory access to minimize
redundant operations for speedup. These improvements result in a significantly
faster convergence compared to DCNv3 and a substantial increase in processing
speed, with DCNv4 achieving more than three times the forward speed. DCNv4
demonstrates exceptional performance across various tasks, including image
classification, instance and semantic segmentation, and notably, image
generation. When integrated into generative models like U-Net in the latent
diffusion model, DCNv4 outperforms its baseline, underscoring its possibility
to enhance generative models. In practical applications, replacing DCNv3 with
DCNv4 in the InternImage model to create FlashInternImage results in up to 80%
speed increase and further performance improvement without further
modifications. The advancements in speed and efficiency of DCNv4, combined with
its robust performance across diverse vision tasks, show its potential as a
foundational building block for future vision models.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06201" title="Abstract">arXiv:2401.06201</a> [<a href="/pdf/2401.06201" title="Download PDF">pdf</a>, <a href="/format/2401.06201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Siyu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaitao Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiangjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yongliang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+R">Ren Kan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Deqing Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">To address intricate real-world tasks, there has been a rising interest in
tool utilization in applications of large language models (LLMs). To develop
LLM-based agents, it usually requires LLMs to understand many tool functions
from different tool documentation. But these documentations could be diverse,
redundant or incomplete, which immensely affects the capability of LLMs in
using tools. To solve this, we introduce EASYTOOL, a framework transforming
diverse and lengthy tool documentation into a unified and concise tool
instruction for easier tool usage. EasyTool purifies essential information from
extensive tool documentation of different sources, and elaborates a unified
interface (i.e., tool instruction) to offer standardized tool descriptions and
functionalities for LLM-based agents. Extensive experiments on multiple
different tasks demonstrate that EasyTool can significantly reduce token
consumption and improve the performance of tool utilization in real-world
scenarios. Our code will be available at
\url{https://github.com/microsoft/JARVIS/} in the future.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06204" title="Abstract">arXiv:2401.06204</a> [<a href="/pdf/2401.06204" title="Download PDF">pdf</a>, <a href="/format/2401.06204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Exploratory Assessment of LLM&#x27;s Potential Toward Flight Trajectory  Reconstruction Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qilei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mott%2C+J+H">John H. Mott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Large Language Models (LLMs) hold transformative potential in aviation,
particularly in reconstructing flight trajectories. This paper investigates
this potential, grounded in the notion that LLMs excel at processing sequential
data and deciphering complex data structures. Utilizing the LLaMA 2 model, a
pre-trained open-source LLM, the study focuses on reconstructing flight
trajectories using Automatic Dependent Surveillance-Broadcast (ADS-B) data with
irregularities inherent in real-world scenarios. The findings demonstrate the
model's proficiency in filtering noise and estimating both linear and curved
flight trajectories. However, the analysis also reveals challenges in managing
longer data sequences, which may be attributed to the token length limitations
of LLM models. The study's insights underscore the promise of LLMs in flight
trajectory reconstruction and open new avenues for their broader application
across the aviation and transportation sectors.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06205" title="Abstract">arXiv:2401.06205</a> [<a href="/pdf/2401.06205" title="Download PDF">pdf</a>, <a href="/format/2401.06205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised detection of coordinated information operations in the wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+D+H">D. Hudson Smith</a>, 
<a href="/search/cs?searchtype=author&query=Ehrett%2C+C">Carl Ehrett</a>, 
<a href="/search/cs?searchtype=author&query=Warren%2C+P+L">Patrick L. Warren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">This paper introduces and tests an unsupervised method for detecting novel
coordinated inauthentic information operations (CIOs) in realistic settings.
This method uses Bayesian inference to identify groups of accounts that share
similar account-level characteristics and target similar narratives. We solve
the inferential problem using amortized variational inference, allowing us to
efficiently infer group identities for millions of accounts. We validate this
method using a set of five CIOs from three countries discussing four topics on
Twitter. Our unsupervised approach increases detection power (area under the
precision-recall curve) relative to a naive baseline (by a factor of 76 to
580), relative to the use of simple flags or narratives on their own (by a
factor of 1.3 to 4.8), and comes quite close to a supervised benchmark. Our
method is robust to observing only a small share of messaging on the topic,
having only weak markers of inauthenticity, and to the CIO accounts making up a
tiny share of messages and accounts on the topic. Although we evaluate the
results on Twitter, the method is general enough to be applied in many
social-media settings.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06207" title="Abstract">arXiv:2401.06207</a> [<a href="/pdf/2401.06207" title="Download PDF">pdf</a>, <a href="/format/2401.06207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing parameter planes of iterative root-finding methods with  several free critical points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Campos%2C+B">Beatriz Campos</a>, 
<a href="/search/math?searchtype=author&query=Canela%2C+J">Jordi Canela</a>, 
<a href="/search/math?searchtype=author&query=Rodr%C3%ADguez-Arenas%2C+A">Alberto Rodr&#xed;guez-Arenas</a>, 
<a href="/search/math?searchtype=author&query=Vindel%2C+P">Pura Vindel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we present an algorithm to obtain the parameter planes of
families of root-finding methods with several free critical points. The
parameter planes show the joint behaviour of all critical points. This
algorithm avoids the inconsistencies arising from the relationship between the
different critical points as well as the indeterminacy caused by the square
roots involved in their computation.
<br />We analyse the suitability of this algorithm by drawing the parameter planes
of different Newton-like methods with two and three critical points. We also
present some results of the expressions of the Newton-like operators and their
derivatives in terms of palindromic polynomials, and we show how to obtain the
expression of the critical points of a Newton-like method with real
coefficients.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06209" title="Abstract">arXiv:2401.06209</a> [<a href="/pdf/2401.06209" title="Download PDF">pdf</a>, <a href="/format/2401.06209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+S">Shengbang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuexiang Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>, 
<a href="/search/cs?searchtype=author&query=LeCun%2C+Y">Yann LeCun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Saining Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://tsb0601.github.io/mmvp_blog/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Is vision good enough for language? Recent advancements in multimodal models
primarily stem from the powerful reasoning abilities of large language models
(LLMs). However, the visual component typically depends only on the
instance-level contrastive language-image pre-training (CLIP). Our research
reveals that the visual capabilities in recent multimodal LLMs (MLLMs) still
exhibit systematic shortcomings. To understand the roots of these errors, we
explore the gap between the visual embedding space of CLIP and vision-only
self-supervised learning. We identify ''CLIP-blind pairs'' - images that CLIP
perceives as similar despite their clear visual differences. With these pairs,
we construct the Multimodal Visual Patterns (MMVP) benchmark. MMVP exposes
areas where state-of-the-art systems, including GPT-4V, struggle with
straightforward questions across nine basic visual patterns, often providing
incorrect answers and hallucinated explanations. We further evaluate various
CLIP-based vision-and-language models and found a notable correlation between
visual patterns that challenge CLIP models and those problematic for multimodal
LLMs. As an initial effort to address these issues, we propose a Mixture of
Features (MoF) approach, demonstrating that integrating vision self-supervised
learning features with MLLMs can significantly enhance their visual grounding
capabilities. Together, our research suggests visual representation learning
remains an open challenge, and accurate visual grounding is crucial for future
successful multimodal systems.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06210" title="Abstract">arXiv:2401.06210</a> [<a href="/pdf/2401.06210" title="Download PDF">pdf</a>, <a href="/format/2401.06210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Unsupervised Semantic Document Representation for Fine-grained  Aspect-based Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hao-Ming Fu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pu-Jen Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International ACM SIGIR Conference 2019
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIGIR 2019: Proceedings of the 42nd International ACM SIGIR
  Conference on Research and Development in Information Retrieval, Pages 1105
  to 1108
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Document representation is the core of many NLP tasks on machine
understanding. A general representation learned in an unsupervised manner
reserves generality and can be used for various applications. In practice,
sentiment analysis (SA) has been a challenging task that is regarded to be
deeply semantic-related and is often used to assess general representations.
Existing methods on unsupervised document representation learning can be
separated into two families: sequential ones, which explicitly take the
ordering of words into consideration, and non-sequential ones, which do not
explicitly do so. However, both of them suffer from their own weaknesses. In
this paper, we propose a model that overcomes difficulties encountered by both
families of methods. Experiments show that our model outperforms
state-of-the-art methods on popular SA datasets and a fine-grained aspect-based
SA by a large margin.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06226" title="Abstract">arXiv:2401.06226</a> [<a href="/pdf/2401.06226" title="Download PDF">pdf</a>, <a href="/format/2401.06226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Crowd Behaviors in Navigation with Attention-based  Spatial-Temporal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanying Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Garcke%2C+J">Jochen Garcke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Safe and efficient navigation in dynamic environments shared with humans
remains an open and challenging task for mobile robots. Previous works have
shown the efficacy of using reinforcement learning frameworks to train policies
for efficient navigation. However, their performance deteriorates when crowd
configurations change, i.e. become larger or more complex. Thus, it is crucial
to fully understand the complex, dynamic, and sophisticated interactions of the
crowd resulting in proactive and foresighted behaviors for robot navigation. In
this paper, a novel deep graph learning architecture based on attention
mechanisms is proposed, which leverages the spatial-temporal graph to enhance
robot navigation. We employ spatial graphs to capture the current spatial
interactions, and through the integration with RNN, the temporal graphs utilize
past trajectory information to infer the future intentions of each agent. The
spatial-temporal graph reasoning ability allows the robot to better understand
and interpret the relationships between agents over time and space, thereby
making more informed decisions. Compared to previous state-of-the-art methods,
our method demonstrates superior robustness in terms of safety, efficiency, and
generalization in various challenging scenarios.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06233" title="Abstract">arXiv:2401.06233</a> [<a href="/pdf/2401.06233" title="Download PDF">pdf</a>, <a href="/format/2401.06233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEGOBench: Leaderboard Generation Benchmark for Scientific Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shruti Singh</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+S">Shoaib Alam</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Mayank Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The ever-increasing volume of paper submissions makes it difficult to stay
informed about the latest state-of-the-art research. To address this challenge,
we introduce LEGOBench, a benchmark for evaluating systems that generate
leaderboards. LEGOBench is curated from 22 years of preprint submission data in
arXiv and more than 11,000 machine learning leaderboards in the PapersWithCode
portal. We evaluate the performance of four traditional graph-based ranking
variants and three recently proposed large language models. Our preliminary
results show significant performance gaps in automatic leaderboard generation.
The code is available on https://github.com/lingo-iitgn/LEGOBench and the
dataset is hosted on
https://osf.io/9v2py/?view_only=6f91b0b510df498ba01595f8f278f94c .
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06234" title="Abstract">arXiv:2401.06234</a> [<a href="/pdf/2401.06234" title="Download PDF">pdf</a>, <a href="/format/2401.06234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Shapley Value in Database Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertossi%2C+L">Leopoldo Bertossi</a>, 
<a href="/search/cs?searchtype=author&query=Kimelfeld%2C+B">Benny Kimelfeld</a>, 
<a href="/search/cs?searchtype=author&query=Livshits%2C+E">Ester Livshits</a>, 
<a href="/search/cs?searchtype=author&query=Monet%2C+M">Mika&#xeb;l Monet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, including references. This is the authors version of the corresponding SIGMOD Record article
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIGMOD Rec. 52(2): 6-17 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Attribution scores can be applied in data management to quantify the
contribution of individual items to conclusions from the data, as part of the
explanation of what led to these conclusions. In Artificial Intelligence,
Machine Learning, and Data Management, some of the common scores are
deployments of the Shapley value, a formula for profit sharing in cooperative
game theory. Since its invention in the 1950s, the Shapley value has been used
for contribution measurement in many fields, from economics to law, with its
latest researched applications in modern machine learning. Recent studies
investigated the application of the Shapley value to database management. This
article gives an overview of recent results on the computational complexity of
the Shapley value for measuring the contribution of tuples to query answers and
to the extent of inconsistency with respect to integrity constraints. More
specifically, the article highlights lower and upper bounds on the complexity
of calculating the Shapley value, either exactly or approximately, as well as
solutions for realizing the calculation in practice.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06238" title="Abstract">arXiv:2401.06238</a> [<a href="/pdf/2401.06238" title="Download PDF">pdf</a>, <a href="/format/2401.06238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiPhom$\varepsilon$ -: HIgh order Projection-based HOMogenisation for  advection diffusion reaction problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Conni%2C+G">Giovanni Conni</a>, 
<a href="/search/math?searchtype=author&query=Piccardo%2C+S">Stefano Piccardo</a>, 
<a href="/search/math?searchtype=author&query=Perotto%2C+S">Simona Perotto</a>, 
<a href="/search/math?searchtype=author&query=Porta%2C+G+M">Giovanni Michele Porta</a>, 
<a href="/search/math?searchtype=author&query=Icardi%2C+M">Matteo Icardi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a new model reduction technique for multiscale scalar transport
problems that exhibit dominant axial dynamics. To this aim, we rely on the
separation of variables to combine a Hierarchical Model (HiMod) reduction with
a two-scale asymptotic expansion. We extend the two-scale asymptotic expansion
to an arbitrary order and exploit the high-order correctors to define the HiMod
modal basis, which approximates the transverse dynamics of the flow, while we
adopt a finite element discretisation to model the leading stream. The
resulting method, which is named HiPhom$\varepsilon$ (HIgh-order
Projection-based HOMogEnisation), is successfully assessed both in steady and
unsteady advection-diffusion-reaction settings. The numerical results confirm
the very good performance of HiPhom$\varepsilon$, which improves the accuracy
and the convergence rate of HiMod and extends the reliability of the standard
homogenised solution to transient and pre-asymptotic regimes.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06243" title="Abstract">arXiv:2401.06243</a> [<a href="/pdf/2401.06243" title="Download PDF">pdf</a>, <a href="/format/2401.06243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modularis: Modular Underwater Robot for Rapid Development and Validation  of Autonomous Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herrin%2C+B">Baker Herrin</a>, 
<a href="/search/cs?searchtype=author&query=Close%2C+V">Victoria Close</a>, 
<a href="/search/cs?searchtype=author&query=Berner%2C+N">Nathan Berner</a>, 
<a href="/search/cs?searchtype=author&query=Herbert%2C+J">Joshua Herbert</a>, 
<a href="/search/cs?searchtype=author&query=Reussow%2C+E">Ethan Reussow</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+R">Ryan James</a>, 
<a href="/search/cs?searchtype=author&query=Woodward%2C+C">Cale Woodward</a>, 
<a href="/search/cs?searchtype=author&query=Mindlin%2C+J">Jared Mindlin</a>, 
<a href="/search/cs?searchtype=author&query=Paez%2C+S">Sebastian Paez</a>, 
<a href="/search/cs?searchtype=author&query=Bretas%2C+N">Nilson Bretas</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jane Shin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 13 figures, presented at OCEANS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous underwater robots typically require higher cost and time for
demonstrations compared to other domains due to the complexity of the
environment. Due to the limited capacity and payload flexibility, it is
challenging to find off-the-shelf underwater robots that are affordable,
customizable, and subject to environmental variability. Custom-built underwater
robots may be necessary for specialized applications or missions, but the
process can be more costly and time-consuming than purchasing an off-the-shelf
autonomous underwater vehicle (AUV). To address these challenges, we propose a
modular underwater robot, Modularis, that can serve as an open-source testbed
system. Our proposed system expedites the testing of perception, planning, and
control algorithms.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06244" title="Abstract">arXiv:2401.06244</a> [<a href="/pdf/2401.06244" title="Download PDF">pdf</a>, <a href="/format/2401.06244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOLO-Former: YOLO Shakes Hand With ViT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khoramdel%2C+J">Javad Khoramdel</a>, 
<a href="/search/cs?searchtype=author&query=Moori%2C+A">Ahmad Moori</a>, 
<a href="/search/cs?searchtype=author&query=Borhani%2C+Y">Yasamin Borhani</a>, 
<a href="/search/cs?searchtype=author&query=Ghanbarzadeh%2C+A">Armin Ghanbarzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Najafi%2C+E">Esmaeil Najafi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The proposed YOLO-Former method seamlessly integrates the ideas of
transformer and YOLOv4 to create a highly accurate and efficient object
detection system. The method leverages the fast inference speed of YOLOv4 and
incorporates the advantages of the transformer architecture through the
integration of convolutional attention and transformer modules. The results
demonstrate the effectiveness of the proposed approach, with a mean average
precision (mAP) of 85.76\% on the Pascal VOC dataset, while maintaining high
prediction speed with a frame rate of 10.85 frames per second. The contribution
of this work lies in the demonstration of how the innovative combination of
these two state-of-the-art techniques can lead to further improvements in the
field of object detection.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06247" title="Abstract">arXiv:2401.06247</a> [<a href="/pdf/2401.06247" title="Download PDF">pdf</a>, <a href="/format/2401.06247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Player Beware: Driving Forces and Influencing Factors for Game-Adapted  Dark Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kronhardt%2C+K">Kirill Kronhardt</a>, 
<a href="/search/cs?searchtype=author&query=Rolfes%2C+K">Kevin Rolfes</a>, 
<a href="/search/cs?searchtype=author&query=Gerken%2C+J">Jens Gerken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Proceedings on Privacy Enhancing Technologies 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Dark patterns are often used in interface design to manipulate users into
performing actions they would otherwise not take, such as consenting to
excessive data collection. We present a narrative serious game concept, along
with seven game-adapted dark patterns designed to create awareness of and
bolster resistance against dark patterns through direct consequences of player
actions. We performed a qualitative, exploratory study investigating player
behavior when confronted with game-adapted dark patterns. A thematic analysis
provides insights into influencing factors for adapting dark patterns into
gameplay, as well as player motivations and driving forces influencing player
behavior.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06251" title="Abstract">arXiv:2401.06251</a> [<a href="/pdf/2401.06251" title="Download PDF">pdf</a>, <a href="/format/2401.06251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Preserving Feature Partitioning for Multi-View Ensemble  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khorshidi%2C+M+S">Mohammad Sadegh Khorshidi</a>, 
<a href="/search/cs?searchtype=author&query=Yazdanjue%2C+N">Navid Yazdanjue</a>, 
<a href="/search/cs?searchtype=author&query=Gharoun%2C+H">Hassan Gharoun</a>, 
<a href="/search/cs?searchtype=author&query=Yazdani%2C+D">Danial Yazdani</a>, 
<a href="/search/cs?searchtype=author&query=Nikoo%2C+M+R">Mohammad Reza Nikoo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gandomi%2C+A+H">Amir H. Gandomi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 44 figures, 26 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In machine learning, the exponential growth of data and the associated
``curse of dimensionality'' pose significant challenges, particularly with
expansive yet sparse datasets. Addressing these challenges, multi-view ensemble
learning (MEL) has emerged as a transformative approach, with feature
partitioning (FP) playing a pivotal role in constructing artificial views for
MEL. Our study introduces the Semantic-Preserving Feature Partitioning (SPFP)
algorithm, a novel method grounded in information theory. The SPFP algorithm
effectively partitions datasets into multiple semantically consistent views,
enhancing the MEL process. Through extensive experiments on eight real-world
datasets, ranging from high-dimensional with limited instances to
low-dimensional with high instances, our method demonstrates notable efficacy.
It maintains model accuracy while significantly improving uncertainty measures
in scenarios where high generalization performance is achievable. Conversely,
it retains uncertainty metrics while enhancing accuracy where high
generalization accuracy is less attainable. An effect size analysis further
reveals that the SPFP algorithm outperforms benchmark models by large effect
size and reduces computational demands through effective dimensionality
reduction. The substantial effect sizes observed in most experiments underscore
the algorithm's significant improvements in model performance.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06252" title="Abstract">arXiv:2401.06252</a> [<a href="/pdf/2401.06252" title="Download PDF">pdf</a>, <a href="/ps/2401.06252" title="Download PostScript">ps</a>, <a href="/format/2401.06252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AGSPNet: A framework for parcel-scale crop fine-grained semantic change  detection from UAV high-resolution imagery with agricultural geographic scene  constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaochun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hengfan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+L">Lina Deng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yunhao Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Real-time and accurate information on fine-grained changes in crop
cultivation is of great significance for crop growth monitoring, yield
prediction and agricultural structure adjustment. Aiming at the problems of
serious spectral confusion in visible high-resolution unmanned aerial vehicle
(UAV) images of different phases, interference of large complex background and
salt-and-pepper noise by existing semantic change detection (SCD) algorithms,
in order to effectively extract deep image features of crops and meet the
demand of agricultural practical engineering applications, this paper designs
and proposes an agricultural geographic scene and parcel-scale constrained SCD
framework for crops (AGSPNet). AGSPNet framework contains three parts:
agricultural geographic scene (AGS) division module, parcel edge extraction
module and crop SCD module. Meanwhile, we produce and introduce an UAV image
SCD dataset (CSCD) dedicated to agricultural monitoring, encompassing multiple
semantic variation types of crops in complex geographical scene. We conduct
comparative experiments and accuracy evaluations in two test areas of this
dataset, and the results show that the crop SCD results of AGSPNet consistently
outperform other deep learning SCD models in terms of quantity and quality,
with the evaluation metrics F1-score, kappa, OA, and mIoU obtaining
improvements of 0.038, 0.021, 0.011 and 0.062, respectively, on average over
the sub-optimal method. The method proposed in this paper can clearly detect
the fine-grained change information of crop types in complex scenes, which can
provide scientific and technical support for smart agriculture monitoring and
management, food policy formulation and food security assurance.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06255" title="Abstract">arXiv:2401.06255</a> [<a href="/pdf/2401.06255" title="Download PDF">pdf</a>, <a href="/format/2401.06255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling and Predicting Online Vaccination Views using Bow-tie  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yueting Han</a>, 
<a href="/search/cs?searchtype=author&query=Bazzi%2C+M">Marya Bazzi</a>, 
<a href="/search/cs?searchtype=author&query=Turrini%2C+P">Paolo Turrini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Social media has become increasingly important in shaping public vaccination
views, especially since the COVID-19 outbreak. This paper uses bow-tie
structure to analyse a temporal dataset of directed online social networks that
represent the information exchange among anti-vaccination, pro-vaccination, and
neutral Facebook pages. Bow-tie structure decomposes a network into seven
components, with two components "SCC" and "OUT" emphasised in this paper: SCC
is the largest strongly connected component, acting as an "information
magnifier", and OUT contains all nodes with a directed path from a node in SCC,
acting as an "information creator". We consistently observe statistically
significant bow-tie structures with different dominant components for each
vaccination group over time. In particular, the anti-vaccination group has a
large OUT, and the pro-vaccination group has a large SCC. We further
investigate changes in opinions over time, as measured by fan count variations,
using agent-based simulations and machine learning models. Across both methods,
accounting for bow-tie decomposition better reflects information flow
differences among vaccination groups and improves our opinion dynamics
prediction results. The modelling frameworks we consider can be applied to any
multi-stance temporal network and could form a basis for exploring opinion
dynamics using bow-tie structure in a wide range of applications.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06256" title="Abstract">arXiv:2401.06256</a> [<a href="/pdf/2401.06256" title="Download PDF">pdf</a>, <a href="/ps/2401.06256" title="Download PostScript">ps</a>, <a href="/format/2401.06256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Universal Knowledge Model and Cognitive Architecture for Prototyping  AGI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sukhobokov%2C+A">Artem Sukhobokov</a>, 
<a href="/search/cs?searchtype=author&query=Belousov%2C+E">Evgeny Belousov</a>, 
<a href="/search/cs?searchtype=author&query=Gromozdov%2C+D">Danila Gromozdov</a>, 
<a href="/search/cs?searchtype=author&query=Zenger%2C+A">Anna Zenger</a>, 
<a href="/search/cs?searchtype=author&query=Popov%2C+I">Ilya Popov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The article identified 42 cognitive architectures for creating general
artificial intelligence (AGI) and proposed a set of interrelated functional
blocks that an agent approaching AGI in its capabilities should possess. Since
the required set of blocks is not found in any of the existing architectures,
the article proposes a new cognitive architecture for intelligent systems
approaching AGI in their capabilities. As one of the key solutions within the
framework of the architecture, a universal method of knowledge representation
is proposed, which allows combining various non-formalized, partially and fully
formalized methods of knowledge representation in a single knowledge base, such
as texts in natural languages, images, audio and video recordings, graphs,
algorithms, databases, neural networks, knowledge graphs, ontologies, frames,
essence-property-relation models, production systems, predicate calculus
models, conceptual models, and others. To combine and structure various
fragments of knowledge, archigraph models are used, constructed as a
development of annotated metagraphs. As components, the cognitive architecture
being developed includes machine consciousness, machine subconsciousness,
blocks of interaction with the external environment, a goal management block,
an emotional control system, a block of social interaction, a block of
reflection, an ethics block and a worldview block, a learning block, a
monitoring block, blocks of statement and solving problems, self-organization
and meta learning block.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06262" title="Abstract">arXiv:2401.06262</a> [<a href="/pdf/2401.06262" title="Download PDF">pdf</a>, <a href="/format/2401.06262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sprout: Designing Expressivity for Robots Using Fiber-Embedded Actuator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koike%2C+A">Amy Koike</a>, 
<a href="/search/cs?searchtype=author&query=Wehner%2C+M">Michael Wehner</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+B">Bilge Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we explore how techniques from soft robotics can help create a
new form of robot expression. We present Sprout, a soft expressive robot that
conveys its internal states by changing its body shape. Sprout can extend,
bend, twist, and expand using fiber-embedded actuators integrated into its
construction. These deformations enable Sprout to express its internal states,
for example, by expanding to express anger and bending its body sideways to
express curiosity. Through two user studies, we investigated how users
interpreted Sprout's expressions, their perceptions of Sprout, and their
expectations from future iterations of Sprout's design. We argue that the use
of soft actuators opens a novel design space for robot expressions to convey
internal states, emotions, and intent.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06263" title="Abstract">arXiv:2401.06263</a> [<a href="/pdf/2401.06263" title="Download PDF">pdf</a>, <a href="/format/2401.06263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedTabDiff: Federated Learning of Diffusion Probabilistic Models for  Synthetic Mixed-Type Tabular Data Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sattarov%2C+T">Timur Sattarov</a>, 
<a href="/search/cs?searchtype=author&query=Schreyer%2C+M">Marco Schreyer</a>, 
<a href="/search/cs?searchtype=author&query=Borth%2C+D">Damian Borth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 2 tables, preprint version, currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Realistic synthetic tabular data generation encounters significant challenges
in preserving privacy, especially when dealing with sensitive information in
domains like finance and healthcare. In this paper, we introduce
\textit{Federated Tabular Diffusion} (FedTabDiff) for generating high-fidelity
mixed-type tabular data without centralized access to the original tabular
datasets. Leveraging the strengths of \textit{Denoising Diffusion Probabilistic
Models} (DDPMs), our approach addresses the inherent complexities in tabular
data, such as mixed attribute types and implicit relationships. More
critically, FedTabDiff realizes a decentralized learning scheme that permits
multiple entities to collaboratively train a generative model while respecting
data privacy and locality. We extend DDPMs into the federated setting for
tabular data generation, which includes a synchronous update scheme and
weighted averaging for effective model aggregation. Experimental evaluations on
real-world financial and medical datasets attest to the framework's capability
to produce synthetic data that maintains high fidelity, utility, privacy, and
coverage.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06268" title="Abstract">arXiv:2401.06268</a> [<a href="/pdf/2401.06268" title="Download PDF">pdf</a>, <a href="/format/2401.06268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Stochastic Model for IRS-Assisted Communication Systems Based on  the Sum-Product of Nakagami-$m$ Random Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amiriara%2C+H">Hamid Amiriara</a>, 
<a href="/search/cs?searchtype=author&query=Mirmohseni%2C+M">Mahtab Mirmohseni</a>, 
<a href="/search/cs?searchtype=author&query=Ashtiani%2C+F">Farid Ashtiani</a>, 
<a href="/search/cs?searchtype=author&query=Nasiri-Kenari%2C+M">Masoumeh Nasiri-Kenari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper presents exact formulas for the probability distribution function
(PDF) and moment generating function (MGF) of the sum-product of statistically
independent but not necessarily identically distributed (i.n.i.d.) Nakagami-$m$
random variables (RVs) in terms of Meijer's G-function. Additionally, exact
series representations are also derived for the sum of double-Nakagami RVs,
providing useful insights on the trade-off between accuracy and computational
cost. Simple asymptotic analytical expressions are provided to gain further
insight into the derived formula, and the achievable diversity order is
obtained. The suggested statistical properties are proved to be a highly useful
tool for modeling parallel cascaded Nakagami-$m$ fading channels. The
application of these new results is illustrated by deriving exact expressions
and simple tight upper bounds for the outage probability (OP) and average
symbol error rate (ASER) of several binary and multilevel modulation signals in
intelligent reflecting surfaces (IRSs)-assisted communication systems operating
over Nakagami-$m$ fading channels. It is demonstrated that the new asymptotic
expression is highly accurate and can be extended to encompass a wider range of
scenarios. To validate the theoretical frameworks and formulations, Monte-Carlo
simulation results are presented. Additionally, supplementary simulations are
provided to compare the derived results with two common types of approximations
available in the literature, namely the central limit theorem (CLT) and gamma
distribution.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06270" title="Abstract">arXiv:2401.06270</a> [<a href="/pdf/2401.06270" title="Download PDF">pdf</a>, <a href="/format/2401.06270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Carbon Modeling of Cloud Servers with Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shixin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoping Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cahoon%2C+S">Stephen Cahoon</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+A+K">Alex K. Jones</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peipei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages; 8 figures; 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Embodied carbon has been widely reported as a significant component in the
full system lifecycle of various computing systems green house gas emissions.
Many efforts have been undertaken to quantify the elements that comprise this
embodied carbon, from tools that evaluate semiconductor manufacturing to those
that can quantify different elements of the computing system from commercial
and academic sources. However, these tools cannot easily reproduce results
reported by server vendors' product carbon reports and the accuracy can vary
substantially due to various assumptions. Furthermore, attempts to determine
green house gas contributions using bottom-up methodologies often do not agree
with system-level studies and are hard to rectify. Nonetheless, given there is
a need to consider all contributions to green house gas emissions in
datacenters, we propose the Server Carbon including Accelerator Reporter with
Intelligence-based Formulation (SCARIF) tool. SCARIF has three main
contributions: (1) We first collect reported carbon cost data from server
vendors and design learning models to predict the embodied carbon cost so that
users can get the embodied carbon cost for their server configurations. (2) We
provide embodied carbon cost if users configure servers with accelerators
including GPUs, and FPGAs. (3) We provide an interface of SCARIF to the ACT and
GreenChip tools and demonstrate the end-to-end system flow through indifference
analysis considering the embodied and operational energy and green house gas
emissions on different years servers with or without accelerators. Thus, SCARIF
provides an opportunity for large-scale datacenter and hyperscaler design.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06273" title="Abstract">arXiv:2401.06273</a> [<a href="/pdf/2401.06273" title="Download PDF">pdf</a>, <a href="/format/2401.06273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qrlew: Rewriting SQL into Differentially Private SQL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grislain%2C+N">Nicolas Grislain</a>, 
<a href="/search/cs?searchtype=author&query=Roussel%2C+P">Paul Roussel</a>, 
<a href="/search/cs?searchtype=author&query=de+Sainte+Agathe%2C+V">Victoria de Sainte Agathe</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PPAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces Qrlew, an open source library that can parse SQL
queries into Relations -- an intermediate representation -- that keeps track of
rich data types, value ranges, and row ownership; so that they can easily be
rewritten into differentially-private equivalent and turned back into SQL
queries for execution in a variety of standard data stores.
<br />With Qrlew, a data practitioner can express their data queries in standard
SQL; the data owner can run the rewritten query without any technical
integration and with strong privacy guarantees on the output; and the query
rewriting can be operated by a privacy-expert who must be trusted by the owner,
but may belong to a separate organization.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06275" title="Abstract">arXiv:2401.06275</a> [<a href="/pdf/2401.06275" title="Download PDF">pdf</a>, <a href="/format/2401.06275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Pulse of Mood Online: Unveiling Emotional Reactions in a Dynamic  Social Media Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Siyi Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zihao He</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Ashwin Rao</a>, 
<a href="/search/cs?searchtype=author&query=Morstatter%2C+F">Fred Morstatter</a>, 
<a href="/search/cs?searchtype=author&query=Brantingham%2C+J">Jeffrey Brantingham</a>, 
<a href="/search/cs?searchtype=author&query=Lerman%2C+K">Kristina Lerman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2307.10245">arXiv:2307.10245</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">The rich and dynamic information environment of social media provides
researchers, policy makers, and entrepreneurs with opportunities to learn about
social phenomena in a timely manner. However, using these data to understand
social behavior is difficult due to heterogeneity of topics and events
discussed in the highly dynamic online information environment. To address
these challenges, we present a method for systematically detecting and
measuring emotional reactions to offline events using change point detection on
the time series of collective affect, and further explaining these reactions
using a transformer-based topic model. We demonstrate the utility of the method
by successfully detecting major and smaller events on three different datasets,
including (1) a Los Angeles Tweet dataset between Jan. and Aug. 2020, in which
we revealed the complex psychological impact of the BlackLivesMatter movement
and the COVID-19 pandemic, (2) a dataset related to abortion rights discussions
in USA, in which we uncovered the strong emotional reactions to the overturn of
Roe v. Wade and state abortion bans, and (3) a dataset about the 2022 French
presidential election, in which we discovered the emotional and moral shift
from positive before voting to fear and criticism after voting. The capability
of our method allows for better sensing and monitoring of population's
reactions during crises using online data.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06277" title="Abstract">arXiv:2401.06277</a> [<a href="/pdf/2401.06277" title="Download PDF">pdf</a>, <a href="/format/2401.06277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting mesh structure to improve multigrid performance for saddle  point problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Spies%2C+L">Lukas Spies</a> (1), 
<a href="/search/math?searchtype=author&query=Olson%2C+L">Luke Olson</a> (1), 
<a href="/search/math?searchtype=author&query=MacLachlan%2C+S">Scott MacLachlan</a> (2) ((1) University of Illinois Urbana-Champaign, USA, (2) Memorial University of Newfoundland, Canada)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IJHPCA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In recent years, solvers for finite-element discretizations of linear or
linearized saddle-point problems, like the Stokes and Oseen equations, have
become well established. There are two main classes of preconditioners for such
systems: those based on block-factorization approach and those based on
monolithic multigrid. Both classes of preconditioners have several critical
choices to be made in their composition, such as the selection of a suitable
relaxation scheme for monolithic multigrid. From existing studies, some insight
can be gained as to what options are preferable in low-performance computing
settings, but there are very few fair comparisons of these approaches in the
literature, particularly for modern architectures, such as GPUs. In this paper,
we perform a comparison between a block-triangular preconditioner and a
monolithic multigrid method with the three most common choices of relaxation
scheme - Braess-Sarazin, Vanka, and Schur-Uzawa. We develop a performant Vanka
relaxation algorithm for structured-grid discretizations, which takes advantage
of memory efficiencies in this setting. We detail the behavior of the various
CUDA kernels for the multigrid relaxation schemes and evaluate their individual
arithmetic intensity, performance, and runtime. Running a preconditioned FGMRES
solver for the Stokes equations with these preconditioners allows us to compare
their efficiency in a practical setting. We show monolithic multigrid can
outperform block-triangular preconditioning, and that using Vanka or
Braess-Sarazin relaxation is most efficient. Even though multigrid with Vanka
relaxation exhibits reduced performance on the CPU (up to $100\%$ slower than
Braess-Sarazin), it is able to outperform Braess-Sarazin by more than $20\%$ on
the GPU, making it a competitive algorithm, especially given the high amount of
algorithmic tuning needed for effective Braess-Sarazin relaxation.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06278" title="Abstract">arXiv:2401.06278</a> [<a href="/pdf/2401.06278" title="Download PDF">pdf</a>, <a href="/format/2401.06278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Self-Supervised Pretraining for Vision Problems in  Gastrointestinal Endoscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanderson%2C+E">Edward Sanderson</a>, 
<a href="/search/cs?searchtype=author&query=Matuszewski%2C+B+J">Bogdan J. Matuszewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Solutions to vision tasks in gastrointestinal endoscopy (GIE) conventionally
use image encoders pretrained in a supervised manner with ImageNet-1k as
backbones. However, the use of modern self-supervised pretraining algorithms
and a recent dataset of 100k unlabelled GIE images (Hyperkvasir-unlabelled) may
allow for improvements. In this work, we study the fine-tuned performance of
models with ResNet50 and ViT-B backbones pretrained in self-supervised and
supervised manners with ImageNet-1k and Hyperkvasir-unlabelled (self-supervised
only) in a range of GIE vision tasks. In addition to identifying the most
suitable pretraining pipeline and backbone architecture for each task, out of
those considered, our results suggest: that self-supervised pretraining
generally produces more suitable backbones for GIE vision tasks than supervised
pretraining; that self-supervised pretraining with ImageNet-1k is typically
more suitable than pretraining with Hyperkvasir-unlabelled, with the notable
exception of monocular depth estimation in colonoscopy; and that ViT-Bs are
more suitable in polyp segmentation and monocular depth estimation in
colonoscopy, ResNet50s are more suitable in polyp detection, and both
architectures perform similarly in anatomical landmark recognition and
pathological finding characterisation. We hope this work draws attention to the
complexity of pretraining for GIE vision tasks, informs this development of
more suitable approaches than the convention, and inspires further research on
this topic to help advance this development. Code available:
\underline{github.com/ESandML/SSL4GIE}
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06279" title="Abstract">arXiv:2401.06279</a> [<a href="/pdf/2401.06279" title="Download PDF">pdf</a>, <a href="/format/2401.06279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling and Uniqueness Sets in Graphon Signal Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parada-Mayorga%2C+A">Alejandro Parada-Mayorga</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this work, we study the properties of sampling sets on families of large
graphs by leveraging the theory of graphons and graph limits. To this end, we
extend to graphon signals the notion of removable and uniqueness sets, which
was developed originally for the analysis of signals on graphs. We state the
formal definition of a $\Lambda-$removable set and conditions under which a
bandlimited graphon signal can be represented in a unique way when its samples
are obtained from the complement of a given $\Lambda-$removable set in the
graphon. By leveraging such results we show that graphon representations of
graphs and graph signals can be used as a common framework to compare sampling
sets between graphs with different numbers of nodes and edges, and different
node labelings. Additionally, given a sequence of graphs that converges to a
graphon, we show that the sequences of sampling sets whose graphon
representation is identical in $[0,1]$ are convergent as well. We exploit the
convergence results to provide an algorithm that obtains approximately close to
optimal sampling sets. Performing a set of numerical experiments, we evaluate
the quality of these sampling sets. Our results open the door for the efficient
computation of optimal sampling sets in graphs of large size.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06280" title="Abstract">arXiv:2401.06280</a> [<a href="/pdf/2401.06280" title="Download PDF">pdf</a>, <a href="/format/2401.06280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stress-hybrid virtual element method on six-noded triangular meshes for  compressible and nearly-incompressible linear elasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+A">Alvin Chen</a>, 
<a href="/search/math?searchtype=author&query=Bishop%2C+J+E">Joseph E. Bishop</a>, 
<a href="/search/math?searchtype=author&query=Sukumar%2C+N">N. Sukumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages, 49 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we present a first-order Stress-Hybrid Virtual Element Method
(SH-VEM) on six-noded triangular meshes for linear plane elasticity. We adopt
the Hellinger--Reissner variational principle to construct a weak equilibrium
condition and a stress based projection operator. On applying the divergence
theorem to the weak strain-displacement relations, the stress projection
operator is expressed in terms of the nodal displacements, which leads to a
displacement-based formulation. This stress-hybrid approach assumes a globally
continuous displacement field while the stress field is discontinuous across
each element. The stress field is initially represented by divergence-free
tensor polynomials based on Airy stress functions. However, for flexibility in
choosing basis functions, we also present a formulation that uses a penalty
term to enforce the element equilibrium conditions. This method is referred to
as the Penalty Stress-Hybrid Virtual Element Method (PSH-VEM). Numerical
results are presented for PSH-VEM and SH-VEM, and we compare their convergence
to the composite triangle FEM and B-bar VEM on benchmark problems in linear
elasticity. The SH-VEM converges optimally in the $L^2$ norm of the
displacement, energy seminorm, and the $L^2$ norm of hydrostatic stress.
Furthermore, the results reveal that PSH-VEM converges in most cases at a
faster rate than the expected optimal rate, but it requires the selection of a
suitably chosen penalty parameter.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06281" title="Abstract">arXiv:2401.06281</a> [<a href="/pdf/2401.06281" title="Download PDF">pdf</a>, <a href="/format/2401.06281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying Variational Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Sousa+Ribeiro%2C+F">Fabio De Sousa Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Glocker%2C+B">Ben Glocker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Despite the growing popularity of diffusion models, gaining a deep
understanding of the model class remains somewhat elusive for the uninitiated
in non-equilibrium statistical physics. With that in mind, we present what we
believe is a more straightforward introduction to diffusion models using
directed graphical modelling and variational Bayesian principles, which imposes
relatively fewer prerequisites on the average reader. Our exposition
constitutes a comprehensive technical review spanning from foundational
concepts like deep latent variable models to recent advances in continuous-time
diffusion-based modelling, highlighting theoretical connections between model
classes along the way. We provide additional mathematical insights that were
omitted in the seminal works whenever possible to aid in understanding, while
avoiding the introduction of new notation. We envision this article serving as
a useful educational supplement for both researchers and practitioners in the
area, and we welcome feedback and contributions from the community at
https://github.com/biomedia-mira/demystifying-diffusion.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06287" title="Abstract">arXiv:2401.06287</a> [<a href="/pdf/2401.06287" title="Download PDF">pdf</a>, <a href="/format/2401.06287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Augmentation and Distillation for Class Incremental  Audio-Visual Video Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Y">Yukun Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hantao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+L">Liansheng Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Audio-visual video recognition (AVVR) aims to integrate audio and visual
clues to categorize videos accurately. While existing methods train AVVR models
using provided datasets and achieve satisfactory results, they struggle to
retain historical class knowledge when confronted with new classes in
real-world situations. Currently, there are no dedicated methods for addressing
this problem, so this paper concentrates on exploring Class Incremental
Audio-Visual Video Recognition (CIAVVR). For CIAVVR, since both stored data and
learned model of past classes contain historical knowledge, the core challenge
is how to capture past data knowledge and past model knowledge to prevent
catastrophic forgetting. We introduce Hierarchical Augmentation and
Distillation (HAD), which comprises the Hierarchical Augmentation Module (HAM)
and Hierarchical Distillation Module (HDM) to efficiently utilize the
hierarchical structure of data and models, respectively. Specifically, HAM
implements a novel augmentation strategy, segmental feature augmentation, to
preserve hierarchical model knowledge. Meanwhile, HDM introduces newly designed
hierarchical (video-distribution) logical distillation and hierarchical
(snippet-video) correlative distillation to capture and maintain the
hierarchical intra-sample knowledge of each data and the hierarchical
inter-sample knowledge between data, respectively. Evaluations on four
benchmarks (AVE, AVK-100, AVK-200, and AVK-400) demonstrate that the proposed
HAD effectively captures hierarchical information in both data and models,
resulting in better preservation of historical class knowledge and improved
performance. Furthermore, we provide a theoretical analysis to support the
necessity of the segmental feature augmentation strategy.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06289" title="Abstract">arXiv:2401.06289</a> [<a href="/pdf/2401.06289" title="Download PDF">pdf</a>, <a href="/format/2401.06289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Evaluation of a Socially Assistive Robot Schoolwork Companion  for College Students with ADHD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=O%27Connell%2C+A">Amy O&#x27;Connell</a>, 
<a href="/search/cs?searchtype=author&query=Banga%2C+A">Ashveen Banga</a>, 
<a href="/search/cs?searchtype=author&query=Ayissi%2C+J">Jennifer Ayissi</a>, 
<a href="/search/cs?searchtype=author&query=Yaminrafie%2C+N">Nikki Yaminrafie</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+E">Ellen Ko</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+A">Andrew Le</a>, 
<a href="/search/cs?searchtype=author&query=Cislowski%2C+B">Bailey Cislowski</a>, 
<a href="/search/cs?searchtype=author&query=Matari%C4%87%2C+M">Maja Matari&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">College students with ADHD respond positively to simple socially assistive
robots (SARs) that monitor attention and provide non-verbal feedback, but
studies have been done only in brief in-lab sessions. We present an initial
design and evaluation of an in-dorm SAR study companion for college students
with ADHD. This work represents the introductory stages of an ongoing
user-centered, participatory design process. In a three-week within-subjects
user study, university students (N=11) with self-reported symptoms of adult
ADHD had a SAR study companion in their dorm room for two weeks and a
computer-based system for one week. Toward developing SARs for long-term,
in-dorm use, we focus on 1) evaluating the usability and desire for SAR study
companions by college students with ADHD and 2) collecting participant feedback
about the SAR design and functionality. Participants responded positively to
the robot; after one week of regular use, 91% (10 of 11) chose to continue
using the robot voluntarily in the second week.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06291" title="Abstract">arXiv:2401.06291</a> [<a href="/pdf/2401.06291" title="Download PDF">pdf</a>, <a href="/format/2401.06291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency-Time Diffusion with Neural Cellular Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalkhof%2C+J">John Kalkhof</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChn%2C+A">Arlene K&#xfc;hn</a>, 
<a href="/search/cs?searchtype=author&query=Frisch%2C+Y">Yannik Frisch</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+A">Anirban Mukhopadhyay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Denoising Diffusion Models (DDMs) have become the leading generative
technique for synthesizing high-quality images but are often constrained by
their UNet-based architectures that impose certain limitations. In particular,
the considerable size of often hundreds of millions of parameters makes them
impractical when hardware resources are limited. However, even with powerful
hardware, processing images in the gigapixel range is difficult. This is
especially true in fields such as microscopy or satellite imaging, where such
challenges arise from the limitation to a predefined generative size and the
inefficient scaling to larger images. We present two variations of Neural
Cellular Automata (NCA)-based DDM methods to address these challenges and
jumpstart NCA-based DDMs: Diff-NCA and FourierDiff-NCA. Diff-NCA performs
diffusion by using only local features of the underlying distribution, making
it suitable for applications where local features are critical. To communicate
global knowledge in image space, naive NCA setups require timesteps that
increase with the image scale. We solve this bottleneck of current NCA
architectures by introducing FourierDiff-NCA, which advances Diff-NCA by adding
a Fourier-based diffusion process and combines the frequency-organized Fourier
space with the image space. By initiating diffusion in the Fourier domain and
finalizing it in the image space, FourierDiff-NCA accelerates global
communication. We validate our techniques by using Diff-NCA (208k parameters)
to generate high-resolution digital pathology scans at 576x576 resolution and
FourierDiff-NCA (887k parameters) to synthesize CelebA images at 64x64,
outperforming VNCA and five times bigger UNet-based DDMs. In addition, we
demonstrate FourierDiff-NCA's capabilities in super-resolution, OOD image
synthesis, and inpainting without additional training.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06293" title="Abstract">arXiv:2401.06293</a> [<a href="/pdf/2401.06293" title="Download PDF">pdf</a>, <a href="/format/2401.06293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiSlot ReRanker: A Generic Model-based Re-Ranking Framework in  Recommendation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Q+C">Qiang Charles Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Muralidharan%2C+A">Ajith Muralidharan</a>, 
<a href="/search/cs?searchtype=author&query=Tiwana%2C+B">Birjodh Tiwana</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Johnson Jia</a>, 
<a href="/search/cs?searchtype=author&query=Borisyuk%2C+F">Fedor Borisyuk</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aman Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Woodard%2C+D">Dawn Woodard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">In this paper, we propose a generic model-based re-ranking framework,
MultiSlot ReRanker, which simultaneously optimizes relevance, diversity, and
freshness. Specifically, our Sequential Greedy Algorithm (SGA) is efficient
enough (linear time complexity) for large-scale production recommendation
engines. It achieved a lift of $+6\%$ to $ +10\%$ offline Area Under the
receiver operating characteristic Curve (AUC) which is mainly due to explicitly
modeling mutual influences among items of a list, and leveraging the second
pass ranking scores of multiple objectives. In addition, we have generalized
the offline replay theory to multi-slot re-ranking scenarios, with trade-offs
among multiple objectives. The offline replay results can be further improved
by Pareto Optimality. Moreover, we've built a multi-slot re-ranking simulator
based on OpenAI Gym integrated with the Ray framework. It can be easily
configured for different assumptions to quickly benchmark both reinforcement
learning and supervised learning algorithms.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06299" title="Abstract">arXiv:2401.06299</a> [<a href="/pdf/2401.06299" title="Download PDF">pdf</a>, <a href="/ps/2401.06299" title="Download PostScript">ps</a>, <a href="/format/2401.06299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free Reinforcement Learning for Automated Fluid Administration in  Critical Care
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Estiri%2C+E">Elham Estiri</a>, 
<a href="/search/eess?searchtype=author&query=Mirinejad%2C+H">Hossein Mirinejad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Fluid administration, also called fluid resuscitation, is a medical treatment
to restore the lost blood volume and optimize cardiac functions in critical
care scenarios such as burn, hemorrhage, and septic shock. Automated fluid
administration systems (AFAS), a potential means to improve the treatment,
employ computational control algorithms to automatically adjust optimal fluid
infusion dosages by targeting physiological variables (e.g., blood volume or
blood pressure). Most of the existing AFAS control algorithms are model-based
approaches, and their performance is highly dependent on the model accuracy,
making them less desirable in real-world care of critically ill patients due to
complexity and variability of modeling patients physiological states. This work
presents a novel model-free reinforcement learning (RL) approach for the
control of fluid infusion dosages in AFAS systems. The proposed RL agent learns
to adjust the blood volume to a desired value by choosing the optimal infusion
dosages using a Q-learning algorithm. The RL agent learns the optimal actions
by interacting with the environment (without having the knowledge of system
dynamics). The proposed methodology (i) overcomes the need for a precise
mathematical model in AFAS systems and (ii) provides a robust performance in
rejecting clinical noises and reaching desired hemodynamic states, as will be
shown by simulation results.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06301" title="Abstract">arXiv:2401.06301</a> [<a href="/pdf/2401.06301" title="Download PDF">pdf</a>, <a href="/format/2401.06301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misconfidence-based Demonstration Selection for LLM In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shangqing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a> (Georgia Institute of Technology)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In-context learning with large language models (LLMs) excels at adapting to
various tasks rapidly. However, its success hinges on carefully selecting
demonstrations, which remains an obstacle in practice. Current approaches to
this problem either rely on hard-to-acquire external supervision or require
frequent interactions with LLMs, resulting in high costs. We propose a new
method called In-Context Reflection (ICR) to overcome these challenges. ICR
strategically selects demonstrations to reduce the discrepancy between the
LLM's outputs and the actual input-output mappings. Specifically, ICR starts
with a random set of initial demonstrations, then iteratively refines it. In
each step, it analyzes a pool of candidate examples and identifies the ones
most likely to challenge the LLM's current understanding, measured by a new
metric called misconfidence. These most confusing examples are then selected to
replace the less informative demonstrations in the current set. Our
comprehensive evaluation across five diverse datasets encompassing 13 subtasks
shows the efficacy of ICR. Compared to existing methods, ICR achieves an
average performance boost of 4%, while demonstrating remarkable cross-task
generalization capabilities.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06305" title="Abstract">arXiv:2401.06305</a> [<a href="/pdf/2401.06305" title="Download PDF">pdf</a>, <a href="/format/2401.06305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Profile Quadratic Programming (MPQP) for Optimal Gap Selection and  Speed Planning of Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anon%2C+A+M">Alexandre Miranda Anon</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+S">Sangjae Bae</a>, 
<a href="/search/cs?searchtype=author&query=Saroya%2C+M">Manish Saroya</a>, 
<a href="/search/cs?searchtype=author&query=Isele%2C+D">David Isele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Smooth and safe speed planning is imperative for the successful deployment of
autonomous vehicles. This paper presents a mathematical formulation for the
optimal speed planning of autonomous driving, which has been validated in
high-fidelity simulations and real-road demonstrations with practical
constraints. The algorithm explores the inter-traffic gaps in the time and
space domain using a breadth-first search. For each gap, quadratic programming
finds an optimal speed profile, synchronizing the time and space pair along
with dynamic obstacles. Qualitative and quantitative analysis in Carla is
reported to discuss the smoothness and robustness of the proposed algorithm.
Finally, we present a road demonstration result for urban city driving.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06306" title="Abstract">arXiv:2401.06306</a> [<a href="/pdf/2401.06306" title="Download PDF">pdf</a>, <a href="/format/2401.06306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Network Slicing, Routing, and In-Network Computing for  Energy-Efficient 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sasan%2C+Z">Zeinab Sasan</a>, 
<a href="/search/cs?searchtype=author&query=Shokrnezhad%2C+M">Masoud Shokrnezhad</a>, 
<a href="/search/cs?searchtype=author&query=Khorsandi%2C+S">Siavash Khorsandi</a>, 
<a href="/search/cs?searchtype=author&query=Taleb%2C+T">Tarik Taleb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2024 IEEE Wireless Communications and Networking Conference (WCNC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">To address the evolving landscape of next-generation mobile networks,
characterized by an increasing number of connected users, surging traffic
demands, and the continuous emergence of new services, a novel communication
paradigm is essential. One promising candidate is the integration of network
slicing and in-network computing, offering resource isolation, deterministic
networking, enhanced resource efficiency, network expansion, and energy
conservation. Although prior research has explored resource allocation within
network slicing, routing, and in-network computing independently, a
comprehensive investigation into their joint approach has been lacking. This
paper tackles the joint problem of network slicing, path selection, and the
allocation of in-network and cloud computing resources, aiming to maximize the
number of accepted users while minimizing energy consumption. First, we
introduce a Mixed-Integer Linear Programming (MILP) formulation of the problem
and analyze its complexity, proving that the problem is NP-hard. Next, a Water
Filling-based Joint Slicing, Routing, and In-Network Computing (WF-JSRIN)
heuristic algorithm is proposed to solve it. Finally, a comparative analysis
was conducted among WF-JSRIN, a random allocation technique, and two optimal
approaches, namely Opt-IN (utilizing in-network computation) and Opt-C (solely
relying on cloud node resources). The results emphasize WF-JSRIN's efficiency
in delivering highly efficient near-optimal solutions with significantly
reduced execution times, solidifying its suitability for practical real-world
applications.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06308" title="Abstract">arXiv:2401.06308</a> [<a href="/pdf/2401.06308" title="Download PDF">pdf</a>, <a href="/format/2401.06308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Semantic-Aware Multiple Access Scheme for Distributed, Dynamic  6G-Based Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazandarani%2C+H">Hamidreza Mazandarani</a>, 
<a href="/search/cs?searchtype=author&query=Shokrnezhad%2C+M">Masoud Shokrnezhad</a>, 
<a href="/search/cs?searchtype=author&query=Taleb%2C+T">Tarik Taleb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2024 IEEE Wireless Communications and Networking Conference (WCNC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">The emergence of the semantic-aware paradigm presents opportunities for
innovative services, especially in the context of 6G-based applications.
Although significant progress has been made in semantic extraction techniques,
the incorporation of semantic information into resource allocation
decision-making is still in its early stages, lacking consideration of the
requirements and characteristics of future systems. In response, this paper
introduces a novel formulation for the problem of multiple access to the
wireless spectrum. It aims to optimize the utilization-fairness trade-off,
using the $\alpha$-fairness metric, while accounting for user data correlation
by introducing the concepts of self- and assisted throughputs. Initially, the
problem is analyzed to identify its optimal solution. Subsequently, a
Semantic-Aware Multi-Agent Double and Dueling Deep Q-Learning (SAMA-D3QL)
technique is proposed. This method is grounded in Model-free Multi-Agent Deep
Reinforcement Learning (MADRL), enabling the user equipment to autonomously
make decisions regarding wireless spectrum access based solely on their local
individual observations. The efficiency of the proposed technique is evaluated
through two scenarios: single-channel and multi-channel. The findings
illustrate that, across a spectrum of $\alpha$ values, association matrices,
and channels, SAMA-D3QL consistently outperforms alternative approaches. This
establishes it as a promising candidate for facilitating the realization of
future federated, dynamically evolving applications.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06310" title="Abstract">arXiv:2401.06310</a> [<a href="/pdf/2401.06310" title="Download PDF">pdf</a>, <a href="/format/2401.06310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Surface: A Global-Scale Analysis of Visual Stereotypes in  Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+A">Akshita Jha</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakaran%2C+V">Vinodkumar Prabhakaran</a>, 
<a href="/search/cs?searchtype=author&query=Denton%2C+R">Remi Denton</a>, 
<a href="/search/cs?searchtype=author&query=Laszlo%2C+S">Sarah Laszlo</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+S">Shachi Dave</a>, 
<a href="/search/cs?searchtype=author&query=Qadri%2C+R">Rida Qadri</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+C+K">Chandan K. Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Dev%2C+S">Sunipa Dev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">Recent studies have highlighted the issue of stereotypical depictions for
people of different identity groups in Text-to-Image (T2I) model generations.
However, these existing approaches have several key limitations, including a
noticeable lack of coverage of global identity groups in their evaluation, and
the range of their associated stereotypes. Additionally, they often lack a
critical distinction between inherently visual stereotypes, such as
`underweight' or `sombrero', and culturally dependent stereotypes like
`attractive' or `terrorist'. In this work, we address these limitations with a
multifaceted approach that leverages existing textual resources to ground our
evaluation of geo-cultural stereotypes in the generated images from T2I models.
We employ existing stereotype benchmarks to identify and evaluate visual
stereotypes at a global scale, spanning 135 nationality-based identity groups.
We demonstrate that stereotypical attributes are thrice as likely to be present
in images of these identities as compared to other attributes. We further
investigate how disparately offensive the depictions of generated images are
for different nationalities. Finally, through a detailed case study, we reveal
how the 'default' representations of all identity groups have a stereotypical
appearance. Moreover, for the Global South, images across different attributes
are visually similar, even when explicitly prompted otherwise. CONTENT WARNING:
Some examples may contain offensive stereotypes.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06311" title="Abstract">arXiv:2401.06311</a> [<a href="/pdf/2401.06311" title="Download PDF">pdf</a>, <a href="/format/2401.06311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuGI: Enhancing Information Retrieval through Multi-Text Generation  Intergration with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yihong Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have emerged as a pivotal force in language
technology. Their robust reasoning capabilities and expansive knowledge
repositories have enabled exceptional zero-shot generalization abilities across
various facets of the natural language processing field, including information
retrieval (IR). In this paper, we conduct an in-depth investigation into the
utility of documents generated by LLMs for IR. We introduce a simple yet
effective framework, Multi-Text Generation Integration (MuGI), to augment
existing IR methodologies. Specifically, we prompt LLMs to generate multiple
pseudo references and integrate with query for retrieval. The training-free
MuGI model eclipses existing query expansion strategies, setting a new standard
in sparse retrieval. It outstrips supervised counterparts like ANCE and DPR,
achieving a notable over 18% enhancement in BM25 on the TREC DL dataset and a
7.5% increase on BEIR. Through MuGI, we have forged a rapid and high-fidelity
re-ranking pipeline. This allows a relatively small 110M parameter retriever to
surpass the performance of larger 3B models in in-domain evaluations, while
also bridging the gap in out-of-distribution situations. We release our code
and all generated references at https://github.com/lezhang7/Retrieval_MuGI.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06312" title="Abstract">arXiv:2401.06312</a> [<a href="/pdf/2401.06312" title="Download PDF">pdf</a>, <a href="/format/2401.06312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Super-Resolution Transformer with Masked Inter&amp;Intra-Frame  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Leheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaorui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Keze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Leida Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shuhang Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, Vision Transformer has achieved great success in recovering missing
details in low-resolution sequences, i.e., the video super-resolution (VSR)
task.Despite its superiority in VSR accuracy, the heavy computational burden as
well as the large memory footprint hinder the deployment of Transformer-based
VSR models on constrained devices.In this paper, we address the above issue by
proposing a novel feature-level masked processing framework: VSR with Masked
Intra and inter frame Attention (MIA-VSR).The core of MIA-VSR is leveraging
feature-level temporal continuity between adjacent frames to reduce redundant
computations and make more rational use of previously enhanced SR features.
Concretely, we propose an intra-frame and inter-frame attention block which
takes the respective roles of past features and input features into
consideration and only exploits previously enhanced features to provide
supplementary information. In addition, an adaptive block-wise mask prediction
module is developed to skip unimportant computations according to feature
similarity between adjacent frames. We conduct detailed ablation studies to
validate our contributions and compare the proposed method with recent
state-of-the-art VSR approaches. The experimental results demonstrate that
MIA-VSR improves the memory and computation efficiency over state-of-the-art
methods, without trading off PSNR accuracy. The code is available at
https://github.com/LabShuHangGU/MIA-VSR.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06318" title="Abstract">arXiv:2401.06318</a> [<a href="/pdf/2401.06318" title="Download PDF">pdf</a>, <a href="/format/2401.06318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Striking a Balance in Fairness for Dynamic Systems Through Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yaowei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lear%2C+J">Jacob Lear</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While significant advancements have been made in the field of fair machine
learning, the majority of studies focus on scenarios where the decision model
operates on a static population. In this paper, we study fairness in dynamic
systems where sequential decisions are made. Each decision may shift the
underlying distribution of features or user behavior. We model the dynamic
system through a Markov Decision Process (MDP). By acknowledging that
traditional fairness notions and long-term fairness are distinct requirements
that may not necessarily align with one another, we propose an algorithmic
framework to integrate various fairness considerations with reinforcement
learning using both pre-processing and in-processing approaches. Three case
studies show that our method can strike a balance between traditional fairness
notions, long-term fairness, and utility.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06320" title="Abstract">arXiv:2401.06320</a> [<a href="/pdf/2401.06320" title="Download PDF">pdf</a>, <a href="/format/2401.06320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Generative Large Language Models for Systematic Review  Screening Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Scells%2C+H">Harrisen Scells</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+S">Shengyao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Potthast%2C+M">Martin Potthast</a>, 
<a href="/search/cs?searchtype=author&query=Koopman%2C+B">Bevan Koopman</a>, 
<a href="/search/cs?searchtype=author&query=Zuccon%2C+G">Guido Zuccon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ECIR2024 full paper (findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Systematic reviews are crucial for evidence-based medicine as they
comprehensively analyse published research findings on specific questions.
Conducting such reviews is often resource- and time-intensive, especially in
the screening phase, where abstracts of publications are assessed for inclusion
in a review. This study investigates the effectiveness of using zero-shot large
language models~(LLMs) for automatic screening. We evaluate the effectiveness
of eight different LLMs and investigate a calibration technique that uses a
predefined recall threshold to determine whether a publication should be
included in a systematic review. Our comprehensive evaluation using five
standard test collections shows that instruction fine-tuning plays an important
role in screening, that calibration renders LLMs practical for achieving a
targeted recall, and that combining both with an ensemble of zero-shot models
saves significant screening time compared to state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06321" title="Abstract">arXiv:2401.06321</a> [<a href="/pdf/2401.06321" title="Download PDF">pdf</a>, <a href="/format/2401.06321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task Learning for Front-End Text Processing in TTS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wonjune Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hinsvark%2C+A">Arthur Hinsvark</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qing He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We propose a multi-task learning (MTL) model for jointly performing three
tasks that are commonly solved in a text-to-speech (TTS) front-end: text
normalization (TN), part-of-speech (POS) tagging, and homograph disambiguation
(HD). Our framework utilizes a tree-like structure with a trunk that learns
shared representations, followed by separate task-specific heads. We further
incorporate a pre-trained language model to utilize its built-in lexical and
contextual knowledge, and study how to best use its embeddings so as to most
effectively benefit our multi-task model. Through task-wise ablations, we show
that our full model trained on all three tasks achieves the strongest overall
performance compared to models trained on individual or sub-combinations of
tasks, confirming the advantages of our MTL framework. Finally, we introduce a
new HD dataset containing a balanced number of sentences in diverse contexts
for a variety of homographs and their pronunciations. We demonstrate that
incorporating this dataset into training significantly improves HD performance
over only using a commonly used, but imbalanced, pre-existing dataset.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06323" title="Abstract">arXiv:2401.06323</a> [<a href="/pdf/2401.06323" title="Download PDF">pdf</a>, <a href="/format/2401.06323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kimera2: Robust and Accurate Metric-Semantic SLAM in the Real World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abate%2C+M">Marcus Abate</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+N">Nathan Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Carlone%2C+L">Luca Carlone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at ISER 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present improvements to Kimera, an open-source metric-semantic
visual-inertial SLAM library. In particular, we enhance Kimera-VIO, the
visual-inertial odometry pipeline powering Kimera, to support better feature
tracking, more efficient keyframe selection, and various input modalities (eg
monocular, stereo, and RGB-D images, as well as wheel odometry). Additionally,
Kimera-RPGO and Kimera-PGMO, Kimera's pose-graph optimization backends, are
updated to support modern outlier rejection methods - specifically,
Graduated-Non-Convexity - for improved robustness to spurious loop closures.
These new features are evaluated extensively on a variety of simulated and real
robotic platforms, including drones, quadrupeds, wheeled robots, and simulated
self-driving cars. We present comparisons against several state-of-the-art
visual-inertial SLAM pipelines and discuss strengths and weaknesses of the new
release of Kimera. The newly added features have been released open-source at
https://github.com/MIT-SPARK/Kimera.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06327" title="Abstract">arXiv:2401.06327</a> [<a href="/pdf/2401.06327" title="Download PDF">pdf</a>, <a href="/format/2401.06327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Semi-Factuals: A Debiased and Semantic-Aware Framework for  Generalized Relation Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tianlin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenjun Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce a novel task, called Generalized Relation Discovery (GRD), for
open-world relation extraction. GRD aims to identify unlabeled instances in
existing pre-defined relations or discover novel relations by assigning
instances to clusters as well as providing specific meanings for these
clusters. The key challenges of GRD are how to mitigate the serious model
biases caused by labeled pre-defined relations to learn effective relational
representations and how to determine the specific semantics of novel relations
during classifying or clustering unlabeled instances. We then propose a novel
framework, SFGRD, for this task to solve the above issues by learning from
semi-factuals in two stages. The first stage is semi-factual generation
implemented by a tri-view debiased relation representation module, in which we
take each original sentence as the main view and design two debiased views to
generate semi-factual examples for this sentence. The second stage is
semi-factual thinking executed by a dual-space tri-view collaborative relation
learning module, where we design a cluster-semantic space and a class-index
space to learn relational semantics and relation label indices, respectively.
In addition, we devise alignment and selection strategies to integrate two
spaces and establish a self-supervised learning loop for unlabeled data by
doing semi-factual thinking across three views. Extensive experimental results
show that SFGRD surpasses state-of-the-art models in terms of accuracy by
2.36\% $\sim$5.78\% and cosine similarity by 32.19\%$\sim$ 84.45\% for relation
label index and relation semantic quality, respectively. To the best of our
knowledge, we are the first to exploit the efficacy of semi-factuals in
relation extraction.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06331" title="Abstract">arXiv:2401.06331</a> [<a href="/pdf/2401.06331" title="Download PDF">pdf</a>, <a href="/ps/2401.06331" title="Download PostScript">ps</a>, <a href="/format/2401.06331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application Of Vision-Language Models For Assessing Osteoarthritis  Disease Severity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Felfeliyan%2C+B">Banafshe Felfeliyan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shrimanti Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Kupper%2C+J">Jessica Kupper</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaobo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hareendranathan%2C+A">Abhilash Hareendranathan</a>, 
<a href="/search/cs?searchtype=author&query=Jaremko%2C+J+L">Jacob L. Jaremko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Osteoarthritis (OA) poses a global health challenge, demanding precise
diagnostic methods. Current radiographic assessments are time consuming and
prone to variability, prompting the need for automated solutions. The existing
deep learning models for OA assessment are unimodal single task systems and
they don't incorporate relevant text information such as patient demographics,
disease history, or physician reports. This study investigates employing Vision
Language Processing (VLP) models to predict OA severity using Xray images and
corresponding reports. Our method leverages Xray images of the knee and diverse
report templates generated from tabular OA scoring values to train a CLIP
(Contrastive Language Image PreTraining) style VLP model. Furthermore, we
incorporate additional contrasting captions to enforce the model to
discriminate between positive and negative reports. Results demonstrate the
efficacy of these models in learning text image representations and their
contextual relationships, showcase potential advancement in OA assessment, and
establish a foundation for specialized vision language models in medical
contexts.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06332" title="Abstract">arXiv:2401.06332</a> [<a href="/pdf/2401.06332" title="Download PDF">pdf</a>, <a href="/format/2401.06332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Solvers for Network Linear Equations with Scalarized  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+Z">Zihao Ren</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+D">Deming Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+G">Guodong Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we study distributed solvers for network linear equations over
a network with node-to-node communication messages compressed as scalar values.
Our key idea lies in a dimension compression scheme including a dimension
compressing vector that applies to individual node states to generate a
real-valued message for node communication as an inner product, and a data
unfolding step in the local computations where the scalar message is plotted
along the subspace generated by the compression vector. We first present a
compressed average consensus flow that relies only on such scalar
communication, and show that exponential convergence can be achieved with well
excited signals for the compression vector. We then employ such a compressed
consensus flow as a fundamental consensus subroutine to develop distributed
continuous-time and discrete-time solvers for network linear equations, and
prove their exponential convergence properties under scalar node
communications. With scalar communications, a direct benefit would be the
reduced node-to-node communication channel capacity requirement for distributed
computing. Numerical examples are presented to illustrate the effectiveness of
the established theoretical results.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06336" title="Abstract">arXiv:2401.06336</a> [<a href="/pdf/2401.06336" title="Download PDF">pdf</a>, <a href="/ps/2401.06336" title="Download PostScript">ps</a>, <a href="/format/2401.06336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRACE: A Time-Relational Approximate Cubing Engine for Fast Data  Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sivakumar%2C+S">Suharsh Sivakumar</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jonathan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Monga%2C+R">Rajat Monga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Databases (cs.DB)

</div>
<p class="mathjax">A large class of data questions can be modeled as identifying important
slices of data driven by user defined metrics. This paper presents TRACE, a
Time-Relational Approximate Cubing Engine that enables interactive analysis on
such slices with a low upfront cost - both in space and computation. It does
this by materializing the most important parts of the cube over time enabling
interactive querying for a large class of analytical queries e.g. what part of
my business has the highest revenue growth ([SubCategory=Sports Equipment,
Gender=Female]), what slices are lagging in revenue per user ([State=CA,
Age=20-30]). Many user defined metrics are supported including common
aggregations such as SUM, COUNT, DISTINCT COUNT and more complex ones such as
AVERAGE. We implemented and deployed TRACE for a variety of business use cases.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06337" title="Abstract">arXiv:2401.06337</a> [<a href="/pdf/2401.06337" title="Download PDF">pdf</a>, <a href="/ps/2401.06337" title="Download PostScript">ps</a>, <a href="/format/2401.06337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An ontology alignment method with user intervention using compact  differential evolution with adaptive parameter control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zhaoming Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">User interaction is one of the most effective ways to improve the ontology
alignment quality. However, this approach faces the challenge of how users can
participate effectively in the matching process. To solve this challenge. In
this paper, an interactive ontology alignment approach using compact
differential evolution algorithm with adaptive parameter control (IOACDE) is
proposed. In this method, the ontology alignment process is modeled as an
interactive optimization problem and users are allowed to intervene in matching
in two ways. One is that the mapping suggestions generated by IOACDE as a
complete candidate alignment is evaluated by user during optimization process.
The other is that the user ameliorates the alignment results by evaluating
single mapping after the automatic matching process. To demonstrate the
effectiveness of the proposed algorithm, the neural embedding model and K
nearest neighbor (KNN) is employed to simulate user for the ontologies of the
real world. The experimental results show that the proposed interactive
approach can improve the alignment quality compared to the non-interactive.
Compared with the state-of-the-art methods from OAEI, the results show that the
proposed algorithm has a better performance under the same error rate.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06340" title="Abstract">arXiv:2401.06340</a> [<a href="/pdf/2401.06340" title="Download PDF">pdf</a>, <a href="/format/2401.06340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Temporal-Spectral Fusion Transformer with Subject-specific Adapter for  Enhancing RSVP-BCI Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xujin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shuang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Huiguang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Rapid Serial Visual Presentation (RSVP)-based Brain-Computer Interface
(BCI) is an efficient technology for target retrieval using
electroencephalography (EEG) signals. The performance improvement of
traditional decoding methods relies on a substantial amount of training data
from new test subjects, which increases preparation time for BCI systems.
Several studies introduce data from existing subjects to reduce the dependence
of performance improvement on data from new subjects, but their optimization
strategy based on adversarial learning with extensive data increases training
time during the preparation procedure. Moreover, most previous methods only
focus on the single-view information of EEG signals, but ignore the information
from other views which may further improve performance. To enhance decoding
performance while reducing preparation time, we propose a Temporal-Spectral
fusion transformer with Subject-specific Adapter (TSformer-SA). Specifically, a
cross-view interaction module is proposed to facilitate information transfer
and extract common representations across two-view features extracted from EEG
temporal signals and spectrogram images. Then, an attention-based fusion module
fuses the features of two views to obtain comprehensive discriminative features
for classification. Furthermore, a multi-view consistency loss is proposed to
maximize the feature similarity between two views of the same EEG signal.
Finally, we propose a subject-specific adapter to rapidly transfer the
knowledge of the model trained on data from existing subjects to decode data
from new subjects. Experimental results show that TSformer-SA significantly
outperforms comparison methods and achieves outstanding performance with
limited training data from new subjects. This facilitates efficient decoding
and rapid deployment of BCI systems in practical use.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06341" title="Abstract">arXiv:2401.06341</a> [<a href="/pdf/2401.06341" title="Download PDF">pdf</a>, <a href="/format/2401.06341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AffordanceLLM: Grounding Affordance from Vision Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shengyi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+M">Min Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhuowen Tu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L+E">Li Erran Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Affordance grounding refers to the task of finding the area of an object with
which one can interact. It is a fundamental but challenging task, as a
successful solution requires the comprehensive understanding of a scene in
multiple aspects including detection, localization, and recognition of objects
with their parts, of geo-spatial configuration/layout of the scene, of 3D
shapes and physics, as well as of the functionality and potential interaction
of the objects and humans. Much of the knowledge is hidden and beyond the image
content with the supervised labels from a limited training set. In this paper,
we make an attempt to improve the generalization capability of the current
affordance grounding by taking the advantage of the rich world, abstract, and
human-object-interaction knowledge from pretrained large-scale vision language
models. Under the AGD20K benchmark, our proposed model demonstrates a
significant performance gain over the competing methods for in-the-wild object
affordance grounding. We further demonstrate it can ground affordance for
objects from random Internet images, even if both objects and actions are
unseen during training. Project site: https://jasonqsy.github.io/AffordanceLLM/
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06344" title="Abstract">arXiv:2401.06344</a> [<a href="/pdf/2401.06344" title="Download PDF">pdf</a>, <a href="/format/2401.06344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyper-STTN: Social Group-aware Spatial-Temporal Transformer Network for  Human Trajectory Prediction with Hypergraph Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weizheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+L">Le Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Baijian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guohua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+B">Byung-Cheol Min</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Predicting crowded intents and trajectories is crucial in varouls real-world
applications, including service robots and autonomous vehicles. Understanding
environmental dynamics is challenging, not only due to the complexities of
modeling pair-wise spatial and temporal interactions but also the diverse
influence of group-wise interactions. To decode the comprehensive pair-wise and
group-wise interactions in crowded scenarios, we introduce Hyper-STTN, a
Hypergraph-based Spatial-Temporal Transformer Network for crowd trajectory
prediction. In Hyper-STTN, crowded group-wise correlations are constructed
using a set of multi-scale hypergraphs with varying group sizes, captured
through random-walk robability-based hypergraph spectral convolution.
Additionally, a spatial-temporal transformer is adapted to capture pedestrians'
pair-wise latent interactions in spatial-temporal dimensions. These
heterogeneous group-wise and pair-wise are then fused and aligned though a
multimodal transformer network. Hyper-STTN outperformes other state-of-the-art
baselines and ablation models on 5 real-world pedestrian motion datasets.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06345" title="Abstract">arXiv:2401.06345</a> [<a href="/pdf/2401.06345" title="Download PDF">pdf</a>, <a href="/format/2401.06345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seek for Incantations: Towards Accurate Text-to-Image Diffusion  Synthesis through Prompt Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Junran Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The text-to-image synthesis by diffusion models has recently shown remarkable
performance in generating high-quality images. Although performs well for
simple texts, the models may get confused when faced with complex texts that
contain multiple objects or spatial relationships. To get the desired images, a
feasible way is to manually adjust the textual descriptions, i.e., narrating
the texts or adding some words, which is labor-consuming. In this paper, we
propose a framework to learn the proper textual descriptions for diffusion
models through prompt learning. By utilizing the quality guidance and the
semantic guidance derived from the pre-trained diffusion model, our method can
effectively learn the prompts to improve the matches between the input text and
the generated images. Extensive experiments and analyses have validated the
effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06354" title="Abstract">arXiv:2401.06354</a> [<a href="/pdf/2401.06354" title="Download PDF">pdf</a>, <a href="/format/2401.06354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Initial Analysis of Data-Driven Haptic Search for the Smart Suction Cup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungpyo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+D">Sebastian D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Huh%2C+T+M">Tae Myung Huh</a>, 
<a href="/search/cs?searchtype=author&query=Stuart%2C+H+S">Hannah S. Stuart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Suction cups offer a useful gripping solution, particularly in industrial
robotics and warehouse applications. Vision-based grasp algorithms, like
Dex-Net, show promise but struggle to accurately perceive dark or reflective
objects, sub-resolution features, and occlusions, resulting in suction cup grip
failures. In our prior work, we designed the Smart Suction Cup, which estimates
the flow state within the cup and provides a mechanically resilient
end-effector that can inform arm feedback control through a sense of touch. We
then demonstrated how this cup's signals enable haptically-driven search
behaviors for better grasping points on adversarial objects. This prior work
uses a model-based approach to predict the desired motion direction, which
opens up the question: does a data-driven approach perform better? This
technical report provides an initial analysis harnessing the data previously
collected. Specifically, we compare the model-based method with a preliminary
data-driven approach to accurately estimate lateral pose adjustment direction
for improved grasp success.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06356" title="Abstract">arXiv:2401.06356</a> [<a href="/pdf/2401.06356" title="Download PDF">pdf</a>, <a href="/format/2401.06356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Investigation into the Effect of Parameter Choices in  Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sultan%2C+M+A">Md Arafat Sultan</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A">Aashka Trivedi</a>, 
<a href="/search/cs?searchtype=author&query=Awasthy%2C+P">Parul Awasthy</a>, 
<a href="/search/cs?searchtype=author&query=Sil%2C+A">Avirup Sil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present a large-scale empirical study of how choices of configuration
parameters affect performance in knowledge distillation (KD). An example of
such a KD parameter is the measure of distance between the predictions of the
teacher and the student, common choices for which include the mean squared
error (MSE) and the KL-divergence. Although scattered efforts have been made to
understand the differences between such options, the KD literature still lacks
a systematic study on their general effect on student performance. We take an
empirical approach to this question in this paper, seeking to find out the
extent to which such choices influence student performance across 13 datasets
from 4 NLP tasks and 3 student sizes. We quantify the cost of making
sub-optimal choices and identify a single configuration that performs well
across the board.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06361" title="Abstract">arXiv:2401.06361</a> [<a href="/pdf/2401.06361" title="Download PDF">pdf</a>, <a href="/format/2401.06361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visions Of Destruction: Exploring Human Impact on Nature by Navigating  the Latent Space of a Diffusion Model via Gaze
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sola%2C+M+C">Mar Canet Sola</a>, 
<a href="/search/cs?searchtype=author&query=Guljajeva%2C+V">Varvara Guljajeva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This paper discusses the artwork "Visions of Destruction", with a primary
conceptual focus on the Anthropocene, which is communicated through audience
interaction and generative AI as artistic research methods. Gaze-based
interaction transitions the audience from mere observers to agents of landscape
transformation, fostering a profound, on-the-edge engagement with pressing
issues such as climate change and planetary destruction. The paper looks into
early references of interactive art history that deploy eye-tracking as a
method for audience interaction, and presents recent AI-aided artworks that
demonstrate interactive latent space navigation.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06362" title="Abstract">arXiv:2401.06362</a> [<a href="/pdf/2401.06362" title="Download PDF">pdf</a>, <a href="/format/2401.06362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention, Distillation, and Tabularization: Towards Practical Neural  Network-Based Prefetching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengmiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Neelesh Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+R">Rajgopal Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+V+K">Viktor K. Prasanna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG); Operating Systems (cs.OS)

</div>
<p class="mathjax">Attention-based Neural Networks (NN) have demonstrated their effectiveness in
accurate memory access prediction, an essential step in data prefetching.
However, the substantial computational overheads associated with these models
result in high inference latency, limiting their feasibility as practical
prefetchers. To close the gap, we propose a new approach based on
tabularization that significantly reduces model complexity and inference
latency without sacrificing prediction accuracy. Our novel tabularization
methodology takes as input a distilled, yet highly accurate attention-based
model for memory access prediction and efficiently converts its expensive
matrix multiplications into a hierarchy of fast table lookups. As an exemplar
of the above approach, we develop DART, a prefetcher comprised of a simple
hierarchy of tables. With a modest 0.09 drop in F1-score, DART reduces 99.99%
of arithmetic operations from the large attention-based model and 91.83% from
the distilled model. DART accelerates the large model inference by 170x and the
distilled model by 9.4x. DART has comparable latency and storage costs as
state-of-the-art rule-based prefetcher BO but surpasses it by 6.1% in IPC
improvement, resulting in a 37.6% speed-up. DART outperforms state-of-the-art
NN-based prefetchers TransFetch by 33.1% and Voyager by 37.2% in terms of IPC
improvement, primarily due to its low prefetching latency.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06366" title="Abstract">arXiv:2401.06366</a> [<a href="/pdf/2401.06366" title="Download PDF">pdf</a>, <a href="/ps/2401.06366" title="Download PostScript">ps</a>, <a href="/format/2401.06366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Anatomy and Real-Time Measurement of Nvidia GeForce NOW Cloud  Gaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M">Minzhao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Madanapalli%2C+S+C">Sharat Chandra Madanapalli</a>, 
<a href="/search/cs?searchtype=author&query=Vishwanath%2C+A">Arun Vishwanath</a>, 
<a href="/search/cs?searchtype=author&query=Sivaraman%2C+V">Vijay Sivaraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted at Passive and Active Measurement (PAM) conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Cloud gaming, wherein game graphics is rendered in the cloud and streamed
back to the user as real-time video, expands the gaming market to billions of
users who do not have gaming consoles or high-power graphics PCs. Companies
like Nvidia, Amazon, Sony and Microsoft are investing in building cloud gaming
platforms to tap this large unserved market. However, cloud gaming requires the
user to have high bandwidth and stable network connectivity - whereas a typical
console game needs about 100-200 kbps, a cloud game demands minimum 10-20 Mbps.
This makes the Internet Service Provider (ISP) a key player in ensuring the
end-user's good gaming experience. In this paper we develop a method to detect
user experience to detect Nvidia's GeForce NOW cloud gaming sessions over their
network infrastructure, and measure associated user experience. In particular,
we envision ISPs taking advantage of our method to provision network capacity
at the right time and in the right place to support growth in cloud gaming at
the right experience level; as well as identify the role of contextual factors
such as user setup (browser vs app) and connectivity type (wired vs wireless)
in performance degradation. We first present a detailed anatomy of flow
establishment and volumetric profiles of cloud gaming sessions over multiple
platforms, followed by a method to detect gameplay and measure key experience
aspects such as latency, frame rate and resolution via real-time analysis of
network traffic. The insights and methods are also validated in the lab for
XBox Cloud Gaming platform. We then implement and deploy our method in a campus
network to capture gameplay behaviors and experience measures across various
user setups and connectivity types which we believe are valuable for network
operators.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06370" title="Abstract">arXiv:2401.06370</a> [<a href="/pdf/2401.06370" title="Download PDF">pdf</a>, <a href="/format/2401.06370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Relation Distillation for Efficient Biomedical Instance  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yueyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Feng Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Instance-aware embeddings predicted by deep neural networks have
revolutionized biomedical instance segmentation, but its resource requirements
are substantial. Knowledge distillation offers a solution by transferring
distilled knowledge from heavy teacher networks to lightweight yet
high-performance student networks. However, existing knowledge distillation
methods struggle to extract knowledge for distinguishing instances and overlook
global relation information. To address these challenges, we propose a graph
relation distillation approach for efficient biomedical instance segmentation,
which considers three essential types of knowledge: instance-level features,
instance relations, and pixel-level boundaries. We introduce two graph
distillation schemes deployed at both the intra-image level and the inter-image
level: instance graph distillation (IGD) and affinity graph distillation (AGD).
IGD constructs a graph representing instance features and relations,
transferring these two types of knowledge by enforcing instance graph
consistency. AGD constructs an affinity graph representing pixel relations to
capture structured knowledge of instance boundaries, transferring
boundary-related knowledge by ensuring pixel affinity consistency. Experimental
results on a number of biomedical datasets validate the effectiveness of our
approach, enabling student models with less than $ 1\%$ parameters and less
than $10\%$ inference time while achieving promising performance compared to
teacher models.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06373" title="Abstract">arXiv:2401.06373</a> [<a href="/pdf/2401.06373" title="Download PDF">pdf</a>, <a href="/format/2401.06373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to  Challenge AI Safety by Humanizing LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongpeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruoxi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weiyan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages of the main text, qualitative examples of jailbreaks may be harmful in nature
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Most traditional AI safety research has approached AI models as machines and
centered on algorithm-focused attacks developed by security experts. As large
language models (LLMs) become increasingly common and competent, non-expert
users can also impose risks during daily interactions. This paper introduces a
new perspective to jailbreak LLMs as human-like communicators, to explore this
overlooked intersection between everyday language interaction and AI safety.
Specifically, we study how to persuade LLMs to jailbreak them. First, we
propose a persuasion taxonomy derived from decades of social science research.
Then, we apply the taxonomy to automatically generate interpretable persuasive
adversarial prompts (PAP) to jailbreak LLMs. Results show that persuasion
significantly increases the jailbreak performance across all risk categories:
PAP consistently achieves an attack success rate of over $92\%$ on Llama 2-7b
Chat, GPT-3.5, and GPT-4 in $10$ trials, surpassing recent algorithm-focused
attacks. On the defense side, we explore various mechanisms against PAP and,
found a significant gap in existing defenses, and advocate for more fundamental
mitigation for highly interactive LLMs
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06374" title="Abstract">arXiv:2401.06374</a> [<a href="/pdf/2401.06374" title="Download PDF">pdf</a>, <a href="/format/2401.06374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SamLP: A Customized Segment Anything Model for License Plate Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Haoxuan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the emergence of foundation model, this novel paradigm of deep learning
has encouraged many powerful achievements in natural language processing and
computer vision. There are many advantages of foundation model, such as
excellent feature extraction power, mighty generalization ability, great
few-shot and zero-shot learning capacity, etc. which are beneficial to vision
tasks. As the unique identity of vehicle, different countries and regions have
diverse license plate (LP) styles and appearances, and even different types of
vehicles have different LPs. However, recent deep learning based license plate
detectors are mainly trained on specific datasets, and these limited datasets
constrain the effectiveness and robustness of LP detectors. To alleviate the
negative impact of limited data, an attempt to exploit the advantages of
foundation model is implement in this paper. We customize a vision foundation
model, i.e. Segment Anything Model (SAM), for LP detection task and propose the
first LP detector based on vision foundation model, named SamLP. Specifically,
we design a Low-Rank Adaptation (LoRA) fine-tuning strategy to inject extra
parameters into SAM and transfer SAM into LP detection task. And then, we
further propose a promptable fine-tuning step to provide SamLP with prompatable
segmentation capacity. The experiments show that our proposed SamLP achieves
promising detection performance compared to other LP detectors. Meanwhile, the
proposed SamLP has great few-shot and zero-shot learning ability, which shows
the potential of transferring vision foundation model. The code is available at
https://github.com/Dinghaoxuan/SamLP
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06375" title="Abstract">arXiv:2401.06375</a> [<a href="/pdf/2401.06375" title="Download PDF">pdf</a>, <a href="/ps/2401.06375" title="Download PostScript">ps</a>, <a href="/format/2401.06375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognitive BPM as an Equalizer: Improving Access and Efficiency for  Employees with (and without) Cognitive Disabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banks%2C+G">Gordon Banks</a>, 
<a href="/search/cs?searchtype=author&query=Bierhuizen%2C+G">Gates Bierhuizen</a>, 
<a href="/search/cs?searchtype=author&query=McCrum%2C+K">Katherine McCrum</a>, 
<a href="/search/cs?searchtype=author&query=Wengert%2C+E">Ellen Wengert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We examine ProcessGPT, an AI model designed to automate, augment, and improve
business processes, to study the challenges of managing business processes
within the cognitive limitations of the human workforce, particularly
individuals with cognitive disabilities. ProcessGPT provides a blueprint for
designing efficient business processes that take into account human cognitive
limitations. By viewing this through the lens of cognitive disabilities, we
show that ProcessGPT improves process usability for individuals with and
without cognitive disabilities. We also demonstrate that organizations
implementing ProcessGPT-like capabilities will realize increased productivity,
morale, and inclusion.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06377" title="Abstract">arXiv:2401.06377</a> [<a href="/pdf/2401.06377" title="Download PDF">pdf</a>, <a href="/format/2401.06377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Nonlinear Modeling of a Modular Cable Driven Soft Robotic Arm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xinda Qi</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yu Mei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaojian Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xiaobo Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE for possible publications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We propose a novel multi-section cable-driven soft robotic arm inspired by
octopus tentacles along with a new modeling approach. Each section of the
modular manipulator is made of a soft tubing backbone, a soft silicon arm body,
and two rigid endcaps, which connect adjacent sections and decouple the
actuation cables of different sections. The soft robotic arm is made with
casting after the rigid endcaps are 3D-printed, achieving low-cost and
convenient fabrication. To capture the nonlinear effect of cables pushing into
the soft silicon arm body, which results from the absence of intermediate rigid
cable guides for higher compliance, an analytical static model is developed to
capture the relationship between the bending curvature and the cable lengths.
The proposed model shows superior prediction performance in experiments over
that of a baseline model, especially under large bending conditions. Based on
the nonlinear static model, a kinematic model of a multi-section arm is further
developed and used to derive a motion planning algorithm. Experiments show that
the proposed soft arm has high flexibility and a large workspace, and the
tracking errors under the algorithm based on the proposed modeling approach are
up to 52$\%$ smaller than those with the algorithm derived from the baseline
model. The presented modeling approach is expected to be applicable to a broad
range of soft cable-driven actuators and manipulators.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06378" title="Abstract">arXiv:2401.06378</a> [<a href="/pdf/2401.06378" title="Download PDF">pdf</a>, <a href="/ps/2401.06378" title="Download PostScript">ps</a>, <a href="/format/2401.06378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Lower Bounds in Merlin-Arthur Communication and Graph Streaming  Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+P">Prantar Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+V">Vihan Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We show new lower bounds in the \emph{Merlin-Arthur} (MA) communication model
and the related \emph{annotated streaming} or stream verification model. The MA
communication model is an enhancement of the classical communication model,
where in addition to the usual players Alice and Bob, there is an all-powerful
but untrusted player Merlin who knows their inputs and tries to convince them
about the output. Most functions have MA protocols with total communication
significantly smaller than what would be needed without Merlin. We focus on the
online MA (OMA) model, which is the MA analogue of one-way communication, and
introduce the notion of \emph{non-trivial-OMA} complexity of a function. This
is the minimum total communication needed by any non-trivial OMA protocol
computing that function, where a trivial OMA protocol is one where Alice sends
Bob roughly as many bits as she would have sent without Merlin. We prove a
lower bound on the non-trivial-OMA complexity of a natural function
\emph{Equals-Index} (basically the well-known Index problem on large domains)
and identify it as a canonical problem for proving strong lower bounds on this
complexity: reductions from it (i) reproduce and/or improve upon the lower
bounds for all functions that were previously known to have large
non-trivial-OMA complexity, (ii) exhibit the first explicit functions whose
non-trivial-OMA complexity is superlinear, and even exponential, in their
classical one-way complexity, and (iii) show functions on input size $n$ for
which this complexity is as large as $n/\log n$. While exhibiting a function
with $\omega(\sqrt{n})$ (standard) OMA complexity is a longstanding open
problem, we did not even know of any function with $\omega(\sqrt{n})$
non-trivial-OMA complexity. We further extend the lower bounds to a related
streaming model called annotated streaming.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06379" title="Abstract">arXiv:2401.06379</a> [<a href="/pdf/2401.06379" title="Download PDF">pdf</a>, <a href="/format/2401.06379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicle: Bridging the Embedding Gap in the Verification of  Neuro-Symbolic Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daggitt%2C+M+L">Matthew L. Daggitt</a>, 
<a href="/search/cs?searchtype=author&query=Kokke%2C+W">Wen Kokke</a>, 
<a href="/search/cs?searchtype=author&query=Atkey%2C+R">Robert Atkey</a>, 
<a href="/search/cs?searchtype=author&query=Slusarz%2C+N">Natalia Slusarz</a>, 
<a href="/search/cs?searchtype=author&query=Arnaboldi%2C+L">Luca Arnaboldi</a>, 
<a href="/search/cs?searchtype=author&query=Komendantskaya%2C+E">Ekaterina Komendantskaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Neuro-symbolic programs -- programs containing both machine learning
components and traditional symbolic code -- are becoming increasingly
widespread. However, we believe that there is still a lack of a general
methodology for verifying these programs whose correctness depends on the
behaviour of the machine learning components. In this paper, we identify the
``embedding gap'' -- the lack of techniques for linking semantically-meaningful
``problem-space'' properties to equivalent ``embedding-space'' properties -- as
one of the key issues, and describe Vehicle, a tool designed to facilitate the
end-to-end verification of neural-symbolic programs in a modular fashion.
Vehicle provides a convenient language for specifying ``problem-space''
properties of neural networks and declaring their relationship to the
``embedding-space", and a powerful compiler that automates interpretation of
these properties in the language of a chosen machine-learning training
environment, neural network verifier, and interactive theorem prover. We
demonstrate Vehicle's utility by using it to formally verify the safety of a
simple autonomous car equipped with a neural network controller.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06382" title="Abstract">arXiv:2401.06382</a> [<a href="/pdf/2401.06382" title="Download PDF">pdf</a>, <a href="/ps/2401.06382" title="Download PostScript">ps</a>, <a href="/format/2401.06382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What should I say? -- Interacting with AI and Natural Language  Interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adkins%2C+M">Mark Adkins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 12 figures, 12 data tables, study data included in appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">As Artificial Intelligence (AI) technology becomes more and more prevalent,
it becomes increasingly important to explore how we as humans interact with AI.
The Human-AI Interaction (HAI) sub-field has emerged from the Human-Computer
Interaction (HCI) field and aims to examine this very notion. Many interaction
patterns have been implemented without fully understanding the changes in
required cognition as well as the cognitive science implications of using these
alternative interfaces that aim to be more human-like in nature. Prior research
suggests that theory of mind representations are crucial to successful and
effortless communication, however very little is understood when it comes to
how theory of mind representations are established when interacting with AI.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06384" title="Abstract">arXiv:2401.06384</a> [<a href="/pdf/2401.06384" title="Download PDF">pdf</a>, <a href="/format/2401.06384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Targeted Message Dissemination in IoT Using Blockchain Enabled  Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mollah%2C+M+B">Muhammad Baqer Mollah</a>, 
<a href="/search/cs?searchtype=author&query=Azad%2C+M+A+K">Md Abul Kalam Azad</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinghui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Smart devices are considered as an integral part of Internet of Things (IoT),
have an aim to make a dynamic network to exchange information, collect data,
analysis, and make optimal decisions in an autonomous way to achieve more
efficient, automatic, and economical services. Message dissemination among
these smart devices allows adding new features, sending updated instructions,
alerts or safety messages, informing the pricing information or billing amount,
incentives, and installing security patches. On one hand, such message
disseminations are directly beneficial to the all parties involved in the IoT
system. On the other hand, due to remote procedure, smart devices, vendors, and
other involved authorities might have to meet a number of security, privacy,
and performance related concerns while disseminating messages among targeted
devices. To this end, in this paper, we design STarEdgeChain, a security and
privacy aware targeted message dissemination in IoT to show how blockchain
along with advanced cryptographic techniques are devoted to address such
concerns. In fact, the STarEdgeChain employs a permissioned blockchain assisted
edge computing in order to expedite a single signcrypted message dissemination
among targeted groups of devices, at the same time avoiding the dependency of
utilizing multiple unicasting approaches. Finally, we develop a software
prototype of STarEdgeChain and show it's practicability for smart devices. The
codes are publicly available at https://github.com/mbaqer/Blockchain-IoT
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06385" title="Abstract">arXiv:2401.06385</a> [<a href="/pdf/2401.06385" title="Download PDF">pdf</a>, <a href="/format/2401.06385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SD-MVS: Segmentation-Driven Deformation Multi-View Stereo with Spherical  Refinement and EM optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhenlong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiakai Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaoxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, published to AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce Segmentation-Driven Deformation Multi-View Stereo
(SD-MVS), a method that can effectively tackle challenges in 3D reconstruction
of textureless areas. We are the first to adopt the Segment Anything Model
(SAM) to distinguish semantic instances in scenes and further leverage these
constraints for pixelwise patch deformation on both matching cost and
propagation. Concurrently, we propose a unique refinement strategy that
combines spherical coordinates and gradient descent on normals and pixelwise
search interval on depths, significantly improving the completeness of
reconstructed 3D model. Furthermore, we adopt the Expectation-Maximization (EM)
algorithm to alternately optimize the aggregate matching cost and
hyperparameters, effectively mitigating the problem of parameters being
excessively dependent on empirical tuning. Evaluations on the ETH3D
high-resolution multi-view stereo benchmark and the Tanks and Temples dataset
demonstrate that our method can achieve state-of-the-art results with less time
consumption.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06386" title="Abstract">arXiv:2401.06386</a> [<a href="/pdf/2401.06386" title="Download PDF">pdf</a>, <a href="/format/2401.06386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI-enabled Mobile Tactical Multimedia Networks: Distribution,  Generation, and Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minrui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuguang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+I">Dong In Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Mobile multimedia networks (MMNs) demonstrate great potential in delivering
low-latency and high-quality entertainment and tactical applications, such as
short-video sharing, online conferencing, and battlefield surveillance. For
instance, in tactical surveillance of battlefields, scalability and
sustainability are indispensable for maintaining large-scale military
multimedia applications in MMNs. Therefore, many data-driven networking
solutions are leveraged to optimize streaming strategies based on real-time
traffic analysis and resource monitoring. In addition, generative AI (GAI) can
not only increase the efficiency of existing data-driven solutions through data
augmentation but also develop potential capabilities for MMNs, including
AI-generated content (AIGC) and AI-aided perception. In this article, we
propose the framework of GAI-enabled MMNs that leverage the capabilities of GAI
in data and content synthesis to distribute high-quality and immersive
interactive content in wireless networks. Specifically, we outline the
framework of GAI-enabled MMNs and then introduce its three main features,
including distribution, generation, and perception. Furthermore, we propose a
second-score auction mechanism for allocating network resources by considering
GAI model values and other metrics jointly. The experimental results show that
the proposed auction mechanism can effectively increase social welfare by
allocating resources and models with the highest user satisfaction.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06390" title="Abstract">arXiv:2401.06390</a> [<a href="/pdf/2401.06390" title="Download PDF">pdf</a>, <a href="/format/2401.06390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LCB-net: Long-Context Biasing for Audio-Visual Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASPP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The growing prevalence of online conferences and courses presents a new
challenge in improving automatic speech recognition (ASR) with enriched textual
information from video slides. In contrast to rare phrase lists, the slides
within videos are synchronized in real-time with the speech, enabling the
extraction of long contextual bias. Therefore, we propose a novel long-context
biasing network (LCB-net) for audio-visual speech recognition (AVSR) to
leverage the long-context information available in videos effectively.
Specifically, we adopt a bi-encoder architecture to simultaneously model audio
and long-context biasing. Besides, we also propose a biasing prediction module
that utilizes binary cross entropy (BCE) loss to explicitly determine biased
phrases in the long-context biasing. Furthermore, we introduce a dynamic
contextual phrases simulation to enhance the generalization and robustness of
our LCB-net. Experiments on the SlideSpeech, a large-scale audio-visual corpus
enriched with slides, reveal that our proposed LCB-net outperforms general ASR
model by 9.4%/9.1%/10.9% relative WER/U-WER/B-WER reduction on test set, which
enjoys high unbiased and biased performance. Moreover, we also evaluate our
model on LibriSpeech corpus, leading to 23.8%/19.2%/35.4% relative
WER/U-WER/B-WER reduction over the ASR model.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06391" title="Abstract">arXiv:2401.06391</a> [<a href="/pdf/2401.06391" title="Download PDF">pdf</a>, <a href="/format/2401.06391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yebo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weisong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xin Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Recent code large language models (LLMs) have shown promising performance in
generating standalone functions but face limitations in repository-level code
generation due to their lack of awareness of repository-level dependencies
(e.g., user-defined attributes), resulting in dependency errors such as
undefined-variable and no-member errors. In this work, we introduce ToolGen, an
approach that integrates autocompletion tools into the code LLM generation
process to address these dependencies. ToolGen comprises two main phases: Data
Augmentation and Model Fine-tuning (Offline), and Tool-integrated Code
Generation (Online). During the offline phase, ToolGen augments functions
within a given code corpus with a special mark token, indicating positions to
trigger autocompletion tools. These augmented functions, along with their
corresponding docstrings, are then used to fine-tune a selected code LLM. In
the online phase, ToolGen iteratively generates functions by predicting tokens
step-by-step using the fine-tuned LLM. Whenever a mark token is encountered,
ToolGen invokes the autocompletion tool to suggest code completions and selects
the most appropriate one.
<br />We conduct comprehensive experiments to evaluate ToolGen's effectiveness in
repository-level code generation. To facilitate this evaluation, we create a
benchmark comprising 680 real-world code repositories and introduce two new
repository-level metrics: Dependency Coverage and Success Rate. The results
demonstrate that ToolGen significantly improves dependency coverage by 15.2% to
45.8% and success rates by 10.9% to 42.2% across three distinct code LLMs,
while maintaining competitive performance in widely-recognized similarity
metrics. Furthermore, our generalizability evaluation confirms ToolGen's
consistent performance when applied to diverse code LLMs, including various
model architectures and scales.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06394" title="Abstract">arXiv:2401.06394</a> [<a href="/pdf/2401.06394" title="Download PDF">pdf</a>, <a href="/format/2401.06394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Data Augmentation for Aspect Sentiment Quad Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinghua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shiyao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuebin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tingwen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024, 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aspect sentiment quad prediction (ASQP) aims to predict the quad sentiment
elements for a given sentence, which is a critical task in the field of
aspect-based sentiment analysis. However, the data imbalance issue has not
received sufficient attention in ASQP task. In this paper, we divide the issue
into two-folds, quad-pattern imbalance and aspect-category imbalance, and
propose an Adaptive Data Augmentation (ADA) framework to tackle the imbalance
issue. Specifically, a data augmentation process with a condition function
adaptively enhances the tail quad patterns and aspect categories, alleviating
the data imbalance in ASQP. Following previous studies, we also further explore
the generative framework for extracting complete quads by introducing the
category prior knowledge and syntax-guided decoding target. Experimental
results demonstrate that data augmentation for imbalance in ASQP task can
improve the performance, and the proposed ADA method is superior to naive data
oversampling.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06395" title="Abstract">arXiv:2401.06395</a> [<a href="/pdf/2401.06395" title="Download PDF">pdf</a>, <a href="/format/2401.06395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ModaVerse: Efficiently Transforming Modalities with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+B">Bohan Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Humans possess the capability to comprehend diverse modalities and seamlessly
transfer information between them. In this work, we introduce ModaVerse, a
Multi-modal Large Language Model (MLLM) capable of comprehending and
transforming content across various modalities including images, videos, and
audio. Predominant MLLM frameworks have largely relied on the alignment of
latent spaces of textual and non-textual features. This alignment process,
which synchronizes a language model trained on textual data with encoders and
decoders trained on multi-modal data, often necessitates extensive training of
several projection layers in multiple stages. Inspired by LLM-as-agent
methodologies, we propose a novel Input/Output (I/O) alignment mechanism that
operates directly at the level of natural language. It aligns the LLM's output
with the input of generative models, avoiding the complexities associated with
latent feature alignments, and simplifying the multiple training stages of
existing MLLMs into a single, efficient process. This conceptual advancement
leads to significant reductions in both data and computational costs. By
conducting experiments on several benchmarks, we demonstrate that our approach
attains comparable performance with the state of the art while achieving
considerable efficiencies in data usage and training duration.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06397" title="Abstract">arXiv:2401.06397</a> [<a href="/pdf/2401.06397" title="Download PDF">pdf</a>, <a href="/format/2401.06397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UMG-CLIP: A Unified Multi-Granularity Vision Generalist for Open-World  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bowen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peisen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenrui Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Junni Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hongkai Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-language foundation models, represented by Contrastive language-image
pre-training (CLIP), have gained increasing attention for jointly understanding
both vision and textual tasks. However, existing approaches primarily focus on
training models to match global image representations with textual
descriptions, thereby overlooking the critical alignment between local regions
and corresponding text tokens. This paper extends CLIP with multi-granularity
alignment. Notably, we deliberately construct a new dataset comprising pseudo
annotations at various levels of granularities, encompassing image-level,
region-level, and pixel-level captions/tags. Accordingly, we develop a unified
multi-granularity learning framework, named UMG-CLIP, that simultaneously
empowers the model with versatile perception abilities across different levels
of detail. Equipped with parameter efficient tuning, UMG-CLIP surpasses current
widely used CLIP models and achieves state-of-the-art performance on diverse
image understanding benchmarks, including open-world recognition, retrieval,
semantic segmentation, and panoptic segmentation tasks. We hope UMG-CLIP can
serve as a valuable option for advancing vision-language foundation models.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06398" title="Abstract">arXiv:2401.06398</a> [<a href="/pdf/2401.06398" title="Download PDF">pdf</a>, <a href="/ps/2401.06398" title="Download PostScript">ps</a>, <a href="/format/2401.06398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An approach for mistranslation removal from popular dataset for Indic MT  Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+S+B">Sudhansu Bala Das</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+L+R">Leo Raphael Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+T+K">Tapas Kumar Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Patra%2C+B+K">Bidyut Kr. Patra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The conversion of content from one language to another utilizing a computer
system is known as Machine Translation (MT). Various techniques have come up to
ensure effective translations that retain the contextual and lexical
interpretation of the source language. End-to-end Neural Machine Translation
(NMT) is a popular technique and it is now widely used in real-world MT
systems. Massive amounts of parallel datasets (sentences in one language
alongside translations in another) are required for MT systems. These datasets
are crucial for an MT system to learn linguistic structures and patterns of
both languages during the training phase. One such dataset is Samanantar, the
largest publicly accessible parallel dataset for Indian languages (ILs). Since
the corpus has been gathered from various sources, it contains many incorrect
translations. Hence, the MT systems built using this dataset cannot perform to
their usual potential. In this paper, we propose an algorithm to remove
mistranslations from the training corpus and evaluate its performance and
efficiency. Two Indic languages (ILs), namely, Hindi (HIN) and Odia (ODI) are
chosen for the experiment. A baseline NMT system is built for these two ILs,
and the effect of different dataset sizes is also investigated. The quality of
the translations in the experiment is evaluated using standard metrics such as
BLEU, METEOR, and RIBES. From the results, it is observed that removing the
incorrect translation from the dataset makes the translation quality better. It
is also noticed that, despite the fact that the ILs-English and English-ILs
systems are trained using the same corpus, ILs-English works more effectively
across all the evaluation metrics.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06400" title="Abstract">arXiv:2401.06400</a> [<a href="/pdf/2401.06400" title="Download PDF">pdf</a>, <a href="/format/2401.06400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Visual Question Answering from Synthetic to Human-Written  Questions via a Chain of QA with a Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Yeongjae Cho</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+H">Heejun Shin</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+Y">Yohan Jo</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+D">Dongmyung Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Visual question answering (VQA) is a task where an image is given, and a
series of questions are asked about the image. To build an efficient VQA
algorithm, a large amount of QA data is required which is very expensive.
Generating synthetic QA pairs based on templates is a practical way to obtain
data. However, VQA models trained on those data do not perform well on complex,
human-written questions. To address this issue, we propose a new method called
{\it chain of QA for human-written questions} (CoQAH). CoQAH utilizes a
sequence of QA interactions between a large language model and a VQA model
trained on synthetic data to reason and derive logical answers for
human-written questions. We tested the effectiveness of CoQAH on two types of
human-written VQA datasets for 3D-rendered and chest X-ray images and found
that it achieved state-of-the-art accuracy in both types of data. Notably,
CoQAH outperformed general vision-language models, VQA models, and medical
foundation models with no finetuning.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06401" title="Abstract">arXiv:2401.06401</a> [<a href="/pdf/2401.06401" title="Download PDF">pdf</a>, <a href="/format/2401.06401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DevEval: Evaluating Code Generation in Practical Software Projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunfei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongmin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huanyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kaibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lecheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lanshen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jiazheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yihong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Bin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mengfei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version. Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">How to evaluate Large Language Models (LLMs) in code generation is an open
question. Many benchmarks have been proposed but are inconsistent with
practical software projects, e.g., unreal program distributions, insufficient
dependencies, and small-scale project contexts. Thus, the capabilities of LLMs
in practical projects are still unclear. In this paper, we propose a new
benchmark named DevEval, aligned with Developers' experiences in practical
projects. DevEval is collected through a rigorous pipeline, containing 2,690
samples from 119 practical projects and covering 10 domains. Compared to
previous benchmarks, DevEval aligns to practical projects in multiple
dimensions, e.g., real program distributions, sufficient dependencies, and
enough-scale project contexts. We assess five popular LLMs on DevEval (e.g.,
gpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual
abilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo
only is 42 in our experiments. We also discuss the challenges and future
directions of code generation in practical projects. We open-source DevEval and
hope it can facilitate the development of code generation in practical
projects.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06405" title="Abstract">arXiv:2401.06405</a> [<a href="/pdf/2401.06405" title="Download PDF">pdf</a>, <a href="/ps/2401.06405" title="Download PostScript">ps</a>, <a href="/format/2401.06405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing the integer points in 2-decomposable polyhedra by  closedness under operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kimura%2C+K">Kei Kimura</a>, 
<a href="/search/cs?searchtype=author&query=Makino%2C+K">Kazuhisa Makino</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+S">Shota Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Yoshizumi%2C+R">Ryo Yoshizumi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Characterizing the solution sets in a problem by closedness under operations
is recognized as one of the key aspects of algorithm development, especially in
constraint satisfaction. An example from the Boolean satisfiability problem is
that the solution set of a Horn conjunctive normal form (CNF) is closed under
the minimum operation, and this property implies that minimizing a nonnegative
linear function over a Horn CNF can be done in polynomial time. In this paper,
we focus on the set of integer points (vectors) in a polyhedron, and study the
relation between these sets and closedness under operations from the viewpoint
of 2-decomposability. By adding further conditions to the 2-decomposable
polyhedra, we show that important classes of sets of integer vectors in
polyhedra are characterized by 2-decomposability and closedness under certain
operations, and in some classes, by closedness under operations alone. The most
prominent result we show is that the set of integer vectors in a
unit-two-variable-per-inequality polyhedron can be characterized by closedness
under the median and directed discrete midpoint operations, each of these
operations was independently considered in constraint satisfaction and discrete
convex analysis.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06406" title="Abstract">arXiv:2401.06406</a> [<a href="/pdf/2401.06406" title="Download PDF">pdf</a>, <a href="/ps/2401.06406" title="Download PostScript">ps</a>, <a href="/format/2401.06406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Informed Machine Learning for Cancer Diagnosis and Prognosis:  A review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+L">Lingchao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hairong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L+S">Leland S. Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+N+L">Nhan L Tran</a>, 
<a href="/search/cs?searchtype=author&query=Canoll%2C+P+D">Peter D Canoll</a>, 
<a href="/search/cs?searchtype=author&query=Swanson%2C+K+R">Kristin R Swanson</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cancer remains one of the most challenging diseases to treat in the medical
field. Machine learning has enabled in-depth analysis of rich multi-omics
profiles and medical imaging for cancer diagnosis and prognosis. Despite these
advancements, machine learning models face challenges stemming from limited
labeled sample sizes, the intricate interplay of high-dimensionality data
types, the inherent heterogeneity observed among patients and within tumors,
and concerns about interpretability and consistency with existing biomedical
knowledge. One approach to surmount these challenges is to integrate biomedical
knowledge into data-driven models, which has proven potential to improve the
accuracy, robustness, and interpretability of model results. Here, we review
the state-of-the-art machine learning studies that adopted the fusion of
biomedical knowledge and data, termed knowledge-informed machine learning, for
cancer diagnosis and prognosis. Emphasizing the properties inherent in four
primary data types including clinical, imaging, molecular, and treatment data,
we highlight modeling considerations relevant to these contexts. We provide an
overview of diverse forms of knowledge representation and current strategies of
knowledge integration into machine learning pipelines with concrete examples.
We conclude the review article by discussing future directions to advance
cancer research through knowledge-informed machine learning.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06407" title="Abstract">arXiv:2401.06407</a> [<a href="/pdf/2401.06407" title="Download PDF">pdf</a>, <a href="/format/2401.06407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UAV-borne Mapping Algorithms for Canopy-Level and High-Speed Drone  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jincheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wolek%2C+A">Artur Wolek</a>, 
<a href="/search/cs?searchtype=author&query=Willis%2C+A+R">Andrew R. Willis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This article presents a comprehensive review of and analysis of
state-of-the-art mapping algorithms for UAV (Unmanned Aerial Vehicle)
applications, focusing on canopy-level and high-speed scenarios. This article
presents a comprehensive exploration of sensor technologies suitable for UAV
mapping, assessing their capabilities to provide measurements that meet the
requirements of fast UAV mapping. Furthermore, the study conducts extensive
experiments in a simulated environment to evaluate the performance of three
distinct mapping algorithms: Direct Sparse Odometry (DSO), Stereo DSO (SDSO),
and DSO Lite (DSOL). The experiments delve into mapping accuracy and mapping
speed, providing valuable insights into the strengths and limitations of each
algorithm. The results highlight the versatility and shortcomings of these
algorithms in meeting the demands of modern UAV applications. The findings
contribute to a nuanced understanding of UAV mapping dynamics, emphasizing
their applicability in complex environments and high-speed scenarios. This
research not only serves as a benchmark for mapping algorithm comparisons but
also offers practical guidance for selecting sensors tailored to specific UAV
mapping applications.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06408" title="Abstract">arXiv:2401.06408</a> [<a href="/pdf/2401.06408" title="Download PDF">pdf</a>, <a href="/format/2401.06408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AboutMe: Using Self-Descriptions in Webpages to Document the Effects of  English Pretraining Data Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lucy%2C+L">Li Lucy</a>, 
<a href="/search/cs?searchtype=author&query=Gururangan%2C+S">Suchin Gururangan</a>, 
<a href="/search/cs?searchtype=author&query=Soldaini%2C+L">Luca Soldaini</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>, 
<a href="/search/cs?searchtype=author&query=Bamman%2C+D">David Bamman</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+L">Lauren Klein</a>, 
<a href="/search/cs?searchtype=author&query=Dodge%2C+J">Jesse Dodge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models' (LLMs) abilities are drawn from their pretraining
data, and model development begins with data curation. However, decisions
around what data is retained or removed during this initial stage is
under-scrutinized. In our work, we ground web text, which is a popular
pretraining data source, to its social and geographic contexts. We create a new
dataset of 10.3 million self-descriptions of website creators, and extract
information about who they are and where they are from: their topical
interests, social roles, and geographic affiliations. Then, we conduct the
first study investigating how ten "quality" and English language identification
(langID) filters affect webpages that vary along these social dimensions. Our
experiments illuminate a range of implicit preferences in data curation: we
show that some quality classifiers act like topical domain filters, and langID
can overlook English content from some regions of the world. Overall, we hope
that our work will encourage a new line of research on pretraining data
curation practices and its social implications.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06411" title="Abstract">arXiv:2401.06411</a> [<a href="/pdf/2401.06411" title="Download PDF">pdf</a>, <a href="/format/2401.06411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient and Scalable Clocking Assignment Algorithm for  Multi-Threaded Multi-Phase Single Flux Quantum Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aviles%2C+R+S">Robert S. Aviles</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xi Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zhaorui Ni</a>, 
<a href="/search/cs?searchtype=author&query=Beerel%2C+P+A">Peter A. Beerel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">A key distinguishing feature of single flux quantum (SFQ) circuits is that
each logic gate is clocked. This feature forces the introduction of
path-balancing flip-flops to ensure proper synchronization of inputs at each
gate. This paper proposes a polynomial time complexity approximation algorithm
for clocking assignments that minimizes the insertion of path balancing buffers
for multi-threaded multi-phase clocking of SFQ circuits. Existing SFQ
multi-phase clocking solutions have been shown to effectively reduce the number
of required buffers inserted while maintaining high throughput, however, the
associated clock assignment algorithms have exponential complexity and can have
prohibitively long runtimes for large circuits, limiting the scalability of
this approach. Our proposed algorithm is based on a linear program (LP) that
leads to solutions that are experimentally on average within 5% of the optimum
and helps accelerate convergence towards the optimal integer linear program
(ILP) based solution. The improved LP and ILP runtimes permit multi-phase
clocking schemes to scale to larger SFQ circuits than previous state of the art
clocking assignment methods. We further extend the existing algorithm to
support fanout sharing of the added buffers, saving, on average, an additional
10% of the inserted DFFs. Compared to traditional full path balancing (FPB)
methods across 10 benchmarks, our enhanced LP saves 79.9%, 87.8%, and 91.2% of
the inserted buffers for 2, 3, and 4 clock phases respectively. Finally, we
extend this approach to the generation of circuits that completely mitigate
potential hold-time violations at the cost of either adding on average less
than 10% more buffers (for designs with 3 or more clock phases) or, more
generally, adding a clock phase and thereby reducing throughput.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06412" title="Abstract">arXiv:2401.06412</a> [<a href="/pdf/2401.06412" title="Download PDF">pdf</a>, <a href="/ps/2401.06412" title="Download PostScript">ps</a>, <a href="/format/2401.06412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding whole-body inter-personal dynamics between two players  using neural Granger causality as the explainable AI (XAI)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takamido%2C+R">Ryota Takamido</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+C">Chiharu Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Ota%2C+J">Jun Ota</a>, 
<a href="/search/cs?searchtype=author&query=Nakamoto%2C+H">Hiroki Nakamoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages (including 6 supporting information), 9 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Background: Simultaneously focusing on intra- and inter-individual body
dynamics and elucidating how these affect each other will help understand human
inter-personal coordination behavior. However, this association has not been
investigated previously owing to difficulties in analyzing complex causal
relations among several body components.To address this issue, this study
proposes a new analytical framework that attempts to understand the underlying
causal structures behind each joint movement of individual baseball players
using neural Granger causality (NGC) as the explainable AI. Methods: In the NGC
analysis, causal relationships were defined as the size of the weight
parameters of the first layer of a machine-learning model trained to predict
the future state of a specific time-series variable. To verify the approach in
a practical context, we conducted an experiment with 16 pairs of expert
baseball pitchers and batters; input datasets with 27 joint resultant velocity
data (joints of 13 pitchers and 14 batters) were generated and used for model
training.Results: NGC analysis revealed significant causal relations among
intra- and inter-individual body components such as the batter's hands having a
causal effect from the pitcher's throwing arm. Remarkably, although the
causality from the batter's body to pitcher's body is much lower than the
reverse, it is significantly correlated with batter performance outcomes.
Conclusions: The above results suggest the effectiveness of NGC analysis for
understanding whole-body inter-personal coordination dynamics and that of the
AI technique as a new approach for analyzing complex human behavior from a
different perspective than conventional techniques.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06413" title="Abstract">arXiv:2401.06413</a> [<a href="/pdf/2401.06413" title="Download PDF">pdf</a>, <a href="/ps/2401.06413" title="Download PostScript">ps</a>, <a href="/format/2401.06413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Doesn&#x27;t Microsoft Let Me Sleep? How Automaticity of Windows Updates  Impacts User Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+S">Sanju Ahuja</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Ridhi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+J">Jyoti Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">'Automating the user away' has been designated as a dark pattern in
literature for performing tasks without user consent or confirmation. However,
limited studies have been reported on how users experience the sense of
autonomy when digital systems fully or partially bypass consent. More research
is required to understand what makes automaticity a threat to autonomy. To
address this gap, a qualitative interview study with 10 users was conducted to
investigate the user experience of Microsoft Windows updates. It was found that
ten design features of Windows updates impact the autonomy experience. For each
design feature, the contextual factors which influence its impact on autonomy
were also noted. The findings of this paper can help designers understand the
ethical concerns posed by automaticity in design and identify measures to
mitigate these concerns.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06415" title="Abstract">arXiv:2401.06415</a> [<a href="/pdf/2401.06415" title="Download PDF">pdf</a>, <a href="/format/2401.06415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Reconstruction of Interacting Multi-Person in Clothing from a Single  Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cha%2C+J">Junuk Cha</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hansol Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaewon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+N+N+B">Nhat Nguyen Bao Truong</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J+S">Jae Shin Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seungryul Baek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a novel pipeline to reconstruct the geometry of
interacting multi-person in clothing on a globally coherent scene space from a
single image. The main challenge arises from the occlusion: a part of a human
body is not visible from a single view due to the occlusion by others or the
self, which introduces missing geometry and physical implausibility (e.g.,
penetration). We overcome this challenge by utilizing two human priors for
complete 3D geometry and surface contacts. For the geometry prior, an encoder
learns to regress the image of a person with missing body parts to the latent
vectors; a decoder decodes these vectors to produce 3D features of the
associated geometry; and an implicit network combines these features with a
surface normal map to reconstruct a complete and detailed 3D humans. For the
contact prior, we develop an image-space contact detector that outputs a
probability distribution of surface contacts between people in 3D. We use these
priors to globally refine the body poses, enabling the penetration-free and
accurate reconstruction of interacting multi-person in clothing on the scene
space. The results demonstrate that our method is complete, globally coherent,
and physically plausible compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06416" title="Abstract">arXiv:2401.06416</a> [<a href="/pdf/2401.06416" title="Download PDF">pdf</a>, <a href="/format/2401.06416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mission: Impossible Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kallini%2C+J">Julie Kallini</a>, 
<a href="/search/cs?searchtype=author&query=Papadimitriou%2C+I">Isabel Papadimitriou</a>, 
<a href="/search/cs?searchtype=author&query=Futrell%2C+R">Richard Futrell</a>, 
<a href="/search/cs?searchtype=author&query=Mahowald%2C+K">Kyle Mahowald</a>, 
<a href="/search/cs?searchtype=author&query=Potts%2C+C">Christopher Potts</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Chomsky and others have very directly claimed that large language models
(LLMs) are equally capable of learning languages that are possible and
impossible for humans to learn. However, there is very little published
experimental evidence to support such a claim. Here, we develop a set of
synthetic impossible languages of differing complexity, each designed by
systematically altering English data with unnatural word orders and grammar
rules. These languages lie on an impossibility continuum: at one end are
languages that are inherently impossible, such as random and irreversible
shuffles of English words, and on the other, languages that may not be
intuitively impossible but are often considered so in linguistics, particularly
those with rules based on counting word positions. We report on a wide range of
evaluations to assess the capacity of GPT-2 small models to learn these
uncontroversially impossible languages, and crucially, we perform these
assessments at various stages throughout training to compare the learning
process for each language. Our core finding is that GPT-2 struggles to learn
impossible languages when compared to English as a control, challenging the
core claim. More importantly, we hope our approach opens up a productive line
of inquiry in which different LLM architectures are tested on a variety of
impossible languages in an effort to learn more about how LLMs can be used as
tools for these cognitive and typological investigations.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06421" title="Abstract">arXiv:2401.06421</a> [<a href="/pdf/2401.06421" title="Download PDF">pdf</a>, <a href="/ps/2401.06421" title="Download PostScript">ps</a>, <a href="/format/2401.06421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty quantification for probabilistic machine learning in earth  observation using conformal prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Geethen Singh</a>, 
<a href="/search/cs?searchtype=author&query=Moncrieff%2C+G">Glenn Moncrieff</a>, 
<a href="/search/cs?searchtype=author&query=Venter%2C+Z">Zander Venter</a>, 
<a href="/search/cs?searchtype=author&query=Cawse-Nicholson%2C+K">Kerry Cawse-Nicholson</a>, 
<a href="/search/cs?searchtype=author&query=Slingsby%2C+J">Jasper Slingsby</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+T+B">Tamara B Robinson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unreliable predictions can occur when using artificial intelligence (AI)
systems with negative consequences for downstream applications, particularly
when employed for decision-making. Conformal prediction provides a
model-agnostic framework for uncertainty quantification that can be applied to
any dataset, irrespective of its distribution, post hoc. In contrast to other
pixel-level uncertainty quantification methods, conformal prediction operates
without requiring access to the underlying model and training dataset,
concurrently offering statistically valid and informative prediction regions,
all while maintaining computational efficiency. In response to the increased
need to report uncertainty alongside point predictions, we bring attention to
the promise of conformal prediction within the domain of Earth Observation (EO)
applications. To accomplish this, we assess the current state of uncertainty
quantification in the EO domain and found that only 20% of the reviewed Google
Earth Engine (GEE) datasets incorporated a degree of uncertainty information,
with unreliable methods prevalent. Next, we introduce modules that seamlessly
integrate into existing GEE predictive modelling workflows and demonstrate the
application of these tools for datasets spanning local to global scales,
including the Dynamic World and Global Ecosystem Dynamics Investigation (GEDI)
datasets. These case studies encompass regression and classification tasks,
featuring both traditional and deep learning-based workflows. Subsequently, we
discuss the opportunities arising from the use of conformal prediction in EO.
We anticipate that the increased availability of easy-to-use implementations of
conformal predictors, such as those provided here, will drive wider adoption of
rigorous uncertainty quantification in EO, thereby enhancing the reliability of
uses such as operational monitoring and decision making.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06426" title="Abstract">arXiv:2401.06426</a> [<a href="/pdf/2401.06426" title="Download PDF">pdf</a>, <a href="/format/2401.06426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UPDP: A Unified Progressive Depth Pruner for CNN and Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Dehua Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuanxian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiaocheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Mingjie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jinzhang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Fan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Lu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Sirasao%2C+A">Ashish Sirasao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traditional channel-wise pruning methods by reducing network channels
struggle to effectively prune efficient CNN models with depth-wise
convolutional layers and certain efficient modules, such as popular inverted
residual blocks. Prior depth pruning methods by reducing network depths are not
suitable for pruning some efficient models due to the existence of some
normalization layers. Moreover, finetuning subnet by directly removing
activation layers would corrupt the original model weights, hindering the
pruned model from achieving high performance. To address these issues, we
propose a novel depth pruning method for efficient models. Our approach
proposes a novel block pruning strategy and progressive training method for the
subnet. Additionally, we extend our pruning method to vision transformer
models. Experimental results demonstrate that our method consistently
outperforms existing depth pruning methods across various pruning
configurations. We obtained three pruned ConvNeXtV1 models with our method
applying on ConvNeXtV1, which surpass most SOTA efficient models with
comparable inference performance. Our method also achieves state-of-the-art
pruning performance on the vision transformer model.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06430" title="Abstract">arXiv:2401.06430</a> [<a href="/pdf/2401.06430" title="Download PDF">pdf</a>, <a href="/format/2401.06430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Distillation Learning For Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huiyuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+K">Kuilong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuanming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+M">Mengshi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huadong Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the rapid advancements in deep learning technologies, person
re-identification (ReID) has witnessed remarkable performance improvements.
However, the majority of prior works have traditionally focused on solving the
problem via extracting features solely from a single perspective, such as
uniform partitioning, hard attention mechanisms, or semantic masks. While these
approaches have demonstrated efficacy within specific contexts, they fall short
in diverse situations. In this paper, we propose a novel approach, Mutual
Distillation Learning For Person Re-identification (termed as MDPR), which
addresses the challenging problem from multiple perspectives within a single
unified model, leveraging the power of mutual distillation to enhance the
feature representations collectively. Specifically, our approach encompasses
two branches: a hard content branch to extract local features via a uniform
horizontal partitioning strategy and a Soft Content Branch to dynamically
distinguish between foreground and background and facilitate the extraction of
multi-granularity features via a carefully designed attention mechanism. To
facilitate knowledge exchange between these two branches, a mutual distillation
and fusion process is employed, promoting the capability of the outputs of each
branch. Extensive experiments are conducted on widely used person ReID datasets
to validate the effectiveness and superiority of our approach. Notably, our
method achieves an impressive $88.7\%/94.4\%$ in mAP/Rank-1 on the
DukeMTMC-reID dataset, surpassing the current state-of-the-art results. Our
source code is available at https://github.com/KuilongCui/MDPR.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06431" title="Abstract">arXiv:2401.06431</a> [<a href="/pdf/2401.06431" title="Download PDF">pdf</a>, <a href="/format/2401.06431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Automation to Augmentation: Large Language Models Elevating Essay  Scoring Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Changrong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenxing Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S+X">Sean Xin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kunpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qi Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Receiving immediate and personalized feedback is crucial for second-language
learners, and Automated Essay Scoring (AES) systems are a vital resource when
human instructors are unavailable. This study investigates the effectiveness of
Large Language Models (LLMs), specifically GPT-4 and fine-tuned GPT-3.5, as
tools for AES. Our comprehensive set of experiments, conducted on both public
and private datasets, highlights the remarkable advantages of LLM-based AES
systems. They include superior accuracy, consistency, generalizability, and
interpretability, with fine-tuned GPT-3.5 surpassing traditional grading
models. Additionally, we undertake LLM-assisted human evaluation experiments
involving both novice and expert graders. One pivotal discovery is that LLMs
not only automate the grading process but also enhance the performance of human
graders. Novice graders when provided with feedback generated by LLMs, achieve
a level of accuracy on par with experts, while experts become more efficient
and maintain greater consistency in their assessments. These results underscore
the potential of LLMs in educational technology, paving the way for effective
collaboration between humans and AI, ultimately leading to transformative
learning experiences through AI-generated feedback.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06432" title="Abstract">arXiv:2401.06432</a> [<a href="/pdf/2401.06432" title="Download PDF">pdf</a>, <a href="/format/2401.06432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous Low-Rank Approximation for Federated Fine-tuning of  On-Device Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y+J">Yae Jee Cho</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fahrezi%2C+A">Aldi Fahrezi</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+G">Gauri Joshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Large foundation models (FMs) adapt surprisingly well to specific domains or
tasks with fine-tuning. Federated learning (FL) further enables private FM
fine-tuning using the local data on devices. However, the standard FMs' large
size poses challenges for resource-constrained and heterogeneous devices. To
address this, we consider FMs with reduced parameter sizes, referred to as
on-device FMs (ODFMs). While ODFMs allow on-device inference, computational
constraints still hinder efficient federated fine-tuning. We propose a
parameter-efficient federated fine-tuning method for ODFMs using heterogeneous
low-rank approximations (LoRAs) that addresses system and data heterogeneity.
We show that homogeneous LoRA ranks face a trade-off between overfitting and
slow convergence, and propose HetLoRA, which employs heterogeneous ranks across
clients and eliminates the shortcomings of homogeneous HetLoRA. By applying
rank self-pruning locally and sparsity-weighted aggregation at the server, we
combine the advantages of high and low-rank LoRAs, which achieves improved
convergence speed and final performance compared to homogeneous LoRA.
Furthermore, it offers enhanced computation efficiency compared to full
fine-tuning, making it suitable for heterogeneous devices while preserving data
privacy.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06435" title="Abstract">arXiv:2401.06435</a> [<a href="/pdf/2401.06435" title="Download PDF">pdf</a>, <a href="/format/2401.06435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swin Transformer-Based CSI Feedback for Massive MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiaming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jialong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiran Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lun Li</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">For massive multiple-input multiple-output systems in the frequency division
duplex (FDD) mode, accurate downlink channel state information (CSI) is
required at the base station (BS). However, the increasing number of transmit
antennas aggravates the feedback overhead of CSI. Recently, deep learning (DL)
has shown considerable potential to reduce CSI feedback overhead. In this
paper, we propose a Swin Transformer-based autoencoder network called SwinCFNet
for the CSI feedback task. In particular, the proposed method can effectively
capture the long-range dependence information of CSI. Moreover, we explore the
impact of the number of Swin Transformer blocks and the dimension of feature
channels on the performance of SwinCFNet. Experimental results show that
SwinCFNet significantly outperforms other DL-based methods with comparable
model sizes, especially for the outdoor scenario.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06436" title="Abstract">arXiv:2401.06436</a> [<a href="/pdf/2401.06436" title="Download PDF">pdf</a>, <a href="/format/2401.06436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Graph Convolutional Networks with Transformer Layer in  social-based items recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T+L">Thi Linh Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T+D">Tuan Dung Pham</a>, 
<a href="/search/cs?searchtype=author&query=Ta%2C+V+C">Viet Cuong Ta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">In this work, we have proposed an approach for improving the GCN for
predicting ratings in social networks. Our model is expanded from the standard
model with several layers of transformer architecture. The main focus of the
paper is on the encoder architecture for node embedding in the network. Using
the embedding layer from the graph-based convolution layer, the attention
mechanism could rearrange the feature space to get a more efficient embedding
for the downstream task. The experiments showed that our proposed architecture
achieves better performance than GCN on the traditional link prediction task.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06437" title="Abstract">arXiv:2401.06437</a> [<a href="/pdf/2401.06437" title="Download PDF">pdf</a>, <a href="/format/2401.06437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-PreMise: Can Large Language Models Generate 3D Shapes with Sharp  Features and Parametric Control?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zeqing Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+H">Haoxuan Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Q">Qiang Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junbo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in implicit 3D representations and generative models have
markedly propelled the field of 3D object generation forward. However, it
remains a significant challenge to accurately model geometries with defined
sharp features under parametric controls, which is crucial in fields like
industrial design and manufacturing. To bridge this gap, we introduce a
framework that employs Large Language Models (LLMs) to generate text-driven 3D
shapes, manipulating 3D software via program synthesis. We present 3D-PreMise,
a dataset specifically tailored for 3D parametric modeling of industrial
shapes, designed to explore state-of-the-art LLMs within our proposed pipeline.
Our work reveals effective generation strategies and delves into the
self-correction capabilities of LLMs using a visual interface. Our work
highlights both the potential and limitations of LLMs in 3D parametric modeling
for industrial applications.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06438" title="Abstract">arXiv:2401.06438</a> [<a href="/pdf/2401.06438" title="Download PDF">pdf</a>, <a href="/ps/2401.06438" title="Download PostScript">ps</a>, <a href="/format/2401.06438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Low-Light Image Recognition Performance Based on  Image-adaptive Learnable Module
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ono%2C+S">Seitaro Ono</a>, 
<a href="/search/cs?searchtype=author&query=Ogino%2C+Y">Yuka Ogino</a>, 
<a href="/search/cs?searchtype=author&query=Toizumi%2C+T">Takahiro Toizumi</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+A">Atsushi Ito</a>, 
<a href="/search/cs?searchtype=author&query=Tsukada%2C+M">Masato Tsukada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, significant progress has been made in image recognition
technology based on deep neural networks. However, improving recognition
performance under low-light conditions remains a significant challenge. This
study addresses the enhancement of recognition model performance in low-light
conditions. We propose an image-adaptive learnable module which apply
appropriate image processing on input images and a hyperparameter predictor to
forecast optimal parameters used in the module. Our proposed approach allows
for the enhancement of recognition performance under low-light conditions by
easily integrating as a front-end filter without the need to retrain existing
recognition models designed for low-light conditions. Through experiments, our
proposed method demonstrates its contribution to enhancing image recognition
performance under low-light conditions.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06439" title="Abstract">arXiv:2401.06439</a> [<a href="/pdf/2401.06439" title="Download PDF">pdf</a>, <a href="/format/2401.06439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ordering-Flexible Multi-Robot Coordination for MovingTarget Convoying  Using Long-TermTask Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin-Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanxin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Henglai Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+C">Chen Lv</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Automatica, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we propose a cooperative long-term task execution (LTTE)
algorithm for protecting a moving target into the interior of an
ordering-flexible convex hull by a team of robots resiliently in the changing
environments. Particularly, by designing target-approaching and
sensing-neighbor collision-free subtasks, and incorporating these subtasks into
the constraints rather than the traditional cost function in an online
constraint-based optimization framework, the proposed LTTE can systematically
guarantee long-term target convoying under changing environments in the
n-dimensional Euclidean space. Then, the introduction of slack variables allow
for the constraint violation of different subtasks; i.e., the attraction from
target-approaching constraints and the repulsion from time-varying
collision-avoidance constraints, which results in the desired formation with
arbitrary spatial ordering sequences. Rigorous analysis is provided to
guarantee asymptotical convergence with challenging nonlinear couplings induced
by time-varying collision-free constraints. Finally, 2D experiments using three
autonomous mobile robots (AMRs) are conducted to validate the effectiveness of
the proposed algorithm, and 3D simulations tackling changing environmental
elements, such as different initial positions, some robots suddenly breakdown
and static obstacles are presented to demonstrate the multi-dimensional
adaptability, robustness and the ability of obstacle avoidance of the proposed
method.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06441" title="Abstract">arXiv:2401.06441</a> [<a href="/pdf/2401.06441" title="Download PDF">pdf</a>, <a href="/ps/2401.06441" title="Download PostScript">ps</a>, <a href="/format/2401.06441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bicycle Stabilization using mechanism optimization and Digital LQR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pirayeshshirazinezhad%2C+R">Reza Pirayeshshirazinezhad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This study introduces lateral pendulum as an innovative balancer design for
bicycle stabilization. This pendulum, operating in the bicycle's vertical
plane, enables the bicycle to remain stationary. The paper develops a dynamic
model for a bicycle equipped with this lateral pendulum, using Lagrange's
method, where the equations are validated with ADAMS software. The
stabilization is demonstrated with traditional vertical and novel lateral
pendulums, managed through a genetic-pole placement control algorithm. This
approach showcases the superiority of the lateral pendulum over traditional
methods, including vertical pendulums and steering the handlebar. Additionally,
a Digital Linear Quadratic Regulator controller is implemented for practical
application, further enhancing system stability.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06442" title="Abstract">arXiv:2401.06442</a> [<a href="/pdf/2401.06442" title="Download PDF">pdf</a>, <a href="/format/2401.06442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RotationDrag: Point-based Image Editing with Rotated Diffusion Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minxing Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wentao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is released at <a href="https://github.com/Tony-Lowe/RotationDrag">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A precise and user-friendly manipulation of image content while preserving
image fidelity has always been crucial to the field of image editing. Thanks to
the power of generative models, recent point-based image editing methods allow
users to interactively change the image content with high generalizability by
clicking several control points. But the above mentioned editing process is
usually based on the assumption that features stay constant in the motion
supervision step from initial to target points. In this work, we conduct a
comprehensive investigation in the feature space of diffusion models, and find
that features change acutely under in-plane rotation. Based on this, we propose
a novel approach named RotationDrag, which significantly improves point-based
image editing performance when users intend to in-plane rotate the image
content. Our method tracks handle points more precisely by utilizing the
feature map of the rotated images, thus ensuring precise optimization and high
image fidelity. Furthermore, we build a in-plane rotation focused benchmark
called RotateBench, the first benchmark to evaluate the performance of
point-based image editing method under in-plane rotation scenario on both real
images and generated images. A thorough user study demonstrates the superior
capability in accomplishing in-plane rotation that users intend to achieve,
comparing the DragDiffusion baseline and other existing diffusion-based
methods. See the project page https://github.com/Tony-Lowe/RotationDrag for
code and experiment results.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06443" title="Abstract">arXiv:2401.06443</a> [<a href="/pdf/2401.06443" title="Download PDF">pdf</a>, <a href="/format/2401.06443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BOK-VQA: Bilingual Outside Knowledge-based Visual Question Answering via  Graph Representation Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Seungwoo Song</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Youhan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+H">Haneol Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+K">Kyungtae Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Will be published at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The current research direction in generative models, such as the recently
developed GPT4, aims to find relevant knowledge information for multimodal and
multilingual inputs to provide answers. Under these research circumstances, the
demand for multilingual evaluation of visual question answering (VQA) tasks, a
representative task of multimodal systems, has increased. Accordingly, we
propose a bilingual outside-knowledge VQA (BOK-VQA) dataset in this study that
can be extended to multilingualism. The proposed data include 17K images, 17K
question-answer pairs for both Korean and English and 280K instances of
knowledge information related to question-answer content. We also present a
framework that can effectively inject knowledge information into a VQA system
by pretraining the knowledge information of BOK-VQA data in the form of graph
embeddings. Finally, through in-depth analysis, we demonstrated the actual
effect of the knowledge information contained in the constructed training data
on VQA.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06451" title="Abstract">arXiv:2401.06451</a> [<a href="/pdf/2401.06451" title="Download PDF">pdf</a>, <a href="/ps/2401.06451" title="Download PostScript">ps</a>, <a href="/format/2401.06451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Logic for Repair and State Recovery in Byzantine Fault-tolerant  Multi-agent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Ditmarsch%2C+H">Hans van Ditmarsch</a>, 
<a href="/search/cs?searchtype=author&query=Fruzsa%2C+K">Krisztina Fruzsa</a>, 
<a href="/search/cs?searchtype=author&query=Kuznets%2C+R">Roman Kuznets</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+U">Ulrich Schmid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We provide an epistemic logical language and semantics for the modeling and
analysis of byzantine fault-tolerant multi-agent systems. This not only
facilitates reasoning about the agents' fault status but also supports model
updates for implementing repair and state recovery. For each agent, besides the
standard knowledge modality our logic provides an additional modality called
hope, which is capable of expressing that the agent is correct (not faulty),
and also dynamic modalities enabling change of the agents' correctness status.
These dynamic modalities are interpreted as model updates that come in three
flavours: fully public, more private, or involving factual change. We provide
complete axiomatizations for all these variants in the form of reduction
systems: formulas with dynamic modalities are equivalent to formulas without.
Therefore, they have the same expressivity as the logic of knowledge and hope.
Multiple examples are provided to demonstrate the utility and flexibility of
our logic for modeling a wide range of repair and state recovery techniques
that have been implemented in the context of fault-detection, isolation, and
recovery (FDIR) approaches in fault-tolerant distributed computing with
byzantine agents.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06452" title="Abstract">arXiv:2401.06452</a> [<a href="/pdf/2401.06452" title="Download PDF">pdf</a>, <a href="/format/2401.06452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Machine Learning for Positive-Unlabelled Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saunders%2C+J+D">Jack D. Saunders</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+A+A">Alex A. Freitas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Positive-Unlabelled (PU) learning is a growing field of machine learning that
aims to learn classifiers from data consisting of labelled positive and
unlabelled instances, which can be in reality positive or negative, but whose
label is unknown. An extensive number of methods have been proposed to address
PU learning over the last two decades, so many so that selecting an optimal
method for a given PU learning task presents a challenge. Our previous work has
addressed this by proposing GA-Auto-PU, the first Automated Machine Learning
(Auto-ML) system for PU learning. In this work, we propose two new Auto-ML
systems for PU learning: BO-Auto-PU, based on a Bayesian Optimisation approach,
and EBO-Auto-PU, based on a novel evolutionary/Bayesian optimisation approach.
We also present an extensive evaluation of the three Auto-ML systems, comparing
them to each other and to well-established PU learning methods across 60
datasets (20 real-world datasets, each with 3 versions in terms of PU learning
characteristics).
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06453" title="Abstract">arXiv:2401.06453</a> [<a href="/pdf/2401.06453" title="Download PDF">pdf</a>, <a href="/format/2401.06453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causally Aware Generative Adversarial Networks for Light Pollution  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Ke Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9pages, 9figures, accepted by AAAI2024, AI for Social Impact (Special Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Artificial light plays an integral role in modern cities, significantly
enhancing human productivity and the efficiency of civilization. However,
excessive illumination can lead to light pollution, posing non-negligible
threats to economic burdens, ecosystems, and human health. Despite its critical
importance, the exploration of its causes remains relatively limited within the
field of artificial intelligence, leaving an incomplete understanding of the
factors contributing to light pollution and sustainable illumination planning
distant. To address this gap, we introduce a novel framework named Causally
Aware Generative Adversarial Networks (CAGAN). This innovative approach aims to
uncover the fundamental drivers of light pollution within cities and offer
intelligent solutions for optimal illumination resource allocation in the
context of sustainable urban development. We commence by examining light
pollution across 33,593 residential areas in seven global metropolises. Our
findings reveal substantial influences on light pollution levels from various
building types, notably grasslands, commercial centers and residential
buildings as significant contributors. These discovered causal relationships
are seamlessly integrated into the generative modeling framework, guiding the
process of generating light pollution maps for diverse residential areas.
Extensive experiments showcase CAGAN's potential to inform and guide the
implementation of effective strategies to mitigate light pollution. Our code
and data are publicly available at
https://github.com/zhangyuuao/Light_Pollution_CAGAN.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06461" title="Abstract">arXiv:2401.06461</a> [<a href="/pdf/2401.06461" title="Download PDF">pdf</a>, <a href="/format/2401.06461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Between Lines of Code: Unraveling the Distinct Patterns of Machine and  Human Programmers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuling Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+C">Chengcheng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiaodong Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models have catalyzed an unprecedented wave in code
generation. While achieving significant advances, they blur the distinctions
between machine-and human-authored source code, causing integrity and
authenticity issues of software artifacts. Previous methods such as DetectGPT
have proven effective in discerning machine-generated texts, but they do not
identify and harness the unique patterns of machine-generated code. Thus, its
applicability falters when applied to code. In this paper, we carefully study
the specific patterns that characterize machine and human-authored code.
Through a rigorous analysis of code attributes such as length, lexical
diversity, and naturalness, we expose unique pat-terns inherent to each source.
We particularly notice that the structural segmentation of code is a critical
factor in identifying its provenance. Based on our findings, we propose a novel
machine-generated code detection method called DetectCodeGPT, which improves
DetectGPT by capturing the distinct structural patterns of code. Diverging from
conventional techniques that depend on external LLMs for perturbations,
DetectCodeGPT perturbs the code corpus by strategically inserting spaces and
newlines, ensuring both efficacy and efficiency. Experiment results show that
our approach significantly outperforms state-of-the-art techniques in detecting
machine-generated code.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06462" title="Abstract">arXiv:2401.06462</a> [<a href="/pdf/2401.06462" title="Download PDF">pdf</a>, <a href="/format/2401.06462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AttributionScanner: A Visual Analytics System for Metadata-Free  Data-Slicing Based Model Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xuan%2C+X">Xiwei Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+J+P">Jorge Piazentin Ono</a>, 
<a href="/search/cs?searchtype=author&query=Gou%2C+L">Liang Gou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kwan-Liu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+L">Liu Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Data slice-finding is an emerging technique for evaluating machine learning
models. It works by identifying subgroups within a specified dataset that
exhibit poor performance, often defined by distinct feature sets or
meta-information. However, in the context of unstructured image data, data
slice-finding poses two notable challenges: it requires additional metadata --
a laborious and costly requirement, and also demands non-trivial efforts for
interpreting the root causes of the underperformance within data slices. To
address these challenges, we introduce AttributionScanner, an innovative
human-in-the-loop Visual Analytics (VA) system, designed for data-slicing-based
machine learning (ML) model validation. Our approach excels in identifying
interpretable data slices, employing explainable features extracted through the
lens of Explainable AI (XAI) techniques, and removing the necessity for
additional metadata of textual annotations or cross-model embeddings.
AttributionScanner demonstrates proficiency in pinpointing critical model
issues, including spurious correlations and mislabeled data. Our novel VA
interface visually summarizes data slices, enabling users to gather insights
into model behavior patterns effortlessly. Furthermore, our framework closes
the ML Development Cycle by empowering domain experts to address model issues
by using a cutting-edge neural network regularization technique. The efficacy
of AttributionScanner is underscored through two prototype use cases,
elucidating its substantial effectiveness in model validation for
vision-centric tasks. Our approach paves the way for ML researchers and
practitioners to drive interpretable model validation in a data-efficient way,
ultimately leading to more reliable and accurate models.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06465" title="Abstract">arXiv:2401.06465</a> [<a href="/pdf/2401.06465" title="Download PDF">pdf</a>, <a href="/format/2401.06465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sanity Checks Revisited: An Exploration to Repair the Model Parameter  Randomisation Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hedstr%C3%B6m%2C+A">Anna Hedstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+L">Leander Weber</a>, 
<a href="/search/cs?searchtype=author&query=Lapuschkin%2C+S">Sebastian Lapuschkin</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6hne%2C+M+M">Marina MC H&#xf6;hne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 12 figures, NeurIPS XAIA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">The Model Parameter Randomisation Test (MPRT) is widely acknowledged in the
eXplainable Artificial Intelligence (XAI) community for its well-motivated
evaluative principle: that the explanation function should be sensitive to
changes in the parameters of the model function. However, recent works have
identified several methodological caveats for the empirical interpretation of
MPRT. To address these caveats, we introduce two adaptations to the original
MPRT -- Smooth MPRT and Efficient MPRT, where the former minimises the impact
that noise has on the evaluation results through sampling and the latter
circumvents the need for biased similarity measurements by re-interpreting the
test through the explanation's rise in complexity, after full parameter
randomisation. Our experimental results demonstrate that these proposed
variants lead to improved metric reliability, thus enabling a more trustworthy
application of XAI methods.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06466" title="Abstract">arXiv:2401.06466</a> [<a href="/pdf/2401.06466" title="Download PDF">pdf</a>, <a href="/format/2401.06466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PersianMind: A Cross-Lingual Persian-English Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rostami%2C+P">Pedram Rostami</a>, 
<a href="/search/cs?searchtype=author&query=Salemi%2C+A">Ali Salemi</a>, 
<a href="/search/cs?searchtype=author&query=Dousti%2C+M+J">Mohammad Javad Dousti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models demonstrate remarkable proficiency in various
linguistic tasks and have extensive knowledge across various domains. Although
they perform best in English, their ability in other languages is notable too.
In contrast, open-source models, such as LLaMa, are primarily trained on
English datasets, resulting in poor performance in non-English languages. In
this paper, we introduce PersianMind, an open-source bilingual large language
model which demonstrates comparable performance to closed-source GPT-3.5-turbo
in the Persian language. By expanding LLaMa2's vocabulary with 10,000 Persian
tokens and training it on a dataset comprising nearly 2 billion Persian tokens,
we show that our approach preserves the model's English knowledge and employs
transfer learning to excel at transferring task knowledge from one language to
another.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06468" title="Abstract">arXiv:2401.06468</a> [<a href="/pdf/2401.06468" title="Download PDF">pdf</a>, <a href="/format/2401.06468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Large Language Models for Document-Level Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Thuy-Trang Vu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Lizhen Qu</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+G">George Foster</a>, 
<a href="/search/cs?searchtype=author&query=Haffari%2C+G">Gholamreza Haffari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress; 21 pages, 14 tables, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have made significant strides in various natural
language processing (NLP) tasks. Recent research shows that the
moderately-sized LLMs often outperform their larger counterparts after
task-specific fine-tuning. In this work, we delve into the process of adapting
LLMs to specialize in document-level machine translation (DocMT) for a specific
language pair. Firstly, we explore how prompt strategies affect downstream
translation performance. Then, we conduct extensive experiments with two
fine-tuning methods, three LLM backbones, and 18 translation tasks across nine
language pairs. Our findings indicate that in some cases, these specialized
models even surpass GPT-4 in translation performance, while they still
significantly suffer from the off-target translation issue in others, even if
they are exclusively fine-tuned on bilingual parallel documents. Furthermore,
we provide an in-depth analysis of these LLMs tailored for DocMT, exploring
aspects such as translation errors, the scaling law of parallel documents,
out-of-domain generalization, and the impact of zero-shot crosslingual
transfer. The findings of this research not only shed light on the strengths
and limitations of LLM-based DocMT models but also provide a foundation for
future research in DocMT.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06469" title="Abstract">arXiv:2401.06469</a> [<a href="/pdf/2401.06469" title="Download PDF">pdf</a>, <a href="/format/2401.06469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+A">Ang Lv</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+H">Hansen Ha</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In this paper, by treating in-context learning (ICL) as a meta-optimization
process, we explain why LLMs are sensitive to the order of ICL examples. This
understanding leads us to the development of Batch-ICL, an effective,
efficient, and order-agnostic inference algorithm for ICL. Differing from the
standard N-shot learning approach, Batch-ICL employs $N$ separate 1-shot
forward computations and aggregates the resulting meta-gradients. These
aggregated meta-gradients are then applied to a zero-shot learning to generate
the final prediction. This batch processing approach renders the LLM agnostic
to the order of ICL examples. Through extensive experiments and analysis, we
demonstrate that Batch-ICL consistently outperforms most permutations of
example sequences. In some cases, it even exceeds the performance of the
optimal order for standard ICL, all while reducing the computational resources
required. Furthermore, we develop a novel variant of Batch-ICL featuring
multiple "epochs" of meta-optimization. This variant implicitly explores
permutations of ICL examples, further enhancing ICL performance.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06470" title="Abstract">arXiv:2401.06470</a> [<a href="/pdf/2401.06470" title="Download PDF">pdf</a>, <a href="/format/2401.06470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UNEX-RL: Reinforcing Long-Term Rewards in Multi-Stage Recommender  Systems with UNidirectional EXecution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gengrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoshuang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Hongyi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+K">Kaiqiao Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Ben Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In recent years, there has been a growing interest in utilizing reinforcement
learning (RL) to optimize long-term rewards in recommender systems. Since
industrial recommender systems are typically designed as multi-stage systems,
RL methods with a single agent face challenges when optimizing multiple stages
simultaneously. The reason is that different stages have different observation
spaces, and thus cannot be modeled by a single agent. To address this issue, we
propose a novel UNidirectional-EXecution-based multi-agent Reinforcement
Learning (UNEX-RL) framework to reinforce the long-term rewards in multi-stage
recommender systems. We show that the unidirectional execution is a key feature
of multi-stage recommender systems, bringing new challenges to the applications
of multi-agent reinforcement learning (MARL), namely the observation dependency
and the cascading effect. To tackle these challenges, we provide a cascading
information chain (CIC) method to separate the independent observations from
action-dependent observations and use CIC to train UNEX-RL effectively. We also
discuss practical variance reduction techniques for UNEX-RL. Finally, we show
the effectiveness of UNEX-RL on both public datasets and an online recommender
system with over 100 million users. Specifically, UNEX-RL reveals a 0.558%
increase in users' usage time compared with single-agent RL algorithms in
online A/B experiments, highlighting the effectiveness of UNEX-RL in industrial
recommender systems.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06471" title="Abstract">arXiv:2401.06471</a> [<a href="/pdf/2401.06471" title="Download PDF">pdf</a>, <a href="/format/2401.06471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Brain-inspired Computational Model for Human-like Concept Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Concept learning is a fundamental aspect of human cognition and plays a
critical role in mental processes such as categorization, reasoning, memory,
and decision-making. Researchers across various disciplines have shown
consistent interest in the process of concept acquisition in individuals. To
elucidate the mechanisms involved in human concept learning, this study
examines the findings from computational neuroscience and cognitive psychology.
These findings indicate that the brain's representation of concepts relies on
two essential components: multisensory representation and text-derived
representation. These two types of representations are coordinated by a
semantic control system, ultimately leading to the acquisition of concepts.
Drawing inspiration from this mechanism, the study develops a human-like
computational model for concept learning based on spiking neural networks. By
effectively addressing the challenges posed by diverse sources and imbalanced
dimensionality of the two forms of concept representations, the study
successfully attains human-like concept representations. Tests involving
similar concepts demonstrate that our model, which mimics the way humans learn
concepts, yields representations that closely align with human cognition.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06473" title="Abstract">arXiv:2401.06473</a> [<a href="/pdf/2401.06473" title="Download PDF">pdf</a>, <a href="/format/2401.06473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Learning of Dense Hierarchical Representations for  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kats%2C+E">Eytan Kats</a>, 
<a href="/search/cs?searchtype=author&query=Hirsch%2C+J+G">Jochen G. Hirsch</a>, 
<a href="/search/cs?searchtype=author&query=Heinrich%2C+M+P">Mattias P. Heinrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper demonstrates a self-supervised framework for learning voxel-wise
coarse-to-fine representations tailored for dense downstream tasks. Our
approach stems from the observation that existing methods for hierarchical
representation learning tend to prioritize global features over local features
due to inherent architectural bias. To address this challenge, we devise a
training strategy that balances the contributions of features from multiple
scales, ensuring that the learned representations capture both coarse and
fine-grained details. Our strategy incorporates 3-fold improvements: (1) local
data augmentations, (2) a hierarchically balanced architecture, and (3) a
hybrid contrastive-restorative loss function. We evaluate our method on CT and
MRI data and demonstrate that our new approach particularly beneficial for
fine-tuning with limited annotated data and consistently outperforms the
baseline counterpart in linear evaluation settings.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06477" title="Abstract">arXiv:2401.06477</a> [<a href="/pdf/2401.06477" title="Download PDF">pdf</a>, <a href="/format/2401.06477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kun: Answer Polishment for Chinese Self-Alignment with Instruction  Back-Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shuyue Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xingwei Qu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiawei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weixu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xinrun Du</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we introduce Kun, a novel approach for creating high-quality
instruction-tuning datasets for large language models (LLMs) without relying on
manual annotations. Adapting a self-training algorithm based on instruction
back-translation and answer polishment, Kun leverages unlabelled data from
diverse sources such as Wudao, Wanjuan, and SkyPile to generate a substantial
dataset of over a million Chinese instructional data points. This approach
significantly deviates from traditional methods by using a self-curation
process to refine and select the most effective instruction-output pairs. Our
experiments with the 6B-parameter Yi model across various benchmarks
demonstrate Kun's robustness and scalability. Our method's core contributions
lie in its algorithmic advancement, which enhances data retention and clarity,
and its innovative data generation approach that substantially reduces the
reliance on costly and time-consuming manual annotations. This methodology
presents a scalable and efficient solution for improving the
instruction-following capabilities of LLMs, with significant implications for
their application across diverse fields. The code and dataset can be found at
https://github.com/Zheng0428/COIG-Kun
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06482" title="Abstract">arXiv:2401.06482</a> [<a href="/pdf/2401.06482" title="Download PDF">pdf</a>, <a href="/format/2401.06482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy Patterns for Web: An Exploratory Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rani%2C+P">Pooja Rani</a>, 
<a href="/search/cs?searchtype=author&query=Zellweger%2C+J">Jonas Zellweger</a>, 
<a href="/search/cs?searchtype=author&query=Kousadianos%2C+V">Veronika Kousadianos</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+L">Luis Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Kehrer%2C+T">Timo Kehrer</a>, 
<a href="/search/cs?searchtype=author&query=Bacchelli%2C+A">Alberto Bacchelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Performance (cs.PF)

</div>
<p class="mathjax">As the energy footprint generated by software is increasing at an alarming
rate, understanding how to develop energy-efficient applications has become a
necessity. Previous work has introduced catalogs of coding practices, also
known as energy patterns. These patterns are yet limited to Mobile or
third-party libraries. In this study, we focus on the Web domain--a main source
of energy consumption. First, we investigated whether and how Mobile energy
patterns could be ported to this domain and found that 20 patterns could be
ported. Then, we interviewed six expert web developers from different companies
to challenge the ported patterns. Most developers expressed concerns for
antipatterns, specifically with functional antipatterns, and were able to
formulate guidelines to locate these patterns in the source code. Finally, to
quantify the effect of Web energy patterns on energy consumption, we set up an
automated pipeline to evaluate two ported patterns: 'Dynamic Retry Delay' (DRD)
and 'Open Only When Necessary' (OOWN). With this, we found no evidence that the
DRD pattern consumes less energy than its antipattern, while the opposite is
true for OOWN. Data and Material: https://doi.org/10.5281/zenodo.8404487
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06484" title="Abstract">arXiv:2401.06484</a> [<a href="/pdf/2401.06484" title="Download PDF">pdf</a>, <a href="/ps/2401.06484" title="Download PostScript">ps</a>, <a href="/format/2401.06484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-enabled Priority and Auction-Based Spectrum Management for 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khadem%2C+M">Mina Khadem</a>, 
<a href="/search/eess?searchtype=author&query=Zeinali%2C+F">Farshad Zeinali</a>, 
<a href="/search/eess?searchtype=author&query=Mokari%2C+N">Nader Mokari</a>, 
<a href="/search/eess?searchtype=author&query=Saeedi%2C+H">Hamid Saeedi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the proceedings of the 2024 IEEE Wireless Communications and Networking Conference (WCNC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we present a quality of service (QoS)-aware priority-based
spectrum management scheme to guarantee the minimum required bit rate of
vertical sector players (VSPs) in the 5G and beyond generation, including the
6th generation (6G). VSPs are considered as spectrum leasers to optimize the
overall spectrum efficiency of the network from the perspective of the mobile
network operator (MNO) as the spectrum licensee and auctioneer. We exploit a
modified Vickrey-Clarke-Groves (VCG) auction mechanism to allocate the spectrum
to them where the QoS and the truthfulness of bidders are considered as two
important parameters for prioritization of VSPs. The simulation is done with
the help of deep deterministic policy gradient (DDPG) as a deep reinforcement
learning (DRL)-based algorithm. Simulation results demonstrate that deploying
the DDPG algorithm results in significant advantages. In particular, the
efficiency of the proposed spectrum management scheme is about %85 compared to
the %35 efficiency in traditional auction methods.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06486" title="Abstract">arXiv:2401.06486</a> [<a href="/pdf/2401.06486" title="Download PDF">pdf</a>, <a href="/format/2401.06486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-optimal adaptive FEM with linearization and algebraic solver for  semilinear elliptic PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brunner%2C+M">Maximilian Brunner</a>, 
<a href="/search/math?searchtype=author&query=Praetorius%2C+D">Dirk Praetorius</a>, 
<a href="/search/math?searchtype=author&query=Streitberger%2C+J">Julian Streitberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider scalar semilinear elliptic PDEs, where the nonlinearity is
strongly monotone, but only locally Lipschitz continuous. To linearize the
arising discrete nonlinear problem, we employ a damped Zarantonello iteration,
which leads to a linear Poisson-type equation that is symmetric and positive
definite. The resulting system is solved by a contractive algebraic solver such
as a multigrid method with local smoothing. We formulate a fully adaptive
algorithm that equibalances the various error components coming from mesh
refinement, iterative linearization, and algebraic solver. We prove that the
proposed adaptive iteratively linearized finite element method (AILFEM)
guarantees convergence with optimal complexity, where the rates are understood
with respect to the overall computational cost (i.e., the computational time).
Numerical experiments investigate the involved adaptivity parameters.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06492" title="Abstract">arXiv:2401.06492</a> [<a href="/pdf/2401.06492" title="Download PDF">pdf</a>, <a href="/ps/2401.06492" title="Download PostScript">ps</a>, <a href="/format/2401.06492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust fully discrete error bounds for the Kuznetsov equation in the  inviscid limit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=D%C3%B6rich%2C+B">Benjamin D&#xf6;rich</a>, 
<a href="/search/math?searchtype=author&query=Nikoli%C4%87%2C+V">Vanja Nikoli&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Kuznetsov equation is a classical wave model of acoustics that
incorporates quadratic gradient nonlinearities. When its strong damping
vanishes, it undergoes a singular behavior change, switching from a
parabolic-like to a hyperbolic quasilinear evolution. In this work, we
establish for the first time the optimal error bounds for its finite element
approximation as well as a semi-implicit fully discrete approximation that are
robust with respect to the vanishing damping parameter. The core of the new
arguments lies in devising energy estimates directly for the error equation
where one can more easily exploit the polynomial structure of the
nonlinearities and compensate inverse estimates with smallness conditions on
the error. Numerical experiments are included to illustrate the theoretical
results.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06493" title="Abstract">arXiv:2401.06493</a> [<a href="/pdf/2401.06493" title="Download PDF">pdf</a>, <a href="/format/2401.06493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expected Shapley-Like Scores of Boolean Functions: Complexity and  Applications to Probabilistic Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karmakar%2C+P">Pratik Karmakar</a>, 
<a href="/search/cs?searchtype=author&query=Monet%2C+M">Mika&#xeb;l Monet</a>, 
<a href="/search/cs?searchtype=author&query=Senellart%2C+P">Pierre Senellart</a>, 
<a href="/search/cs?searchtype=author&query=Bressan%2C+S">St&#xe9;phane Bressan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, including 10 pages of maintext
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC)

</div>
<p class="mathjax">Shapley values, originating in game theory and increasingly prominent in
explainable AI, have been proposed to assess the contribution of facts in query
answering over databases, along with other similar power indices such as
Banzhaf values. In this work we adapt these Shapley-like scores to
probabilistic settings, the objective being to compute their expected value. We
show that the computations of expected Shapley values and of the expected
values of Boolean functions are interreducible in polynomial time, thus
obtaining the same tractability landscape. We investigate the specific
tractable case where Boolean functions are represented as deterministic
decomposable circuits, designing a polynomial-time algorithm for this setting.
We present applications to probabilistic databases through database provenance,
and an effective implementation of this algorithm within the ProvSQL system,
which experimentally validates its feasibility over a standard benchmark.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06495" title="Abstract">arXiv:2401.06495</a> [<a href="/pdf/2401.06495" title="Download PDF">pdf</a>, <a href="/format/2401.06495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An investigation of structures responsible for gender bias in BERT and  DistilBERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leteno%2C+T">Thibaud Leteno</a>, 
<a href="/search/cs?searchtype=author&query=Gourru%2C+A">Antoine Gourru</a>, 
<a href="/search/cs?searchtype=author&query=Laclau%2C+C">Charlotte Laclau</a>, 
<a href="/search/cs?searchtype=author&query=Gravier%2C+C">Christophe Gravier</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 21st International Symposium on Intelligent Data Analysis, IDA
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, large Transformer-based Pre-trained Language Models (PLM)
have changed the Natural Language Processing (NLP) landscape, by pushing the
performance boundaries of the state-of-the-art on a wide variety of tasks.
However, this performance gain goes along with an increase in complexity, and
as a result, the size of such models (up to billions of parameters) represents
a constraint for their deployment on embedded devices or short-inference time
tasks. To cope with this situation, compressed models emerged (e.g.
DistilBERT), democratizing their usage in a growing number of applications that
impact our daily lives. A crucial issue is the fairness of the predictions made
by both PLMs and their distilled counterparts. In this paper, we propose an
empirical exploration of this problem by formalizing two questions: (1) Can we
identify the neural mechanism(s) responsible for gender bias in BERT (and by
extension DistilBERT)? (2) Does distillation tend to accentuate or mitigate
gender bias (e.g. is DistilBERT more prone to gender bias than its uncompressed
version, BERT)? Our findings are the following: (I) one cannot identify a
specific layer that produces bias; (II) every attention head uniformly encodes
bias; except in the context of underrepresented classes with a high imbalance
of the sensitive attribute; (III) this subset of heads is different as we
re-fine tune the network; (IV) bias is more homogeneously produced by the heads
in the distilled model.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06498" title="Abstract">arXiv:2401.06498</a> [<a href="/pdf/2401.06498" title="Download PDF">pdf</a>, <a href="/format/2401.06498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal and Between-Group Variability in College Dropout Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glandorf%2C+D">Dominik Glandorf</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H+R">Hye Rin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Orona%2C+G+A">Gabe Avakian Orona</a>, 
<a href="/search/cs?searchtype=author&query=Pumptow%2C+M">Marina Pumptow</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Renzhe Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+C">Christian Fischer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full paper accepted to Learning Analytics and Knowledge (LAK 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large-scale administrative data is a common input in early warning systems
for college dropout in higher education. Still, the terminology and methodology
vary significantly across existing studies, and the implications of different
modeling decisions are not fully understood. This study provides a systematic
evaluation of contributing factors and predictive performance of machine
learning models over time and across different student groups. Drawing on
twelve years of administrative data at a large public university in the US, we
find that dropout prediction at the end of the second year has a 20% higher AUC
than at the time of enrollment in a Random Forest model. Also, most predictive
factors at the time of enrollment, including demographics and high school
performance, are quickly superseded in predictive importance by college
performance and in later stages by enrollment behavior. Regarding variability
across student groups, college GPA has more predictive value for students from
traditionally disadvantaged backgrounds than their peers. These results can
help researchers and administrators understand the comparative value of
different data sources when building early warning systems and optimizing
decisions under specific policy goals.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06503" title="Abstract">arXiv:2401.06503</a> [<a href="/pdf/2401.06503" title="Download PDF">pdf</a>, <a href="/format/2401.06503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Detection of Small Oriented Objects in Aerial Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doloriel%2C+C+T+C">Chandler Timm C. Doloriel</a>, 
<a href="/search/cs?searchtype=author&query=Cajote%2C+R+D">Rhandley D. Cajote</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> C. T. C. Doloriel and R. D. Cajote, "Improving the Detection of Small Oriented Objects in Aerial Images," 2023 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW), Waikoloa, HI, USA, 2023, pp. 176-185, doi: 10.1109/WACVW58289.<a href="/abs/2023.00023">2023.00023</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Small oriented objects that represent tiny pixel-area in large-scale aerial
images are difficult to detect due to their size and orientation. Existing
oriented aerial detectors have shown promising results but are mainly focused
on orientation modeling with less regard to the size of the objects. In this
work, we proposed a method to accurately detect small oriented objects in
aerial images by enhancing the classification and regression tasks of the
oriented object detection model. We designed the Attention-Points Network
consisting of two losses: Guided-Attention Loss (GALoss) and Box-Points Loss
(BPLoss). GALoss uses an instance segmentation mask as ground-truth to learn
the attention features needed to improve the detection of small objects. These
attention features are then used to predict box points for BPLoss, which
determines the points' position relative to the target oriented bounding box.
Experimental results show the effectiveness of our Attention-Points Network on
a standard oriented aerial dataset with small object instances (DOTA-v1.5) and
on a maritime-related dataset (HRSC2016). The code is publicly available.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06506" title="Abstract">arXiv:2401.06506</a> [<a href="/pdf/2401.06506" title="Download PDF">pdf</a>, <a href="/format/2401.06506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency Masking for Universal Deepfake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doloriel%2C+C+T">Chandler Timm Doloriel</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+N">Ngai-Man Cheung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We study universal deepfake detection. Our goal is to detect synthetic images
from a range of generative AI approaches, particularly from emerging ones which
are unseen during training of the deepfake detector. Universal deepfake
detection requires outstanding generalization capability. Motivated by recently
proposed masked image modeling which has demonstrated excellent generalization
in self-supervised pre-training, we make the first attempt to explore masked
image modeling for universal deepfake detection. We study spatial and frequency
domain masking in training deepfake detectors. Based on empirical analysis, we
propose a novel deepfake detector via frequency masking. Our focus on frequency
domain is different from the majority, which primarily target spatial domain
detection. Our comparative analyses reveal substantial performance gains over
existing methods. Code and models are publicly available.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06508" title="Abstract">arXiv:2401.06508</a> [<a href="/pdf/2401.06508" title="Download PDF">pdf</a>, <a href="/format/2401.06508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Layout Effects for Analog Logic Locking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aljafar%2C+M+J">Muayad J. Aljafar</a>, 
<a href="/search/cs?searchtype=author&query=Azais%2C+F">Florence Azais</a>, 
<a href="/search/cs?searchtype=author&query=Flottes%2C+M">Marie-Lise Flottes</a>, 
<a href="/search/cs?searchtype=author&query=Pagliarini%2C+S">Samuel Pagliarini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> JCEN special issue from ASHES'22
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">While numerous obfuscation techniques are available for securing digital
assets in the digital domain, there has been a notable lack of focus on
protecting Intellectual Property (IP) in the analog domain. This is primarily
due to the relatively smaller footprint of analog components within an
Integrated Circuit (IC), with the majority of the surface dedicated to digital
elements. However, despite their smaller nature, analog components are highly
valuable IP and warrant effective protection. In this paper, we present a
groundbreaking method for safeguarding analog IP by harnessing layout-based
effects that are typically considered undesirable in IC design. Specifically,
we exploit the impact of Length of Oxide Diffusion and Well Proximity Effect on
transistors to fine-tune critical parameters such as transconductance (gm) and
threshold voltage (Vth). These parameters remain concealed behind key inputs,
akin to the logic locking approach employed in digital ICs. Our research
explores the application of layout-based effects in two commercial CMOS
technologies, namely a 28nm and a 65nm node. To demonstrate the efficacy of our
proposed technique, we implement it for locking an Operational Transconductance
Amplifier. Extensive simulations are performed, evaluating the obfuscation
strength by applying a large number of key sets (over 50,000 and 300,000). The
results exhibit a significant degradation in performance metrics, such as
open-loop gain (up to 130dB), phase margin (up to 50 degrees), 3dB bandwidth
(approximately 2.5MHz), and power consumption (around 1mW) when incorrect keys
are employed. Our findings highlight the advantages of our approach as well as
the associated overhead.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06509" title="Abstract">arXiv:2401.06509</a> [<a href="/pdf/2401.06509" title="Download PDF">pdf</a>, <a href="/format/2401.06509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AntEval: Quantitatively Evaluating Informativeness and Expressiveness of  Agent Social Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuanzhi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Linchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version of an ongoing work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While Large Language Models (LLMs) based agents have successfully mimicked
human behaviors in various scenarios, the realm of complex, multi-character
social interactions within extended contexts remains underexplored. The
challenge is compounded by privacy concerns, making it difficult to capture and
utilize intricate real-life interactions. More importantly, the absence of
quantitative evaluation methods hampers the pursuit of high-quality agent
interactions, often leading to interactions that are limited in informativeness
and expressiveness, characterized by superficial small talk without clear
intentions. In this work, we leverage the rules of Tabletop Role-Playing Games
(TRPG) to create an environment conducive to complex, context-rich
interactions, emphasizing informativeness and expressiveness. This virtual
setting alleviates privacy concerns and motivates agents to engage in
meaningful, high-quality interactions as part of their in-game objectives. To
assess these interactions, we introduce the Agent interaction Evaluation
framework (AntEval), targeting the qualitative evaluation of interaction
informativeness and expressiveness. Specifically, we propose two novel
evaluation metrics: Information Exchanging Precision (IEP) and Interaction
Expressiveness Gap (IEG). These metrics are designed to assess interactions in
scenarios focused on information exchange and intention expression,
respectively. Our experimental results demonstrate the effectiveness of these
metrics in evaluating interaction quality. Notably, we identify significant
areas for improvement in LLMs regarding social interactions, as highlighted by
our metrics. We believe AntEval will guide further exploration in complex agent
interactions, bringing them closer to emulating real human behavior and
enhancing their integration and utility in real-world applications.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06512" title="Abstract">arXiv:2401.06512</a> [<a href="/pdf/2401.06512" title="Download PDF">pdf</a>, <a href="/format/2401.06512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Optimal Randomized Algorithm for Finding the Saddlepoint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dallant%2C+J">Justin Dallant</a>, 
<a href="/search/cs?searchtype=author&query=Haagensen%2C+F">Frederik Haagensen</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+R">Riko Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Kozma%2C+L">L&#xe1;szl&#xf3; Kozma</a>, 
<a href="/search/cs?searchtype=author&query=Wild%2C+S">Sebastian Wild</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">A \emph{saddlepoint} of an $n \times n$ matrix is an entry that is the
maximum of its row and the minimum of its column. Saddlepoints give the
\emph{value} of a two-player zero-sum game, corresponding to its pure-strategy
Nash equilibria; efficiently finding a saddlepoint is thus a natural and
fundamental algorithmic task.
<br />For finding a \emph{strict saddlepoint} (an entry that is the strict maximum
of its row and the strict minimum of its column) we recently gave an
$O({n\log^*{n}})$-time algorithm, improving the $O({n\log{n}})$ bounds from
1991 of Bienstock, Chung, Fredman, Sch\"affer, Shor, Suri and of Byrne and
Vaserstein.
<br />In this paper we present an optimal $O({n})$-time algorithm for finding a
strict saddlepoint based on random sampling. Our algorithm, like earlier
approaches, accesses matrix entries only via unit-cost binary comparisons. For
finding a (non-strict) saddlepoint, we extend an existing lower bound to
randomized algorithms, showing that the trivial $O(n^2)$ runtime cannot be
improved even with the use of randomness.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06513" title="Abstract">arXiv:2401.06513</a> [<a href="/pdf/2401.06513" title="Download PDF">pdf</a>, <a href="/format/2401.06513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ML-On-Rails: Safeguarding Machine Learning Models in Software Systems A  Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelkader%2C+H">Hala Abdelkader</a>, 
<a href="/search/cs?searchtype=author&query=Abdelrazek%2C+M">Mohamed Abdelrazek</a>, 
<a href="/search/cs?searchtype=author&query=Barnett%2C+S">Scott Barnett</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jean-Guy Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Rani%2C+P">Priya Rani</a>, 
<a href="/search/cs?searchtype=author&query=Vasa%2C+R">Rajesh Vasa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning (ML), especially with the emergence of large language models
(LLMs), has significantly transformed various industries. However, the
transition from ML model prototyping to production use within software systems
presents several challenges. These challenges primarily revolve around ensuring
safety, security, and transparency, subsequently influencing the overall
robustness and trustworthiness of ML models. In this paper, we introduce
ML-On-Rails, a protocol designed to safeguard ML models, establish a
well-defined endpoint interface for different ML tasks, and clear communication
between ML providers and ML consumers (software engineers). ML-On-Rails
enhances the robustness of ML models via incorporating detection capabilities
to identify unique challenges specific to production ML. We evaluated the
ML-On-Rails protocol through a real-world case study of the MoveReminder
application. Through this evaluation, we emphasize the importance of
safeguarding ML models in production.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06514" title="Abstract">arXiv:2401.06514</a> [<a href="/pdf/2401.06514" title="Download PDF">pdf</a>, <a href="/format/2401.06514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Reinforcement Learning with a Budget of Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+D">Dmitry Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Porat%2C+O">Omer Ben-Porat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024. Code: <a href="https://github.com/dimonenka/RL_policy_budget">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Personalization in machine learning (ML) tailors models' decisions to the
individual characteristics of users. While this approach has seen success in
areas like recommender systems, its expansion into high-stakes fields such as
healthcare and autonomous driving is hindered by the extensive regulatory
approval processes involved. To address this challenge, we propose a novel
framework termed represented Markov Decision Processes (r-MDPs) that is
designed to balance the need for personalization with the regulatory
constraints. In an r-MDP, we cater to a diverse user population, each with
unique preferences, through interaction with a small set of representative
policies. Our objective is twofold: efficiently match each user to an
appropriate representative policy and simultaneously optimize these policies to
maximize overall social welfare. We develop two deep reinforcement learning
algorithms that efficiently solve r-MDPs. These algorithms draw inspiration
from the principles of classic K-means clustering and are underpinned by robust
theoretical foundations. Our empirical investigations, conducted across a
variety of simulated environments, showcase the algorithms' ability to
facilitate meaningful personalization even under constrained policy budgets.
Furthermore, they demonstrate scalability, efficiently adapting to larger
policy budgets.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06518" title="Abstract">arXiv:2401.06518</a> [<a href="/pdf/2401.06518" title="Download PDF">pdf</a>, <a href="/format/2401.06518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transitional Grid Maps: Efficient Analytical Inference of Dynamic  Environments under Limited Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+J+M+G">Jos&#xe9; Manuel Gaspar S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Bruns%2C+L">Leonard Bruns</a>, 
<a href="/search/cs?searchtype=author&query=Tumova%2C+J">Jana Tumova</a>, 
<a href="/search/cs?searchtype=author&query=Jensfelt%2C+P">Patric Jensfelt</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B6rngren%2C+M">Martin T&#xf6;rngren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous agents rely on sensor data to construct representations of their
environment, essential for predicting future events and planning their own
actions. However, sensor measurements suffer from limited range, occlusions,
and sensor noise. These challenges become more evident in dynamic environments,
where efficiently inferring the state of the environment based on sensor
readings from different times is still an open problem. This work focuses on
inferring the state of the dynamic part of the environment, i.e., where dynamic
objects might be, based on previous observations and constraints on their
dynamics. We formalize the problem and introduce Transitional Grid Maps (TGMs),
an efficient analytical solution. TGMs are based on a set of novel assumptions
that hold in many practical scenarios. They significantly reduce the complexity
of the problem, enabling continuous prediction and updating of the entire
dynamic map based on the known static map (see Fig.1), differentiating them
from other alternatives. We compare our approach with a state-of-the-art
particle filter, obtaining more prudent predictions in occluded scenarios and
on-par results on unoccluded tracking.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06519" title="Abstract">arXiv:2401.06519</a> [<a href="/pdf/2401.06519" title="Download PDF">pdf</a>, <a href="/ps/2401.06519" title="Download PostScript">ps</a>, <a href="/format/2401.06519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graded modal logic and counting message passing automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahvonen%2C+V">Veeti Ahvonen</a>, 
<a href="/search/cs?searchtype=author&query=Heiman%2C+D">Damian Heiman</a>, 
<a href="/search/cs?searchtype=author&query=Kuusisto%2C+A">Antti Kuusisto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We examine the relationship of graded (multi)modal logic to counting
(multichannel) message passing automata with applications to the
Weisfeiler-Leman algorithm. We introduce the notion of graded multimodal types,
which are formulae of graded multimodal logic that encode the local information
of a pointed Kripke-model. We also introduce message passing automata that
carry out a generalization of the Weisfeiler-Leman algorithm for distinguishing
non-isomorphic graph nodes. We show that the classes of pointed Kripke-models
recognizable by these automata are definable by a countable (possibly infinite)
disjunction of graded multimodal formulae and vice versa. In particular, this
equivalence also holds between recursively enumerable disjunctions and
recursively enumerable automata. We also show a way of carrying out the
Weisfeiler-Leman algorithm with a formula of first order logic that has been
augmented with H\"artig's quantifier and greatest fixed points.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06521" title="Abstract">arXiv:2401.06521</a> [<a href="/pdf/2401.06521" title="Download PDF">pdf</a>, <a href="/format/2401.06521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Diverse Representations for Open Set Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+J">Junxian Mu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Pengfei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghua Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures. Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open set recognition (OSR) requires the model to classify samples that belong
to closed sets while rejecting unknown samples during test. Currently,
generative models often perform better than discriminative models in OSR, but
recent studies show that generative models may be computationally infeasible or
unstable on complex tasks. In this paper, we provide insights into OSR and find
that learning supplementary representations can theoretically reduce the open
space risk. Based on the analysis, we propose a new model, namely Multi-Expert
Diverse Attention Fusion (MEDAF), that learns diverse representations in a
discriminative way. MEDAF consists of multiple experts that are learned with an
attention diversity regularization term to ensure the attention maps are
mutually different. The logits learned by each expert are adaptively fused and
used to identify the unknowns through the score function. We show that the
differences in attention maps can lead to diverse representations so that the
fused representations can well handle the open space. Extensive experiments are
conducted on standard and OSR large-scale benchmarks. Results show that the
proposed discriminative method can outperform existing generative models by up
to 9.5% on AUROC and achieve new state-of-the-art performance with little
computational cost. Our method can also seamlessly integrate existing
classification models. Code is available at https://github.com/Vanixxz/MEDAF.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06524" title="Abstract">arXiv:2401.06524</a> [<a href="/pdf/2401.06524" title="Download PDF">pdf</a>, <a href="/ps/2401.06524" title="Download PostScript">ps</a>, <a href="/format/2401.06524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptation for Time series Transformers using One-step  fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khanal%2C+S">Subina Khanal</a>, 
<a href="/search/cs?searchtype=author&query=Tirupathi%2C+S">Seshu Tirupathi</a>, 
<a href="/search/cs?searchtype=author&query=Zizzo%2C+G">Giulio Zizzo</a>, 
<a href="/search/cs?searchtype=author&query=Rawat%2C+A">Ambrish Rawat</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+T+B">Torben Bach Pedersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Fourth Workshop of Artificial Intelligence for Time Series Analysis (AI4TS): Theory, Algorithms, and Applications, AAAI 2024, Vancouver, Canada
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The recent breakthrough of Transformers in deep learning has drawn
significant attention of the time series community due to their ability to
capture long-range dependencies. However, like other deep learning models,
Transformers face limitations in time series prediction, including insufficient
temporal understanding, generalization challenges, and data shift issues for
the domains with limited data. Additionally, addressing the issue of
catastrophic forgetting, where models forget previously learned information
when exposed to new data, is another critical aspect that requires attention in
enhancing the robustness of Transformers for time series tasks. To address
these limitations, in this paper, we pre-train the time series Transformer
model on a source domain with sufficient data and fine-tune it on the target
domain with limited data. We introduce the \emph{One-step fine-tuning}
approach, adding some percentage of source domain data to the target domains,
providing the model with diverse time series instances. We then fine-tune the
pre-trained model using a gradual unfreezing technique. This helps enhance the
model's performance in time series prediction for domains with limited data.
Extensive experimental results on two real-world datasets show that our
approach improves over the state-of-the-art baselines by 4.35% and 11.54% for
indoor temperature and wind power prediction, respectively.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06526" title="Abstract">arXiv:2401.06526</a> [<a href="/pdf/2401.06526" title="Download PDF">pdf</a>, <a href="/format/2401.06526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaHate: A Dataset for Unifying Efforts on Hate Speech Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piot%2C+P">Paloma Piot</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn-Rodilla%2C+P">Patricia Mart&#xed;n-Rodilla</a>, 
<a href="/search/cs?searchtype=author&query=Parapar%2C+J">Javier Parapar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Hate speech represents a pervasive and detrimental form of online discourse,
often manifested through an array of slurs, from hateful tweets to defamatory
posts. As such speech proliferates, it connects people globally and poses
significant social, psychological, and occasionally physical threats to
targeted individuals and communities. Current computational linguistic
approaches for tackling this phenomenon rely on labelled social media datasets
for training. For unifying efforts, our study advances in the critical need for
a comprehensive meta-collection, advocating for an extensive dataset to help
counteract this problem effectively. We scrutinized over 60 datasets,
selectively integrating those pertinent into MetaHate. This paper offers a
detailed examination of existing collections, highlighting their strengths and
limitations. Our findings contribute to a deeper understanding of the existing
datasets, paving the way for training more robust and adaptable models. These
enhanced models are essential for effectively combating the dynamic and complex
nature of hate speech in the digital realm.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06528" title="Abstract">arXiv:2401.06528</a> [<a href="/pdf/2401.06528" title="Download PDF">pdf</a>, <a href="/format/2401.06528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCB-Vision: A Multiscene RGB-Hyperspectral Benchmark Dataset of Printed  Circuit Boards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arbash%2C+E">Elias Arbash</a>, 
<a href="/search/cs?searchtype=author&query=Fuchs%2C+M">Margret Fuchs</a>, 
<a href="/search/cs?searchtype=author&query=Rasti%2C+B">Behnood Rasti</a>, 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+S">Sandra Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Ghamisi%2C+P">Pedram Ghamisi</a>, 
<a href="/search/cs?searchtype=author&query=Gloaguen%2C+R">Richard Gloaguen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Addressing the critical theme of recycling electronic waste (E-waste), this
contribution is dedicated to developing advanced automated data processing
pipelines as a basis for decision-making and process control. Aligning with the
broader goals of the circular economy and the United Nations (UN) Sustainable
Development Goals (SDG), our work leverages non-invasive analysis methods
utilizing RGB and hyperspectral imaging data to provide both quantitative and
qualitative insights into the E-waste stream composition for optimizing
recycling efficiency. In this paper, we introduce 'PCB-Vision'; a pioneering
RGB-hyperspectral printed circuit board (PCB) benchmark dataset, comprising 53
RGB images of high spatial resolution paired with their corresponding high
spectral resolution hyperspectral data cubes in the visible and near-infrared
(VNIR) range. Grounded in open science principles, our dataset provides a
comprehensive resource for researchers through high-quality ground truths,
focusing on three primary PCB components: integrated circuits (IC), capacitors,
and connectors. We provide extensive statistical investigations on the proposed
dataset together with the performance of several state-of-the-art (SOTA)
models, including U-Net, Attention U-Net, Residual U-Net, LinkNet, and
DeepLabv3+. By openly sharing this multi-scene benchmark dataset along with the
baseline codes, we hope to foster transparent, traceable, and comparable
developments of advanced data processing across various scientific communities,
including, but not limited to, computer vision and remote sensing. Emphasizing
our commitment to supporting a collaborative and inclusive scientific
community, all materials, including code, data, ground truth, and masks, will
be accessible at https://github.com/hifexplo/PCBVision.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06529" title="Abstract">arXiv:2401.06529</a> [<a href="/pdf/2401.06529" title="Download PDF">pdf</a>, <a href="/format/2401.06529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Industrial Challenges in Secure Continuous Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moy%C3%B3n%2C+F">Fabiola Moy&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Angermeir%2C+F">Florian Angermeir</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+D">Daniel Mendez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The intersection between security and continuous software engineering has
been of great interest since the early years of the agile development movement,
and it remains relevant as software development processes are more frequently
guided by agility and the adoption of DevOps. Several authors have contributed
studies about the framing of secure agile development and secure DevOps,
motivating academic contributions to methods and practices, but also
discussions around benefits and challenges. Especially the challenges captured
also our interest since, for the last few years, we are conducting research on
secure continuous software engineering from a more applied, practical
perspective with the overarching aim to introduce solutions that can be adopted
at scale. The short positioning at hands summarizes a relevant part of our
endeavors in which we validated challenges with several practitioners of
different roles. More than framing a set of challenges, we conclude by
presenting four key research directions we identified for practitioners and
researchers to delineate future work.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06532" title="Abstract">arXiv:2401.06532</a> [<a href="/pdf/2401.06532" title="Download PDF">pdf</a>, <a href="/format/2401.06532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INTERS: Unlocking the Power of Large Language Models in Search with  Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yutao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Binyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhicheng Dou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated impressive capabilities in
various natural language processing tasks. Despite this, their application to
information retrieval (IR) tasks is still challenging due to the infrequent
occurrence of many IR-specific concepts in natural language. While prompt-based
methods can provide task descriptions to LLMs, they often fall short in
facilitating comprehensive understanding and execution of IR tasks, thereby
limiting LLMs' applicability. To address this gap, in this work, we explore the
potential of instruction tuning to enhance LLMs' proficiency in IR tasks. We
introduce a novel instruction tuning dataset, INTERS, encompassing 21 tasks
across three fundamental IR categories: query understanding, document
understanding, and query-document relationship understanding. The data are
derived from 43 distinct datasets with manually written templates. Our
empirical results reveal that INTERS significantly boosts the performance of
various publicly available LLMs, such as LLaMA, Mistral, and Phi, in
search-related tasks. Furthermore, we conduct a comprehensive analysis to
ascertain the effects of base model selection, instruction design, volume of
instructions, and task variety on performance. We make our dataset and the
models fine-tuned on it publicly accessible at https://github.com/DaoD/INTERS.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06538" title="Abstract">arXiv:2401.06538</a> [<a href="/pdf/2401.06538" title="Download PDF">pdf</a>, <a href="/format/2401.06538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Data-Driven Architectural Features Orchestration for Network  Slicing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moreira%2C+R">Rodrigo Moreira</a>, 
<a href="/search/cs?searchtype=author&query=de+Oliveira+Silva%2C+F">Flavio de Oliveira Silva</a>, 
<a href="/search/cs?searchtype=author&query=de+Brito+Carvalho%2C+T+C+M">Tereza Cristina Melo de Brito Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+J+S+B">Joberto S. B. Martins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, Conference ADVANCE 24 - International Workshop on ADVANCEs in ICT Infrastructures and Services - February 26--29, 2024 - Hanoi, Vietnam
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Network slicing is a crucial enabler and a trend for the Next Generation
Mobile Network (NGMN) and various other new systems like the Internet of
Vehicles (IoV) and Industrial IoT (IIoT). Orchestration and machine learning
are key elements with a crucial role in the network-slicing processes since the
NS process needs to orchestrate resources and functionalities, and machine
learning can potentially optimize the orchestration process. However, existing
network-slicing architectures lack the ability to define intelligent approaches
to orchestrate features and resources in the slicing process. This paper
discusses machine learning-based orchestration of features and capabilities in
network slicing architectures. Initially, the slice resource orchestration and
allocation in the slicing planning, configuration, commissioning, and operation
phases are analyzed. In sequence, we highlight the need for optimized
architectural feature orchestration and recommend using ML-embed agents,
federated learning intrinsic mechanisms for knowledge acquisition, and a
data-driven approach embedded in the network slicing architecture. We further
develop an architectural features orchestration case embedded in the SFI2
network slicing architecture. An attack prevention security mechanism is
developed for the SFI2 architecture using distributed embedded and cooperating
ML agents. The case presented illustrates the architectural feature's
orchestration process and benefits, highlighting its importance for the network
slicing process.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06541" title="Abstract">arXiv:2401.06541</a> [<a href="/pdf/2401.06541" title="Download PDF">pdf</a>, <a href="/format/2401.06541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical Dialogue Generation via Intuitive-then-Analytical Differential  Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaishuai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+W">Wenjun Hou</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Medical dialogue systems have attracted growing research attention as they
have the potential to provide rapid diagnoses, treatment plans, and health
consultations. In medical dialogues, a proper diagnosis is crucial as it
establishes the foundation for future consultations. Clinicians typically
employ both intuitive and analytic reasoning to formulate a differential
diagnosis. This reasoning process hypothesizes and verifies a variety of
possible diseases and strives to generate a comprehensive and rigorous
diagnosis. However, recent studies on medical dialogue generation have
overlooked the significance of modeling a differential diagnosis, which hinders
the practical application of these systems. To address the above issue, we
propose a medical dialogue generation framework with the
Intuitive-then-Analytic Differential Diagnosis (IADDx). Our method starts with
a differential diagnosis via retrieval-based intuitive association and
subsequently refines it through a graph-enhanced analytic procedure. The
resulting differential diagnosis is then used to retrieve medical knowledge and
guide response generation. Experimental results on two datasets validate the
efficacy of our method. Besides, we demonstrate how our framework assists both
clinicians and patients in understanding the diagnostic process, for instance,
by producing intermediate results and graph-based diagnosis paths.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06542" title="Abstract">arXiv:2401.06542</a> [<a href="/pdf/2401.06542" title="Download PDF">pdf</a>, <a href="/format/2401.06542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness-Aware 3D Object Detection in Autonomous Driving: A Review and  Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Ziying Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+F">Feiyang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yadan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guoxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Caiyan Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the realm of modern autonomous driving, the perception system is
indispensable for accurately assessing the state of the surrounding
environment, thereby enabling informed prediction and planning. Key to this
system is 3D object detection methods, that utilize vehicle-mounted sensors
such as LiDAR and cameras to identify the size, category, and location of
nearby objects. Despite the surge in 3D object detection methods aimed at
enhancing detection precision and efficiency, there is a gap in the literature
that systematically examines their resilience against environmental variations,
noise, and weather changes. This study emphasizes the importance of robustness,
alongside accuracy and latency, in evaluating perception systems under
practical scenarios. Our work presents an extensive survey of camera-based,
LiDAR-based, and multimodal 3D object detection algorithms, thoroughly
evaluating their trade-off between accuracy, latency, and robustness,
particularly on datasets like KITTI-C and nuScenes-C to ensure fair
comparisons. Among these,multimodal 3D detection approaches exhibit superior
robustness and a novel taxonomy is introduced to reorganize its literature for
enhanced clarity. This survey aims to offer a more practical perspective on the
current capabilities and constraints of 3D object detection algorithms in
real-world applications, thus steering future research towards
robustness-centric advancements
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06546" title="Abstract">arXiv:2401.06546</a> [<a href="/pdf/2401.06546" title="Download PDF">pdf</a>, <a href="/ps/2401.06546" title="Download PostScript">ps</a>, <a href="/format/2401.06546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Feature Selection for Binary Classification with Noisy  Labels: A Genetic Algorithm Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imani%2C+V">Vandad Imani</a>, 
<a href="/search/cs?searchtype=author&query=Moradi%2C+E">Elaheh Moradi</a>, 
<a href="/search/cs?searchtype=author&query=Sevilla-Salcedo%2C+C">Carlos Sevilla-Salcedo</a>, 
<a href="/search/cs?searchtype=author&query=Fortino%2C+V">Vittorio Fortino</a>, 
<a href="/search/cs?searchtype=author&query=Tohka%2C+J">Jussi Tohka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Feature selection in noisy label scenarios remains an understudied topic. We
propose a novel genetic algorithm-based approach, the Noise-Aware
Multi-Objective Feature Selection Genetic Algorithm (NMFS-GA), for selecting
optimal feature subsets in binary classification with noisy labels. NMFS-GA
offers a unified framework for selecting feature subsets that are both accurate
and interpretable. We evaluate NMFS-GA on synthetic datasets with label noise,
a Breast Cancer dataset enriched with noisy features, and a real-world ADNI
dataset for dementia conversion prediction. Our results indicate that NMFS-GA
can effectively select feature subsets that improve the accuracy and
interpretability of binary classifiers in scenarios with noisy labels.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06547" title="Abstract">arXiv:2401.06547</a> [<a href="/pdf/2401.06547" title="Download PDF">pdf</a>, <a href="/ps/2401.06547" title="Download PostScript">ps</a>, <a href="/format/2401.06547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are We Still Missing an Item?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Magen%2C+R">Roey Magen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The missing item problem, as introduced by Stoeckl in his work at SODA 23,
focuses on continually identifying a missing element $e$ in a stream of
elements ${e_1, ..., e_{\ell}}$ from the set $\{1,2,...,n\}$, such that $e \neq
e_i$ for any $i \in \{1,...,n\}$. Stoeckl's investigation primarily delves into
scenarios with $\ell&lt;n$, providing bounds for the (i) deterministic case, (ii)
the static case -- where the algorithm might be randomized but the stream is
fixed in advanced) and (iii) the adversarially robust case -- where the
algorithm is randomized and each stream element can be chosen depending on
earlier algorithm outputs. Building upon this foundation, our paper addresses
previously unexplored aspects of the missing item problem.
<br />In the first segment, we examine the static setting with a long stream, where
the length of the steam $\ell$ is close to or even exceeds the size of the
universe $n$. We present an algorithm demonstrating that even when $\ell$ is
very close to $n$ (say $\ell=n-1$), polylog($n$) bits of memory suffice to
identify the missing item. Additionally, we establish tight bounds of
$\tilde{\Theta(k)}$ for the scenario of $\ell = n+k$.
<br />The second segment of this part of our work focuses on the {\em adversarially
robust setting}. We show a lower bound for a pseudo-deterministic error-zero
(where the algorithm reports its errors) algorithm of approximating
$\Omega(\ell)$, up to polylog factors. Based on Stoeckl's work, we establish a
lower bound for a random-start (only use randomness at initialization)
error-zero streaming algorithm.
<br />In the final segment, we explore streaming algorithms with
randomness-on-the-fly, where the random bits that are saved for future use are
included in the space cost. For streams with length $\ell = O(\sqrt{n})$, we
provide an upper bound of $O(log n)$. This establishes a gap between
randomness-on-the-fly to random-start.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06548" title="Abstract">arXiv:2401.06548</a> [<a href="/pdf/2401.06548" title="Download PDF">pdf</a>, <a href="/format/2401.06548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Consistency and Mitigating Bias: A Data Replay Approach for  Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xingyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning systems are prone to catastrophic forgetting when learning from
a sequence of tasks, where old data from experienced tasks is unavailable when
learning from a new task. To mitigate the problem, a line of methods propose to
replay the data of experienced tasks when learning new tasks. These methods
usually adopt an extra memory to store the data for replay. However, it is not
expected in practice considering the memory constraint or data privacy issue.
As a replacement, data-free data replay methods are proposed by inverting
samples from the classification model. Though achieving good results, these
methods still suffer from the inconsistency of the inverted and real training
data, which is neglected in the inversion stage in recent works. To that
effect, we propose to measure the data consistency quantitatively by some
simplification and assumptions. Using the measurement, we analyze existing
techniques for inverting samples and get some insightful information that
inspires a novel loss function to reduce the inconsistency. Specifically, the
loss minimizes the KL divergence of the distributions of inverted and real data
under the tied multivariate Gaussian assumption, which is easy to implement in
continual learning. In addition, we observe that the norms of old class weights
turn to decrease continually as learning progresses. We thus analyze the
underlying reasons and propose a simple regularization term to balance the
class weights so that the samples of old classes are more distinguishable. To
conclude, we propose the Consistency enhanced data replay with debiased
classifier for Class Incremental Learning (CCIL). Extensive experiments on
CIFAR-100, Tiny-ImageNet, and ImageNet100 show consistently improved
performance of CCIL compared to previous approaches.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06550" title="Abstract">arXiv:2401.06550</a> [<a href="/pdf/2401.06550" title="Download PDF">pdf</a>, <a href="/ps/2401.06550" title="Download PostScript">ps</a>, <a href="/format/2401.06550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Learning for detecting urban functional zones using remote  sensing image and multi-semantic information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuanji Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaotuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qiqi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Urban area-of-interest (AOI) refers to an integrated urban functional zone
with defined boundaries. The rapid development of urban commerce has resulted
in an increased demand for more precise requirements in defining AOIs. However,
existing research primarily concentrates on broad AOI mining for urban planning
or regional economic analysis, failing to cater to the precise requirements of
mobile Internet online-to-offline businesses. These businesses necessitate
accuracy down to a specific community, school, or hospital. In this paper, we
propose an end-to-end multimodal deep learning algorithm for detecting AOI
fence polygon using remote sensing images and multi-semantics reference
information. We then evaluate its timeliness through a cascaded module that
incorporates dynamic human mobility and logistics address information.
Specifically, we begin by selecting a point-of-interest (POI) of specific
category, and use it to recall corresponding remote sensing images, nearby
POIs, road nodes, human mobility, and logistics addresses to build a multimodal
detection model based on transformer encoder-decoder architecture, titled
AOITR. In the model, in addition to the remote sensing images, multi-semantic
information including core POI and road nodes is embedded and reorganized as
the query content part for the transformer decoder to generate the AOI polygon.
Meanwhile, relatively dynamic distribution features of human mobility, nearby
POIs, and logistics addresses are used for AOI reliability evaluation through a
cascaded feedforward network. The experimental results demonstrate that our
algorithm significantly outperforms two existing methods.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06557" title="Abstract">arXiv:2401.06557</a> [<a href="/pdf/2401.06557" title="Download PDF">pdf</a>, <a href="/format/2401.06557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Treatment-Aware Hyperbolic Representation Learning for Causal Effect  Estimation with Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Ziqiang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yang Qiao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bowei He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiuqiang He</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chen Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SIAM SDM'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Methodology (stat.ME)

</div>
<p class="mathjax">Estimating the individual treatment effect (ITE) from observational data is a
crucial research topic that holds significant value across multiple domains.
How to identify hidden confounders poses a key challenge in ITE estimation.
Recent studies have incorporated the structural information of social networks
to tackle this challenge, achieving notable advancements. However, these
methods utilize graph neural networks to learn the representation of hidden
confounders in Euclidean space, disregarding two critical issues: (1) the
social networks often exhibit a scalefree structure, while Euclidean embeddings
suffer from high distortion when used to embed such graphs, and (2) each
ego-centric network within a social network manifests a treatment-related
characteristic, implying significant patterns of hidden confounders. To address
these issues, we propose a novel method called Treatment-Aware Hyperbolic
Representation Learning (TAHyper). Firstly, TAHyper employs the hyperbolic
space to encode the social networks, thereby effectively reducing the
distortion of confounder representation caused by Euclidean embeddings.
Secondly, we design a treatment-aware relationship identification module that
enhances the representation of hidden confounders by identifying whether an
individual and her neighbors receive the same treatment. Extensive experiments
on two benchmark datasets are conducted to demonstrate the superiority of our
method.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06559" title="Abstract">arXiv:2401.06559</a> [<a href="/pdf/2401.06559" title="Download PDF">pdf</a>, <a href="/ps/2401.06559" title="Download PostScript">ps</a>, <a href="/format/2401.06559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Benchmark Framework is Dynamic Graph Neural Network Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yusen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Dynamic graph learning is crucial for modeling real-world systems with
evolving relationships and temporal dynamics. However, the lack of a unified
benchmark framework in current research has led to inaccurate evaluations of
dynamic graph models. This paper highlights the significance of dynamic graph
learning and its applications in various domains. It emphasizes the need for a
standardized benchmark framework that captures temporal dynamics, evolving
graph structures, and downstream task requirements. Establishing a unified
benchmark will help researchers understand the strengths and limitations of
existing models, foster innovation, and advance dynamic graph learning. In
conclusion, this paper identifies the lack of a standardized benchmark
framework as a current limitation in dynamic graph learning research . Such a
framework will facilitate accurate model evaluation, drive advancements in
dynamic graph learning techniques, and enable the development of more effective
models for real-world applications.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06561" title="Abstract">arXiv:2401.06561</a> [<a href="/pdf/2401.06561" title="Download PDF">pdf</a>, <a href="/format/2401.06561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intention Analysis Prompting Makes Large Language Models A Good  Jailbreak Defender
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lefei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Aligning large language models (LLMs) with human values, particularly in the
face of stealthy and complex jailbreaks, presents a formidable challenge. In
this study, we present a simple yet highly effective defense strategy, i.e.,
Intention Analysis Prompting (IAPrompt). The principle behind is to trigger
LLMs' inherent self-correct and improve ability through a two-stage process: 1)
essential intention analysis, and 2) policy-aligned response. Notably, IAPrompt
is an inference-only method, thus could enhance the safety of LLMs without
compromising their helpfulness. Extensive experiments on SAP200 and DAN
benchmarks across Vicuna, ChatGLM, MPT, DeepSeek, and GPT-3.5 show that
IAPrompt could consistently and significantly reduce the harmfulness in
response (averagely -46.5% attack success rate) and maintain the general
helpfulness. Further analyses present some insights into how our method works.
To facilitate reproducibility, We release our code and scripts at:
https://github.com/alphadl/SafeLLM_with_IntentionAnalysis
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06563" title="Abstract">arXiv:2401.06563</a> [<a href="/pdf/2401.06563" title="Download PDF">pdf</a>, <a href="/format/2401.06563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource-Efficient Gesture Recognition using Low-Resolution Thermal  Camera via Spiking Neural Networks and Sparse Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Safa%2C+A">Ali Safa</a>, 
<a href="/search/cs?searchtype=author&query=Mommen%2C+W">Wout Mommen</a>, 
<a href="/search/cs?searchtype=author&query=Keuninckx%2C+L">Lars Keuninckx</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This work proposes a novel approach for hand gesture recognition using an
inexpensive, low-resolution (24 x 32) thermal sensor processed by a Spiking
Neural Network (SNN) followed by Sparse Segmentation and feature-based gesture
classification via Robust Principal Component Analysis (R-PCA). Compared to the
use of standard RGB cameras, the proposed system is insensitive to lighting
variations while being significantly less expensive compared to high-frequency
radars, time-of-flight cameras and high-resolution thermal sensors previously
used in literature. Crucially, this paper shows that the innovative use of the
recently proposed Monostable Multivibrator (MMV) neural networks as a new class
of SNN achieves more than one order of magnitude smaller memory and compute
complexity compared to deep learning approaches, while reaching a top gesture
recognition accuracy of 93.9% using a 5-class thermal camera dataset acquired
in a car cabin, within an automotive context. Our dataset is released for
helping future research.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06566" title="Abstract">arXiv:2401.06566</a> [<a href="/pdf/2401.06566" title="Download PDF">pdf</a>, <a href="/ps/2401.06566" title="Download PostScript">ps</a>, <a href="/format/2401.06566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Causal Entropy Inverse Reinforcement Learning for Mean-Field  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Anahtarci%2C+B">Berkay Anahtarci</a>, 
<a href="/search/eess?searchtype=author&query=Kariksiz%2C+C+D">Can Deha Kariksiz</a>, 
<a href="/search/eess?searchtype=author&query=Saldi%2C+N">Naci Saldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we introduce the maximum casual entropy Inverse Reinforcement
Learning (IRL) problem for discrete-time mean-field games (MFGs) under an
infinite-horizon discounted-reward optimality criterion. The state space of a
typical agent is finite. Our approach begins with a comprehensive review of the
maximum entropy IRL problem concerning deterministic and stochastic Markov
decision processes (MDPs) in both finite and infinite-horizon scenarios.
Subsequently, we formulate the maximum casual entropy IRL problem for MFGs - a
non-convex optimization problem with respect to policies. Leveraging the linear
programming formulation of MDPs, we restructure this IRL problem into a convex
optimization problem and establish a gradient descent algorithm to compute the
optimal solution with a rate of convergence. Finally, we present a new
algorithm by formulating the MFG problem as a generalized Nash equilibrium
problem (GNEP), which is capable of computing the mean-field equilibrium (MFE)
for the forward RL problem. This method is employed to produce data for a
numerical example. We note that this novel algorithm is also applicable to
general MFE computations.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06568" title="Abstract">arXiv:2401.06568</a> [<a href="/pdf/2401.06568" title="Download PDF">pdf</a>, <a href="/format/2401.06568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lost in the Source Language: How Large Language Models Evaluate the  Quality of Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhirui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xiang Geng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yichao Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have achieved remarkable results in the machine
translation evaluation task, yet there remains a gap in knowledge regarding how
they utilize the provided data to conduct evaluations. This study aims to
explore how LLMs leverage source and reference information in evaluating
translations, with the ultimate goal of better understanding the working
mechanism of LLMs. To this end, we design the controlled experiments across
various input modes and model types, and employ both coarse-grained and
fine-grained prompts to discern the utility of source versus reference
information. Surprisingly, we find that reference information significantly
enhances the evaluation accuracy, while source information sometimes is
counterproductive, indicating a lack of cross-lingual capability when using
LLMs to evaluate translations. We further conduct a meta-evaluation for
translation error detection of LLMs, observing a similar phenomenon. These
findings also suggest a potential research direction for LLMs that fully
exploits the cross-lingual capability of LLMs to achieve better performance in
machine translation evaluation tasks.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06574" title="Abstract">arXiv:2401.06574</a> [<a href="/pdf/2401.06574" title="Download PDF">pdf</a>, <a href="/format/2401.06574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CTMCs with Imprecisely Timed Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badings%2C+T">Thom Badings</a>, 
<a href="/search/cs?searchtype=author&query=Volk%2C+M">Matthias Volk</a>, 
<a href="/search/cs?searchtype=author&query=Junges%2C+S">Sebastian Junges</a>, 
<a href="/search/cs?searchtype=author&query=Stoelinga%2C+M">Marielle Stoelinga</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+N">Nils Jansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version (with appendix) of the paper accepted at TACAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Labeled continuous-time Markov chains (CTMCs) describe processes subject to
random timing and partial observability. In applications such as runtime
monitoring, we must incorporate past observations. The timing of these
observations matters but may be uncertain. Thus, we consider a setting in which
we are given a sequence of imprecisely timed labels called the evidence. The
problem is to compute reachability probabilities, which we condition on this
evidence. Our key contribution is a method that solves this problem by
unfolding the CTMC states over all possible timings for the evidence. We
formalize this unfolding as a Markov decision process (MDP) in which each
timing for the evidence is reflected by a scheduler. This MDP has infinitely
many states and actions in general, making a direct analysis infeasible. Thus,
we abstract the continuous MDP into a finite interval MDP (iMDP) and develop an
iterative refinement scheme to upper-bound conditional probabilities in the
CTMC. We show the feasibility of our method on several numerical benchmarks and
discuss key challenges to further enhance the performance.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06576" title="Abstract">arXiv:2401.06576</a> [<a href="/pdf/2401.06576" title="Download PDF">pdf</a>, <a href="/format/2401.06576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalar Representation of 2D Steady Vector Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theisel%2C+H">Holger Theisel</a>, 
<a href="/search/cs?searchtype=author&query=Motejat%2C+M">Michael Motejat</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+J">Janos Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6ssl%2C+C">Christian R&#xf6;ssl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">We introduce a representation of a 2D steady vector field ${{\mathbf v}}$ by
two scalar fields $a$, $b$, such that the isolines of $a$ correspond to stream
lines of ${{\mathbf v}}$, and $b$ increases with constant speed under
integration of ${{\mathbf v}}$. This way, we get a direct encoding of stream
lines, i.e., a numerical integration of ${{\mathbf v}}$ can be replaced by a
local isoline extraction of $a$. To guarantee a solution in every case,
gradient-preserving cuts are introduced such that the scalar fields are allowed
to be discontinuous in the values but continuous in the gradient. Along with a
piecewise linear discretization and a proper placement of the cuts, the fields
$a$ and $b$ can be computed. We show several evaluations on non-trivial vector
fields.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06578" title="Abstract">arXiv:2401.06578</a> [<a href="/pdf/2401.06578" title="Download PDF">pdf</a>, <a href="/format/2401.06578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360DVD: Controllable Panorama Video Generation with 360-Degree Video  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+C">Chong Mou</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xinhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2307.04725">arXiv:2307.04725</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">360-degree panoramic videos recently attract more interest in both studies
and applications, courtesy of the heightened immersive experiences they
engender. Due to the expensive cost of capturing 360-degree panoramic videos,
generating desirable panoramic videos by given prompts is urgently required.
Recently, the emerging text-to-video (T2V) diffusion methods demonstrate
notable effectiveness in standard video generation. However, due to the
significant gap in content and motion patterns between panoramic and standard
videos, these methods encounter challenges in yielding satisfactory 360-degree
panoramic videos. In this paper, we propose a controllable panorama video
generation pipeline named 360-Degree Video Diffusion model (360DVD) for
generating panoramic videos based on the given prompts and motion conditions.
Concretely, we introduce a lightweight module dubbed 360-Adapter and assisted
360 Enhancement Techniques to transform pre-trained T2V models for 360-degree
video generation. We further propose a new panorama dataset named WEB360
consisting of 360-degree video-text pairs for training 360DVD, addressing the
absence of captioned panoramic video datasets. Extensive experiments
demonstrate the superiority and effectiveness of 360DVD for panorama video
generation. The code and dataset will be released soon.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06579" title="Abstract">arXiv:2401.06579</a> [<a href="/pdf/2401.06579" title="Download PDF">pdf</a>, <a href="/format/2401.06579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Throughput for TTEthernet via Co-optimizing Routing and  Scheduling: An Online Time-Varying Graph-based Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yaoxu He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Time-Triggered Ethernet (TTEthernet) has been widely applied in many
scenarios such as industrial internet, automotive electronics, and aerospace,
where offline routing and scheduling for TTEthernet has been largely
investigated. However, predetermined routes and schedules cannot meet the
demands in some agile scenarios, such as smart factories, autonomous driving,
and satellite network switching, where the transmission requests join in and
leave the network frequently. Thus, we study the online joint routing and
scheduling problem for TTEthernet. However, balancing efficient and effective
routing and scheduling in an online environment can be quite challenging. To
ensure high-quality and fast routing and scheduling, we first design a
time-slot expanded graph (TSEG) to model the available resources of TTEthernet
over time. The fine-grained representation of TSEG allows us to select a time
slot via selecting an edge, thus transforming the scheduling problem into a
simple routing problem. Next, we design a dynamic weighting method for each
edge in TSEG and further propose an algorithm to co-optimize the routing and
scheduling. Our scheme enhances the TTEthernet throughput by co-optimizing the
routing and scheduling to eliminate potential conflicts among flow requests, as
compared to existing methods. The extensive simulation results show that our
scheme runs &gt;400 times faster than standard solutions (i.e., ILP solver), while
the gap is only 2% to the optimally scheduled number of flow requests. Besides,
as compared to existing schemes, our method can improve the successfully
scheduled number of flows by more than 18%.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06580" title="Abstract">arXiv:2401.06580</a> [<a href="/pdf/2401.06580" title="Download PDF">pdf</a>, <a href="/format/2401.06580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TestSpark: IntelliJ IDEA&#x27;s Ultimate Test Generation Companion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sapozhnikov%2C+A">Arkadii Sapozhnikov</a>, 
<a href="/search/cs?searchtype=author&query=Olsthoorn%2C+M">Mitchell Olsthoorn</a>, 
<a href="/search/cs?searchtype=author&query=Panichella%2C+A">Annibale Panichella</a>, 
<a href="/search/cs?searchtype=author&query=Kovalenko%2C+V">Vladimir Kovalenko</a>, 
<a href="/search/cs?searchtype=author&query=Derakhshanfar%2C+P">Pouria Derakhshanfar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Writing software tests is laborious and time-consuming. To address this,
prior studies introduced various automated test-generation techniques. A
well-explored research direction in this field is unit test generation, wherein
artificial intelligence (AI) techniques create tests for a method/class under
test. While many of these techniques have primarily found applications in a
research context, existing tools (e.g., EvoSuite, Randoop, and AthenaTest) are
not user-friendly and are tailored to a single technique. This paper introduces
TestSpark, a plugin for IntelliJ IDEA that enables users to generate unit tests
with only a few clicks directly within their Integrated Development Environment
(IDE). Furthermore, TestSpark also allows users to easily modify and run each
generated test and integrate them into the project workflow. TestSpark
leverages the advances of search-based test generation tools, and it introduces
a technique to generate unit tests using Large Language Models (LLMs) by
creating a feedback cycle between the IDE and the LLM. Since TestSpark is an
open-source (https://github.com/JetBrains-Research/TestSpark), extendable, and
well-documented tool, it is possible to add new test generation methods into
the plugin with the minimum effort. This paper also explains our future studies
related to TestSpark and our preliminary results. Demo video:
https://youtu.be/0F4PrxWfiXo
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06582" title="Abstract">arXiv:2401.06582</a> [<a href="/pdf/2401.06582" title="Download PDF">pdf</a>, <a href="/format/2401.06582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cyborgs for strategic communication on social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ng%2C+L+H+X">Lynnette Hui Xian Ng</a>, 
<a href="/search/cs?searchtype=author&query=Robertson%2C+D+C">Dawn C. Robertson</a>, 
<a href="/search/cs?searchtype=author&query=Carley%2C+K+M">Kathleen M. Carley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Big Data and Society
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Social media platforms are a key ground of information consumption and
dissemination. Key figures like politicians, celebrities and activists have
leveraged on its wide user base for strategic communication. Strategic
communications, or StratCom, is the deliberate act of information creation and
distribution. Its techniques are used by these key figures for establishing
their brand and amplifying their messages. Automated scripts are used on top of
personal touches to quickly and effectively perform these tasks. The
combination of automation and manual online posting creates a Cyborg social
media profile, which is a hybrid between bot and human. In this study, we
establish a quantitative definition for a Cyborg account, which is an account
that are detected as bots in one time window, and identified as humans in
another. This definition makes use of frequent changes of bot classification
labels and large differences in bot likelihood scores to identify Cyborgs. We
perform a large-scale analysis across over 3.1 million users from Twitter
collected from two key events, the 2020 Coronavirus pandemic and 2020 US
Elections. We extract Cyborgs from two datasets and employ tools from network
science, natural language processing and manual annotation to characterize
Cyborg accounts. Our analyses identify Cyborg accounts are mostly constructed
for strategic communication uses, have a strong duality in their bot/human
classification and are tactically positioned in the social media network,
aiding these accounts to promote their desired content. Cyborgs are also
discovered to have long online lives, indicating their ability to evade bot
detectors, or the graciousness of platforms to allow their operations.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06583" title="Abstract">arXiv:2401.06583</a> [<a href="/pdf/2401.06583" title="Download PDF">pdf</a>, <a href="/format/2401.06583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mapping Transformer Leveraged Embeddings for Cross-Lingual Document  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tashu%2C+T+M">Tsegaye Misikir Tashu</a>, 
<a href="/search/cs?searchtype=author&query=Kontos%2C+E">Eduard-Raul Kontos</a>, 
<a href="/search/cs?searchtype=author&query=Sabatelli%2C+M">Matthia Sabatelli</a>, 
<a href="/search/cs?searchtype=author&query=Valdenegro-Toro%2C+M">Matias Valdenegro-Toro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recommendation systems, for documents, have become tools to find relevant
content on the Web. However, these systems have limitations when it comes to
recommending documents in languages different from the query language, which
means they might overlook resources in non-native languages. This research
focuses on representing documents across languages by using Transformer
Leveraged Document Representations (TLDRs) that are mapped to a cross-lingual
domain. Four multilingual pre-trained transformer models (mBERT, mT5 XLM
RoBERTa, ErnieM) were evaluated using three mapping methods across 20 language
pairs representing combinations of five selected languages of the European
Union. Metrics like Mate Retrieval Rate and Reciprocal Rank were used to
measure the effectiveness of mapped TLDRs compared to non-mapped ones. The
results highlight the power of cross-lingual representations achieved through
pre-trained transformers and mapping approaches suggesting a promising
direction for expanding beyond language connections, between two specific
languages.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06591" title="Abstract">arXiv:2401.06591</a> [<a href="/pdf/2401.06591" title="Download PDF">pdf</a>, <a href="/format/2401.06591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prometheus-Vision: Vision-Language Model as a Judge for Fine-Grained  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seongyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungone Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S+H">Sue Hyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Geewook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minjoon Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Assessing long-form responses generated by Vision-Language Models (VLMs) is
challenging. It not only requires checking whether the VLM follows the given
instruction but also verifying whether the text output is properly grounded on
the given image. Inspired by the recent approach of evaluating LMs with LMs, in
this work, we propose to evaluate VLMs with VLMs. For this purpose, we present
a new feedback dataset called the Perception Collection, encompassing 15K
customized score rubrics that users might care about during assessment. Using
the Perception Collection, we train Prometheus-Vision, the first open-source
VLM evaluator model that can understand the user-defined score criteria during
evaluation. Prometheus-Vision shows the highest Pearson correlation with human
evaluators and GPT-4V among open-source models, showing its effectiveness for
transparent and accessible evaluation of VLMs. We open-source our code,
dataset, and model at https://github.com/kaistAI/prometheus-vision
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06595" title="Abstract">arXiv:2401.06595</a> [<a href="/pdf/2401.06595" title="Download PDF">pdf</a>, <a href="/format/2401.06595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Every Node is Different: Dynamically Fusing Self-Supervised Tasks for  Attributed Graph Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Pengfei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialu Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghua Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Attributed graph clustering is an unsupervised task that partitions nodes
into different groups. Self-supervised learning (SSL) shows great potential in
handling this task, and some recent studies simultaneously learn multiple SSL
tasks to further boost performance. Currently, different SSL tasks are assigned
the same set of weights for all graph nodes. However, we observe that some
graph nodes whose neighbors are in different groups require significantly
different emphases on SSL tasks. In this paper, we propose to dynamically learn
the weights of SSL tasks for different nodes and fuse the embeddings learned
from different SSL tasks to boost performance. We design an innovative graph
clustering approach, namely Dynamically Fusing Self-Supervised Learning
(DyFSS). Specifically, DyFSS fuses features extracted from diverse SSL tasks
using distinct weights derived from a gating network. To effectively learn the
gating network, we design a dual-level self-supervised strategy that
incorporates pseudo labels and the graph structure. Extensive experiments on
five datasets show that DyFSS outperforms the state-of-the-art multi-task SSL
methods by up to 8.66% on the accuracy metric. The code of DyFSS is available
at: https://github.com/q086/DyFSS.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06596" title="Abstract">arXiv:2401.06596</a> [<a href="/pdf/2401.06596" title="Download PDF">pdf</a>, <a href="/ps/2401.06596" title="Download PostScript">ps</a>, <a href="/format/2401.06596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Boolean Closure of Deterministic Top-Down Tree Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B6ding%2C+C">Christof L&#xf6;ding</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+W">Wolfgang Thomas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint of a paper published in a special issue dedicated to the memory of Magnus Steinby in the International Journal of Foundations of Computer Science. Compared to the published journal version, reference [8] has been added in a comment at the end of the introduction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">The class of Boolean combinations of tree languages recognized by
deterministic top-down tree automata (also known as deterministic
root-to-frontier automata) is studied. The problem of determining for a given
regular tree language whether it belongs to this class is open. We provide some
progress by two results: First, a characterization of this class by a natural
extension of deterministic top-down tree automata is presented, and as an
application we obtain a convenient method to show that certain regular tree
languages are outside this class. In the second result, it is shown that, for
fixed $k$, it is decidable whether a regular tree language is a Boolean
combination of $k$ tree languages recognized by deterministic top-down tree
automata.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06601" title="Abstract">arXiv:2401.06601</a> [<a href="/pdf/2401.06601" title="Download PDF">pdf</a>, <a href="/format/2401.06601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A proposal to increase data utility on Global Differential Privacy data  based on data use predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nunes%2C+H+C">Henry C. Nunes</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+M+P">Marlon P. da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Neu%2C+C+V">Charles V. Neu</a>, 
<a href="/search/cs?searchtype=author&query=Zorzo%2C+A+F">Avelino F. Zorzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Databases (cs.DB)

</div>
<p class="mathjax">This paper presents ongoing research focused on improving the utility of data
protected by Global Differential Privacy(DP) in the scenario of summary
statistics. Our approach is based on predictions on how an analyst will use
statistics released under DP protection, so that a developer can optimise data
utility on further usage of the data in the privacy budget allocation. This
novel approach can potentially improve the utility of data without compromising
privacy constraints. We also propose a metric that can be used by the developer
to optimise the budget allocation process.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06602" title="Abstract">arXiv:2401.06602</a> [<a href="/pdf/2401.06602" title="Download PDF">pdf</a>, <a href="/format/2401.06602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Security Findings Management: A Case Study in Industrial  DevOps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voggenreiter%2C+M">Markus Voggenreiter</a>, 
<a href="/search/cs?searchtype=author&query=Angermeir%2C+F">Florian Angermeir</a>, 
<a href="/search/cs?searchtype=author&query=Moy%C3%B3n%2C+F">Fabiola Moy&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6pp%2C+U">Ulrich Sch&#xf6;pp</a>, 
<a href="/search/cs?searchtype=author&query=Bonvin%2C+P">Pierre Bonvin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In recent years, DevOps, the unification of development and operation
workflows, has become a trend for the industrial software development
lifecycle. Security activities turned into an essential field of application
for DevOps principles as they are a fundamental part of secure software
development in the industry. A common practice arising from this trend is the
automation of security tests that analyze a software product from several
perspectives. To effectively improve the security of the analyzed product, the
identified security findings must be managed and looped back to the project
team for stakeholders to take action. This management must cope with several
challenges ranging from low data quality to a consistent prioritization of
findings while following DevOps aims. To manage security findings with the same
efficiency as other activities in DevOps projects, a methodology for the
management of industrial security findings minding DevOps principles is
essential.
<br />In this paper, we propose a methodology for the management of security
findings in industrial DevOps projects, summarizing our research in this domain
and presenting the resulting artifact. As an instance of the methodology, we
developed the Security Flama, a semantic knowledge base for the automated
management of security findings. To analyze the impact of our methodology on
industrial practice, we performed a case study on two DevOps projects of a
multinational industrial enterprise. The results emphasize the importance of
using such an automated methodology in industrial DevOps projects, confirm our
approach's usefulness and positive impact on the studied projects, and identify
the communication strategy as a crucial factor for usability in practice.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06603" title="Abstract">arXiv:2401.06603</a> [<a href="/pdf/2401.06603" title="Download PDF">pdf</a>, <a href="/format/2401.06603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Enhancement of Large Language and Reinforcement Learning Models  through Bi-Directional Feedback Mechanisms: A Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shangding Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated remarkable capabilities for
reinforcement learning (RL) models, such as planning and reasoning
capabilities. However, the problems of LLMs and RL model collaboration still
need to be solved. In this study, we employ a teacher-student learning
framework to tackle these problems, specifically by offering feedback for LLMs
using RL models and providing high-level information for RL models with LLMs in
a cooperative multi-agent setting. Within this framework, the LLM acts as a
teacher, while the RL model acts as a student. The two agents cooperatively
assist each other through a process of recursive help, such as "I help you help
I help." The LLM agent supplies abstract information to the RL agent, enabling
efficient exploration and policy improvement. In turn, the RL agent offers
feedback to the LLM agent, providing valuable, real-time information that helps
generate more useful tokens. This bi-directional feedback loop promotes
optimization, exploration, and mutual improvement for both agents, enabling
them to accomplish increasingly challenging tasks. Remarkably, we propose a
practical algorithm to address the problem and conduct empirical experiments to
evaluate the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06604" title="Abstract">arXiv:2401.06604</a> [<a href="/pdf/2401.06604" title="Download PDF">pdf</a>, <a href="/format/2401.06604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Policy Gradient Subspaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jan Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Schumacher%2C+P">Pierre Schumacher</a>, 
<a href="/search/cs?searchtype=author&query=Guist%2C+S">Simon Guist</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Le Chen</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4ufle%2C+D">Daniel H&#xe4;ufle</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCchler%2C+D">Dieter B&#xfc;chler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review as a conference paper at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Policy gradient methods hold great potential for solving complex continuous
control tasks. Still, their training efficiency can be improved by exploiting
structure within the optimization problem. Recent work indicates that
supervised learning can be accelerated by leveraging the fact that gradients
lie in a low-dimensional and slowly-changing subspace. In this paper, we
conduct a thorough evaluation of this phenomenon for two popular deep policy
gradient methods on various simulated benchmark tasks. Our results demonstrate
the existence of such gradient subspaces despite the continuously changing data
distribution inherent to reinforcement learning. These findings reveal
promising directions for future work on more efficient reinforcement learning,
e.g., through improving parameter-space exploration or enabling second-order
optimization.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06610" title="Abstract">arXiv:2401.06610</a> [<a href="/pdf/2401.06610" title="Download PDF">pdf</a>, <a href="/ps/2401.06610" title="Download PostScript">ps</a>, <a href="/format/2401.06610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Hand-object Kinematic Model for Bimanual Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper addresses the planar finger kinematics for seeking optimized
manipulation strategies. The first step is to model based on geometric features
of linear and rotation motion so that the robot can select the fingers
configurations. This kinematic model considers the motion between hands and
object. Based on 2-finger manipulation cases, this model can output the
strategies for bimanual manipulation. For executing strategies, the second step
is to seek the appropriate values of finger joints according to the ending
orientation of fingers. The simulation shows that the computed solutions can
complete the relative rotation and linear motion of unknown objects.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06612" title="Abstract">arXiv:2401.06612</a> [<a href="/pdf/2401.06612" title="Download PDF">pdf</a>, <a href="/ps/2401.06612" title="Download PostScript">ps</a>, <a href="/format/2401.06612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Machine Learning for Wi-Fi-based Environmental Continuous  Two-Factor Authentication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AlQahtani%2C+A+A+S">Ali Abdullah S. AlQahtani</a>, 
<a href="/search/cs?searchtype=author&query=Alshayeb%2C+T">Thamraa Alshayeb</a>, 
<a href="/search/cs?searchtype=author&query=Nabil%2C+M">Mahmoud Nabil</a>, 
<a href="/search/cs?searchtype=author&query=Patooghy%2C+A">Ahmad Patooghy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The traditional two-factor authentication (2FA) methods primarily rely on the
user manually entering a code or token during the authentication process. This
can be burdensome and time-consuming, particularly for users who must be
authenticated frequently. To tackle this challenge, we present a novel 2FA
approach replacing the user's input with decisions made by Machine Learning
(ML) that continuously verifies the user's identity with zero effort. Our
system exploits unique environmental features associated with the user, such as
beacon frame characteristics and Received Signal Strength Indicator (RSSI)
values from Wi-Fi Access Points (APs). These features are gathered and analyzed
in real-time by our ML algorithm to ascertain the user's identity. For enhanced
security, our system mandates that the user's two devices (i.e., a login device
and a mobile device) be situated within a predetermined proximity before
granting access. This precaution ensures that unauthorized users cannot access
sensitive information or systems, even with the correct login credentials.
Through experimentation, we have demonstrated our system's effectiveness in
determining the location of the user's devices based on beacon frame
characteristics and RSSI values, achieving an accuracy of 92.4%. Additionally,
we conducted comprehensive security analysis experiments to evaluate the
proposed 2FA system's resilience against various cyberattacks. Our findings
indicate that the system exhibits robustness and reliability in the face of
these threats. The scalability, flexibility, and adaptability of our system
render it a promising option for organizations and users seeking a secure and
convenient authentication system.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06614" title="Abstract">arXiv:2401.06614</a> [<a href="/pdf/2401.06614" title="Download PDF">pdf</a>, <a href="/format/2401.06614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion2VecSets: 4D Latent Vector Set Diffusion for Non-rigid Shape  Reconstruction and Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+W">Wei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Biao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiapeng Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Motion2VecSets, a 4D diffusion model for dynamic surface
reconstruction from point cloud sequences. While existing state-of-the-art
methods have demonstrated success in reconstructing non-rigid objects using
neural field representations, conventional feed-forward networks encounter
challenges with ambiguous observations from noisy, partial, or sparse point
clouds. To address these challenges, we introduce a diffusion model that
explicitly learns the shape and motion distribution of non-rigid objects
through an iterative denoising process of compressed latent representations.
The diffusion-based prior enables more plausible and probabilistic
reconstructions when handling ambiguous inputs. We parameterize 4D dynamics
with latent vector sets instead of using a global latent. This novel 4D
representation allows us to learn local surface shape and deformation patterns,
leading to more accurate non-linear motion capture and significantly improving
generalizability to unseen motions and identities. For more temporal-coherent
object tracking, we synchronously denoise deformation latent sets and exchange
information across multiple frames. To avoid the computational overhead, we
design an interleaved space and time attention block to alternately aggregate
deformation latents along spatial and temporal domains. Extensive comparisons
against the state-of-the-art methods demonstrate the superiority of our
Motion2VecSets in 4D reconstruction from various imperfect observations,
notably achieving a 19% improvement in Intersection over Union (IoU) compared
to CaDex for reconstructing unseen individuals from sparse point clouds on the
DeformingThings4D-Animals dataset. More detailed information can be found at
https://vveicao.github.io/projects/Motion2VecSets/.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06619" title="Abstract">arXiv:2401.06619</a> [<a href="/pdf/2401.06619" title="Download PDF">pdf</a>, <a href="/format/2401.06619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyTy: Repairing Static Type Errors in Python
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chow%2C+Y+W">Yiu Wai Chow</a>, 
<a href="/search/cs?searchtype=author&query=Di+Grazia%2C+L">Luca Di Grazia</a>, 
<a href="/search/cs?searchtype=author&query=Pradel%2C+M">Michael Pradel</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Gradual typing enables developers to annotate types of their own choosing,
offering a flexible middle ground between no type annotations and a fully
statically typed language. As more and more code bases get type-annotated,
static type checkers detect an increasingly large number of type errors.
Unfortunately, fixing these errors requires manual effort, hampering the
adoption of gradual typing in practice. This paper presents PyTy, an automated
program repair approach targeted at statically detectable type errors in
Python. The problem of repairing type errors deserves specific attention
because it exposes particular repair patterns, offers a warning message with
hints about where and how to apply a fix, and because gradual type checking
serves as an automatic way to validate fixes. We addresses this problem through
three contributions: (i) an empirical study that investigates how developers
fix Python type errors, showing a diverse set of fixing strategies with some
recurring patterns; (ii) an approach to automatically extract type error fixes,
which enables us to create a dataset of 2,766 error-fix pairs from 176 GitHub
repositories, named PyTyDefects; (iii) the first learning-based repair
technique for fixing type errors in Python. Motivated by the relative data
scarcity of the problem, the neural model at the core of PyTy is trained via
cross-lingual transfer learning. Our evaluation shows that PyTy offers fixes
for ten frequent categories of type errors, successfully addressing 85.4% of
281 real-world errors. This effectiveness outperforms state-of-the-art large
language models asked to repair type errors (by 2.1x) and complements a
previous technique aimed at type errors that manifest at runtime. Finally, 20
out of 30 pull requests with PyTy-suggested fixes have been merged by
developers, showing the usefulness of PyTy in practice.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06620" title="Abstract">arXiv:2401.06620</a> [<a href="/pdf/2401.06620" title="Download PDF">pdf</a>, <a href="/format/2401.06620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransliCo: A Contrastive Learning Framework to Address the Script  Barrier in Multilingual Pretrained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yihong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chunlan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haotian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtze%2C+H">Hinrich Sch&#xfc;tze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">There are 293 scripts representing over 7,000 languages in the written form.
Due to various reasons, many closely related languages use different scripts,
which poses difficulty for multilingual pretrained language models (mPLMs) in
learning crosslingual knowledge through lexical overlap. As a result, mPLMs
present a script barrier: representations from different scripts are located in
different subspaces, which is a strong indicator of why crosslingual transfer
involving languages of different scripts shows sub-optimal performance. To
address this problem, we propose a simple framework TransliCo that contains
Transliteration Contrastive Modeling (TCM) to fine-tune an mPLM by contrasting
sentences in its training data and their transliterations in a unified script
(Latn, in our case), which ensures uniformity in the representation space for
different scripts. Using Glot500-m, an mPLM pretrained on over 500 languages,
as our source model, we find-tune it on a small portion (5\%) of its training
data, and refer to the resulting model as Furina. We show that Furina not only
better aligns representations from distinct scripts but also outperforms the
original Glot500-m on various crosslingual transfer tasks. Additionally, we
achieve consistent improvement in a case study on the Indic group where the
languages are highly related but use different scripts. We make our code and
models publicly available.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06626" title="Abstract">arXiv:2401.06626</a> [<a href="/pdf/2401.06626" title="Download PDF">pdf</a>, <a href="/format/2401.06626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software-Based Memory Erasure with relaxed isolation requirements:  Extended Version
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bursuc%2C+S">Sergiu Bursuc</a>, 
<a href="/search/cs?searchtype=author&query=Gil-Pons%2C+R">Reynaldo Gil-Pons</a>, 
<a href="/search/cs?searchtype=author&query=Mauw%2C+S">Sjouke Mauw</a>, 
<a href="/search/cs?searchtype=author&query=Trujillo-Rasua%2C+R">Rolando Trujillo-Rasua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">A Proof of Secure Erasure (PoSE) is a communication protocol where a verifier
seeks evidence that a prover has erased its memory within the time frame of the
protocol execution. Designers of PoSE protocols have long been aware that, if a
prover can outsource the computation of the memory erasure proof to another
device, then their protocols are trivially defeated. As a result, most
software-based PoSE protocols in the literature assume that provers are
isolated during the protocol execution, that is, provers cannot receive help
from a network adversary. Our main contribution is to show that this assumption
is not necessary. We introduce formal models for PoSE protocols playing against
provers aided by external conspirators and develop three PoSE protocols that we
prove secure in this context. We reduce the requirement of isolation to the
more realistic requirement that the communication with the external conspirator
is relatively slow. Software-based protocols with such relaxed isolation
assumptions are especially pertinent for low-end devices, where it is too
costly to deploy sophisticated protection methods.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06628" title="Abstract">arXiv:2401.06628</a> [<a href="/pdf/2401.06628" title="Download PDF">pdf</a>, <a href="/format/2401.06628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OOP: Object-Oriented Programming Evaluation Benchmark for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Advancing automated programming necessitates robust and comprehensive code
generation benchmarks, yet current evaluation frameworks largely neglect
object-oriented programming (OOP) in favor of functional programming (FP),
e.g., HumanEval and MBPP. To address this, our study introduces a pioneering
OOP-focused benchmark, featuring 431 Python programs that encompass essential
OOP concepts and features like classes and encapsulation methods. We propose a
novel evaluation metric, pass@o, tailored for OOP, enhancing traditional pass@k
measures. Our evaluation of 23 leading large language models (LLMs), including
both general and code-specialized models, reveals three key insights: 1) pass@o
offers a more relevant and comprehensive assessment for OOP code generation; 2)
Despite excelling in FP, code-specialized LLMs like WizardCoder lag in OOP
compared to models like ChatGPT; 3) The poor performance of all advanced LLMs
on our OOP benchmark highlights a critical need for improvements in this field.
Our benchmark and scripts are publicly released at:
https://github.com/alphadl/OOP-eval.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06633" title="Abstract">arXiv:2401.06633</a> [<a href="/pdf/2401.06633" title="Download PDF">pdf</a>, <a href="/format/2401.06633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ada-Retrieval: An Adaptive Multi-Round Retrieval Paradigm for Sequential  Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jianxun Lian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Retrieval models aim at selecting a small set of item candidates which match
the preference of a given user. They play a vital role in large-scale
recommender systems since subsequent models such as rankers highly depend on
the quality of item candidates. However, most existing retrieval models employ
a single-round inference paradigm, which may not adequately capture the dynamic
nature of user preferences and stuck in one area in the item space. In this
paper, we propose Ada-Retrieval, an adaptive multi-round retrieval paradigm for
recommender systems that iteratively refines user representations to better
capture potential candidates in the full item space. Ada-Retrieval comprises
two key modules: the item representation adapter and the user representation
adapter, designed to inject context information into items' and users'
representations. The framework maintains a model-agnostic design, allowing
seamless integration with various backbone models such as RNNs or Transformers.
We perform experiments on three widely used public datasets, incorporating five
powerful sequential recommenders as backbone models. Our results demonstrate
that Ada-Retrieval significantly enhances the performance of various base
models, with consistent improvements observed across different datasets. Our
code and data are publicly available at:
https://github.com/ll0ruc/Ada-Retrieval.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06634" title="Abstract">arXiv:2401.06634</a> [<a href="/pdf/2401.06634" title="Download PDF">pdf</a>, <a href="/format/2401.06634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CCFC: Bridging Federated Clustering and Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jie Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhong-Yuan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated clustering, an essential extension of centralized clustering for
federated scenarios, enables multiple data-holding clients to collaboratively
group data while keeping their data locally. In centralized scenarios,
clustering driven by representation learning has made significant advancements
in handling high-dimensional complex data. However, the combination of
federated clustering and representation learning remains underexplored. To
bridge this, we first tailor a cluster-contrastive model for learning
clustering-friendly representations. Then, we harness this model as the
foundation for proposing a new federated clustering method, named
cluster-contrastive federated clustering (CCFC). Benefiting from representation
learning, the clustering performance of CCFC even double those of the best
baseline methods in some cases. Compared to the most related baseline, the
benefit results in substantial NMI score improvements of up to 0.4155 on the
most conspicuous case. Moreover, CCFC also shows superior performance in
handling device failures from a practical viewpoint.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06637" title="Abstract">arXiv:2401.06637</a> [<a href="/pdf/2401.06637" title="Download PDF">pdf</a>, <a href="/format/2401.06637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Examples are Misaligned in Diffusion Model Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+P">Peter Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Durall%2C+R">Ricard Durall</a>, 
<a href="/search/cs?searchtype=author&query=Keuper%2C+J">Jansi Keuper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In recent years, diffusion models (DMs) have drawn significant attention for
their success in approximating data distributions, yielding state-of-the-art
generative results. Nevertheless, the versatility of these models extends
beyond their generative capabilities to encompass various vision applications,
such as image inpainting, segmentation, adversarial robustness, among others.
This study is dedicated to the investigation of adversarial attacks through the
lens of diffusion models. However, our objective does not involve enhancing the
adversarial robustness of image classifiers. Instead, our focus lies in
utilizing the diffusion model to detect and analyze the anomalies introduced by
these attacks on images. To that end, we systematically examine the alignment
of the distributions of adversarial examples when subjected to the process of
transformation using diffusion models. The efficacy of this approach is
assessed across CIFAR-10 and ImageNet datasets, including varying image sizes
in the latter. The results demonstrate a notable capacity to discriminate
effectively between benign and attacked images, providing compelling evidence
that adversarial instances do not align with the learned manifold of the DMs.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06638" title="Abstract">arXiv:2401.06638</a> [<a href="/pdf/2401.06638" title="Download PDF">pdf</a>, <a href="/ps/2401.06638" title="Download PostScript">ps</a>, <a href="/format/2401.06638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Prototype on the Feasibility of Learning Spatial Provenance in XBee  and LoRa Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Manish Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+P">Pramsu Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Harshan%2C+J">J. Harshan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short paper on prototype demonstration
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In Vehicle-to-Everything (V2X) networks that involve multi-hop communication,
the Road Side Units (RSUs) typically desire to gather the location information
of the participating vehicles to provide security and network-diagnostics
features. Although Global Positioning System (GPS) based localization is widely
used by vehicles for navigation; they may not forward their exact GPS
coordinates to the RSUs due to privacy issues. Therefore, to balance the
high-localization requirements of RSU and the privacy of the vehicles, we
demonstrate a new spatial-provenance framework wherein the vehicles agree to
compromise their privacy to a certain extent and share a low-precision variant
of its coordinates in agreement with the demands of the RSU. To study the
deployment feasibility of the proposed framework in state-of-the-art wireless
standards, we propose a testbed of ZigBee and LoRa devices and implement the
underlying protocols on their stack using correlated Bloom filters and Rake
compression algorithms. Our demonstrations reveal that low-to-moderate
precision localization can be achieved in fewer packets, thus making an
appealing case for next-generation vehicular networks to include our methods
for providing real-time security and network-diagnostics features.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06640" title="Abstract">arXiv:2401.06640</a> [<a href="/pdf/2401.06640" title="Download PDF">pdf</a>, <a href="/format/2401.06640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Contexts Can Facilitate Robust Semantic Property Inference  in Language Models, but Inconsistently
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Misra%2C+K">Kanishka Misra</a>, 
<a href="/search/cs?searchtype=author&query=Ettinger%2C+A">Allyson Ettinger</a>, 
<a href="/search/cs?searchtype=author&query=Mahowald%2C+K">Kyle Mahowald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent zero-shot evaluations have highlighted important limitations in the
abilities of language models (LMs) to perform meaning extraction. However, it
is now well known that LMs can demonstrate radical improvements in the presence
of experimental contexts such as in-context examples and instructions. How well
does this translate to previously studied meaning-sensitive tasks? We present a
case-study on the extent to which experimental contexts can improve LMs'
robustness in performing property inheritance -- predicting semantic properties
of novel concepts, a task that they have been previously shown to fail on. Upon
carefully controlling the nature of the in-context examples and the
instructions, our work reveals that they can indeed lead to non-trivial
property inheritance behavior in LMs. However, this ability is inconsistent:
with a minimal reformulation of the task, some LMs were found to pick up on
shallow, non-semantic heuristics from their inputs, suggesting that the
computational principles of semantic property inference are yet to be mastered
by LMs.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06643" title="Abstract">arXiv:2401.06643</a> [<a href="/pdf/2401.06643" title="Download PDF">pdf</a>, <a href="/format/2401.06643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects of diversity incentives on sample diversity and downstream model  performance in LLM-based text augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cegin%2C+J">Jan Cegin</a>, 
<a href="/search/cs?searchtype=author&query=Pecher%2C+B">Branislav Pecher</a>, 
<a href="/search/cs?searchtype=author&query=Simko%2C+J">Jakub Simko</a>, 
<a href="/search/cs?searchtype=author&query=Srba%2C+I">Ivan Srba</a>, 
<a href="/search/cs?searchtype=author&query=Bielikova%2C+M">Maria Bielikova</a>, 
<a href="/search/cs?searchtype=author&query=Brusilovsky%2C+P">Peter Brusilovsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 37 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The latest generative large language models (LLMs) have found their
application in data augmentation tasks, where small numbers of text samples are
LLM-paraphrased and then used to fine-tune the model. However, more research is
needed to assess how different prompts, seed data selection strategies,
filtering methods, or model settings affect the quality of paraphrased data
(and downstream models). In this study, we investigate three text diversity
incentive methods well established in crowdsourcing: taboo words, hints by
previous outlier solutions, and chaining on previous outlier solutions. Using
these incentive methods as part of instructions to LLMs augmenting text
datasets, we measure their effects on generated texts' lexical diversity and
downstream model performance. We compare the effects over 5 different LLMs and
6 datasets. We show that diversity is most increased by taboo words, while
downstream model performance is highest when previously created paraphrases are
used as hints.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06644" title="Abstract">arXiv:2401.06644</a> [<a href="/pdf/2401.06644" title="Download PDF">pdf</a>, <a href="/format/2401.06644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeizNet: An AI-enabled Implantable Sensor Network System for Seizure  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saeizadeh%2C+A">Ali Saeizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Schonholtz%2C+D">Douglas Schonholtz</a>, 
<a href="/search/cs?searchtype=author&query=Uvaydov%2C+D">Daniel Uvaydov</a>, 
<a href="/search/cs?searchtype=author&query=Guida%2C+R">Raffaele Guida</a>, 
<a href="/search/cs?searchtype=author&query=Demirors%2C+E">Emrecan Demirors</a>, 
<a href="/search/cs?searchtype=author&query=Johari%2C+P">Pedram Johari</a>, 
<a href="/search/cs?searchtype=author&query=Jimenez%2C+J+M">Jorge M. Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Neimat%2C+J+S">Joseph S. Neimat</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we introduce SeizNet, a closed-loop system for predicting
epileptic seizures through the use of Deep Learning (DL) method and implantable
sensor networks. While pharmacological treatment is effective for some epilepsy
patients (with ~65M people affected worldwide), one out of three suffer from
drug-resistant epilepsy. To alleviate the impact of seizure, predictive systems
have been developed that can notify such patients of an impending seizure,
allowing them to take precautionary measures. SeizNet leverages DL techniques
and combines data from multiple recordings, specifically intracranial
electroencephalogram (iEEG) and electrocardiogram (ECG) sensors, that can
significantly improve the specificity of seizure prediction while preserving
very high levels of sensitivity. SeizNet DL algorithms are designed for
efficient real-time execution at the edge, minimizing data privacy concerns,
data transmission overhead, and power inefficiencies associated with
cloud-based solutions. Our results indicate that SeizNet outperforms
traditional single-modality and non-personalized prediction systems in all
metrics, achieving up to 99% accuracy in predicting seizure, offering a
promising new avenue in refractory epilepsy treatment.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06646" title="Abstract">arXiv:2401.06646</a> [<a href="/pdf/2401.06646" title="Download PDF">pdf</a>, <a href="/format/2401.06646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Block Majorization Minimization with Extrapolation and Application to  $&#x3b2;$-NMF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hien%2C+L+T+K">Le Thi Khanh Hien</a>, 
<a href="/search/cs?searchtype=author&query=Leplat%2C+V">Valentin Leplat</a>, 
<a href="/search/cs?searchtype=author&query=Gillis%2C+N">Nicolas Gillis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, code available from <a href="https://github.com/vleplat/BMMe">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a Block Majorization Minimization method with Extrapolation (BMMe)
for solving a class of multi-convex optimization problems. The extrapolation
parameters of BMMe are updated using a novel adaptive update rule. By showing
that block majorization minimization can be reformulated as a block mirror
descent method, with the Bregman divergence adaptively updated at each
iteration, we establish subsequential convergence for BMMe. We use this method
to design efficient algorithms to tackle nonnegative matrix factorization
problems with the $\beta$-divergences ($\beta$-NMF) for $\beta\in [1,2]$. These
algorithms, which are multiplicative updates with extrapolation, benefit from
our novel results that offer convergence guarantees. We also empirically
illustrate the significant acceleration of BMMe for $\beta$-NMF through
extensive experiments.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06648" title="Abstract">arXiv:2401.06648</a> [<a href="/pdf/2401.06648" title="Download PDF">pdf</a>, <a href="/format/2401.06648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time MPC with Control Barrier Functions for Autonomous Driving  using Safety Enhanced Collocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Allamaa%2C+J+P">Jean Pierre Allamaa</a>, 
<a href="/search/eess?searchtype=author&query=Patrinos%2C+P">Panagiotis Patrinos</a>, 
<a href="/search/eess?searchtype=author&query=Ohtsuka%2C+T">Toshiyuki Ohtsuka</a>, 
<a href="/search/eess?searchtype=author&query=Son%2C+T+D">Tong Duy Son</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to IFAC for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The autonomous driving industry is continuously dealing with more
safety-critical scenarios, and nonlinear model predictive control (NMPC) is a
powerful control strategy for handling such situations. However, standard
safety constraints are not scalable and require a long NMPC horizon. Moreover,
the adoption of NMPC in the automotive industry is limited by the heavy
computation of numerical optimization routines. To address those issues, this
paper presents a real-time capable NMPC for automated driving in urban
environments, using control barrier functions (CBFs). Furthermore, the designed
NMPC is based on a novel collocation transcription approach, named RESAFE/COL,
that allows to reduce the number of optimization variables while still
guaranteeing the continuous time (nonlinear) inequality constraints
satisfaction, through regional convex hull approximation. RESAFE/COL is proven
to be 5 times faster than multiple shooting and more tractable for embedded
hardware without a decrease in the performance, nor accuracy and safety of the
numerical solution. We validate our NMPC-CBF with RESAFE/COL approach with
highly accurate digital twins of the vehicle and the urban environment and show
the safe controller's ability to improve crash avoidance by 91%.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06649" title="Abstract">arXiv:2401.06649</a> [<a href="/pdf/2401.06649" title="Download PDF">pdf</a>, <a href="/format/2401.06649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Efficient Interactive Multi-Objective Optimization Using ParEGO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heidari%2C+A">Arash Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+S+R">Sebastian Rojas Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Dhaene%2C+T">Tom Dhaene</a>, 
<a href="/search/cs?searchtype=author&query=Couckuyt%2C+I">Ivo Couckuyt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at ECML PKDD 2023 workshop: Neuro-Explicit AI and Expert-informed Machine Learning for Engineering and Physical Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Multi-objective optimization is a widely studied problem in diverse fields,
such as engineering and finance, that seeks to identify a set of non-dominated
solutions that provide optimal trade-offs among competing objectives. However,
the computation of the entire Pareto front can become prohibitively expensive,
both in terms of computational resources and time, particularly when dealing
with a large number of objectives. In practical applications, decision-makers
(DMs) will select a single solution of the Pareto front that aligns with their
preferences to be implemented; thus, traditional multi-objective algorithms
invest a lot of budget sampling solutions that are not interesting for the DM.
In this paper, we propose two novel algorithms that employ Gaussian Processes
and advanced discretization methods to efficiently locate the most preferred
region of the Pareto front in expensive-to-evaluate problems. Our approach
involves interacting with the decision-maker to guide the optimization process
towards their preferred trade-offs. Our experimental results demonstrate that
our proposed algorithms are effective in finding non-dominated solutions that
align with the decision-maker's preferences while maintaining computational
efficiency.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06650" title="Abstract">arXiv:2401.06650</a> [<a href="/pdf/2401.06650" title="Download PDF">pdf</a>, <a href="/ps/2401.06650" title="Download PostScript">ps</a>, <a href="/format/2401.06650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMI-based robust model predictive control for a quarter car with series  active variable geometry suspension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+Z">Zilin Feng</a>, 
<a href="/search/eess?searchtype=author&query=Georgiou%2C+A">Anastasis Georgiou</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+M">Min Yu</a>, 
<a href="/search/eess?searchtype=author&query=Evangelou%2C+S+A">Simos A. Evangelou</a>, 
<a href="/search/eess?searchtype=author&query=Jaimoukha%2C+I+M">Imad M Jaimoukha</a>, 
<a href="/search/eess?searchtype=author&query=Dini%2C+D">Daniele Dini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, 2 tables, IEEE Transactions on Control Systems Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a robust model predictive control-based solution for the
recently introduced series active variable geometry suspension (SAVGS) to
improve the ride comfort and road holding of a quarter car. In order to close
the gap between the nonlinear multi-body SAVGS model and its linear equivalent,
a new uncertain system characterization is proposed that captures unmodeled
dynamics, parameter variation, and external disturbances. Based on the newly
proposed linear uncertain model for the quarter car SAVGS system, a constrained
optimal control problem (OCP) is presented in the form of a linear matrix
inequality (LMI) optimization. More specifically, utilizing semidefinite
relaxation techniques a state-feedback robust model predictive control (RMPC)
scheme is presented and integrated with the nonlinear multi-body SAVGS model,
where state-feedback gain and control perturbation are computed online to
optimise performance, while physical and design constraints are preserved.
Numerical simulation results with different ISO-defined road events demonstrate
the robustness and significant performance improvement in terms of ride comfort
and road holding of the proposed approach, as compared to the conventional
passive suspension, as well as, to actively controlled SAVGS by a previously
developed conventional H-infinity control scheme.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06653" title="Abstract">arXiv:2401.06653</a> [<a href="/pdf/2401.06653" title="Download PDF">pdf</a>, <a href="/format/2401.06653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary Generative Fuzzing for Differential Testing of the Kotlin  Compiler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgescu%2C+C">Calin Georgescu</a>, 
<a href="/search/cs?searchtype=author&query=Olsthoorn%2C+M">Mitchell Olsthoorn</a>, 
<a href="/search/cs?searchtype=author&query=Derakhshanfar%2C+P">Pouria Derakhshanfar</a>, 
<a href="/search/cs?searchtype=author&query=Akhin%2C+M">Marat Akhin</a>, 
<a href="/search/cs?searchtype=author&query=Panichella%2C+A">Annibale Panichella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Compiler correctness is a cornerstone of reliable software development.
However, systematic testing of compilers is infeasible, given the vast space of
possible programs and the complexity of modern programming languages. In this
context, differential testing offers a practical methodology as it addresses
the oracle problem by comparing the output of alternative compilers given the
same set of programs as input. In this paper, we investigate the effectiveness
of differential testing in finding bugs within the Kotlin compilers developed
at JetBrains. We propose a black-box generative approach that creates input
programs for the K1 and K2 compilers. First, we build workable models of Kotlin
semantic (semantic interface) and syntactic (enriched context-free grammar)
language features, which are subsequently exploited to generate random code
snippets. Second, we extend random sampling by introducing two genetic
algorithms (GAs) that aim to generate more diverse input programs. Our case
study shows that the proposed approach effectively detects bugs in K1 and K2;
these bugs have been confirmed and (some) fixed by JetBrains developers. While
we do not observe a significant difference w.r.t. the number of defects
uncovered by the different search algorithms, random search and GAs are
complementary as they find different categories of bugs. Finally, we provide
insights into the relationships between the size, complexity, and fault
detection capability of the generated input programs.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06654" title="Abstract">arXiv:2401.06654</a> [<a href="/pdf/2401.06654" title="Download PDF">pdf</a>, <a href="/format/2401.06654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling Pixel Flipping and Occlusion Strategy for Consistent XAI  Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bl%C3%BCcher%2C+S">Stefan Bl&#xfc;cher</a>, 
<a href="/search/cs?searchtype=author&query=Vielhaben%2C+J">Johanna Vielhaben</a>, 
<a href="/search/cs?searchtype=author&query=Strodthoff%2C+N">Nils Strodthoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Feature removal is a central building block for eXplainable AI (XAI), both
for occlusion-based explanations (Shapley values) as well as their evaluation
(pixel flipping, PF). However, occlusion strategies can vary significantly from
simple mean replacement up to inpainting with state-of-the-art diffusion
models. This ambiguity limits the usefulness of occlusion-based approaches. For
example, PF benchmarks lead to contradicting rankings. This is amplified by
competing PF measures: Features are either removed starting with most
influential first (MIF) or least influential first (LIF). This study proposes
two complementary perspectives to resolve this disagreement problem. Firstly,
we address the common criticism of occlusion-based XAI, that artificial samples
lead to unreliable model evaluations. We propose to measure the reliability by
the R(eference)-Out-of-Model-Scope (OMS) score. The R-OMS score enables a
systematic comparison of occlusion strategies and resolves the disagreement
problem by grouping consistent PF rankings. Secondly, we show that the
insightfulness of MIF and LIF is conversely dependent on the R-OMS score. To
leverage this, we combine the MIF and LIF measures into the symmetric relevance
gain (SRG) measure. This breaks the inherent connection to the underlying
occlusion strategy and leads to consistent rankings. This resolves the
disagreement problem, which we verify for a set of 40 different occlusion
strategies.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06656" title="Abstract">arXiv:2401.06656</a> [<a href="/pdf/2401.06656" title="Download PDF">pdf</a>, <a href="/ps/2401.06656" title="Download PostScript">ps</a>, <a href="/format/2401.06656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Networks for Singular Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Opschoor%2C+J+A+A">Joost A. A. Opschoor</a>, 
<a href="/search/math?searchtype=author&query=Schwab%2C+C">Christoph Schwab</a>, 
<a href="/search/math?searchtype=author&query=Xenophontos%2C+C">Christos Xenophontos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We prove deep neural network (DNN for short) expressivity rate bounds for
solution sets of a model class of singularly perturbed, elliptic two-point
boundary value problems, in Sobolev norms, on the bounded interval $(-1,1)$. We
assume that the given source term and reaction coefficient are analytic in
$[-1,1]$.
<br />We establish expression rate bounds in Sobolev norms in terms of the NN size
which are uniform with respect to the singular perturbation parameter for
several classes of DNN architectures. In particular, ReLU NNs, spiking NNs, and
$\tanh$- and sigmoid-activated NNs. The latter activations can represent
``exponential boundary layer solution features'' explicitly, in the last hidden
layer of the DNN, i.e. in a shallow subnetwork, and afford improved robust
expression rate bounds in terms of the NN size.
<br />We prove that all DNN architectures allow robust exponential solution
expression in so-called `energy' as well as in `balanced' Sobolev norms, for
analytic input data.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06657" title="Abstract">arXiv:2401.06657</a> [<a href="/pdf/2401.06657" title="Download PDF">pdf</a>, <a href="/format/2401.06657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Tactile Internet with QUIC: A Security and Privacy  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+J">Jayasree Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+D">Debasmita Dey</a>, 
<a href="/search/cs?searchtype=author&query=Ferlin%2C+S">Simone Ferlin</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+N">Nirnay Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Bajpai%2C+V">Vaibhav Bajpai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The Tactile Internet paradigm is set to revolutionize human society by
enabling skill-set delivery and haptic communication over ultra-reliable,
low-latency networks. The emerging sixth-generation (6G) mobile communication
systems are envisioned to underpin this Tactile Internet ecosystem at the
network edge by providing ubiquitous global connectivity. However, apart from a
multitude of opportunities of the Tactile Internet, security and privacy
challenges emerge at the forefront. We believe that the recently standardized
QUIC protocol, characterized by end-to-end encryption and reduced round-trip
delay would serve as the backbone of Tactile Internet. In this article, we
envision a futuristic scenario where a QUIC-enabled network uses the underlying
6G communication infrastructure to achieve the requirements for Tactile
Internet. Interestingly this requires a deeper investigation of a wide range of
security and privacy challenges in QUIC, that need to be mitigated for its
adoption in Tactile Internet. Henceforth, this article reviews the existing
security and privacy attacks in QUIC and their implication on users. Followed
by that, we discuss state-of-the-art attack mitigation strategies and
investigate some of their drawbacks with possible directions for future work
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06658" title="Abstract">arXiv:2401.06658</a> [<a href="/pdf/2401.06658" title="Download PDF">pdf</a>, <a href="/ps/2401.06658" title="Download PostScript">ps</a>, <a href="/format/2401.06658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exposing Hate -- Understanding Anti-Immigration Sentiment Spreading on  Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasuto%2C+A">Andrea Nasuto</a>, 
<a href="/search/cs?searchtype=author&query=Rowe%2C+F">Francisco Rowe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Immigration is one of the most salient topics in public debate. Social media
heavily influences opinions on immigration, often sparking polarized debates
and offline tensions. Studying 220,870 immigration-related tweets in the UK, we
assessed the extent of polarization, key content creators and disseminators,
and the speed of content dissemination. We identify a high degree of online
polarization between pro and anti-immigration communities. We found that the
anti-migration community is small but denser and more active than the
pro-immigration community with the top 1% of users responsible for over 23% of
anti-immigration tweets and 21% of retweets. We also discovered that
anti-immigration content spreads also 1.66 times faster than pro-immigration
messages and bots have minimal impact on content dissemination. Our findings
suggest that identifying and tracking highly active users could curb
anti-immigration sentiment, potentially easing social polarization and shaping
broader societal attitudes toward migration.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06659" title="Abstract">arXiv:2401.06659</a> [<a href="/pdf/2401.06659" title="Download PDF">pdf</a>, <a href="/format/2401.06659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WisdoM: Improving Multimodal Sentiment Analysis by Fusing Contextual  World Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Sentiment analysis is rapidly advancing by utilizing various data modalities
(e.g., text, image). However, most previous works relied on superficial
information, neglecting the incorporation of contextual world knowledge (e.g.,
background information derived from but beyond the given image and text pairs)
and thereby restricting their ability to achieve better multimodal sentiment
analysis. In this paper, we proposed a plug-in framework named WisdoM, designed
to leverage contextual world knowledge induced from the large vision-language
models (LVLMs) for enhanced multimodal sentiment analysis. WisdoM utilizes a
LVLM to comprehensively analyze both images and corresponding sentences,
simultaneously generating pertinent context. To reduce the noise in the
context, we also introduce a training-free Contextual Fusion mechanism.
Experimental results across diverse granularities of multimodal sentiment
analysis tasks consistently demonstrate that our approach has substantial
improvements (brings an average +1.89 F1 score among five advanced methods)
over several state-of-the-art methods. Code will be released.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06665" title="Abstract">arXiv:2401.06665</a> [<a href="/pdf/2401.06665" title="Download PDF">pdf</a>, <a href="/format/2401.06665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyTOPS: Reconfigurable and Flexible Polyhedral Scheduler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Consolaro%2C+G">Gianpietro Consolaro</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Razanajato%2C+H">Harenome Razanajato</a>, 
<a href="/search/cs?searchtype=author&query=Lossing%2C+N">Nelson Lossing</a>, 
<a href="/search/cs?searchtype=author&query=Tchoulak%2C+N">Nassim Tchoulak</a>, 
<a href="/search/cs?searchtype=author&query=Susungi%2C+A">Adilla Susungi</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+A+C+A">Artur Cesar Araujo Alves</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Barthou%2C+D">Denis Barthou</a>, 
<a href="/search/cs?searchtype=author&query=Ancourt%2C+C">Corinne Ancourt</a>, 
<a href="/search/cs?searchtype=author&query=Bastoul%2C+C">Cedric Bastoul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, bibliography included. The paper has been accepted to CGO 2024 and the publication and proceedings are ongoing. This is a preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computation and Language (cs.CL); Performance (cs.PF)

</div>
<p class="mathjax">Polyhedral techniques have been widely used for automatic code optimization
in low-level compilers and higher-level processes. Loop optimization is central
to this technique, and several polyhedral schedulers like Feautrier, Pluto, isl
and Tensor Scheduler have been proposed, each of them targeting a different
architecture, parallelism model, or application scenario. The need for
scenario-specific optimization is growing due to the heterogeneity of
architectures. One of the most critical cases is represented by NPUs (Neural
Processing Units) used for AI, which may require loop optimization with
different objectives. Another factor to be considered is the framework or
compiler in which polyhedral optimization takes place. Different scenarios,
depending on the target architecture, compilation environment, and application
domain, may require different kinds of optimization to best exploit the
architecture feature set.
<br />We introduce a new configurable polyhedral scheduler, PolyTOPS, that can be
adjusted to various scenarios with straightforward, high-level configurations.
This scheduler allows the creation of diverse scheduling strategies that can be
both scenario-specific (like state-of-the-art schedulers) and kernel-specific,
breaking the concept of a one-size-fits-all scheduler approach. PolyTOPS has
been used with isl and CLooG as code generators and has been integrated in
MindSpore AKG deep learning compiler. Experimental results in different
scenarios show good performance: a geomean speedup of 7.66x on MindSpore (for
the NPU Ascend architecture) hybrid custom operators over isl scheduling, a
geomean speedup up to 1.80x on PolyBench on different multicore architectures
over Pluto scheduling. Finally, some comparisons with different
state-of-the-art tools are presented in the PolyMage scenario.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06667" title="Abstract">arXiv:2401.06667</a> [<a href="/pdf/2401.06667" title="Download PDF">pdf</a>, <a href="/format/2401.06667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The SemIoE Ontology: A Semantic Model Solution for an IoE-based Industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arazzi%2C+M">Marco Arazzi</a>, 
<a href="/search/cs?searchtype=author&query=Nocera%2C+A">Antonino Nocera</a>, 
<a href="/search/cs?searchtype=author&query=Storti%2C+E">Emanuele Storti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recently, the Industry 5.0 is gaining attention as a novel paradigm, defining
the next concrete steps toward more and more intelligent, green-aware and
user-centric digital systems. In an era in which smart devices typically
adopted in the industry domain are more and more sophisticated and autonomous,
the Internet of Things and its evolution, known as the Internet of Everything
(IoE, for short), involving also people, robots, processes and data in the
network, represent the main driver to allow industries to put the experiences
and needs of human beings at the center of their ecosystems. However, due to
the extreme heterogeneity of the involved entities, their intrinsic need and
capability to cooperate, and the aim to adapt to a dynamic user-centric
context, special attention is required for the integration and processing of
the data produced by such an IoE. This is the objective of the present paper,
in which we propose a novel semantic model that formalizes the fundamental
actors, elements and information of an IoE, along with their relationships. In
our design, we focus on state-of-the-art design principles, in particular
reuse, and abstraction, to build ``SemIoE'', a lightweight ontology inheriting
and extending concepts from well-known and consolidated reference ontologies.
The defined semantic layer represents a core data model that can be extended to
embrace any modern industrial scenario. It represents the base of an IoE
Knowledge Graph, on top of which, as an additional contribution, we analyze and
define some essential services for an IoE-based industry.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06669" title="Abstract">arXiv:2401.06669</a> [<a href="/pdf/2401.06669" title="Download PDF">pdf</a>, <a href="/format/2401.06669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User-Centric Cell-Free Wireless Networks for 6G: Communication Theoretic  Models and Research Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B6ttsch%2C+F">Fabian G&#xf6;ttsch</a>, 
<a href="/search/cs?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Schubert%2C+M">Martin Schubert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper presents a comprehensive communication theoretic model for the
physical layer of a cell-free user-centric network, formed by user equipments
(UEs), radio units (RUs), and decentralized units (DUs), uniformly spatially
distributed over a given coverage area. We consider RUs equipped with multiple
antennas, and focus on the regime where the UE, RU, and DU densities are
constant and therefore the number of such nodes grows with the coverage area. A
system is said scalable if the computing load and information rate at any node
in the network converges to a constant as the network size (coverage area)
grows to infinity. This imposes that each UE must be processed by a
(user-centric) finite-size cluster of RUs, and that such cluster processors are
dynamically allocated to the DUs (e.g., as software defined virtual network
functions) in order to achieve a balanced computation load. We also assume that
the RUs are connected to the DUs through a packet switching network, in order
to achieve adaptive routing and load balance. For this model, we define in
details the dynamic cluster formation and uplink pilot allocation. As a
consequence of the pilot allocation and the scalability constraint, each
cluster processor has a partial view of the network channel state information.
We define the condition of ``ideal partial CSI'' when the channel vectors that
can be estimated are perfectly known (while the ones that cannot be estimated
are not know at all). We develop two attractive cluster-based linear receiver
schemes for the uplink, and an uplink-downlink duality that allows to reuse
such vectors as precoders for the downlink.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06671" title="Abstract">arXiv:2401.06671</a> [<a href="/pdf/2401.06671" title="Download PDF">pdf</a>, <a href="/format/2401.06671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Joint Space Reference Manifold for Reliable Physical Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Razmjoo%2C+A">Amirreza Razmjoo</a>, 
<a href="/search/cs?searchtype=author&query=Brecelj%2C+T">Tilen Brecelj</a>, 
<a href="/search/cs?searchtype=author&query=Savevska%2C+K">Kristina Savevska</a>, 
<a href="/search/cs?searchtype=author&query=Ude%2C+A">Ale&#x161; Ude</a>, 
<a href="/search/cs?searchtype=author&query=Petri%C4%8D%2C+T">Tadej Petri&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Calinon%2C+S">Sylvain Calinon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Video can be accessed via: <a href="https://www.youtube.com/watch?v=GQAad6GFPlE">this https URL</a>&amp;list=LL&amp;index=1; Accepted for IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a study on the use of the Talos humanoid robot for
performing assistive sit-to-stand or stand-to-sit tasks. In such tasks, the
human exerts a large amount of force (100--200 N) within a very short time
(2--8 s), posing significant challenges in terms of human unpredictability and
robot stability control. To address these challenges, we propose an approach
for finding a spatial reference for the robot, which allows the robot to move
according to the force exerted by the human and control its stability during
the task. Specifically, we focus on the problem of finding a 1D manifold for
the robot, while assuming a simple controller to guide its movement on this
manifold. To achieve this, we use a functional representation to parameterize
the manifold and solve an optimization problem that takes into account the
robot's stability and the unpredictability of human behavior. We demonstrate
the effectiveness of our approach through simulations and experiments with the
Talos robot, showing robustness and adaptability.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06672" title="Abstract">arXiv:2401.06672</a> [<a href="/pdf/2401.06672" title="Download PDF">pdf</a>, <a href="/format/2401.06672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding critical transitions of the post-disaster recovery using the  sensitivity analysis of agent-based models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangung Park</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jiawei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Ukkusuri%2C+S+V">Satish V. Ukkusuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Frequent and intensive disasters make the repeated and uncertain
post-disaster recovery process. Despite the importance of the successful
recovery process, previous simulation studies on the post-disaster recovery
process did not explore the sufficient number of household return decision
model types, population sizes, and the corresponding critical transition
conditions of the system. This paper simulates the recovery process in the
agent-based model with multilayer networks to reveal the impact of household
return decision model types and population sizes in a toy network. After that,
this paper applies the agent-based model to the five selected counties affected
by Hurricane Harvey in 2017 to check the urban-rural recovery differences by
types of household return decision models. The agent-based model yields three
conclusions. First, the threshold model can successfully substitute the binary
logit model. Second, high thresholds and less than 1,000 populations perturb
the recovery process, yielding critical transitions during the recovery
process. Third, this study checks the urban-rural recovery value differences by
different decision model types. This study highlights the importance of the
threshold models and population sizes to check the critical transitions and
urban-rural differences in the recovery process.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06676" title="Abstract">arXiv:2401.06676</a> [<a href="/pdf/2401.06676" title="Download PDF">pdf</a>, <a href="/ps/2401.06676" title="Download PostScript">ps</a>, <a href="/format/2401.06676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMRS: Unlocking Potentials of LLM-Based Recommender Systems for  Software Purchase
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=John%2C+A">Angela John</a>, 
<a href="/search/cs?searchtype=author&query=Aidoo%2C+T">Theophilus Aidoo</a>, 
<a href="/search/cs?searchtype=author&query=Behmanush%2C+H">Hamayoon Behmanush</a>, 
<a href="/search/cs?searchtype=author&query=Gunduz%2C+I+B">Irem B. Gunduz</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+H">Hewan Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+R">Maxx Richard Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Maa%C3%9F%2C+W">Wolfgang Maa&#xdf;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recommendation systems are ubiquitous, from Spotify playlist suggestions to
Amazon product suggestions. Nevertheless, depending on the methodology or the
dataset, these systems typically fail to capture user preferences and generate
general recommendations. Recent advancements in Large Language Models (LLM)
offer promising results for analyzing user queries. However, employing these
models to capture user preferences and efficiency remains an open question. In
this paper, we propose LLMRS, an LLM-based zero-shot recommender system where
we employ pre-trained LLM to encode user reviews into a review score and
generate user-tailored recommendations. We experimented with LLMRS on a
real-world dataset, the Amazon product reviews, for software purchase use
cases. The results show that LLMRS outperforms the ranking-based baseline model
while successfully capturing meaningful information from product reviews,
thereby providing more reliable recommendations.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06683" title="Abstract">arXiv:2401.06683</a> [<a href="/pdf/2401.06683" title="Download PDF">pdf</a>, <a href="/format/2401.06683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DQNC2S: DQN-based Cross-stream Crisis event Summarizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cambrin%2C+D+R">Daniele Rege Cambrin</a>, 
<a href="/search/cs?searchtype=author&query=Cagliero%2C+L">Luca Cagliero</a>, 
<a href="/search/cs?searchtype=author&query=Garza%2C+P">Paolo Garza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ECIR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Summarizing multiple disaster-relevant data streams simultaneously is
particularly challenging as existing Retrieve&amp;Re-ranking strategies suffer from
the inherent redundancy of multi-stream data and limited scalability in a
multi-query setting. This work proposes an online approach to crisis timeline
generation based on weak annotation with Deep Q-Networks. It selects on-the-fly
the relevant pieces of text without requiring neither human annotations nor
content re-ranking. This makes the inference time independent of the number of
input queries. The proposed approach also incorporates a redundancy filter into
the reward function to effectively handle cross-stream content overlaps. The
achieved ROUGE and BERTScore results are superior to those of best-performing
models on the CrisisFACTS 2022 benchmark.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06684" title="Abstract">arXiv:2401.06684</a> [<a href="/pdf/2401.06684" title="Download PDF">pdf</a>, <a href="/format/2401.06684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial Preconditioning for the Action of the Matrix Square Root and  Inverse Square Root
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frommer%2C+A">Andreas Frommer</a>, 
<a href="/search/math?searchtype=author&query=Ramirez-Hidalgo%2C+G">Gustavo Ramirez-Hidalgo</a>, 
<a href="/search/math?searchtype=author&query=Schweitzer%2C+M">Marcel Schweitzer</a>, 
<a href="/search/math?searchtype=author&query=Tsolakis%2C+M">Manuel Tsolakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">While preconditioning is a long-standing concept to accelerate iterative
methods for linear systems, generalizations to matrix functions are still in
their infancy. We go a further step in this direction, introducing polynomial
preconditioning for Krylov subspace methods which approximate the action of the
matrix square root and inverse square root on a vector. Preconditioning reduces
the subspace size and therefore avoids the storage problem together with -- for
non-Hermitian matrices -- the increased computational cost per iteration that
arises in the unpreconditioned case. Polynomial preconditioning is an
attractive alternative to current restarting or sketching approaches since it
is simpler and computationally more efficient. We demonstrate this for several
numerical examples.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06686" title="Abstract">arXiv:2401.06686</a> [<a href="/pdf/2401.06686" title="Download PDF">pdf</a>, <a href="/format/2401.06686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Conversational Agents as an Effective Tool for Measuring  Cognitive Biases in Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pilli%2C+S">Stephen Pilli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Heuristics and cognitive biases are an integral part of human
decision-making. Automatically detecting a particular cognitive bias could
enable intelligent tools to provide better decision-support. Detecting the
presence of a cognitive bias currently requires a hand-crafted experiment and
human interpretation. Our research aims to explore conversational agents as an
effective tool to measure various cognitive biases in different domains. Our
proposed conversational agent incorporates a bias measurement mechanism that is
informed by the existing experimental designs and various experimental tasks
identified in the literature. Our initial experiments to measure framing and
loss-aversion biases indicate that the conversational agents can be effectively
used to measure the biases.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06687" title="Abstract">arXiv:2401.06687</a> [<a href="/pdf/2401.06687" title="Download PDF">pdf</a>, <a href="/format/2401.06687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proximal Causal Inference With Text Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+M">Jacob M. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+R">Rohit Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Keith%2C+K+A">Katherine A. Keith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Recent text-based causal methods attempt to mitigate confounding bias by
including unstructured text data as proxies of confounding variables that are
partially or imperfectly measured. These approaches assume analysts have
supervised labels of the confounders given text for a subset of instances, a
constraint that is not always feasible due to data privacy or cost. Here, we
address settings in which an important confounding variable is completely
unobserved. We propose a new causal inference method that splits pre-treatment
text data, infers two proxies from two zero-shot models on the separate splits,
and applies these proxies in the proximal g-formula. We prove that our
text-based proxy method satisfies identification conditions required by the
proximal g-formula while other seemingly reasonable proposals do not. We
evaluate our method in synthetic and semi-synthetic settings and find that it
produces estimates with low bias. This combination of proximal causal inference
and zero-shot classifiers is novel (to our knowledge) and expands the set of
text-specific causal methods available to practitioners.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06688" title="Abstract">arXiv:2401.06688</a> [<a href="/pdf/2401.06688" title="Download PDF">pdf</a>, <a href="/format/2401.06688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t Rank, Combine! Combining Machine Translation Hypotheses Using  Quality Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vernikos%2C+G">Giorgos Vernikos</a>, 
<a href="/search/cs?searchtype=author&query=Popescu-Belis%2C+A">Andrei Popescu-Belis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural machine translation systems estimate probabilities of target sentences
given source sentences, yet these estimates may not align with human
preferences. This work introduces QE-fusion, a method utilizing a quality
estimation metric (QE) that better correlates with human judgments to
synthesize improved translations. QE-fusion leverages a candidate pool sampled
from a model, combining spans from different candidates using QE metrics such
as CometKiwi. We compare QE-fusion against beam search and recent reranking
techniques, such as Minimum Bayes Risk decoding or QE-reranking. Our method
consistently improves translation quality in terms of COMET and BLEURT scores
when applied to large language models (LLMs) used for translation (PolyLM,
XGLM, Llama2, and Mistral) and to multilingual translation models (NLLB), over
five language pairs. Notably, QE-fusion exhibits larger improvements for LLMs
due to their ability to generate diverse outputs. We demonstrate that our
approach generates novel translations in over half of the cases and
consistently outperforms other methods across varying numbers of candidates
(5-200). Furthermore, we empirically establish that QE-fusion scales linearly
with the number of candidates in the pool. QE-fusion proves effective in
enhancing LLM-based translation without the need for costly retraining of LLMs.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06690" title="Abstract">arXiv:2401.06690</a> [<a href="/pdf/2401.06690" title="Download PDF">pdf</a>, <a href="/format/2401.06690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedded Planogram Compliance Control System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Y%C3%BCcel%2C+M+E">M. Erkin Y&#xfc;cel</a>, 
<a href="/search/cs?searchtype=author&query=Topalo%C4%9Flu%2C+S">Serkan Topalo&#x11f;lu</a>, 
<a href="/search/cs?searchtype=author&query=%C3%9Cnsalan%2C+C">Cem &#xdc;nsalan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The retail sector presents several open and challenging problems that could
benefit from advanced pattern recognition and computer vision techniques. One
such critical challenge is planogram compliance control. In this study, we
propose a complete embedded system to tackle this issue. Our system consists of
four key components as image acquisition and transfer via stand-alone embedded
camera module, object detection via computer vision and deep learning methods
working on single board computers, planogram compliance control method again
working on single board computers, and energy harvesting and power management
block to accompany the embedded camera modules. The image acquisition and
transfer block is implemented on the ESP-EYE camera module. The object
detection block is based on YOLOv5 as the deep learning method and local
feature extraction. We implement these methods on Raspberry Pi 4, NVIDIA Jetson
Orin Nano, and NVIDIA Jetson AGX Orin as single board computers. The planogram
compliance control block utilizes sequence alignment through a modified
Needleman-Wunsch algorithm. This block is also working along with the object
detection block on the same single board computers. The energy harvesting and
power management block consists of solar and RF energy harvesting modules with
suitable battery pack for operation. We tested the proposed embedded planogram
compliance control system on two different datasets to provide valuable
insights on its strengths and weaknesses. The results show that our method
achieves F1 scores of 0.997 and 1.0 in object detection and planogram
compliance control blocks, respectively. Furthermore, we calculated that the
complete embedded system can work in stand-alone form up to two years based on
battery. This duration can be further extended with the integration of the
proposed solar and RF energy harvesting options.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06692" title="Abstract">arXiv:2401.06692</a> [<a href="/pdf/2401.06692" title="Download PDF">pdf</a>, <a href="/format/2401.06692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Experimental Design Framework for Label-Efficient Supervised  Finetuning of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+G">Gantavya Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A+M">Arnav M. Das</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+S+T">Sang T. Truong</a>, 
<a href="/search/cs?searchtype=author&query=Mussmann%2C+S">Stephen Mussmann</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yinglun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Bilmes%2C+J">Jeffrey Bilmes</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kevin Jamieson</a>, 
<a href="/search/cs?searchtype=author&query=Ash%2C+J+T">Jordan T. Ash</a>, 
<a href="/search/cs?searchtype=author&query=Nowak%2C+R+D">Robert D. Nowak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Supervised finetuning (SFT) on instruction datasets has played a crucial role
in achieving the remarkable zero-shot generalization capabilities observed in
modern large language models (LLMs). However, the annotation efforts required
to produce high quality responses for instructions are becoming prohibitively
expensive, especially as the number of tasks spanned by instruction datasets
continues to increase. Active learning is effective in identifying useful
subsets of samples to annotate from an unlabeled pool, but its high
computational cost remains a barrier to its widespread applicability in the
context of LLMs. To mitigate the annotation cost of SFT and circumvent the
computational bottlenecks of active learning, we propose using experimental
design. Experimental design techniques select the most informative samples to
label, and typically maximize some notion of uncertainty and/or diversity. In
our work, we implement a framework that evaluates several existing and novel
experimental design techniques and find that these methods consistently yield
significant gains in label efficiency with little computational overhead. On
generative tasks, our methods achieve the same generalization performance with
only $50\%$ of annotation cost required by random sampling.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06697" title="Abstract">arXiv:2401.06697</a> [<a href="/pdf/2401.06697" title="Download PDF">pdf</a>, <a href="/ps/2401.06697" title="Download PostScript">ps</a>, <a href="/format/2401.06697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Machine Learning in the Cognitive Domain: Alzheimer&#x27;s Disease  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akpinar%2C+E">Emine Akpinar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Alzheimer's disease (AD) is the most prevalent neurodegenerative brain
disorder, which results in significant cognitive impairments, especially in the
elderly population. Cognitive impairments can manifest as a decline in various
mental faculties, such as concentration, memory, and other higher-order
cognitive abilities. These deficits can significantly impact an individual's
capacity to comprehend information, acquire new knowledge, and communicate
effectively. One of the affected activities due to cognitive impairments is
handwriting. By analyzing different aspects of handwriting, including pressure,
velocity, and spatial organization, researchers can detect subtle alterations
that might indicate early-stage cognitive impairments, especially AD. Recently,
several classical artificial intelligence (AI) approaches have been proposed
for detecting AD in elderly individuals through handwriting analysis. However,
advanced AI methods require more computational power as the size of the data
increases. Additionally, diagnoses can be influenced by factors such as limited
relevant classical vector space and correlations between features. Recent
studies have shown that using quantum computing technologies in healthcare can
not only address these problems but also accelerate complex data analysis and
process large datasets more efficiently. In this study, we introduced a
variational quantum classifier with fewer circuit elements to facilitate the
early diagnosis of AD in elderly individuals based on handwriting data. We
employed ZZFeatureMap for encoding features. To classify AD, a parameterized
quantum circuit consisting of repeated Ry and Rz rotation gates, as well as CY
and CZ two-qubit entangling gates, was designed and implemented. The proposed
model achieved an accuracy of 0.75 in classifying AD.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06699" title="Abstract">arXiv:2401.06699</a> [<a href="/pdf/2401.06699" title="Download PDF">pdf</a>, <a href="/ps/2401.06699" title="Download PostScript">ps</a>, <a href="/format/2401.06699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Closed-form Solution for Weight Optimization in Fully-connected  Feed-forward Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tomic%2C+S">Slavisa Tomic</a>, 
<a href="/search/cs?searchtype=author&query=Matos-Carvalho%2C+J+P">Jo&#xe3;o Pedro Matos-Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Beko%2C+M">Marko Beko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work addresses weight optimization problem for fully-connected
feed-forward neural networks. Unlike existing approaches that are based on
back-propagation (BP) and chain rule gradient-based optimization (which implies
iterative execution, potentially burdensome and time-consuming in some cases),
the proposed approach offers the solution for weight optimization in
closed-form by means of least squares (LS) methodology. In the case where the
input-to-output mapping is injective, the new approach optimizes the weights in
a back-propagating fashion in a single iteration by jointly optimizing a set of
weights in each layer for each neuron. In the case where the input-to-output
mapping is not injective (e.g., in classification problems), the proposed
solution is easily adapted to obtain its final solution in a few iterations. An
important advantage over the existing solutions is that these computations (for
all neurons in a layer) are independent from each other; thus, they can be
carried out in parallel to optimize all weights in a given layer
simultaneously. Furthermore, its running time is deterministic in the sense
that one can obtain the exact number of computations necessary to optimize the
weights in all network layers (per iteration, in the case of non-injective
mapping). Our simulation and empirical results show that the proposed scheme,
BPLS, works well and is competitive with existing ones in terms of accuracy,
but significantly surpasses them in terms of running time. To summarize, the
new method is straightforward to implement, is competitive and computationally
more efficient than the existing ones, and is well-tailored for parallel
implementation.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06703" title="Abstract">arXiv:2401.06703</a> [<a href="/pdf/2401.06703" title="Download PDF">pdf</a>, <a href="/format/2401.06703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Learned Sparse Retrieval with Corpus-Specific Vocabularies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+P">Puxuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Mallia%2C+A">Antonio Mallia</a>, 
<a href="/search/cs?searchtype=author&query=Petri%2C+M">Matthias Petri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ECIR 2024 Full Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">We explore leveraging corpus-specific vocabularies that improve both
efficiency and effectiveness of learned sparse retrieval systems. We find that
pre-training the underlying BERT model on the target corpus, specifically
targeting different vocabulary sizes incorporated into the document expansion
process, improves retrieval quality by up to 12% while in some scenarios
decreasing latency by up to 50%. Our experiments show that adopting
corpus-specific vocabulary and increasing vocabulary size decreases average
postings list length which in turn reduces latency. Ablation studies show
interesting interactions between custom vocabularies, document expansion
techniques, and sparsification objectives of sparse models. Both effectiveness
and efficiency improvements transfer to different retrieval approaches such as
uniCOIL and SPLADE and offer a simple yet effective approach to providing new
efficiency-effectiveness trade-offs for learned sparse retrieval systems.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06704" title="Abstract">arXiv:2401.06704</a> [<a href="/pdf/2401.06704" title="Download PDF">pdf</a>, <a href="/format/2401.06704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable 3D Panoptic Segmentation With Superpoint Graph Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robert%2C+D">Damien Robert</a>, 
<a href="/search/cs?searchtype=author&query=Raguet%2C+H">Hugo Raguet</a>, 
<a href="/search/cs?searchtype=author&query=Landrieu%2C+L">Loic Landrieu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 3DV 2024, Oral presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a highly efficient method for panoptic segmentation of large 3D
point clouds by redefining this task as a scalable graph clustering problem.
This approach can be trained using only local auxiliary tasks, thereby
eliminating the resource-intensive instance-matching step during training.
Moreover, our formulation can easily be adapted to the superpoint paradigm,
further increasing its efficiency. This allows our model to process scenes with
millions of points and thousands of objects in a single inference. Our method,
called SuperCluster, achieves a new state-of-the-art panoptic segmentation
performance for two indoor scanning datasets: $50.1$ PQ ($+7.8$) for S3DIS
Area~5, and $58.7$ PQ ($+25.2$) for ScanNetV2. We also set the first
state-of-the-art for two large-scale mobile mapping benchmarks: KITTI-360 and
DALES. With only $209$k parameters, our model is over $30$ times smaller than
the best-competing method and trains up to $15$ times faster. Our code and
pretrained models are available at
https://github.com/drprojects/superpoint_transformer.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06706" title="Abstract">arXiv:2401.06706</a> [<a href="/pdf/2401.06706" title="Download PDF">pdf</a>, <a href="/format/2401.06706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Candidate Speculative Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xinyu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models have shown impressive capabilities across a variety of
NLP tasks, yet their generating text autoregressively is time-consuming. One
way to speed them up is speculative decoding, which generates candidate
segments (a sequence of tokens) from a fast draft model that is then verified
in parallel by the target model. However, the acceptance rate of candidate
tokens receives limitations from several factors, such as the model, the
dataset, and the decoding setup. This paper proposes sampling multiple
candidates from a draft model and then organising them in batches for
verification. We design algorithms for efficient multi-candidate verification
while maintaining the distribution of the target model. Our approach shows
significant improvements in acceptance rates on multiple datasets and models,
consistently outperforming standard speculative decoding.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06709" title="Abstract">arXiv:2401.06709</a> [<a href="/pdf/2401.06709" title="Download PDF">pdf</a>, <a href="/format/2401.06709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability Analysis of Psychological Concept Extraction and  Classification in User-penned Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+M">Muskan Garg</a>, 
<a href="/search/cs?searchtype=author&query=Sathvik%2C+M">MSVPJ Sathvik</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Amrit Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Raza%2C+S">Shaina Raza</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+S">Sunghwan Sohn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The social NLP research community witness a recent surge in the computational
advancements of mental health analysis to build responsible AI models for a
complex interplay between language use and self-perception. Such responsible AI
models aid in quantifying the psychological concepts from user-penned texts on
social media. On thinking beyond the low-level (classification) task, we
advance the existing binary classification dataset, towards a higher-level task
of reliability analysis through the lens of explanations, posing it as one of
the safety measures. We annotate the LoST dataset to capture nuanced textual
cues that suggest the presence of low self-esteem in the posts of Reddit users.
We further state that the NLP models developed for determining the presence of
low self-esteem, focus more on three types of textual cues: (i) Trigger: words
that triggers mental disturbance, (ii) LoST indicators: text indicators
emphasizing low self-esteem, and (iii) Consequences: words describing the
consequences of mental disturbance. We implement existing classifiers to
examine the attention mechanism in pre-trained language models (PLMs) for a
domain-specific psychology-grounded task. Our findings suggest the need of
shifting the focus of PLMs from Trigger and Consequences to a more
comprehensive explanation, emphasizing LoST indicators while determining low
self-esteem in Reddit posts.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06710" title="Abstract">arXiv:2401.06710</a> [<a href="/pdf/2401.06710" title="Download PDF">pdf</a>, <a href="/format/2401.06710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free Approximate Bayesian Learning for Large-Scale Conversion  Funnel Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iyengar%2C+G">Garud Iyengar</a>, 
<a href="/search/cs?searchtype=author&query=Singal%2C+R">Raghav Singal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">The flexibility of choosing the ad action as a function of the consumer state
is critical for modern-day marketing campaigns. We study the problem of
identifying the optimal sequential personalized interventions that maximize the
adoption probability for a new product. We model consumer behavior by a
conversion funnel that captures the state of each consumer (e.g., interaction
history with the firm) and allows the consumer behavior to vary as a function
of both her state and firm's sequential interventions. We show our model
captures consumer behavior with very high accuracy (out-of-sample AUC of over
0.95) in a real-world email marketing dataset. However, it results in a very
large-scale learning problem, where the firm must learn the state-specific
effects of various interventions from consumer interactions. We propose a novel
attribution-based decision-making algorithm for this problem that we call
model-free approximate Bayesian learning. Our algorithm inherits the
interpretability and scalability of Thompson sampling for bandits and maintains
an approximate belief over the value of each state-specific intervention. The
belief is updated as the algorithm interacts with the consumers. Despite being
an approximation to the Bayes update, we prove the asymptotic optimality of our
algorithm and analyze its convergence rate. We show that our algorithm
significantly outperforms traditional approaches on extensive simulations
calibrated to a real-world email marketing dataset.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06712" title="Abstract">arXiv:2401.06712</a> [<a href="/pdf/2401.06712" title="Download PDF">pdf</a>, <a href="/format/2401.06712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Detection of Machine-Generated Text using Style Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soto%2C+R+R">Rafael Rivera Soto</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+K">Kailin Koch</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Aleem Khan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Barry Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bishop%2C+M">Marcus Bishop</a>, 
<a href="/search/cs?searchtype=author&query=Andrews%2C+N">Nicholas Andrews</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The advent of instruction-tuned language models that convincingly mimic human
writing poses a significant risk of abuse. For example, such models could be
used for plagiarism, disinformation, spam, or phishing. However, such abuse may
be counteracted with the ability to detect whether a piece of text was composed
by a language model rather than a human. Some previous approaches to this
problem have relied on supervised methods trained on corpora of confirmed human
and machine-written documents. Unfortunately, model under-specification poses
an unavoidable challenge for neural network-based detectors, making them
brittle in the face of data shifts, such as the release of further language
models producing still more fluent text than the models used to train the
detectors. Other previous approaches require access to the models that may have
generated a document in question at inference or detection time, which is often
impractical. In light of these challenges, we pursue a fundamentally different
approach not relying on samples from language models of concern at training
time. Instead, we propose to leverage representations of writing style
estimated from human-authored text. Indeed, we find that features effective at
distinguishing among human authors are also effective at distinguishing human
from machine authors, including state of the art large language models like
Llama 2, ChatGPT, and GPT-4. Furthermore, given a handful of examples composed
by each of several specific language models of interest, our approach affords
the ability to predict which model generated a given document.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06713" title="Abstract">arXiv:2401.06713</a> [<a href="/pdf/2401.06713" title="Download PDF">pdf</a>, <a href="/format/2401.06713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> \texttt{Picasso}: Memory-Efficient Graph Coloring Using Palettes With  Applications in Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdous%2C+S+M">S M Ferdous</a>, 
<a href="/search/cs?searchtype=author&query=Neff%2C+R">Reece Neff</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Shuvo%2C+S">Salman Shuvo</a>, 
<a href="/search/cs?searchtype=author&query=Minutoli%2C+M">Marco Minutoli</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Sayak Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Kowalski%2C+K">Karol Kowalski</a>, 
<a href="/search/cs?searchtype=author&query=Becchi%2C+M">Michela Becchi</a>, 
<a href="/search/cs?searchtype=author&query=Halappanavar%2C+M">Mahantesh Halappanavar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IPDPS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">A \emph{coloring} of a graph is an assignment of colors to vertices such that
no two neighboring vertices have the same color. The need for memory-efficient
coloring algorithms is motivated by their application in computing clique
partitions of graphs arising in quantum computations where the objective is to
map a large set of Pauli strings into a compact set of unitaries. We present
\texttt{Picasso}, a randomized memory-efficient iterative parallel graph
coloring algorithm with theoretical sublinear space guarantees under practical
assumptions. The parameters of our algorithm provide a trade-off between
coloring quality and resource consumption. To assist the user, we also propose
a machine learning model to predict the coloring algorithm's parameters
considering these trade-offs. We provide a sequential and a parallel
implementation of the proposed algorithm.
<br />We perform an experimental evaluation on a 64-core AMD CPU equipped with 512
GB of memory and an Nvidia A100 GPU with 40GB of memory. For a small dataset
where existing coloring algorithms can be executed within the 512 GB memory
budget, we show up to {\bf 68$\times$} memory savings. On massive datasets we
demonstrate that GPU-accelerated \pic{} can process inputs with {\bf
49.5$\times$} more Pauli strings (vertex set in our graph) and {\bf
2,478$\times$} more edges than state-of-the-art parallel approaches.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06714" title="Abstract">arXiv:2401.06714</a> [<a href="/pdf/2401.06714" title="Download PDF">pdf</a>, <a href="/format/2401.06714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPT Approximation for Capacitated Sum of Radii
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaiswal%2C+R">Ragesh Jaiswal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Amit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+J">Jatin Yadav</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We consider the capacitated clustering problem in general metric spaces where
the goal is to identify $k$ clusters and minimize the sum of the radii of the
clusters (we call this the Capacitated-$k$-sumRadii problem). We are interested
in fixed-parameter tractable (FPT) approximation algorithms where the running
time is of the form $f(k) \cdot \text{poly}(n)$, where $f(k)$ can be an
exponential function of $k$ and $n$ is the number of points in the input. In
the uniform capacity case, Bandyapadhyay et al. recently gave a
$4$-approximation algorithm for this problem. Our first result improves this to
an FPT $3$-approximation and extends to a constant factor approximation for any
$L_p$ norm of the cluster radii. In the general capacities version,
Bandyapadhyay et al. gave an FPT $15$-approximation algorithm. We extend their
framework to give an FPT $(4 + \sqrt{13})$-approximation algorithm for this
problem. Our framework relies on a novel idea of identifying approximations to
optimal clusters by carefully pruning points from an initial candidate set of
points. This is in contrast to prior results that rely on guessing suitable
points and building balls of appropriate radii around them.
<br />On the hardness front, we show that assuming the Exponential Time Hypothesis,
there is a constant $c &gt; 1$ such that any $c$-approximation algorithm for the
non-uniform capacity version of this problem requires running time $2^{\Omega
\left(\frac{k}{polylog(k)} \right)}$.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06715" title="Abstract">arXiv:2401.06715</a> [<a href="/pdf/2401.06715" title="Download PDF">pdf</a>, <a href="/format/2401.06715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reframing Tax Law Entailment as Analogical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xinrui Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Weir%2C+N">Nathaniel Weir</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Holzenberger%2C+N">Nils Holzenberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Statutory reasoning refers to the application of legislative provisions to a
series of case facts described in natural language. We re-frame statutory
reasoning as an analogy task, where each instance of the analogy task involves
a combination of two instances of statutory reasoning. This increases the
dataset size by two orders of magnitude, and introduces an element of
interpretability. We show that this task is roughly as difficult to Natural
Language Processing models as the original task. Finally, we come back to
statutory reasoning, solving it with a combination of a retrieval mechanism and
analogy models, and showing some progress on prior comparable work.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06717" title="Abstract">arXiv:2401.06717</a> [<a href="/pdf/2401.06717" title="Download PDF">pdf</a>, <a href="/format/2401.06717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Obstacle-Aware Positioning of a Mobile Robotic Platform for 6G Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costa%2C+A">Alexandre Costa</a>, 
<a href="/search/cs?searchtype=author&query=Duarte%2C+P">Pedro Duarte</a>, 
<a href="/search/cs?searchtype=author&query=Coelho%2C+A">Andr&#xe9; Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Campos%2C+R">Rui Campos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The 6G paradigm and the massive usage of interconnected wireless devices
introduced the need for flexible wireless networks. A promising approach lies
in employing Mobile Robotic Platforms (MRPs) to create communications cells
on-demand. The challenge consists in positioning the MRPs to improve the
wireless connectivity offered. This is exacerbated in millimeter wave (mmWave),
Terahertz (THz), and visible light-based networks, which imply the
establishment of short-range, Line of Sight (LoS) wireless links to take
advantage of the ultra-high bandwidth channels available.
<br />This paper proposes a solution to enable the obstacle-aware, autonomous
positioning of MRPs and provide LoS wireless connectivity to communications
devices. It consists of 1) a Vision Module that uses video data gathered by the
MRP to determine the location of obstacles, wireless devices and users, and 2)
a Control Module, which autonomously positions the MRP based on the information
provided by the Vision Module. The proposed solution was validated in
simulation and through experimental testing, showing that it is able to
position an MRP while ensuring LoS wireless links between a mobile
communications cell and wireless devices or users.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06721" title="Abstract">arXiv:2401.06721</a> [<a href="/pdf/2401.06721" title="Download PDF">pdf</a>, <a href="/format/2401.06721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Identification in Data-driven Policy Iteration: A System  Theoretic Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+B">Bowen Song</a>, 
<a href="/search/eess?searchtype=author&query=Iannelli%2C+A">Andrea Iannelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The goal of this article is to study fundamental mechanisms behind so-called
indirect and direct data-driven control for unknown systems. Specifically, we
consider policy iteration applied to the linear quadratic regulator problem.
Two iterative procedures, where data collected from the system are repeatedly
used to compute new estimates of the desired optimal controller, are
considered. In indirect policy iteration, data are used to obtain an updated
model estimate through a recursive identification scheme, which is used in a
certainty-equivalent fashion to perform the classic policy iteration update. By
casting the concurrent model identification and control design as a feedback
interconnection between two algorithmic systems, we provide a closed-loop
analysis that shows convergence and robustness properties for arbitrary levels
of excitation in the data. In direct policy iteration, data are used to
approximate the value function and design the associated controller without
requiring the intermediate identification step. After proposing an extension to
a recently proposed scheme that overcomes potential identifiability issues, we
establish under which conditions this procedure is guaranteed to deliver the
optimal controller. Based on these analyses we are able to compare the
strengths and limitations of the two approaches, highlighting aspects such as
the required samples, convergence properties, and excitation requirement.
Simulations are also provided to illustrate the results.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06722" title="Abstract">arXiv:2401.06722</a> [<a href="/pdf/2401.06722" title="Download PDF">pdf</a>, <a href="/ps/2401.06722" title="Download PostScript">ps</a>, <a href="/format/2401.06722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NetMind: Adaptive RAN Baseband Function Placement by GCN Encoding and  Maze-solving DRL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peizheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Assis%2C+K+D">Karcius Day Assis</a>, 
<a href="/search/cs?searchtype=author&query=Aijaz%2C+A">Adnan Aijaz</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Sen Shen</a>, 
<a href="/search/cs?searchtype=author&query=Nejabati%2C+R">Reza Nejabati</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuangyi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Simeonidou%2C+D">Dimitra Simeonidou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accpeted by IEEE Wireless Communications and Networking Conference (WCNC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The disaggregated and hierarchical architecture of advanced RAN presents
significant challenges in efficiently placing baseband functions and user plane
functions in conjunction with Multi-Access Edge Computing (MEC) to accommodate
diverse 5G services. Therefore, this paper proposes a novel approach NetMind,
which leverages Deep Reinforcement Learning (DRL) to determine the function
placement strategies in RANs with diverse topologies, aiming at minimizing
power consumption. NetMind formulates the function placement problem as a
maze-solving task, enabling a Markov Decision Process with standardized action
space scales across different networks. Additionally, a Graph Convolutional
Network (GCN) based encoding mechanism is introduced, allowing features from
different networks to be aggregated into a single RL agent. That facilitates
the RL agent's generalization capability and minimizes the negative impact of
retraining on power consumption. In an example with three sub-networks, NetMind
achieves comparable performance to traditional methods that require a dedicated
DRL agent for each network, resulting in a 70% reduction in training costs.
Furthermore, it demonstrates a substantial 32.76% improvement in power savings
and a 41.67% increase in service stability compared to benchmarks from the
existing literature.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06723" title="Abstract">arXiv:2401.06723</a> [<a href="/pdf/2401.06723" title="Download PDF">pdf</a>, <a href="/format/2401.06723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of the Energy Consumption of a Mobile Robotic Platform for  Sustainable 6G Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+D">Diogo Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Coelho%2C+A">Andr&#xe9; Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Campos%2C+R">Rui Campos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The emerging 6G paradigm and the proliferation of wireless devices require
flexible network infrastructures capable of meeting the increasing Quality of
Service (QoS) requirements. Mobile Robotic Platforms (MRPs) acting as mobile
communications cells are a promising solution to provide on-demand wireless
connectivity in dynamic networking scenarios. However, the energy consumption
of MRPs is a challenge that must be considered, in order to maximize the
availability of the wireless networks created.
<br />The main contribution of this paper is the experimental evaluation of the
energy consumption of an MRP acting as a mobile communications cell. The
evaluation considers different actions performed by a real MRP, showing that
the energy consumption varies significantly with the type of action performed.
The obtained results pave the way for optimizing the MRP movement in dynamic
networking scenarios so that the wireless network's availability is maximized
while minimizing the MRP's energy consumption.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06727" title="Abstract">arXiv:2401.06727</a> [<a href="/pdf/2401.06727" title="Download PDF">pdf</a>, <a href="/format/2401.06727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Manifold Graph Auto-Encoder for Attributed Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bozhen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Z">Zelin Zang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lirong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by ICASSP2023, due to download limitations, we upload this work here
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In ICASSP 2023-2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP) (pp. 1-5). IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Representing graph data in a low-dimensional space for subsequent tasks is
the purpose of attributed graph embedding. Most existing neural network
approaches learn latent representations by minimizing reconstruction errors.
Rare work considers the data distribution and the topological structure of
latent codes simultaneously, which often results in inferior embeddings in
real-world graph data. This paper proposes a novel Deep Manifold (Variational)
Graph Auto-Encoder (DMVGAE/DMGAE) method for attributed graph data to improve
the stability and quality of learned representations to tackle the crowding
problem. The node-to-node geodesic similarity is preserved between the original
and latent space under a pre-defined distribution. The proposed method
surpasses state-of-the-art baseline algorithms by a significant margin on
different downstream tasks across popular datasets, which validates our
solutions. We promise to release the code after acceptance.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06730" title="Abstract">arXiv:2401.06730</a> [<a href="/pdf/2401.06730" title="Download PDF">pdf</a>, <a href="/format/2401.06730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relying on the Unreliable: The Impact of Language Models&#x27; Reluctance to  Express Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaitlyn Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J+D">Jena D. Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sap%2C+M">Maarten Sap</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">As natural language becomes the default interface for human-AI interaction,
there is a critical need for LMs to appropriately communicate uncertainties in
downstream applications. In this work, we investigate how LMs incorporate
confidence about their responses via natural language and how downstream users
behave in response to LM-articulated uncertainties. We examine publicly
deployed models and find that LMs are unable to express uncertainties when
answering questions even when they produce incorrect responses. LMs can be
explicitly prompted to express confidences, but tend to be overconfident,
resulting in high error rates (on average 47%) among confident responses. We
test the risks of LM overconfidence by running human experiments and show that
users rely heavily on LM generations, whether or not they are marked by
certainty. Lastly, we investigate the preference-annotated datasets used in
RLHF alignment and find that humans have a bias against texts with uncertainty.
Our work highlights a new set of safety harms facing human-LM interactions and
proposes design recommendations and mitigating strategies moving forward.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06742" title="Abstract">arXiv:2401.06742</a> [<a href="/pdf/2401.06742" title="Download PDF">pdf</a>, <a href="/format/2401.06742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Natural Language Inference to Improve Persona Extraction from  Dialogue in a New Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DeLucia%2C+A">Alexandra DeLucia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mengjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Maeda%2C+Y">Yoshinori Maeda</a>, 
<a href="/search/cs?searchtype=author&query=Yoda%2C+M">Makoto Yoda</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+K">Keiichi Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Wakaki%2C+H">Hiromi Wakaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and models will be released upon publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While valuable datasets such as PersonaChat provide a foundation for training
persona-grounded dialogue agents, they lack diversity in conversational and
narrative settings, primarily existing in the "real" world. To develop dialogue
agents with unique personas, models are trained to converse given a specific
persona, but hand-crafting these persona can be time-consuming, thus methods
exist to automatically extract persona information from existing
character-specific dialogue. However, these persona-extraction models are also
trained on datasets derived from PersonaChat and struggle to provide
high-quality persona information from conversational settings that do not take
place in the real world, such as the fantasy-focused dataset, LIGHT. Creating
new data to train models on a specific setting is human-intensive, thus
prohibitively expensive. To address both these issues, we introduce a natural
language inference method for post-hoc adapting a trained persona extraction
model to a new setting. We draw inspiration from the literature of dialog
natural language inference (NLI), and devise NLI-reranking methods to extract
structured persona information from dialogue. Compared to existing persona
extraction models, our method returns higher-quality extracted persona and
requires less human annotation.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06748" title="Abstract">arXiv:2401.06748</a> [<a href="/pdf/2401.06748" title="Download PDF">pdf</a>, <a href="/format/2401.06748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measure Theoretic Reeb Graphs and Reeb Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingsong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+G">Guanquan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Sridharamurthy%2C+R">Raghavendra Sridharamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">A Reeb graph is a graphical representation of a scalar function $f: X \to
\mathbb{R}$ on a topological space $X$ that encodes the topology of the level
sets. A Reeb space is a generalization of the Reeb graph to a multivariate
function $f: X \to \mathbb{R}^d$. In this paper, we propose novel constructions
of Reeb graphs and Reeb spaces that incorporate the use of a measure.
Specifically, we introduce measure theoretic Reeb graphs and Reeb spaces when
the domain or the range is modeled as a metric measure space (i.e.,~a metric
space equipped with a measure). Our main goal is to enhance the robustness of
the Reeb graph and Reeb space in representing the topological features of a
scalar field while accounting for the distribution of the measure. We first
prove the stability of our measure theoretic constructions with respect to the
interleaving distance. We then prove their stability with respect to the
measure, defined using the distance to a measure or the kernel distance to a
measure, respectively.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06749" title="Abstract">arXiv:2401.06749</a> [<a href="/pdf/2401.06749" title="Download PDF">pdf</a>, <a href="/format/2401.06749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing nonlinear solvers for the Navier-Stokes equations with  continuous (noisy) data assimilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Garcia-Archilla%2C+B">Bosco Garcia-Archilla</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xuejian Li</a>, 
<a href="/search/math?searchtype=author&query=Novo%2C+J">Julia Novo</a>, 
<a href="/search/math?searchtype=author&query=Rebholz%2C+L">Leo Rebholz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider nonlinear solvers for the incompressible, steady (or at a fixed
time step for unsteady) Navier-Stokes equations in the setting where partial
measurement data of the solution is available. The measurement data is
incorporated/assimilated into the solution through a nudging term addition to
the the Picard iteration that penalized the difference between the coarse mesh
interpolants of the true solution and solver solution, analogous to how
continuous data assimilation (CDA) is implemented for time dependent PDEs. This
was considered in the paper [Li et al. {\it CMAME} 2023], and we extend the
methodology by improving the analysis to be in the $L^2$ norm instead of a
weighted $H^1$ norm where the weight depended on the coarse mesh width, and to
the case of noisy measurement data. For noisy measurement data, we prove that
the CDA-Picard method is stable and convergent, up to the size of the noise.
Numerical tests illustrate the results, and show that a very good strategy when
using noisy data is to use CDA-Picard to generate an initial guess for the
classical Newton iteration.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06751" title="Abstract">arXiv:2401.06751</a> [<a href="/pdf/2401.06751" title="Download PDF">pdf</a>, <a href="/format/2401.06751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Unreasonable Effectiveness of Easy Training Data for Hard Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hase%2C+P">Peter Hase</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+P">Peter Clark</a>, 
<a href="/search/cs?searchtype=author&query=Wiegreffe%2C+S">Sarah Wiegreffe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">How can we train models to perform well on hard test data when hard training
data is by definition difficult to label correctly? This question has been
termed the scalable oversight problem and has drawn increasing attention as
language models have continually improved. In this paper, we present the
surprising conclusion that current language models often generalize relatively
well from easy to hard data, even performing as well as "oracle" models trained
on hard data. We demonstrate this kind of easy-to-hard generalization using
simple training methods like in-context learning, linear classifier heads, and
QLoRA for seven different measures of datapoint hardness, including six
empirically diverse human hardness measures (like grade level) and one
model-based measure (loss-based). Furthermore, we show that even if one cares
most about model performance on hard data, it can be better to collect and
train on easy data rather than hard data, since hard data is generally noisier
and costlier to collect. Our experiments use open models up to 70b in size and
four publicly available question-answering datasets with questions ranging in
difficulty from 3rd grade science questions to college level STEM questions and
general-knowledge trivia. We conclude that easy-to-hard generalization in LMs
is surprisingly strong for the tasks studied, suggesting the scalable oversight
problem may be easier than previously thought. Our code is available at
https://github.com/allenai/easy-to-hard-generalization
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06752" title="Abstract">arXiv:2401.06752</a> [<a href="/pdf/2401.06752" title="Download PDF">pdf</a>, <a href="/format/2401.06752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stylometry Analysis of Multi-authored Documents for Authorship and  Author Style Change Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zamir%2C+M+T">Muhammad Tayyab Zamir</a>, 
<a href="/search/cs?searchtype=author&query=Ayub%2C+M+A">Muhammad Asif Ayub</a>, 
<a href="/search/cs?searchtype=author&query=Gul%2C+A">Asma Gul</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+N">Nasir Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+K">Kashif Ahmad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tables 7, pages 4;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, the increasing use of Artificial Intelligence based text
generation tools has posed new challenges in document provenance,
authentication, and authorship detection. However, advancements in stylometry
have provided opportunities for automatic authorship and author change
detection in multi-authored documents using style analysis techniques. Style
analysis can serve as a primary step toward document provenance and
authentication through authorship detection. This paper investigates three key
tasks of style analysis: (i) classification of single and multi-authored
documents, (ii) single change detection, which involves identifying the point
where the author switches, and (iii) multiple author-switching detection in
multi-authored documents. We formulate all three tasks as classification
problems and propose a merit-based fusion framework that integrates several
state-of-the-art natural language processing (NLP) algorithms and weight
optimization techniques. We also explore the potential of special characters,
which are typically removed during pre-processing in NLP applications, on the
performance of the proposed methods for these tasks by conducting extensive
experiments on both cleaned and raw datasets. Experimental results demonstrate
significant improvements over existing solutions for all three tasks on a
benchmark dataset.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06757" title="Abstract">arXiv:2401.06757</a> [<a href="/pdf/2401.06757" title="Download PDF">pdf</a>, <a href="/format/2401.06757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Data Generation Framework, Dataset, and Efficient Deep Model  for Pedestrian Intention Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riaz%2C+M+N">Muhammad Naveed Riaz</a>, 
<a href="/search/cs?searchtype=author&query=Wielgosz%2C+M">Maciej Wielgosz</a>, 
<a href="/search/cs?searchtype=author&query=Romera%2C+A+G">Abel Garcia Romera</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+A+M">Antonio M. Lopez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 26th IEEE International Conference on Intelligent Transportation
  Systems ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pedestrian intention prediction is crucial for autonomous driving. In
particular, knowing if pedestrians are going to cross in front of the
ego-vehicle is core to performing safe and comfortable maneuvers. Creating
accurate and fast models that predict such intentions from sequential images is
challenging. A factor contributing to this is the lack of datasets with diverse
crossing and non-crossing (C/NC) scenarios. We address this scarceness by
introducing a framework, named ARCANE, which allows programmatically generating
synthetic datasets consisting of C/NC video clip samples. As an example, we use
ARCANE to generate a large and diverse dataset named PedSynth. We will show how
PedSynth complements widely used real-world datasets such as JAAD and PIE, so
enabling more accurate models for C/NC prediction. Considering the onboard
deployment of C/NC prediction models, we also propose a deep model named
PedGNN, which is fast and has a very low memory footprint. PedGNN is based on a
GNN-GRU architecture that takes a sequence of pedestrian skeletons as input to
predict crossing intentions.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06760" title="Abstract">arXiv:2401.06760</a> [<a href="/pdf/2401.06760" title="Download PDF">pdf</a>, <a href="/format/2401.06760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Metrics Maze: Reconciling Score Magnitudes and Accuracies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kocmi%2C+T">Tom Kocmi</a>, 
<a href="/search/cs?searchtype=author&query=Zouhar%2C+V">Vil&#xe9;m Zouhar</a>, 
<a href="/search/cs?searchtype=author&query=Federmann%2C+C">Christian Federmann</a>, 
<a href="/search/cs?searchtype=author&query=Post%2C+M">Matt Post</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Ten years ago a single metric, BLEU, governed progress in machine translation
research. For better or worse, there is no such consensus today, and
consequently it is difficult for researchers to develop and retain the kinds of
heuristic intuitions about metric deltas that drove earlier research and
deployment decisions. This paper investigates the "dynamic range" of a number
of modern metrics in an effort to provide a collective understanding of the
meaning of differences in scores both within and among metrics; in other words,
we ask what point difference X in metric Y is required between two systems for
humans to notice? We conduct our evaluation on a new large dataset, ToShip23,
using it to discover deltas at which metrics achieve system-level differences
that are meaningful to humans, which we measure by pairwise system accuracy. We
additionally show that this method of establishing delta-accuracy is more
stable than the standard use of statistical p-values in regards to testset
size. Where data size permits, we also explore the effect of metric deltas and
accuracy across finer-grained features such as translation direction, domain,
and system closeness.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06761" title="Abstract">arXiv:2401.06761</a> [<a href="/pdf/2401.06761" title="Download PDF">pdf</a>, <a href="/format/2401.06761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APAR: LLMs Can Do Auto-Parallel Auto-Regressive Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingdao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Aohan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The massive adoption of large language models (LLMs) demands efficient
deployment strategies. However, the auto-regressive decoding process, which is
fundamental to how most LLMs generate text, poses challenges to achieve
efficient serving. In this work, we introduce a parallel auto-regressive
generation method. By instruct-tuning on general domain data that contains
hierarchical structures, we enable LLMs to independently plan their generation
process and perform auto-parallel auto-regressive (APAR) generation,
significantly reducing the number of generation steps. APAR alone can achieve
up to 2x speed-up, and when combined with speculative decoding, the speed-up
can reach up to 4x. In addition, APAR reduces the key-value cache consumption
and attention computation during generation. This leads to a throughput
increase of 20-70% and a latency reduce of 20-35% in high-throughput scenarios,
compared to state-of-the-art serving frameworks.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06762" title="Abstract">arXiv:2401.06762</a> [<a href="/pdf/2401.06762" title="Download PDF">pdf</a>, <a href="/format/2401.06762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing the roads through the trees: A benchmark for modeling spatial  dependencies with aerial imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robinson%2C+C">Caleb Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Corley%2C+I">Isaac Corley</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+A">Anthony Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Dodhia%2C+R">Rahul Dodhia</a>, 
<a href="/search/cs?searchtype=author&query=Ferres%2C+J+M+L">Juan M. Lavista Ferres</a>, 
<a href="/search/cs?searchtype=author&query=Najafirad%2C+P">Peyman Najafirad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission to IGARSS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Fully understanding a complex high-resolution satellite or aerial imagery
scene often requires spatial reasoning over a broad relevant context. The human
object recognition system is able to understand object in a scene over a
long-range relevant context. For example, if a human observes an aerial scene
that shows sections of road broken up by tree canopy, then they will be
unlikely to conclude that the road has actually been broken up into disjoint
pieces by trees and instead think that the canopy of nearby trees is occluding
the road. However, there is limited research being conducted to understand
long-range context understanding of modern machine learning models. In this
work we propose a road segmentation benchmark dataset, Chesapeake Roads Spatial
Context (RSC), for evaluating the spatial long-range context understanding of
geospatial machine learning models and show how commonly used semantic
segmentation models can fail at this task. For example, we show that a U-Net
trained to segment roads from background in aerial imagery achieves an 84%
recall on unoccluded roads, but just 63.5% recall on roads covered by tree
canopy despite being trained to model both the same way. We further analyze how
the performance of models changes as the relevant context for a decision
(unoccluded roads in our case) varies in distance. We release the code to
reproduce our experiments and dataset of imagery and masks to encourage future
research in this direction -- https://github.com/isaaccorley/ChesapeakeRSC.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06763" title="Abstract">arXiv:2401.06763</a> [<a href="/pdf/2401.06763" title="Download PDF">pdf</a>, <a href="/format/2401.06763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimally Blending Honeypots into Production Networks: Hardness and  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaman%2C+M+M+U">Md Mahabub Uz Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Liangde Tao</a>, 
<a href="/search/cs?searchtype=author&query=Maldonado%2C+M">Mark Maldonado</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sunny%2C+A">Ahmed Sunny</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shouhuai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published in 5th International Conference on Science of Cyber Security - SciSec 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Honeypot is an important cyber defense technique that can expose attackers
new attacks. However, the effectiveness of honeypots has not been
systematically investigated, beyond the rule of thumb that their effectiveness
depends on how they are deployed. In this paper, we initiate a systematic study
on characterizing the cybersecurity effectiveness of a new paradigm of
deploying honeypots: blending honeypot computers (or IP addresses) into
production computers. This leads to the following Honeypot Deployment (HD)
problem, How should the defender blend honeypot computers into production
computers to maximize the utility in forcing attackers to expose their new
attacks while minimizing the loss to the defender in terms of the digital
assets stored in the compromised production computers? We formalize HD as a
combinatorial optimization problem, prove its NP hardness, provide a near
optimal algorithm (i.e., polynomial time approximation scheme). We also conduct
simulations to show the impact of attacker capabilities.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06765" title="Abstract">arXiv:2401.06765</a> [<a href="/pdf/2401.06765" title="Download PDF">pdf</a>, <a href="/format/2401.06765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Test Case Repair Using Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yaraghi%2C+A+S">Ahmadreza Saboor Yaraghi</a>, 
<a href="/search/cs?searchtype=author&query=Holden%2C+D">Darren Holden</a>, 
<a href="/search/cs?searchtype=author&query=Kahani%2C+N">Nafiseh Kahani</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L">Lionel Briand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Ensuring the quality of software systems through testing is essential, yet
maintaining test cases poses significant challenges and costs. The need for
frequent updates to align with the evolving system under test often entails
high complexity and cost for maintaining these test cases. Further, unrepaired
broken test cases can degrade test suite quality and disrupt the software
development process, wasting developers' time. To address this challenge, we
present TaRGet (Test Repair GEneraTor), a novel approach leveraging pre-trained
code language models for automated test case repair. TaRGet treats test repair
as a language translation task, employing a two-step process to fine-tune a
language model based on essential context data characterizing the test
breakage. To evaluate our approach, we introduce TaRBench, a comprehensive
benchmark we developed covering 45,373 broken test repairs across 59
open-source projects. Our results demonstrate TaRGet's effectiveness, achieving
a 66.1% exact match accuracy. Furthermore, our study examines the effectiveness
of TaRGet across different test repair scenarios. We provide a practical guide
to predict situations where the generated test repairs might be less reliable.
We also explore whether project-specific data is always necessary for
fine-tuning and if our approach can be effective on new projects.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06766" title="Abstract">arXiv:2401.06766</a> [<a href="/pdf/2401.06766" title="Download PDF">pdf</a>, <a href="/format/2401.06766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mind Your Format: Towards Consistent Evaluation of In-Context Learning  Improvements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voronov%2C+A">Anton Voronov</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lena Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Ryabinin%2C+M">Max Ryabinin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models demonstrate a remarkable capability for learning to
solve new tasks from a few examples. The prompt template, or the way the input
examples are formatted to obtain the prompt, is an important yet often
overlooked aspect of in-context learning. In this work, we conduct a
comprehensive study of the template format's influence on the in-context
learning performance. We evaluate the impact of the prompt template across
models (from 770M to 70B parameters) and 4 standard classification datasets. We
show that a poor choice of the template can reduce the performance of the
strongest models and inference methods to a random guess level. More
importantly, the best templates do not transfer between different setups and
even between models of the same family. Our findings show that the currently
prevalent approach to evaluation, which ignores template selection, may give
misleading results due to different templates in different works. As a first
step towards mitigating this issue, we propose Template Ensembles that
aggregate model predictions across several templates. This simple test-time
augmentation boosts average performance while being robust to the choice of
random set of templates.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06769" title="Abstract">arXiv:2401.06769</a> [<a href="/pdf/2401.06769" title="Download PDF">pdf</a>, <a href="/format/2401.06769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Translation Models are Zero-Shot Detectors of Translation  Direction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wastl%2C+M">Michelle Wastl</a>, 
<a href="/search/cs?searchtype=author&query=Vamvas%2C+J">Jannis Vamvas</a>, 
<a href="/search/cs?searchtype=author&query=Sennrich%2C+R">Rico Sennrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Detecting the translation direction of parallel text has applications for
machine translation training and evaluation, but also has forensic applications
such as resolving plagiarism or forgery allegations. In this work, we explore
an unsupervised approach to translation direction detection based on the simple
hypothesis that
$p(\text{translation}|\text{original})&gt;p(\text{original}|\text{translation})$,
motivated by the well-known simplification effect in translationese or
machine-translationese. In experiments with massively multilingual machine
translation models across 20 translation directions, we confirm the
effectiveness of the approach for high-resource language pairs, achieving
document-level accuracies of 82-96% for NMT-produced translations, and 60-81%
for human translations, depending on the model used. Code and demo are
available at https://github.com/ZurichNLP/translation-direction-detection
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon, 15 Jan 24</h3>
<dl>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06132" title="Abstract">arXiv:2401.06132</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2401.06132" title="Download PDF">pdf</a>, <a href="/ps/2401.06132" title="Download PostScript">ps</a>, <a href="/format/2401.06132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cache Blocking for Flux Reconstruction: Extension to Navier-Stokes  Equations and Anti-aliasing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Akkurt%2C+S">Semih Akkurt</a>, 
<a href="/search/physics?searchtype=author&query=Witherden%2C+F">Freddie Witherden</a>, 
<a href="/search/physics?searchtype=author&query=Vincent%2C+P">Peter Vincent</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Performance (cs.PF); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this article, cache blocking is implemented for the Navier Stokes
equations with anti-aliasing support on mixed grids in PyFR for CPUs. In
particular, cache blocking is used as an alternative to kernel fusion to
eliminate unnecessary data movements between kernels at the main memory level.
Specifically, kernels that exchange data are grouped together, and these groups
are then executed on small sub-regions of the domain that fit in per-core
private data cache. Additionally, cache blocking is also used to efficiently
implement a tensor product factorisation of the interpolation operators
associated with anti-aliasing. By using cache blocking, the intermediate
results between application of the sparse factors are stored in per-core
private data cache, and a significant amount of data movement from main memory
is avoided. In order to assess the performance gains a theoretical model is
developed, and the implementation is benchmarked using a compressible 3D
Taylor-Green vortex test case on both hexahedral and prismatic grids, with
third- and forth-order solution polynomials. The expected performance gains
based on the theoretical model range from 1.99 to 2.62, and the speedups
obtained in practice range from 1.67 to 3.67 compared to PyFR v1.11.0.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06139" title="Abstract">arXiv:2401.06139</a> (cross-list from q-fin.TR) [<a href="/pdf/2401.06139" title="Download PDF">pdf</a>, <a href="/format/2401.06139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StockFormer: A Swing Trading Strategy Based on STL Decomposition and  Self-Attention Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Ma%2C+B">Bohan Ma</a>, 
<a href="/search/q-fin?searchtype=author&query=Wang%2C+Y">Yiheng Wang</a>, 
<a href="/search/q-fin?searchtype=author&query=Lu%2C+Y">Yuchao Lu</a>, 
<a href="/search/q-fin?searchtype=author&query=Hu%2C+T">Tianzixuan Hu</a>, 
<a href="/search/q-fin?searchtype=author&query=Xu%2C+J">Jinling Xu</a>, 
<a href="/search/q-fin?searchtype=author&query=Houlihan%2C+P">Patrick Houlihan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently under consideration for publication in the International Journal of Forecasting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Amidst ongoing market recalibration and increasing investor optimism, the
U.S. stock market is experiencing a resurgence, prompting the need for
sophisticated tools to protect and grow portfolios. Addressing this, we
introduce "Stockformer," a cutting-edge deep learning framework optimized for
swing trading, featuring the TopKDropout method for enhanced stock selection.
By integrating STL decomposition and self-attention networks, Stockformer
utilizes the S&amp;P 500's complex data to refine stock return predictions. Our
methodology entailed segmenting data for training and validation (January 2021
to January 2023) and testing (February to June 2023). During testing,
Stockformer's predictions outperformed ten industry models, achieving superior
precision in key predictive accuracy indicators (MAE, RMSE, MAPE), with a
remarkable accuracy rate of 62.39% in detecting market trends. In our
backtests, Stockformer's swing trading strategy yielded a cumulative return of
13.19% and an annualized return of 30.80%, significantly surpassing current
state-of-the-art models. Stockformer has emerged as a beacon of innovation in
these volatile times, offering investors a potent tool for market forecasting.
To advance the field and foster community collaboration, we have open-sourced
Stockformer, available at https://github.com/Eric991005/Stockformer.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06148" title="Abstract">arXiv:2401.06148</a> (cross-list from eess.IV) [<a href="/pdf/2401.06148" title="Download PDF">pdf</a>, <a href="/format/2401.06148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence for Digital and Computational Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+A+H">Andrew H. Song</a>, 
<a href="/search/eess?searchtype=author&query=Jaume%2C+G">Guillaume Jaume</a>, 
<a href="/search/eess?searchtype=author&query=Williamson%2C+D+F+K">Drew F.K. Williamson</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+M+Y">Ming Y. Lu</a>, 
<a href="/search/eess?searchtype=author&query=Vaidya%2C+A">Anurag Vaidya</a>, 
<a href="/search/eess?searchtype=author&query=Miller%2C+T+R">Tiffany R. Miller</a>, 
<a href="/search/eess?searchtype=author&query=Mahmood%2C+F">Faisal Mahmood</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Advances in digitizing tissue slides and the fast-paced progress in
artificial intelligence, including deep learning, have boosted the field of
computational pathology. This field holds tremendous potential to automate
clinical diagnosis, predict patient prognosis and response to therapy, and
discover new morphological biomarkers from tissue images. Some of these
artificial intelligence-based systems are now getting approved to assist
clinical diagnosis; however, technical barriers remain for their widespread
clinical adoption and integration as a research tool. This Review consolidates
recent methodological advances in computational pathology for predicting
clinical end points in whole-slide images and highlights how these developments
enable the automation of clinical practice and the discovery of new biomarkers.
We then provide future perspectives as the field expands into a broader range
of clinical and research tasks with increasingly diverse modalities of clinical
data.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06150" title="Abstract">arXiv:2401.06150</a> (cross-list from eess.IV) [<a href="/pdf/2401.06150" title="Download PDF">pdf</a>, <a href="/format/2401.06150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D-STGCNT: A Dense Spatio-Temporal Graph Conv-GRU Network based on  transformer for assessment of patient physical rehabilitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mourchid%2C+Y">Youssef Mourchid</a>, 
<a href="/search/eess?searchtype=author&query=Slama%2C+R">Rim Slama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, Computers in Biology and Medicine Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper tackles the challenge of automatically assessing physical
rehabilitation exercises for patients who perform the exercises without
clinician supervision. The objective is to provide a quality score to ensure
correct performance and achieve desired results. To achieve this goal, a new
graph-based model, the Dense Spatio-Temporal Graph Conv-GRU Network with
Transformer, is introduced. This model combines a modified version of STGCN and
transformer architectures for efficient handling of spatio-temporal data. The
key idea is to consider skeleton data respecting its non-linear structure as a
graph and detecting joints playing the main role in each rehabilitation
exercise. Dense connections and GRU mechanisms are used to rapidly process
large 3D skeleton inputs and effectively model temporal dynamics. The
transformer encoder's attention mechanism focuses on relevant parts of the
input sequence, making it useful for evaluating rehabilitation exercises. The
evaluation of our proposed approach on the KIMORE and UI-PRMD datasets
highlighted its potential, surpassing state-of-the-art methods in terms of
accuracy and computational time. This resulted in faster and more accurate
learning and assessment of rehabilitation exercises. Additionally, our model
provides valuable feedback through qualitative illustrations, effectively
highlighting the significance of joints in specific exercises.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06151" title="Abstract">arXiv:2401.06151</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.06151" title="Download PDF">pdf</a>, <a href="/format/2401.06151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Joint Sequence-Structure Generation of Nucleic Acid and Protein  Complexes with SE(3)-Discrete Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Morehead%2C+A">Alex Morehead</a>, 
<a href="/search/q-bio?searchtype=author&query=Ruffolo%2C+J">Jeffrey Ruffolo</a>, 
<a href="/search/q-bio?searchtype=author&query=Bhatnagar%2C+A">Aadyot Bhatnagar</a>, 
<a href="/search/q-bio?searchtype=author&query=Madani%2C+A">Ali Madani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures, presented at the NeurIPS 2023 Machine Learning in Structural Biology (MLSB) workshop. Code available at <a href="https://github.com/Profluent-Internships/MMDiff">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Generative models of macromolecules carry abundant and impactful implications
for industrial and biomedical efforts in protein engineering. However, existing
methods are currently limited to modeling protein structures or sequences,
independently or jointly, without regard to the interactions that commonly
occur between proteins and other macromolecules. In this work, we introduce
MMDiff, a generative model that jointly designs sequences and structures of
nucleic acid and protein complexes, independently or in complex, using joint
SE(3)-discrete diffusion noise. Such a model has important implications for
emerging areas of macromolecular design including structure-based transcription
factor design and design of noncoding RNA sequences. We demonstrate the utility
of MMDiff through a rigorous new design benchmark for macromolecular complex
generation that we introduce in this work. Our results demonstrate that MMDiff
is able to successfully generate micro-RNA and single-stranded DNA molecules
while being modestly capable of joint modeling DNA and RNA molecules in
interaction with multi-chain protein complexes. Source code:
https://github.com/Profluent-Internships/MMDiff.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06155" title="Abstract">arXiv:2401.06155</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.06155" title="Download PDF">pdf</a>, <a href="/format/2401.06155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De novo Drug Design using Reinforcement Learning with Multiple GPT  Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+X">Xiuyuan Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+G">Guoqing Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">De novo drug design is a pivotal issue in pharmacology and a new area of
focus in AI for science research. A central challenge in this field is to
generate molecules with specific properties while also producing a wide range
of diverse candidates. Although advanced technologies such as transformer
models and reinforcement learning have been applied in drug design, their
potential has not been fully realized. Therefore, we propose MolRL-MGPT, a
reinforcement learning algorithm with multiple GPT agents for drug molecular
generation. To promote molecular diversity, we encourage the agents to
collaborate in searching for desirable molecules in diverse directions. Our
algorithm has shown promising results on the GuacaMol benchmark and exhibits
efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes
are available at: https://github.com/HXYfighter/MolRL-MGPT.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06164" title="Abstract">arXiv:2401.06164</a> (cross-list from q-fin.GN) [<a href="/pdf/2401.06164" title="Download PDF">pdf</a>, <a href="/format/2401.06164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Gen-AI for Fundamental Investment Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Li%2C+L">Lezhi Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Chang%2C+T">Ting-Yu Chang</a>, 
<a href="/search/q-fin?searchtype=author&query=Wang%2C+H">Hai Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This report outlines a transformative initiative in the financial investment
industry, where the conventional decision-making process, laden with
labor-intensive tasks such as sifting through voluminous documents, is being
reimagined. Leveraging language models, our experiments aim to automate
information summarization and investment idea generation. We seek to evaluate
the effectiveness of fine-tuning methods on a base model (Llama2) to achieve
specific application-level goals, including providing insights into the impact
of events on companies and sectors, understanding market condition
relationships, generating investor-aligned investment ideas, and formatting
results with stock recommendations and detailed explanations. Through
state-of-the-art generative modeling techniques, the ultimate objective is to
develop an AI agent prototype, liberating human investors from repetitive tasks
and allowing a focus on high-level strategic thinking. The project encompasses
a diverse corpus dataset, including research reports, investment memos, market
news, and extensive time-series market data. We conducted three experiments
applying unsupervised and supervised LoRA fine-tuning on the llama2_7b_hf_chat
as the base model, as well as instruction fine-tuning on the GPT3.5 model.
Statistical and human evaluations both show that the fine-tuned versions
perform better in solving text modeling, summarization, reasoning, and finance
domain questions, demonstrating a pivotal step towards enhancing
decision-making processes in the financial domain. Code implementation for the
project can be found on GitHub: https://github.com/Firenze11/finance_lm.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06166" title="Abstract">arXiv:2401.06166</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.06166" title="Download PDF">pdf</a>, <a href="/ps/2401.06166" title="Download PostScript">ps</a>, <a href="/format/2401.06166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adjustable Molecular Representation for Unified Pre-training Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+Y">Yan Ding</a>, 
<a href="/search/q-bio?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/q-bio?searchtype=author&query=Ye%2C+Z">Zeliang Ye</a>, 
<a href="/search/q-bio?searchtype=author&query=Feng%2C+R">Ruyi Feng</a>, 
<a href="/search/q-bio?searchtype=author&query=Gu%2C+Z">Zhongze Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a new large-scale molecular model, named AdaMR, which stands for
Adjustable Molecular Representation for Unified Pre-training Strategy. Unlike
recent large-scale molecular models that use a single molecular encoding, AdaMR
employs a granularity-adjustable molecular encoder, learning molecular
representations at both the atomic and substructure levels. For the
pre-training process, we designed a task for molecular canonicalization, which
involves transforming ltiple generic molecular representations into canonical
representations. By adjusting the granularity of molecular encoding, the
trained model can improve the effects on multiple downstream tasks, such as
model attribute prediction and molecule generation. Substructure-level
molecular representation retains information of specific atom groups or
arrangements that determine chemical properties and have similar functions,
which is beneficial for tasks like property prediction. Meanwhile, atomic-level
representation, combined with generative molecular canonicalization
pre-training tasks, enhances the validity, novelty, and uniqueness in
generative tasks. These features of AdaMR demonstrate its strong performance in
numerous downstream tasks. We use different molecular properties prediction
tasks on six different datasets on MoleculeNet and two generative tasks on
ZINC250K dataset to evaluate our proposed molecular encoding and pre-training
methods, and obtain state-of-the-art (SOTA) results on five of these tasks.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06169" title="Abstract">arXiv:2401.06169</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.06169" title="Download PDF">pdf</a>, <a href="/ps/2401.06169" title="Download PostScript">ps</a>, <a href="/format/2401.06169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning model predicts the c-Kit-11 mutational status of canine  cutaneous mast cell tumors by HE stained histological slides
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Puget%2C+C">Chlo&#xe9; Puget</a>, 
<a href="/search/q-bio?searchtype=author&query=Ganz%2C+J">Jonathan Ganz</a>, 
<a href="/search/q-bio?searchtype=author&query=Ostermaier%2C+J">Julian Ostermaier</a>, 
<a href="/search/q-bio?searchtype=author&query=Konrad%2C+T">Thomas Konrad</a>, 
<a href="/search/q-bio?searchtype=author&query=Parlak%2C+E">Eda Parlak</a>, 
<a href="/search/q-bio?searchtype=author&query=Bertram%2C+C+A">Christof Albert Bertram</a>, 
<a href="/search/q-bio?searchtype=author&query=Kiupel%2C+M">Matti Kiupel</a>, 
<a href="/search/q-bio?searchtype=author&query=Breininger%2C+K">Katharina Breininger</a>, 
<a href="/search/q-bio?searchtype=author&query=Aubreville%2C+M">Marc Aubreville</a>, 
<a href="/search/q-bio?searchtype=author&query=Klopfleisch%2C+R">Robert Klopfleisch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Numerous prognostic factors are currently assessed histopathologically in
biopsies of canine mast cell tumors to evaluate clinical behavior. In addition,
PCR analysis of the c-Kit exon 11 mutational status is often performed to
evaluate the potential success of a tyrosine kinase inhibitor therapy. This
project aimed at training deep learning models (DLMs) to identify the c-Kit-11
mutational status of MCTs solely based on morphology without additional
molecular analysis. HE slides of 195 mutated and 173 non-mutated tumors were
stained consecutively in two different laboratories and scanned with three
different slide scanners. This resulted in six different datasets
(stain-scanner variations) of whole slide images. DLMs were trained with single
and mixed datasets and their performances was assessed under scanner and
staining domain shifts. The DLMs correctly classified HE slides according to
their c-Kit 11 mutation status in, on average, 87% of cases for the best-suited
stain-scanner variant. A relevant performance drop could be observed when the
stain-scanner combination of the training and test dataset differed.
Multi-variant datasets improved the average accuracy but did not reach the
maximum accuracy of algorithms trained and tested on the same stain-scanner
variant. In summary, DLM-assisted morphological examination of MCTs can predict
c-Kit-exon 11 mutational status of MCTs with high accuracy. However, the
recognition performance is impeded by a change of scanner or staining protocol.
Larger data sets with higher numbers of scans originating from different
laboratories and scanners may lead to more robust DLMs to identify c-Kit
mutations in HE slides.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06172" title="Abstract">arXiv:2401.06172</a> (cross-list from q-fin.ST) [<a href="/pdf/2401.06172" title="Download PDF">pdf</a>, <a href="/ps/2401.06172" title="Download PostScript">ps</a>, <a href="/format/2401.06172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRISIS ALERT:Forecasting Stock Market Crisis Events Using Machine  Learning Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/q-fin?searchtype=author&query=Andrew%2C+X">Xingyi Andrew</a>, 
<a href="/search/q-fin?searchtype=author&query=Supasanya%2C+S">Salintip Supasanya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Historically, the economic recession often came abruptly and disastrously.
For instance, during the 2008 financial crisis, the SP 500 fell 46 percent from
October 2007 to March 2009. If we could detect the signals of the crisis
earlier, we could have taken preventive measures. Therefore, driven by such
motivation, we use advanced machine learning techniques, including Random
Forest and Extreme Gradient Boosting, to predict any potential market crashes
mainly in the US market. Also, we would like to compare the performance of
these methods and examine which model is better for forecasting US stock market
crashes. We apply our models on the daily financial market data, which tend to
be more responsive with higher reporting frequencies. We consider 75
explanatory variables, including general US stock market indexes, SP 500 sector
indexes, as well as market indicators that can be used for the purpose of
crisis prediction. Finally, we conclude, with selected classification metrics,
that the Extreme Gradient Boosting method performs the best in predicting US
stock market crisis events.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06173" title="Abstract">arXiv:2401.06173</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.06173" title="Download PDF">pdf</a>, <a href="/format/2401.06173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree Search-Based Evolutionary Bandits for Protein Sequence Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Qiu%2C+J">Jiahao Qiu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yuan%2C+H">Hui Yuan</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+J">Jinghong Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+W">Wentao Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+H">Huazheng Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+M">Mengdi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While modern biotechnologies allow synthesizing new proteins and function
measurements at scale, efficiently exploring a protein sequence space and
engineering it remains a daunting task due to the vast sequence space of any
given protein. Protein engineering is typically conducted through an iterative
process of adding mutations to the wild-type or lead sequences, recombination
of mutations, and running new rounds of screening. To enhance the efficiency of
such a process, we propose a tree search-based bandit learning method, which
expands a tree starting from the initial sequence with the guidance of a bandit
machine learning model. Under simplified assumptions and a Gaussian Process
prior, we provide theoretical analysis and a Bayesian regret bound,
demonstrating that the combination of local search and bandit learning method
can efficiently discover a near-optimal design. The full algorithm is
compatible with a suite of randomized tree search heuristics, machine learning
models, pre-trained embeddings, and bandit techniques. We test various
instances of the algorithm across benchmark protein datasets using simulated
screens. Experiment results demonstrate that the algorithm is both
sample-efficient and able to find top designs using reasonably small mutation
counts.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06174" title="Abstract">arXiv:2401.06174</a> (cross-list from eess.IV) [<a href="/pdf/2401.06174" title="Download PDF">pdf</a>, <a href="/ps/2401.06174" title="Download PostScript">ps</a>, <a href="/format/2401.06174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Applications in Spine Biomechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghezelbash%2C+F">Farshid Ghezelbash</a>, 
<a href="/search/eess?searchtype=author&query=Eskandari%2C+A+H">Amir Hossein Eskandari</a>, 
<a href="/search/eess?searchtype=author&query=Robert-Lachaine%2C+X">Xavier Robert-Lachaine</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+F">Frank Cao</a>, 
<a href="/search/eess?searchtype=author&query=Pesteie%2C+M">Mehran Pesteie</a>, 
<a href="/search/eess?searchtype=author&query=Qiao%2C+Z">Zhuohua Qiao</a>, 
<a href="/search/eess?searchtype=author&query=Shirazi-Adl%2C+A">Aboulfazl Shirazi-Adl</a>, 
<a href="/search/eess?searchtype=author&query=Larivi%C3%A8re%2C+C">Christian Larivi&#xe8;re</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Spine biomechanics is at a transformation with the advent and integration of
machine learning and computer vision technologies. These novel techniques
facilitate the estimation of 3D body shapes, anthropometrics, and kinematics
from as simple as a single-camera image, making them more accessible and
practical for a diverse range of applications. This study introduces a
framework that merges these methodologies with traditional musculoskeletal
modeling, enabling comprehensive analysis of spinal biomechanics during complex
activities from a single camera. Additionally, we aim to evaluate their
performance and limitations in spine biomechanics applications. The real-world
applications explored in this study include assessment in workplace lifting,
evaluation of whiplash injuries in car accidents, and biomechanical analysis in
professional sports. Our results demonstrate potential and limitations of
various algorithms in estimating body shape, kinematics, and conducting
in-field biomechanical analyses. In industrial settings, the potential to
utilize these new technologies for biomechanical risk assessments offers a
pathway for preventive measures against back injuries. In sports activities,
the proposed framework provides new opportunities for performance optimization,
injury prevention, and rehabilitation. The application in forensic domain
further underscores the wide-reaching implications of this technology. While
certain limitations were identified, particularly in accuracy of predictions,
complex interactions, and external load estimation, this study demonstrates
their potential for advancement in spine biomechanics, heralding an optimistic
future in both research and practical applications.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06179" title="Abstract">arXiv:2401.06179</a> (cross-list from q-fin.ST) [<a href="/pdf/2401.06179" title="Download PDF">pdf</a>, <a href="/format/2401.06179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CNN-DRL for Scalable Actions in Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Montazeri%2C+S">Sina Montazeri</a>, 
<a href="/search/q-fin?searchtype=author&query=Mirzaeinia%2C+A">Akram Mirzaeinia</a>, 
<a href="/search/q-fin?searchtype=author&query=Jumakhan%2C+H">Haseebullah Jumakhan</a>, 
<a href="/search/q-fin?searchtype=author&query=Mirzaeinia%2C+A">Amir Mirzaeinia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10th Annual Conf. on Computational Science &amp; Computational Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The published MLP-based DRL in finance has difficulties in learning the
dynamics of the environment when the action scale increases. If the buying and
selling increase to one thousand shares, the MLP agent will not be able to
effectively adapt to the environment. To address this, we designed a CNN agent
that concatenates the data from the last ninety days of the daily feature
vector to create the CNN input matrix. Our extensive experiments demonstrate
that the MLP-based agent experiences a loss corresponding to the initial
environment setup, while our designed CNN remains stable, effectively learns
the environment, and leads to an increase in rewards.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06180" title="Abstract">arXiv:2401.06180</a> (cross-list from eess.IV) [<a href="/pdf/2401.06180" title="Download PDF">pdf</a>, <a href="/ps/2401.06180" title="Download PostScript">ps</a>, <a href="/format/2401.06180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Gossip Mutual Learning (GML) for automatic head and neck  tumor segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jingyun Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+Y">Yading Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, accepted to SPIE Medical Imaging 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning (FL) has emerged as a promising strategy for
collaboratively training complicated machine learning models from different
medical centers without the need of data sharing. However, the traditional FL
relies on a central server to orchestrate the global model training among
clients. This makes it vulnerable to the failure of the model server.
Meanwhile, the model trained based on the global data property may not yield
the best performance on the local data of a particular site due to the
variations of data characteristics among them. To address these limitations, we
proposed Gossip Mutual Learning(GML), a decentralized collaborative learning
framework that employs Gossip Protocol for direct peer-to-peer communication
and encourages each site to optimize its local model by leveraging useful
information from peers through mutual learning. On the task of tumor
segmentation on PET/CT images using HECKTOR21 dataset with 223 cases from five
clinical sites, we demonstrated GML could improve tumor segmentation
performance in terms of Dice Similarity Coefficient (DSC) by 3.2%, 4.6% and
10.4% on site-specific testing cases as compared to three baseline methods:
pooled training, FedAvg and individual training, respectively. We also showed
GML has comparable generalization performance as pooled training and FedAvg
when applying them on 78 cases from two out-of-sample sites where no case was
used for model training. In our experimental setup, GML showcased a sixfold
decrease in communication overhead compared to FedAvg, requiring only 16.67% of
the total communication overhead.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06182" title="Abstract">arXiv:2401.06182</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.06182" title="Download PDF">pdf</a>, <a href="/format/2401.06182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of Cellular Identities from Trajectory and Cell Fate  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Dai%2C+B">Baiyang Dai</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+J">Jiamin Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Shroff%2C+H">Hari Shroff</a>, 
<a href="/search/q-bio?searchtype=author&query=La+Riviere%2C+P">Patrick La Riviere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Determining cell identities in imaging sequences is an important yet
challenging task. The conventional method for cell identification is via cell
tracking, which is complex and can be time-consuming. In this study, we propose
an innovative approach to cell identification during early C. elegans
embryogenesis using machine learning. We employed random forest, MLP, and LSTM
models, and tested cell classification accuracy on 3D time-lapse confocal
datasets spanning the first 4 hours of embryogenesis. By leveraging a small
number of spatial-temporal features of individual cells, including cell
trajectory and cell fate information, our models achieve an accuracy of over
90%, even with limited data. We also determine the most important feature
contributions and can interpret these features in the context of biological
knowledge. Our research demonstrates the success of predicting cell identities
in 4D imaging sequences directly from simple spatio-temporal features.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06183" title="Abstract">arXiv:2401.06183</a> (cross-list from eess.AS) [<a href="/pdf/2401.06183" title="Download PDF">pdf</a>, <a href="/format/2401.06183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End to end Hindi to English speech conversion using Bark, mBART and a  finetuned XLSR Wav2Vec2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tathe%2C+A">Aniket Tathe</a>, 
<a href="/search/eess?searchtype=author&query=Kamble%2C+A">Anand Kamble</a>, 
<a href="/search/eess?searchtype=author&query=Kumbharkar%2C+S">Suyash Kumbharkar</a>, 
<a href="/search/eess?searchtype=author&query=Bhandare%2C+A">Atharva Bhandare</a>, 
<a href="/search/eess?searchtype=author&query=Mitra%2C+A+C">Anirban C. Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Speech has long been a barrier to effective communication and connection,
persisting as a challenge in our increasingly interconnected world. This
research paper introduces a transformative solution to this persistent obstacle
an end-to-end speech conversion framework tailored for Hindi-to-English
translation, culminating in the synthesis of English audio. By integrating
cutting-edge technologies such as XLSR Wav2Vec2 for automatic speech
recognition (ASR), mBART for neural machine translation (NMT), and a
Text-to-Speech (TTS) synthesis component, this framework offers a unified and
seamless approach to cross-lingual communication. We delve into the intricate
details of each component, elucidating their individual contributions and
exploring the synergies that enable a fluid transition from spoken Hindi to
synthesized English audio.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06188" title="Abstract">arXiv:2401.06188</a> (cross-list from quant-ph) [<a href="/pdf/2401.06188" title="Download PDF">pdf</a>, <a href="/format/2401.06188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State of practice: evaluating GPU performance of state vector and tensor  network methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Vallero%2C+M">Marzio Vallero</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vella%2C+F">Flavio Vella</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rech%2C+P">Paolo Rech</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The frontier of quantum computing (QC) simulation on classical hardware is
quickly reaching the hard scalability limits for computational feasibility.
Nonetheless, there is still a need to simulate large quantum systems
classically, as the Noisy Intermediate Scale Quantum (NISQ) devices are yet to
be considered fault tolerant and performant enough in terms of operations per
second. Each of the two main exact simulation techniques, state vector and
tensor network simulators, boasts specific limitations. The exponential memory
requirement of state vector simulation, when compared to the qubit register
sizes of currently available quantum computers, quickly saturates the capacity
of the top HPC machines currently available. Tensor network contraction
approaches, which encode quantum circuits into tensor networks and then
contract them over an output bit string to obtain its probability amplitude,
still fall short of the inherent complexity of finding an optimal contraction
path, which maps to a max-cut problem on a dense mesh, a notably NP-hard
problem.
<br />This article aims at investigating the limits of current state-of-the-art
simulation techniques on a test bench made of eight widely used quantum
subroutines, each in 31 different configurations, with special emphasis on
performance. We then correlate the performance measures of the simulators with
the metrics that characterise the benchmark circuits, identifying the main
reasons behind the observed performance trend. From our observations, given the
structure of a quantum circuit and the number of qubits, we highlight how to
select the best simulation strategy, obtaining a speedup of up to an order of
magnitude.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06199" title="Abstract">arXiv:2401.06199</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.06199" title="Download PDF">pdf</a>, <a href="/format/2401.06199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering  the Language of Protein
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Cheng%2C+X">Xingyi Cheng</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+P">Pan Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Geng%2C+Y">Yangli-ao Geng</a>, 
<a href="/search/q-bio?searchtype=author&query=Gong%2C+J">Jing Gong</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S">Shen Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Bei%2C+Z">Zhilei Bei</a>, 
<a href="/search/q-bio?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+B">Boyan Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zeng%2C+X">Xin Zeng</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+C">Chiming Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Zeng%2C+A">Aohan Zeng</a>, 
<a href="/search/q-bio?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+J">Jie Tang</a>, 
<a href="/search/q-bio?searchtype=author&query=Song%2C+L">Le Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Protein language models have shown remarkable success in learning biological
information from protein sequences. However, most existing models are limited
by either autoencoding or autoregressive pre-training objectives, which makes
them struggle to handle protein understanding and generation tasks
concurrently. We propose a unified protein language model, xTrimoPGLM, to
address these two types of tasks simultaneously through an innovative
pre-training framework. Our key technical contribution is an exploration of the
compatibility and the potential for joint optimization of the two types of
objectives, which has led to a strategy for training xTrimoPGLM at an
unprecedented scale of 100 billion parameters and 1 trillion training tokens.
Our extensive experiments reveal that 1) xTrimoPGLM significantly outperforms
other advanced baselines in 18 protein understanding benchmarks across four
categories. The model also facilitates an atomic-resolution view of protein
structures, leading to an advanced 3D structural prediction model that
surpasses existing language model-based tools. 2) xTrimoPGLM not only can
generate de novo protein sequences following the principles of natural ones,
but also can perform programmable generation after supervised fine-tuning (SFT)
on curated sequences. These results highlight the substantial capability and
versatility of xTrimoPGLM in understanding and generating protein sequences,
contributing to the evolving landscape of foundation models in protein science.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06203" title="Abstract">arXiv:2401.06203</a> (cross-list from eess.AS) [<a href="/pdf/2401.06203" title="Download PDF">pdf</a>, <a href="/ps/2401.06203" title="Download PostScript">ps</a>, <a href="/format/2401.06203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remixing Music for Hearing Aids Using Ensemble of Fine-Tuned Source  Separators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Daly%2C+M">Matthew Daly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, ICASSP 2024, Cadenza Grand Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper introduces our system submission for the Cadenza ICASSP 2024 Grand
Challenge, which presents the problem of remixing and enhancing music for
hearing aid users. Our system placed first in the challenge, achieving the best
average Hearing-Aid Audio Quality Index (HAAQI) score on the evaluation data
set. We describe the system, which uses an ensemble of deep learning music
source separators that are fine tuned on the challenge data. We demonstrate the
effectiveness of our system through the challenge results and analyze the
importance of different system aspects through ablation studies.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06224" title="Abstract">arXiv:2401.06224</a> (cross-list from eess.IV) [<a href="/pdf/2401.06224" title="Download PDF">pdf</a>, <a href="/format/2401.06224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Frequency Domain Learning in 3D Vessel Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xinyuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+C">Chengwei Pan</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+H">Hongming Dai</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+G">Gangming Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jinpeng Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Y">Yizhou Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Coronary microvascular disease constitutes a substantial risk to human
health. Employing computer-aided analysis and diagnostic systems, medical
professionals can intervene early in disease progression, with 3D vessel
segmentation serving as a crucial component. Nevertheless, conventional U-Net
architectures tend to yield incoherent and imprecise segmentation outcomes,
particularly for small vessel structures. While models with attention
mechanisms, such as Transformers and large convolutional kernels, demonstrate
superior performance, their extensive computational demands during training and
inference lead to increased time complexity. In this study, we leverage Fourier
domain learning as a substitute for multi-scale convolutional kernels in 3D
hierarchical segmentation models, which can reduce computational expenses while
preserving global receptive fields within the network. Furthermore, a
zero-parameter frequency domain fusion method is designed to improve the skip
connections in U-Net architecture. Experimental results on a public dataset and
an in-house dataset indicate that our novel Fourier transformation-based
network achieves remarkable dice performance (84.37\% on ASACA500 and 80.32\%
on ImageCAS) in tubular vessel segmentation tasks and substantially reduces
computational requirements without compromising global receptive fields.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06228" title="Abstract">arXiv:2401.06228</a> (cross-list from math.CO) [<a href="/pdf/2401.06228" title="Download PDF">pdf</a>, <a href="/format/2401.06228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Combinatorics of Motzkin Polyominoes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Baril%2C+J">Jean-Luc Baril</a>, 
<a href="/search/math?searchtype=author&query=Kirgizov%2C+S">Sergey Kirgizov</a>, 
<a href="/search/math?searchtype=author&query=Ram%C3%ADrez%2C+J+L">Jos&#xe9; L. Ram&#xed;rez</a>, 
<a href="/search/math?searchtype=author&query=Villamizar%2C+D">Diego Villamizar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A word $w=w_1\cdots w_n$ over the set of positive integers is a Motzkin word
whenever $w_1=\texttt{1}$, $1\leq w_k\leq w_{k-1}+1$, and $w_{k-1}\neq w_{k}$
for $k=2, \dots, n$. It can be associated to a $n$-column Motzkin polyomino
whose $i$-th column contains $w_i$ cells, and all columns are bottom-justified.
We reveal bijective connections between Motzkin paths, restricted Catalan
words, primitive {\L}ukasiewicz paths, and Motzkin polyominoes. Using the
aforementioned bijections together with classical one-to-one correspondence
with Dyck paths avoiding $UDU$s, we provide generating functions with respect
to the length, area, semiperimeter, value of the last symbol, and number of
interior points of Motzkin polyominoes. We give asymptotics and close
expressions for the total area, total semiperimeter, sum of the last symbol
values, and total number of interior points over all Motzkin polyominoes of a
given length. We also present and prove an engaging trinomial relation
concerning the number of cells lying at different levels and first terms of the
expanded $(1+x+x^2)^n$.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06230" title="Abstract">arXiv:2401.06230</a> (cross-list from physics.geo-ph) [<a href="/pdf/2401.06230" title="Download PDF">pdf</a>, <a href="/format/2401.06230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WISE: full-Waveform variational Inference via Subsurface Extensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yin%2C+Z">Ziyi Yin</a>, 
<a href="/search/physics?searchtype=author&query=Orozco%2C+R">Rafael Orozco</a>, 
<a href="/search/physics?searchtype=author&query=Louboutin%2C+M">Mathias Louboutin</a>, 
<a href="/search/physics?searchtype=author&query=Herrmann%2C+F+J">Felix J. Herrmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP); Applications (stat.AP)

</div>
<p class="mathjax">We introduce a probabilistic technique for full-waveform inversion, employing
variational inference and conditional normalizing flows to quantify uncertainty
in migration-velocity models and its impact on imaging. Our approach integrates
generative artificial intelligence with physics-informed common-image gathers,
reducing reliance on accurate initial velocity models. Considered case studies
demonstrate its efficacy producing realizations of migration-velocity models
conditioned by the data. These models are used to quantify amplitude and
positioning effects during subsequent imaging.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06240" title="Abstract">arXiv:2401.06240</a> (cross-list from quant-ph) [<a href="/pdf/2401.06240" title="Download PDF">pdf</a>, <a href="/format/2401.06240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum eigenvalue processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Low%2C+G+H">Guang Hao Low</a>, 
<a href="/search/quant-ph?searchtype=author&query=Su%2C+Y">Yuan Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 106 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Numerical Analysis (math.NA); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Many problems in linear algebra -- such as those arising from non-Hermitian
physics and differential equations -- can be solved on a quantum computer by
processing eigenvalues of the non-normal input matrices. However, the existing
Quantum Singular Value Transformation (QSVT) framework is ill-suited to this
task, as eigenvalues and singular values are different in general. We present a
Quantum EigenValue Transformation (QEVT) framework for applying arbitrary
polynomial transformations on eigenvalues of block-encoded non-normal
operators, and a related Quantum EigenValue Estimation (QEVE) algorithm for
operators with real spectra. QEVT has query complexity to the block encoding
nearly recovering that of the QSVT for a Hermitian input, and QEVE achieves the
Heisenberg-limited scaling for diagonalizable input matrices. As applications,
we develop a linear differential equation solver with strictly linear time
query complexity for average-case diagonalizable operators, as well as a ground
state preparation algorithm that upgrades previous nearly optimal results for
Hermitian Hamiltonians to diagonalizable matrices with real spectra.
Underpinning our algorithms is an efficient method to prepare a quantum
superposition of Faber polynomials, which generalize the nearly-best uniform
approximation properties of Chebyshev polynomials to the complex plane. Of
independent interest, we also develop techniques to generate $n$ Fourier
coefficients with $\mathbf{O}(\mathrm{polylog}(n))$ gates compared to prior
approaches with linear cost.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06272" title="Abstract">arXiv:2401.06272</a> (cross-list from eess.IV) [<a href="/pdf/2401.06272" title="Download PDF">pdf</a>, <a href="/format/2401.06272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segmentation of Mediastinal Lymph Nodes in CT with Anatomical Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mathai%2C+T+S">Tejas Sudharshan Mathai</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+B">Bohan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Summers%2C+R+M">Ronald M. Summers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to CARS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Purpose: Lymph nodes (LNs) in the chest have a tendency to enlarge due to
various pathologies, such as lung cancer or pneumonia. Clinicians routinely
measure nodal size to monitor disease progression, confirm metastatic cancer,
and assess treatment response. However, variations in their shapes and
appearances make it cumbersome to identify LNs, which reside outside of most
organs. Methods: We propose to segment LNs in the mediastinum by leveraging the
anatomical priors of 28 different structures (e.g., lung, trachea etc.)
generated by the public TotalSegmentator tool. The CT volumes from 89 patients
available in the public NIH CT Lymph Node dataset were used to train three 3D
nnUNet models to segment LNs. The public St. Olavs dataset containing 15
patients (out-of-training-distribution) was used to evaluate the segmentation
performance. Results: For the 15 test patients, the 3D cascade nnUNet model
obtained the highest Dice score of 72.2 +- 22.3 for mediastinal LNs with short
axis diameter $\geq$ 8mm and 54.8 +- 23.8 for all LNs respectively. These
results represent an improvement of 10 points over a current approach that was
evaluated on the same test dataset. Conclusion: To our knowledge, we are the
first to harness 28 distinct anatomical priors to segment mediastinal LNs, and
our work can be extended to other nodal zones in the body. The proposed method
has immense potential for improved patient outcomes through the identification
of enlarged nodes in initial staging CT scans.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06274" title="Abstract">arXiv:2401.06274</a> (cross-list from eess.SP) [<a href="/pdf/2401.06274" title="Download PDF">pdf</a>, <a href="/format/2401.06274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer Masked Autoencoders for Next-Generation Wireless  Communications: Architecture and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zayat%2C+A">Abdullah Zayat</a>, 
<a href="/search/eess?searchtype=author&query=Hasabelnaby%2C+M+A">Mahmoud A. Hasabelnaby</a>, 
<a href="/search/eess?searchtype=author&query=Obeed%2C+M">Mohanad Obeed</a>, 
<a href="/search/eess?searchtype=author&query=Chaaban%2C+A">Anas Chaaban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to appear at IEEE Communications Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Next-generation communication networks are expected to exploit recent
advances in data science and cutting-edge communications technologies to
improve the utilization of the available communications resources. In this
article, we introduce an emerging deep learning (DL) architecture, the
transformer-masked autoencoder (TMAE), and discuss its potential in
next-generation wireless networks. We discuss the limitations of current DL
techniques in meeting the requirements of 5G and beyond 5G networks, and how
the TMAE differs from the classical DL techniques can potentially address
several wireless communication problems. We highlight various areas in
next-generation mobile networks which can be addressed using a TMAE, including
source and channel coding, estimation, and security. Furthermore, we
demonstrate a case study showing how a TMAE can improve data compression
performance and complexity compared to existing schemes. Finally, we discuss
key challenges and open future research directions for deploying the TMAE in
intelligent next-generation mobile networks.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06300" title="Abstract">arXiv:2401.06300</a> (cross-list from quant-ph) [<a href="/pdf/2401.06300" title="Download PDF">pdf</a>, <a href="/format/2401.06300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advantage of Quantum Neural Networks as Quantum Information Decoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhong%2C+W">Weishun Zhong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shtanko%2C+O">Oles Shtanko</a>, 
<a href="/search/quant-ph?searchtype=author&query=Movassagh%2C+R">Ramis Movassagh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">A promising strategy to protect quantum information from noise-induced errors
is to encode it into the low-energy states of a topological quantum memory
device. However, readout errors from such memory under realistic settings is
less understood. We study the problem of decoding quantum information encoded
in the groundspaces of topological stabilizer Hamiltonians in the presence of
generic perturbations, such as quenched disorder. We first prove that the
standard stabilizer-based error correction and decoding schemes work adequately
well in such perturbed quantum codes by showing that the decoding error
diminishes exponentially in the distance of the underlying unperturbed code. We
then prove that Quantum Neural Network (QNN) decoders provide an almost
quadratic improvement on the readout error. Thus, we demonstrate provable
advantage of using QNNs for decoding realistic quantum error-correcting codes,
and our result enables the exploration of a wider range of non-stabilizer codes
in the near-term laboratory settings.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06309" title="Abstract">arXiv:2401.06309</a> (cross-list from math.DS) [<a href="/pdf/2401.06309" title="Download PDF">pdf</a>, <a href="/format/2401.06309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cyberattacks on Adaptive Cruise Control Vehicles: An Analytical  Characterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+S">Shian Wang</a>, 
<a href="/search/math?searchtype=author&query=Shang%2C+M">Mingfeng Shang</a>, 
<a href="/search/math?searchtype=author&query=Stern%2C+R">Raphael Stern</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">While automated vehicles (AVs) are expected to revolutionize future
transportation systems, emerging AV technologies open a door for malicious
actors to compromise intelligent vehicles. As the first generation of AVs,
adaptive cruise control (ACC) vehicles are vulnerable to cyberattacks. While
recent effort has been made to understanding the impact of attacks on
transportation systems, little work has been done to systematically model and
characterize the malicious nature of candidate attacks. In this study, we
develop a general framework for modeling and synthesizing two types of
candidate attacks on ACC vehicles, namely direct attacks on vehicle control
commands and false data injection attacks on sensor measurement, with explicit
characterization of their adverse effects. Based on linear stability analysis
of car-following dynamics, we derive a series of analytical conditions
characterizing the malicious nature of potential attacks. This ensures a higher
degree of realism in modeling attacks with adverse effects, as opposed to
simply considering attacks as constants or random variables. Notably, the
conditions derived provide an effective method for strategically synthesizing
an array of candidate attacks on ACC vehicles. We conduct extensive simulation
to examine the impacts of intelligently designed attacks on microscopic
car-following dynamics and macroscopic traffic flow. Numerical results
illustrate the mechanism of candidate attacks, offering useful insights into
understanding the vulnerability of future transportation systems. The
methodology developed allows for further study of the widespread impact of
strategically designed attacks on traffic cybersecurity, and is expected to
inspire the development of efficient attack detection techniques and advanced
vehicle controls.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06325" title="Abstract">arXiv:2401.06325</a> (cross-list from stat.ML) [<a href="/pdf/2401.06325" title="Download PDF">pdf</a>, <a href="/format/2401.06325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Sampling without Isoperimetry via Diffusion-based Monte Carlo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huang%2C+X">Xunpeng Huang</a>, 
<a href="/search/stat?searchtype=author&query=Zou%2C+D">Difan Zou</a>, 
<a href="/search/stat?searchtype=author&query=Dong%2C+H">Hanze Dong</a>, 
<a href="/search/stat?searchtype=author&query=Ma%2C+Y">Yian Ma</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 54 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Computation (stat.CO)

</div>
<p class="mathjax">To sample from a general target distribution $p_*\propto e^{-f_*}$ beyond the
isoperimetric condition, Huang et al. (2023) proposed to perform sampling
through reverse diffusion, giving rise to Diffusion-based Monte Carlo (DMC).
Specifically, DMC follows the reverse SDE of a diffusion process that
transforms the target distribution to the standard Gaussian, utilizing a
non-parametric score estimation. However, the original DMC algorithm
encountered high gradient complexity, resulting in an exponential dependency on
the error tolerance $\epsilon$ of the obtained samples. In this paper, we
demonstrate that the high complexity of DMC originates from its redundant
design of score estimation, and proposed a more efficient algorithm, called
RS-DMC, based on a novel recursive score estimation method. In particular, we
first divide the entire diffusion process into multiple segments and then
formulate the score estimation step (at any time step) as a series of
interconnected mean estimation and sampling subproblems accordingly, which are
correlated in a recursive manner. Importantly, we show that with a proper
design of the segment decomposition, all sampling subproblems will only need to
tackle a strongly log-concave distribution, which can be very efficient to
solve using the Langevin-based samplers with a provably rapid convergence rate.
As a result, we prove that the gradient complexity of RS-DMC only has a
quasi-polynomial dependency on $\epsilon$, which significantly improves
exponential gradient complexity in Huang et al. (2023). Furthermore, under
commonly used dissipative conditions, our algorithm is provably much faster
than the popular Langevin-based algorithms. Our algorithm design and
theoretical framework illuminate a novel direction for addressing sampling
problems, which could be of broader applicability in the community.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06328" title="Abstract">arXiv:2401.06328</a> (cross-list from math.MG) [<a href="/pdf/2401.06328" title="Download PDF">pdf</a>, <a href="/format/2401.06328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Euclidean Erd&#x151;s--Anning Theorems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Eppstein%2C+D">David Eppstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Metric Geometry (math.MG)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">The Erd\H{o}s--Anning theorem states that every point set in the Euclidean
plane with integer distances must be either collinear or finite. More strongly,
for any (non-degenerate) triangle of diameter $\delta$, at most $O(\delta^2)$
points can have integer distances from all three triangle vertices. We prove
the same results for any strictly convex distance function on the plane, and
analogous results for every two-dimensional complete Riemannian manifold of
bounded genus and for geodesic distance on the boundary of every
three-dimensional Euclidean convex set. Our proofs are based on the properties
of additively weighted Voronoi diagrams of these distances.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06349" title="Abstract">arXiv:2401.06349</a> (cross-list from eess.IV) [<a href="/pdf/2401.06349" title="Download PDF">pdf</a>, <a href="/format/2401.06349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedTransformer: Accurate AD Diagnosis for 3D MRI Images through 2D  Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yifeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+K">Ke Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yihan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Automated diagnosis of AD in brain images is becoming a clinically important
technique to support precision and efficient diagnosis and treatment planning.
A few efforts have been made to automatically diagnose AD in magnetic resonance
imaging (MRI) using three-dimensional CNNs. However, due to the complexity of
3D models, the performance is still unsatisfactory, both in terms of accuracy
and efficiency. To overcome the complexities of 3D images and 3D models, in
this study, we aim to attack this problem with 2D vision Transformers. We
propose a 2D transformer-based medical image model with various transformer
attention encoders to diagnose AD in 3D MRI images, by cutting the 3D images
into multiple 2D slices.The model consists of four main components: shared
encoders across three dimensions, dimension-specific encoders, attention across
images from the same dimension, and attention across three dimensions. It is
used to obtain attention relationships among multiple sequences from different
dimensions (axial, coronal, and sagittal) and multiple slices. We also propose
morphology augmentation, an erosion and dilation based method to increase the
structural difference between AD and normal images. In this experiment, we use
multiple datasets from ADNI, AIBL, MIRAID, OASIS to show the performance of our
model. Our proposed MedTransformer demonstrates a strong ability in diagnosing
AD. These results demonstrate the effectiveness of MedTransformer in learning
from 3D data using a much smaller model and its capability to generalize among
different medical tasks, which provides a possibility to help doctors diagnose
AD in a simpler way.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06387" title="Abstract">arXiv:2401.06387</a> (cross-list from eess.AS) [<a href="/pdf/2401.06387" title="Download PDF">pdf</a>, <a href="/format/2401.06387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards High-Quality and Efficient Speech Bandwidth Extension with  Parallel Amplitude and Phase Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+Y">Ye-Xin Lu</a>, 
<a href="/search/eess?searchtype=author&query=Ai%2C+Y">Yang Ai</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+H">Hui-Peng Du</a>, 
<a href="/search/eess?searchtype=author&query=Ling%2C+Z">Zhen-Hua Ling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE/ACM Transactions on Audio, Speech, and Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Speech bandwidth extension (BWE) refers to widening the frequency bandwidth
range of speech signals, enhancing the speech quality towards brighter and
fuller. This paper proposes a generative adversarial network (GAN) based BWE
model with parallel prediction of Amplitude and Phase spectra, named AP-BWE,
which achieves both high-quality and efficient wideband speech waveform
generation. The proposed AP-BWE generator is entirely based on convolutional
neural networks (CNNs). It features a dual-stream architecture with mutual
interaction, where the amplitude stream and the phase stream communicate with
each other and respectively extend the high-frequency components from the input
narrowband amplitude and phase spectra. To improve the naturalness of the
extended speech signals, we employ a multi-period discriminator at the waveform
level and design a pair of multi-resolution amplitude and phase discriminators
at the spectral level, respectively. Experimental results demonstrate that our
proposed AP-BWE achieves state-of-the-art performance in terms of speech
quality for BWE tasks targeting sampling rates of both 16 kHz and 48 kHz. In
terms of generation efficiency, due to the all-convolutional architecture and
all-frame-level operations, the proposed AP-BWE can generate 48 kHz waveform
samples 292.3 times faster than real-time on a single RTX 4090 GPU and 18.1
times faster than real-time on a single CPU. Notably, to our knowledge, AP-BWE
is the first to achieve the direct extension of the high-frequency phase
spectrum, which is beneficial for improving the effectiveness of existing BWE
methods.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06422" title="Abstract">arXiv:2401.06422</a> (cross-list from eess.SP) [<a href="/pdf/2401.06422" title="Download PDF">pdf</a>, <a href="/format/2401.06422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Mechanical and Electrical Adjustment of IRS-aided LEO Satellite  MIMO Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+D">Doyoung Kim</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+S">Seongah Jeong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this letter, we propose a joint mechanical and electrical adjustment of
intelligent reflecting surface (IRS) for the performance improvements of
low-earth orbit (LEO) satellite multiple-input multiple-output (MIMO)
communications. In particular, we construct a three-dimensional (3D) MIMO
channel model for the mechanically-tilted IRS, and consider two types of
scenarios with and without the direct path of LEO-ground user link due to the
orbital flight. With the aim of maximizing the end-to-end performance, we
jointly optimize tilting angle and phase shift of IRS along with the
transceiver beamforming, whose performance superiority is verified via
simulations.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06445" title="Abstract">arXiv:2401.06445</a> (cross-list from physics.soc-ph) [<a href="/pdf/2401.06445" title="Download PDF">pdf</a>, <a href="/format/2401.06445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directed network comparison using motifs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Xie%2C+C">Chenwei Xie</a>, 
<a href="/search/physics?searchtype=author&query=Ke%2C+Q">Qiao Ke</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+H">Haoyu Chen</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+C">Chuang Liu</a>, 
<a href="/search/physics?searchtype=author&query=Zhan%2C+X">Xiu-Xiu Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Analyzing and characterizing the differences between networks is a
fundamental and challenging problem in network science. Previously, most
network comparison methods that rely on topological properties have been
restricted to measuring differences between two undirected networks. However,
many networks, such as biological networks, social networks, and transportation
networks, exhibit inherent directionality and higher-order attributes that
should not be ignored when comparing networks. Therefore, we propose a
motif-based directed network comparison method that captures local, global, and
higher-order differences between two directed networks. Specifically, we first
construct a motif distribution vector for each node, which captures the
information of a node's involvement in different directed motifs. Then, the
dissimilarity between two directed networks is defined on the basis of a matrix
which is composed of the motif distribution vector of every node and
Jensen-Shannon divergence. The performance of our method is evaluated via the
comparison of six real directed networks with their null models as well as
their perturbed networks based on edge perturbation. Our method is superior to
the state-of-the-art baselines and is robust with different parameter settings.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06485" title="Abstract">arXiv:2401.06485</a> (cross-list from eess.AS) [<a href="/pdf/2401.06485" title="Download PDF">pdf</a>, <a href="/format/2401.06485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning With Audio Discrimination For Customizable Keyword  Spotting In Continuous Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xi%2C+Y">Yu Xi</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+B">Baochen Yang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jiaqi Guo</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Customizable keyword spotting (KWS) in continuous speech has attracted
increasing attention due to its real-world application potential. While
contrastive learning (CL) has been widely used to extract keyword
representations, previous CL approaches all operate on pre-segmented isolated
words and employ only audio-text representations matching strategy. However,
for KWS in continuous speech, co-articulation and streaming word segmentation
can easily yield similar audio patterns for different texts, which may
consequently trigger false alarms. To address this issue, we propose a novel CL
with Audio Discrimination (CLAD) approach to learning keyword representation
with both audio-text matching and audio-audio discrimination ability. Here, an
InfoNCE loss considering both audio-audio and audio-text CL data pairs is
employed for each sliding window during training. Evaluations on the
open-source LibriPhrase dataset show that the use of sliding-window level
InfoNCE loss yields comparable performance compared to previous CL approaches.
Furthermore, experiments on the continuous speech dataset LibriSpeech
demonstrate that, by incorporating audio discrimination, CLAD achieves
significant performance gain over CL without audio discrimination. Meanwhile,
compared to two-stage KWS approaches, the end-to-end KWS with CLAD achieves not
only better performance, but also significant speed-up.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06499" title="Abstract">arXiv:2401.06499</a> (cross-list from eess.IV) [<a href="/pdf/2401.06499" title="Download PDF">pdf</a>, <a href="/format/2401.06499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Automated Tumor Segmentation for Brain MRI data using Multiplanner  UNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pandey%2C+S">Sumit Pandey</a>, 
<a href="/search/eess?searchtype=author&query=Changdar%2C+S">Satyasaran Changdar</a>, 
<a href="/search/eess?searchtype=author&query=Perslev%2C+M">Mathias Perslev</a>, 
<a href="/search/eess?searchtype=author&query=Dam%2C+E+B">Erik B Dam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Automated segmentation of distinct tumor regions is critical for accurate
diagnosis and treatment planning in pediatric brain tumors. This study
evaluates the efficacy of the Multi-Planner U-Net (MPUnet) approach in
segmenting different tumor subregions across three challenging datasets:
Pediatrics Tumor Challenge (PED), Brain Metastasis Challenge (MET), and
Sub-Sahara-Africa Adult Glioma (SSA). These datasets represent diverse
scenarios and anatomical variations, making them suitable for assessing the
robustness and generalization capabilities of the MPUnet model. By utilizing
multi-planar information, the MPUnet architecture aims to enhance segmentation
accuracy. Our results show varying performance levels across the evaluated
challenges, with the tumor core (TC) class demonstrating relatively higher
segmentation accuracy. However, variability is observed in the segmentation of
other classes, such as the edema and enhancing tumor (ET) regions. These
findings emphasize the complexity of brain tumor segmentation and highlight the
potential for further refinement of the MPUnet approach and inclusion of MRI
more data and preprocessing.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06523" title="Abstract">arXiv:2401.06523</a> (cross-list from stat.ML) [<a href="/pdf/2401.06523" title="Download PDF">pdf</a>, <a href="/format/2401.06523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Causal Additive Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kertel%2C+M">Maximilian Kertel</a>, 
<a href="/search/stat?searchtype=author&query=Klein%2C+N">Nadja Klein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Probability (math.PR); Statistics Theory (math.ST)

</div>
<p class="mathjax">We present a boosting-based method to learn additive Structural Equation
Models (SEMs) from observational data, with a focus on the theoretical aspects
of determining the causal order among variables. We introduce a family of score
functions based on arbitrary regression techniques, for which we establish
necessary conditions to consistently favor the true causal ordering. Our
analysis reveals that boosting with early stopping meets these criteria and
thus offers a consistent score function for causal orderings. To address the
challenges posed by high-dimensional data sets, we adapt our approach through a
component-wise gradient descent in the space of additive SEMs. Our simulation
study underlines our theoretical results for lower dimensions and demonstrates
that our high-dimensional adaptation is competitive with state-of-the-art
methods. In addition, it exhibits robustness with respect to the choice of the
hyperparameters making the procedure easy to tune.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06588" title="Abstract">arXiv:2401.06588</a> (cross-list from eess.AS) [<a href="/pdf/2401.06588" title="Download PDF">pdf</a>, <a href="/format/2401.06588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Behaviour of Connectionist Speech Recognition with Strong  Latency Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salvi%2C+G">Giampiero Salvi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Speech Communication Volume 48, Issue 7, July 2006, Pages 802-818
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">This paper describes the use of connectionist techniques in phonetic speech
recognition with strong latency constraints. The constraints are imposed by the
task of deriving the lip movements of a synthetic face in real time from the
speech signal, by feeding the phonetic string into an articulatory synthesiser.
Particular attention has been paid to analysing the interaction between the
time evolution model learnt by the multi-layer perceptrons and the transition
model imposed by the Viterbi decoder, in different latency conditions. Two
experiments were conducted in which the time dependencies in the language model
(LM) were controlled by a parameter. The results show a strong interaction
between the three factors involved, namely the neural network topology, the
length of time dependencies in the LM and the decoder latency.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06592" title="Abstract">arXiv:2401.06592</a> (cross-list from math.OC) [<a href="/pdf/2401.06592" title="Download PDF">pdf</a>, <a href="/format/2401.06592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonconvex Deterministic Matrix Completion by Projected Gradient Descent  Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+S">Song Li</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+J">Junhong Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 3figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We study deterministic matrix completion problem, i.e., recovering a low-rank
matrix from a few observed entries where the sampling set is chosen as the edge
set of a Ramanujan graph. We first investigate projected gradient descent (PGD)
applied to a Burer-Monteiro least-squares problem and show that it converges
linearly to the incoherent ground-truth with respect to the condition number
\k{appa} of ground-truth under a benign initialization and large samples. We
next apply the scaled variant of PGD to deal with the ill-conditioned case when
\k{appa} is large, and we show the algorithm converges at a linear rate
independent of the condition number \k{appa} under similar conditions. Finally,
we provide numerical experiments to corroborate our results.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06618" title="Abstract">arXiv:2401.06618</a> (cross-list from math.CO) [<a href="/pdf/2401.06618" title="Download PDF">pdf</a>, <a href="/ps/2401.06618" title="Download PostScript">ps</a>, <a href="/format/2401.06618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabiliser codes over fields of even order
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ball%2C+S">Simeon Ball</a>, 
<a href="/search/math?searchtype=author&query=Moreno%2C+E">Edgar Moreno</a>, 
<a href="/search/math?searchtype=author&query=Simoens%2C+R">Robin Simoens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We prove that the natural isomorphism between GF(2^h) and GF(2)^h induces a
bijection between stabiliser codes on n quqits with local dimension q=2^h and
binary stabiliser codes on hn qubits. This allows us to describe these codes
geometrically: a stabiliser code over a field of even order corresponds to a
so-called quantum set of symplectic polar spaces. Moreover, equivalent
stabiliser codes have a similar geometry, which can be used to prove the
uniqueness of a [[4,0,3]]_4 stabiliser code and the nonexistence of both a
[[7,1,4]]_4 and an [[8,0,5]]_4 stabiliser code.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06635" title="Abstract">arXiv:2401.06635</a> (cross-list from math.FA) [<a href="/pdf/2401.06635" title="Download PDF">pdf</a>, <a href="/ps/2401.06635" title="Download PostScript">ps</a>, <a href="/format/2401.06635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An elementary approach to splittings of unbounded operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Iserles%2C+A">Arieh Iserles</a>, 
<a href="/search/math?searchtype=author&query=Kropielnicka%2C+K">Karolina Kropielnicka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Using elementary means, we derive the three most popular splittings of
$e^{(A+B)}$ and their error bounds in the case when $A$ and $B$ are (possibly
unbounded) operators in a Hilbert space, generating strongly continuous
semigroups, $e^{tA}$, $e^{tB}$ and $e^{t(A+B)}$. The error of these splittings
is bounded in terms of the norm of the commutators $[A, B]$, $[A, [A, B]]$ and
$[B, [A, B]]$.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06725" title="Abstract">arXiv:2401.06725</a> (cross-list from quant-ph) [<a href="/pdf/2401.06725" title="Download PDF">pdf</a>, <a href="/ps/2401.06725" title="Download PostScript">ps</a>, <a href="/format/2401.06725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity Classification of Product State Problems for Local  Hamiltonians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kallaugher%2C+J">John Kallaugher</a>, 
<a href="/search/quant-ph?searchtype=author&query=Parekh%2C+O">Ojas Parekh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Thompson%2C+K">Kevin Thompson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Y">Yipu Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yirka%2C+J">Justin Yirka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Product states, unentangled tensor products of single qubits, are a
ubiquitous ansatz in quantum computation, including for state-of-the-art
Hamiltonian approximation algorithms. A natural question is whether we should
expect to efficiently solve product state problems on any interesting families
of Hamiltonians.
<br />We completely classify the complexity of finding minimum-energy product
states for Hamiltonians defined by any fixed set of allowed 2-qubit
interactions. Our results follow a line of work classifying the complexity of
solving Hamiltonian problems and classical constraint satisfaction problems
based on the allowed constraints. We prove that estimating the minimum energy
of a product state is in P if and only if all allowed interactions are 1-local,
and NP-complete otherwise. Equivalently, any family of non-trivial two-body
interactions generates Hamiltonians with NP-complete product-state problems.
Our hardness constructions only require coupling strengths of constant
magnitude.
<br />A crucial component of our proofs is a collection of hardness results for a
new variant of the Vector Max-Cut problem, which should be of independent
interest. Our definition involves sums of distances rather than squared
distances and allows linear stretches.
<br />A corollary of our classification is a new proof that optimizing product
states in the Quantum Max-Cut model (the quantum Heisenberg model) is
NP-complete.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06738" title="Abstract">arXiv:2401.06738</a> (cross-list from math.OC) [<a href="/pdf/2401.06738" title="Download PDF">pdf</a>, <a href="/format/2401.06738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise-adaptive (Accelerated) Stochastic Heavy-Ball Momentum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dang%2C+A">Anh Dang</a>, 
<a href="/search/math?searchtype=author&query=Babanezhad%2C+R">Reza Babanezhad</a>, 
<a href="/search/math?searchtype=author&query=Vaswani%2C+S">Sharan Vaswani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We analyze the convergence of stochastic heavy ball (SHB) momentum in the
smooth, strongly-convex setting. Kidambi et al. (2018) show that SHB (with
small mini-batches) cannot attain an accelerated rate of convergence even for
quadratics, and conjecture that the practical gain of SHB is a by-product of
mini-batching. We substantiate this claim by showing that SHB can obtain an
accelerated rate when the mini-batch size is larger than some threshold. In
particular, for strongly-convex quadratics with condition number $\kappa$, we
prove that SHB with the standard step-size and momentum parameters results in
an $O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ convergence rate,
where $T$ is the number of iterations and $\sigma^2$ is the variance in the
stochastic gradients. To ensure convergence to the minimizer, we propose a
multi-stage approach that results in a noise-adaptive
$O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$
rate. For general strongly-convex functions, we use the averaging
interpretation of SHB along with exponential step-sizes to prove an
$O\left(\exp\left(-\frac{T}{\kappa} \right) + \frac{\sigma^2}{T} \right)$
convergence to the minimizer in a noise-adaptive manner. Finally, we
empirically demonstrate the effectiveness of the proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06740" title="Abstract">arXiv:2401.06740</a> (cross-list from q-fin.CP) [<a href="/pdf/2401.06740" title="Download PDF">pdf</a>, <a href="/format/2401.06740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deep implicit-explicit minimizing movement method for option pricing  in jump-diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Georgoulis%2C+E+H">Emmanuil H. Georgoulis</a>, 
<a href="/search/q-fin?searchtype=author&query=Papapantoleon%2C+A">Antonis Papapantoleon</a>, 
<a href="/search/q-fin?searchtype=author&query=Smaragdakis%2C+C">Costas Smaragdakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">We develop a novel deep learning approach for pricing European basket options
written on assets that follow jump-diffusion dynamics. The option pricing
problem is formulated as a partial integro-differential equation, which is
approximated via a new implicit-explicit minimizing movement time-stepping
approach, involving approximation by deep, residual-type Artificial Neural
Networks (ANNs) for each time step. The integral operator is discretized via
two different approaches: a) a sparse-grid Gauss--Hermite approximation
following localised coordinate axes arising from singular value decompositions,
and b) an ANN-based high-dimensional special-purpose quadrature rule.
Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of
the solution for large values of the underlyings and also leads to consistent
outputs with respect to a priori known qualitative properties of the solution.
The performance and robustness with respect to the dimension of the methods are
assessed in a series of numerical experiments involving the Merton
jump-diffusion model.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06744" title="Abstract">arXiv:2401.06744</a> (cross-list from eess.IV) [<a href="/pdf/2401.06744" title="Download PDF">pdf</a>, <a href="/format/2401.06744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Parallel Algorithms for Inpainting-Based Representations of 4K  Images -- Part I: Homogeneous Diffusion Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=K%C3%A4mper%2C+N">Niklas K&#xe4;mper</a>, 
<a href="/search/eess?searchtype=author&query=Chizhov%2C+V">Vassillen Chizhov</a>, 
<a href="/search/eess?searchtype=author&query=Weickert%2C+J">Joachim Weickert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In recent years inpainting-based compression methods have been shown to be a
viable alternative to classical codecs such as JPEG and JPEG2000. Unlike
transform-based codecs, which store coefficients in the transform domain,
inpainting-based approaches store a small subset of the original image pixels
and reconstruct the image from those by using a suitable inpainting operator. A
good candidate for such an inpainting operator is homogeneous diffusion
inpainting, as it is simple, theoretically well-motivated, and can achieve good
reconstruction quality for optimized data. However, a major challenge has been
to design fast solvers for homogeneous diffusion inpainting that scale to 4K
image resolution ($3840 \times 2160$ pixels) and are real-time capable. We
overcome this with a careful adaptation and fusion of two of the most efficient
concept from numerical analysis: multigrid and domain decomposition. Our domain
decomposition algorithm efficiently utilizes GPU parallelism by solving
inpainting problems on small overlapping blocks. Unlike simple block
decomposition strategies such as the ones in JPEG, our approach yields block
artifact-free reconstructions. Furthermore, embedding domain decomposition in a
full multigrid scheme provides global interactions and allows us to achieve
optimal convergence by reducing both low- and high-frequency errors at the same
rate. We are able to achieve 4K color image reconstruction at more than $60$
frames per second even from very sparse data - something which has been
previously unfeasible.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06747" title="Abstract">arXiv:2401.06747</a> (cross-list from eess.IV) [<a href="/pdf/2401.06747" title="Download PDF">pdf</a>, <a href="/format/2401.06747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Parallel Algorithms for Inpainting-Based Representations of 4K  Images -- Part II: Spatial and Tonal Data Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=K%C3%A4mper%2C+N">Niklas K&#xe4;mper</a>, 
<a href="/search/eess?searchtype=author&query=Chizhov%2C+V">Vassillen Chizhov</a>, 
<a href="/search/eess?searchtype=author&query=Weickert%2C+J">Joachim Weickert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Homogeneous diffusion inpainting can reconstruct missing image areas with
high quality from a sparse subset of known pixels, provided that their location
as well as their gray or color values are well optimized. This property is
exploited in inpainting-based image compression, which is a promising
alternative to classical transform-based codecs such as JPEG and JPEG2000.
However, optimizing the inpainting data is a challenging task. Current
approaches are either quite slow or do not produce high quality results. As a
remedy we propose fast spatial and tonal optimization algorithms for
homogeneous diffusion inpainting that efficiently utilize GPU parallelism, with
a careful adaptation of some of the most successful numerical concepts. We
propose a densification strategy using ideas from error-map dithering combined
with a Delaunay triangulation for the spatial optimization. For the tonal
optimization we design a domain decomposition solver that solves the
corresponding normal equations in a matrix-free fashion and supplement it with
a Voronoi-based initialization strategy. With our proposed methods we are able
to generate high quality inpainting masks for homogeneous diffusion and
optimized tonal values in a runtime that outperforms prior state-of-the-art by
a wide margin.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06755" title="Abstract">arXiv:2401.06755</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2401.06755" title="Download PDF">pdf</a>, <a href="/format/2401.06755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving the Discretised Multiphase Flow Equations with Interface  Capturing on Structured Grids Using Machine Learning Libraries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+B">Boyang Chen</a>, 
<a href="/search/physics?searchtype=author&query=Heaney%2C+C+E">Claire E. Heaney</a>, 
<a href="/search/physics?searchtype=author&query=Gomes%2C+J+L+M+A">Jefferson L. M. A. Gomes</a>, 
<a href="/search/physics?searchtype=author&query=Matar%2C+O+K">Omar K. Matar</a>, 
<a href="/search/physics?searchtype=author&query=Pain%2C+C+C">Christopher C. Pain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 18 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper solves the multiphase flow equations with interface capturing
using the AI4PDEs approach (Artificial Intelligence for Partial Differential
Equations). The solver within AI4PDEs uses tools from machine learning (ML)
libraries to solve (exactly) partial differential equations (PDEs) that have
been discretised using numerical methods. Convolutional layers can be used to
express the discretisations as a neural network, whose weights are determined
by the numerical method, rather than by training. To solve the system, a
multigrid solver is implemented through a neural network with a U-Net
architecture. Immiscible two-phase flow is modelled by the 3D incompressible
Navier-Stokes equations with surface tension and advection of a volume fraction
field, which describes the interface between the fluids. A new compressive
algebraic volume-of-fluids method is introduced, based on a residual
formulation using Petrov-Galerkin for accuracy and designed with AI4PDEs in
mind. High-order finite-element based schemes are chosen to model a collapsing
water column and a rising bubble. Results compare well with experimental data
and other numerical results from the literature, demonstrating that, for the
first time, finite element discretisations of multiphase flows can be solved
using the neural network solver from the AI4PDEs approach. A benefit of
expressing numerical discretisations as neural networks is that the code can
run, without modification, on CPUs, GPUs or the latest accelerators designed
especially to run AI codes.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon, 15 Jan 24</h3>
<dl>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1404.4599" title="Abstract">arXiv:1404.4599</a> (replaced) [<a href="/e-print/1404.4599" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite Groupoids, Finite Coverings and Symmetries in Finite Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Otto%2C+M">Martin Otto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The construction of finite n-acyclic groupoids in Section 2.4 is flawed and I know of no direct repair: completion turns out to be incompatible with restriction to proper subsets of the generator set, so that the induction towards Proposition 2.22 does not stabilise as claimed. This problem has been overcome in arxiv:<a href="/abs/1806.08664">1806.08664</a>. Also compare arxiv:<a href="/abs/1709.00031">1709.00031</a> and <a href="/abs/2208.03273">arXiv:2208.03273</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Logic in Computer Science (cs.LO); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1908.01135" title="Abstract">arXiv:1908.01135</a> (replaced) [<a href="/pdf/1908.01135" title="Download PDF">pdf</a>, <a href="/format/1908.01135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplayer Bandit Learning, from Competition to Cooperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%A2nzei%2C+S">Simina Br&#xe2;nzei</a>, 
<a href="/search/cs?searchtype=author&query=Peres%2C+Y">Yuval Peres</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.12882" title="Abstract">arXiv:2007.12882</a> (replaced) [<a href="/pdf/2007.12882" title="Download PDF">pdf</a>, <a href="/ps/2007.12882" title="Download PostScript">ps</a>, <a href="/format/2007.12882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A finite sample analysis of the benign overfitting phenomenon for ridge  function estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Caron%2C+E">Emmanuel Caron</a>, 
<a href="/search/stat?searchtype=author&query=Chretien%2C+S">Stephane Chretien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New section on generalisation added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.15003" title="Abstract">arXiv:2104.15003</a> (replaced) [<a href="/pdf/2104.15003" title="Download PDF">pdf</a>, <a href="/format/2104.15003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Bounds for Concurrent Bounded Queues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aksenov%2C+V">Vitaly Aksenov</a>, 
<a href="/search/cs?searchtype=author&query=Koval%2C+N">Nikita Koval</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+P">Petr Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Paramonov%2C+A">Anton Paramonov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.03180" title="Abstract">arXiv:2106.03180</a> (replaced) [<a href="/pdf/2106.03180" title="Download PDF">pdf</a>, <a href="/format/2106.03180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision Transformers with Hierarchical Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yu-Huan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guolei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chhatkuli%2C+A">Ajad Chhatkuli</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Machine Intelligence Research (MIR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.06147" title="Abstract">arXiv:2106.06147</a> (replaced) [<a href="/pdf/2106.06147" title="Download PDF">pdf</a>, <a href="/format/2106.06147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NAAQA: A Neural Architecture for Acoustic Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelnour%2C+J">Jerome Abdelnour</a>, 
<a href="/search/cs?searchtype=author&query=Rouat%2C+J">Jean Rouat</a>, 
<a href="/search/cs?searchtype=author&query=Salvi%2C+G">Giampiero Salvi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) in April 2021 (first revision February 2022)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Pattern Analysis and Machine Intelligence,
  2023, Volume: 45 Issue: 4, Page(s): 4997-5009
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.01616" title="Abstract">arXiv:2109.01616</a> (replaced) [<a href="/pdf/2109.01616" title="Download PDF">pdf</a>, <a href="/format/2109.01616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal artificial boundary conditions based on second-order correctors  for three dimensional random elliptic media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/math?searchtype=author&query=Otto%2C+F">Felix Otto</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+L">Lihan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.09551" title="Abstract">arXiv:2109.09551</a> (replaced) [<a href="/pdf/2109.09551" title="Download PDF">pdf</a>, <a href="/ps/2109.09551" title="Download PostScript">ps</a>, <a href="/format/2109.09551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Sum-Rank Distance Codes over Finite Chain Rings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Pe%C3%B1as%2C+U">Umberto Mart&#xed;nez-Pe&#xf1;as</a>, 
<a href="/search/cs?searchtype=author&query=Puchinger%2C+S">Sven Puchinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.02381" title="Abstract">arXiv:2110.02381</a> (replaced) [<a href="/pdf/2110.02381" title="Download PDF">pdf</a>, <a href="/ps/2110.02381" title="Download PostScript">ps</a>, <a href="/format/2110.02381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Peak Detection for Holter ECGs by Self-Organized Operational  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gabbouj%2C+M">Moncef Gabbouj</a>, 
<a href="/search/eess?searchtype=author&query=Kiranyaz%2C+S">Serkan Kiranyaz</a>, 
<a href="/search/eess?searchtype=author&query=Malik%2C+J">Junaid Malik</a>, 
<a href="/search/eess?searchtype=author&query=Zahid%2C+M+U">Muhammad Uzair Zahid</a>, 
<a href="/search/eess?searchtype=author&query=Ince%2C+T">Turker Ince</a>, 
<a href="/search/eess?searchtype=author&query=Chowdhury%2C+M">Muhammad Chowdhury</a>, 
<a href="/search/eess?searchtype=author&query=Khandakar%2C+A">Amith Khandakar</a>, 
<a href="/search/eess?searchtype=author&query=Tahir%2C+A">Anas Tahir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2110.02215">arXiv:2110.02215</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Neural Networks and Learning Systems, vol.
  34, no. 11, pp. 9363-9374, Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03224" title="Abstract">arXiv:2203.03224</a> (replaced) [<a href="/pdf/2203.03224" title="Download PDF">pdf</a>, <a href="/format/2203.03224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factor Graph-Based Planning as Inference for Autonomous Vehicle Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bari%2C+S">Salman Bari</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiagong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Haidari%2C+A+S">Ahmad Schoha Haidari</a>, 
<a href="/search/cs?searchtype=author&query=Wollherr%2C+D">Dirk Wollherr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.15968" title="Abstract">arXiv:2203.15968</a> (replaced) [<a href="/pdf/2203.15968" title="Download PDF">pdf</a>, <a href="/format/2203.15968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Light Clients for Lazy Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+E+N">Ertem Nusret Tas</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+D">David Tse</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zindros%2C+D">Dionysis Zindros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Financial Cryptography and Data Security 2024 (FC24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00832" title="Abstract">arXiv:2205.00832</a> (replaced) [<a href="/pdf/2205.00832" title="Download PDF">pdf</a>, <a href="/format/2205.00832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Descent, Stochastic Optimization, and Other Tales
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jun Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.06221" title="Abstract">arXiv:2205.06221</a> (replaced) [<a href="/pdf/2205.06221" title="Download PDF">pdf</a>, <a href="/ps/2205.06221" title="Download PostScript">ps</a>, <a href="/format/2205.06221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Frequency Tunable Grounded &amp; Floating Incremental-Decremental  Meminductor Emulator and Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shukla%2C+G">Garima Shukla</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+P">Pratik Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Paul%2C+S+K">Sajal K. Paul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 Pages, 22 Figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Vol 53, No 3 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09542" title="Abstract">arXiv:2206.09542</a> (replaced) [<a href="/pdf/2206.09542" title="Download PDF">pdf</a>, <a href="/format/2206.09542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Guidance for User Placement in Avatar-Mediated Telepresence  between Dissimilar Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dongseok Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiho Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehei Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sung-Hee Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10708" title="Abstract">arXiv:2206.10708</a> (replaced) [<a href="/pdf/2206.10708" title="Download PDF">pdf</a>, <a href="/format/2206.10708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlashSyn: Flash Loan Attack Synthesis via Counter Example Driven  Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Beillahi%2C+S+M">Sidi Mohamed Beillahi</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+F">Fan Long</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures, conference paper extended version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11892" title="Abstract">arXiv:2206.11892</a> (replaced) [<a href="/pdf/2206.11892" title="Download PDF">pdf</a>, <a href="/format/2206.11892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DDPM-CD: Denoising Diffusion Probabilistic Models as Feature Extractors  for Change Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bandara%2C+W+G+C">Wele Gedara Chaminda Bandara</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+N+G">Nithin Gopalakrishnan Nair</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+V+M">Vishal M. Patel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at: <a href="https://github.com/wgcban/ddpm-cd">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07898" title="Abstract">arXiv:2208.07898</a> (replaced) [<a href="/pdf/2208.07898" title="Download PDF">pdf</a>, <a href="/format/2208.07898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative causal inference on distributed data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kawamata%2C+Y">Yuji Kawamata</a>, 
<a href="/search/stat?searchtype=author&query=Motai%2C+R">Ryoki Motai</a>, 
<a href="/search/stat?searchtype=author&query=Okada%2C+Y">Yukihiko Okada</a>, 
<a href="/search/stat?searchtype=author&query=Imakura%2C+A">Akira Imakura</a>, 
<a href="/search/stat?searchtype=author&query=Sakurai%2C+T">Tetsuya Sakurai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11866" title="Abstract">arXiv:2209.11866</a> (replaced) [<a href="/pdf/2209.11866" title="Download PDF">pdf</a>, <a href="/format/2209.11866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlVC: Zero-Shot Voice Conversion with Time-Varying Controls on  Pitch and Speed
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+M">Meiying Chen</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+Z">Zhiyao Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Audio samples: <a href="https://bit.ly/3PsrKLJ">this https URL</a>; Code: <a href="https://github.com/MelissaChen15/control-vc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.15573" title="Abstract">arXiv:2209.15573</a> (replaced) [<a href="/pdf/2209.15573" title="Download PDF">pdf</a>, <a href="/format/2209.15573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of weak-SINDy Surrogate Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Russo%2C+B">Benjamin Russo</a>, 
<a href="/search/math?searchtype=author&query=Laiu%2C+M+P">M. Paul Laiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01719" title="Abstract">arXiv:2210.01719</a> (replaced) [<a href="/pdf/2210.01719" title="Download PDF">pdf</a>, <a href="/format/2210.01719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Temporal Resolution in Spectrogram for Audio Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haohe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xubo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Q">Qiuqiang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Plumbley%2C+M+D">Mark D. Plumbley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02091" title="Abstract">arXiv:2210.02091</a> (replaced) [<a href="/pdf/2210.02091" title="Download PDF">pdf</a>, <a href="/ps/2210.02091" title="Download PostScript">ps</a>, <a href="/format/2210.02091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tripletformer for Probabilistic Interpolation of Irregularly sampled  Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yalavarthi%2C+V+K">Vijaya Krishna Yalavarthi</a>, 
<a href="/search/cs?searchtype=author&query=Burchert%2C+J">Johannes Burchert</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-thieme%2C+L">Lars Schmidt-thieme</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on BigData, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03050" title="Abstract">arXiv:2210.03050</a> (replaced) [<a href="/pdf/2210.03050" title="Download PDF">pdf</a>, <a href="/format/2210.03050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State-of-the-art generalisation research in NLP: A taxonomy and review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hupkes%2C+D">Dieuwke Hupkes</a>, 
<a href="/search/cs?searchtype=author&query=Giulianelli%2C+M">Mario Giulianelli</a>, 
<a href="/search/cs?searchtype=author&query=Dankers%2C+V">Verna Dankers</a>, 
<a href="/search/cs?searchtype=author&query=Artetxe%2C+M">Mikel Artetxe</a>, 
<a href="/search/cs?searchtype=author&query=Elazar%2C+Y">Yanai Elazar</a>, 
<a href="/search/cs?searchtype=author&query=Pimentel%2C+T">Tiago Pimentel</a>, 
<a href="/search/cs?searchtype=author&query=Christodoulopoulos%2C+C">Christos Christodoulopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Lasri%2C+K">Karim Lasri</a>, 
<a href="/search/cs?searchtype=author&query=Saphra%2C+N">Naomi Saphra</a>, 
<a href="/search/cs?searchtype=author&query=Sinclair%2C+A">Arabella Sinclair</a>, 
<a href="/search/cs?searchtype=author&query=Ulmer%2C+D">Dennis Ulmer</a>, 
<a href="/search/cs?searchtype=author&query=Schottmann%2C+F">Florian Schottmann</a>, 
<a href="/search/cs?searchtype=author&query=Batsuren%2C+K">Khuyagbaatar Batsuren</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kaiser Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+K">Koustuv Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Khalatbari%2C+L">Leila Khalatbari</a>, 
<a href="/search/cs?searchtype=author&query=Ryskina%2C+M">Maria Ryskina</a>, 
<a href="/search/cs?searchtype=author&query=Frieske%2C+R">Rita Frieske</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhijing Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint was published as an Analysis article in Nature Machine Intelligence. Please refer to the published version when citing this work. 28 pages of content + 6 pages of appendix + 52 pages of references
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Nat Mach Intell 5, 1161-1174 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06015" title="Abstract">arXiv:2210.06015</a> (replaced) [<a href="/pdf/2210.06015" title="Download PDF">pdf</a>, <a href="/format/2210.06015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural  Architecture Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakhtiarifard%2C+P">Pedram Bakhtiarifard</a>, 
<a href="/search/cs?searchtype=author&query=Igel%2C+C">Christian Igel</a>, 
<a href="/search/cs?searchtype=author&query=Selvan%2C+R">Raghavendra Selvan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to be presented at the International Conference on Acoustics, Speech and Signal Processing (ICASSP-2024). Source code at <a href="https://github.com/saintslab/EC-NAS-Bench">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.17309" title="Abstract">arXiv:2210.17309</a> (replaced) [<a href="/pdf/2210.17309" title="Download PDF">pdf</a>, <a href="/format/2210.17309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spontaneous emergence of groups and signaling diversity in dynamic  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fulker%2C+Z">Zachary Fulker</a>, 
<a href="/search/cs?searchtype=author&query=Forber%2C+P">Patrick Forber</a>, 
<a href="/search/cs?searchtype=author&query=Smead%2C+R">Rory Smead</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+C">Christoph Riedl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Theoretical Economics (econ.TH); Physics and Society (physics.soc-ph); Molecular Networks (q-bio.MN); Populations and Evolution (q-bio.PE)

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05408" title="Abstract">arXiv:2211.05408</a> (replaced) [<a href="/pdf/2211.05408" title="Download PDF">pdf</a>, <a href="/format/2211.05408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling Moments with Kernel Stein Discrepancies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kanagawa%2C+H">Heishiro Kanagawa</a>, 
<a href="/search/stat?searchtype=author&query=Barp%2C+A">Alessandro Barp</a>, 
<a href="/search/stat?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>, 
<a href="/search/stat?searchtype=author&query=Mackey%2C+L">Lester Mackey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 93 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06544" title="Abstract">arXiv:2211.06544</a> (replaced) [<a href="/pdf/2211.06544" title="Download PDF">pdf</a>, <a href="/format/2211.06544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correcting Faulty Road Maps by Image Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Soojung Hong</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Kwanghee Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024. Implementation available at <a href="https://github.com/SoojungHong/image_inpainting_model_for_lane_geomery_discovery">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08332" title="Abstract">arXiv:2211.08332</a> (replaced) [<a href="/pdf/2211.08332" title="Download PDF">pdf</a>, <a href="/format/2211.08332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Versatile Diffusion: Text, Images and Variations All in One Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xingqian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Eric Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023; Github link: <a href="https://github.com/SHI-Labs/Versatile-Diffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15207" title="Abstract">arXiv:2211.15207</a> (replaced) [<a href="/pdf/2211.15207" title="Download PDF">pdf</a>, <a href="/ps/2211.15207" title="Download PostScript">ps</a>, <a href="/format/2211.15207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Query Satisfiability of Constrained Horn Clauses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Angelis%2C+E">Emanuele De Angelis</a> (1), 
<a href="/search/cs?searchtype=author&query=Fioravanti%2C+F">Fabio Fioravanti</a> (2), 
<a href="/search/cs?searchtype=author&query=Pettorossi%2C+A">Alberto Pettorossi</a> (3), 
<a href="/search/cs?searchtype=author&query=Proietti%2C+M">Maurizio Proietti</a> (1) ((1) IASI-CNR, Rome, Italy, (2) DEc, University &#x27;G. d&#x27;Annunzio&#x27;, Chieti-Pescara, Italy, (3) DICII, University of Rome &#x27;Tor Vergata&#x27;, Italy)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01249" title="Abstract">arXiv:2212.01249</a> (replaced) [<a href="/pdf/2212.01249" title="Download PDF">pdf</a>, <a href="/format/2212.01249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Immersed Mesh Method (AIMM) for Fluid Structure Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nemer%2C+R">R. Nemer</a>, 
<a href="/search/math?searchtype=author&query=Larcher%2C+A">A. Larcher</a>, 
<a href="/search/math?searchtype=author&query=Hachem%2C+E">E. Hachem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07946" title="Abstract">arXiv:2212.07946</a> (replaced) [<a href="/pdf/2212.07946" title="Download PDF">pdf</a>, <a href="/format/2212.07946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Inference and Reinforcement Learning: A unified inference on  continuous state and action spaces under partially observability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malekzadeh%2C+P">Parvin Malekzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Plataniotis%2C+K+N">Konstantinos N. Plataniotis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 93 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11952" title="Abstract">arXiv:2302.11952</a> (replaced) [<a href="/pdf/2302.11952" title="Download PDF">pdf</a>, <a href="/format/2302.11952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Drawing of Layered Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katheder%2C+J">Julia Katheder</a>, 
<a href="/search/cs?searchtype=author&query=Kobourov%2C+S+G">Stephen G. Kobourov</a>, 
<a href="/search/cs?searchtype=author&query=Kuckuk%2C+A">Axel Kuckuk</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+M">Maximilian Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+J">Johannes Zink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in Proc. 18th International Conference and Workshops on Algorithms and Computation 2024 (WALCOM'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14627" title="Abstract">arXiv:2302.14627</a> (replaced) [<a href="/pdf/2302.14627" title="Download PDF">pdf</a>, <a href="/format/2302.14627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNA digital data storage and retrieval using algebraic codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%2C+N">NallappaBhavithran G</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+S">Selvakumar R</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14752" title="Abstract">arXiv:2302.14752</a> (replaced) [<a href="/pdf/2302.14752" title="Download PDF">pdf</a>, <a href="/format/2302.14752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot-Guided Crowd Evacuation: Two-Scale Modeling and Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tongjia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhenyuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Nayyar%2C+M">Mollik Nayyar</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+A+R">Alan R. Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minghui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hai Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00259" title="Abstract">arXiv:2303.00259</a> (replaced) [<a href="/pdf/2303.00259" title="Download PDF">pdf</a>, <a href="/format/2303.00259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing All Restricted Skyline Probabilities on Uncertain Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiangyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianzhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+D">Dongjing Miao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version, a shorter version to appear in ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04384" title="Abstract">arXiv:2303.04384</a> (replaced) [<a href="/pdf/2303.04384" title="Download PDF">pdf</a>, <a href="/format/2303.04384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEMv2: Table Separation Line Detection Based on Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Pengfei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiefeng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jun Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianshu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huihui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Baocai Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Bing Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05910" title="Abstract">arXiv:2303.05910</a> (replaced) [<a href="/pdf/2303.05910" title="Download PDF">pdf</a>, <a href="/ps/2303.05910" title="Download PostScript">ps</a>, <a href="/format/2303.05910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Product Jacobi-Theta Boltzmann machines with score matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pasquale%2C+A">Andrea Pasquale</a>, 
<a href="/search/stat?searchtype=author&query=Krefl%2C+D">Daniel Krefl</a>, 
<a href="/search/stat?searchtype=author&query=Carrazza%2C+S">Stefano Carrazza</a>, 
<a href="/search/stat?searchtype=author&query=Nielsen%2C+F">Frank Nielsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, ACAT22 proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06936" title="Abstract">arXiv:2303.06936</a> (replaced) [<a href="/pdf/2303.06936" title="Download PDF">pdf</a>, <a href="/format/2303.06936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid multi-observer for improving estimation performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Petri%2C+E">E. Petri</a>, 
<a href="/search/eess?searchtype=author&query=Postoyan%2C+R">R. Postoyan</a>, 
<a href="/search/eess?searchtype=author&query=Astolfi%2C+D">D. Astolfi</a>, 
<a href="/search/eess?searchtype=author&query=Nesic%2C+D">D. Nesic</a>, 
<a href="/search/eess?searchtype=author&query=Andrieu%2C+V">V. Andrieu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2209.10130">arXiv:2209.10130</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13199" title="Abstract">arXiv:2303.13199</a> (replaced) [<a href="/pdf/2303.13199" title="Download PDF">pdf</a>, <a href="/format/2303.13199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> First Session Adaptation: A Strong Replay-Free Baseline for  Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panos%2C+A">Aristeidis Panos</a>, 
<a href="/search/cs?searchtype=author&query=Kobe%2C+Y">Yuriko Kobe</a>, 
<a href="/search/cs?searchtype=author&query=Reino%2C+D+O">Daniel Olmeda Reino</a>, 
<a href="/search/cs?searchtype=author&query=Aljundi%2C+R">Rahaf Aljundi</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+R+E">Richard E. Turner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ICCV 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13959" title="Abstract">arXiv:2303.13959</a> (replaced) [<a href="/pdf/2303.13959" title="Download PDF">pdf</a>, <a href="/format/2303.13959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Stereo Geometry and BEV Representation with Reliable Mutual  Interaction for Semantic Scene Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yasheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhujin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dalong Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuanghui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunnan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenjun Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15954" title="Abstract">arXiv:2303.15954</a> (replaced) [<a href="/pdf/2303.15954" title="Download PDF">pdf</a>, <a href="/ps/2303.15954" title="Download PostScript">ps</a>, <a href="/format/2303.15954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TraffNet: Learning Causality of Traffic Generation for What-if  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Ming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qiang Ai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruimin Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Geqi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangfu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haibo Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01386" title="Abstract">arXiv:2304.01386</a> (replaced) [<a href="/pdf/2304.01386" title="Download PDF">pdf</a>, <a href="/format/2304.01386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attrition-Aware Adaptation for Multi-Agent Patrolling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goeckner%2C+A">Anthony Goeckner</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+E">Ermin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for review to IEEE Robotics &amp; Automation Letters. 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06686" title="Abstract">arXiv:2304.06686</a> (replaced) [<a href="/pdf/2304.06686" title="Download PDF">pdf</a>, <a href="/format/2304.06686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OKRidge: Scalable Optimal k-Sparse Ridge Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiachang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Rosen%2C+S">Sam Rosen</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Chudi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06815" title="Abstract">arXiv:2304.06815</a> (replaced) [<a href="/pdf/2304.06815" title="Download PDF">pdf</a>, <a href="/format/2304.06815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Semantic Augmentation of Language Model Prompts (for Code  Summarization)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+T">Toufique Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+K+S">Kunal Suresh Pai</a>, 
<a href="/search/cs?searchtype=author&query=Devanbu%2C+P">Premkumar Devanbu</a>, 
<a href="/search/cs?searchtype=author&query=Barr%2C+E+T">Earl T. Barr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at International Conference on Software Engineering (ICSE-2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07772" title="Abstract">arXiv:2304.07772</a> (replaced) [<a href="/pdf/2304.07772" title="Download PDF">pdf</a>, <a href="/format/2304.07772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Evaluation of Neural SPARQL Query Generation from  Natural Language Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diallo%2C+P+A+K+K">Papa Abdou Karim Karou Diallo</a>, 
<a href="/search/cs?searchtype=author&query=Reyd%2C+S">Samuel Reyd</a>, 
<a href="/search/cs?searchtype=author&query=Zouaq%2C+A">Amal Zouaq</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08172" title="Abstract">arXiv:2304.08172</a> (replaced) [<a href="/pdf/2304.08172" title="Download PDF">pdf</a>, <a href="/ps/2304.08172" title="Download PostScript">ps</a>, <a href="/format/2304.08172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pointwise convergence of Fourier series and deep neural network for the  indicator function of d-dimensional ball
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawasumi%2C+R">Ryota Kawasumi</a>, 
<a href="/search/cs?searchtype=author&query=Yoneda%2C+T">Tsuyoshi Yoneda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> When the version 2 was rejected (where I submitted it to an AI journal), I realized I needed to further clarify the key point, and also realized the field is rather Fourier analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09853" title="Abstract">arXiv:2304.09853</a> (replaced) [<a href="/pdf/2304.09853" title="Download PDF">pdf</a>, <a href="/format/2304.09853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging RL Theory and Practice with the Effective Horizon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laidlaw%2C+C">Cassidy Laidlaw</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+S">Stuart Russell</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A">Anca Dragan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13182" title="Abstract">arXiv:2304.13182</a> (replaced) [<a href="/pdf/2304.13182" title="Download PDF">pdf</a>, <a href="/format/2304.13182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Camera Visual-Inertial Simultaneous Localization and Mapping for  Autonomous Valet Parking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abate%2C+M">Marcus Abate</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+A">Ariel Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+X+I">Xue Iuan Wong</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wangdong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Littman%2C+R">Rotem Littman</a>, 
<a href="/search/cs?searchtype=author&query=Klinger%2C+M">Marc Klinger</a>, 
<a href="/search/cs?searchtype=author&query=Kuhnert%2C+L">Lars Kuhnert</a>, 
<a href="/search/cs?searchtype=author&query=Blue%2C+D">Douglas Blue</a>, 
<a href="/search/cs?searchtype=author&query=Carlone%2C+L">Luca Carlone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05614" title="Abstract">arXiv:2305.05614</a> (replaced) [<a href="/pdf/2305.05614" title="Download PDF">pdf</a>, <a href="/ps/2305.05614" title="Download PostScript">ps</a>, <a href="/format/2305.05614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bilingual analogical proportions via hedges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anti%C4%87%2C+C">Christian Anti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05826" title="Abstract">arXiv:2305.05826</a> (replaced) [<a href="/pdf/2305.05826" title="Download PDF">pdf</a>, <a href="/ps/2305.05826" title="Download PostScript">ps</a>, <a href="/format/2305.05826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Matrix Sparsifiers and Fast Deterministic Algorithms for  Linear Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+R">Rajarshi Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Dexter%2C+G">Gregory Dexter</a>, 
<a href="/search/cs?searchtype=author&query=Musco%2C+C">Cameron Musco</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+A">Archan Ray</a>, 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+S">Sushant Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Woodruff%2C+D+P">David P Woodruff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15795" title="Abstract">arXiv:2305.15795</a> (replaced) [<a href="/pdf/2305.15795" title="Download PDF">pdf</a>, <a href="/format/2305.15795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergency Response Person Localization and Vital Sign Estimation Using a  Semi-Autonomous Robot Mounted SFCW Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schroth%2C+C+A">Christian A. Schroth</a>, 
<a href="/search/eess?searchtype=author&query=Eckrich%2C+C">Christian Eckrich</a>, 
<a href="/search/eess?searchtype=author&query=Kakouche%2C+I">Ibrahim Kakouche</a>, 
<a href="/search/eess?searchtype=author&query=Fabian%2C+S">Stefan Fabian</a>, 
<a href="/search/eess?searchtype=author&query=von+Stryk%2C+O">Oskar von Stryk</a>, 
<a href="/search/eess?searchtype=author&query=Zoubir%2C+A+M">Abdelhak M. Zoubir</a>, 
<a href="/search/eess?searchtype=author&query=Muma%2C+M">Michael Muma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dataset availabe at <a href="https://doi.org/10.21227/4bzd-jm32">this https URL</a>, code available at <a href="https://github.com/schrchr/radar-vitals-estimation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16671" title="Abstract">arXiv:2305.16671</a> (replaced) [<a href="/pdf/2305.16671" title="Download PDF">pdf</a>, <a href="/ps/2305.16671" title="Download PostScript">ps</a>, <a href="/format/2305.16671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach for Maximizing Continuous DR-submodular Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pedramfar%2C+M">Mohammad Pedramfar</a>, 
<a href="/search/cs?searchtype=author&query=Quinn%2C+C+J">Christopher John Quinn</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19265" title="Abstract">arXiv:2305.19265</a> (replaced) [<a href="/pdf/2305.19265" title="Download PDF">pdf</a>, <a href="/format/2305.19265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic computation and uncertainty quantification with emerging  covariance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hengyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenlian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianfeng Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available in <a href="https://github.com/AwakerMhy/probabilistic-computing-mnn">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00917" title="Abstract">arXiv:2306.00917</a> (replaced) [<a href="/pdf/2306.00917" title="Download PDF">pdf</a>, <a href="/format/2306.00917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vocabulary-free Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Conti%2C+A">Alessandro Conti</a>, 
<a href="/search/cs?searchtype=author&query=Fini%2C+E">Enrico Fini</a>, 
<a href="/search/cs?searchtype=author&query=Mancini%2C+M">Massimiliano Mancini</a>, 
<a href="/search/cs?searchtype=author&query=Rota%2C+P">Paolo Rota</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS2023, 19 pages, 8 figures, code is available at <a href="https://github.com/altndrr/vic">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01393" title="Abstract">arXiv:2306.01393</a> (replaced) [<a href="/pdf/2306.01393" title="Download PDF">pdf</a>, <a href="/format/2306.01393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Importance of Frequency versus Compositionality for  Subword-based Tokenization in NMT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolleb%2C+B">Benoist Wolleb</a>, 
<a href="/search/cs?searchtype=author&query=Silvestri%2C+R">Romain Silvestri</a>, 
<a href="/search/cs?searchtype=author&query=Vernikos%2C+G">Giorgos Vernikos</a>, 
<a href="/search/cs?searchtype=author&query=Dolamic%2C+L">Ljiljana Dolamic</a>, 
<a href="/search/cs?searchtype=author&query=Popescu-Belis%2C+A">Andrei Popescu-Belis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EAMT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06251" title="Abstract">arXiv:2306.06251</a> (replaced) [<a href="/pdf/2306.06251" title="Download PDF">pdf</a>, <a href="/format/2306.06251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Principles for Model Generalization and Scalable AI Integration  in Radio Access Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soldati%2C+P">Pablo Soldati</a>, 
<a href="/search/cs?searchtype=author&query=Ghadimi%2C+E">Euhanna Ghadimi</a>, 
<a href="/search/cs?searchtype=author&query=Demirel%2C+B">Burak Demirel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gaigalas%2C+R">Raimundas Gaigalas</a>, 
<a href="/search/cs?searchtype=author&query=Sintorn%2C+M">Mathias Sintorn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06734" title="Abstract">arXiv:2306.06734</a> (replaced) [<a href="/pdf/2306.06734" title="Download PDF">pdf</a>, <a href="/ps/2306.06734" title="Download PostScript">ps</a>, <a href="/format/2306.06734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLE-based Device Activity Detection under Rician Fading for Massive  Grant-free Access with Perfect and Imperfect Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Ying Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Feng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Lianghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jun Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09910" title="Abstract">arXiv:2306.09910</a> (replaced) [<a href="/pdf/2306.09910" title="Download PDF">pdf</a>, <a href="/format/2306.09910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LabelBench: A Comprehensive Framework for Benchmarking Adaptive  Label-Efficient Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Canal%2C+G">Gregory Canal</a>, 
<a href="/search/cs?searchtype=author&query=Mussmann%2C+S">Stephen Mussmann</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A+M">Arnav M. Das</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+G">Gantavya Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yinglun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Bilmes%2C+J">Jeffrey Bilmes</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon Shaolei Du</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kevin Jamieson</a>, 
<a href="/search/cs?searchtype=author&query=Nowak%2C+R+D">Robert D Nowak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11086" title="Abstract">arXiv:2306.11086</a> (replaced) [<a href="/pdf/2306.11086" title="Download PDF">pdf</a>, <a href="/format/2306.11086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing variational quantum state diagonalization using reinforcement  learning techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kundu%2C+A">Akash Kundu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bede%C5%82ek%2C+P">Przemys&#x142;aw Bede&#x142;ek</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ostaszewski%2C+M">Mateusz Ostaszewski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Danaci%2C+O">Onur Danaci</a>, 
<a href="/search/quant-ph?searchtype=author&query=Patel%2C+Y+J">Yash J. Patel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dunjko%2C+V">Vedran Dunjko</a>, 
<a href="/search/quant-ph?searchtype=author&query=Miszczak%2C+J+A">Jaros&#x142;aw A. Miszczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages with 13 figures, accepted in the New Journal of Physics, code available at <a href="https://github.com/iitis/RL_for_VQSD_ansatz_optimization">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15175" title="Abstract">arXiv:2306.15175</a> (replaced) [<a href="/pdf/2306.15175" title="Download PDF">pdf</a>, <a href="/ps/2306.15175" title="Download PostScript">ps</a>, <a href="/format/2306.15175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error analyses of Sinc-collocation methods for exponential decay initial  value problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Okayama%2C+T">Tomoaki Okayama</a>, 
<a href="/search/math?searchtype=author&query=Hara%2C+R">Ryota Hara</a>, 
<a href="/search/math?searchtype=author&query=Goto%2C+S">Shun&#x27;ichi Goto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywork: Ordinary differential equations, Initial value problems, Volterra integral equations, Sinc numerical methods, SE transformation, DE transformation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15632" title="Abstract">arXiv:2306.15632</a> (replaced) [<a href="/pdf/2306.15632" title="Download PDF">pdf</a>, <a href="/format/2306.15632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Algorithmic Alignment with Cocycles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dudzik%2C+A">Andrew Dudzik</a>, 
<a href="/search/cs?searchtype=author&query=von+Glehn%2C+T">Tamara von Glehn</a>, 
<a href="/search/cs?searchtype=author&query=Pascanu%2C+R">Razvan Pascanu</a>, 
<a href="/search/cs?searchtype=author&query=Veli%C4%8Dkovi%C4%87%2C+P">Petar Veli&#x10d;kovi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17010" title="Abstract">arXiv:2306.17010</a> (replaced) [<a href="/pdf/2306.17010" title="Download PDF">pdf</a>, <a href="/format/2306.17010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human  Motion Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+F">Fangqiang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peijun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C+X">Chris Xiaoxuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01163" title="Abstract">arXiv:2307.01163</a> (replaced) [<a href="/pdf/2307.01163" title="Download PDF">pdf</a>, <a href="/format/2307.01163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Language Plasticity via Pretraining with Active Forgetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yihong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Marchisio%2C+K">Kelly Marchisio</a>, 
<a href="/search/cs?searchtype=author&query=Raileanu%2C+R">Roberta Raileanu</a>, 
<a href="/search/cs?searchtype=author&query=Adelani%2C+D+I">David Ifeoluwa Adelani</a>, 
<a href="/search/cs?searchtype=author&query=Stenetorp%2C+P">Pontus Stenetorp</a>, 
<a href="/search/cs?searchtype=author&query=Riedel%2C+S">Sebastian Riedel</a>, 
<a href="/search/cs?searchtype=author&query=Artetxe%2C+M">Mikel Artetxe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Final Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01838" title="Abstract">arXiv:2307.01838</a> (replaced) [<a href="/pdf/2307.01838" title="Download PDF">pdf</a>, <a href="/format/2307.01838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EdgeFace: Efficient Face Recognition Model for Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=George%2C+A">Anjith George</a>, 
<a href="/search/cs?searchtype=author&query=Ecabert%2C+C">Christophe Ecabert</a>, 
<a href="/search/cs?searchtype=author&query=Shahreza%2C+H+O">Hatef Otroshi Shahreza</a>, 
<a href="/search/cs?searchtype=author&query=Kotwal%2C+K">Ketan Kotwal</a>, 
<a href="/search/cs?searchtype=author&query=Marcel%2C+S">Sebastien Marcel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, Accepted for publication in IEEE Transactions on Biometrics, Behavior, and Identity Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05065" title="Abstract">arXiv:2307.05065</a> (replaced) [<a href="/pdf/2307.05065" title="Download PDF">pdf</a>, <a href="/format/2307.05065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metatickles and Death in Damascus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Saira Khan</a> (University of California, Irvine)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a revision of a paper with the same title, published in EPTCS 379, 2023, pp. 359-378, <a href="/abs/2307.04005">arXiv:2307.04005v1</a>. Typing errors in the formal presentation of Huttegger's independence dynamics have been corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06244" title="Abstract">arXiv:2307.06244</a> (replaced) [<a href="/pdf/2307.06244" title="Download PDF">pdf</a>, <a href="/format/2307.06244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models for Multi-target Adversarial Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Sean Ye</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+M">Manisha Natarajan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zixuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gombolay%2C+M">Matthew Gombolay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06857" title="Abstract">arXiv:2307.06857</a> (replaced) [<a href="/pdf/2307.06857" title="Download PDF">pdf</a>, <a href="/format/2307.06857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight reranking for language model generations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Siddhartha Jain</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaofei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Deoras%2C+A">Anoop Deoras</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+B">Bing Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07596" title="Abstract">arXiv:2307.07596</a> (replaced) [<a href="/pdf/2307.07596" title="Download PDF">pdf</a>, <a href="/ps/2307.07596" title="Download PostScript">ps</a>, <a href="/format/2307.07596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal approximation of stochastic evolution equations with irregular  nonlinearities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Klioba%2C+K">Katharina Klioba</a>, 
<a href="/search/math?searchtype=author&query=Veraar%2C+M">Mark Veraar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, this version: minor changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Functional Analysis (math.FA); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10730" title="Abstract">arXiv:2307.10730</a> (replaced) [<a href="/pdf/2307.10730" title="Download PDF">pdf</a>, <a href="/format/2307.10730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Port Selection Based Channel Acquisition for FDD Cell-Free Massive  MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+P">Pengguang Du</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Minjie Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Yindi Jing</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures. The paper has been accepted by IEEE TRANSACTIONS ON COMMUNICATIONS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10870" title="Abstract">arXiv:2307.10870</a> (replaced) [<a href="/pdf/2307.10870" title="Download PDF">pdf</a>, <a href="/ps/2307.10870" title="Download PostScript">ps</a>, <a href="/format/2307.10870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Meta-Learning Can Guarantee Faster Rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Meunier%2C+D">Dimitri Meunier</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+Z">Zhu Li</a>, 
<a href="/search/stat?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>, 
<a href="/search/stat?searchtype=author&query=Kpotufe%2C+S">Samory Kpotufe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11993" title="Abstract">arXiv:2307.11993</a> (replaced) [<a href="/pdf/2307.11993" title="Download PDF">pdf</a>, <a href="/format/2307.11993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifiable Sustainability in Data Centers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+S+R">Syed Rafiul Hussain</a>, 
<a href="/search/cs?searchtype=author&query=McDaniel%2C+P">Patrick McDaniel</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+A">Anshul Gandhi</a>, 
<a href="/search/cs?searchtype=author&query=Ghose%2C+K">Kanad Ghose</a>, 
<a href="/search/cs?searchtype=author&query=Gopalan%2C+K">Kartik Gopalan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongyoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+D">Yu David Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+S">Shuai Mu</a>, 
<a href="/search/cs?searchtype=author&query=Zadok%2C+E">Erez Zadok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY); Distributed, Parallel, and Cluster Computing (cs.DC); Operating Systems (cs.OS); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12613" title="Abstract">arXiv:2307.12613</a> (replaced) [<a href="/pdf/2307.12613" title="Download PDF">pdf</a>, <a href="/format/2307.12613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning-free one-bit covariance estimation using data-driven dithering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dirksen%2C+S">Sjoerd Dirksen</a>, 
<a href="/search/math?searchtype=author&query=Maly%2C+J">Johannes Maly</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13713" title="Abstract">arXiv:2307.13713</a> (replaced) [<a href="/pdf/2307.13713" title="Download PDF">pdf</a>, <a href="/format/2307.13713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase Transitions of Diversity in Stochastic Block Model Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%A2nzei%2C+S">Simina Br&#xe2;nzei</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Nithish Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Ranade%2C+G">Gireeja Ranade</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 figures. In Proceedings of Allerton 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computer Science and Game Theory (cs.GT); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14288" title="Abstract">arXiv:2307.14288</a> (replaced) [<a href="/pdf/2307.14288" title="Download PDF">pdf</a>, <a href="/format/2307.14288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> US \&amp; MRI Image Fusion Based on Markerless Skin Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paccini%2C+M">Martina Paccini</a>, 
<a href="/search/cs?searchtype=author&query=Paschina%2C+G">Giacomo Paschina</a>, 
<a href="/search/cs?searchtype=author&query=De+Beni%2C+S">Stefano De Beni</a>, 
<a href="/search/cs?searchtype=author&query=Patan%C3%A8%2C+G">Giuseppe Patan&#xe8;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00244" title="Abstract">arXiv:2308.00244</a> (replaced) [<a href="/pdf/2308.00244" title="Download PDF">pdf</a>, <a href="/format/2308.00244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Screening Curve Method for Economic Analysis of Household Solar Energy  Self-Consumption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hoshino%2C+H">Hikaru Hoshino</a>, 
<a href="/search/eess?searchtype=author&query=Irie%2C+Y">Yosuke Irie</a>, 
<a href="/search/eess?searchtype=author&query=Furutani%2C+E">Eiko Furutani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03083" title="Abstract">arXiv:2308.03083</a> (replaced) [<a href="/pdf/2308.03083" title="Download PDF">pdf</a>, <a href="/format/2308.03083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Group Choices from Group Profiles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emamgholizadeh%2C+H">Hanif Emamgholizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Delic%2C+A">Amra Delic</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+F">Francesco Ricci</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Trans. Interact. Intell. Syst. (January 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07593" title="Abstract">arXiv:2308.07593</a> (replaced) [<a href="/pdf/2308.07593" title="Download PDF">pdf</a>, <a href="/format/2308.07593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AKVSR: Audio Knowledge Empowered Visual Speech Recognition by  Compressing Audio Knowledge of a Pretrained Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J+H">Jeong Hun Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongsoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+H">Dae Hoe Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Multimedia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09311" title="Abstract">arXiv:2308.09311</a> (replaced) [<a href="/pdf/2308.09311" title="Download PDF">pdf</a>, <a href="/format/2308.09311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lip Reading for Low-resource Languages by Learning and Combining General  Speech Knowledge and Language-specific Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J+H">Jeong Hun Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongsoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09932" title="Abstract">arXiv:2308.09932</a> (replaced) [<a href="/pdf/2308.09932" title="Download PDF">pdf</a>, <a href="/format/2308.09932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Memorization in Code Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhipeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jieke Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongsun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">DongGyun Han</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, Camera-Ready Version that will appear in ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10364" title="Abstract">arXiv:2308.10364</a> (replaced) [<a href="/pdf/2308.10364" title="Download PDF">pdf</a>, <a href="/format/2308.10364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SE(3) Equivariant Augmented Coupling Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Midgley%2C+L+I">Laurence I. Midgley</a>, 
<a href="/search/cs?searchtype=author&query=Stimper%2C+V">Vincent Stimper</a>, 
<a href="/search/cs?searchtype=author&query=Antor%C3%A1n%2C+J">Javier Antor&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+E">Emile Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12604" title="Abstract">arXiv:2308.12604</a> (replaced) [<a href="/pdf/2308.12604" title="Download PDF">pdf</a>, <a href="/format/2308.12604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haibo Jin</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+H">Haoxuan Che</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15552" title="Abstract">arXiv:2308.15552</a> (replaced) [<a href="/pdf/2308.15552" title="Download PDF">pdf</a>, <a href="/ps/2308.15552" title="Download PostScript">ps</a>, <a href="/format/2308.15552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pure Exploration under Mediators&#x27; Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poiani%2C+R">Riccardo Poiani</a>, 
<a href="/search/cs?searchtype=author&query=Metelli%2C+A+M">Alberto Maria Metelli</a>, 
<a href="/search/cs?searchtype=author&query=Restelli%2C+M">Marcello Restelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04027" title="Abstract">arXiv:2309.04027</a> (replaced) [<a href="/pdf/2309.04027" title="Download PDF">pdf</a>, <a href="/format/2309.04027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIDE: Textual Identity Detection for Evaluating and Augmenting  Classification and Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klu%2C+E">Emmanuel Klu</a>, 
<a href="/search/cs?searchtype=author&query=Sethi%2C+S">Sameer Sethi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04076" title="Abstract">arXiv:2309.04076</a> (replaced) [<a href="/pdf/2309.04076" title="Download PDF">pdf</a>, <a href="/format/2309.04076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greening Large Language Models of Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jieke Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H+J">Hong Jin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junda He</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Software Engineering in Society Track of the 46th IEEE/ACM International Conference on Software Engineering (ICSE '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05499" title="Abstract">arXiv:2309.05499</a> (replaced) [<a href="/pdf/2309.05499" title="Download PDF">pdf</a>, <a href="/format/2309.05499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Co-salient Object Detection Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Haoke Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lv Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhiming Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaozi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07846" title="Abstract">arXiv:2309.07846</a> (replaced) [<a href="/pdf/2309.07846" title="Download PDF">pdf</a>, <a href="/format/2309.07846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MC-NeRF: Multi-Camera Neural Radiance Fields for Multi-Camera Image  Acquisition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Lutong Su</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Hao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yufeng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+M">Mengyin Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript is currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08535" title="Abstract">arXiv:2309.08535</a> (replaced) [<a href="/pdf/2309.08535" title="Download PDF">pdf</a>, <a href="/format/2309.08535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Speech Recognition for Languages with Limited Labeled Data using  Automatic Labels from Whisper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J+H">Jeong Hun Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13018" title="Abstract">arXiv:2309.13018</a> (replaced) [<a href="/pdf/2309.13018" title="Download PDF">pdf</a>, <a href="/format/2309.13018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient  Pruning of A Multilingual ASR Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+J">Jiamin Xie</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jinxi Guo</a>, 
<a href="/search/eess?searchtype=author&query=Tjandra%2C+A">Andros Tjandra</a>, 
<a href="/search/eess?searchtype=author&query=Shangguan%2C+Y">Yuan Shangguan</a>, 
<a href="/search/eess?searchtype=author&query=Sari%2C+L">Leda Sari</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Chunyang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+J">Junteng Jia</a>, 
<a href="/search/eess?searchtype=author&query=Mahadeokar%2C+J">Jay Mahadeokar</a>, 
<a href="/search/eess?searchtype=author&query=Kalinli%2C+O">Ozlem Kalinli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13745" title="Abstract">arXiv:2309.13745</a> (replaced) [<a href="/pdf/2309.13745" title="Download PDF">pdf</a>, <a href="/format/2309.13745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of Computer Vision Techniques in Robotized Wire Harness  Assembly: Current State and Future Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Salunkhe%2C+O">Omkar Salunkhe</a>, 
<a href="/search/cs?searchtype=author&query=Quadrini%2C+W">Walter Quadrini</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4mkull%2C+D">Dan L&#xe4;mkull</a>, 
<a href="/search/cs?searchtype=author&query=Ore%2C+F">Fredrik Ore</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+B">Bj&#xf6;rn Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Stahre%2C+J">Johan Stahre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 56th CIRP Conference on Manufacturing Systems (CIRP CMS 2023), Cape Town, South Africa, 24-26 October 2023. Published in Procedia CIRP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14062" title="Abstract">arXiv:2309.14062</a> (replaced) [<a href="/pdf/2309.14062" title="Download PDF">pdf</a>, <a href="/format/2309.14062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FeCAM: Exploiting the Heterogeneity of Class Distributions in  Exemplar-Free Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+D">Dipam Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Twardowski%2C+B">Bart&#x142;omiej Twardowski</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Weijer%2C+J">Joost van de Weijer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14129" title="Abstract">arXiv:2309.14129</a> (replaced) [<a href="/pdf/2309.14129" title="Download PDF">pdf</a>, <a href="/format/2309.14129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speaker anonymization using neural audio codec language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Panariello%2C+M">Michele Panariello</a>, 
<a href="/search/eess?searchtype=author&query=Nespoli%2C+F">Francesco Nespoli</a>, 
<a href="/search/eess?searchtype=author&query=Todisco%2C+M">Massimiliano Todisco</a>, 
<a href="/search/eess?searchtype=author&query=Evans%2C+N">Nicholas Evans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14521" title="Abstract">arXiv:2309.14521</a> (replaced) [<a href="/pdf/2309.14521" title="Download PDF">pdf</a>, <a href="/format/2309.14521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoLACE: Improving Low-Complexity Speech Codec Enhancement Through  Adaptive Temporal Shaping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=B%C3%BCthe%2C+J">Jan B&#xfc;the</a>, 
<a href="/search/eess?searchtype=author&query=Mustafa%2C+A">Ahmed Mustafa</a>, 
<a href="/search/eess?searchtype=author&query=Valin%2C+J">Jean-Marc Valin</a>, 
<a href="/search/eess?searchtype=author&query=Helwani%2C+K">Karim Helwani</a>, 
<a href="/search/eess?searchtype=author&query=Goodwin%2C+M+M">Michael M. Goodwin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> final version, accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16995" title="Abstract">arXiv:2309.16995</a> (replaced) [<a href="/pdf/2309.16995" title="Download PDF">pdf</a>, <a href="/ps/2309.16995" title="Download PostScript">ps</a>, <a href="/format/2309.16995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Max Weight Independent Set in sparse graphs with no long claws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abrishami%2C+T">Tara Abrishami</a>, 
<a href="/search/cs?searchtype=author&query=Chudnovsky%2C+M">Maria Chudnovsky</a>, 
<a href="/search/cs?searchtype=author&query=Dibek%2C+C">Cemil Dibek</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Marcin Pilipczuk</a>, 
<a href="/search/cs?searchtype=author&query=Rz%C4%85%C5%BCewski%2C+P">Pawe&#x142; Rz&#x105;&#x17c;ewski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2107.05434">arXiv:2107.05434</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00177" title="Abstract">arXiv:2310.00177</a> (replaced) [<a href="/pdf/2310.00177" title="Download PDF">pdf</a>, <a href="/format/2310.00177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Neural-preconditioned Poisson Solver for Mixed Dirichlet and Neumann  Boundary Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lan%2C+K+W">Kai Weixian Lan</a>, 
<a href="/search/math?searchtype=author&query=Gueidon%2C+E">Elias Gueidon</a>, 
<a href="/search/math?searchtype=author&query=Kaneda%2C+A">Ayano Kaneda</a>, 
<a href="/search/math?searchtype=author&query=Panetta%2C+J">Julian Panetta</a>, 
<a href="/search/math?searchtype=author&query=Teran%2C+J">Joseph Teran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02772" title="Abstract">arXiv:2310.02772</a> (replaced) [<a href="/pdf/2310.02772" title="Download PDF">pdf</a>, <a href="/format/2310.02772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spike Accumulation Forwarding for Effective Training of Spiking Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saiin%2C+R">Ryuji Saiin</a>, 
<a href="/search/cs?searchtype=author&query=Shirakawa%2C+T">Tomoya Shirakawa</a>, 
<a href="/search/cs?searchtype=author&query=Yoshihara%2C+S">Sota Yoshihara</a>, 
<a href="/search/cs?searchtype=author&query=Sawada%2C+Y">Yoshihide Sawada</a>, 
<a href="/search/cs?searchtype=author&query=Kusumoto%2C+H">Hiroyuki Kusumoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, Appendix:8 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05392" title="Abstract">arXiv:2310.05392</a> (replaced) [<a href="/pdf/2310.05392" title="Download PDF">pdf</a>, <a href="/format/2310.05392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Full-Convolutional Siamese Tracker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunfeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xueyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuoyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ye Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07987" title="Abstract">arXiv:2310.07987</a> (replaced) [<a href="/pdf/2310.07987" title="Download PDF">pdf</a>, <a href="/format/2310.07987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Forward Relaying: A Novel Framework Towards 6G Cooperative  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wensheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuna Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lixin Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>, 
<a href="/search/cs?searchtype=author&query=Matsumoto%2C+T">Tad Matsumoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08036" title="Abstract">arXiv:2310.08036</a> (replaced) [<a href="/pdf/2310.08036" title="Download PDF">pdf</a>, <a href="/format/2310.08036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZEST: Attention-based Zero-Shot Learning for Unseen IoT Device  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Binghui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gysel%2C+P">Philipp Gysel</a>, 
<a href="/search/cs?searchtype=author&query=Divakaran%2C+D+M">Dinil Mon Divakaran</a>, 
<a href="/search/cs?searchtype=author&query=Gurusamy%2C+M">Mohan Gurusamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09874" title="Abstract">arXiv:2310.09874</a> (replaced) [<a href="/pdf/2310.09874" title="Download PDF">pdf</a>, <a href="/format/2310.09874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TF-DCon: Leveraging Large Language Models (LLMs) to Empower  Training-Free Dataset Condensation for Content-Based Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiahao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qijiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hengchang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wenqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengcai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Ke Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12489" title="Abstract">arXiv:2310.12489</a> (replaced) [<a href="/pdf/2310.12489" title="Download PDF">pdf</a>, <a href="/format/2310.12489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedAI Dialog Corpus (MEDIC): Zero-Shot Classification of Doctor and AI  Responses in Health Consultations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ojo%2C+O+E">Olumide E. Ojo</a>, 
<a href="/search/cs?searchtype=author&query=Adebanji%2C+O+O">Olaronke O. Adebanji</a>, 
<a href="/search/cs?searchtype=author&query=Gelbukh%2C+A">Alexander Gelbukh</a>, 
<a href="/search/cs?searchtype=author&query=Calvo%2C+H">Hiram Calvo</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+A">Anna Feldman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13459" title="Abstract">arXiv:2310.13459</a> (replaced) [<a href="/pdf/2310.13459" title="Download PDF">pdf</a>, <a href="/format/2310.13459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Nonconvex-Nonconcave Training via Linear Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pethick%2C+T">Thomas Pethick</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wanyun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cevher%2C+V">Volkan Cevher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14403" title="Abstract">arXiv:2310.14403</a> (replaced) [<a href="/pdf/2310.14403" title="Download PDF">pdf</a>, <a href="/format/2310.14403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> O3D: Offline Data-driven Discovery and Distillation for Sequential  Decision-Making with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yuchen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanchao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengda Xu</a>, 
<a href="/search/cs?searchtype=author&query=Madhushani%2C+U">Udari Madhushani</a>, 
<a href="/search/cs?searchtype=author&query=Vann%2C+J">Jared Vann</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+D">Deepeka Garg</a>, 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+S">Sumitra Ganesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16185" title="Abstract">arXiv:2310.16185</a> (replaced) [<a href="/pdf/2310.16185" title="Download PDF">pdf</a>, <a href="/format/2310.16185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing Information on Smartwatch Faces: A Review and Design Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+A">Alaul Islam</a> (1), 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tingying He</a> (1), 
<a href="/search/cs?searchtype=author&query=Bezerianos%2C+A">Anastasia Bezerianos</a> (1), 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Bongshin Lee</a> (2), 
<a href="/search/cs?searchtype=author&query=Blascheck%2C+T">Tanja Blascheck</a> (3), 
<a href="/search/cs?searchtype=author&query=Isenberg%2C+P">Petra Isenberg</a> (1) ((1) Universit&#xe9; Paris-Saclay, CNRS, Inria, France, (2) Microsoft Research, Redmond, WA, US, (3) University of Stuttgart, Germany)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18152" title="Abstract">arXiv:2310.18152</a> (replaced) [<a href="/pdf/2310.18152" title="Download PDF">pdf</a>, <a href="/format/2310.18152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Representation Learning with Large Language Models for  Text-Attributed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yijian Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01797" title="Abstract">arXiv:2311.01797</a> (replaced) [<a href="/pdf/2311.01797" title="Download PDF">pdf</a>, <a href="/format/2311.01797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Generalization Properties of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Puheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huishuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01811" title="Abstract">arXiv:2311.01811</a> (replaced) [<a href="/pdf/2311.01811" title="Download PDF">pdf</a>, <a href="/format/2311.01811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffDub: Person-generic Visual Dubbing Using Inpainting Renderer with  Diffusion Auto-encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shuai Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feilong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03865" title="Abstract">arXiv:2311.03865</a> (replaced) [<a href="/pdf/2311.03865" title="Download PDF">pdf</a>, <a href="/format/2311.03865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Fairness Meets Privacy: Exploring Privacy Threats in Fair Binary  Classifiers through Membership Inference Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Huan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guangsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tianqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wanlei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07946" title="Abstract">arXiv:2311.07946</a> (replaced) [<a href="/pdf/2311.07946" title="Download PDF">pdf</a>, <a href="/format/2311.07946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Adversarial Node Placement in Decentralized Federated  Learning Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piaseczny%2C+A">Adam Piaseczny</a>, 
<a href="/search/cs?searchtype=author&query=Ruzomberka%2C+E">Eric Ruzomberka</a>, 
<a href="/search/cs?searchtype=author&query=Parasnis%2C+R">Rohit Parasnis</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICC 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08640" title="Abstract">arXiv:2311.08640</a> (replaced) [<a href="/pdf/2311.08640" title="Download PDF">pdf</a>, <a href="/format/2311.08640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multistage Collaborative Knowledge Distillation from Large Language  Models for Semi-Supervised Sequence Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiachen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenlong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Drozdov%2C+A">Andrew Drozdov</a>, 
<a href="/search/cs?searchtype=author&query=Rozonoyer%2C+B">Benjamin Rozonoyer</a>, 
<a href="/search/cs?searchtype=author&query=Sultan%2C+M+A">Md Arafat Sultan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jay-Yoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Iyyer%2C+M">Mohit Iyyer</a>, 
<a href="/search/cs?searchtype=author&query=McCallum%2C+A">Andrew McCallum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15643" title="Abstract">arXiv:2311.15643</a> (replaced) [<a href="/pdf/2311.15643" title="Download PDF">pdf</a>, <a href="/format/2311.15643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Monocular Re-Localization: From the Perspective of Scene Map  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+J">Jinyu Miao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+T">Tuopu Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+P">Peijing Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qian Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhongyang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhihua Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diange Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 10 tables, 16 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17492" title="Abstract">arXiv:2311.17492</a> (replaced) [<a href="/pdf/2311.17492" title="Download PDF">pdf</a>, <a href="/format/2311.17492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mergen: The First Manchu-Korean Machine Translation Model Trained on  Augmented Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Jean Seo</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+S">Sungjoo Byun</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Minha Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangah Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> emnlp2023/mrl2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18787" title="Abstract">arXiv:2311.18787</a> (replaced) [<a href="/pdf/2311.18787" title="Download PDF">pdf</a>, <a href="/format/2311.18787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Federated Optimization over Semi-Decentralized  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Y">Yuejie Chi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01655" title="Abstract">arXiv:2312.01655</a> (replaced) [<a href="/pdf/2312.01655" title="Download PDF">pdf</a>, <a href="/format/2312.01655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Polar Metric Learning: Efficient Classically Learned Quantum  Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sharma%2C+V">Vinayak Sharma</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shrivastava%2C+A">Aviral Shrivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01988" title="Abstract">arXiv:2312.01988</a> (replaced) [<a href="/pdf/2312.01988" title="Download PDF">pdf</a>, <a href="/format/2312.01988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geranos: a Novel Tilted-Rotors Aerial Robot for the Transportation of  Poles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorlo%2C+N">Nicolas Gorlo</a>, 
<a href="/search/cs?searchtype=author&query=Bamert%2C+S">Samuel Bamert</a>, 
<a href="/search/cs?searchtype=author&query=Cathomen%2C+R">Rafael Cathomen</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4ppeli%2C+G">Gabriel K&#xe4;ppeli</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M">Mario M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Reinhart%2C+T">Tim Reinhart</a>, 
<a href="/search/cs?searchtype=author&query=Stadler%2C+H">Henriette Stadler</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cuniato%2C+E">Eugenio Cuniato</a>, 
<a href="/search/cs?searchtype=author&query=Tognon%2C+M">Marco Tognon</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at IEEE Robotics and Automation Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03209" title="Abstract">arXiv:2312.03209</a> (replaced) [<a href="/pdf/2312.03209" title="Download PDF">pdf</a>, <a href="/format/2312.03209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cache Me if You Can: Accelerating Diffusion Models through Block Caching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wimbauer%2C+F">Felix Wimbauer</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Schoenfeld%2C+E">Edgar Schoenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xiaoliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Ji Hou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zijian He</a>, 
<a href="/search/cs?searchtype=author&query=Sanakoyeu%2C+A">Artsiom Sanakoyeu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+S">Sam Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Kohler%2C+J">Jonas Kohler</a>, 
<a href="/search/cs?searchtype=author&query=Rupprecht%2C+C">Christian Rupprecht</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jialiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://fwmb.github.io/blockcaching/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03393" title="Abstract">arXiv:2312.03393</a> (replaced) [<a href="/pdf/2312.03393" title="Download PDF">pdf</a>, <a href="/format/2312.03393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PS$^3$: Precise Patch Presence Test based on Semantic Symbolic Signature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Q">Qi Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanping Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICSE 2024; Camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05398" title="Abstract">arXiv:2312.05398</a> (replaced) [<a href="/pdf/2312.05398" title="Download PDF">pdf</a>, <a href="/ps/2312.05398" title="Download PostScript">ps</a>, <a href="/format/2312.05398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Network Layer for Communication Systems with Artificial  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thorsager%2C+M">Mathias Thorsager</a>, 
<a href="/search/cs?searchtype=author&query=Leyva-Mayorga%2C+I">Israel Leyva-Mayorga</a>, 
<a href="/search/cs?searchtype=author&query=Soret%2C+B">Beatriz Soret</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for poublication in IEEE Networking Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05530" title="Abstract">arXiv:2312.05530</a> (replaced) [<a href="/pdf/2312.05530" title="Download PDF">pdf</a>, <a href="/format/2312.05530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Smart Healthcare: Challenges and Opportunities in IoT and ML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saifuzzaman%2C+M">Munshi Saifuzzaman</a>, 
<a href="/search/cs?searchtype=author&query=Ananna%2C+T+N">Tajkia Nuri Ananna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 3 tables, 2 figures, chapter 10 revised version of "IoT and ML for Information Management: A Smart Healthcare Perspective" under "Springer Studies in Computational Challenge" series
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06131" title="Abstract">arXiv:2312.06131</a> (replaced) [<a href="/pdf/2312.06131" title="Download PDF">pdf</a>, <a href="/format/2312.06131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ML-based Modeling to Predict I/O Performance on Different Storage  Sub-systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sivaraman%2C+P">Pranav Sivaraman</a>, 
<a href="/search/cs?searchtype=author&query=Devarajan%2C+H">Hariharan Devarajan</a>, 
<a href="/search/cs?searchtype=author&query=Mohror%2C+K">Kathryn Mohror</a>, 
<a href="/search/cs?searchtype=author&query=Bhatele%2C+A">Abhinav Bhatele</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06689" title="Abstract">arXiv:2312.06689</a> (replaced) [<a href="/pdf/2312.06689" title="Download PDF">pdf</a>, <a href="/format/2312.06689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introduction to IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ananna%2C+T+N">Tajkia Nuri Ananna</a>, 
<a href="/search/cs?searchtype=author&query=Saifuzzaman%2C+M">Munshi Saifuzzaman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 7 figures, 8 tables, chapter 1 revised version of "IoT and ML for Information Management: A Smart Healthcare Perspective" under the Springer Studies in Computational Intelligence series
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07991" title="Abstract">arXiv:2312.07991</a> (replaced) [<a href="/pdf/2312.07991" title="Download PDF">pdf</a>, <a href="/format/2312.07991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating the Global Aggregation of Local Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mor%2C+A">Alon Mor</a>, 
<a href="/search/cs?searchtype=author&query=Belinkov%2C+Y">Yonatan Belinkov</a>, 
<a href="/search/cs?searchtype=author&query=Kimelfeld%2C+B">Benny Kimelfeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08856" title="Abstract">arXiv:2312.08856</a> (replaced) [<a href="/pdf/2312.08856" title="Download PDF">pdf</a>, <a href="/format/2312.08856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Guided Adaptation for Code-Switching Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aditya%2C+B">Bobbi Aditya</a>, 
<a href="/search/eess?searchtype=author&query=Rohmatillah%2C+M">Mahdin Rohmatillah</a>, 
<a href="/search/eess?searchtype=author&query=Tai%2C+L">Liang-Hsuan Tai</a>, 
<a href="/search/eess?searchtype=author&query=Chien%2C+J">Jen-Tzung Chien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10394" title="Abstract">arXiv:2312.10394</a> (replaced) [<a href="/pdf/2312.10394" title="Download PDF">pdf</a>, <a href="/ps/2312.10394" title="Download PostScript">ps</a>, <a href="/format/2312.10394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Far-field Beam Training Be Deployed for Cross-field Beam Alignment  in Terahertz UM-MIMO Communications?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chong Han</a>, 
<a href="/search/cs?searchtype=author&query=Bj%C3%B6rnson%2C+E">Emil Bj&#xf6;rnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13636" title="Abstract">arXiv:2312.13636</a> (replaced) [<a href="/pdf/2312.13636" title="Download PDF">pdf</a>, <a href="/ps/2312.13636" title="Download PostScript">ps</a>, <a href="/format/2312.13636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Optimization Algorithms in Operations Research: Methods,  Applications, and Implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klug%2C+F">Florian Klug</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13700" title="Abstract">arXiv:2312.13700</a> (replaced) [<a href="/pdf/2312.13700" title="Download PDF">pdf</a>, <a href="/ps/2312.13700" title="Download PostScript">ps</a>, <a href="/format/2312.13700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplayer boycotts in convex games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fokkink%2C+R">Robbert Fokkink</a>, 
<a href="/search/cs?searchtype=author&query=de+Munnik%2C+H">Hans de Munnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14276" title="Abstract">arXiv:2312.14276</a> (replaced) [<a href="/pdf/2312.14276" title="Download PDF">pdf</a>, <a href="/ps/2312.14276" title="Download PostScript">ps</a>, <a href="/format/2312.14276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Networks and Finite Elements of Any Order on Arbitrary  Dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=He%2C+J">Juncai He</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+J">Jinchao Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14430" title="Abstract">arXiv:2312.14430</a> (replaced) [<a href="/html/2312.14430" title="Download HTML">html</a>, <a href="/format/2312.14430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Higashinaka%2C+R">Ryuichiro Higashinaka</a>, 
<a href="/search/cs?searchtype=author&query=Minato%2C+T">Takashi Minato</a>, 
<a href="/search/cs?searchtype=author&query=Nishizaki%2C+H">Hiromitsu Nishizaki</a>, 
<a href="/search/cs?searchtype=author&query=Nagai%2C+T">Takayuki Nagai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14890" title="Abstract">arXiv:2312.14890</a> (replaced) [<a href="/pdf/2312.14890" title="Download PDF">pdf</a>, <a href="/format/2312.14890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language  Models via Complexity Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lizhou Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haoyang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Complexity (cs.CC); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16015" title="Abstract">arXiv:2312.16015</a> (replaced) [<a href="/pdf/2312.16015" title="Download PDF">pdf</a>, <a href="/ps/2312.16015" title="Download PostScript">ps</a>, <a href="/format/2312.16015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Evaluation Techniques for Recommendation  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jadon%2C+A">Aryan Jadon</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+A">Avinash Patil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17279" title="Abstract">arXiv:2312.17279</a> (replaced) [<a href="/pdf/2312.17279" title="Download PDF">pdf</a>, <a href="/format/2312.17279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stateful Conformer with Cache-based Inference for Streaming Automatic  Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noroozi%2C+V">Vahid Noroozi</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+S">Somshubra Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ankur Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Balam%2C+J">Jagadeesh Balam</a>, 
<a href="/search/cs?searchtype=author&query=Ginsburg%2C+B">Boris Ginsburg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Shorter version accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17431" title="Abstract">arXiv:2312.17431</a> (replaced) [<a href="/pdf/2312.17431" title="Download PDF">pdf</a>, <a href="/format/2312.17431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVPatch: More Vivid Patch for Adversarial Camouflaged Attacks on Object  Detectors in the Physical World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ju Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiaosheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+L">Liwei Geng</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Shuchang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wenquan Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17663" title="Abstract">arXiv:2312.17663</a> (replaced) [<a href="/pdf/2312.17663" title="Download PDF">pdf</a>, <a href="/format/2312.17663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape-IoU: More Accurate Metric considering Bounding Box Shape and Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuaijie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00280" title="Abstract">arXiv:2401.00280</a> (replaced) [<a href="/pdf/2401.00280" title="Download PDF">pdf</a>, <a href="/format/2401.00280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing TTP Analysis: Harnessing the Power of Encoder-Only and  Decoder-Only Language Models with Retrieval Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fayyazi%2C+R">Reza Fayyazi</a>, 
<a href="/search/cs?searchtype=author&query=Taghdimi%2C+R">Rozhina Taghdimi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S+J">Shanchieh Jay Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01055" title="Abstract">arXiv:2401.01055</a> (replaced) [<a href="/pdf/2401.01055" title="Download PDF">pdf</a>, <a href="/format/2401.01055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaMA Beyond English: An Empirical Study on Language Capability Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Luhui Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01623" title="Abstract">arXiv:2401.01623</a> (replaced) [<a href="/pdf/2401.01623" title="Download PDF">pdf</a>, <a href="/format/2401.01623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can AI Be as Creative as Humans?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Mozer%2C+M">Michael Mozer</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+A">Anirudh Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Lamb%2C+A">Alex Lamb</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W+J">Weijie J Su</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M+Q">Michael Qizhe Xie</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+H">Hannah Brown</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper examines AI's creativity, introducing Relative and Statistical Creativity for theoretical and practical analysis, along with practical training guidelines. Project Page: ai-relative-creativity.github.io
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02300" title="Abstract">arXiv:2401.02300</a> (replaced) [<a href="/pdf/2401.02300" title="Download PDF">pdf</a>, <a href="/format/2401.02300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Physics Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%81o%C5%9B%2C+M">Marcin &#x141;o&#x15b;</a>, 
<a href="/search/cs?searchtype=author&query=Paszy%C5%84ski%2C+M">Maciej Paszy&#x144;ski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03223" title="Abstract">arXiv:2401.03223</a> (replaced) [<a href="/pdf/2401.03223" title="Download PDF">pdf</a>, <a href="/ps/2401.03223" title="Download PostScript">ps</a>, <a href="/format/2401.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An intelligent sociotechnical systems (iSTS) framework: Toward a  sociotechnically-based hierarchical human-centered AI approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zaifeng Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04003" title="Abstract">arXiv:2401.04003</a> (replaced) [<a href="/pdf/2401.04003" title="Download PDF">pdf</a>, <a href="/format/2401.04003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Task Allocation and Planning for Multi-Robots under  Hierarchical Temporal Logic Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xusheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04531" title="Abstract">arXiv:2401.04531</a> (replaced) [<a href="/pdf/2401.04531" title="Download PDF">pdf</a>, <a href="/format/2401.04531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MERA: A Comprehensive LLM Evaluation in Russian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fenogenova%2C+A">Alena Fenogenova</a>, 
<a href="/search/cs?searchtype=author&query=Chervyakov%2C+A">Artem Chervyakov</a>, 
<a href="/search/cs?searchtype=author&query=Martynov%2C+N">Nikita Martynov</a>, 
<a href="/search/cs?searchtype=author&query=Kozlova%2C+A">Anastasia Kozlova</a>, 
<a href="/search/cs?searchtype=author&query=Tikhonova%2C+M">Maria Tikhonova</a>, 
<a href="/search/cs?searchtype=author&query=Akhmetgareeva%2C+A">Albina Akhmetgareeva</a>, 
<a href="/search/cs?searchtype=author&query=Emelyanov%2C+A">Anton Emelyanov</a>, 
<a href="/search/cs?searchtype=author&query=Shevelev%2C+D">Denis Shevelev</a>, 
<a href="/search/cs?searchtype=author&query=Lebedev%2C+P">Pavel Lebedev</a>, 
<a href="/search/cs?searchtype=author&query=Sinev%2C+L">Leonid Sinev</a>, 
<a href="/search/cs?searchtype=author&query=Isaeva%2C+U">Ulyana Isaeva</a>, 
<a href="/search/cs?searchtype=author&query=Kolomeytseva%2C+K">Katerina Kolomeytseva</a>, 
<a href="/search/cs?searchtype=author&query=Moskovskiy%2C+D">Daniil Moskovskiy</a>, 
<a href="/search/cs?searchtype=author&query=Goncharova%2C+E">Elizaveta Goncharova</a>, 
<a href="/search/cs?searchtype=author&query=Savushkin%2C+N">Nikita Savushkin</a>, 
<a href="/search/cs?searchtype=author&query=Mikhailova%2C+P">Polina Mikhailova</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrov%2C+D">Denis Dimitrov</a>, 
<a href="/search/cs?searchtype=author&query=Panchenko%2C+A">Alexander Panchenko</a>, 
<a href="/search/cs?searchtype=author&query=Markov%2C+S">Sergei Markov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper version comparable with the release code v.1.1.0 of the benchmark. The links and scores are updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04679" title="Abstract">arXiv:2401.04679</a> (replaced) [<a href="/pdf/2401.04679" title="Download PDF">pdf</a>, <a href="/format/2401.04679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikdan%2C+M">Mahdi Nikdan</a>, 
<a href="/search/cs?searchtype=author&query=Tabesh%2C+S">Soroush Tabesh</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05363" title="Abstract">arXiv:2401.05363</a> (replaced) [<a href="/pdf/2401.05363" title="Download PDF">pdf</a>, <a href="/format/2401.05363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Sleep Staging via Multi-Level Domain Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiquan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Sha Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+H">Haiteng Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shijian Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+G">Gang Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05379" title="Abstract">arXiv:2401.05379</a> (replaced) [<a href="/pdf/2401.05379" title="Download PDF">pdf</a>, <a href="/format/2401.05379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoVisual Fusion Suite: A Comprehensive Evaluation of Image  Segmentation and Voice Conversion Tools on HuggingFace Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+A">Amirreza Hashemi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05414" title="Abstract">arXiv:2401.05414</a> (replaced) [<a href="/pdf/2401.05414" title="Download PDF">pdf</a>, <a href="/format/2401.05414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Three Demons in Causality in Finance: Time Resolution,  Nonstationarity, and Latent Factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Dong%2C+X">Xinshuai Dong</a>, 
<a href="/search/q-fin?searchtype=author&query=Dai%2C+H">Haoyue Dai</a>, 
<a href="/search/q-fin?searchtype=author&query=Fan%2C+Y">Yewen Fan</a>, 
<a href="/search/q-fin?searchtype=author&query=Jin%2C+S">Songyao Jin</a>, 
<a href="/search/q-fin?searchtype=author&query=Rajendran%2C+S">Sathyamoorthy Rajendran</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05437" title="Abstract">arXiv:2401.05437</a> (replaced) [<a href="/pdf/2401.05437" title="Download PDF">pdf</a>, <a href="/format/2401.05437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation Learning for Wearable-Based Applications in the Case of  Missing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jungo%2C+J">Janosch Jungo</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+Y">Yutong Xiang</a>, 
<a href="/search/eess?searchtype=author&query=Gashi%2C+S">Shkurta Gashi</a>, 
<a href="/search/eess?searchtype=author&query=Holz%2C+C">Christian Holz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted in Human-Centric Representation Learning workshop at AAAI 2024 (<a href="https://hcrl-workshop.github.io/2024/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05442" title="Abstract">arXiv:2401.05442</a> (replaced) [<a href="/pdf/2401.05442" title="Download PDF">pdf</a>, <a href="/format/2401.05442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Graphical Models: Structure Enables Offline Data-Driven  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuba%2C+J+G">Jakub Grudzien Kuba</a>, 
<a href="/search/cs?searchtype=author&query=Uehara%2C+M">Masatoshi Uehara</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05566" title="Abstract">arXiv:2401.05566</a> (replaced) [<a href="/pdf/2401.05566" title="Download PDF">pdf</a>, <a href="/format/2401.05566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sleeper Agents: Training Deceptive LLMs that Persist Through Safety  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hubinger%2C+E">Evan Hubinger</a>, 
<a href="/search/cs?searchtype=author&query=Denison%2C+C">Carson Denison</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+J">Jesse Mu</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+M">Mike Lambert</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Meg Tong</a>, 
<a href="/search/cs?searchtype=author&query=MacDiarmid%2C+M">Monte MacDiarmid</a>, 
<a href="/search/cs?searchtype=author&query=Lanham%2C+T">Tamera Lanham</a>, 
<a href="/search/cs?searchtype=author&query=Ziegler%2C+D+M">Daniel M. Ziegler</a>, 
<a href="/search/cs?searchtype=author&query=Maxwell%2C+T">Tim Maxwell</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Newton Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Jermyn%2C+A">Adam Jermyn</a>, 
<a href="/search/cs?searchtype=author&query=Askell%2C+A">Amanda Askell</a>, 
<a href="/search/cs?searchtype=author&query=Radhakrishnan%2C+A">Ansh Radhakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Anil%2C+C">Cem Anil</a>, 
<a href="/search/cs?searchtype=author&query=Duvenaud%2C+D">David Duvenaud</a>, 
<a href="/search/cs?searchtype=author&query=Ganguli%2C+D">Deep Ganguli</a>, 
<a href="/search/cs?searchtype=author&query=Barez%2C+F">Fazl Barez</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+J">Jack Clark</a>, 
<a href="/search/cs?searchtype=author&query=Ndousse%2C+K">Kamal Ndousse</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+K">Kshitij Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Sellitto%2C+M">Michael Sellitto</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Mrinank Sharma</a>, 
<a href="/search/cs?searchtype=author&query=DasSarma%2C+N">Nova DasSarma</a>, 
<a href="/search/cs?searchtype=author&query=Grosse%2C+R">Roger Grosse</a>, 
<a href="/search/cs?searchtype=author&query=Kravec%2C+S">Shauna Kravec</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yuntao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Witten%2C+Z">Zachary Witten</a>, 
<a href="/search/cs?searchtype=author&query=Favaro%2C+M">Marina Favaro</a>, 
<a href="/search/cs?searchtype=author&query=Brauner%2C+J">Jan Brauner</a>, 
<a href="/search/cs?searchtype=author&query=Karnofsky%2C+H">Holden Karnofsky</a>, 
<a href="/search/cs?searchtype=author&query=Christiano%2C+P">Paul Christiano</a>, 
<a href="/search/cs?searchtype=author&query=Bowman%2C+S+R">Samuel R. Bowman</a>, 
<a href="/search/cs?searchtype=author&query=Graham%2C+L">Logan Graham</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+J">Jared Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Mindermann%2C+S">S&#xf6;ren Mindermann</a>, 
<a href="/search/cs?searchtype=author&query=Greenblatt%2C+R">Ryan Greenblatt</a>, 
<a href="/search/cs?searchtype=author&query=Shlegeris%2C+B">Buck Shlegeris</a>, 
<a href="/search/cs?searchtype=author&query=Schiefer%2C+N">Nicholas Schiefer</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+E">Ethan Perez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> added missing acknowledgement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05594" title="Abstract">arXiv:2401.05594</a> (replaced) [<a href="/pdf/2401.05594" title="Download PDF">pdf</a>, <a href="/format/2401.05594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein Distance-based Expansion of Low-Density Latent Regions for  Unknown Class Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mallick%2C+P">Prakash Mallick</a>, 
<a href="/search/cs?searchtype=author&query=Dayoub%2C+F">Feras Dayoub</a>, 
<a href="/search/cs?searchtype=author&query=Sherrah%2C+J">Jamie Sherrah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Full length pages, followed by 2 supplementary pages, total of 9 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05628" title="Abstract">arXiv:2401.05628</a> (replaced) [<a href="/pdf/2401.05628" title="Download PDF">pdf</a>, <a href="/format/2401.05628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Multi-Source Directed Reachability via Shortcuts and Matrix  Multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elkin%2C+M">Michael Elkin</a>, 
<a href="/search/cs?searchtype=author&query=Trehan%2C+C">Chhaya Trehan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05646" title="Abstract">arXiv:2401.05646</a> (replaced) [<a href="/pdf/2401.05646" title="Download PDF">pdf</a>, <a href="/format/2401.05646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Attribute Description Embedding for Cloth-Changing Person  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chunlei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Decheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruimin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, 52 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05712" title="Abstract">arXiv:2401.05712</a> (replaced) [<a href="/pdf/2401.05712" title="Download PDF">pdf</a>, <a href="/format/2401.05712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BOD: Blindly Optimal Data Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Thomas Hoang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Still working on other parts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05717" title="Abstract">arXiv:2401.05717</a> (replaced) [<a href="/pdf/2401.05717" title="Download PDF">pdf</a>, <a href="/format/2401.05717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Boundary Detection via Class Entropy Measurements in  Connectionist Phoneme Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salvi%2C+G">Giampiero Salvi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Speech Communication Volume 48, Issue 12, December 2006, Pages
  1666-1676
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05806" title="Abstract">arXiv:2401.05806</a> (replaced) [<a href="/pdf/2401.05806" title="Download PDF">pdf</a>, <a href="/format/2401.05806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-Driven Semantic Discovery Network for Visible-Infrared Person  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaoyan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Neng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liehuang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dapeng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05834" title="Abstract">arXiv:2401.05834</a> (replaced) [<a href="/pdf/2401.05834" title="Download PDF">pdf</a>, <a href="/ps/2401.05834" title="Download PostScript">ps</a>, <a href="/format/2401.05834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Online Paging in Multi-Core Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mari%2C+M">Mathieu Mari</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Anish Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+R">Runtian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sankowski%2C+P">Piotr Sankowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05872" title="Abstract">arXiv:2401.05872</a> (replaced) [<a href="/pdf/2401.05872" title="Download PDF">pdf</a>, <a href="/ps/2401.05872" title="Download PostScript">ps</a>, <a href="/format/2401.05872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logical Predicates in Higher-Order Mathematical Operational Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goncharov%2C+S">Sergey Goncharov</a>, 
<a href="/search/cs?searchtype=author&query=Santamaria%2C+A">Alessio Santamaria</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+L">Lutz Schr&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Tsampas%2C+S">Stelios Tsampas</a>, 
<a href="/search/cs?searchtype=author&query=Urbat%2C+H">Henning Urbat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05883" title="Abstract">arXiv:2401.05883</a> (replaced) [<a href="/pdf/2401.05883" title="Download PDF">pdf</a>, <a href="/format/2401.05883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Deduplication For Socia Media Data Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianming Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work In Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05949" title="Abstract">arXiv:2401.05949</a> (replaced) [<a href="/pdf/2401.05949" title="Download PDF">pdf</a>, <a href="/format/2401.05949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Vulnerabilities in Large Language Models: In-context Learning  Backdoor Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Meihuizi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Tuan%2C+L+A">Luu Anh Tuan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jinming Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05982" title="Abstract">arXiv:2401.05982</a> (replaced) [<a href="/pdf/2401.05982" title="Download PDF">pdf</a>, <a href="/ps/2401.05982" title="Download PostScript">ps</a>, <a href="/format/2401.05982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A tree-based varying coefficient model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zakrisson%2C+H">Henning Zakrisson</a>, 
<a href="/search/stat?searchtype=author&query=Lindholm%2C+M">Mathias Lindholm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06013" title="Abstract">arXiv:2401.06013</a> (replaced) [<a href="/pdf/2401.06013" title="Download PDF">pdf</a>, <a href="/format/2401.06013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surgical-DINO: Adapter Learning of Foundation Models for Depth  Estimation in Endoscopic Surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Beilei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M">Mobarakol Islam</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Long Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hongliang Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IPCAI 2024 (IJCAR Special Issue)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06071" title="Abstract">arXiv:2401.06071</a> (replaced) [<a href="/pdf/2401.06071" title="Download PDF">pdf</a>, <a href="/format/2401.06071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEGO:Language Enhanced Multi-modal Grounding Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hang Song</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiqing Cai</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Qi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ran Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Junting Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zefeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+V+T">Van Tu Vu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhida Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06080" title="Abstract">arXiv:2401.06080</a> (replaced) [<a href="/pdf/2401.06080" title="Download PDF">pdf</a>, <a href="/format/2401.06080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secrets of RLHF in Large Language Models Part II: Reward Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Binghai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+S">Shihan Dou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Caishuang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Senjie Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chenyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Songyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zhiheng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lixing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06102" title="Abstract">arXiv:2401.06102</a> (replaced) [<a href="/pdf/2401.06102" title="Download PDF">pdf</a>, <a href="/format/2401.06102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patchscopes: A Unifying Framework for Inspecting Hidden Representations  of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghandeharioun%2C+A">Asma Ghandeharioun</a>, 
<a href="/search/cs?searchtype=author&query=Caciularu%2C+A">Avi Caciularu</a>, 
<a href="/search/cs?searchtype=author&query=Pearce%2C+A">Adam Pearce</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+L">Lucas Dixon</a>, 
<a href="/search/cs?searchtype=author&query=Geva%2C+M">Mor Geva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item261">Cross-lists</a></li>
<li><a href="#item307">Replacements</a></li>
</ul>
<small>[ total of 466 entries:  <b>1-466</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2401">2401</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
