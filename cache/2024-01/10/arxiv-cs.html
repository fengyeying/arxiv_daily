<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Mon  8 Jan 24  to  Tue  9 Jan 24, announced Wed, 10 Jan 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item222">Cross-lists</a></li>
<li><a href="#item255">Replacements</a></li>
</ul>
<small>[ total of 446 entries:  <b>1-446</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed, 10 Jan 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04108" title="Abstract">arXiv:2401.04108</a> [<a href="/pdf/2401.04108" title="Download PDF">pdf</a>, <a href="/ps/2401.04108" title="Download PostScript">ps</a>, <a href="/format/2401.04108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Working with Trouble and Failures in Conversation between Humans and  Robots (WTF 2023) &amp; Is CUI Design Ready Yet?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=F%C3%B6rster%2C+F">Frank F&#xf6;rster</a>, 
<a href="/search/cs?searchtype=author&query=Romeo%2C+M">Marta Romeo</a>, 
<a href="/search/cs?searchtype=author&query=Holthaus%2C+P">Patrick Holthaus</a>, 
<a href="/search/cs?searchtype=author&query=Trigo%2C+M+J+G">Maria Jose Galvez Trigo</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+J+E">Joel E. Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Nesset%2C+B">Birthe Nesset</a>, 
<a href="/search/cs?searchtype=author&query=Dondrup%2C+C">Christian Dondrup</a>, 
<a href="/search/cs?searchtype=author&query=Murad%2C+C">Christine Murad</a>, 
<a href="/search/cs?searchtype=author&query=Munteanu%2C+C">Cosmin Munteanu</a>, 
<a href="/search/cs?searchtype=author&query=Cowan%2C+B+R">Benjamin R. Cowan</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+L">Leigh Clark</a>, 
<a href="/search/cs?searchtype=author&query=Porcheron%2C+M">Martin Porcheron</a>, 
<a href="/search/cs?searchtype=author&query=Candello%2C+H">Heloisa Candello</a>, 
<a href="/search/cs?searchtype=author&query=Langevin%2C+R">Raina Langevin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WTF 2023 &amp; 'Is CUI Design Ready Yet?' workshop proceedings including 10 extended abstracts and articles
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)

</div>
<p class="mathjax">Workshop proceedings of two co-located workshops "Working with Troubles and
Failures in Conversation with Humans and Robots" (WTF 2023) and "Is CUI Design
Ready Yet?", both of which were part of the ACM conference on conversational
user interfaces 2023.
<br />WTF 23 aimed at bringing together researchers from human-robot interaction,
dialogue systems, human-computer interaction, and conversation analysis.
Despite all progress, robotic speech interfaces continue to be brittle in a
number of ways and the experience of failure of such interfaces is commonplace
amongst roboticists. However, the technical literature is positively skewed
toward their good performance. The workshop aims to provide a platform for
discussing communicative troubles and failures in human-robot interactions and
related failures in non-robotic speech interfaces. Aims include a scrupulous
investigation into communicative failures, to begin working on a taxonomy of
such failures, and enable a preliminary discussion on possible mitigating
strategies. Workshop website: https://sites.google.com/view/wtf2023/overview
<br />Is CUI Design Ready Yet? As CUIs become more prevalent in both academic
research and the commercial market, it becomes more essential to design usable
and adoptable CUIs. While research has been growing on the methods for
designing CUIs for commercial use, there has been little discussion on the
overall community practice of developing design resources to aid in practical
CUI design. The aim of this workshop, therefore, is to bring the CUI community
together to discuss the current practices for developing tools and resources
for practical CUI design, the adoption (or non-adoption) of these tools and
resources, and how these resources are utilized in the training and education
of new CUI designers entering the field. Workshop website:
https://speech-interaction.org/cui2023_design_workshop/index.html
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04109" title="Abstract">arXiv:2401.04109</a> [<a href="/pdf/2401.04109" title="Download PDF">pdf</a>, <a href="/ps/2401.04109" title="Download PostScript">ps</a>, <a href="/format/2401.04109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent developments of selective laser processes for wearable devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngchan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+E">Eunseung Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Kai%2C+C">Chang Kai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaichen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Heng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sukjoon Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Recently, the growing interest in wearable technology for personal healthcare
and smart VR/AR applications newly imposed a need for development of facile
fabrication method. Regarding the issue, laser has long been proposing original
answers to such challenging technological demands with its remote, sterile,
rapid, and site-selective processing characteristics for arbitrary materials.
In this review, recent developments in relevant laser processes are summarized
in two separate categories. Firstly, transformative approaches represented by
laser-induced graphene (LIG) are introduced. Apart from design optimization and
alteration of native substrate, latest advancements in the transformative
approach now enable not only more complex material compositions but also
multilayer device configurations by simultaneous transformation of
heterogeneous precursor or sequential addition of functional layers coupled
with other electronic elements. Besides, more conventional laser techniques
such as ablation, sintering and synthesis are still accessible for enhancing
the functionality of the entire system through expansion of applicable
materials and adoption of new mechanisms. Various wearable device components
developed through the corresponding laser processes are then organized with
emphasis on chemical/physical sensors and energy devices. At the same time,
special attention is given to the applications utilizing multiple laser sources
or multiple laser processes, which pave the way towards all-laser fabrication
of wearable devices.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04111" title="Abstract">arXiv:2401.04111</a> [<a href="/pdf/2401.04111" title="Download PDF">pdf</a>, <a href="/ps/2401.04111" title="Download PostScript">ps</a>, <a href="/format/2401.04111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recognition of Cyber-Intrusion patterns in user cognitive behavioural  characteristics for remote identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orun%2C+A">Ahmet Orun</a>, 
<a href="/search/cs?searchtype=author&query=Orun%2C+E">Emre Orun</a>, 
<a href="/search/cs?searchtype=author&query=Kurugollu%2C+F">Fatih Kurugollu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Cyber-attacks keep threatening global networks and information
infrastructures. The threat is getting more and more destructive and hard to
counter day by day as the global networks continue to enlarge exponentially
with limited security counter-measures. As this fact requires more
sophisticated methods and techniques in urgency, a multidisciplinary remote
cognitive observation technique is proposed in this paper to meet today's
cybersecurity needs. The proposed method introduces a non-traditional Cognitive
Psychology and Artificial Intelligence (AI) based remote threat identification
which can be considered during the cyber security system design. It also
enables to access the cognitive behavioural parameters of an intruder/hacker
remotely without any physical contact via online connection, disregarding the
distance of the thread. The ultimate goal of this work is to develop a
supplementary cognitive cyber security tool for next generations secure online
banking, finance or trade systems.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04112" title="Abstract">arXiv:2401.04112</a> [<a href="/pdf/2401.04112" title="Download PDF">pdf</a>, <a href="/ps/2401.04112" title="Download PostScript">ps</a>, <a href="/format/2401.04112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational Swarm Intelligence amplifies the accuracy of networked  groupwise deliberations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenberg%2C+L">Louis Rosenberg</a>, 
<a href="/search/cs?searchtype=author&query=Willcox%2C+G">Gregg Willcox</a>, 
<a href="/search/cs?searchtype=author&query=Schumann%2C+H">Hans Schumann</a>, 
<a href="/search/cs?searchtype=author&query=Mani%2C+G">Ganesh Mani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted for publication in proceedings IEEE 14th Annual Computing and Communication Workshop and Conference (CCWC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Conversational Swarm Intelligence (CSI) is a communication technology that
enables large, networked groups (25 to 2500 people) to hold real-time
conversational deliberations online. Modeled on the dynamics of biological
swarms, CSI enables the reasoning benefits of small-groups with the collective
intelligence benefits of large-groups. In this pilot study, groups of 25 to 30
participants were asked to select players for a weekly Fantasy Football contest
over an 11-week period. As a baseline, participants filled out a survey to
record their player selections. As an experimental method, participants engaged
in a real-time text-chat deliberation using a CSI platform called Thinkscape to
collaboratively select sets of players. The results show that the real-time
conversational group using CSI outperformed 66% of survey participants,
demonstrating significant amplification of intelligence versus the median
individual (p=0.020). The CSI method also significantly outperformed the most
popular choices from the survey (the Wisdom of Crowd, p&lt;0.001). These results
suggest that CSI is an effective technology for amplifying the intelligence of
groups engaged in real-time large-scale conversational deliberation and may
offer a path to collective superintelligence.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04114" title="Abstract">arXiv:2401.04114</a> [<a href="/pdf/2401.04114" title="Download PDF">pdf</a>, <a href="/format/2401.04114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timeline-based Process Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaur%2C+H">Harleen Kaur</a>, 
<a href="/search/cs?searchtype=author&query=Mendling%2C+J">Jan Mendling</a>, 
<a href="/search/cs?searchtype=author&query=Rubensson%2C+C">Christoffer Rubensson</a>, 
<a href="/search/cs?searchtype=author&query=Kampik%2C+T">Timotheus Kampik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">A key concern of automatic process discovery is to provide insights into
performance aspects of business processes. Waiting times are of particular
importance in this context. For that reason, it is surprising that current
techniques for automatic process discovery generate directly-follows graphs and
comparable process models, but often miss the opportunity to explicitly
represent the time axis. In this paper, we present an approach for
automatically constructing process models that explicitly align with a time
axis. We exemplify our approach for directly-follows graphs. Our evaluation
using two BPIC datasets and a proprietary dataset highlight the benefits of
this representation in comparison to standard layout techniques.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04116" title="Abstract">arXiv:2401.04116</a> [<a href="/pdf/2401.04116" title="Download PDF">pdf</a>, <a href="/ps/2401.04116" title="Download PostScript">ps</a>, <a href="/format/2401.04116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Draw Engineering for Text-to-Image Creation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Huaqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yangkai Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Advances in Information Science and Technology, Volume
  1, Issue 1, 2023, Pages 1-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Text-to-image generation is conducted through Generative Adversarial Networks
(GANs) or transformer models. However, the current challenge lies in accurately
generating images based on textual descriptions, especially in scenarios where
the content and theme of the target image are ambiguous. In this paper, we
propose a method that utilizes artificial intelligence models for thematic
creativity, followed by a classification modeling of the actual painting
process. The method involves converting all visual elements into quantifiable
data structures before creating images. We evaluate the effectiveness of this
approach in terms of semantic accuracy, image reproducibility, and
computational efficiency, in comparison with existing image generation
algorithms.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04117" title="Abstract">arXiv:2401.04117</a> [<a href="/pdf/2401.04117" title="Download PDF">pdf</a>, <a href="/ps/2401.04117" title="Download PostScript">ps</a>, <a href="/format/2401.04117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Holistic Approach on Smart Garment for Patients with Juvenile  Idiopathic Arthritis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+S">Safal Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Randhawa%2C+P">Princy Randhawa</a>, 
<a href="/search/cs?searchtype=author&query=Jinka%2C+S+K+P">Sampath Kumar P Jinka</a>, 
<a href="/search/cs?searchtype=author&query=C%2C+S+P+H">Shiva Prasad H.C</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 08 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 10.3390/engproc2023059083;2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Juvenile Idiopathic Arthritis (JIA) is a widespread and chronic condition
that affects children and adolescents worldwide. The person suffering from JIA
is characterized by chronic joint inflammation leading to pain, swelling,
stiffness, and limited body movements. Individuals suffering from JIA require
ongoing treatment for their lifetime. Beyond inflammation, JIA patients have
expressed concerns about various factors and the lack of responsive services
addressing their challenges. The implementation of smart garments offers a
promising solution to assist individuals with Juvenile Idiopathic Arthritis in
performing their daily activities. These garments are designed to seamlessly
integrate technology and clothing, providing not only physical support but also
addressing the psychological and emotional aspects of living with a chronic
condition. By incorporating sensors, these smart garments can monitor joint
movement, detect inflammation, and provide real-time feedback to both patients
and healthcare providers. To tackle these comprehensive challenges, the
research aims to offer a solution through the design of a smart garment,
created with a holistic approach. This smart garment is intended to improve the
overall well-being of JIA patients by enhancing their mobility, comfort, and
overall quality of life. The integration of technology into clothing can
potentially revolutionize the way JIA is managed, allowing patients to better
manage their condition and minimize its impact on their daily lives. The
synergy between healthcare and technology holds great potential in addressing
the multifaceted challenges posed by Juvenile Idiopathic Arthritis patients.
Through innovation and empathy, this research aims to pave the way for a
brighter future for individuals living with Juvenile Idiopathic Arthritis.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04118" title="Abstract">arXiv:2401.04118</a> [<a href="/pdf/2401.04118" title="Download PDF">pdf</a>, <a href="/format/2401.04118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Directive Explanations: Crafting Explainable AI Systems for  Actionable Human-AI Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+A">Aditya Bhattacharya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">With Artificial Intelligence (AI) becoming ubiquitous in every application
domain, the need for explanations is paramount to enhance transparency and
trust among non-technical users. Despite the potential shown by Explainable AI
(XAI) for enhancing understanding of complex AI systems, most XAI methods are
designed for technical AI experts rather than non-technical consumers.
Consequently, such explanations are overwhelmingly complex and seldom guide
users in achieving their desired predicted outcomes. This paper presents
ongoing research for crafting XAI systems tailored to guide users in achieving
desired outcomes through improved human-AI interactions. This paper highlights
the research objectives and methods, key takeaways and implications learned
from user studies. It outlines open questions and challenges for enhanced
human-AI collaboration, which the author aims to address in future work.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04119" title="Abstract">arXiv:2401.04119</a> [<a href="/pdf/2401.04119" title="Download PDF">pdf</a>, <a href="/format/2401.04119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why is the User Interface a Dark Pattern? : Explainable Auto-Detection  and its Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yada%2C+Y">Yuki Yada</a>, 
<a href="/search/cs?searchtype=author&query=Matsumoto%2C+T">Tsuneo Matsumoto</a>, 
<a href="/search/cs?searchtype=author&query=Kido%2C+F">Fuyuko Kido</a>, 
<a href="/search/cs?searchtype=author&query=Yamana%2C+H">Hayato Yamana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Big Data (IEEE BigData 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Dark patterns are deceptive user interface designs for online services that
make users behave in unintended ways. Dark patterns, such as privacy invasion,
financial loss, and emotional distress, can harm users. These issues have been
the subject of considerable debate in recent years. In this paper, we study
interpretable dark pattern auto-detection, that is, why a particular user
interface is detected as having dark patterns. First, we trained a model using
transformer-based pre-trained language models, BERT, on a text-based dataset
for the automatic detection of dark patterns in e-commerce. Then, we applied
post-hoc explanation techniques, including local interpretable model agnostic
explanation (LIME) and Shapley additive explanations (SHAP), to the trained
model, which revealed which terms influence each prediction as a dark pattern.
In addition, we extracted and analyzed terms that affected the dark patterns.
Our findings may prevent users from being manipulated by dark patterns, and aid
in the construction of more equitable internet services. Our code is available
at https://github.com/yamanalab/why-darkpattern.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04120" title="Abstract">arXiv:2401.04120</a> [<a href="/pdf/2401.04120" title="Download PDF">pdf</a>, <a href="/format/2401.04120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation Z&#x27;s Ability to Discriminate Between AI-generated and  Human-Authored Text on Discord
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramu%2C+D">Dhruv Ramu</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rishab Jain</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Aditya Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The growing popularity of generative artificial intelligence (AI) chatbots
such as ChatGPT is having transformative effects on social media. As the
prevalence of AI-generated content grows, concerns have been raised regarding
privacy and misinformation online. Among social media platforms, Discord
enables AI integrations -- making their primarily "Generation Z" userbase
particularly exposed to AI-generated content. We surveyed Generation Z aged
individuals (n = 335) to evaluate their proficiency in discriminating between
AI-generated and human-authored text on Discord. The investigation employed
one-shot prompting of ChatGPT, disguised as a text message received on the
Discord.com platform. We explore the influence of demographic factors on
ability, as well as participants' familiarity with Discord and artificial
intelligence technologies. We find that Generation Z individuals are unable to
discern between AI and human-authored text (p = 0.011), and that those with
lower self-reported familiarity with Discord demonstrated an improved ability
in identifying human-authored compared to those with self-reported experience
with AI (p &lt;&lt; 0.0001). Our results suggest that there is a nuanced relationship
between AI technology and popular modes of communication for Generation Z,
contributing valuable insights into human-computer interactions, digital
communication, and artificial intelligence literacy.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04122" title="Abstract">arXiv:2401.04122</a> [<a href="/pdf/2401.04122" title="Download PDF">pdf</a>, <a href="/format/2401.04122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Prompt Engineering to Prompt Science With Human in the Loop
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+C">Chirag Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As LLMs make their way into many aspects of our lives, one place that
warrants increased scrutiny with LLM usage is scientific research. Using LLMs
for generating or analyzing data for research purposes is gaining popularity.
But when such application is marred with ad-hoc decisions and engineering
solutions, we need to be concerned about how it may affect that research, its
findings, or any future works based on that research. We need a more scientific
approach to using LLMs in our research. While there are several active efforts
to support more systematic construction of prompts, they are often focused more
on achieving desirable outcomes rather than producing replicable and
generalizable knowledge with sufficient transparency, objectivity, or rigor.
This article presents a new methodology inspired by codebook construction
through qualitative methods to address that. Using humans in the loop and a
multi-phase verification processes, this methodology lays a foundation for more
systematic, objective, and trustworthy way of applying LLMs for analyzing data.
Specifically, we show how a set of researchers can work through a rigorous
process of labeling, deliberating, and documenting to remove subjectivity and
bring transparency and replicability to prompt generation process. A set of
experiments are presented to show how this methodology can be put in practice.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04124" title="Abstract">arXiv:2401.04124</a> [<a href="/pdf/2401.04124" title="Download PDF">pdf</a>, <a href="/format/2401.04124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobileAgent: enhancing mobile control via human-machine interaction and  SOP integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+T">Tinghe Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> agent, mobile control, SOP, human-machine interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Agents centered around Large Language Models (LLMs) are now capable of
automating mobile device operations for users. After fine-tuning to learn a
user's mobile operations, these agents can adhere to high-level user
instructions online. They execute tasks such as goal decomposition, sequencing
of sub-goals, and interactive environmental exploration, until the final
objective is achieved. However, privacy concerns related to personalized user
data arise during mobile operations, requiring user confirmation. Moreover,
users' real-world operations are exploratory, with action data being complex
and redundant, posing challenges for agent learning. To address these issues,
in our practical application, we have designed interactive tasks between agents
and humans to identify sensitive information and align with personalized user
needs. Additionally, we integrated Standard Operating Procedure (SOP)
information within the model's in-context learning to enhance the agent's
comprehension of complex task execution. Our approach is evaluated on the new
device control benchmark AitW, which encompasses 30K unique instructions across
multi-step tasks, including application operation, web searching, and web
shopping. Experimental results show that the SOP-based agent achieves
state-of-the-art performance without incurring additional inference costs,
boasting an overall action success rate of 66.92%.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04126" title="Abstract">arXiv:2401.04126</a> [<a href="/pdf/2401.04126" title="Download PDF">pdf</a>, <a href="/ps/2401.04126" title="Download PostScript">ps</a>, <a href="/format/2401.04126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Concept of the Tactile Signature System for Individuals with Visual  Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kremenchutskiy%2C+A">Anatoliy Kremenchutskiy</a>, 
<a href="/search/cs?searchtype=author&query=Gabdreshov%2C+G">Galymzhan Gabdreshov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 14 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The lack of an accessible and effective system for blind individuals to
create handwritten signatures presents a significant barrier to their
independence and full participation in various aspects of life. This research
introduces the Tactile Signature System, a groundbreaking approach that
empowers individuals with visual impairments to form their unique handwritten
signatures. Key features of the system include: Personalized customization:
Through tactile interaction and voice algorithmic guidance, individuals create
signatures reflecting their preferences and natural writing style. Real-time
feedback: AI-powered voice prompts and analysis ensure accuracy and consistency
in signature formation. Accessibility: Installation in local service centers
provides a secure and supervised environment for signature creation. The
system's impact reaches beyond the individual level: Promotes inclusivity and
independence: Blind individuals can engage in legal and financial transactions
without relying on others. Empowers and fosters equal opportunities:
Participation in education, employment, and civic engagement becomes more
accessible. Aligns with international conventions: Upholds the right of persons
with disabilities to participate fully in society. The Tactile Signature System
represents a significant step towards an inclusive and accessible future for
individuals with visual impairments.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04130" title="Abstract">arXiv:2401.04130</a> [<a href="/pdf/2401.04130" title="Download PDF">pdf</a>, <a href="/format/2401.04130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Test-Time Adaptation via Plug-and-Play Transformer Modules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiangyu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+M">Sk Miraj Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Guler%2C+B">Basak Guler</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+S+V">Srikanth V. Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Swami%2C+A">Ananthram Swami</a>, 
<a href="/search/cs?searchtype=author&query=Oymak%2C+S">Samet Oymak</a>, 
<a href="/search/cs?searchtype=author&query=Roy-Chowdhury%2C+A+K">Amit K. Roy-Chowdhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Parameter-efficient tuning (PET) methods such as LoRA, Adapter, and Visual
Prompt Tuning (VPT) have found success in enabling adaptation to new domains by
tuning small modules within a transformer model. However, the number of domains
encountered during test time can be very large, and the data is usually
unlabeled. Thus, adaptation to new domains is challenging; it is also
impractical to generate customized tuned modules for each such domain. Toward
addressing these challenges, this work introduces PLUTO: a Plug-and-pLay
modUlar Test-time domain adaptatiOn strategy. We pre-train a large set of
modules, each specialized for different source domains, effectively creating a
``module store''. Given a target domain with few-shot unlabeled data, we
introduce an unsupervised test-time adaptation (TTA) method to (1) select a
sparse subset of relevant modules from this store and (2) create a weighted
combination of selected modules without tuning their weights. This
plug-and-play nature enables us to harness multiple most-relevant source
domains in a single inference call. Comprehensive evaluations demonstrate that
PLUTO uniformly outperforms alternative TTA methods and that selecting $\leq$5
modules suffice to extract most of the benefit. At a high level, our method
equips pre-trained transformers with the capability to dynamically adapt to new
domains, motivating a new paradigm for efficient and scalable domain
adaptation.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04131" title="Abstract">arXiv:2401.04131</a> [<a href="/pdf/2401.04131" title="Download PDF">pdf</a>, <a href="/ps/2401.04131" title="Download PostScript">ps</a>, <a href="/format/2401.04131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Synthesis of Distributed Cryptographic Applications (Technical  Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acay%2C+C">Co&#x15f;ku Acay</a>, 
<a href="/search/cs?searchtype=author&query=Gancher%2C+J">Joshua Gancher</a>, 
<a href="/search/cs?searchtype=author&query=Recto%2C+R">Rolph Recto</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+A+C">Andrew C. Myers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Developing secure distributed systems is difficult, and even harder when
advanced cryptography must be used to achieve security goals. Following prior
work, we advocate using secure program partitioning to synthesize cryptographic
applications: instead of implementing a system of communicating processes, the
programmer implements a centralized, sequential program, which is automatically
compiled into a secure distributed version that uses cryptography.
<br />While this approach is promising, formal results for the security of such
compilers are limited in scope. In particular, no security proof yet
simultaneously addresses subtleties essential for robust, efficient
applications: multiple cryptographic mechanisms, malicious corruption, and
asynchronous communication.
<br />In this work, we develop a compiler security proof that handles these
subtleties. Our proof relies on a novel unification of simulation-based
security, information-flow control, choreographic programming, and
sequentialization techniques for concurrent programs. While our proof targets
hybrid protocols, which abstract cryptographic mechanisms as idealized
functionalities, our approach offers a clear path toward leveraging Universal
Composability to obtain end-to-end, modular security results with fully
instantiated cryptographic mechanisms.
<br />Finally, following prior observations about simulation-based security, we
prove that our result guarantees robust hyperproperty preservation, an
important criterion for compiler correctness that preserves all source-level
security properties in target programs.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04133" title="Abstract">arXiv:2401.04133</a> [<a href="/pdf/2401.04133" title="Download PDF">pdf</a>, <a href="/format/2401.04133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynHIN: Generating Synthetic Heterogeneous Information Network for  Explainable AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Ming-Yi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yi-Hsiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">You-Chen Teng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chih-Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Che Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) excel in various domains, from detecting
e-commerce spam to social network classification problems. However, the lack of
public graph datasets hampers research progress, particularly in heterogeneous
information networks (HIN). The demand for datasets for fair HIN comparisons is
growing due to advancements in GNN interpretation models. In response, we
propose SynHIN, a unique method for generating synthetic heterogeneous
information networks. SynHIN identifies motifs in real-world datasets,
summarizes graph statistics, and constructs a synthetic network. Our approach
utilizes In-Cluster and Out-Cluster Merge modules to build the synthetic HIN
from primary motif clusters. After In/Our-Cluster mergers and a post-pruning
process fitting the real dataset constraints, we ensure the synthetic graph
statistics align closely with the reference one. SynHIN generates a synthetic
heterogeneous graph dataset for node classification tasks, using the primary
motif as the explanation ground truth. It can adapt and address the lack of
heterogeneous graph datasets and motif ground truths, proving beneficial for
assessing heterogeneous graph neural network explainers. We further present a
benchmark dataset for future heterogeneous graph explainer model research. Our
work marks a significant step towards explainable AI in HGNNs.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04134" title="Abstract">arXiv:2401.04134</a> [<a href="/pdf/2401.04134" title="Download PDF">pdf</a>, <a href="/format/2401.04134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Web Neural Network with Complete DiGraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Frank Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces a new neural network model that aims to mimic the
biological brain more closely by structuring the network as a complete directed
graph that processes continuous data for each timestep. Current neural networks
have structures that vaguely mimic the brain structure, such as neurons,
convolutions, and recurrence. The model proposed in this paper adds additional
structural properties by introducing cycles into the neuron connections and
removing the sequential nature commonly seen in other network layers.
Furthermore, the model has continuous input and output, inspired by spiking
neural networks, which allows the network to learn a process of classification,
rather than simply returning the final result.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04135" title="Abstract">arXiv:2401.04135</a> [<a href="/pdf/2401.04135" title="Download PDF">pdf</a>, <a href="/format/2401.04135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global-Aware Enhanced Spatial-Temporal Graph Recurrent Networks: A New  Framework For Traffic Flow Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chunjiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Detian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traffic flow prediction plays a crucial role in alleviating traffic
congestion and enhancing transport efficiency. While combining graph
convolution networks with recurrent neural networks for spatial-temporal
modeling is a common strategy in this realm, the restricted structure of
recurrent neural networks limits their ability to capture global information.
For spatial modeling, many prior studies learn a graph structure that is
assumed to be fixed and uniform at all time steps, which may not be true. This
paper introduces a novel traffic prediction framework, Global-Aware Enhanced
Spatial-Temporal Graph Recurrent Network (GA-STGRN), comprising two core
components: a spatial-temporal graph recurrent neural network and a global
awareness layer. Within this framework, three innovative prediction models are
formulated. A sequence-aware graph neural network is proposed and integrated
into the Gated Recurrent Unit (GRU) to learn non-fixed graphs at different time
steps and capture local temporal relationships. To enhance the model's global
perception, three distinct global spatial-temporal transformer-like
architectures (GST^2) are devised for the global awareness layer. We conduct
extensive experiments on four real traffic datasets and the results demonstrate
the superiority of our framework and the three concrete models.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04136" title="Abstract">arXiv:2401.04136</a> [<a href="/pdf/2401.04136" title="Download PDF">pdf</a>, <a href="/format/2401.04136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Stronger the Diffusion Model, the Easier the Backdoor: Data  Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Q">Qianli Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Y">Yao Tong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This study reveals that by subtly inserting non-copyright-infringing poisoning data into a diffusion model's training dataset, it's possible to trigger the model to generate copyrighted content, highlighting vulnerabilities in current copyright protection strategies
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The commercialization of diffusion models, renowned for their ability to
generate high-quality images that are often indistinguishable from real ones,
brings forth potential copyright concerns. Although attempts have been made to
impede unauthorized access to copyrighted material during training and to
subsequently prevent DMs from generating copyrighted images, the effectiveness
of these solutions remains unverified. This study explores the vulnerabilities
associated with copyright protection in DMs by introducing a backdoor data
poisoning attack (SilentBadDiffusion) against text-to-image diffusion models.
Our attack method operates without requiring access to or control over the
diffusion model's training or fine-tuning processes; it merely involves the
insertion of poisoning data into the clean training dataset. This data,
comprising poisoning images equipped with prompts, is generated by leveraging
the powerful capabilities of multimodal large language models and text-guided
image inpainting techniques. Our experimental results and analysis confirm the
method's effectiveness. By integrating a minor portion of
non-copyright-infringing stealthy poisoning data into the clean
dataset-rendering it free from suspicion-we can prompt the finetuned diffusion
models to produce copyrighted content when activated by specific trigger
prompts. These findings underline potential pitfalls in the prevailing
copyright protection strategies and underscore the necessity for increased
scrutiny and preventative measures against the misuse of DMs.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04138" title="Abstract">arXiv:2401.04138</a> [<a href="/pdf/2401.04138" title="Download PDF">pdf</a>, <a href="/format/2401.04138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expanding Horizons in HCI Research Through LLM-Driven Qualitative  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torii%2C+M+G">Maya Grace Torii</a>, 
<a href="/search/cs?searchtype=author&query=Murakami%2C+T">Takahito Murakami</a>, 
<a href="/search/cs?searchtype=author&query=Ochiai%2C+Y">Yoichi Ochiai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">How would research be like if we still needed to "send" papers typed with a
typewriter? Our life and research environment have continually evolved, often
accompanied by controversial opinions about new methodologies. In this paper,
we embrace this change by introducing a new approach to qualitative analysis in
HCI using Large Language Models (LLMs). We detail a method that uses LLMs for
qualitative data analysis and present a quantitative framework using SBART
cosine similarity for performance evaluation. Our findings indicate that LLMs
not only match the efficacy of traditional analysis methods but also offer
unique insights. Through a novel dataset and benchmark, we explore LLMs'
characteristics in HCI research, suggesting potential avenues for further
exploration and application in the field.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04139" title="Abstract">arXiv:2401.04139</a> [<a href="/pdf/2401.04139" title="Download PDF">pdf</a>, <a href="/ps/2401.04139" title="Download PostScript">ps</a>, <a href="/format/2401.04139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CCNETS: A Novel Brain-Inspired Approach for Enhanced Pattern Recognition  in Imbalanced Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hanbeot Park</a> (1), 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Yunjeong Cho</a> (2), 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hoon-Hee Kim</a> (3)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, authors (3) is Corresponding Author
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study introduces CCNETS (Causal Learning with Causal Cooperative Nets),
a novel generative model-based classifier designed to tackle the challenge of
generating data for imbalanced datasets in pattern recognition. CCNETS is
uniquely crafted to emulate brain-like information processing and comprises
three main components: Explainer, Producer, and Reasoner. Each component is
designed to mimic specific brain functions, which aids in generating
high-quality datasets and enhancing classification performance.
<br />The model is particularly focused on addressing the common and significant
challenge of handling imbalanced datasets in machine learning. CCNETS's
effectiveness is demonstrated through its application to a "fraud dataset,"
where normal transactions significantly outnumber fraudulent ones (99.83% vs.
0.17%). Traditional methods often struggle with such imbalances, leading to
skewed performance metrics. However, CCNETS exhibits superior classification
ability, as evidenced by its performance metrics. Specifically, it achieved an
F1-score of 0.7992, outperforming traditional models like Autoencoders and
Multi-layer Perceptrons (MLP) in the same context. This performance indicates
CCNETS's proficiency in more accurately distinguishing between normal and
fraudulent patterns.
<br />The innovative structure of CCNETS enhances the coherence between generative
and classification models, helping to overcome the limitations of pattern
recognition that rely solely on generative models. This study emphasizes
CCNETS's potential in diverse applications, especially where quality data
generation and pattern recognition are key. It proves effective in machine
learning, particularly for imbalanced datasets. CCNETS overcomes current
challenges in these datasets and advances machine learning with brain-inspired
approaches.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04141" title="Abstract">arXiv:2401.04141</a> [<a href="/pdf/2401.04141" title="Download PDF">pdf</a>, <a href="/format/2401.04141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Potential of The Fractal Geometry and The CNNs Ability to Encode  it
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zini%2C+J+E">Julia El Zini</a>, 
<a href="/search/cs?searchtype=author&query=Musharrafieh%2C+B">Bassel Musharrafieh</a>, 
<a href="/search/cs?searchtype=author&query=Awad%2C+M">Mariette Awad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The fractal dimension provides a statistical index of object complexity by
studying how the pattern changes with the measuring scale. Although useful in
several classification tasks, the fractal dimension is under-explored in deep
learning applications. In this work, we investigate the features that are
learned by deep models and we study whether these deep networks are able to
encode features as complex and high-level as the fractal dimensions.
Specifically, we conduct a correlation analysis experiment to show that deep
networks are not able to extract such a feature in none of their layers. We
combine our analytical study with a human evaluation to investigate the
differences between deep learning networks and models that operate on the
fractal feature solely. Moreover, we show the effectiveness of fractal features
in applications where the object structure is crucial for the classification
task. We empirically show that training a shallow network on fractal features
achieves performance comparable, even superior in specific cases, to that of
deep networks trained on raw data while requiring less computational resources.
Fractals improved the accuracy of the classification by 30% on average while
requiring up to 84% less time to train. We couple our empirical study with a
complexity analysis of the computational cost of extracting the proposed
fractal features, and we study its limitation.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04143" title="Abstract">arXiv:2401.04143</a> [<a href="/pdf/2401.04143" title="Download PDF">pdf</a>, <a href="/format/2401.04143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RHOBIN Challenge: Reconstruction of Human Object Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xianghui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Athanasiou%2C+N">Nikos Athanasiou</a>, 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+B+L">Bharat Lal Bhatnagar</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C+P">Chun-Hao P. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+K">Kaichun Mo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xia Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zerui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Liangxian Cui</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+B">Bingqiao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jie Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+H">Hyeongjin Nam</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+D+S">Daniel Sungho Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kihoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+M">Kyoung Mu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>, 
<a href="/search/cs?searchtype=author&query=Pons-Moll%2C+G">Gerard Pons-Moll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 tables, 7 figure. Technical report of the CVPR'23 workshop: RHOBIN challenge (<a href="https://rhobin-challenge.github.io/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Modeling the interaction between humans and objects has been an emerging
research direction in recent years. Capturing human-object interaction is
however a very challenging task due to heavy occlusion and complex dynamics,
which requires understanding not only 3D human pose, and object pose but also
the interaction between them. Reconstruction of 3D humans and objects has been
two separate research fields in computer vision for a long time. We hence
proposed the first RHOBIN challenge: reconstruction of human-object
interactions in conjunction with the RHOBIN workshop. It was aimed at bringing
the research communities of human and object reconstruction as well as
interaction modeling together to discuss techniques and exchange ideas. Our
challenge consists of three tracks of 3D reconstruction from monocular RGB
images with a focus on dealing with challenging interaction scenarios. Our
challenge attracted more than 100 participants with more than 300 submissions,
indicating the broad interest in the research communities. This paper describes
the settings of our challenge and discusses the winning methods of each track
in more detail. We observe that the human reconstruction task is becoming
mature even under heavy occlusion settings while object pose estimation and
joint reconstruction remain challenging tasks. With the growing interest in
interaction modeling, we hope this report can provide useful insights and
foster future research in this direction. Our workshop website can be found at
\href{https://rhobin-challenge.github.io/}{https://rhobin-challenge.github.io/}.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04144" title="Abstract">arXiv:2401.04144</a> [<a href="/pdf/2401.04144" title="Download PDF">pdf</a>, <a href="/format/2401.04144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Calibration For Improved Weather Prediction Under Distributional  Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gilda%2C+S">Sankalp Gilda</a>, 
<a href="/search/cs?searchtype=author&query=Bhandari%2C+N">Neel Bhandari</a>, 
<a href="/search/cs?searchtype=author&query=Mak%2C+W">Wendy Mak</a>, 
<a href="/search/cs?searchtype=author&query=Panizza%2C+A">Andrea Panizza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Bayesian Deep Learning workshop at NeurIPS 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we present results on improving out-of-domain weather
prediction and uncertainty estimation as part of the \texttt{Shifts Challenge
on Robustness and Uncertainty under Real-World Distributional Shift} challenge.
We find that by leveraging a mixture of experts in conjunction with an advanced
data augmentation technique borrowed from the computer vision domain, in
conjunction with robust \textit{post-hoc} calibration of predictive
uncertainties, we can potentially achieve more accurate and better-calibrated
results with deep neural networks than with boosted tree models for tabular
data. We quantify our predictions using several metrics and propose several
future lines of inquiry and experimentation to boost performance.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04145" title="Abstract">arXiv:2401.04145</a> [<a href="/pdf/2401.04145" title="Download PDF">pdf</a>, <a href="/format/2401.04145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn Once Plan Arbitrarily (LOPA): Attention-Enhanced Deep  Reinforcement Learning Method for Global Path Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guoming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+M">Mingxin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaofang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shuqiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaonan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Deep reinforcement learning (DRL) methods have recently shown promise in path
planning tasks. However, when dealing with global planning tasks, these methods
face serious challenges such as poor convergence and generalization. To this
end, we propose an attention-enhanced DRL method called LOPA (Learn Once Plan
Arbitrarily) in this paper. Firstly, we analyze the reasons of these problems
from the perspective of DRL's observation, revealing that the traditional
design causes DRL to be interfered by irrelevant map information. Secondly, we
develop the LOPA which utilizes a novel attention-enhanced mechanism to attain
an improved attention capability towards the key information of the
observation. Such a mechanism is realized by two steps: (1) an attention model
is built to transform the DRL's observation into two dynamic views: local and
global, significantly guiding the LOPA to focus on the key information on the
given maps; (2) a dual-channel network is constructed to process these two
views and integrate them to attain an improved reasoning capability. The LOPA
is validated via multi-objective global path planning experiments. The result
suggests the LOPA has improved convergence and generalization performance as
well as great path planning efficiency.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04148" title="Abstract">arXiv:2401.04148</a> [<a href="/pdf/2401.04148" title="Download PDF">pdf</a>, <a href="/format/2401.04148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Test-Time Adaptation of Spatial-Temporal Traffic Flow Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pengxin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Pengrong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Accurate spatial-temporal traffic flow forecasting is crucial in aiding
traffic managers in implementing control measures and assisting drivers in
selecting optimal travel routes. Traditional deep-learning based methods for
traffic flow forecasting typically rely on historical data to train their
models, which are then used to make predictions on future data. However, the
performance of the trained model usually degrades due to the temporal drift
between the historical and future data. To make the model trained on historical
data better adapt to future data in a fully online manner, this paper conducts
the first study of the online test-time adaptation techniques for
spatial-temporal traffic flow forecasting problems. To this end, we propose an
Adaptive Double Correction by Series Decomposition (ADCSD) method, which first
decomposes the output of the trained model into seasonal and trend-cyclical
parts and then corrects them by two separate modules during the testing phase
using the latest observed data entry by entry. In the proposed ADCSD method,
instead of fine-tuning the whole trained model during the testing phase, a lite
network is attached after the trained model, and only the lite network is
fine-tuned in the testing process each time a data entry is observed. Moreover,
to satisfy that different time series variables may have different levels of
temporal drift, two adaptive vectors are adopted to provide different weights
for different time series variables. Extensive experiments on four real-world
traffic flow forecasting datasets demonstrate the effectiveness of the proposed
ADCSD method. The code is available at https://github.com/Pengxin-Guo/ADCSD.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04150" title="Abstract">arXiv:2401.04150</a> [<a href="/pdf/2401.04150" title="Download PDF">pdf</a>, <a href="/format/2401.04150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-stream joint matching method based on contrastive learning for  few-shot action recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+L">Long Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bingxin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhongming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yongxin Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although few-shot action recognition based on metric learning paradigm has
achieved significant success, it fails to address the following issues: (1)
inadequate action relation modeling and underutilization of multi-modal
information; (2) challenges in handling video matching problems with different
lengths and speeds, and video matching problems with misalignment of video
sub-actions. To address these issues, we propose a Two-Stream Joint Matching
method based on contrastive learning (TSJM), which consists of two modules:
Multi-modal Contrastive Learning Module (MCL) and Joint Matching Module (JMM).
The objective of the MCL is to extensively investigate the inter-modal mutual
information relationships, thereby thoroughly extracting modal information to
enhance the modeling of action relationships. The JMM aims to simultaneously
address the aforementioned video matching problems. The effectiveness of the
proposed method is evaluated on two widely used few shot action recognition
datasets, namely, SSv2 and Kinetics. Comprehensive ablation experiments are
also conducted to substantiate the efficacy of our proposed approach.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04151" title="Abstract">arXiv:2401.04151</a> [<a href="/pdf/2401.04151" title="Download PDF">pdf</a>, <a href="/format/2401.04151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of LoRA: Efficient Fine-tuning of Language Models via Residual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+W">Wenhan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chengwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Hazan%2C+E">Elad Hazan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Fine-tuning is the primary methodology for tailoring pre-trained large
language models to specific tasks. As the model's scale and the diversity of
tasks expand, parameter-efficient fine-tuning methods are of paramount
importance. One of the most widely used family of methods is low-rank
adaptation (LoRA) and its variants. LoRA encodes weight update as the product
of two low-rank matrices. Despite its advantages, LoRA falls short of
full-parameter fine-tuning in terms of generalization error for certain tasks.
<br />We introduce Chain of LoRA (COLA), an iterative optimization framework
inspired by the Frank-Wolfe algorithm, to bridge the gap between LoRA and full
parameter fine-tuning, without incurring additional computational costs or
memory overheads. COLA employs a residual learning procedure where it merges
learned LoRA modules into the pre-trained language model parameters and
re-initilize optimization for new born LoRA modules. We provide theoretical
convergence guarantees as well as empirical results to validate the
effectiveness of our algorithm. Across various models (OPT and llama-2) and
seven benchmarking tasks, we demonstrate that COLA can consistently outperform
LoRA without additional computational or memory costs.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04152" title="Abstract">arXiv:2401.04152</a> [<a href="/pdf/2401.04152" title="Download PDF">pdf</a>, <a href="/format/2401.04152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Speaker Encoding Network for Multi-Talker Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lingwei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Mingyu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haohan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xunying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">End-to-end multi-talker speech recognition has garnered great interest as an
effective approach to directly transcribe overlapped speech from multiple
speakers. Current methods typically adopt either 1) single-input
multiple-output (SIMO) models with a branched encoder, or 2) single-input
single-output (SISO) models based on attention-based encoder-decoder
architecture with serialized output training (SOT). In this work, we propose a
Cross-Speaker Encoding (CSE) network to address the limitations of SIMO models
by aggregating cross-speaker representations. Furthermore, the CSE model is
integrated with SOT to leverage both the advantages of SIMO and SISO while
mitigating their drawbacks. To the best of our knowledge, this work represents
an early effort to integrate SIMO and SISO for multi-talker speech recognition.
Experiments on the two-speaker LibrispeechMix dataset show that the CES model
reduces word error rate (WER) by 8% over the SIMO baseline. The CSE-SOT model
reduces WER by 10% overall and by 16% on high-overlap speech compared to the
SOT model.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04154" title="Abstract">arXiv:2401.04154</a> [<a href="/pdf/2401.04154" title="Download PDF">pdf</a>, <a href="/ps/2401.04154" title="Download PostScript">ps</a>, <a href="/format/2401.04154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Selective Audio Masked Multimodal Bottleneck Transformer for  Audio-Video Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024; well-formatted PDF is in <a href="https://drive.google.com/file/d/1qvW52lamsvNGMCqPS7q8g8L4NaR_LlbR/view?usp=sharing.">this https URL</a> arXiv admin note: text overlap with <a href="/abs/2401.04023">arXiv:2401.04023</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio and video are two most common modalities in the mainstream media
platforms, e.g., YouTube. To learn from multimodal videos effectively, in this
work, we propose a novel audio-video recognition approach termed audio video
Transformer, AVT, leveraging the effective spatio-temporal representation by
the video Transformer to improve action recognition accuracy. For multimodal
fusion, simply concatenating multimodal tokens in a cross-modal Transformer
requires large computational and memory resources, instead we reduce the
cross-modality complexity through an audio-video bottleneck Transformer. To
improve the learning efficiency of multimodal Transformer, we integrate
self-supervised objectives, i.e., audio-video contrastive learning, audio-video
matching, and masked audio and video learning, into AVT training, which maps
diverse audio and video representations into a common multimodal representation
space. We further propose a masked audio segment loss to learn semantic audio
activities in AVT. Extensive experiments and ablation studies on three public
datasets and two in-house datasets consistently demonstrate the effectiveness
of the proposed AVT. Specifically, AVT outperforms its previous
state-of-the-art counterparts on Kinetics-Sounds by 8%. AVT also surpasses one
of the previous state-of-the-art video Transformers [25] by 10% on VGGSound by
leveraging the audio signal. Compared to one of the previous state-of-the-art
multimodal methods, MBT [32], AVT is 1.3% more efficient in terms of FLOPs and
improves the accuracy by 3.8% on Epic-Kitchens-100.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04157" title="Abstract">arXiv:2401.04157</a> [<a href="/pdf/2401.04157" title="Download PDF">pdf</a>, <a href="/format/2401.04157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RePLan: Robotic Replanning with Perception and Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skreta%2C+M">Marta Skreta</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J+L">Jia Lin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Darvish%2C+K">Kourosh Darvish</a>, 
<a href="/search/cs?searchtype=author&query=Aspuru-Guzik%2C+A">Al&#xe1;n Aspuru-Guzik</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Animesh Garg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Advancements in large language models (LLMs) have demonstrated their
potential in facilitating high-level reasoning, logical reasoning and robotics
planning. Recently, LLMs have also been able to generate reward functions for
low-level robot actions, effectively bridging the interface between high-level
planning and low-level robot control. However, the challenge remains that even
with syntactically correct plans, robots can still fail to achieve their
intended goals. This failure can be attributed to imperfect plans proposed by
LLMs or to unforeseeable environmental circumstances that hinder the execution
of planned subtasks due to erroneous assumptions about the state of objects.
One way to prevent these challenges is to rely on human-provided step-by-step
instructions, limiting the autonomy of robotic systems. Vision Language Models
(VLMs) have shown remarkable success in tasks such as visual question answering
and image captioning. Leveraging the capabilities of VLMs, we present a novel
framework called Robotic Replanning with Perception and Language Models
(RePLan) that enables real-time replanning capabilities for long-horizon tasks.
This framework utilizes the physical grounding provided by a VLM's
understanding of the world's state to adapt robot actions when the initial plan
fails to achieve the desired goal. We test our approach within four
environments containing seven long-horizion tasks. We find that RePLan enables
a robot to successfully adapt to unforeseen obstacles while accomplishing
open-ended, long-horizon goals, where baseline models cannot. Find more
information at https://replan-lm.github.io/replan.github.io/
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04181" title="Abstract">arXiv:2401.04181</a> [<a href="/pdf/2401.04181" title="Download PDF">pdf</a>, <a href="/format/2401.04181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Conditioned Robotic Manipulation with Fast and Slow Thinking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinming Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Junjie Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+Z">Zhengping Che</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chaomin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yaxin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Feifei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The language-conditioned robotic manipulation aims to transfer natural
language instructions into executable actions, from simple pick-and-place to
tasks requiring intent recognition and visual reasoning. Inspired by the dual
process theory in cognitive science, which suggests two parallel systems of
fast and slow thinking in human decision-making, we introduce Robotics with
Fast and Slow Thinking (RFST), a framework that mimics human cognitive
architecture to classify tasks and makes decisions on two systems based on
instruction types. Our RFST consists of two key components: 1) an instruction
discriminator to determine which system should be activated based on the
current user instruction, and 2) a slow-thinking system that is comprised of a
fine-tuned vision language model aligned with the policy networks, which allows
the robot to recognize user intention or perform reasoning tasks. To assess our
methodology, we built a dataset featuring real-world trajectories, capturing
actions ranging from spontaneous impulses to tasks requiring deliberate
contemplation. Our results, both in simulation and real-world scenarios,
confirm that our approach adeptly manages intricate tasks that demand intent
recognition and reasoning. The project is available at
https://jlm-z.github.io/RSFT/
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04192" title="Abstract">arXiv:2401.04192</a> [<a href="/pdf/2401.04192" title="Download PDF">pdf</a>, <a href="/ps/2401.04192" title="Download PostScript">ps</a>, <a href="/format/2401.04192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Multi-Objective Evolutionary Optimization of Software  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ram%C3%ADrez%2C+A">Aurora Ram&#xed;rez</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+J+R">Jos&#xe9; Ra&#xfa;l Romero</a>, 
<a href="/search/cs?searchtype=author&query=Ventura%2C+S">Sebasti&#xe1;n Ventura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 5 figures, journal "Information Sciences"
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information Sciences, vol. 463-464, pp. 92-109, 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">While working on a software specification, designers usually need to evaluate
different architectural alternatives to be sure that quality criteria are met.
Even when these quality aspects could be expressed in terms of multiple
software metrics, other qualitative factors cannot be numerically measured, but
they are extracted from the engineer's know-how and prior experiences. In fact,
detecting not only strong but also weak points in the different solutions seems
to fit better with the way humans make their decisions. Putting the human in
the loop brings new challenges to the search-based software engineering field,
especially for those human-centered activities within the early analysis phase.
This paper explores how the interactive evolutionary computation can serve as a
basis for integrating the human's judgment into the search process. An
interactive approach is proposed to discover software architectures, in which
both quantitative and qualitative criteria are applied to guide a
multi-objective evolutionary algorithm. The obtained feedback is incorporated
into the fitness function using architectural preferences allowing the
algorithm to discern between promising and poor solutions. Experimentation with
real users has revealed that the proposed interaction mechanism can effectively
guide the search towards those regions of the search space that are of real
interest to the expert.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04196" title="Abstract">arXiv:2401.04196</a> [<a href="/pdf/2401.04196" title="Download PDF">pdf</a>, <a href="/format/2401.04196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetric-conjugate splitting methods for evolution equations of  parabolic type
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Blanes%2C+S">Sergio Blanes</a>, 
<a href="/search/math?searchtype=author&query=Casas%2C+F">Fernando Casas</a>, 
<a href="/search/math?searchtype=author&query=Gonz%C3%A1lez%2C+C">Ces&#xe1;reo Gonz&#xe1;lez</a>, 
<a href="/search/math?searchtype=author&query=Thalhammer%2C+M">Mechthild Thalhammer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper to be published in Journal of Computational Dynamics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">The present work provides a comprehensive study of symmetric-conjugate
operator splitting methods in the context of linear parabolic problems and
demonstrates their additional benefits compared to symmetric splitting methods.
Relevant applications include nonreversible systems and ground state
computations for linear Schr\"odinger equations based on the imaginary time
propagation. Numerical examples confirm the favourable error behaviour of
higher-order symmetric-conjugate splitting methods and illustrate the
usefulness of a time stepsize control, where the local error estimation relies
on the computation of the imaginary parts and thus requires negligible costs.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04198" title="Abstract">arXiv:2401.04198</a> [<a href="/pdf/2401.04198" title="Download PDF">pdf</a>, <a href="/format/2401.04198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curiosity &amp; Entropy Driven Unsupervised RL in Multiple Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dewan%2C+S">Shaurya Dewan</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Anisha Jain</a>, 
<a href="/search/cs?searchtype=author&query=LaLena%2C+Z">Zoe LaLena</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lifan Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The authors of 'Unsupervised Reinforcement Learning in Multiple environments'
propose a method, alpha-MEPOL, to tackle unsupervised RL across multiple
environments. They pre-train a task-agnostic exploration policy using
interactions from an entire environment class and then fine-tune this policy
for various tasks using supervision. We expanded upon this work, with the goal
of improving performance. We primarily propose and experiment with five new
modifications to the original work: sampling trajectories using an
entropy-based probability distribution, dynamic alpha, higher KL Divergence
threshold, curiosity-driven exploration, and alpha-percentile sampling on
curiosity. Dynamic alpha and higher KL-Divergence threshold both provided a
significant improvement over the baseline from the earlier work. PDF-sampling
failed to provide any improvement due to it being approximately equivalent to
the baseline method when the sample space is small. In high-dimensional
environments, the addition of curiosity-driven exploration enhances learning by
encouraging the agent to seek diverse experiences and explore the unknown more.
However, its benefits are limited in low-dimensional and simpler environments
where exploration possibilities are constrained and there is little that is
truly unknown to the agent. Overall, some of our experiments did boost
performance over the baseline and there are a few directions that seem
promising for further research.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04206" title="Abstract">arXiv:2401.04206</a> [<a href="/pdf/2401.04206" title="Download PDF">pdf</a>, <a href="/format/2401.04206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Racing From an AI Coach: Effects of Multimodal Autonomous  Driving Explanations on Driving Performance, Cognitive Load, Expertise, and  Trust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaufman%2C+R">Robert Kaufman</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+J">Jean Costa</a>, 
<a href="/search/cs?searchtype=author&query=Kimani%2C+E">Everlyne Kimani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">In a pre-post experiment (n = 41), we test the impact of an AI Coach's
explanatory communications modeled after the instructions of human driving
experts. Participants were divided into four (4) groups to assess two (2)
dimensions of the AI coach's explanations: information type ('what' and
'why'-type explanations) and presentation modality (auditory and visual). We
directly compare how AI Coaching sessions employing these techniques impact
driving performance, cognitive load, confidence, expertise, and trust in an
observation learning context. Through interviews, we delineate the learning
process of our participants. Results show that an AI driving coach can be
useful for teaching performance driving skills to novices. Comparing between
groups, we find the type and modality of information influences performance
outcomes. We attribute differences to how information directed attention,
mitigated uncertainty, and influenced overload experienced by participants.
These, in turn, affected how successfully participants were able to learn.
Results suggest efficient, modality-appropriate explanations should be opted
for when designing effective HMI communications that can instruct without
overwhelming. Further, they support the need to align communications with human
learning and cognitive processes. Results are synthesized into eight design
implications for future autonomous vehicle HMI and AI coach design.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04210" title="Abstract">arXiv:2401.04210</a> [<a href="/pdf/2401.04210" title="Download PDF">pdf</a>, <a href="/format/2401.04210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FunnyNet-W: Multimodal Learning of Funny Moments in Videos in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhi-Song Liu</a>, 
<a href="/search/cs?searchtype=author&query=Courant%2C+R">Robin Courant</a>, 
<a href="/search/cs?searchtype=author&query=Kalogeiton%2C+V">Vicky Kalogeiton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automatically understanding funny moments (i.e., the moments that make people
laugh) when watching comedy is challenging, as they relate to various features,
such as body language, dialogues and culture. In this paper, we propose
FunnyNet-W, a model that relies on cross- and self-attention for visual, audio
and text data to predict funny moments in videos. Unlike most methods that rely
on ground truth data in the form of subtitles, in this work we exploit
modalities that come naturally with videos: (a) video frames as they contain
visual information indispensable for scene understanding, (b) audio as it
contains higher-level cues associated with funny moments, such as intonation,
pitch and pauses and (c) text automatically extracted with a speech-to-text
model as it can provide rich information when processed by a Large Language
Model. To acquire labels for training, we propose an unsupervised approach that
spots and labels funny audio moments. We provide experiments on five datasets:
the sitcoms TBBT, MHD, MUStARD, Friends, and the TED talk UR-Funny. Extensive
experiments and analysis show that FunnyNet-W successfully exploits visual,
auditory and textual cues to identify funny moments, while our findings reveal
FunnyNet-W's ability to predict funny moments in the wild. FunnyNet-W sets the
new state of the art for funny moment detection with multimodal cues on all
datasets with and without using ground truth information.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04218" title="Abstract">arXiv:2401.04218</a> [<a href="/pdf/2401.04218" title="Download PDF">pdf</a>, <a href="/ps/2401.04218" title="Download PostScript">ps</a>, <a href="/format/2401.04218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distortions in Judged Spatial Relations in Large Language Models: The  Dawn of Natural Language Geographic Data?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fulman%2C+N">Nir Fulman</a>, 
<a href="/search/cs?searchtype=author&query=Memduho%C4%9Flu%2C+A">Abdulkadir Memduho&#x11f;lu</a>, 
<a href="/search/cs?searchtype=author&query=Zipf%2C+A">Alexander Zipf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present a benchmark for assessing the capability of Large Language Models
(LLMs) to discern intercardinal directions between geographic locations and
apply it to three prominent LLMs: GPT-3.5, GPT-4, and Llama-2. This benchmark
specifically evaluates whether LLMs exhibit a hierarchical spatial bias similar
to humans, where judgments about individual locations' spatial relationships
are influenced by the perceived relationships of the larger groups that contain
them. To investigate this, we formulated 14 questions focusing on well-known
American cities. Seven questions were designed to challenge the LLMs with
scenarios potentially influenced by the orientation of larger geographical
units, such as states or countries, while the remaining seven targeted
locations less susceptible to such hierarchical categorization. Among the
tested models, GPT-4 exhibited superior performance with 55.3% accuracy,
followed by GPT-3.5 at 47.3%, and Llama-2 at 44.7%. The models showed
significantly reduced accuracy on tasks with suspected hierarchical bias. For
example, GPT-4's accuracy dropped to 32.9% on these tasks, compared to 85.7% on
others. Despite these inaccuracies, the models identified the nearest cardinal
direction in most cases, suggesting associative learning, embodying human-like
misconceptions. We discuss the potential of text-based data representing
geographic relationships directly to improve the spatial reasoning capabilities
of LLMs.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04221" title="Abstract">arXiv:2401.04221</a> [<a href="/pdf/2401.04221" title="Download PDF">pdf</a>, <a href="/ps/2401.04221" title="Download PostScript">ps</a>, <a href="/format/2401.04221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RaceFixer -- An Automated Data Race Fixer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malakar%2C+S">Sanjay Malakar</a>, 
<a href="/search/cs?searchtype=author&query=Haider%2C+T+B">Tameem Bin Haider</a>, 
<a href="/search/cs?searchtype=author&query=Shahriar%2C+R">Rifat Shahriar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Fixing software bugs has always been an essential and time-consuming process
in software development. Fixing concurrency bugs has become especially critical
in the multicore era. However, fixing concurrency bugs is challenging due to
non-deterministic failures and tricky parallel reasoning. Beyond correctly
fixing the original problem in the software, a good patch should also avoid
introducing new bugs, degrading performance unnecessarily, or damaging software
readability. Existing tools cannot automate the whole fixing process and
provide good-quality patches. We present RaceFixer, a tool that automates the
process of fixing one common type of concurrency bug: single-variable atomicity
violations. RaceFixer starts from the bug reports of an existing bug-detection
tool ThreadSanitizer. It augments these with static analysis to construct a
suitable patch for each bug report. It tries to combine the patches of multiple
bugs for better performance and code readability. Finally, we test RaceFixer on
benchmarks from TheadSanitizer.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04226" title="Abstract">arXiv:2401.04226</a> [<a href="/pdf/2401.04226" title="Download PDF">pdf</a>, <a href="/format/2401.04226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Multi-Topology Routing for QoS Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huin%2C+N">Nicolas Huin</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+S">S&#xe9;bastien Martin</a>, 
<a href="/search/cs?searchtype=author&query=Leguay%2C+J">J&#xe9;r&#xe9;mie Leguay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE/IFIP NOMS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Multi-topology routing (MTR) provides an attractive alternative to segment
routing for traffic engineering when network devices cannot be upgraded.
However, due to a high overhead in terms of link state messages exchanged by
topologies and the need to frequently update link weights to follow evolving
network conditions, MTR is often limited to a small number of topologies and
the satisfaction of loose QoS constraints. To overcome these limitations we
propose vMTR, an MTR extension where demands are routed over virtual topologies
that are silent, i.e., they do not exchange LSA messages, and that are
continuously derived from a very limited set of real topologies, optimizing
each a QoS parameter. In this context, we present a polynomial and exact
algorithm for vMTR and, as a benchmark, a local search algorithm for MTR. We
show that vMTR helps reducing drastically the number of real topologies and
that it is more robust to QoS changes.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04230" title="Abstract">arXiv:2401.04230</a> [<a href="/pdf/2401.04230" title="Download PDF">pdf</a>, <a href="/format/2401.04230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SOAP: Cross-sensor Domain Adaptation for 3D Object Detection Using  Stationary Object Aggregation Pseudo-labelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Abdelzad%2C+V">Vahdat Abdelzad</a>, 
<a href="/search/cs?searchtype=author&query=Sedwards%2C+S">Sean Sedwards</a>, 
<a href="/search/cs?searchtype=author&query=Czarnecki%2C+K">Krzysztof Czarnecki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We consider the problem of cross-sensor domain adaptation in the context of
LiDAR-based 3D object detection and propose Stationary Object Aggregation
Pseudo-labelling (SOAP) to generate high quality pseudo-labels for stationary
objects. In contrast to the current state-of-the-art in-domain practice of
aggregating just a few input scans, SOAP aggregates entire sequences of point
clouds at the input level to reduce the sensor domain gap. Then, by means of
what we call quasi-stationary training and spatial consistency post-processing,
the SOAP model generates accurate pseudo-labels for stationary objects, closing
a minimum of 30.3% domain gap compared to few-frame detectors. Our results also
show that state-of-the-art domain adaptation approaches can achieve even
greater performance in combination with SOAP, in both the unsupervised and
semi-supervised settings.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04235" title="Abstract">arXiv:2401.04235</a> [<a href="/pdf/2401.04235" title="Download PDF">pdf</a>, <a href="/format/2401.04235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-precision Voice Search Query Correction via Retrievable Speech-text  Embedings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Christopher Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gary Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kastner%2C+K">Kyle Kastner</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Heng Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Allen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rosenberg%2C+A">Andrew Rosenberg</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhehuai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zelin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Velikovich%2C+L">Leonid Velikovich</a>, 
<a href="/search/cs?searchtype=author&query=Rondon%2C+P">Pat Rondon</a>, 
<a href="/search/cs?searchtype=author&query=Caseiro%2C+D">Diamantino Caseiro</a>, 
<a href="/search/cs?searchtype=author&query=Aleksic%2C+P">Petar Aleksic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automatic speech recognition (ASR) systems can suffer from poor recall for
various reasons, such as noisy audio, lack of sufficient training data, etc.
<br />Previous work has shown that recall can be improved by retrieving rewrite
candidates from a large database of likely, contextually-relevant alternatives
to the hypothesis text using nearest-neighbors search over embeddings of the
ASR hypothesis text to correct and candidate corrections.
<br />However, ASR-hypothesis-based retrieval can yield poor precision if the
textual hypotheses are too phonetically dissimilar to the transcript truth. In
this paper, we eliminate the hypothesis-audio mismatch problem by querying the
correction database directly using embeddings derived from the utterance audio;
the embeddings of the utterance audio and candidate corrections are produced by
multimodal speech-text embedding networks trained to place the embedding of the
audio of an utterance and the embedding of its corresponding textual transcript
close together.
<br />After locating an appropriate correction candidate using nearest-neighbor
search, we score the candidate with its speech-text embedding distance before
adding the candidate to the original n-best list.
<br />We show a relative word error rate (WER) reduction of 6% on utterances whose
transcripts appear in the candidate set, without increasing WER on general
utterances.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04241" title="Abstract">arXiv:2401.04241</a> [<a href="/pdf/2401.04241" title="Download PDF">pdf</a>, <a href="/format/2401.04241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Agnostic Face Image Synthesis Detection Using Bayesian CNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leyva%2C+R">Roberto Leyva</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+V">Victor Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Epiphaniou%2C+G">Gregory Epiphaniou</a>, 
<a href="/search/cs?searchtype=author&query=Maple%2C+C">Carsten Maple</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face image synthesis detection is considerably gaining attention because of
the potential negative impact on society that this type of synthetic data
brings. In this paper, we propose a data-agnostic solution to detect the face
image synthesis process. Specifically, our solution is based on an anomaly
detection framework that requires only real data to learn the inference
process. It is therefore data-agnostic in the sense that it requires no
synthetic face images. The solution uses the posterior probability with respect
to the reference data to determine if new samples are synthetic or not. Our
evaluation results using different synthesizers show that our solution is very
competitive against the state-of-the-art, which requires synthetic data for
training.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04246" title="Abstract">arXiv:2401.04246</a> [<a href="/pdf/2401.04246" title="Download PDF">pdf</a>, <a href="/format/2401.04246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Normalizing Flows Enable Boltzmann Generators for  Macromolecules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+C">Joseph C. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bloore%2C+D">David Bloore</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+K">Karan Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jun Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+M">Ming-Hong Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengdi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">The Boltzmann distribution of a protein provides a roadmap to all of its
functional states. Normalizing flows are a promising tool for modeling this
distribution, but current methods are intractable for typical pharmacological
targets; they become computationally intractable due to the size of the system,
heterogeneity of intra-molecular potential energy, and long-range interactions.
To remedy these issues, we present a novel flow architecture that utilizes
split channels and gated attention to efficiently learn the conformational
distribution of proteins defined by internal coordinates. We show that by
utilizing a 2-Wasserstein loss, one can smooth the transition from maximum
likelihood training to energy-based training, enabling the training of
Boltzmann Generators for macromolecules. We evaluate our model and training
strategy on villin headpiece HP35(nle-nle), a 35-residue subdomain, and protein
G, a 56-residue protein. We demonstrate that standard architectures and
training strategies, such as maximum likelihood alone, fail while our novel
architecture and multi-stage training strategy are able to model the
conformational distributions of protein G and HP35.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04247" title="Abstract">arXiv:2401.04247</a> [<a href="/pdf/2401.04247" title="Download PDF">pdf</a>, <a href="/format/2401.04247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Image Watermarking using Stable Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+A+V">Antoni Viros Martin</a>, 
<a href="/search/cs?searchtype=author&query=Bearfield%2C+C+X">Cindy Xiong Bearfield</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+Y">Yuriy Brun</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Hui Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Watermarking images is critical for tracking image provenance and claiming
ownership. With the advent of generative models, such as stable diffusion, able
to create fake but realistic images, watermarking has become particularly
important, e.g., to make generated images reliably identifiable. Unfortunately,
the very same stable diffusion technology can remove watermarks injected using
existing methods. To address this problem, we present a ZoDiac, which uses a
pre-trained stable diffusion model to inject a watermark into the trainable
latent space, resulting in watermarks that can be reliably detected in the
latent vector, even when attacked. We evaluate ZoDiac on three benchmarks,
MS-COCO, DiffusionDB, and WikiArt, and find that ZoDiac is robust against
state-of-the-art watermark attacks, with a watermark detection rate over 98%
and a false positive rate below 6.4%, outperforming state-of-the-art
watermarking methods. Our research demonstrates that stable diffusion is a
promising approach to robust watermarking, able to withstand even
stable-diffusion-based attacks.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04248" title="Abstract">arXiv:2401.04248</a> [<a href="/pdf/2401.04248" title="Download PDF">pdf</a>, <a href="/ps/2401.04248" title="Download PostScript">ps</a>, <a href="/format/2401.04248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniform Distribution on $(n-1)$-Sphere: Rate-Distortion under Squared  Error Distortion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dytso%2C+A">Alex Dytso</a>, 
<a href="/search/cs?searchtype=author&query=Cardone%2C+M">Martina Cardone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper investigates the rate-distortion function, under a squared error
distortion $D$, for an $n$-dimensional random vector uniformly distributed on
an $(n-1)$-sphere of radius $R$. First, an expression for the rate-distortion
function is derived for any values of $n$, $D$, and $R$. Second, two types of
asymptotics with respect to the rate-distortion function of a Gaussian source
are characterized. More specifically, these asymptotics concern the
low-distortion regime (that is, $D \to 0$) and the high-dimensional regime
(that is, $n \to \infty$).
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04249" title="Abstract">arXiv:2401.04249</a> [<a href="/pdf/2401.04249" title="Download PDF">pdf</a>, <a href="/format/2401.04249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A DEIM Tucker Tensor Cross Algorithm and its Application to Dynamical  Low-Rank Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ghahremani%2C+B">Behzad Ghahremani</a>, 
<a href="/search/math?searchtype=author&query=Babaee%2C+H">Hessam Babaee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We introduce a Tucker tensor cross approximation method that constructs a
low-rank representation of a $d$-dimensional tensor by sparsely sampling its
fibers. These fibers are selected using the discrete empirical interpolation
method (DEIM). Our proposed algorithm is referred to as DEIM fiber sampling
(DEIM-FS). For a rank-$r$ approximation of an $\mathcal{O}(N^d)$ tensor,
DEIM-FS requires access to only $dNr^{d-1}$ tensor entries, a requirement that
scales linearly with the tensor size along each mode. We demonstrate that
DEIM-FS achieves an approximation accuracy close to the Tucker-tensor
approximation obtained via higher-order singular value decomposition at a
significantly reduced cost. We also present DEIM-FS (iterative) that does not
require access to singular vectors of the target tensor unfolding and can be
viewed as a black-box Tucker tensor algorithm. We employ DEIM-FS to reduce the
computational cost associated with solving nonlinear tensor differential
equations (TDEs) using dynamical low-rank approximation (DLRA). The
computational cost of solving DLRA equations can become prohibitive when the
exact rank of the right-hand side tensor is large. This issue arises in many
TDEs, especially in cases involving non-polynomial nonlinearities, where the
right-hand side tensor has full rank. This necessitates the storage and
computation of tensors of size $\mathcal{O}(N^d)$. We show that DEIM-FS results
in significant computational savings for DLRA by constructing a low-rank Tucker
approximation of the right-hand side tensor on the fly. Another advantage of
using DEIM-FS is to significantly simplify the implementation of DLRA
equations, irrespective of the type of TDEs. We demonstrate the efficiency of
the algorithm through several examples including solving high-dimensional
partial differential equations.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04250" title="Abstract">arXiv:2401.04250</a> [<a href="/pdf/2401.04250" title="Download PDF">pdf</a>, <a href="/format/2401.04250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining the Power of Topological Data Analysis in Graph Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taiwo%2C+F+M">Funmilola Mary Taiwo</a>, 
<a href="/search/cs?searchtype=author&query=Islambekov%2C+U">Umar Islambekov</a>, 
<a href="/search/cs?searchtype=author&query=Akcora%2C+C+G">Cuneyt Gurcan Akcora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Topological Data Analysis (TDA) has been praised by researchers for its
ability to capture intricate shapes and structures within data. TDA is
considered robust in handling noisy and high-dimensional datasets, and its
interpretability is believed to promote an intuitive understanding of model
behavior. However, claims regarding the power and usefulness of TDA have only
been partially tested in application domains where TDA-based models are
compared to other graph machine learning approaches, such as graph neural
networks. We meticulously test claims on TDA through a comprehensive set of
experiments and validate their merits. Our results affirm TDA's robustness
against outliers and its interpretability, aligning with proponents' arguments.
However, we find that TDA does not significantly enhance the predictive power
of existing methods in our specific experiments, while incurring significant
computational costs. We investigate phenomena related to graph characteristics,
such as small diameters and high clustering coefficients, to mitigate the
computational expenses of TDA computations. Our results offer valuable
perspectives on integrating TDA into graph machine learning tasks.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04257" title="Abstract">arXiv:2401.04257</a> [<a href="/pdf/2401.04257" title="Download PDF">pdf</a>, <a href="/format/2401.04257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Face Synthesis Using a Concealed Fusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leyva%2C+R">Roberto Leyva</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+V">Victor Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Epiphaniou%2C+G">Gregory Epiphaniou</a>, 
<a href="/search/cs?searchtype=author&query=Maple%2C+C">Carsten Maple</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face image synthesis is gaining more attention in computer security due to
concerns about its potential negative impacts, including those related to fake
biometrics. Hence, building models that can detect the synthesized face images
is an important challenge to tackle. In this paper, we propose a fusion-based
strategy to detect face image synthesis while providing resiliency to several
attacks. The proposed strategy uses a late fusion of the outputs computed by
several undisclosed models by relying on random polynomial coefficients and
exponents to conceal a new feature space. Unlike existing concealing solutions,
our strategy requires no quantization, which helps to preserve the feature
space. Our experiments reveal that our strategy achieves state-of-the-art
performance while providing protection against poisoning, perturbation,
backdoor, and reverse model attacks.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04259" title="Abstract">arXiv:2401.04259</a> [<a href="/pdf/2401.04259" title="Download PDF">pdf</a>, <a href="/format/2401.04259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARG: Multi-Agent Review Generation for Scientific Papers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Arcy%2C+M">Mike D&#x27;Arcy</a>, 
<a href="/search/cs?searchtype=author&query=Hope%2C+T">Tom Hope</a>, 
<a href="/search/cs?searchtype=author&query=Birnbaum%2C+L">Larry Birnbaum</a>, 
<a href="/search/cs?searchtype=author&query=Downey%2C+D">Doug Downey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We study the ability of LLMs to generate feedback for scientific papers and
develop MARG, a feedback generation approach using multiple LLM instances that
engage in internal discussion. By distributing paper text across agents, MARG
can consume the full text of papers beyond the input length limitations of the
base LLM, and by specializing agents and incorporating sub-tasks tailored to
different comment types (experiments, clarity, impact) it improves the
helpfulness and specificity of feedback. In a user study, baseline methods
using GPT-4 were rated as producing generic or very generic comments more than
half the time, and only 1.7 comments per paper were rated as good overall in
the best baseline. Our system substantially improves the ability of GPT-4 to
generate specific and helpful feedback, reducing the rate of generic comments
from 60% to 29% and generating 3.7 good comments per paper (a 2.2x
improvement).
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04261" title="Abstract">arXiv:2401.04261</a> [<a href="/pdf/2401.04261" title="Download PDF">pdf</a>, <a href="/format/2401.04261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Statically and Dynamically Scalable Soft GPGPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Langhammer%2C+M">Martin Langhammer</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+G+A">George A. Constantinides</a> (2) ((1) Intel Corporation, (2) Imperial College London)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Current soft processor architectures for FPGAs do not utilize the potential
of the massive parallelism available. FPGAs now support many thousands of
embedded floating point operators, and have similar computational densities to
GPGPUs. Several soft GPGPU or SIMT processors have been published, but the
reported large areas and modest Fmax makes their widespread use unlikely for
commercial designs. In this paper we take an alternative approach, building the
soft GPU microarchitecture around the FPGA resource mix available. We
demonstrate a statically scalable soft GPGPU processor (where both parameters
and feature set can be determined at configuration time) that always closes
timing at the peak speed of the slowest embedded component in the FPGA (DSP or
hard memory), with a completely unconstrained compile into a current Intel
Agilex FPGA. We also show dynamic scalability, where a subset of the thread
space can be specified on an instruction-by-instruction basis.
<br />For one example core type, we show a logic range -- depending on the
configuration -- of 4k to 10k ALMs, along with 24 to 32 DSP Blocks, and 50 to
250 M20K memories. All of these instances close timing at 771 MHz, a
performance level limited only by the DSP Blocks. We describe our methodology
for reliably achieving this clock rate by matching the processor pipeline
structure to the physical structure of the FPGA fabric. We also benchmark
several algorithms across a range of data sizes, and compare to a commercial
soft RISC processor.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04264" title="Abstract">arXiv:2401.04264</a> [<a href="/pdf/2401.04264" title="Download PDF">pdf</a>, <a href="/ps/2401.04264" title="Download PostScript">ps</a>, <a href="/format/2401.04264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Performance Evaluation for Competitive Resource Allocation Games  via Unseen Payoff Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diamond%2C+N">N&#x27;yoma Diamond</a>, 
<a href="/search/cs?searchtype=author&query=Murai%2C+F">Fabricio Murai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA); Combinatorics (math.CO); Optimization and Control (math.OC)

</div>
<p class="mathjax">Many high-stakes decision-making problems, such as those found within
cybersecurity and economics, can be modeled as competitive resource allocation
games. In these games, multiple players must allocate limited resources to
overcome their opponent(s), while minimizing any induced individual losses.
However, existing means of assessing the performance of resource allocation
algorithms are highly disparate and problem-dependent. As a result, evaluating
such algorithms is unreliable or impossible in many contexts and applications,
especially when considering differing levels of feedback. To resolve this
problem, we propose a generalized definition of payoff which uses an arbitrary
user-provided function. This unifies performance evaluation under all contexts
and levels of feedback. Using this definition, we develop metrics for
evaluating player performance, and estimators to approximate them under
uncertainty (i.e., bandit or semi-bandit feedback). These metrics and their
respective estimators provide a problem-agnostic means to contextualize and
evaluate algorithm performance. To validate the accuracy of our estimator, we
explore the Colonel Blotto ($\mathcal{CB}$) game as an example. To this end, we
propose a graph-pruning approach to efficiently identify feasible opponent
decisions, which are used in computing our estimation metrics. Using various
resource allocation algorithms and game parameters, a suite of $\mathcal{CB}$
games are simulated and used to compute and evaluate the quality of our
estimates. These simulations empirically show our approach to be highly
accurate at estimating the metrics associated with the unseen outcomes of an
opponent's latent behavior.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04266" title="Abstract">arXiv:2401.04266</a> [<a href="/pdf/2401.04266" title="Download PDF">pdf</a>, <a href="/format/2401.04266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention versus Contrastive Learning of Tabular Data -- A Data-centric  Benchmarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rabbani%2C+S+B">Shourav B. Rabbani</a>, 
<a href="/search/cs?searchtype=author&query=Medri%2C+I+V">Ivan V. Medri</a>, 
<a href="/search/cs?searchtype=author&query=Samad%2C+M+D">Manar D. Samad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Despite groundbreaking success in image and text learning, deep learning has
not achieved significant improvements against traditional machine learning (ML)
when it comes to tabular data. This performance gap underscores the need for
data-centric treatment and benchmarking of learning algorithms. Recently,
attention and contrastive learning breakthroughs have shifted computer vision
and natural language processing paradigms. However, the effectiveness of these
advanced deep models on tabular data is sparsely studied using a few data sets
with very large sample sizes, reporting mixed findings after benchmarking
against a limited number of baselines. We argue that the heterogeneity of
tabular data sets and selective baselines in the literature can bias the
benchmarking outcomes. This article extensively evaluates state-of-the-art
attention and contrastive learning methods on a wide selection of 28 tabular
data sets (14 easy and 14 hard-to-classify) against traditional deep and
machine learning. Our data-centric benchmarking demonstrates when traditional
ML is preferred over deep learning and vice versa because no best learning
method exists for all tabular data sets. Combining between-sample and
between-feature attentions conquers the invincible traditional ML on tabular
data sets by a significant margin but fails on high dimensional data, where
contrastive learning takes a robust lead. While a hybrid attention-contrastive
learning strategy mostly wins on hard-to-classify data sets, traditional
methods are frequently superior on easy-to-classify data sets with presumably
simpler decision boundaries. To the best of our knowledge, this is the first
benchmarking paper with statistical analyses of attention and contrastive
learning performances on a diverse selection of tabular data sets against
traditional deep and machine learning baselines to facilitate further advances
in this field.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04268" title="Abstract">arXiv:2401.04268</a> [<a href="/pdf/2401.04268" title="Download PDF">pdf</a>, <a href="/format/2401.04268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Development of a Remotely-enabled Modular Release Mechanism  for Autonomous Underwater Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kutzke%2C+D+T">Demetrious T. Kutzke</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+G+E+M">Gustavo E. Miranda L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Herman%2C+R+J">Robert J. Herman</a>, 
<a href="/search/cs?searchtype=author&query=Philippeaux%2C+H">Harryel Philippeaux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We introduce a launch device, called the remotely-enabled modular release
mechanism, to augment rapid testing and prototyping of cooperative autonomy
maritime applications by facilitating autonomous deployment of an autonomous
underwater vehicle (AUV) from an autonomous surface vessel (ASV). While we
focus our development on a specific application of deploying an AUV from a
catamaran style ASV, the release mechanism can be adapted to different
deployable objects and towing vehicles, such as buoys and sensors for
oceanographic surveys or mono-hull ASVs. In this paper we explore a number of
hardware and software design considerations to facilitate ease of integration
with existing maritime autonomy systems. We expound on bench tests and in-water
tests used to explore the utility of the release system and diagnose system
issues. Additionally, we make a first-principles argument, based on a
hydrodynamics physics model, for assured deployment that is virtually
independent of sea state, making the release system a suitable alternative for
different maritime applications in varying environmental conditions.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04280" title="Abstract">arXiv:2401.04280</a> [<a href="/pdf/2401.04280" title="Download PDF">pdf</a>, <a href="/format/2401.04280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting the structure of dynamic graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kandanaarachchi%2C+S">Sevvandi Kandanaarachchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Dynamic graph embeddings, inductive and incremental learning facilitate
predictive tasks such as node classification and link prediction. However,
predicting the structure of a graph at a future time step from a time series of
graphs, allowing for new nodes has not gained much attention. In this paper, we
present such an approach. We use time series methods to predict the node degree
at future time points and combine it with flux balance analysis -- a linear
programming method used in biochemistry -- to obtain the structure of future
graphs. Furthermore, we explore the predictive graph distribution for different
parameter values. We evaluate this method using synthetic and real datasets and
demonstrate its utility and applicability.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04282" title="Abstract">arXiv:2401.04282</a> [<a href="/pdf/2401.04282" title="Download PDF">pdf</a>, <a href="/ps/2401.04282" title="Download PostScript">ps</a>, <a href="/format/2401.04282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fast Graph Search Algorithm with Dynamic Optimization and Reduced  Histogram for Discrimination of Binary Classification Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qinwu Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study develops a graph search algorithm to find the optimal
discrimination path for the binary classification problem. The objective
function is defined as the difference of variations between the true positive
(TP) and false positive (FP). It uses the depth first search (DFS) algorithm to
find the top-down paths for discrimination. It proposes a dynamic optimization
procedure to optimize TP at the upper levels and then reduce FP at the lower
levels. To accelerate computing speed with improving accuracy, it proposes a
reduced histogram algorithm with variable bin size instead of looping over all
data points, to find the feature threshold of discrimination. The algorithm is
applied on top of a Support Vector Machine (SVM) model for a binary
classification problem on whether a person is fit or unfit. It significantly
improves TP and reduces FP of the SVM results (e.g., reduced FP by 90% with a
loss of only\ 5% TP). The graph search auto-generates 39 ranked discrimination
paths within 9 seconds on an input of total 328,464 objects, using a dual-core
Laptop computer with a processor of 2.59 GHz.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04285" title="Abstract">arXiv:2401.04285</a> [<a href="/pdf/2401.04285" title="Download PDF">pdf</a>, <a href="/format/2401.04285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-sweep moment-based semi-implicit-explicit integration for gray  thermal radiation transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Southworth%2C+B+S">Ben S. Southworth</a>, 
<a href="/search/math?searchtype=author&query=Olivier%2C+S+S">Samuel S. Olivier</a>, 
<a href="/search/math?searchtype=author&query=Park%2C+H">HyeongKae Park</a>, 
<a href="/search/math?searchtype=author&query=Buvoli%2C+T">Tommaso Buvoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">Thermal radiation transport (TRT) is a time dependent, high dimensional
partial integro-differential equation. In practical applications such as
inertial confinement fusion, TRT is coupled to other physics such as
hydrodynamics, plasmas, etc., and the timescales one is interested in capturing
are often much slower than the radiation timescale. As a result, TRT is treated
implicitly, and due to its stiffness and high dimensionality, is often a
dominant computational cost in multiphysics simulations. Here we develop a new
approach for implicit-explicit (IMEX) integration of gray TRT in the
deterministic S$_N$ setting, which requires only one sweep per stage, with the
simplest first-order method requiring only one sweep per time step. The
partitioning of equations is done via a moment-based high-order low-order
formulation of TRT, where the streaming operator and first two moments are used
to capture the asymptotic stiff regimes of the streaming limit and diffusion
limit. Absorption-reemission is treated explicitly, and although stiff, is
sufficiently damped by the implicit solve that we achieve stable accurate time
integration without incorporating the coupling of the high order and low order
equations implicitly. Due to nonlinear coupling of the high-order and low-order
equations through temperature-dependent opacities, to facilitate IMEX
partitioning and higher-order methods, we use a semi-implicit integration
approach amenable to nonlinear partitions. Results are demonstrated on thick
Marshak and crooked pipe benchmark problems, demonstrating orders of magnitude
improvement in accuracy and wallclock compared with the standard first-order
implicit integration typically used.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04287" title="Abstract">arXiv:2401.04287</a> [<a href="/pdf/2401.04287" title="Download PDF">pdf</a>, <a href="/format/2401.04287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Is an App Store? The Software Engineering Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenhan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Proksch%2C+S">Sebastian Proksch</a>, 
<a href="/search/cs?searchtype=author&query=German%2C+D+M">Daniel M. German</a>, 
<a href="/search/cs?searchtype=author&query=Godfrey%2C+M+W">Michael W. Godfrey</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=McIntosh%2C+S">Shane McIntosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Empir Software Eng 29, 35 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">"App stores" are online software stores where end users may browse, purchase,
download, and install software applications. By far, the best known app stores
are associated with mobile platforms, such as Google Play for Android and
Apple's App Store for iOS. The ubiquity of smartphones has led to mobile app
stores becoming a touchstone experience of modern living. However, most of app
store research has concentrated on properties of the apps rather than the
stores themselves. Today, there is a rich diversity of app stores and these
stores have largely been overlooked by researchers: app stores exist on many
distinctive platforms, are aimed at different classes of users, and have
different end-goals beyond simply selling a standalone app to a smartphone
user.
<br />We survey and characterize the broader dimensionality of app stores, and
explore how and why they influence software development practices, such as
system design and release management. We begin by collecting a set of app store
examples from web search queries. By analyzing and curating the results, we
derive a set of features common to app stores. We then build a dimensional
model of app stores based on these features, and we fit each app store from our
web search result set into this model. Next, we performed unsupervised
clustering to the app stores to find their natural groupings. Our results
suggest that app stores have become an essential stakeholder in modern software
development. They control the distribution channel to end users and ensure that
the applications are of suitable quality; in turn, this leads to developers
adhering to various store guidelines when creating their applications. However,
we found the app stores operational model could vary widely between stores, and
this variability could in turn affect the generalizability of existing
understanding of app stores.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04289" title="Abstract">arXiv:2401.04289</a> [<a href="/pdf/2401.04289" title="Download PDF">pdf</a>, <a href="/ps/2401.04289" title="Download PostScript">ps</a>, <a href="/format/2401.04289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expiring Assets in Automated Market Makers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wood%2C+K">Kenan Wood</a>, 
<a href="/search/cs?searchtype=author&query=Herlihy%2C+M">Maurice Herlihy</a>, 
<a href="/search/cs?searchtype=author&query=Mendes%2C+H">Hammurabi Mendes</a>, 
<a href="/search/cs?searchtype=author&query=Pulaj%2C+J">Jonad Pulaj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Mathematical Finance (q-fin.MF); Trading and Market Microstructure (q-fin.TR)

</div>
<p class="mathjax">An automated market maker (AMM) is a state machine that manages pools of
assets, allowing parties to buy and sell those assets according to a fixed
mathematical formula. AMMs are typically implemented as smart contracts on
blockchains, and its prices are kept in line with the overall market price by
arbitrage: if the AMM undervalues an asset with respect to the market, an
"arbitrageur" can make a risk-free profit by buying just enough of that asset
to bring the AMM's price back in line with the market.
<br />AMMs, however, are not designed for assets that expire: that is, assets that
cannot be produced or resold after a specified date. As assets approach
expiration, arbitrage may not be able to reconcile supply and demand, and the
liquidity providers that funded the AMM may have excessive exposure to risk due
to rapid price variations.
<br />This paper formally describes the design of a decentralized exchange (DEX)
for assets that expire, combining aspects of AMMs and limit-order books. We
ensure liveness and market clearance, providing mechanisms for liquidity
providers to control their exposure to risk and adjust prices dynamically in
response to situations where arbitrage may fail.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04290" title="Abstract">arXiv:2401.04290</a> [<a href="/pdf/2401.04290" title="Download PDF">pdf</a>, <a href="/format/2401.04290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StarCraftImage: A Dataset For Prototyping Spatial Reasoning Methods For  Multi-Agent Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulinski%2C+S">Sean Kulinski</a>, 
<a href="/search/cs?searchtype=author&query=Waytowich%2C+N+R">Nicholas R. Waytowich</a>, 
<a href="/search/cs?searchtype=author&query=Hare%2C+J+Z">James Z. Hare</a>, 
<a href="/search/cs?searchtype=author&query=Inouye%2C+D+I">David I. Inouye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in CVPR 23'
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Spatial reasoning tasks in multi-agent environments such as event prediction,
agent type identification, or missing data imputation are important for
multiple applications (e.g., autonomous surveillance over sensor networks and
subtasks for reinforcement learning (RL)). StarCraft II game replays encode
intelligent (and adversarial) multi-agent behavior and could provide a testbed
for these tasks; however, extracting simple and standardized representations
for prototyping these tasks is laborious and hinders reproducibility. In
contrast, MNIST and CIFAR10, despite their extreme simplicity, have enabled
rapid prototyping and reproducibility of ML methods. Following the simplicity
of these datasets, we construct a benchmark spatial reasoning dataset based on
StarCraft II replays that exhibit complex multi-agent behaviors, while still
being as easy to use as MNIST and CIFAR10. Specifically, we carefully summarize
a window of 255 consecutive game states to create 3.6 million summary images
from 60,000 replays, including all relevant metadata such as game outcome and
player races. We develop three formats of decreasing complexity: Hyperspectral
images that include one channel for every unit type (similar to multispectral
geospatial images), RGB images that mimic CIFAR10, and grayscale images that
mimic MNIST. We show how this dataset can be used for prototyping spatial
reasoning methods. All datasets, code for extraction, and code for dataset
loading can be found at https://starcraftdata.davidinouye.com
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04301" title="Abstract">arXiv:2401.04301</a> [<a href="/pdf/2401.04301" title="Download PDF">pdf</a>, <a href="/format/2401.04301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Setting the Record Straight on Transformer Oversmoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dovonon%2C+G+J">Gb&#xe8;tondji J-S Dovonon</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+M+M">Michael M. Bronstein</a>, 
<a href="/search/cs?searchtype=author&query=Kusner%2C+M+J">Matt J. Kusner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformer-based models have recently become wildly successful across a
diverse set of domains. At the same time, recent work has shown that
Transformers are inherently low-pass filters that gradually oversmooth the
inputs, reducing the expressivity of their representations. A natural question
is: How can Transformers achieve these successes given this shortcoming? In
this work we show that in fact Transformers are not inherently low-pass
filters. Instead, whether Transformers oversmooth or not depends on the
eigenspectrum of their update equations. Our analysis extends prior work in
oversmoothing and in the closely-related phenomenon of rank collapse. We show
that many successful Transformer models have attention and weights which
satisfy conditions that avoid oversmoothing. Based on this analysis, we derive
a simple way to parameterize the weights of the Transformer update equations
that allows for control over its spectrum, ensuring that oversmoothing does not
occur. Compared to a recent solution for oversmoothing, our approach improves
generalization, even when training with more layers, fewer datapoints, and data
that is corrupted.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04302" title="Abstract">arXiv:2401.04302</a> [<a href="/pdf/2401.04302" title="Download PDF">pdf</a>, <a href="/format/2401.04302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> eSIM Technology in IoT Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Baloian%2C+A">Artiom Baloian</a>, 
<a href="/search/cs?searchtype=author&query=Janak%2C+J">Jan Janak</a>, 
<a href="/search/cs?searchtype=author&query=Schulzrinne%2C+H">Henning Schulzrinne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">eSIM(embedded SIM) is an advanced alternative to traditional physical SIM
cards initially developed by the GSM Association(GSMA) in 2013 [1][2]. The eSIM
technology has been deployed in many commercial products such as mobile
devices. However, the application of the eSIM technology in IoT devices has yet
to start being primarily deployed. Understanding the eSIM architecture and the
basic ideas of the eSIM provisioning and operations is very important for
engineers to promote eSIM technology deployment in more areas, both academics
and industries.
<br />The report focuses on the eSIM technology in the IoT architecture and two
major operations of Remote SIM Provisioning(RSP) procedure: the Common Mutual
Authentication procedure, a process used to authenticate eSIM trusted
communication parties over the public internet, and the Profile Downloading
procedure, the way to download the Profile from the operator SM-DP+ server and
eventually remotely provision the end-user devices.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04305" title="Abstract">arXiv:2401.04305</a> [<a href="/pdf/2401.04305" title="Download PDF">pdf</a>, <a href="/format/2401.04305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Deep Active Learning &amp; Data Subset Selection: Unifying  Principles with Information-Theory Intuitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirsch%2C+A">Andreas Kirsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">At its core, this thesis aims to enhance the practicality of deep learning by
improving the label and training efficiency of deep learning models. To this
end, we investigate data subset selection techniques, specifically active
learning and active sampling, grounded in information-theoretic principles.
Active learning improves label efficiency, while active sampling enhances
training efficiency. Supervised deep learning models often require extensive
training with labeled data. Label acquisition can be expensive and
time-consuming, and training large models is resource-intensive, hindering the
adoption outside academic research and ``big tech.'' Existing methods for data
subset selection in deep learning often rely on heuristics or lack a principled
information-theoretic foundation. In contrast, this thesis examines several
objectives for data subset selection and their applications within deep
learning, striving for a more principled approach inspired by information
theory. We begin by disentangling epistemic and aleatoric uncertainty in single
forward-pass deep neural networks, which provides helpful intuitions and
insights into different forms of uncertainty and their relevance for data
subset selection. We then propose and investigate various approaches for active
learning and data subset selection in (Bayesian) deep learning. Finally, we
relate various existing and proposed approaches to approximations of
information quantities in weight or prediction space. Underpinning this work is
a principled and practical notation for information-theoretic quantities that
includes both random variables and observed outcomes. This thesis demonstrates
the benefits of working from a unified perspective and highlights the potential
impact of our contributions to the practical application of deep learning.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04308" title="Abstract">arXiv:2401.04308</a> [<a href="/pdf/2401.04308" title="Download PDF">pdf</a>, <a href="/format/2401.04308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Remotely Verifiable Software Integrity in Resource-Constrained  IoT Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Oliveira+Nunes%2C+I">Ivan De Oliveira Nunes</a>, 
<a href="/search/cs?searchtype=author&query=Jakkamsetti%2C+S">Sashidhar Jakkamsetti</a>, 
<a href="/search/cs?searchtype=author&query=Rattanavipanon%2C+N">Norrathep Rattanavipanon</a>, 
<a href="/search/cs?searchtype=author&query=Tsudik%2C+G">Gene Tsudik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Lower-end IoT devices typically have strict cost constraints that rule out
usual security mechanisms available in general-purpose computers or higher-end
devices. To secure low-end devices, various low-cost security architectures
have been proposed for remote verification of their software state via
integrity proofs. These proofs vary in terms of expressiveness, with simpler
ones confirming correct binary presence, while more expressive ones support
verification of arbitrary code execution. This article provides a holistic and
systematic treatment of this family of architectures. It also compares
(qualitatively and quantitatively) the types of software integrity proofs,
respective architectural support, and associated costs. Finally, we outline
some research directions and emerging challenges.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04311" title="Abstract">arXiv:2401.04311</a> [<a href="/pdf/2401.04311" title="Download PDF">pdf</a>, <a href="/ps/2401.04311" title="Download PostScript">ps</a>, <a href="/format/2401.04311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Truly-Everlasting Robust-Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stemmer%2C+U">Uri Stemmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Private Everlasting Prediction (PEP), recently introduced by Naor et al.
[2023], is a model for differentially private learning in which the learner
never publicly releases a hypothesis. Instead, it provides black-box access to
a "prediction oracle" that can predict the labels of an endless stream of
unlabeled examples drawn from the underlying distribution. Importantly, PEP
provides privacy both for the initial training set and for the endless stream
of classification queries. We present two conceptual modifications to the
definition of PEP, as well as new constructions exhibiting significant
improvements over prior work. Specifically,
<br />(1) Robustness: PEP only guarantees accuracy provided that all the
classification queries are drawn from the correct underlying distribution. A
few out-of-distribution queries might break the validity of the prediction
oracle for future queries, even for future queries which are sampled from the
correct distribution. We incorporate robustness against such poisoning attacks
into the definition of PEP, and show how to obtain it.
<br />(2) Dependence of the privacy parameter $\delta$ in the time horizon: We
present a relaxed privacy definition, suitable for PEP, that allows us to
disconnect the privacy parameter $\delta$ from the number of total time steps
$T$. This allows us to obtain algorithms for PEP whose sample complexity is
independent from $T$, thereby making them "truly everlasting". This is in
contrast to prior work where the sample complexity grows with $polylog(T)$.
<br />(3) New constructions: Prior constructions for PEP exhibit sample complexity
that is quadratic in the VC dimension of the target class. We present new
constructions of PEP for axis-aligned rectangles and for decision-stumps that
exhibit sample complexity linear in the dimension (instead of quadratic). We
show that our constructions satisfy very strong robustness properties.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04312" title="Abstract">arXiv:2401.04312</a> [<a href="/pdf/2401.04312" title="Download PDF">pdf</a>, <a href="/format/2401.04312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-based Multi-interest Learning Method for Sequential  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xue Dong</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuemeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+W">Weili Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Multi-interest learning method for sequential recommendation aims to predict
the next item according to user multi-faceted interests given the user
historical interactions. Existing methods mainly consist of two modules: the
multi-interest extraction module that learns user multi-interest embeddings to
capture the user multi-interests, and the multi-interest weight prediction
module that learns the weight of each interest for aggregating the learned
multi-interest embeddings to derive the user embedding, used for predicting the
user rating to an item. Despite their effectiveness, existing methods have two
key limitations: 1) they directly feed the user interactions into the two
modules, while ignoring their different learning objectives, and 2) they merely
consider the centrality of the user interactions to learn the user
multi-interests, while overlooking their dispersion. To tackle these
limitations, we propose a prompt-based multi-interest learning method (PoMRec),
where specific prompts are inserted into user interactions to make them
adaptive to different learning objectives of the two modules. Moreover, we
utilize both the mean and variance embeddings of user interactions to derive
the user multi-interest embeddings for comprehensively model the user
multi-interests. We conduct extensive experiments on two public datasets, and
the results verify that our proposed PoMRec outperforms the state-of-the-art
multi-interest learning methods.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04316" title="Abstract">arXiv:2401.04316</a> [<a href="/pdf/2401.04316" title="Download PDF">pdf</a>, <a href="/format/2401.04316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Control of An Aerial Manipulator Based on A Variable Inertia  Parameters Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guangyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuqing He</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+F">Feng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianda Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guangjun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Aerial manipulator, which is composed of an UAV (Unmanned Aerial Vehicle) and
a multi-link manipulator and can perform aerial manipulation, has shown great
potential of applications. However, dynamic coupling between the UAV and the
manipulator makes it difficult to control the aerial manipulator with high
performance. In this paper, system modeling and control problem of the aerial
manipulator are studied. Firstly, an UAV dynamic model is proposed with
consideration of the dynamic coupling from an attached manipulator, which is
treated as disturbance for the UAV. In the dynamic model, the disturbance is
affected by the variable inertia parameters of the aerial manipulator system.
Then, based on the proposed dynamic model, a disturbance compensation robust
$H_{\infty}$ controller is designed to stabilize flight of the UAV while the
manipulator is in operation. Finally, experiments are conducted and the
experimental results demonstrate the feasibility and validity of the proposed
control scheme.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04317" title="Abstract">arXiv:2401.04317</a> [<a href="/pdf/2401.04317" title="Download PDF">pdf</a>, <a href="/format/2401.04317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision Reimagined: AI-Powered Breakthroughs in WiFi Indoor Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jianyang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Amartansh Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Murch%2C+R">Ross Murch</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liwen Jing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Indoor imaging is a critical task for robotics and internet-of-things. WiFi
as an omnipresent signal is a promising candidate for carrying out passive
imaging and synchronizing the up-to-date information to all connected devices.
This is the first research work to consider WiFi indoor imaging as a
multi-modal image generation task that converts the measured WiFi power into a
high-resolution indoor image. Our proposed WiFi-GEN network achieves a shape
reconstruction accuracy that is 275% of that achieved by physical model-based
inversion methods. Additionally, the Frechet Inception Distance score has been
significantly reduced by 82%. To examine the effectiveness of models for this
task, the first large-scale dataset is released containing 80,000 pairs of WiFi
signal and imaging target. Our model absorbs challenges for the model-based
methods including the non-linearity, ill-posedness and non-certainty into
massive parameters of our generative AI network. The network is also designed
to best fit measured WiFi signals and the desired imaging output. For
reproducibility, we will release the data and code upon acceptance.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04318" title="Abstract">arXiv:2401.04318</a> [<a href="/pdf/2401.04318" title="Download PDF">pdf</a>, <a href="/ps/2401.04318" title="Download PostScript">ps</a>, <a href="/format/2401.04318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contiguous Allocation of Indivisible Items on a Path
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawase%2C+Y">Yasushi Kawase</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+B">Bodhayan Roy</a>, 
<a href="/search/cs?searchtype=author&query=Sanpui%2C+M+A">Mohammad Azharuddin Sanpui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version was accepted at AAMAS 2024 as an extended abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the problem of allocating indivisible items on a path among agents.
The objective is to find a fair and efficient allocation in which each agent's
bundle forms a contiguous block on the line. We demonstrate that, even when the
valuations are binary additive, deciding whether every item can be allocated to
an agent who wants it is NP-complete. Consequently, we provide two
fixed-parameter tractable (FPT) algorithms for maximizing utilitarian social
welfare, with respect to the number of agents and the number of items.
Additionally, we present a 2-approximation algorithm for the special case when
the valuations are binary additive and the maximum utility is equal to the
number of items. Furthermore, we establish that deciding whether the maximum
egalitarian social welfare is at least 2 or at most 1 is NP-complete, even when
the valuations are binary additive. We also explore the case where the order of
the blocks of items allocated to the agents is predetermined. In this case, we
show that both maximum utilitarian social welfare and egalitarian social
welfare can be computed in polynomial time. However, we determine that checking
the existence of an EF1 allocation is NP-complete, even when the valuations are
binary additive.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04319" title="Abstract">arXiv:2401.04319</a> [<a href="/pdf/2401.04319" title="Download PDF">pdf</a>, <a href="/format/2401.04319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Know Your Needs Better: Towards Structured Understanding of Marketer  Demands with Analogical Reasoning Augmented LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Binbin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we explore a new way for user targeting, where non-expert
marketers could select their target users solely given demands in natural
language form. The key to this issue is how to transform natural languages into
practical structured logical languages, i.e., the structured understanding of
marketer demands. Considering the impressive natural language processing
ability of large language models (LLMs), we try to leverage LLMs to solve this
issue. Past research indicates that the reasoning ability of LLMs can be
effectively enhanced through chain-of-thought (CoT) prompting. But existing
methods still have some limitations: (1) Previous methods either use simple
"Let's think step by step" spells or provide fixed examples in demonstrations
without considering compatibility between prompts and questions, making LLMs
ineffective in some complex reasoning tasks such as structured language
transformation. (2) Previous methods are often implemented in closed-source
models or excessively large models, which is not suitable in industrial
practical scenarios. Based on these, we propose ARALLM (i.e., Analogical
Reasoning Augmented Large Language Models) consisting of two modules:
Analogical Reasoning based Prompting and Reasoning-Augmented Multi-Task Model
Distillation.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04320" title="Abstract">arXiv:2401.04320</a> [<a href="/pdf/2401.04320" title="Download PDF">pdf</a>, <a href="/format/2401.04320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous robotic re-alignment for face-to-face underwater human-robot  interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kutzke%2C+D+T">Demetrious T. Kutzke</a>, 
<a href="/search/cs?searchtype=author&query=Wariar%2C+A">Ashwin Wariar</a>, 
<a href="/search/cs?searchtype=author&query=Sattar%2C+J">Junaed Sattar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Proceedings of the 2024 IEEE Conference on Robotics &amp; Automation (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The use of autonomous underwater vehicles (AUVs) to accomplish traditionally
challenging and dangerous tasks has proliferated thanks to advances in sensing,
navigation, manipulation, and on-board computing technologies. Utilizing AUVs
in underwater human-robot interaction (UHRI) has witnessed comparatively
smaller levels of growth due to limitations in bi-directional communication and
significant technical hurdles to bridge the gap between analogies with
terrestrial interaction strategies and those that are possible in the
underwater domain. A necessary component to support UHRI is establishing a
system for safe robotic-diver approach to establish face-to-face communication
that considers non-standard human body pose. In this work, we introduce a
stereo vision system for enhancing UHRI that utilizes three-dimensional
reconstruction from stereo image pairs and machine learning for localizing
human joint estimates. We then establish a convention for a coordinate system
that encodes the direction the human is facing with respect to the camera
coordinate frame. This allows automatic setpoint computation that preserves
human body scale and can be used as input to an image-based visual servo
control scheme. We show that our setpoint computations tend to agree both
quantitatively and qualitatively with experimental setpoint baselines. The
methodology introduced shows promise for enhancing UHRI by improving robotic
perception of human orientation underwater.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04323" title="Abstract">arXiv:2401.04323</a> [<a href="/pdf/2401.04323" title="Download PDF">pdf</a>, <a href="/format/2401.04323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divergent Characteristics of Biomedical Research across Publication  Types: A Quantitative Analysis on the Aging-related Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chenxing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qingyue Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 3 tables, 9 figures, supplementary figures and tables attached in latex code
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Information Retrieval (cs.IR); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">This paper investigates differences in characteristics across publication
types for aging-related genetic research. We utilized bibliometric data for
five model species retrieved from authoritative databases including PubMed.
Publications are classified into types according to PubMed. Results indicate
substantial divergence across publication types in attention paid to
aging-related research, scopes of studied genes, and topical preferences. For
instance, comparative studies and meta-analyses show a greater focus on aging
than validation studies. Reviews concentrate more on cell biology while
clinical studies emphasize translational topics. Publication types also
manifest variations in highly studied genes, like APOE for reviews versus GH1
for clinical studies. Despite differences, top genes like insulin are
universally emphasized. Publication types demonstrate similar levels of
imbalance in research efforts to genes. Differences also exist in bibliometrics
like authorship numbers, citation counts, etc. Publication types show distinct
preferences for journals of certain topical specialties and scope of
readership. Overall, findings showcase distinct characteristics of publication
types in studying aging-related genetics, owing to their unique nature and
objectives. This study is the first endeavor to systematically depict the
inherent structure of a biomedical research field from the perspective of
publication types and provides insights into knowledge production and
evaluation patterns across biomedical communities.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04325" title="Abstract">arXiv:2401.04325</a> [<a href="/pdf/2401.04325" title="Download PDF">pdf</a>, <a href="/format/2401.04325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RadarCam-Depth: Radar-Camera Fusion for Depth Estimation with Learned  Metric Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Han Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yukai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yaqing Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kewei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+X">Xingxing Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel approach for metric dense depth estimation based on the
fusion of a single-view image and a sparse, noisy Radar point cloud. The direct
fusion of heterogeneous Radar and image data, or their encodings, tends to
yield dense depth maps with significant artifacts, blurred boundaries, and
suboptimal accuracy. To circumvent this issue, we learn to augment versatile
and robust monocular depth prediction with the dense metric scale induced from
sparse and noisy Radar data. We propose a Radar-Camera framework for highly
accurate and fine-detailed dense depth estimation with four stages, including
monocular depth prediction, global scale alignment of monocular depth with
sparse Radar points, quasi-dense scale estimation through learning the
association between Radar points and image patches, and local scale refinement
of dense depth using a scale map learner. Our proposed method significantly
outperforms the state-of-the-art Radar-Camera depth estimation methods by
reducing the mean absolute error (MAE) of depth estimation by 25.6% and 40.2%
on the challenging nuScenes dataset and our self-collected ZJU-4DRadarCam
dataset, respectively.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04328" title="Abstract">arXiv:2401.04328</a> [<a href="/pdf/2401.04328" title="Download PDF">pdf</a>, <a href="/format/2401.04328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Underdetermined Fourier Extensions for Partial Differential Equations on  Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Venn%2C+D+R">Daniel R. Venn</a>, 
<a href="/search/math?searchtype=author&query=Ruuth%2C+S+J">Steven J. Ruuth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose and analyze a class of meshfree, super-algebraically convergent
methods for partial differential equations (PDEs) on surfaces using Fourier
extensions minimizing a measure of non-smoothness (such as a Sobolev norm).
Current spectral methods for surface PDEs are primarily limited to a small
class of surfaces, such as subdomains of spheres. Other high order methods for
surface PDEs typically use radial basis functions (RBFs). Many of these methods
are not well-understood analytically for surface PDEs and are highly
ill-conditioned. Our methods work by extending a surface PDE into a box-shaped
domain so that differential operators of the extended function agree with the
surface differential operators, as in the Closest Point Method. The methods can
be proven to converge super-algebraically for certain well-posed linear PDEs,
and spectral convergence to machine error has been observed numerically for a
variety of problems. Our approach works on arbitrary smooth surfaces (closed or
non-closed) defined by point clouds with minimal conditions.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04330" title="Abstract">arXiv:2401.04330</a> [<a href="/pdf/2401.04330" title="Download PDF">pdf</a>, <a href="/format/2401.04330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method  guided by multi-scale feature information aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yonghui Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaolong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yishu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+J">Jinquan Ai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The purpose of remote sensing image change detection (RSCD) is to detect
differences between bi-temporal images taken at the same place. Deep learning
has been extensively used to RSCD tasks, yielding significant results in terms
of result recognition. However, due to the shooting angle of the satellite, the
impacts of thin clouds, and certain lighting conditions, the problem of fuzzy
edges in the change region in some remote sensing photographs cannot be
properly handled using current RSCD algorithms. To solve this issue, we
proposed a Body Decouple Multi-Scale by fearure Aggregation change detection
(BD-MSA), a novel model that collects both global and local feature map
information in the channel and space dimensions of the feature map during the
training and prediction phases. This approach allows us to successfully extract
the change region's boundary information while also divorcing the change
region's main body from its boundary. Numerous studies have shown that the
assessment metrics and evaluation effects of the model described in this paper
on the publicly available datasets DSIFN-CD and S2Looking are the best when
compared to other models.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04331" title="Abstract">arXiv:2401.04331</a> [<a href="/pdf/2401.04331" title="Download PDF">pdf</a>, <a href="/format/2401.04331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coupling Graph Neural Networks with Fractional Order Continuous  Dynamics: A Robustness Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+Q">Qiyu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yihang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+R">Rui She</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+W+P">Wee Peng Tay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Proc. AAAI Conference on Artificial Intelligence, Vancouver, Canada, Feb. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we rigorously investigate the robustness of graph neural
fractional-order differential equation (FDE) models. This framework extends
beyond traditional graph neural (integer-order) ordinary differential equation
(ODE) models by implementing the time-fractional Caputo derivative. Utilizing
fractional calculus allows our model to consider long-term memory during the
feature updating process, diverging from the memoryless Markovian updates seen
in traditional graph neural ODE models. The superiority of graph neural FDE
models over graph neural ODE models has been established in environments free
from attacks or perturbations. While traditional graph neural ODE models have
been verified to possess a degree of stability and resilience in the presence
of adversarial attacks in existing literature, the robustness of graph neural
FDE models, especially under adversarial conditions, remains largely
unexplored. This paper undertakes a detailed assessment of the robustness of
graph neural FDE models. We establish a theoretical foundation outlining the
robustness characteristics of graph neural FDE models, highlighting that they
maintain more stringent output perturbation bounds in the face of input and
graph topology disturbances, compared to their integer-order counterparts. Our
empirical evaluations further confirm the enhanced robustness of graph neural
FDE models, highlighting their potential in adversarially robust applications.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04332" title="Abstract">arXiv:2401.04332</a> [<a href="/pdf/2401.04332" title="Download PDF">pdf</a>, <a href="/format/2401.04332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mix-GENEO: A flexible filtration for multiparameter persistent homology  detects digital images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiaxing He</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+B">Bingzhe Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tieru Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+Y">Yue Xin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Algebraic Topology (math.AT)

</div>
<p class="mathjax">Two important problems in the field of Topological Data Analysis are defining
practical multifiltrations on objects and showing ability of TDA to detect the
geometry. Motivated by the problems, we constuct three multifiltrations named
multi-GENEO, multi-DGENEO and mix-GENEO, and prove the stability of both the
interleaving distance and multiparameter persistence landscape of multi-GENEO
with respect to the pseudometric of the subspace of bounded functions. We also
give the estimations of upper bound for multi-DGENEO and mix-GENEO. Finally, we
provide experiment results on MNIST dataset to demonstrate our bifiltrations
have ability to detect geometric and topological differences of digital images.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04334" title="Abstract">arXiv:2401.04334</a> [<a href="/pdf/2401.04334" title="Download PDF">pdf</a>, <a href="/format/2401.04334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Robotics: Opportunities, Challenges, and  Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hanqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+P">Peng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+E">Enze Shi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Huawen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yincheng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huaqin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Haixing Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+B">Bao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have undergone significant expansion and have
been increasingly integrated across various domains. Notably, in the realm of
robot task planning, LLMs harness their advanced reasoning and language
comprehension capabilities to formulate precise and efficient action plans
based on natural language instructions. However, for embodied tasks, where
robots interact with complex environments, text-only LLMs often face challenges
due to a lack of compatibility with robotic visual perception. This study
provides a comprehensive overview of the emerging integration of LLMs and
multimodal LLMs into various robotic tasks. Additionally, we propose a
framework that utilizes multimodal GPT-4V to enhance embodied task planning
through the combination of natural language instructions and robot visual
perceptions. Our results, based on diverse datasets, indicate that GPT-4V
effectively enhances robot performance in embodied tasks. This extensive survey
and evaluation of LLMs and multimodal LLMs across a variety of robotic tasks
enriches the understanding of LLM-centric embodied intelligence and provides
forward-looking insights toward bridging the gap in Human-Robot-Environment
interaction.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04336" title="Abstract">arXiv:2401.04336</a> [<a href="/pdf/2401.04336" title="Download PDF">pdf</a>, <a href="/format/2401.04336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Efficient Private Neighbor Generation for Subgraph Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yiu%2C+S+M">Siu Ming Yiu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Behemoth graphs are often fragmented and separately stored by multiple data
owners as distributed subgraphs in many realistic applications. Without harming
data privacy, it is natural to consider the subgraph federated learning
(subgraph FL) scenario, where each local client holds a subgraph of the entire
global graph, to obtain globally generalized graph mining models. To overcome
the unique challenge of incomplete information propagation on local subgraphs
due to missing cross-subgraph neighbors, previous works resort to the
augmentation of local neighborhoods through the joint FL of missing neighbor
generators and GNNs. Yet their technical designs have profound limitations
regarding the utility, efficiency, and privacy goals of FL. In this work, we
propose FedDEP to comprehensively tackle these challenges in subgraph FL.
FedDEP consists of a series of novel technical designs: (1) Deep neighbor
generation through leveraging the GNN embeddings of potential missing
neighbors; (2) Efficient pseudo-FL for neighbor generation through embedding
prototyping; and (3) Privacy protection through noise-less
edge-local-differential-privacy.
<br />We analyze the correctness and efficiency of FedDEP, and provide theoretical
guarantees on its privacy.
<br />Empirical results on four real-world datasets justify the clear benefits of
proposed techniques.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04338" title="Abstract">arXiv:2401.04338</a> [<a href="/pdf/2401.04338" title="Download PDF">pdf</a>, <a href="/format/2401.04338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G-Meta: Distributed Meta Learning in GPU Clusters for Large-Scale  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Youshao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shangchun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhenglei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huan%2C+Z">Zhaoxin Huan</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+L">Lin Ju</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaolu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Recently, a new paradigm, meta learning, has been widely applied to Deep
Learning Recommendation Models (DLRM) and significantly improves statistical
performance, especially in cold-start scenarios. However, the existing systems
are not tailored for meta learning based DLRM models and have critical problems
regarding efficiency in distributed training in the GPU cluster. It is because
the conventional deep learning pipeline is not optimized for two task-specific
datasets and two update loops in meta learning. This paper provides a
high-performance framework for large-scale training for Optimization-based Meta
DLRM models over the \textbf{G}PU cluster, namely \textbf{G}-Meta. Firstly,
G-Meta utilizes both data parallelism and model parallelism with careful
orchestration regarding computation and communication efficiency, to enable
high-speed distributed training. Secondly, it proposes a Meta-IO pipeline for
efficient data ingestion to alleviate the I/O bottleneck. Various experimental
results show that G-Meta achieves notable training speed without loss of
statistical performance. Since early 2022, G-Meta has been deployed in Alipay's
core advertising and recommender system, shrinking the continuous delivery of
models by four times. It also obtains 6.48\% improvement in Conversion Rate
(CVR) and 1.06\% increase in CPM (Cost Per Mille) in Alipay's homepage display
advertising, with the benefit of larger training samples and tasks.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04339" title="Abstract">arXiv:2401.04339</a> [<a href="/pdf/2401.04339" title="Download PDF">pdf</a>, <a href="/format/2401.04339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-Efficient Personalization using Quantized Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ryu%2C+H">Hyogon Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Seohyun Lim</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+H">Hyunjung Shim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rise of billion-parameter diffusion models like Stable Diffusion XL,
Imagen, and Dall-E3 markedly advances the field of generative AI. However,
their large-scale nature poses challenges in fine-tuning and deployment due to
high resource demands and slow inference speed. This paper ventures into the
relatively unexplored yet promising realm of fine-tuning quantized diffusion
models. We establish a strong baseline by customizing three models: PEQA for
fine-tuning quantization parameters, Q-Diffusion for post-training
quantization, and DreamBooth for personalization. Our analysis reveals a
notable trade-off between subject and prompt fidelity within the baseline
model. To address these issues, we introduce two strategies, inspired by the
distinct roles of different timesteps in diffusion models: S1 optimizing a
single set of fine-tuning parameters exclusively at selected intervals, and S2
creating multiple fine-tuning parameter sets, each specialized for different
timestep intervals. Our approach not only enhances personalization but also
upholds prompt fidelity and image quality, significantly outperforming the
baseline qualitatively and quantitatively. The code will be made publicly
available.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04340" title="Abstract">arXiv:2401.04340</a> [<a href="/pdf/2401.04340" title="Download PDF">pdf</a>, <a href="/format/2401.04340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Allocation with Replenishable Budgets: Worst Case and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+J">Mohammad Jaminur Islam</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shaolei Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM SIGMETRICS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Performance (cs.PF)

</div>
<p class="mathjax">This paper studies online resource allocation with replenishable budgets,
where budgets can be replenished on top of the initial budget and an agent
sequentially chooses online allocation decisions without violating the
available budget constraint at each round. We propose a novel online algorithm,
called OACP (Opportunistic Allocation with Conservative Pricing), that
conservatively adjusts dual variables while opportunistically utilizing
available resources. OACP achieves a bounded asymptotic competitive ratio in
adversarial settings as the number of decision rounds T gets large.
Importantly, the asymptotic competitive ratio of OACP is optimal in the absence
of additional assumptions on budget replenishment. To further improve the
competitive ratio, we make a mild assumption that there is budget replenishment
every T^* &gt;= 1 decision rounds and propose OACP+ to dynamically adjust the
total budget assignment for online allocation. Next, we move beyond the
worst-case and propose LA-OACP (Learning-Augmented OACP/OACP+), a novel
learning-augmented algorithm for online allocation with replenishable budgets.
We prove that LA-OACP can improve the average utility compared to OACP/OACP+
when the ML predictor is properly trained, while still offering worst-case
utility guarantees when the ML predictions are arbitrarily wrong. Finally, we
run simulation studies of sustainable AI inference powered by renewables,
validating our analysis and demonstrating the empirical benefits of LA-OACP.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04343" title="Abstract">arXiv:2401.04343</a> [<a href="/pdf/2401.04343" title="Download PDF">pdf</a>, <a href="/format/2401.04343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Fine-tuning of Large Language Models with Zeroth-order  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xinyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+A">Ashwinee Panda</a>, 
<a href="/search/cs?searchtype=author&query=Nasr%2C+M">Milad Nasr</a>, 
<a href="/search/cs?searchtype=author&query=Mahloujifar%2C+S">Saeed Mahloujifar</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+P">Prateek Mittal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Fine-tuning large pretrained models on private datasets may run the risk of
violating privacy. Differential privacy is a framework for mitigating privacy
risks by enforcing algorithmic stability. DP-SGD enables training models with
private data in a privacy-preserving manner, but raises new obstacles in the
form of performance loss and significant engineering challenges. We introduce
DP-ZO, a new method for fine-tuning large language models that preserves the
privacy of training data by privatizing zeroth-order optimization. A key
insight into the design of our method is that the direction of the gradient in
SPSA, the zeroth-order algorithm we use, is always random and the only
information that depends on private data is the step size, i.e., a scalar.
Therefore, we only need to privatize the scalar step size, which is
memory-efficient. DP-ZO, which can be instantiated with either Laplace or
Gaussian noise, provides a strong privacy-utility trade-off across different
tasks, and model sizes, under conservative privacy budgets. One noteworthy
result is that DP-ZO exhibits just $1.86\%$ performance degradation due to
privacy at $(1,10^{-5})$-DP when fine-tuning OPT-66B on 1000 training samples
from SQuAD.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04345" title="Abstract">arXiv:2401.04345</a> [<a href="/pdf/2401.04345" title="Download PDF">pdf</a>, <a href="/format/2401.04345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RomniStereo: Recurrent Omnidirectional Stereo Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hualie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Minglang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wenjie Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE RA-L, <a href="https://github.com/HalleyJiang/RomniStereo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Omnidirectional stereo matching (OSM) is an essential and reliable means for
$360^{\circ}$ depth sensing. However, following earlier works on conventional
stereo matching, prior state-of-the-art (SOTA) methods rely on a 3D
encoder-decoder block to regularize the cost volume, causing the whole system
complicated and sub-optimal results. Recently, the Recurrent All-pairs Field
Transforms (RAFT) based approach employs the recurrent update in 2D and has
efficiently improved image-matching tasks, \ie, optical flow, and stereo
matching. To bridge the gap between OSM and RAFT, we mainly propose an opposite
adaptive weighting scheme to seamlessly transform the outputs of spherical
sweeping of OSM into the required inputs for the recurrent update, thus
creating a recurrent omnidirectional stereo matching (RomniStereo) algorithm.
Furthermore, we introduce two techniques, \ie, grid embedding and adaptive
context feature generation, which also contribute to RomniStereo's performance.
Our best model improves the average MAE metric by 40.7\% over the previous SOTA
baseline across five datasets. When visualizing the results, our models
demonstrate clear advantages on both synthetic and realistic examples. The code
is available at \url{https://github.com/HalleyJiang/RomniStereo}.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04348" title="Abstract">arXiv:2401.04348</a> [<a href="/pdf/2401.04348" title="Download PDF">pdf</a>, <a href="/format/2401.04348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAMPAT: Low-Rank Adaption for Multilingual Paraphrasing Using  Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+K+M">Khoi M.Le</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Trinh Pham</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+T">Tho Quan</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024. Data and code are available at <a href="https://github.com/phkhanhtrinh23/LAMPAT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Paraphrases are texts that convey the same meaning while using different
words or sentence structures. It can be used as an automatic data augmentation
tool for many Natural Language Processing tasks, especially when dealing with
low-resource languages, where data shortage is a significant problem. To
generate a paraphrase in multilingual settings, previous studies have leveraged
the knowledge from the machine translation field, i.e., forming a paraphrase
through zero-shot machine translation in the same language. Despite good
performance on human evaluation, those methods still require parallel
translation datasets, thus making them inapplicable to languages that do not
have parallel corpora. To mitigate that problem, we proposed the first
unsupervised multilingual paraphrasing model, LAMPAT ($\textbf{L}$ow-rank
$\textbf{A}$daptation for $\textbf{M}$ultilingual $\textbf{P}$araphrasing using
$\textbf{A}$dversarial $\textbf{T}$raining), by which monolingual dataset is
sufficient enough to generate a human-like and diverse sentence. Throughout the
experiments, we found out that our method not only works well for English but
can generalize on unseen languages as well. Data and code are available at
https://github.com/phkhanhtrinh23/LAMPAT.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04349" title="Abstract">arXiv:2401.04349</a> [<a href="/pdf/2401.04349" title="Download PDF">pdf</a>, <a href="/ps/2401.04349" title="Download PostScript">ps</a>, <a href="/format/2401.04349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WebGPU-SPY: Finding Fingerprints in the Sandbox through GPU Cache  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferguson%2C+E">Ethan Ferguson</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A">Adam Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Naghibijouybari%2C+H">Hoda Naghibijouybari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Microarchitectural attacks on CPU structures have been studied in native
applications, as well as in web browsers. These attacks continue to be a
substantial threat to computing systems at all scales.
<br />With the proliferation of heterogeneous systems and integration of hardware
accelerators in every computing system, modern web browsers provide the support
of GPU-based acceleration for the graphics and rendering processes. Emerging
web standards also support the GPU acceleration of general-purpose computation
within web browsers.
<br />In this paper, we present a new attack vector for microarchitectural attacks
in web browsers. We use emerging GPU accelerating APIs in modern browsers
(specifically WebGPU) to launch a GPU-based cache side channel attack on the
compute stack of the GPU that spies on victim activities on the graphics
(rendering) stack of the GPU. Unlike prior works that rely on JavaScript APIs
or software interfaces to build timing primitives, we build the timer using GPU
hardware resources and develop a cache side channel attack on Intel's
integrated GPUs. We leverage the GPU's inherent parallelism at different levels
to develop high-resolution parallel attacks. We demonstrate that GPU-based
cache attacks can achieve a precision of 90 for website fingerprinting of 100
top websites. We also discuss potential countermeasures against the proposed
attack to secure the systems at a critical time when these web standards are
being developed and before they are widely deployed.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04350" title="Abstract">arXiv:2401.04350</a> [<a href="/pdf/2401.04350" title="Download PDF">pdf</a>, <a href="/format/2401.04350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-trained Model Guided Fine-Tuning for Zero-Shot Adversarial  Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguang Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale pre-trained vision-language models like CLIP have demonstrated
impressive performance across various tasks, and exhibit remarkable zero-shot
generalization capability, while they are also vulnerable to imperceptible
adversarial examples. Existing works typically employ adversarial training
(fine-tuning) as a defense method against adversarial examples. However, direct
application to the CLIP model may result in overfitting, compromising the
model's capacity for generalization. In this paper, we propose Pre-trained
Model Guided Adversarial Fine-Tuning (PMG-AFT) method, which leverages
supervision from the original pre-trained model by carefully designing an
auxiliary branch, to enhance the model's zero-shot adversarial robustness.
Specifically, PMG-AFT minimizes the distance between the features of
adversarial examples in the target model and those in the pre-trained model,
aiming to preserve the generalization features already captured by the
pre-trained model. Extensive Experiments on 15 zero-shot datasets demonstrate
that PMG-AFT significantly outperforms the state-of-the-art method, improving
the top-1 robust accuracy by an average of 4.99%. Furthermore, our approach
consistently improves clean accuracy by an average of 8.72%.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04351" title="Abstract">arXiv:2401.04351</a> [<a href="/pdf/2401.04351" title="Download PDF">pdf</a>, <a href="/format/2401.04351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Change Point Detection Integrated Remaining Useful Life Estimation  Model under Variable Operating Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arunan%2C+A">Anushiya Arunan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoli Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Control Engineering Practice Journal with DOI: <a href="https://doi.org/10.1016/j.conengprac.2023.105840">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">By informing the onset of the degradation process, health status evaluation
serves as a significant preliminary step for reliable remaining useful life
(RUL) estimation of complex equipment. This paper proposes a novel temporal
dynamics learning-based model for detecting change points of individual
devices, even under variable operating conditions, and utilises the learnt
change points to improve the RUL estimation accuracy. During offline model
development, the multivariate sensor data are decomposed to learn fused
temporal correlation features that are generalisable and representative of
normal operation dynamics across multiple operating conditions. Monitoring
statistics and control limit thresholds for normal behaviour are dynamically
constructed from these learnt temporal features for the unsupervised detection
of device-level change points. The detected change points then inform the
degradation data labelling for training a long short-term memory (LSTM)-based
RUL estimation model. During online monitoring, the temporal correlation
dynamics of a query device is monitored for breach of the control limit derived
in offline training. If a change point is detected, the device's RUL is
estimated with the well-trained offline model for early preventive action.
Using C-MAPSS turbofan engines as the case study, the proposed method improved
the accuracy by 5.6\% and 7.5\% for two scenarios with six operating
conditions, when compared to existing LSTM-based RUL estimation models that do
not consider heterogeneous change points.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04354" title="Abstract">arXiv:2401.04354</a> [<a href="/pdf/2401.04354" title="Download PDF">pdf</a>, <a href="/format/2401.04354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-enhanced Multi-perspective Video Representation Learning for  Scene Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuzheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+T">Tian Gan</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+L">Linlin Chao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qingpei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wei Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the explosive growth of video data in real-world applications, a
comprehensive representation of videos becomes increasingly important. In this
paper, we address the problem of video scene recognition, whose goal is to
learn a high-level video representation to classify scenes in videos. Due to
the diversity and complexity of video contents in realistic scenarios, this
task remains a challenge. Most existing works identify scenes for videos only
from visual or textual information in a temporal perspective, ignoring the
valuable information hidden in single frames, while several earlier studies
only recognize scenes for separate images in a non-temporal perspective. We
argue that these two perspectives are both meaningful for this task and
complementary to each other, meanwhile, externally introduced knowledge can
also promote the comprehension of videos. We propose a novel two-stream
framework to model video representations from multiple perspectives, i.e.
temporal and non-temporal perspectives, and integrate the two perspectives in
an end-to-end manner by self-distillation. Besides, we design a
knowledge-enhanced feature fusion and label prediction method that contributes
to naturally introducing knowledge into the task of video scene recognition.
Experiments conducted on a real-world dataset demonstrate the effectiveness of
our proposed method.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04357" title="Abstract">arXiv:2401.04357</a> [<a href="/pdf/2401.04357" title="Download PDF">pdf</a>, <a href="/format/2401.04357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Feedback Network for Unsupervised Point Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yifan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jihua Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, accepted by RAL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As a fundamental problem in computer vision, point cloud registration aims to
seek the optimal transformation for aligning a pair of point clouds. In most
existing methods, the information flows are usually forward transferring, thus
lacking the guidance from high-level information to low-level information.
Besides, excessive high-level information may be overly redundant, and directly
using it may conflict with the original low-level information. In this paper,
we propose a novel Iterative Feedback Network (IFNet) for unsupervised point
cloud registration, in which the representation of low-level features is
efficiently enriched by rerouting subsequent high-level features. Specifically,
our IFNet is built upon a series of Feedback Registration Block (FRB) modules,
with each module responsible for generating the feedforward rigid
transformation and feedback high-level features. These FRB modules are cascaded
and recurrently unfolded over time. Further, the Feedback Transformer is
designed to efficiently select relevant information from feedback high-level
features, which is utilized to refine the low-level features. What's more, we
incorporate a geometry-awareness descriptor to empower the network for making
full use of most geometric information, which leads to more precise
registration results. Extensive experiments on various benchmark datasets
demonstrate the superior registration performance of our IFNet.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04358" title="Abstract">arXiv:2401.04358</a> [<a href="/pdf/2401.04358" title="Download PDF">pdf</a>, <a href="/ps/2401.04358" title="Download PostScript">ps</a>, <a href="/format/2401.04358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Message-Passing Receiver for OCDM over Multi-Lag Multi-Doppler Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Ji%2C+F">Fei Ji</a> (2), 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Miaowen Wen</a> (2), 
<a href="/search/cs?searchtype=author&query=Qing%2C+H">Hua Qing</a> (3) ((1) Guangdong University of Finance, Guangzhou, China, (2) South China University of Technology, Guangzhou, China, (3) Zhengzhou University of Light Industry, Zhengzhou, China)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">As a new candidate waveform for the next generation wireless communications,
orthogonal chirp division multiplexing (OCDM) has attracted growing attention
for its ability to achieve full diversity in uncoded transmission, and its
robustness to narrow-band interference or impulsive noise. Under high mobility
channels with multiple lags and multiple Doppler-shifts (MLMD), the signal
suffers doubly selective (DS) fadings in time and frequency domain, and data
symbols modulated on orthogonal chirps are interfered by each other. To address
the problem of symbol detection of OCDM over MLMD channel, under the assumption
that path attenuation factors, delays, and Doppler shifts of the channel are
available, we first derive the closed-form channel matrix in Fresnel domain,
and then propose a low-complexity method to approximate it as a sparse matrix.
Based on the approximated Fresnel-domain channel, we propose a message passing
(MP) based detector to estimate the transmit symbols iteratively. Finally,
under two MLMD channels (an underspread channel for terrestrial vehicular
communication, and an overspread channel for narrow-band underwater acoustic
communications), Monte Carlo simulation results and analysis are provided to
validate its advantages as a promising detector for OCDM.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04360" title="Abstract">arXiv:2401.04360</a> [<a href="/pdf/2401.04360" title="Download PDF">pdf</a>, <a href="/ps/2401.04360" title="Download PostScript">ps</a>, <a href="/format/2401.04360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New non-GRS type MDS codes and NMDS codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shixin Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we study a class of special linear codes involving their
parameters, weight distributions, and self-orthogonal properties. On one hand,
we prove that such codes must be maximum distance separable (MDS) or near MDS
(NMDS) codes and completely determine their weight distributions with the help
of the solutions to some subset sum problems. Based on the well-known Schur
method, we also show that such codes are non-equivalent to generalized
Reed-Solomon codes. On the other hand, a sufficient and necessary condition for
such codes to be self-orthogonal is characterized. Based on this condition, we
further deduce that there are no self-dual codes in this class of linear codes
and explicitly construct two classes of almost self-dual codes.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04361" title="Abstract">arXiv:2401.04361</a> [<a href="/pdf/2401.04361" title="Download PDF">pdf</a>, <a href="/format/2401.04361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+J">Jianfeng Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kexin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixu Li</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wen Hua</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Ximing Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">An Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge-grounded dialogue (KGD) learns to generate an informative response
based on a given dialogue context and external knowledge (\emph{e.g.},
knowledge graphs; KGs). Recently, the emergence of large language models (LLMs)
and pre-training techniques has brought great success to knowledge-grounded
dialogue. However, when building KGD systems in real applications, there are
various real-world noises that are inevitable to face. For example, the
dialogue context might involve perturbations such as misspellings and
abbreviations. In addition, KGs typically suffer from incompletion and also
might contain erroneous and outdated facts. Such real-world noises pose a
challenge to the robustness of KGD systems and hinder their applications in the
real world. In this paper, we propose an entity-based contrastive learning
framework for improving the robustness of KGD. Specifically, we make use of the
entity information in a KGD sample to create both its positive and negative
samples which involve semantic-irrelevant and semantic-relevant perturbations,
respectively. The contrastive learning framework ensures the KGD model is aware
of these two types of perturbations, thus generating informative responses with
the potentially noisy inputs in real applications. Experimental results on
three benchmark datasets show that our method achieves new state-of-the-art
performance in terms of automatic evaluation scores, verifying its
effectiveness and potentiality. Furthermore, we show that our method can
generate better responses than comparison models in both the noisy and the
few-shot settings.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04362" title="Abstract">arXiv:2401.04362</a> [<a href="/pdf/2401.04362" title="Download PDF">pdf</a>, <a href="/format/2401.04362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representative Feature Extraction During Diffusion Process for Sketch  Extraction with One Example
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+K">Kwan Yun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngseo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+K">Kwanggyoon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+C+W">Chang Wook Seo</a>, 
<a href="/search/cs?searchtype=author&query=Noh%2C+J">Junyong Noh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages(main paper), 8 pages(supplementary material)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We introduce DiffSketch, a method for generating a variety of stylized
sketches from images. Our approach focuses on selecting representative features
from the rich semantics of deep features within a pretrained diffusion model.
This novel sketch generation method can be trained with one manual drawing.
Furthermore, efficient sketch extraction is ensured by distilling a trained
generator into a streamlined extractor. We select denoising diffusion features
through analysis and integrate these selected features with VAE features to
produce sketches. Additionally, we propose a sampling scheme for training
models using a conditional generative approach. Through a series of
comparisons, we verify that distilled DiffSketch not only outperforms existing
state-of-the-art sketch extraction methods but also surpasses diffusion-based
stylization methods in the task of extracting sketches.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04364" title="Abstract">arXiv:2401.04364</a> [<a href="/pdf/2401.04364" title="Download PDF">pdf</a>, <a href="/format/2401.04364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Facial Deepfake Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+B+M">Binh M. Le</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiwon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Tariq%2C+S">Shahroz Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+K">Kristen Moore</a>, 
<a href="/search/cs?searchtype=author&query=Abuadbba%2C+A">Alsharif Abuadbba</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S+S">Simon S. Woo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures, 5 table, under peer-review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deepfakes have rapidly emerged as a profound and serious threat to society,
primarily due to their ease of creation and dissemination. This situation has
triggered an accelerated development of deepfake detection technologies.
However, many existing detectors rely heavily on lab-generated datasets for
validation, which may not effectively prepare them for novel, emerging, and
real-world deepfake techniques. In this paper, we conduct an extensive and
comprehensive review and analysis of the latest state-of-the-art deepfake
detectors, evaluating them against several critical criteria. These criteria
facilitate the categorization of these detectors into 4 high-level groups and
13 fine-grained sub-groups, all aligned with a unified standard conceptual
framework. This classification and framework offer deep and practical insights
into the factors that affect detector efficacy. We assess the generalizability
of 16 leading detectors across various standard attack scenarios, including
black-box, white-box, and gray-box settings. Our systematized analysis and
experimentation lay the groundwork for a deeper understanding of deepfake
detectors and their generalizability, paving the way for future research
focused on creating detectors adept at countering various attack scenarios.
Additionally, this work offers insights for developing more proactive defenses
against deepfakes.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04367" title="Abstract">arXiv:2401.04367</a> [<a href="/pdf/2401.04367" title="Download PDF">pdf</a>, <a href="/format/2401.04367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic emotion and sentiment modelling of patient-reported  experiences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murray%2C+C">Curtis Murray</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+L">Lewis Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Tuke%2C+J">Jonathan Tuke</a>, 
<a href="/search/cs?searchtype=author&query=Mackay%2C+M">Mark Mackay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 10 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study introduces a novel methodology for modelling patient emotions from
online patient experience narratives. We employed metadata network topic
modelling to analyse patient-reported experiences from Care Opinion, revealing
key emotional themes linked to patient-caregiver interactions and clinical
outcomes. We develop a probabilistic, context-specific emotion recommender
system capable of predicting both multilabel emotions and binary sentiments
using a naive Bayes classifier using contextually meaningful topics as
predictors. The superior performance of our predicted emotions under this model
compared to baseline models was assessed using the information retrieval
metrics nDCG and Q-measure, and our predicted sentiments achieved an F1 score
of 0.921, significantly outperforming standard sentiment lexicons. This method
offers a transparent, cost-effective way to understand patient feedback,
enhancing traditional collection methods and informing individualised patient
care. Our findings are accessible via an R package and interactive dashboard,
providing valuable tools for healthcare researchers and practitioners.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04368" title="Abstract">arXiv:2401.04368</a> [<a href="/pdf/2401.04368" title="Download PDF">pdf</a>, <a href="/ps/2401.04368" title="Download PostScript">ps</a>, <a href="/format/2401.04368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Acute Kidney Injury Prediction through Integration of Drug  Features in Intensive Care Units
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manalu%2C+G+D+M">Gabriel D. M. Manalu</a>, 
<a href="/search/cs?searchtype=author&query=Christian%2C+M+M">Mulomba Mukendi Christian</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Songhee You</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hyebong Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Advanced Smart Convergence Vol.12 No.4
  434- 442 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The relationship between acute kidney injury (AKI) prediction and nephrotoxic
drugs, or drugs that adversely affect kidney function, is one that has yet to
be explored in the critical care setting. One contributing factor to this gap
in research is the limited investigation of drug modalities in the intensive
care unit (ICU) context, due to the challenges of processing prescription data
into the corresponding drug representations and a lack in the comprehensive
understanding of these drug representations. This study addresses this gap by
proposing a novel approach that leverages patient prescription data as a
modality to improve existing models for AKI prediction. We base our research on
Electronic Health Record (EHR) data, extracting the relevant patient
prescription information and converting it into the selected drug
representation for our research, the extended-connectivity fingerprint (ECFP).
Furthermore, we adopt a unique multimodal approach, developing machine learning
models and 1D Convolutional Neural Networks (CNN) applied to clinical drug
representations, establishing a procedure which has not been used by any
previous studies predicting AKI. The findings showcase a notable improvement in
AKI prediction through the integration of drug embeddings and other patient
cohort features. By using drug features represented as ECFP molecular
fingerprints along with common cohort features such as demographics and lab
test values, we achieved a considerable improvement in model performance for
the AKI prediction task over the baseline model which does not include the drug
representations as features, indicating that our distinct approach enhances
existing baseline techniques and highlights the relevance of drug data in
predicting AKI in the ICU setting
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04369" title="Abstract">arXiv:2401.04369</a> [<a href="/pdf/2401.04369" title="Download PDF">pdf</a>, <a href="/ps/2401.04369" title="Download PostScript">ps</a>, <a href="/format/2401.04369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Air Quality Forecasting Using Machine Learning: A Global perspective  with Relevance to Low-Resource Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christian%2C+M+M">Mulomba Mukendi Christian</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hyebong Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages. This is a conference proceeding Presented at: SIBR 2024 (Seoul) Conference on Interdisciplinary Business and Economics Research, 5th-6th January 2024, Seoul, South Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Air pollution stands as the fourth leading cause of death globally. While
extensive research has been conducted in this domain, most approaches rely on
large datasets when it comes to prediction. This limits their applicability in
low-resource settings though more vulnerable. This study addresses this gap by
proposing a novel machine learning approach for accurate air quality prediction
using two months of air quality data. By leveraging the World Weather
Repository, the meteorological, air pollutant, and Air Quality Index features
from 197 capital cities were considered to predict air quality for the next
day. The evaluation of several machine learning models demonstrates the
effectiveness of the Random Forest algorithm in generating reliable
predictions, particularly when applied to classification rather than
regression, approach which enhances the model's generalizability by 42%,
achieving a cross-validation score of 0.38 for regression and 0.89 for
classification. To instill confidence in the predictions, interpretable machine
learning was considered. Finally, a cost estimation comparing the
implementation of this solution in high-resource and low-resource settings is
presented including a tentative of technology licensing business model. This
research highlights the potential for resource-limited countries to
independently predict air quality while awaiting larger datasets to further
refine their predictions.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04371" title="Abstract">arXiv:2401.04371</a> [<a href="/pdf/2401.04371" title="Download PDF">pdf</a>, <a href="/format/2401.04371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategic Routing and Scheduling for Evacuations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+K+A">Kazi Ashik Islam</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D+Q">Da Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Marathe%2C+M">Madhav Marathe</a>, 
<a href="/search/cs?searchtype=author&query=Mortveit%2C+H">Henning Mortveit</a>, 
<a href="/search/cs?searchtype=author&query=Swarup%2C+S">Samarth Swarup</a>, 
<a href="/search/cs?searchtype=author&query=Vullikanti%2C+A">Anil Vullikanti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Evacuation planning is an essential part of disaster management where the
goal is to relocate people under imminent danger to safety. Although government
authorities may prescribe routes and a schedule, evacuees generally behave as
self-interested agents and may choose their action according to their own
selfish interests. It is crucial to understand the degree of inefficiency this
can cause to the evacuation process. However, existing research has mainly
focused on selfish routing, i.e., they consider route selection as the only
strategic action. In this paper, we present a strategic routing and scheduling
game, named the Evacuation Planning Game (EPG), where evacuees choose both
their route and the time of departure. We focus on confluent evacuation plans,
where, if two routes meet at a node then their remaining portion is identical.
We also use dynamic flows to model the time-varying traffic on roads during
evacuation. We show that every instance of EPG has at least one pure strategy
Nash equilibrium. We then present a polynomial time algorithm, the Sequential
Action Algorithm (SAA), for finding equilibria in a given instance.
Additionally, we provide bounds on how bad an equilibrium state can be compared
to a socially optimal state. Finally, We use Harris County of Houston, Texas as
our study area and construct a game instance for it. Our results show that, by
utilizing SAA, we can efficiently find equilibria in this instance that have
social objective close to the optimal value.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04374" title="Abstract">arXiv:2401.04374</a> [<a href="/pdf/2401.04374" title="Download PDF">pdf</a>, <a href="/format/2401.04374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Explainable Artificial Intelligence (XAI): A Data Mining  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Haoyi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=L%2C+X">Xuhong L</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiamin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinhao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zeyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Given the complexity and lack of transparency in deep neural networks (DNNs),
extensive efforts have been made to make these systems more interpretable or
explain their behaviors in accessible terms. Unlike most reviews, which focus
on algorithmic and model-centric perspectives, this work takes a "data-centric"
view, examining how data collection, processing, and analysis contribute to
explainable AI (XAI). We categorize existing work into three categories subject
to their purposes: interpretations of deep models, referring to feature
attributions and reasoning processes that correlate data points with model
outputs; influences of training data, examining the impact of training data
nuances, such as data valuation and sample anomalies, on decision-making
processes; and insights of domain knowledge, discovering latent patterns and
fostering new knowledge from data and models to advance social values and
scientific discovery. Specifically, we distill XAI methodologies into data
mining operations on training and testing data across modalities, such as
images, text, and tabular data, as well as on training logs, checkpoints,
models and other DNN behavior descriptors. In this way, our study offers a
comprehensive, data-centric examination of XAI from a lens of data mining
methods and applications.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04377" title="Abstract">arXiv:2401.04377</a> [<a href="/pdf/2401.04377" title="Download PDF">pdf</a>, <a href="/format/2401.04377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Real-World Aerial Vision Guidance with Categorical 6D Pose  Tracker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingtao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danwei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Tracking the object 6-DoF pose is crucial for various downstream robot tasks
and real-world applications. In this paper, we investigate the real-world robot
task of aerial vision guidance for aerial robotics manipulation, utilizing
category-level 6-DoF pose tracking. Aerial conditions inevitably introduce
special challenges, such as rapid viewpoint changes in pitch and roll. To
support this task and challenge, we firstly introduce a robust category-level
6-DoF pose tracker (Robust6DoF). This tracker leverages shape and temporal
prior knowledge to explore optimal inter-frame keypoint pairs, generated under
a priori structural adaptive supervision in a coarse-to-fine manner. Notably,
our Robust6DoF employs a Spatial-Temporal Augmentation module to deal with the
problems of the inter-frame differences and intra-class shape variations
through both temporal dynamic filtering and shape-similarity filtering. We
further present a Pose-Aware Discrete Servo strategy (PAD-Servo), serving as a
decoupling approach to implement the final aerial vision guidance task. It
contains two servo action policies to better accommodate the structural
properties of aerial robotics manipulation. Exhaustive experiments on four
well-known public benchmarks demonstrate the superiority of our Robust6DoF.
Real-world tests directly verify that our Robust6DoF along with PAD-Servo can
be readily used in real-world aerial robotic applications.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04378" title="Abstract">arXiv:2401.04378</a> [<a href="/pdf/2401.04378" title="Download PDF">pdf</a>, <a href="/format/2401.04378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing the Gerber-Shiu function with interest and a constant dividend  barrier by physics-informed neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yu%2C+Z">Zan Yu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+L">Lianzeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages; 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR); Risk Management (q-fin.RM)

</div>
<p class="mathjax">In this paper, we propose a new efficient method for calculating the
Gerber-Shiu discounted penalty function. Generally, the Gerber-Shiu function
usually satisfies a class of integro-differential equation. We introduce the
physics-informed neural networks (PINN) which embed a differential equation
into the loss of the neural network using automatic differentiation. In
addition, PINN is more free to set boundary conditions and does not rely on the
determination of the initial value. This gives us an idea to calculate more
general Gerber-Shiu functions. Numerical examples are provided to illustrate
the very good performance of our approximation.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04385" title="Abstract">arXiv:2401.04385</a> [<a href="/pdf/2401.04385" title="Download PDF">pdf</a>, <a href="/format/2401.04385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine unlearning through fine-grained model parameters perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Z">Zhiwei Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhuo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kenli Li</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+A">Anwitaman Datta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine unlearning techniques, which involve retracting data records and
reducing influence of said data on trained models, help with the user privacy
protection objective but incur significant computational costs. Weight
perturbation-based unlearning is a general approach, but it typically involves
globally modifying the parameters. We propose fine-grained Top-K and Random-k
parameters perturbed inexact machine unlearning strategies that address the
privacy needs while keeping the computational costs tractable.
<br />In order to demonstrate the efficacy of our strategies we also tackle the
challenge of evaluating the effectiveness of machine unlearning by considering
the model's generalization performance across both unlearning and remaining
data. To better assess the unlearning effect and model generalization, we
propose novel metrics, namely, the forgetting rate and memory retention rate.
However, for inexact machine unlearning, current metrics are inadequate in
quantifying the degree of forgetting that occurs after unlearning strategies
are applied. To address this, we introduce SPD-GAN, which subtly perturbs the
distribution of data targeted for unlearning. Then, we evaluate the degree of
unlearning by measuring the performance difference of the models on the
perturbed unlearning data before and after the unlearning process. By
implementing these innovative techniques and metrics, we achieve
computationally efficacious privacy protection in machine learning applications
without significant sacrifice of model performance. Furthermore, this approach
provides a novel method for evaluating the degree of unlearning.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04389" title="Abstract">arXiv:2401.04389</a> [<a href="/pdf/2401.04389" title="Download PDF">pdf</a>, <a href="/format/2401.04389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RaD-Net: A Repairing and Denoising Network for Speech Signal Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingshuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuangqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiaopeng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yuanjun Lv</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xianjun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chuanzeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yijian Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper introduces our repairing and denoising network (RaD-Net) for the
ICASSP 2024 Speech Signal Improvement (SSI) Challenge. We extend our previous
framework based on a two-stage network and propose an upgraded model.
Specifically, we replace the repairing network with COM-Net from TEA-PSE. In
addition, multi-resolution discriminators and multi-band discriminators are
adopted in the training stage. Finally, we use a three-step training strategy
to optimize our model. We submit two models with different sets of parameters
to meet the RTF requirement of the two tracks. According to the official
results, the proposed systems rank 2nd in track 1 and 3rd in track 2.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04390" title="Abstract">arXiv:2401.04390</a> [<a href="/pdf/2401.04390" title="Download PDF">pdf</a>, <a href="/format/2401.04390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Noisy Labels: Interconnection of Two  Expectation-Maximizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Heewon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H+S">Hyun Sung Chang</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kiho Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaeyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bohyung Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Labor-intensive labeling becomes a bottleneck in developing computer vision
algorithms based on deep learning. For this reason, dealing with imperfect
labels has increasingly gained attention and has become an active field of
study. We address learning with noisy labels (LNL) problem, which is formalized
as a task of finding a structured manifold in the midst of noisy data. In this
framework, we provide a proper objective function and an optimization algorithm
based on two expectation-maximization (EM) cycles. The separate networks
associated with the two EM cycles collaborate to optimize the objective
function, where one model is for distinguishing clean labels from corrupted
ones while the other is for refurbishing the corrupted labels. This approach
results in a non-collapsing LNL-flywheel model in the end. Experiments show
that our algorithm achieves state-of-the-art performance in multiple standard
benchmarks with substantial margins under various types of label noise.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04394" title="Abstract">arXiv:2401.04394</a> [<a href="/pdf/2401.04394" title="Download PDF">pdf</a>, <a href="/format/2401.04394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SonicVisionLM: Playing Sound with Vision Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhifeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shengye Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengtian Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qile He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">There has been a growing interest in the task of generating sound for silent
videos, primarily because of its practicality in streamlining video
post-production. However, existing methods for video-sound generation attempt
to directly create sound from visual representations, which can be challenging
due to the difficulty of aligning visual representations with audio
representations. In this paper, we present SonicVisionLM, a novel framework
aimed at generating a wide range of sound effects by leveraging vision language
models. Instead of generating audio directly from video, we use the
capabilities of powerful vision language models (VLMs). When provided with a
silent video, our approach first identifies events within the video using a VLM
to suggest possible sounds that match the video content. This shift in approach
transforms the challenging task of aligning image and audio into more
well-studied sub-problems of aligning image-to-text and text-to-audio through
the popular diffusion models. To improve the quality of audio recommendations
with LLMs, we have collected an extensive dataset that maps text descriptions
to specific sound effects and developed temporally controlled audio adapters.
Our approach surpasses current state-of-the-art methods for converting video to
audio, resulting in enhanced synchronization with the visuals and improved
alignment between audio and video components. Project page:
https://yusiissy.github.io/SonicVisionLM.github.io/
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04397" title="Abstract">arXiv:2401.04397</a> [<a href="/pdf/2401.04397" title="Download PDF">pdf</a>, <a href="/format/2401.04397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Higher-Order Cognitive Models in Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keurulainen%2C+O">Oskar Keurulainen</a>, 
<a href="/search/cs?searchtype=author&query=Alcan%2C+G">Gokhan Alcan</a>, 
<a href="/search/cs?searchtype=author&query=Kyrki%2C+V">Ville Kyrki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, to appear in the CAIHu bridge program at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Building machines capable of efficiently collaborating with humans has been a
longstanding goal in artificial intelligence. Especially in the presence of
uncertainties, optimal cooperation often requires that humans and artificial
agents model each other's behavior and use these models to infer underlying
goals, beliefs or intentions, potentially involving multiple levels of
recursion. Empirical evidence for such higher-order cognition in human behavior
is also provided by previous works in cognitive science, linguistics, and
robotics. We advocate for a new paradigm for active learning for human feedback
that utilises humans as active data sources while accounting for their higher
levels of agency. In particular, we discuss how increasing level of agency
results in qualitatively different forms of rational communication between an
active learning system and a teacher. Additionally, we provide a practical
example of active learning using a higher-order cognitive model. This is
accompanied by a computational study that underscores the unique behaviors that
this model produces.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04398" title="Abstract">arXiv:2401.04398</a> [<a href="/pdf/2401.04398" title="Download PDF">pdf</a>, <a href="/format/2401.04398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain-of-Table: Evolving Tables in the Reasoning Chain for Table  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chun-Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Eisenschlos%2C+J+M">Julian Martin Eisenschlos</a>, 
<a href="/search/cs?searchtype=author&query=Perot%2C+V">Vincent Perot</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Miculicich%2C+L">Lesly Miculicich</a>, 
<a href="/search/cs?searchtype=author&query=Fujii%2C+Y">Yasuhisa Fujii</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chen-Yu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+T">Tomas Pfister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Table-based reasoning with large language models (LLMs) is a promising
direction to tackle many table understanding tasks, such as table-based
question answering and fact verification. Compared with generic reasoning,
table-based reasoning requires the extraction of underlying semantics from both
free-form questions and semi-structured tabular data. Chain-of-Thought and its
similar approaches incorporate the reasoning chain in the form of textual
context, but it is still an open question how to effectively leverage tabular
data in the reasoning chain. We propose the Chain-of-Table framework, where
tabular data is explicitly used in the reasoning chain as a proxy for
intermediate thoughts. Specifically, we guide LLMs using in-context learning to
iteratively generate operations and update the table to represent a tabular
reasoning chain. LLMs can therefore dynamically plan the next operation based
on the results of the previous ones. This continuous evolution of the table
forms a chain, showing the reasoning process for a given tabular problem. The
chain carries structured information of the intermediate results, enabling more
accurate and reliable predictions. Chain-of-Table achieves new state-of-the-art
performance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLM
choices.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04402" title="Abstract">arXiv:2401.04402</a> [<a href="/pdf/2401.04402" title="Download PDF">pdf</a>, <a href="/format/2401.04402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IGNITE: Individualized GeNeration of Imputations in Time-series  Electronic health records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosheh%2C+G+O">Ghadeer O. Ghosheh</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tingting Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Electronic Health Records present a valuable modality for driving
personalized medicine, where treatment is tailored to fit individual-level
differences. For this purpose, many data-driven machine learning and
statistical models rely on the wealth of longitudinal EHRs to study patients'
physiological and treatment effects. However, longitudinal EHRs tend to be
sparse and highly missing, where missingness could also be informative and
reflect the underlying patient's health status. Therefore, the success of
data-driven models for personalized medicine highly depends on how the EHR data
is represented from physiological data, treatments, and the missing values in
the data. To this end, we propose a novel deep-learning model that learns the
underlying patient dynamics over time across multivariate data to generate
personalized realistic values conditioning on an individual's demographic
characteristics and treatments. Our proposed model, IGNITE (Individualized
GeNeration of Imputations in Time-series Electronic health records), utilises a
conditional dual-variational autoencoder augmented with dual-stage attention to
generate missing values for an individual. In IGNITE, we further propose a
novel individualized missingness mask (IMM), which helps our model generate
values based on the individual's observed data and missingness patterns. We
further extend the use of IGNITE from imputing missingness to a personalized
data synthesizer, where it generates missing EHRs that were never observed
prior or even generates new patients for various applications. We validate our
model on three large publicly available datasets and show that IGNITE
outperforms state-of-the-art approaches in missing data reconstruction and task
prediction.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04403" title="Abstract">arXiv:2401.04403</a> [<a href="/pdf/2401.04403" title="Download PDF">pdf</a>, <a href="/format/2401.04403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MST: Adaptive Multi-Scale Tokens Guided Interactive Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Long Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanghong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongquan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jun Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the field of Industrial Informatics, interactive segmentation has gained
significant attention for its application in human-computer interaction and
data annotation. Existing algorithms, however, face challenges in balancing the
segmentation accuracy between large and small targets, often leading to an
increased number of user interactions. To tackle this, a novel multi-scale
token adaptation algorithm, leveraging token similarity, has been devised to
enhance segmentation across varying target sizes. This algorithm utilizes a
differentiable top-k tokens selection mechanism, allowing for fewer tokens to
be used while maintaining efficient multi-scale token interaction. Furthermore,
a contrastive loss is introduced to better discriminate between target and
background tokens, improving the correctness and robustness of the tokens
similar to the target. Extensive benchmarking shows that the algorithm achieves
state-of-the-art (SOTA) performance compared to current methods. An interactive
demo and all reproducible codes will be released at
https://github.com/hahamyt/mst.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04405" title="Abstract">arXiv:2401.04405</a> [<a href="/pdf/2401.04405" title="Download PDF">pdf</a>, <a href="/format/2401.04405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Transcoding Resolution Prediction for Efficient Per-Title  Bitrate Ladder Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinhai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mengxi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shijie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 2024 Data Compression Conference (DCC) for presentation as a poster. This is the full paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Adaptive video streaming requires efficient bitrate ladder construction to
meet heterogeneous network conditions and end-user demands. Per-title optimized
encoding typically traverses numerous encoding parameters to search the
Pareto-optimal operating points for each video. Recently, researchers have
attempted to predict the content-optimized bitrate ladder for pre-encoding
overhead reduction. However, existing methods commonly estimate the encoding
parameters on the Pareto front and still require subsequent pre-encodings. In
this paper, we propose to directly predict the optimal transcoding resolution
at each preset bitrate for efficient bitrate ladder construction. We adopt a
Temporal Attentive Gated Recurrent Network to capture spatial-temporal features
and predict transcoding resolutions as a multi-task classification problem. We
demonstrate that content-optimized bitrate ladders can thus be efficiently
determined without any pre-encoding. Our method well approximates the
ground-truth bitrate-resolution pairs with a slight Bj{\o}ntegaard Delta rate
loss of 1.21% and significantly outperforms the state-of-the-art fixed ladder.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04406" title="Abstract">arXiv:2401.04406</a> [<a href="/pdf/2401.04406" title="Download PDF">pdf</a>, <a href="/format/2401.04406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MapAI: Precision in Building Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jyhne%2C+S+R">Sander Riis&#xf8;en Jyhne</a>, 
<a href="/search/cs?searchtype=author&query=Goodwin%2C+M">Morten Goodwin</a>, 
<a href="/search/cs?searchtype=author&query=Andersen%2C+P+A">Per Arne Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Oveland%2C+I">Ivar Oveland</a>, 
<a href="/search/cs?searchtype=author&query=Nossum%2C+A+S">Alexander Salveson Nossum</a>, 
<a href="/search/cs?searchtype=author&query=Ormseth%2C+K">Karianne Ormseth</a>, 
<a href="/search/cs?searchtype=author&query=%C3%98rstavik%2C+M">Mathilde &#xd8;rstavik</a>, 
<a href="/search/cs?searchtype=author&query=Flatman%2C+A+C">Andrew C. Flatman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, competition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">MapAI: Precision in Building Segmentation is a competition arranged with the
Norwegian Artificial Intelligence Research Consortium (NORA) in collaboration
with Centre for Artificial Intelligence Research at the University of Agder
(CAIR), the Norwegian Mapping Authority, AI:Hub, Norkart, and the Danish Agency
for Data Supply and Infrastructure. The competition will be held in the fall of
2022. It will be concluded at the Northern Lights Deep Learning conference
focusing on the segmentation of buildings using aerial images and laser data.
We propose two different tasks to segment buildings, where the first task can
only utilize aerial images, while the second must use laser data (LiDAR) with
or without aerial images. Furthermore, we use IoU and Boundary IoU to properly
evaluate the precision of the models, with the latter being an IoU measure that
evaluates the results' boundaries. We provide the participants with a training
dataset and keep a test dataset for evaluation.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04408" title="Abstract">arXiv:2401.04408</a> [<a href="/pdf/2401.04408" title="Download PDF">pdf</a>, <a href="/format/2401.04408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Embedding Dimension Optimization During Training for  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Q">Qinyi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Penghan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+F">Fan Lai</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiachen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaohan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jun Song</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+W">Wei-Yu Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuxi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xuehai Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Huge embedding tables in modern Deep Learning Recommender Models (DLRM)
require prohibitively large memory during training and inference. Aiming to
reduce the memory footprint of training, this paper proposes FIne-grained
In-Training Embedding Dimension optimization (FIITED). Given the observation
that embedding vectors are not equally important, FIITED adjusts the dimension
of each individual embedding vector continuously during training, assigning
longer dimensions to more important embeddings while adapting to dynamic
changes in data. A novel embedding storage system based on virtually-hashed
physically-indexed hash tables is designed to efficiently implement the
embedding dimension adjustment and effectively enable memory saving.
Experiments on two industry models show that FIITED is able to reduce the size
of embeddings by more than 65% while maintaining the trained model's quality,
saving significantly more memory than a state-of-the-art in-training embedding
pruning method. On public click-through rate prediction datasets, FIITED is
able to prune up to 93.75%-99.75% embeddings without significant accuracy loss.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04411" title="Abstract">arXiv:2401.04411</a> [<a href="/pdf/2401.04411" title="Download PDF">pdf</a>, <a href="/format/2401.04411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hiding Information for Secure and Covert Data Storage in Commercial  ReRAM Chips
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdaus%2C+F">Farah Ferdaus</a>, 
<a href="/search/cs?searchtype=author&query=Talukder%2C+B+M+S+B">B. M. S. Bahar Talukder</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+T">Md Tauhidur Rahman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2204.02104">arXiv:2204.02104</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This article introduces a novel, low-cost technique for hiding data in
commercially available resistive-RAM (ReRAM) chips. The data is kept hidden in
ReRAM cells by manipulating its analog physical properties through switching
($\textit{set/reset}$) operations. This hidden data, later, is retrieved by
sensing the changes in cells' physical properties (i.e., $\textit{set/reset}$
time of the memory cells). The proposed system-level hiding technique does not
affect the normal memory operations and does not require any hardware
modifications. Furthermore, the proposed hiding approach is robust against
temperature variations and the aging of the devices through normal read/write
operation. The silicon results show that our proposed data hiding technique is
acceptably fast with ${\sim}0.4bit/min$ of encoding and ${\sim}15.625bits/s$ of
retrieval rates, and the hidden message is unrecoverable without the knowledge
of the secret key, which is used to enhance the security of hidden information.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04422" title="Abstract">arXiv:2401.04422</a> [<a href="/pdf/2401.04422" title="Download PDF">pdf</a>, <a href="/format/2401.04422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Text Similarity based on Semantic Concept Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=der+Br%C3%BCck%2C+T+v">Tim vor der Br&#xfc;ck</a>, 
<a href="/search/cs?searchtype=author&query=Pouly%2C+M">Marc Pouly</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IARIA Congress Proceedings, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Due to their ease of use and high accuracy, Word2Vec (W2V) word embeddings
enjoy great success in the semantic representation of words, sentences, and
whole documents as well as for semantic similarity estimation. However, they
have the shortcoming that they are directly extracted from a surface
representation, which does not adequately represent human thought processes and
also performs poorly for highly ambiguous words. Therefore, we propose Semantic
Concept Embeddings (CE) based on the MultiNet Semantic Network (SN) formalism,
which addresses both shortcomings. The evaluation on a marketing target group
distribution task showed that the accuracy of predicted target groups can be
increased by combining traditional word embeddings with semantic CEs.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04423" title="Abstract">arXiv:2401.04423</a> [<a href="/pdf/2401.04423" title="Download PDF">pdf</a>, <a href="/format/2401.04423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Sequential Recommendation with Collaborative  Confusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yujie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mine%2C+T">Tsunenori Mine</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Moyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ben%2C+X">Xianye Ben</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yujun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Sequential recommendation has attracted a lot of attention from both academia
and industry, however the privacy risks associated to gathering and
transferring users' personal interaction data are often underestimated or
ignored. Existing privacy-preserving studies are mainly applied to traditional
collaborative filtering or matrix factorization rather than sequential
recommendation. Moreover, these studies are mostly based on differential
privacy or federated learning, which often leads to significant performance
degradation, or has high requirements for communication. In this work, we
address privacy-preserving from a different perspective. Unlike existing
research, we capture collaborative signals of neighbor interaction sequences
and directly inject indistinguishable items into the target sequence before the
recommendation process begins, thereby increasing the perplexity of the target
sequence. Even if the target interaction sequence is obtained by attackers, it
is difficult to discern which ones are the actual user interaction records. To
achieve this goal, we propose a CoLlaborative-cOnfusion seqUential recommenDer,
namely CLOUD, which incorporates a collaborative confusion mechanism to edit
the raw interaction sequences before conducting recommendation. Specifically,
CLOUD first calculates the similarity between the target interaction sequence
and other neighbor sequences to find similar sequences. Then, CLOUD considers
the shared representation of the target sequence and similar sequences to
determine the operation to be performed: keep, delete, or insert. We design a
copy mechanism to make items from similar sequences have a higher probability
to be inserted into the target sequence. Finally, the modified sequence is used
to train the recommender and predict the next item.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04425" title="Abstract">arXiv:2401.04425</a> [<a href="/pdf/2401.04425" title="Download PDF">pdf</a>, <a href="/format/2401.04425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-forests: Domain generalization on random forests with meta-learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kosmas%2C+P">Panagiotis Kosmas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by ACML2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Domain generalization is a popular machine learning technique that enables
models to perform well on the unseen target domain, by learning from multiple
source domains. Domain generalization is useful in cases where data is limited,
difficult, or expensive to collect, such as in object recognition and
biomedicine. In this paper, we propose a novel domain generalization algorithm
called "meta-forests", which builds upon the basic random forests model by
incorporating the meta-learning strategy and maximum mean discrepancy measure.
The aim of meta-forests is to enhance the generalization ability of classifiers
by reducing the correlation among trees and increasing their strength. More
specifically, meta-forests conducts meta-learning optimization during each
meta-task, while also utilizing the maximum mean discrepancy as a
regularization term to penalize poor generalization performance in the
meta-test process. To evaluate the effectiveness of our algorithm, we test it
on two publicly object recognition datasets and a glucose monitoring dataset
that we have used in a previous study. Our results show that meta-forests
outperforms state-of-the-art approaches in terms of generalization performance
on both object recognition and glucose monitoring datasets.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04429" title="Abstract">arXiv:2401.04429</a> [<a href="/pdf/2401.04429" title="Download PDF">pdf</a>, <a href="/format/2401.04429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> i-Rebalance: Personalized Vehicle Repositioning for Supply Demand  Balance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peiyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qiyuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wanyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weiwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wencan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Guanyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yan Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Ride-hailing platforms have been facing the challenge of balancing demand and
supply. Existing vehicle reposition techniques often treat drivers as
homogeneous agents and relocate them deterministically, assuming compliance
with the reposition. In this paper, we consider a more realistic and
driver-centric scenario where drivers have unique cruising preferences and can
decide whether to take the recommendation or not on their own. We propose
i-Rebalance, a personalized vehicle reposition technique with deep
reinforcement learning (DRL). i-Rebalance estimates drivers' decisions on
accepting reposition recommendations through an on-field user study involving
99 real drivers. To optimize supply-demand balance and enhance preference
satisfaction simultaneously, i-Rebalance has a sequential reposition strategy
with dual DRL agents: Grid Agent to determine the reposition order of idle
vehicles, and Vehicle Agent to provide personalized recommendations to each
vehicle in the pre-defined order. This sequential learning strategy facilitates
more effective policy training within a smaller action space compared to
traditional joint-action methods. Evaluation of real-world trajectory data
shows that i-Rebalance improves driver acceptance rate by 38.07% and total
driver income by 9.97%.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04435" title="Abstract">arXiv:2401.04435</a> [<a href="/pdf/2401.04435" title="Download PDF">pdf</a>, <a href="/format/2401.04435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware Sampling for Long-tailed Semi-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Duo Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Menghan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao-Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For semi-supervised learning with imbalance classes, the long-tailed
distribution of data will increase the model prediction bias toward dominant
classes, undermining performance on less frequent classes. Existing methods
also face challenges in ensuring the selection of sufficiently reliable
pseudo-labels for model training and there is a lack of mechanisms to adjust
the selection of more reliable pseudo-labels based on different training
stages. To mitigate this issue, we introduce uncertainty into the modeling
process for pseudo-label sampling, taking into account that the model
performance on the tailed classes varies over different training stages. For
example, at the early stage of model training, the limited predictive accuracy
of model results in a higher rate of uncertain pseudo-labels. To counter this,
we propose an Uncertainty-Aware Dynamic Threshold Selection (UDTS) approach.
This approach allows the model to perceive the uncertainty of pseudo-labels at
different training stages, thereby adaptively adjusting the selection
thresholds for different classes. Compared to other methods such as the
baseline method FixMatch, UDTS achieves an increase in accuracy of at least
approximately 5.26%, 1.75%, 9.96%, and 1.28% on the natural scene image
datasets CIFAR10-LT, CIFAR100-LT, STL-10-LT, and the medical image dataset
TissueMNIST, respectively. The source code of UDTS is publicly available at:
https://github.com/yangk/UDTS.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04437" title="Abstract">arXiv:2401.04437</a> [<a href="/pdf/2401.04437" title="Download PDF">pdf</a>, <a href="/format/2401.04437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Analysis of Anomaly Detection on Hyperspectral Imaging Using  Dimension Reduction Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">YeongHyeon Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 4 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent studies try to use hyperspectral imaging (HSI) to detect foreign
matters in products because it enables to visualize the invisible wavelengths
including ultraviolet and infrared. Considering the enormous image channels of
the HSI, several dimension reduction methods-e.g., PCA or UMAP-can be
considered to reduce but those cannot ease the fundamental limitations, as
follows: (1) latency of HSI capturing. (2) less explanation ability of the
important channels. In this paper, to circumvent the aforementioned methods,
one of the ways to channel reduction, on anomaly detection proposed HSI.
Different from feature extraction methods (i.e., PCA or UMAP), feature
selection can sort the feature by impact and show better explainability so we
might redesign the task-optimized and cost-effective spectroscopic camera. Via
the extensive experiment results with synthesized MVTec AD dataset, we confirm
that the feature selection method shows 6.90x faster at the inference phase
compared with feature extraction-based approaches while preserving anomaly
detection performance. Ultimately, we conclude the advantage of feature
selection which is effective yet fast.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04441" title="Abstract">arXiv:2401.04441</a> [<a href="/pdf/2401.04441" title="Download PDF">pdf</a>, <a href="/format/2401.04441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image classification network enhancement methods based on knowledge  injection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yishuang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The current deep neural network algorithm still stays in the end-to-end
training supervision method like Image-Label pairs, which makes traditional
algorithm is difficult to explain the reason for the results, and the
prediction logic is difficult to understand and analyze. The current algorithm
does not use the existing human knowledge information, which makes the model
not in line with the human cognition model and makes the model not suitable for
human use. In order to solve the above problems, the present invention provides
a deep neural network training method based on the human knowledge, which uses
the human cognition model to construct the deep neural network training model,
and uses the existing human knowledge information to construct the deep neural
network training model. This paper proposes a multi-level hierarchical deep
learning algorithm, which is composed of multi-level hierarchical deep neural
network architecture and multi-level hierarchical deep learning framework. The
experimental results show that the proposed algorithm can effectively explain
the hidden information of the neural network. The goal of our study is to
improve the interpretability of deep neural networks (DNNs) by providing an
analysis of the impact of knowledge injection on the classification task. We
constructed a knowledge injection dataset with matching knowledge data and
image classification data. The knowledge injection dataset is the benchmark
dataset for the experiments in the paper. Our model expresses the improvement
in interpretability and classification task performance of hidden layers at
different scales.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04446" title="Abstract">arXiv:2401.04446</a> [<a href="/pdf/2401.04446" title="Download PDF">pdf</a>, <a href="/format/2401.04446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Dataflow Diagrams Impact Software Security Analysis: an Empirical  Experiment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+S">Simon Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Ferreyra%2C+N+E+D">Nicol&#xe1;s E. D&#xed;az Ferreyra</a>, 
<a href="/search/cs?searchtype=author&query=Qu%C3%A9val%2C+P">Pierre-Jean Qu&#xe9;val</a>, 
<a href="/search/cs?searchtype=author&query=Simhandl%2C+G">Georg Simhandl</a>, 
<a href="/search/cs?searchtype=author&query=Zdun%2C+U">Uwe Zdun</a>, 
<a href="/search/cs?searchtype=author&query=Scandariato%2C+R">Riccardo Scandariato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Models of software systems are used throughout the software development
lifecycle. Dataflow diagrams (DFDs), in particular, are well-established
resources for security analysis. Many techniques, such as threat modelling, are
based on DFDs of the analysed application. However, their impact on the
performance of analysts in a security analysis setting has not been explored
before. In this paper, we present the findings of an empirical experiment
conducted to investigate this effect. Following a within-groups design,
participants were asked to solve security-relevant tasks for a given
microservice application. In the control condition, the participants had to
examine the source code manually. In the model-supported condition, they were
additionally provided a DFD of the analysed application and traceability
information linking model items to artefacts in source code. We found that the
participants (n = 24) performed significantly better in answering the analysis
tasks correctly in the model-supported condition (41% increase in analysis
correctness). Further, participants who reported using the provided
traceability information performed better in giving evidence for their answers
(315% increase in correctness of evidence). Finally, we identified three open
challenges of using DFDs for security analysis based on the insights gained in
the experiment.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04448" title="Abstract">arXiv:2401.04448</a> [<a href="/pdf/2401.04448" title="Download PDF">pdf</a>, <a href="/format/2401.04448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Dataset for Non-Destructive Inspection of Handwritten Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breci%2C+E">Eleonora Breci</a> (1), 
<a href="/search/cs?searchtype=author&query=Guarnera%2C+L">Luca Guarnera</a> (1), 
<a href="/search/cs?searchtype=author&query=Battiato%2C+S">Sebastiano Battiato</a> (1) ((1) University of Catania)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Forensic handwriting examination is a branch of Forensic Science that aims to
examine handwritten documents in order to properly define or hypothesize the
manuscript's author. These analysis involves comparing two or more (digitized)
documents through a comprehensive comparison of intrinsic local and global
features. If a correlation exists and specific best practices are satisfied,
then it will be possible to affirm that the documents under analysis were
written by the same individual. The need to create sophisticated tools capable
of extracting and comparing significant features has led to the development of
cutting-edge software with almost entirely automated processes, improving the
forensic examination of handwriting and achieving increasingly objective
evaluations. This is made possible by algorithmic solutions based on purely
mathematical concepts. Machine Learning and Deep Learning models trained with
specific datasets could turn out to be the key elements to best solve the task
at hand. In this paper, we proposed a new and challenging dataset consisting of
two subsets: the first consists of 21 documents written either by the classic
``pen and paper" approach (and later digitized) and directly acquired on common
devices such as tablets; the second consists of 362 handwritten manuscripts by
124 different people, acquired following a specific pipeline. Our study
pioneered a comparison between traditionally handwritten documents and those
produced with digital tools (e.g., tablets). Preliminary results on the
proposed datasets show that 90% classification accuracy can be achieved on the
first subset (documents written on both paper and pen and later digitized and
on tablets) and 96% on the second portion of the data. The datasets are
available at
https://iplab.dmi.unict.it/mfs/forensic-handwriting-analysis/novel-dataset-2023/.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04452" title="Abstract">arXiv:2401.04452</a> [<a href="/pdf/2401.04452" title="Download PDF">pdf</a>, <a href="/format/2401.04452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Competitions and Benchmarks, Practical issues: Proposals, grant  money, sponsors, prizes, dissemination, publicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Richard%2C+M">Magali Richard</a> (TIMC-MAGe), 
<a href="/search/cs?searchtype=author&query=Blum%2C+Y">Yuna Blum</a> (IGDR), 
<a href="/search/cs?searchtype=author&query=Guinney%2C+J">Justin Guinney</a>, 
<a href="/search/cs?searchtype=author&query=Stolovitzky%2C+G">Gustavo Stolovitzky</a>, 
<a href="/search/cs?searchtype=author&query=Pav%C3%A3o%2C+A">Adrien Pav&#xe3;o</a> (LRI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This chapter provides a comprehensive overview of the pragmatic aspects
involved in organizing AI competitions. We begin by discussing strategies to
incentivize participation, touching upon effective communication techniques,
aligning with trending topics in the field, structuring awards, potential
recruitment opportunities, and more. We then shift to the essence of community
engagement, and into organizational best practices and effective means of
disseminating challenge outputs. Lastly, the chapter addresses the logistics,
exposing on costs, required manpower, and resource allocation for effectively
managing and executing a challenge. By examining these practical problems,
readers will gain actionable insights to navigate the multifaceted landscape of
AI competition organization, from inception to completion.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04454" title="Abstract">arXiv:2401.04454</a> [<a href="/pdf/2401.04454" title="Download PDF">pdf</a>, <a href="/ps/2401.04454" title="Download PostScript">ps</a>, <a href="/format/2401.04454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Character comes from practice: longitudinal practice-based ethics  training in data science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bezuidenhout%2C+L">Louise Bezuidenhout</a>, 
<a href="/search/cs?searchtype=author&query=Ratti%2C+E">Emanuele Ratti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In this chapter, we propose a non-traditional RCR training in data science
that is grounded into a virtue theory framework. First, we delineate the
approach in more theoretical detail, by discussing how the goal of RCR training
is to foster the cultivation of certain moral abilities. We specify the nature
of these abilities: while the ideal is the cultivation of virtues, the limited
space allowed by RCR modules can only facilitate the cultivation of superficial
abilities or proto-virtues, which help students to familiarize with moral and
political issues in the data science environment. Third, we operationalize our
approach by stressing that (proto-)virtue acquisition (like skill acquisition)
occurs through the technical and social tasks of daily data science activities,
where these repetitive tasks provide the opportunities to develop
(proto-)virtue capacity and to support the development of ethically robust data
systems. Finally, we discuss a concrete example of how this approach has been
implemented. In particular, we describe how this method is applied to teach
data ethics to students participating in the CODATA-RDA Data Science Summer
Schools.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04456" title="Abstract">arXiv:2401.04456</a> [<a href="/pdf/2401.04456" title="Download PDF">pdf</a>, <a href="/format/2401.04456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A pressure-robust Discrete de Rham scheme for the Navier-Stokes  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Di+Pietro%2C+D+A">Daniele A. Di Pietro</a>, 
<a href="/search/math?searchtype=author&query=Droniou%2C+J">Jerome Droniou</a>, 
<a href="/search/math?searchtype=author&query=Qian%2C+J+J">Jia Jia Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work we design and analyse a Discrete de Rham (DDR) method for the
incompressible Navier-Stokes equations. Our focus is, more specifically, on the
SDDR variant, where a reduction in the number of unknowns is obtained using
serendipity techniques. The main features of the DDR approach are the support
of general meshes and arbitrary approximation orders. The method we develop is
based on the curl-curl formulation of the momentum equation and, through
compatibility with the Helmholtz-Hodge decomposition, delivers pressure-robust
error estimates for the velocity. It also enables non-standard boundary
conditions, such as imposing the value of the pressure on the boundary.
In-depth numerical validation on a complete panel of tests including general
polyhedral meshes is provided. The paper also contains an appendix where bounds
on DDR potential reconstructions and differential operators are proved in the
more general framework of Polytopal Exterior Calculus.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04461" title="Abstract">arXiv:2401.04461</a> [<a href="/pdf/2401.04461" title="Download PDF">pdf</a>, <a href="/format/2401.04461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-domain spectral approach to rational-order fractional derivatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Klein%2C+C">C. Klein</a>, 
<a href="/search/math?searchtype=author&query=Stoilov%2C+N">N. Stoilov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We propose a method to numerically compute fractional derivatives (or the
fractional Laplacian) on the whole real line via Riesz fractional integrals.
The compactified real line is divided into a number of intervals, thus
amounting to a multi-domain approach; after transformations in accordance with
the underlying $Z_{q}$ curve ensuring analyticity of the respective integrands,
the integrals over the different domains are computed with a Clenshaw-Curtis
algorithm. As an example, we consider solitary waves for fractional Korteweg-de
Vries equations and compare these to results obtained with a discrete Fourier
transform.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04463" title="Abstract">arXiv:2401.04463</a> [<a href="/pdf/2401.04463" title="Download PDF">pdf</a>, <a href="/format/2401.04463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D3AD: Dynamic Denoising Diffusion Probabilistic Model for Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tebbe%2C+J">Justin Tebbe</a>, 
<a href="/search/cs?searchtype=author&query=Tayyub%2C+J">Jawad Tayyub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have found valuable applications in anomaly detection by
capturing the nominal data distribution and identifying anomalies via
reconstruction. Despite their merits, they struggle to localize anomalies of
varying scales, especially larger anomalies like entire missing components.
Addressing this, we present a novel framework that enhances the capability of
diffusion models, by extending the previous introduced implicit conditioning
approach Meng et al. (2022) in three significant ways. First, we incorporate a
dynamic step size computation that allows for variable noising steps in the
forward process guided by an initial anomaly prediction. Second, we demonstrate
that denoising an only scaled input, without any added noise, outperforms
conventional denoising process. Third, we project images in a latent space to
abstract away from fine details that interfere with reconstruction of large
missing components. Additionally, we propose a fine-tuning mechanism that
facilitates the model to effectively grasp the nuances of the target domain.
Our method undergoes rigorous evaluation on two prominent anomaly detection
datasets VISA and BTAD, yielding state-of-the-art performance. Importantly, our
framework effectively localizes anomalies regardless of their scale, marking a
pivotal advancement in diffusion-based anomaly detection.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04464" title="Abstract">arXiv:2401.04464</a> [<a href="/pdf/2401.04464" title="Download PDF">pdf</a>, <a href="/format/2401.04464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhilEO Bench: Evaluating Geo-Spatial Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fibaek%2C+C">Casper Fibaek</a>, 
<a href="/search/cs?searchtype=author&query=Camilleri%2C+L">Luke Camilleri</a>, 
<a href="/search/cs?searchtype=author&query=Luyts%2C+A">Andreas Luyts</a>, 
<a href="/search/cs?searchtype=author&query=Dionelis%2C+N">Nikolaos Dionelis</a>, 
<a href="/search/cs?searchtype=author&query=Saux%2C+B+L">Bertrand Le Saux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, Submitted to IGARSS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Massive amounts of unlabelled data are captured by Earth Observation (EO)
satellites, with the Sentinel-2 constellation generating 1.6 TB of data daily.
This makes Remote Sensing a data-rich domain well suited to Machine Learning
(ML) solutions. However, a bottleneck in applying ML models to EO is the lack
of annotated data as annotation is a labour-intensive and costly process. As a
result, research in this domain has focused on Self-Supervised Learning and
Foundation Model approaches. This paper addresses the need to evaluate
different Foundation Models on a fair and uniform benchmark by introducing the
PhilEO Bench, a novel evaluation framework for EO Foundation Models. The
framework comprises of a testbed and a novel 400 GB Sentinel-2 dataset
containing labels for three downstream tasks, building density estimation, road
segmentation, and land cover classification. We present experiments using our
framework evaluating different Foundation Models, including Prithvi and SatMAE,
at multiple n-shots and convergence rates.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04468" title="Abstract">arXiv:2401.04468</a> [<a href="/pdf/2401.04468" title="Download PDF">pdf</a>, <a href="/format/2401.04468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weimin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhijie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jiangqiao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+C">Chetwin Low</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Tuyen Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+J+H">Jun Hao Liew</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hanshu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Daquan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The growing demand for high-fidelity video generation from textual
descriptions has catalyzed significant research in this field. In this work, we
introduce MagicVideo-V2 that integrates the text-to-image model, video motion
generator, reference image embedding module and frame interpolation module into
an end-to-end video generation pipeline. Benefiting from these architecture
designs, MagicVideo-V2 can generate an aesthetically pleasing, high-resolution
video with remarkable fidelity and smoothness. It demonstrates superior
performance over leading Text-to-Video systems such as Runway, Pika 1.0, Morph,
Moon Valley and Stable Video Diffusion model via user evaluation at large
scale.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04471" title="Abstract">arXiv:2401.04471</a> [<a href="/pdf/2401.04471" title="Download PDF">pdf</a>, <a href="/format/2401.04471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransportationGames: Benchmarking Transportation Knowledge of  (Multimodal) Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiangyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+X">Xinyue Lou</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+R">Rui Qi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yufeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wenjuan Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) and multimodal large language models (MLLMs)
have shown excellent general capabilities, even exhibiting adaptability in many
professional domains such as law, economics, transportation, and medicine.
Currently, many domain-specific benchmarks have been proposed to verify the
performance of (M)LLMs in specific fields. Among various domains,
transportation plays a crucial role in modern society as it impacts the
economy, the environment, and the quality of life for billions of people.
However, it is unclear how much traffic knowledge (M)LLMs possess and whether
they can reliably perform transportation-related tasks. To address this gap, we
propose TransportationGames, a carefully designed and thorough evaluation
benchmark for assessing (M)LLMs in the transportation domain. By
comprehensively considering the applications in real-world scenarios and
referring to the first three levels in Bloom's Taxonomy, we test the
performance of various (M)LLMs in memorizing, understanding, and applying
transportation knowledge by the selected tasks. The experimental results show
that although some models perform well in some tasks, there is still much room
for improvement overall. We hope the release of TransportationGames can serve
as a foundation for future research, thereby accelerating the implementation
and application of (M)LLMs in the transportation domain.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04472" title="Abstract">arXiv:2401.04472</a> [<a href="/pdf/2401.04472" title="Download PDF">pdf</a>, <a href="/format/2401.04472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Efficient Federated Learning Methods for Foundation Model  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woisetschl%C3%A4ger%2C+H">Herbert Woisetschl&#xe4;ger</a>, 
<a href="/search/cs?searchtype=author&query=Isenko%2C+A">Alexander Isenko</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+R">Ruben Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Jacobsen%2C+H">Hans-Arno Jacobsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) has become an established technique to facilitate
privacy-preserving collaborative training. However, new approaches to FL often
discuss their contributions involving small deep-learning models only. With the
tremendous success of transformer models, the following question arises: What
is necessary to operationalize foundation models in an FL application? Knowing
that computation and communication often take up similar amounts of time in FL,
we introduce a novel taxonomy focused on computational and communication
efficiency methods in FL applications. This said, these methods aim to optimize
the training time and reduce communication between clients and the server. We
also look at the current state of widely used FL frameworks and discuss future
research potentials based on existing approaches in FL research and beyond.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04474" title="Abstract">arXiv:2401.04474</a> [<a href="/pdf/2401.04474" title="Download PDF">pdf</a>, <a href="/format/2401.04474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Embedding-Based and Semantic-Based Models for Post-hoc  Explanations in Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+N+L">Ngoc Luyen Le</a>, 
<a href="/search/cs?searchtype=author&query=Abel%2C+M">Marie-H&#xe9;l&#xe8;ne Abel</a>, 
<a href="/search/cs?searchtype=author&query=Gouspillou%2C+P">Philippe Gouspillou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In today's data-rich environment, recommender systems play a crucial role in
decision support systems. They provide to users personalized recommendations
and explanations about these recommendations. Embedding-based models, despite
their widespread use, often suffer from a lack of interpretability, which can
undermine trust and user engagement. This paper presents an approach that
combines embedding-based and semantic-based models to generate post-hoc
explanations in recommender systems, leveraging ontology-based knowledge graphs
to improve interpretability and explainability. By organizing data within a
structured framework, ontologies enable the modeling of intricate relationships
between entities, which is essential for generating explanations. By combining
embedding-based and semantic based models for post-hoc explanations in
recommender systems, the framework we defined aims at producing meaningful and
easy-to-understand explanations, enhancing user trust and satisfaction, and
potentially promoting the adoption of recommender systems across the e-commerce
sector.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04481" title="Abstract">arXiv:2401.04481</a> [<a href="/pdf/2401.04481" title="Download PDF">pdf</a>, <a href="/format/2401.04481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fighting Fire with Fire: Adversarial Prompting to Generate a  Misinformation Detection Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Satapara%2C+S">Shrey Satapara</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+P">Parth Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Ganguly%2C+D">Debasis Ganguly</a>, 
<a href="/search/cs?searchtype=author&query=Modha%2C+S">Sandip Modha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent success in language generation capabilities of large language
models (LLMs), such as GPT, Bard, Llama etc., can potentially lead to concerns
about their possible misuse in inducing mass agitation and communal hatred via
generating fake news and spreading misinformation. Traditional means of
developing a misinformation ground-truth dataset does not scale well because of
the extensive manual effort required to annotate the data. In this paper, we
propose an LLM-based approach of creating silver-standard ground-truth datasets
for identifying misinformation. Specifically speaking, given a trusted news
article, our proposed approach involves prompting LLMs to automatically
generate a summarised version of the original article. The prompts in our
proposed approach act as a controlling mechanism to generate specific types of
factual incorrectness in the generated summaries, e.g., incorrect quantities,
false attributions etc. To investigate the usefulness of this dataset, we
conduct a set of experiments where we train a range of supervised models for
the task of misinformation detection.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04482" title="Abstract">arXiv:2401.04482</a> [<a href="/pdf/2401.04482" title="Download PDF">pdf</a>, <a href="/format/2401.04482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuously Learning New Words in Automatic Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huber%2C+C">Christian Huber</a>, 
<a href="/search/cs?searchtype=author&query=Waibel%2C+A">Alexander Waibel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite recent advances, Automatic Speech Recognition (ASR) systems are still
far from perfect. Typical errors include acronyms, named entities and
domain-specific special words for which little or no data is available. To
address the problem of recognizing these words, we propose an self-supervised
continual learning approach. Given the audio of a lecture talk with
corresponding slides, we bias the model towards decoding new words from the
slides by using a memory-enhanced ASR model from previous work. Then, we
perform inference on the talk, collecting utterances that contain detected new
words into an adaptation dataset. Continual learning is then performed on this
set by adapting low-rank matrix weights added to each weight matrix of the
model. The whole procedure is iterated for many talks. We show that with this
approach, we obtain increasing performance on the new words when they occur
more frequently (more than 80% recall) while preserving the general performance
of the model.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04485" title="Abstract">arXiv:2401.04485</a> [<a href="/pdf/2401.04485" title="Download PDF">pdf</a>, <a href="/format/2401.04485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the stabilization of a virtual element method for an acoustic  vibration problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alzaben%2C+L">Linda Alzaben</a>, 
<a href="/search/math?searchtype=author&query=Boffi%2C+D">Daniele Boffi</a>, 
<a href="/search/math?searchtype=author&query=Dedner%2C+A">Andreas Dedner</a>, 
<a href="/search/math?searchtype=author&query=Gastaldi%2C+L">Lucia Gastaldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 7 figures, 14 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we introduce an abstract setting for the convergence analysis
of the virtual element approximation of an acoustic vibration problem. We
discuss the effect of the stabilization parameters and remark that in some
cases it is possible to achieve optimal convergence without the need of any
stabilization. This statement is rigorously proved for lowest order triangular
element and supported by several numerical experiments.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04486" title="Abstract">arXiv:2401.04486</a> [<a href="/pdf/2401.04486" title="Download PDF">pdf</a>, <a href="/format/2401.04486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Take A Shortcut Back: Mitigating the Gradient Vanishing for Training  Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yufei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanpei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Spiking Neural Network (SNN) is a biologically inspired neural network
infrastructure that has recently garnered significant attention. It utilizes
binary spike activations to transmit information, thereby replacing
multiplications with additions and resulting in high energy efficiency.
However, training an SNN directly poses a challenge due to the undefined
gradient of the firing spike process. Although prior works have employed
various surrogate gradient training methods that use an alternative function to
replace the firing process during back-propagation, these approaches ignore an
intrinsic problem: gradient vanishing. To address this issue, we propose a
shortcut back-propagation method in our paper, which advocates for transmitting
the gradient directly from the loss to the shallow layers. This enables us to
present the gradient to the shallow layers directly, thereby significantly
mitigating the gradient vanishing problem. Additionally, this method does not
introduce any burden during the inference phase. To strike a balance between
final accuracy and ease of training, we also propose an evolutionary training
framework and implement it by inducing a balance coefficient that dynamically
changes with the training epoch, which further improves the network's
performance. Extensive experiments conducted over static and dynamic datasets
using several popular network structures reveal that our method consistently
outperforms state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04487" title="Abstract">arXiv:2401.04487</a> [<a href="/pdf/2401.04487" title="Download PDF">pdf</a>, <a href="/format/2401.04487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online convex optimization for robust control of constrained dynamical  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nonhoff%2C+M">Marko Nonhoff</a>, 
<a href="/search/eess?searchtype=author&query=Dall%27Anese%2C+E">Emiliano Dall&#x27;Anese</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This article investigates the problem of controlling linear time-invariant
systems subject to time-varying and a priori unknown cost functions, state and
input constraints, and exogenous disturbances. We combine the online convex
optimization framework with tools from robust model predictive control to
propose an algorithm that is able to guarantee robust constraint satisfaction.
The performance of the closed loop emerging from application of our framework
is studied in terms of its dynamic regret, which is proven to be bounded
linearly by the variation of the cost functions and the magnitude of the
disturbances. We corroborate our theoretical findings and illustrate
implementational aspects of the proposed algorithm by a numerical case study of
a tracking control problem of an autonomous vehicle.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04489" title="Abstract">arXiv:2401.04489</a> [<a href="/pdf/2401.04489" title="Download PDF">pdf</a>, <a href="/format/2401.04489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Survival Trees: A Dynamic Programming Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huisman%2C+T">Tim Huisman</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Linden%2C+J+G+M">Jacobus G. M. van der Linden</a>, 
<a href="/search/cs?searchtype=author&query=Demirovi%C4%87%2C+E">Emir Demirovi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Survival analysis studies and predicts the time of death, or other singular
unrepeated events, based on historical data, while the true time of death for
some instances is unknown. Survival trees enable the discovery of complex
nonlinear relations in a compact human comprehensible model, by recursively
splitting the population and predicting a distinct survival distribution in
each leaf node. We use dynamic programming to provide the first survival tree
method with optimality guarantees, enabling the assessment of the optimality
gap of heuristics. We improve the scalability of our method through a special
algorithm for computing trees up to depth two. The experiments show that our
method's run time even outperforms some heuristics for realistic cases while
obtaining similar out-of-sample performance with the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04491" title="Abstract">arXiv:2401.04491</a> [<a href="/pdf/2401.04491" title="Download PDF">pdf</a>, <a href="/format/2401.04491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpiNNaker2: A Large-Scale Neuromorphic System for Event-Based and  Asynchronous Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+H+A">Hector A. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiaxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kelber%2C+F">Florian Kelber</a>, 
<a href="/search/cs?searchtype=author&query=Nazeer%2C+K+K">Khaleelulla Khan Nazeer</a>, 
<a href="/search/cs?searchtype=author&query=Langer%2C+T">Tim Langer</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lohrmann%2C+M">Matthias Lohrmann</a>, 
<a href="/search/cs?searchtype=author&query=Rostami%2C+A">Amirhossein Rostami</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6ne%2C+M">Mark Sch&#xf6;ne</a>, 
<a href="/search/cs?searchtype=author&query=Vogginger%2C+B">Bernhard Vogginger</a>, 
<a href="/search/cs?searchtype=author&query=Wunderlich%2C+T+C">Timo C. Wunderlich</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yexin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Akl%2C+M">Mahmoud Akl</a>, 
<a href="/search/cs?searchtype=author&query=Mayr%2C+C">Christian Mayr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted at the Workshop on Machine Learning with New Compute Paradigms at NeurIPS 2023 (MLNPCP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The joint progress of artificial neural networks (ANNs) and domain specific
hardware accelerators such as GPUs and TPUs took over many domains of machine
learning research. This development is accompanied by a rapid growth of the
required computational demands for larger models and more data. Concurrently,
emerging properties of foundation models such as in-context learning drive new
opportunities for machine learning applications. However, the computational
cost of such applications is a limiting factor of the technology in data
centers, and more importantly in mobile devices and edge systems. To mediate
the energy footprint and non-trivial latency of contemporary systems,
neuromorphic computing systems deeply integrate computational principles of
neurobiological systems by leveraging low-power analog and digital
technologies. SpiNNaker2 is a digital neuromorphic chip developed for scalable
machine learning. The event-based and asynchronous design of SpiNNaker2 allows
the composition of large-scale systems involving thousands of chips. This work
features the operating principles of SpiNNaker2 systems, outlining the
prototype of novel machine learning applications. These applications range from
ANNs over bio-inspired spiking neural networks to generalized event-based
neural networks. With the successful development and deployment of SpiNNaker2,
we aim to facilitate the advancement of event-based and asynchronous algorithms
for future generations of machine learning systems.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04492" title="Abstract">arXiv:2401.04492</a> [<a href="/pdf/2401.04492" title="Download PDF">pdf</a>, <a href="/format/2401.04492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmented Reality and Human-Robot Collaboration Framework for  Percutaneous Nephrolithotomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Junling Fu</a>, 
<a href="/search/cs?searchtype=author&query=Pecorella%2C+M">Matteo Pecorella</a>, 
<a href="/search/cs?searchtype=author&query=Iovene%2C+E">Elisa Iovene</a>, 
<a href="/search/cs?searchtype=author&query=Palumbo%2C+M+C">Maria Chiara Palumbo</a>, 
<a href="/search/cs?searchtype=author&query=Rota%2C+A">Alberto Rota</a>, 
<a href="/search/cs?searchtype=author&query=Redaelli%2C+A">Alberto Redaelli</a>, 
<a href="/search/cs?searchtype=author&query=Ferrigno%2C+G">Giancarlo Ferrigno</a>, 
<a href="/search/cs?searchtype=author&query=De+Momi%2C+E">Elena De Momi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages,10 figure, accepted by IEEE Robotics and Automation Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">During Percutaneous Nephrolithotomy (PCNL) operations, the surgeon is
required to define the incision point on the patient's back, align the needle
to a pre-planned path, and perform puncture operations afterward. The procedure
is currently performed manually using ultrasound or fluoroscopy imaging for
needle orientation, which, however, implies limited accuracy and low
reproducibility. This work incorporates Augmented Reality (AR) visualization
with an optical see-through head-mounted display (OST-HMD) and Human-Robot
Collaboration (HRC) framework to empower the surgeon's task completion
performance. In detail, Eye-to-Hand calibration, system registration, and
hologram model registration are performed to realize visual guidance. A
Cartesian impedance controller is used to guide the operator during the needle
puncture task execution. Experiments are conducted to verify the system
performance compared with conventional manual puncture procedures and a 2D
monitor-based visualisation interface. The results showed that the proposed
framework achieves the lowest median and standard deviation error across all
the experimental groups, respectively. Furthermore, the NASA-TLX user
evaluation results indicate that the proposed framework requires the lowest
workload score for task completion compared to other experimental setups. The
proposed framework exhibits significant potential for clinical application in
the PCNL task, as it enhances the surgeon's perception capability, facilitates
collision-free needle insertion path planning, and minimises errors in task
completion.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04494" title="Abstract">arXiv:2401.04494</a> [<a href="/pdf/2401.04494" title="Download PDF">pdf</a>, <a href="/format/2401.04494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Asynchronous Work-Stealing for distributed load-balancing in  heterogeneous systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandesa%2C+J+B">Jo&#xe3;o B. Fernandesa</a>, 
<a href="/search/cs?searchtype=author&query=de+Assis%2C+%C3%8D+A+S">&#xcd;talo A. S. de Assis</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+I+M+S">Idalmis M. S. Martins</a>, 
<a href="/search/cs?searchtype=author&query=Barros%2C+T">Tiago Barros</a>, 
<a href="/search/cs?searchtype=author&query=Xavier-de-Souza%2C+S">Samuel Xavier-de-Souza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Supercomputers have revolutionized how industries and scientific fields
process large amounts of data. These machines group hundreds or thousands of
computing nodes working together to execute time-consuming programs that
require a large amount of computational resources. Over the years,
supercomputers have expanded to include new and different technologies
characterizing them as heterogeneous. However, executing a program in a
heterogeneous environment requires attention to a specific aspect of
performance degradation: load imbalance. In this research, we address the
challenges associated with load imbalance when scheduling many homogeneous
tasks in a heterogeneous environment. To address this issue, we introduce the
concept of adaptive asynchronous work-stealing. This approach collects
information about the nodes and utilizes it to improve work-stealing aspects,
such as victim selection and task offloading. Additionally, the proposed
approach eliminates the need for extra threads to communicate information,
thereby reducing overhead when implementing a fully asynchronous approach. Our
experimental results demonstrate a performance improvement of approximately
10.1\% compared to other conventional and state-of-the-art implementations.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04495" title="Abstract">arXiv:2401.04495</a> [<a href="/pdf/2401.04495" title="Download PDF">pdf</a>, <a href="/format/2401.04495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential experiments using parallel alternative operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calderini%2C+M">Marco Calderini</a>, 
<a href="/search/cs?searchtype=author&query=Civino%2C+R">Roberto Civino</a>, 
<a href="/search/cs?searchtype=author&query=Invernizzi%2C+R">Riccardo Invernizzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT); Group Theory (math.GR)

</div>
<p class="mathjax">The use of alternative operations in differential cryptanalysis, or
alternative notions of differentials, are lately receiving increasing
attention. Recently, Civino et al. managed to design a block cipher which is
secure w.r.t. classical differential cryptanalysis performed using
XOR-differentials, but weaker with respect to the attack based on an
alternative difference operation acting on the first s-box of the block. We
extend this result to parallel alternative operations, i.e. acting on each
s-box of the block. First, we recall the mathematical framework needed to
define and use such operations. After that, we perform some differential
experiments against a toy cipher and compare the effectiveness of the attack
w.r.t. the one that uses XOR-differentials.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04507" title="Abstract">arXiv:2401.04507</a> [<a href="/pdf/2401.04507" title="Download PDF">pdf</a>, <a href="/format/2401.04507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TechGPT-2.0: A large language model project to solve the task of  knowledge graph construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yuying Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong Li</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+N">Ning An</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hei%2C+L">Lei Hei</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haibo Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yifei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+F">Feiliang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models have exhibited robust performance across diverse
natural language processing tasks. This report introduces TechGPT-2.0, a
project designed to enhance the capabilities of large language models
specifically in knowledge graph construction tasks, including named entity
recognition (NER) and relationship triple extraction (RTE) tasks in NLP
applications. Additionally, it serves as a LLM accessible for research within
the Chinese open-source model community. We offer two 7B large language model
weights and a QLoRA weight specialized for processing lengthy texts.Notably,
TechGPT-2.0 is trained on Huawei's Ascend server. Inheriting all
functionalities from TechGPT-1.0, it exhibits robust text processing
capabilities, particularly in the domains of medicine and law. Furthermore, we
introduce new capabilities to the model, enabling it to process texts in
various domains such as geographical areas, transportation, organizations,
literary works, biology, natural sciences, astronomical objects, and
architecture. These enhancements also fortified the model's adeptness in
handling hallucinations, unanswerable queries, and lengthy texts. This report
provides a comprehensive and detailed introduction to the full fine-tuning
process on Huawei's Ascend servers, encompassing experiences in Ascend server
debugging, instruction fine-tuning data processing, and model training. Our
code is available at https://github.com/neukg/TechGPT-2.0
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04508" title="Abstract">arXiv:2401.04508</a> [<a href="/pdf/2401.04508" title="Download PDF">pdf</a>, <a href="/ps/2401.04508" title="Download PostScript">ps</a>, <a href="/format/2401.04508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Nonlinear Model Reduction using Koopman Theory: Integrated  Control Form and NMPC Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schulze%2C+J+C">Jan C. Schulze</a>, 
<a href="/search/eess?searchtype=author&query=Mitsos%2C+A">Alexander Mitsos</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Control Systems Letters, Vol. 6, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">We use Koopman theory for data-driven model reduction of nonlinear dynamical
systems with controls. We propose generic model structures combining
delay-coordinate encoding of measurements and full-state decoding to integrate
reduced Koopman modeling and state estimation. We present a deep-learning
approach to train the proposed models. A case study demonstrates that our
approach provides accurate control models and enables real-time capable
nonlinear model predictive control of a high-purity cryogenic distillation
column.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04509" title="Abstract">arXiv:2401.04509</a> [<a href="/pdf/2401.04509" title="Download PDF">pdf</a>, <a href="/format/2401.04509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear-size Suffix Tries and Linear-size CDAWGs Simplified and Improved
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inenaga%2C+S">Shunsuke Inenaga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">The linear-size suffix tries (LSTries) [Crochemore et al., TCS 2016] are a
version of suffix trees in which the edge labels are single characters, yet are
able to perform pattern matching queries in optimal time. Instead of explicitly
storing the input text, LSTries have some extra non-branching internal nodes
called type-2 nodes. The extended techniques are then used in the linear-size
compact directed acyclic word graphs (LCDAWGs) [Takagi et al. SPIRE 2017],
which can be stored with $O(el(T)+er(T))$ space (i.e. without the text), where
$el(T)$ and $er(T)$ are the numbers of left- and right-extensions of the
maximal repeats in the input text string $T$, respectively. In this paper, we
present simpler alternatives to the aforementioned indexing structures, called
the simplified LSTries (simLSTries) and the simplified LCDAWGs (simLCDAWGs), in
which most of the type-2 nodes are removed. In particular, our simLCDAWGs
require only $O(er(T))$ space and work on a weaker model of computation (i.e.
the pointer machine). This contrasts the $O(er(T))$-space CDAWG representation
of [Belazzougui \&amp; Cunial, SPIRE 2017], which works on the word RAM.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04514" title="Abstract">arXiv:2401.04514</a> [<a href="/pdf/2401.04514" title="Download PDF">pdf</a>, <a href="/format/2401.04514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rewriting the Code: A Simple Method for Large Language Model Augmented  Code Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haochen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqi Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">In code search, the Generation-Augmented Retrieval (GAR) framework, which
generates exemplar code snippets to augment queries, has emerged as a promising
strategy to address the principal challenge of modality misalignment between
code snippets and natural language queries, particularly with the demonstrated
code generation capabilities of Large Language Models (LLMs). Nevertheless, our
preliminary investigations indicate that the improvements conferred by such an
LLM-augmented framework are somewhat constrained. This limitation could
potentially be ascribed to the fact that the generated codes, albeit
functionally accurate, frequently display a pronounced stylistic deviation from
the ground truth code in the codebase. In this paper, we extend the
foundational GAR framework and propose a simple yet effective method that
additionally Rewrites the Code (ReCo) within the codebase for style
normalization. Experimental results demonstrate that ReCo significantly boosts
retrieval accuracy across sparse (up to 35.7%), zero-shot dense (up to 27.6%),
and fine-tuned dense (up to 23.6%) retrieval settings in diverse search
scenarios. To further elucidate the advantages of ReCo and stimulate research
in code style normalization, we introduce Code Style Similarity, the first
metric tailored to quantify stylistic similarities in code. Notably, our
empirical findings reveal the inadequacy of existing metrics in capturing
stylistic nuances.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04515" title="Abstract">arXiv:2401.04515</a> [<a href="/pdf/2401.04515" title="Download PDF">pdf</a>, <a href="/format/2401.04515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tikhomirov%2C+M">Mikhail Tikhomirov</a>, 
<a href="/search/cs?searchtype=author&query=Loukachevitch%2C+N">Natalia Loukachevitch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This article investigates a zero-shot approach to hypernymy prediction using
large language models (LLMs). The study employs a method based on text
probability calculation, applying it to various generated prompts. The
experiments demonstrate a strong correlation between the effectiveness of
language model prompts and classic patterns, indicating that preliminary prompt
selection can be carried out using smaller models before moving to larger ones.
We also explore prompts for predicting co-hyponyms and improving hypernymy
predictions by augmenting prompts with additional information through
automatically identified co-hyponyms. An iterative approach is developed for
predicting higher-level concepts, which further improves the quality on the
BLESS dataset (MAP = 0.8).
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04518" title="Abstract">arXiv:2401.04518</a> [<a href="/pdf/2401.04518" title="Download PDF">pdf</a>, <a href="/format/2401.04518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Critique of Critique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weizhe Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+R">Ruifeng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengfei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Critique, as a natural language description for assessing the quality of
model-generated content, has been proven to play an essential role in the
training, evaluation, and refinement of Large Language Models (LLMs). However,
there is a lack of principled understanding in evaluating the quality of the
critique itself. In this paper, we pioneer the critique of critique, termed
MetaCritique, which is a framework to evaluate the critique from two aspects,
i.e., factuality as precision score and comprehensiveness as recall score. We
calculate the harmonic mean of precision and recall as the overall rating
called F1 score. To obtain a reliable evaluation outcome, we propose Atomic
Information Units (AIUs), which describe the critique in a more fine-grained
manner. MetaCritique takes each AIU into account and aggregates each AIU's
judgment for the overall score. Moreover, given the evaluation process involves
intricate reasoning, our MetaCritique provides a natural language rationale to
support each judgment. We construct a meta-evaluation dataset containing 300
critiques (2653 AIUs) across four tasks (question answering, reasoning,
entailment, and summarization), and we conduct a comparative study to
demonstrate the feasibility and effectiveness. Experiments also show superior
critique judged by MetaCritique leads to better refinement, indicating
generative artificial intelligence indeed has the potential to be significantly
advanced with our MetaCritique. We will release relevant code and
meta-evaluation datasets at https://github.com/GAIR-NLP/MetaCritique.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04519" title="Abstract">arXiv:2401.04519</a> [<a href="/pdf/2401.04519" title="Download PDF">pdf</a>, <a href="/ps/2401.04519" title="Download PostScript">ps</a>, <a href="/format/2401.04519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed methods and lower eigenvalue bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gallistl%2C+D">Dietmar Gallistl</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Math. Comp., volume 92, no.342, pp.1491--1509, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">It is shown how mixed finite element methods for symmetric positive definite
eigenvalue problems related to partial differential operators can provide
guaranteed lower eigenvalue bounds. The method is based on a classical
compatibility condition (inclusion of kernels) of the mixed scheme and on local
constants related to compact embeddings, which are often known explicitly.
Applications include scalar second-order elliptic operators, linear elasticity,
and the Steklov eigenvalue problem.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04522" title="Abstract">arXiv:2401.04522</a> [<a href="/pdf/2401.04522" title="Download PDF">pdf</a>, <a href="/format/2401.04522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LUNA: A Framework for Language Understanding and Naturalness Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saidov%2C+M">Marat Saidov</a>, 
<a href="/search/cs?searchtype=author&query=Bakalova%2C+A">Aleksandra Bakalova</a>, 
<a href="/search/cs?searchtype=author&query=Taktasheva%2C+E">Ekaterina Taktasheva</a>, 
<a href="/search/cs?searchtype=author&query=Mikhailov%2C+V">Vladislav Mikhailov</a>, 
<a href="/search/cs?searchtype=author&query=Artemova%2C+E">Ekaterina Artemova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The evaluation of Natural Language Generation (NLG) models has gained
increased attention, urging the development of metrics that evaluate various
aspects of generated text. LUNA addresses this challenge by introducing a
unified interface for 20 NLG evaluation metrics. These metrics are categorized
based on their reference-dependence and the type of text representation they
employ, from string-based n-gram overlap to the utilization of static
embeddings and pre-trained language models.
<br />The straightforward design of LUNA allows for easy extension with novel
metrics, requiring just a few lines of code. LUNA offers a user-friendly tool
for evaluating generated texts.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04524" title="Abstract">arXiv:2401.04524</a> [<a href="/pdf/2401.04524" title="Download PDF">pdf</a>, <a href="/format/2401.04524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Coherency in Facet-based Clarification Prompt Generation for  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Litvinov%2C+O">Oleg Litvinov</a>, 
<a href="/search/cs?searchtype=author&query=Sekuli%C4%87%2C+I">Ivan Sekuli&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Aliannejadi%2C+M">Mohammad Aliannejadi</a>, 
<a href="/search/cs?searchtype=author&query=Crestani%2C+F">Fabio Crestani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Clarifying user's information needs is an essential component of modern
search systems. While most of the approaches for constructing clarifying
prompts rely on query facets, the impact of the quality of the facets is
relatively unexplored. In this work, we concentrate on facet quality through
the notion of facet coherency and assess its importance for overall usefulness
for clarification in search. We find that existing evaluation procedures do not
account for facet coherency, as evident by the poor correlation of coherency
with automated metrics. Moreover, we propose a coherency classifier and assess
the prevalence of incoherent facets in a well-established dataset on
clarification. Our findings can serve as motivation for future work on the
topic.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04531" title="Abstract">arXiv:2401.04531</a> [<a href="/pdf/2401.04531" title="Download PDF">pdf</a>, <a href="/format/2401.04531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MERA: A Comprehensive LLM Evaluation in Russian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fenogenova%2C+A">Alena Fenogenova</a>, 
<a href="/search/cs?searchtype=author&query=Chervyakov%2C+A">Artem Chervyakov</a>, 
<a href="/search/cs?searchtype=author&query=Martynov%2C+N">Nikita Martynov</a>, 
<a href="/search/cs?searchtype=author&query=Kozlova%2C+A">Anastasia Kozlova</a>, 
<a href="/search/cs?searchtype=author&query=Tikhonova%2C+M">Maria Tikhonova</a>, 
<a href="/search/cs?searchtype=author&query=Akhmetgareeva%2C+A">Albina Akhmetgareeva</a>, 
<a href="/search/cs?searchtype=author&query=Emelyanov%2C+A">Anton Emelyanov</a>, 
<a href="/search/cs?searchtype=author&query=Shevelev%2C+D">Denis Shevelev</a>, 
<a href="/search/cs?searchtype=author&query=Lebedev%2C+P">Pavel Lebedev</a>, 
<a href="/search/cs?searchtype=author&query=Sinev%2C+L">Leonid Sinev</a>, 
<a href="/search/cs?searchtype=author&query=Isaeva%2C+U">Ulyana Isaeva</a>, 
<a href="/search/cs?searchtype=author&query=Kolomeytseva%2C+K">Katerina Kolomeytseva</a>, 
<a href="/search/cs?searchtype=author&query=Moskovskiy%2C+D">Daniil Moskovskiy</a>, 
<a href="/search/cs?searchtype=author&query=Goncharova%2C+E">Elizaveta Goncharova</a>, 
<a href="/search/cs?searchtype=author&query=Savushkin%2C+N">Nikita Savushkin</a>, 
<a href="/search/cs?searchtype=author&query=Mikhailova%2C+P">Polina Mikhailova</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrov%2C+D">Denis Dimitrov</a>, 
<a href="/search/cs?searchtype=author&query=Panchenko%2C+A">Alexander Panchenko</a>, 
<a href="/search/cs?searchtype=author&query=Markov%2C+S">Sergei Markov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> the paper version comparable with the release code v.1.1.0 of the benchmark; <a href="https://mera.a-ai.ru/en">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Over the past few years, one of the most notable advancements in AI research
has been in foundation models (FMs), headlined by the rise of language models
(LMs). As the models' size increases, LMs demonstrate enhancements in
measurable aspects and the development of new qualitative features. However,
despite researchers' attention and the rapid growth in LM application, the
capabilities, limitations, and associated risks still need to be better
understood. To address these issues, we introduce an open Multimodal Evaluation
of Russian-language Architectures (MERA), a new instruction benchmark for
evaluating foundation models oriented towards the Russian language. The
benchmark encompasses 21 evaluation tasks for generative models in 11 skill
domains and is designed as a black-box test to ensure the exclusion of data
leakage. The paper introduces a methodology to evaluate FMs and LMs in zero-
and few-shot fixed instruction settings that can be extended to other
modalities. We propose an evaluation methodology, an open-source code base for
the MERA assessment, and a leaderboard with a submission system. We evaluate
open LMs as baselines and find that they are still far behind the human level.
We publicly release MERA to guide forthcoming research, anticipate
groundbreaking model features, standardize the evaluation procedure, and
address potential societal drawbacks.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04534" title="Abstract">arXiv:2401.04534</a> [<a href="/pdf/2401.04534" title="Download PDF">pdf</a>, <a href="/format/2401.04534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Human-Robot Interaction in Virtual Reality: Experience from a  Study on Speech Act Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaszuba%2C+S">Sara Kaszuba</a> (1), 
<a href="/search/cs?searchtype=author&query=Sabbella%2C+S+R">Sandeep Reddy Sabbella</a> (1), 
<a href="/search/cs?searchtype=author&query=Leotta%2C+F">Francesco Leotta</a> (1), 
<a href="/search/cs?searchtype=author&query=Serrarens%2C+P">Pascal Serrarens</a> (2), 
<a href="/search/cs?searchtype=author&query=Nardi%2C+D">Daniele Nardi</a> (1) ((1) Sapienza Universit&#xe0; di Roma, Rome, Italy (2) PaleBlue, Stavanger, Norway)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 3 Figures, 6th International Workshop on Virtual, Augmented, and Mixed-Reality for Human-Robot Interactions VAM-HRI 2023. ACM/IEEE International Conference on Human-Robot Interaction. HRI 2023. March 13-16, 2023 Stockholm, SE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In recent years, an increasing number of Human-Robot Interaction (HRI)
approaches have been implemented and evaluated in Virtual Reality (VR), as it
allows to speed-up design iterations and makes it safer for the final user to
evaluate and master the HRI primitives. However, identifying the most suitable
VR experience is not straightforward. In this work, we evaluate how, in a smart
agriculture scenario, immersive and non-immersive VR are perceived by users
with respect to a speech act understanding task. In particular, we collect
opinions and suggestions from the 81 participants involved in both experiments
to highlight the strengths and weaknesses of these different experiences.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04536" title="Abstract">arXiv:2401.04536</a> [<a href="/pdf/2401.04536" title="Download PDF">pdf</a>, <a href="/format/2401.04536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Language Model Agency through Negotiations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davidson%2C+T+R">Tim R. Davidson</a>, 
<a href="/search/cs?searchtype=author&query=Veselovsky%2C+V">Veniamin Veselovsky</a>, 
<a href="/search/cs?searchtype=author&query=Josifoski%2C+M">Martin Josifoski</a>, 
<a href="/search/cs?searchtype=author&query=Peyrard%2C+M">Maxime Peyrard</a>, 
<a href="/search/cs?searchtype=author&query=Bosselut%2C+A">Antoine Bosselut</a>, 
<a href="/search/cs?searchtype=author&query=Kosinski%2C+M">Michal Kosinski</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+R">Robert West</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and link to project data are made available at <a href="https://github.com/epfl-dlab/LAMEN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Companies, organizations, and governments increasingly exploit Language
Models' (LM) remarkable capability to display agent-like behavior. As LMs are
adopted to perform tasks with growing autonomy, there exists an urgent need for
reliable and scalable evaluation benchmarks. Current, predominantly static LM
benchmarks are ill-suited to evaluate such dynamic applications. Thus, we
propose jointly evaluating LM performance and alignment through the lenses of
negotiation games. We argue that this common task better reflects real-world
deployment conditions while offering insights into LMs' decision-making
processes. Crucially, negotiation games allow us to study multi-turn, and
cross-model interactions, modulate complexity, and side-step accidental data
leakage in evaluation. We report results for six publicly accessible LMs from
several major providers on a variety of negotiation games, evaluating both
self-play and cross-play performance. Noteworthy findings include: (i)
open-source models are currently unable to complete these tasks; (ii)
cooperative bargaining games prove challenging; and (iii) the most powerful
models do not always "win".
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04538" title="Abstract">arXiv:2401.04538</a> [<a href="/pdf/2401.04538" title="Download PDF">pdf</a>, <a href="/format/2401.04538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UBfuzz: Finding Bugs in Sanitizer Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaohua Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhendong Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to ASPLOS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">In this paper, we propose a testing framework for validating sanitizer
implementations in compilers. Our core components are (1) a program generator
specifically designed for producing programs containing undefined behavior
(UB), and (2) a novel test oracle for sanitizer testing. The program generator
employs Shadow Statement Insertion, a general and effective approach for
introducing UB into a valid seed program. The generated UB programs are
subsequently utilized for differential testing of multiple sanitizer
implementations. Nevertheless, discrepant sanitizer reports may stem from
either compiler optimization or sanitizer bugs. To accurately determine if a
discrepancy is caused by sanitizer bugs, we introduce a new test oracle called
crash-site mapping. We have incorporated our techniques into UBfuzz, a
practical tool for testing sanitizers. Over a five-month testing period, UBfuzz
successfully found 31 bugs in both GCC and LLVM sanitizers. These bugs reveal
the serious false negative problems in sanitizers, where certain UBs in
programs went unreported. This research paves the way for further investigation
in this crucial area of study.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04539" title="Abstract">arXiv:2401.04539</a> [<a href="/pdf/2401.04539" title="Download PDF">pdf</a>, <a href="/format/2401.04539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Framework of K-repetition Grant-free Access via Diversity  Slotted Aloha (DSA)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Haoran Mei</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Limei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+P">Pin-Han Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This article introduces a novel framework of multi-user detection (MUD) for
K-repetition grant-free non-orthogonal multiple access (K-GF-NOMA), called
$\alpha$ iterative interference cancellation diversity slotted aloha
($\alpha$-IIC-DSA). The proposed framework targets at a simple yet effective
decoding process where the AP can intelligently exploit the correlation among
signals received at different resource blocks (RBs) so as to generate required
multi-access interference (MAI) for realizing the signal-interference
cancellation (SIC) based MUD. By keeping all operation and hardware complexity
at the access point (AP), the proposed framework is applicable to the scenarios
with random and uncoordinated access by numerous miniature mMTC devices
(MTCDs). Numerical experiments are conducted to gain deep understanding on the
performance of launching the proposed framework for K-GF-NOMA.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04543" title="Abstract">arXiv:2401.04543</a> [<a href="/pdf/2401.04543" title="Download PDF">pdf</a>, <a href="/format/2401.04543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Healthcare Voice AI Assistants: Factors Influencing Trust and Intention  to Use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiao Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Abdi%2C+N">Noura Abdi</a>, 
<a href="/search/cs?searchtype=author&query=Seymour%2C+W">William Seymour</a>, 
<a href="/search/cs?searchtype=author&query=Such%2C+J">Jose Such</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">AI assistants such as Alexa, Google Assistant, and Siri, are making their way
into the healthcare sector, offering a convenient way for users to access
different healthcare services. Trust is a vital factor in the uptake of
healthcare services, but the factors affecting trust in voice assistants used
for healthcare are under-explored and this specialist domain introduces
additional requirements. This study explores the effects of different
functional, personal, and risk factors on trust in and adoption of healthcare
voice AI assistants (HVAs), generating a partial least squares structural model
from a survey of 300 voice assistant users. Our results indicate that trust in
HVAs can be significantly explained by functional factors (usefulness, content
credibility, quality of service relative to a healthcare professional),
together with security, and privacy risks and personal stance in technology. We
also discuss differences in terms of trust between HVAs and general-purpose
voice assistants as well as implications that are unique to HVAs.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04545" title="Abstract">arXiv:2401.04545</a> [<a href="/pdf/2401.04545" title="Download PDF">pdf</a>, <a href="/format/2401.04545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Gesture Recognition in Virtual Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabbella%2C+S+R">Sandeep Reddy Sabbella</a> (1), 
<a href="/search/cs?searchtype=author&query=Kaszuba%2C+S">Sara Kaszuba</a> (1), 
<a href="/search/cs?searchtype=author&query=Leotta%2C+F">Francesco Leotta</a> (1), 
<a href="/search/cs?searchtype=author&query=Serrarens%2C+P">Pascal Serrarens</a> (2), 
<a href="/search/cs?searchtype=author&query=Nardi%2C+D">Daniele Nardi</a> (1) ((1) Sapienza Universit&#xe0; di Roma, Rome, Italy, (2) PaleBlue, Stavanger, Norway)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 Pages, 3 Figures, Workshop YOUR Study Design!(WYSD 2023) Participatory critique and refinement of participants' studies. Workshop at the ACM/IEEE International Conference on Human-Robot Interaction (HRI 2023). March 13-16, 2023, Stockholm, SE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Human-Robot Interaction (HRI) has become increasingly important as robots are
being integrated into various aspects of daily life. One key aspect of HRI is
gesture recognition, which allows robots to interpret and respond to human
gestures in real-time. Gesture recognition plays an important role in
non-verbal communication in HRI. To this aim, there is ongoing research on how
such non-verbal communication can strengthen verbal communication and improve
the system's overall efficiency, thereby enhancing the user experience with the
robot. However, several challenges need to be addressed in gesture recognition
systems, which include data generation, transferability, scalability,
generalizability, standardization, and lack of benchmarking of the gestural
systems. In this preliminary paper, we want to address the challenges of data
generation using virtual reality simulations and standardization issues by
presenting gestures to some commands that can be used as a standard in ground
robots.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04550" title="Abstract">arXiv:2401.04550</a> [<a href="/pdf/2401.04550" title="Download PDF">pdf</a>, <a href="/ps/2401.04550" title="Download PostScript">ps</a>, <a href="/format/2401.04550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WaveletFormerNet: A Transformer-based Wavelet Network for Real-world  Non-homogeneous and Dense Fog Removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zhiyong Tao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Sen Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although deep convolutional neural networks have achieved remarkable success
in removing synthetic fog, it is essential to be able to process images taken
in complex foggy conditions, such as dense or non-homogeneous fog, in the real
world. However, the haze distribution in the real world is complex, and
downsampling can lead to color distortion or loss of detail in the output
results as the resolution of a feature map or image resolution decreases. In
addition to the challenges of obtaining sufficient training data, overfitting
can also arise in deep learning techniques for foggy image processing, which
can limit the generalization abilities of the model, posing challenges for its
practical applications in real-world scenarios. Considering these issues, this
paper proposes a Transformer-based wavelet network (WaveletFormerNet) for
real-world foggy image recovery. We embed the discrete wavelet transform into
the Vision Transformer by proposing the WaveletFormer and IWaveletFormer
blocks, aiming to alleviate texture detail loss and color distortion in the
image due to downsampling. We introduce parallel convolution in the Transformer
block, which allows for the capture of multi-frequency information in a
lightweight mechanism. Additionally, we have implemented a feature aggregation
module (FAM) to maintain image resolution and enhance the feature extraction
capacity of our model, further contributing to its impressive performance in
real-world foggy image recovery tasks. Extensive experiments demonstrate that
our WaveletFormerNet performs better than state-of-the-art methods, as shown
through quantitative and qualitative evaluations of minor model complexity.
Additionally, our satisfactory results on real-world dust removal and
application tests showcase the superior generalization ability and improved
performance of WaveletFormerNet in computer vision-related applications.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04552" title="Abstract">arXiv:2401.04552</a> [<a href="/pdf/2401.04552" title="Download PDF">pdf</a>, <a href="/format/2401.04552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XaaS: Acceleration as a Service to Enable Productive High-Performance  Cloud Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>, 
<a href="/search/cs?searchtype=author&query=Copik%2C+M">Marcin Copik</a>, 
<a href="/search/cs?searchtype=author&query=Beckman%2C+P">Pete Beckman</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+A">Andrew Jones</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+I">Ian Foster</a>, 
<a href="/search/cs?searchtype=author&query=Parashar%2C+M">Manish Parashar</a>, 
<a href="/search/cs?searchtype=author&query=Reed%2C+D">Daniel Reed</a>, 
<a href="/search/cs?searchtype=author&query=Troyer%2C+M">Matthias Troyer</a>, 
<a href="/search/cs?searchtype=author&query=Schulthess%2C+T">Thomas Schulthess</a>, 
<a href="/search/cs?searchtype=author&query=Ernst%2C+D">Dan Ernst</a>, 
<a href="/search/cs?searchtype=author&query=Dongarra%2C+J">Jack Dongarra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">HPC and Cloud have evolved independently, specializing their innovations into
performance or productivity. Acceleration as a Service (XaaS) is a recipe to
empower both fields with a shared execution platform that provides transparent
access to computing resources, regardless of the underlying cloud or HPC
service provider. Bridging HPC and cloud advancements, XaaS presents a unified
architecture built on performance-portable containers. Our converged model
concentrates on low-overhead, high-performance communication and computing,
targeting resource-intensive workloads from climate simulations to machine
learning. XaaS lifts the restricted allocation model of Function-as-a-Service
(FaaS), allowing users to benefit from the flexibility and efficient resource
utilization of serverless while supporting long-running and
performance-sensitive workloads from HPC.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04558" title="Abstract">arXiv:2401.04558</a> [<a href="/pdf/2401.04558" title="Download PDF">pdf</a>, <a href="/format/2401.04558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperGANStrument: Instrument Sound Synthesis and Editing with  Pitch-Invariant Hypernetworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Akama%2C+T">Taketo Akama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, Accepted for 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Audio examples: <a href="https://noto.li/MLIuBC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">GANStrument, exploiting GANs with a pitch-invariant feature extractor and
instance conditioning technique, has shown remarkable capabilities in
synthesizing realistic instrument sounds. To further improve the reconstruction
ability and pitch accuracy to enhance the editability of user-provided sound,
we propose HyperGANStrument, which introduces a pitch-invariant hypernetwork to
modulate the weights of a pre-trained GANStrument generator, given a one-shot
sound as input. The hypernetwork modulation provides feedback for the generator
in the reconstruction of the input sound. In addition, we take advantage of an
adversarial fine-tuning scheme for the hypernetwork to improve the
reconstruction fidelity and generation diversity of the generator. Experimental
results show that the proposed model not only enhances the generation
capability of GANStrument but also significantly improves the editability of
synthesized sounds. Audio examples are available at the online demo page.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04560" title="Abstract">arXiv:2401.04560</a> [<a href="/pdf/2401.04560" title="Download PDF">pdf</a>, <a href="/format/2401.04560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase-shifted remote photoplethysmography for estimating heart rate and  blood pressure from facial video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+G">Gyutae Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+J">Sang Jun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human health can be critically affected by cardiovascular diseases, such as
hypertension, arrhythmias, and stroke. Heart rate and blood pressure are
important biometric information for the monitoring of cardiovascular system and
early diagnosis of cardiovascular diseases. Existing methods for estimating the
heart rate are based on electrocardiography and photoplethyomography, which
require contacting the sensor to the skin surface. Moreover, catheter and
cuff-based methods for measuring blood pressure cause inconvenience and have
limited applicability. Therefore, in this thesis, we propose a vision-based
method for estimating the heart rate and blood pressure. This thesis proposes a
2-stage deep learning framework consisting of a dual remote
photoplethysmography network (DRP-Net) and bounded blood pressure network
(BBP-Net). In the first stage, DRP-Net infers remote photoplethysmography
(rPPG) signals for the acral and facial regions, and these phase-shifted rPPG
signals are utilized to estimate the heart rate. In the second stage, BBP-Net
integrates temporal features and analyzes phase discrepancy between the acral
and facial rPPG signals to estimate SBP and DBP values. To improve the accuracy
of estimating the heart rate, we employed a data augmentation method based on a
frame interpolation model. Moreover, we designed BBP-Net to infer blood
pressure within a predefined range by incorporating a scaled sigmoid function.
Our method resulted in estimating the heart rate with the mean absolute error
(MAE) of 1.78 BPM, reducing the MAE by 34.31 % compared to the recent method,
on the MMSE-HR dataset. The MAE for estimating the systolic blood pressure
(SBP) and diastolic blood pressure (DBP) were 10.19 mmHg and 7.09 mmHg. On the
V4V dataset, the MAE for the heart rate, SBP, and DBP were 3.83 BPM, 13.64
mmHg, and 9.4 mmHg, respectively.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04567" title="Abstract">arXiv:2401.04567</a> [<a href="/pdf/2401.04567" title="Download PDF">pdf</a>, <a href="/ps/2401.04567" title="Download PostScript">ps</a>, <a href="/format/2401.04567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Discrete Particle Swarm Optimizer for the Design of Cryptographic  Boolean Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mariot%2C+L">Luca Mariot</a>, 
<a href="/search/cs?searchtype=author&query=Leporati%2C+A">Alberto Leporati</a>, 
<a href="/search/cs?searchtype=author&query=Manzoni%2C+L">Luca Manzoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the poster paper "Heuristic Search by Particle Swarm Optimization of Boolean Functions for Cryptographic Applications" published in GECCO 2015
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">A Particle Swarm Optimizer for the search of balanced Boolean functions with
good cryptographic properties is proposed in this paper. The algorithm is a
modified version of the permutation PSO by Hu, Eberhart and Shi which preserves
the Hamming weight of the particles positions, coupled with the Hill Climbing
method devised by Millan, Clark and Dawson to improve the nonlinearity and
deviation from correlation immunity of Boolean functions. The parameters for
the PSO velocity equation are tuned by means of two meta-optimization
techniques, namely Local Unimodal Sampling (LUS) and Continuous Genetic
Algorithms (CGA), finding that CGA produces better results. Using the
CGA-evolved parameters, the PSO algorithm is then run on the spaces of Boolean
functions from $n=7$ to $n=12$ variables. The results of the experiments are
reported, observing that this new PSO algorithm generates Boolean functions
featuring similar or better combinations of nonlinearity, correlation immunity
and propagation criterion with respect to the ones obtained by other
optimization methods.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04572" title="Abstract">arXiv:2401.04572</a> [<a href="/pdf/2401.04572" title="Download PDF">pdf</a>, <a href="/format/2401.04572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Imitation Learning for Automated Game Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amadori%2C+P+V">Pierluigi Vito Amadori</a>, 
<a href="/search/cs?searchtype=author&query=Bradley%2C+T">Timothy Bradley</a>, 
<a href="/search/cs?searchtype=author&query=Spick%2C+R">Ryan Spick</a>, 
<a href="/search/cs?searchtype=author&query=Moss%2C+G">Guy Moss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Game development is a long process that involves many stages before a product
is ready for the market. Human play testing is among the most time consuming,
as testers are required to repeatedly perform tasks in the search for errors in
the code. Therefore, automated testing is seen as a key technology for the
gaming industry, as it would dramatically improve development costs and
efficiency. Toward this end, we propose EVOLUTE, a novel imitation
learning-based architecture that combines behavioural cloning (BC) with energy
based models (EBMs). EVOLUTE is a two-stream ensemble model that splits the
action space of autonomous agents into continuous and discrete tasks. The EBM
stream handles the continuous tasks, to have a more refined and adaptive
control, while the BC stream handles discrete actions, to ease training. We
evaluate the performance of EVOLUTE in a shooting-and-driving game, where the
agent is required to navigate and continuously identify targets to attack. The
proposed model has higher generalisation capabilities than standard BC
approaches, showing a wider range of behaviours and higher performances. Also,
EVOLUTE is easier to train than a pure end-to-end EBM model, as discrete tasks
can be quite sparse in the dataset and cause model training to explore a much
wider set of possible actions while training.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04575" title="Abstract">arXiv:2401.04575</a> [<a href="/pdf/2401.04575" title="Download PDF">pdf</a>, <a href="/format/2401.04575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual  Concept Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yatong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+U">Utsav Garg</a>, 
<a href="/search/cs?searchtype=author&query=Shanker%2C+A">Apaar Shanker</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Parajuli%2C+S">Samyak Parajuli</a>, 
<a href="/search/cs?searchtype=author&query=Bas%2C+E">Erhan Bas</a>, 
<a href="/search/cs?searchtype=author&query=Filipovic%2C+I">Isidora Filipovic</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+A+N">Amelia N. Chu</a>, 
<a href="/search/cs?searchtype=author&query=Fomitcheva%2C+E+D">Eugenia D Fomitcheva</a>, 
<a href="/search/cs?searchtype=author&query=Branson%2C+E">Elliot Branson</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Aerin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sojoudi%2C+S">Somayeh Sojoudi</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision and vision-language applications of neural networks, such as image
classification and captioning, rely on large-scale annotated datasets that
require non-trivial data-collecting processes. This time-consuming endeavor
hinders the emergence of large-scale datasets, limiting researchers and
practitioners to a small number of choices. Therefore, we seek more efficient
ways to collect and annotate images. Previous initiatives have gathered
captions from HTML alt-texts and crawled social media postings, but these data
sources suffer from noise, sparsity, or subjectivity. For this reason, we turn
to commercial shopping websites whose data meet three criteria: cleanliness,
informativeness, and fluency. We introduce the Let's Go Shopping (LGS) dataset,
a large-scale public dataset with 15 million image-caption pairs from publicly
available e-commerce websites. When compared with existing general-domain
datasets, the LGS images focus on the foreground object and have less complex
backgrounds. Our experiments on LGS show that the classifiers trained on
existing benchmark datasets do not readily generalize to e-commerce data, while
specific self-supervised visual feature extractors can better generalize.
Furthermore, LGS's high-quality e-commerce-focused images and bimodal nature
make it advantageous for vision-language bi-modal tasks: LGS enables
image-captioning models to generate richer captions and helps text-to-image
generation models achieve e-commerce style transfer.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04577" title="Abstract">arXiv:2401.04577</a> [<a href="/pdf/2401.04577" title="Download PDF">pdf</a>, <a href="/format/2401.04577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Audio Generation using a Single Non-Autoregressive Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziv%2C+A">Alon Ziv</a>, 
<a href="/search/cs?searchtype=author&query=Gat%2C+I">Itai Gat</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+G+L">Gael Le Lan</a>, 
<a href="/search/cs?searchtype=author&query=Remez%2C+T">Tal Remez</a>, 
<a href="/search/cs?searchtype=author&query=Kreuk%2C+F">Felix Kreuk</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%A9fossez%2C+A">Alexandre D&#xe9;fossez</a>, 
<a href="/search/cs?searchtype=author&query=Copet%2C+J">Jade Copet</a>, 
<a href="/search/cs?searchtype=author&query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="/search/cs?searchtype=author&query=Adi%2C+Y">Yossi Adi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce MAGNeT, a masked generative sequence modeling method that
operates directly over several streams of audio tokens. Unlike prior work,
MAGNeT is comprised of a single-stage, non-autoregressive transformer. During
training, we predict spans of masked tokens obtained from a masking scheduler,
while during inference we gradually construct the output sequence using several
decoding steps. To further enhance the quality of the generated audio, we
introduce a novel rescoring method in which, we leverage an external
pre-trained model to rescore and rank predictions from MAGNeT, which will be
then used for later decoding steps. Lastly, we explore a hybrid version of
MAGNeT, in which we fuse between autoregressive and non-autoregressive models
to generate the first few seconds in an autoregressive manner while the rest of
the sequence is being decoded in parallel. We demonstrate the efficiency of
MAGNeT for the task of text-to-music and text-to-audio generation and conduct
an extensive empirical evaluation, considering both objective metrics and human
studies. The proposed approach is comparable to the evaluated baselines, while
being significantly faster (x7 faster than the autoregressive baseline).
Through ablation studies and analysis, we shed light on the importance of each
of the components comprising MAGNeT, together with pointing to the trade-offs
between autoregressive and non-autoregressive modeling, considering latency,
throughput, and generation quality. Samples are available on our demo page
https://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04578" title="Abstract">arXiv:2401.04578</a> [<a href="/pdf/2401.04578" title="Download PDF">pdf</a>, <a href="/format/2401.04578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective pruning of web-scale datasets based on complexity of concept  clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbas%2C+A">Amro Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Rusak%2C+E">Evgenia Rusak</a>, 
<a href="/search/cs?searchtype=author&query=Tirumala%2C+K">Kushal Tirumala</a>, 
<a href="/search/cs?searchtype=author&query=Brendel%2C+W">Wieland Brendel</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+K">Kamalika Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Morcos%2C+A+S">Ari S. Morcos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Oral at the DataComp Workshop, ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Utilizing massive web-scale datasets has led to unprecedented performance
gains in machine learning models, but also imposes outlandish compute
requirements for their training. In order to improve training and data
efficiency, we here push the limits of pruning large-scale multimodal datasets
for training CLIP-style models. Today's most effective pruning method on
ImageNet clusters data samples into separate concepts according to their
embedding and prunes away the most prototypical samples. We scale this approach
to LAION and improve it by noting that the pruning rate should be
concept-specific and adapted to the complexity of the concept. Using a simple
and intuitive complexity measure, we are able to reduce the training cost to a
quarter of regular training. By filtering from the LAION dataset, we find that
training on a smaller set of high-quality data can lead to higher performance
with significantly lower training costs. More specifically, we are able to
outperform the LAION-trained OpenCLIP-ViT-B32 model on ImageNet zero-shot
accuracy by 1.1p.p. while only using 27.7% of the data and training compute.
Despite a strong reduction in training cost, we also see improvements on
ImageNet dist. shifts, retrieval tasks and VTAB. On the DataComp Medium
benchmark, we achieve a new state-of-the-art ImageNet zero-shot accuracy and a
competitive average zero-shot accuracy on 38 evaluation tasks.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04585" title="Abstract">arXiv:2401.04585</a> [<a href="/pdf/2401.04585" title="Download PDF">pdf</a>, <a href="/format/2401.04585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Distribution Alignment for Post-Training Quantization of  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuewen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhikai Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Junrui Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qingyi Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models have achieved great success in image generation tasks
through iterative noise estimation. However, the heavy denoising process and
complex neural networks hinder their low-latency applications in real-world
scenarios. Quantization can effectively reduce model complexity, and
post-training quantization (PTQ), which does not require fine-tuning, is highly
promising in accelerating the denoising process. Unfortunately, we find that
due to the highly dynamic distribution of activations in different denoising
steps, existing PTQ methods for diffusion models suffer from distribution
mismatch issues at both calibration sample level and reconstruction output
level, which makes the performance far from satisfactory, especially in low-bit
cases. In this paper, we propose Enhanced Distribution Alignment for
Post-Training Quantization of Diffusion Models (EDA-DM) to address the above
issues. Specifically, at the calibration sample level, we select calibration
samples based on the density and diversity in the latent space, thus
facilitating the alignment of their distribution with the overall samples; and
at the reconstruction output level, we propose Fine-grained Block
Reconstruction, which can align the outputs of the quantized model and the
full-precision model at different network granularity. Extensive experiments
demonstrate that EDA-DM outperforms the existing post-training quantization
frameworks in both unconditional and conditional generation scenarios. At
low-bit precision, the quantized models with our method even outperform the
full-precision models on most datasets.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04592" title="Abstract">arXiv:2401.04592</a> [<a href="/pdf/2401.04592" title="Download PDF">pdf</a>, <a href="/ps/2401.04592" title="Download PostScript">ps</a>, <a href="/format/2401.04592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Assessment on Comprehending Mental Health through Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arcan%2C+M">Mihael Arcan</a>, 
<a href="/search/cs?searchtype=author&query=Niland%2C+P">Paul-David Niland</a>, 
<a href="/search/cs?searchtype=author&query=Delahunty%2C+F">Fionn Delahunty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Mental health challenges pose considerable global burdens on individuals and
communities. Recent data indicates that more than 20% of adults may encounter
at least one mental disorder in their lifetime. On the one hand, the
advancements in large language models have facilitated diverse applications,
yet a significant research gap persists in understanding and enhancing the
potential of large language models within the domain of mental health. On the
other hand, across various applications, an outstanding question involves the
capacity of large language models to comprehend expressions of human mental
health conditions in natural language. This study presents an initial
evaluation of large language models in addressing this gap. Due to this, we
compare the performance of Llama-2 and ChatGPT with classical Machine as well
as Deep learning models. Our results on the DAIC-WOZ dataset show that
transformer-based models, like BERT or XLNet, outperform the large language
models.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04594" title="Abstract">arXiv:2401.04594</a> [<a href="/pdf/2401.04594" title="Download PDF">pdf</a>, <a href="/format/2401.04594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Relatively Complete Program Logic for Effectful Branching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zilberstein%2C+N">Noam Zilberstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Starting with Hoare Logic over 50 years ago, numerous sound and relatively
complete program logics have been devised to reason about the diverse programs
encountered in the real world. This includes reasoning about computational
effects, particularly those effects that cause the program execution to branch
into multiple paths due to, e.g., nondeterministic or probabilistic choice.
<br />The recently introduced Outcome Logic reimagines Hoare Logic with effects at
its core, using an algebraic representation of choice to capture a variety of
effects. In this paper, we give the first relatively complete proof system for
Outcome Logic, handling general purpose looping for the first time. We also
show that this proof system applies to programs with various effects and that
it facilitates the reuse of proof fragments across different kinds of
specifications.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04595" title="Abstract">arXiv:2401.04595</a> [<a href="/pdf/2401.04595" title="Download PDF">pdf</a>, <a href="/format/2401.04595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Modal Approach Based on Large Vision Model for Close-Range  Underwater Target Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+Z">Zeyu Sha</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feitian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Underwater target localization uses real-time sensory measurements to
estimate the position of underwater objects of interest, providing critical
feedback information for underwater robots. While acoustic sensing is the most
acknowledged method in underwater robots and possibly the only effective
approach for long-range underwater target localization, such a sensing modality
generally suffers from low resolution, high cost and high energy consumption,
thus leading to a mediocre performance when applied to close-range underwater
target localization. On the other hand, optical sensing has attracted
increasing attention in the underwater robotics community for its advantages of
high resolution and low cost, holding a great potential particularly in
close-range underwater target localization. However, most existing studies in
underwater optical sensing are restricted to specific types of targets due to
the limited training data available. In addition, these studies typically focus
on the design of estimation algorithms and ignore the influence of illumination
conditions on the sensing performance, thus hindering wider applications in the
real world. To address the aforementioned issues, this paper proposes a novel
target localization method that assimilates both optical and acoustic sensory
measurements to estimate the 3D positions of close-range underwater targets. A
test platform with controllable illumination conditions is designed and
developed to experimentally investigate the proposed multi-modal sensing
approach. A large vision model is applied to process the optical imaging
measurements, eliminating the requirement for training data acquisition, thus
significantly expanding the scope of potential applications. Extensive
experiments are conducted, the results of which validate the effectiveness of
the proposed underwater target localization method.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04601" title="Abstract">arXiv:2401.04601</a> [<a href="/pdf/2401.04601" title="Download PDF">pdf</a>, <a href="/ps/2401.04601" title="Download PostScript">ps</a>, <a href="/format/2401.04601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imagining Computing Education Assessment after Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MacNeil%2C+S">Stephen MacNeil</a>, 
<a href="/search/cs?searchtype=author&query=Spurlock%2C+S">Scott Spurlock</a>, 
<a href="/search/cs?searchtype=author&query=Applebaum%2C+I">Ian Applebaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In the contemporary landscape of computing education, the ubiquity of
Generative Artificial Intelligence has significantly disrupted traditional
assessment methods, rendering them obsolete and prompting educators to seek
innovative alternatives. This research paper explores the challenges posed by
Generative AI in the assessment domain and the persistent attempts to
circumvent its impact. Despite various efforts to devise workarounds, the
academic community is yet to find a comprehensive solution. Amidst this
struggle, ungrading emerges as a potential yet under-appreciated solution to
the assessment dilemma. Ungrading, a pedagogical approach that involves moving
away from traditional grading systems, has faced resistance due to its
perceived complexity and the reluctance of educators to depart from
conventional assessment practices. However, as the inadequacies of current
assessment methods become increasingly evident in the face of Generative AI,
the time is ripe to reconsider and embrace ungrading.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04606" title="Abstract">arXiv:2401.04606</a> [<a href="/pdf/2401.04606" title="Download PDF">pdf</a>, <a href="/ps/2401.04606" title="Download PostScript">ps</a>, <a href="/format/2401.04606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Importance of Parameters in Database Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grohe%2C+M">Martin Grohe</a>, 
<a href="/search/cs?searchtype=author&query=Kimelfeld%2C+B">Benny Kimelfeld</a>, 
<a href="/search/cs?searchtype=author&query=Lindner%2C+P">Peter Lindner</a>, 
<a href="/search/cs?searchtype=author&query=Standke%2C+C">Christoph Standke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">We propose and study a framework for quantifying the importance of the
choices of parameter values to the result of a query over a database. These
parameters occur as constants in logical queries, such as conjunctive queries.
In our framework, the importance of a parameter is its SHAP score. This score
is a popular instantiation of the game-theoretic Shapley value to measuring the
importance of feature values in machine learning models. We make the case for
the rationale of using this score by explaining the intuition behind SHAP, and
by showing that we arrive at this score in two different, apparently opposing,
approaches to quantifying the contribution of a parameter.
<br />The application of the SHAP score requires two components in addition to the
query and the database: (a) a probability distribution over the combinations of
parameter values, and (b) a utility function that measures the similarity
between the result for the original parameters and the result for hypothetical
parameters. The main question addressed in the paper is the complexity of
calculating the SHAP score for different distributions and similarity measures.
We first address the case of probabilistically independent parameters. The
problem is hard if we consider a fragment of queries that is hard to evaluate
(as one would expect), and even for the fragment of acyclic conjunctive
queries. In some cases, though, one can efficiently list all relevant parameter
combinations, and then the SHAP score can be computed in polynomial time under
reasonable general conditions. Also tractable is the case of full acyclic
conjunctive queries for certain (natural) similarity functions. We extend our
results to conjunctive queries with inequalities between variables and
parameters. Finally, we discuss a simple approximation technique for the case
of correlated parameters.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04608" title="Abstract">arXiv:2401.04608</a> [<a href="/pdf/2401.04608" title="Download PDF">pdf</a>, <a href="/format/2401.04608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiawei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hui Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent years have witnessed remarkable progress in image generation task,
where users can create visually astonishing images with high-quality. However,
existing text-to-image diffusion models are proficient in generating concrete
concepts (dogs) but encounter challenges with more abstract ones (emotions).
Several efforts have been made to modify image emotions with color and style
adjustments, facing limitations in effectively conveying emotions with fixed
image contents. In this work, we introduce Emotional Image Content Generation
(EICG), a new task to generate semantic-clear and emotion-faithful images given
emotion categories. Specifically, we propose an emotion space and construct a
mapping network to align it with the powerful Contrastive Language-Image
Pre-training (CLIP) space, providing a concrete interpretation of abstract
emotions. Attribute loss and emotion confidence are further proposed to ensure
the semantic diversity and emotion fidelity of the generated images. Our method
outperforms the state-of-the-art text-to-image approaches both quantitatively
and qualitatively, where we derive three custom metrics, i.e., emotion
accuracy, semantic clarity and semantic diversity. In addition to generation,
our method can help emotion understanding and inspire emotional art design.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04609" title="Abstract">arXiv:2401.04609</a> [<a href="/pdf/2401.04609" title="Download PDF">pdf</a>, <a href="/ps/2401.04609" title="Download PostScript">ps</a>, <a href="/format/2401.04609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of a family of time-continuous strongly conservative space-time  finite element methods for the dynamic Biot model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kraus%2C+J">Johannes Kraus</a>, 
<a href="/search/math?searchtype=author&query=Lymbery%2C+M">Maria Lymbery</a>, 
<a href="/search/math?searchtype=author&query=Osthues%2C+K">Kevin Osthues</a>, 
<a href="/search/math?searchtype=author&query=Philo%2C+F">Fadi Philo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the dynamic Biot model describing the interaction between fluid
flow and solid deformation including wave propagation phenomena in both the
liquid and solid phases of a saturated porous medium. The model couples a
hyperbolic equation for momentum balance to a second-order in time dynamic
Darcy law and a parabolic equation for the balance of mass and is here
considered in three-field formulation with the displacement of the elastic
matrix, the fluid velocity, and the fluid pressure being the physical fields of
interest. A family of variational space-time finite element methods is proposed
that combines a continuous-in-time Galerkin ansatz of arbitrary polynomial
degree with inf-sup stable $H(\rm{div})$-conforming approximations of
discontinuous Galerkin (DG) type in case of the displacement and a mixed
approximation of the flux, its time derivative and the pressure field. We prove
error estimates in a combined energy norm as well as $L^2$~error estimates in
space for the individual fields for both maximum and $L^2$ norm in time which
are optimal for the displacement and pressure approximations.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04612" title="Abstract">arXiv:2401.04612</a> [<a href="/pdf/2401.04612" title="Download PDF">pdf</a>, <a href="/format/2401.04612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Free Conformal Joint Prediction Regions for Neural Marked  Temporal Point Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dheur%2C+V">Victor Dheur</a>, 
<a href="/search/cs?searchtype=author&query=Bosser%2C+T">Tanguy Bosser</a>, 
<a href="/search/cs?searchtype=author&query=Izbicki%2C+R">Rafael Izbicki</a>, 
<a href="/search/cs?searchtype=author&query=Taieb%2C+S+B">Souhaib Ben Taieb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Sequences of labeled events observed at irregular intervals in continuous
time are ubiquitous across various fields. Temporal Point Processes (TPPs)
provide a mathematical framework for modeling these sequences, enabling
inferences such as predicting the arrival time of future events and their
associated label, called mark. However, due to model misspecification or lack
of training data, these probabilistic models may provide a poor approximation
of the true, unknown underlying process, with prediction regions extracted from
them being unreliable estimates of the underlying uncertainty. This paper
develops more reliable methods for uncertainty quantification in neural TPP
models via the framework of conformal prediction. A primary objective is to
generate a distribution-free joint prediction region for the arrival time and
mark, with a finite-sample marginal coverage guarantee. A key challenge is to
handle both a strictly positive, continuous response and a categorical
response, without distributional assumptions. We first consider a simple but
overly conservative approach that combines individual prediction regions for
the event arrival time and mark. Then, we introduce a more effective method
based on bivariate highest density regions derived from the joint predictive
density of event arrival time and mark. By leveraging the dependencies between
these two variables, this method exclude unlikely combinations of the two,
resulting in sharper prediction regions while still attaining the pre-specified
coverage level. We also explore the generation of individual univariate
prediction regions for arrival times and marks through conformal regression and
classification techniques. Moreover, we investigate the stronger notion of
conditional coverage. Finally, through extensive experimentation on both
simulated and real-world datasets, we assess the validity and efficiency of
these methods.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04614" title="Abstract">arXiv:2401.04614</a> [<a href="/pdf/2401.04614" title="Download PDF">pdf</a>, <a href="/format/2401.04614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generic Knowledge Boosted Pre-training For Remote Sensing Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziyue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning models are essential for scene classification, change
detection, land cover segmentation, and other remote sensing image
understanding tasks. Most backbones of existing remote sensing deep learning
models are typically initialized by pre-trained weights obtained from ImageNet
pre-training (IMP). However, domain gaps exist between remote sensing images
and natural images (e.g., ImageNet), making deep learning models initialized by
pre-trained weights of IMP perform poorly for remote sensing image
understanding. Although some pre-training methods are studied in the remote
sensing community, current remote sensing pre-training methods face the problem
of vague generalization by only using remote sensing images. In this paper, we
propose a novel remote sensing pre-training framework, Generic Knowledge
Boosted Remote Sensing Pre-training (GeRSP), to learn robust representations
from remote sensing and natural images for remote sensing understanding tasks.
GeRSP contains two pre-training branches: (1) A self-supervised pre-training
branch is adopted to learn domain-related representations from unlabeled remote
sensing images. (2) A supervised pre-training branch is integrated into GeRSP
for general knowledge learning from labeled natural images. Moreover, GeRSP
combines two pre-training branches using a teacher-student architecture to
simultaneously learn representations with general and special knowledge, which
generates a powerful pre-trained model for deep learning model initialization.
Finally, we evaluate GeRSP and other remote sensing pre-training methods on
three downstream tasks, i.e., object detection, semantic segmentation, and
scene classification. The extensive experimental results consistently
demonstrate that GeRSP can effectively learn robust representations in a
unified manner, improving the performance of remote sensing downstream tasks.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04619" title="Abstract">arXiv:2401.04619</a> [<a href="/pdf/2401.04619" title="Download PDF">pdf</a>, <a href="/format/2401.04619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Detection for Transliterated Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+S+K">Selva Kumar S</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+K+M+A">Afifah Khan Mohammed Ajmal Khan</a>, 
<a href="/search/cs?searchtype=author&query=Manjeshwar%2C+C">Chirag Manjeshwar</a>, 
<a href="/search/cs?searchtype=author&query=Banday%2C+I+A">Imadh Ajaz Banday</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 Pages, 6 diagrams
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the contemporary digital era, the Internet functions as an unparalleled
catalyst, dismantling geographical and linguistic barriers particularly evident
in texting. This evolution facilitates global communication, transcending
physical distances and fostering dynamic cultural exchange. A notable trend is
the widespread use of transliteration, where the English alphabet is employed
to convey messages in native languages, posing a unique challenge for language
technology in accurately detecting the source language. This paper addresses
this challenge through a dataset of phone text messages in Hindi and Russian
transliterated into English utilizing BERT for language classification and
Google Translate API for transliteration conversion. The research pioneers
innovative approaches to identify and convert transliterated text, navigating
challenges in the diverse linguistic landscape of digital communication.
Emphasizing the pivotal role of comprehensive datasets for training Large
Language Models LLMs like BERT, our model showcases exceptional proficiency in
accurately identifying and classifying languages from transliterated text. With
a validation accuracy of 99% our models robust performance underscores its
reliability. The comprehensive exploration of transliteration dynamics
supported by innovative approaches and cutting edge technologies like BERT,
positions our research at the forefront of addressing unique challenges in the
linguistic landscape of digital communication. Beyond contributing to language
identification and transliteration capabilities this work holds promise for
applications in content moderation, analytics and fostering a globally
connected community engaged in meaningful dialogue.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04620" title="Abstract">arXiv:2401.04620</a> [<a href="/pdf/2401.04620" title="Download PDF">pdf</a>, <a href="/format/2401.04620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent Alignment in Evolving Social Norms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shimin Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tianxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Agents based on Large Language Models (LLMs) are increasingly permeating
various domains of human production and life, highlighting the importance of
aligning them with human values. The current alignment of AI systems primarily
focuses on passively aligning LLMs through human intervention. However, agents
possess characteristics like receiving environmental feedback and
self-evolution, rendering the LLM alignment methods inadequate. In response, we
propose an evolutionary framework for agent evolution and alignment, named
EvolutionaryAgent, which transforms agent alignment into a process of evolution
and selection under the principle of survival of the fittest. In an environment
where social norms continuously evolve, agents better adapted to the current
social norms will have a higher probability of survival and proliferation,
while those inadequately aligned dwindle over time. Experimental results
assessing the agents from multiple perspectives in aligning with social norms
demonstrate that EvolutionaryAgent possesses the capability to align
progressively better with the evolving social norms while maintaining its
proficiency in general tasks. Effectiveness tests conducted on various open and
closed-source LLMs as the foundation for agents also prove the applicability of
our approach.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04621" title="Abstract">arXiv:2401.04621</a> [<a href="/pdf/2401.04621" title="Download PDF">pdf</a>, <a href="/format/2401.04621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DebugBench: Evaluating Debugging Capability of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+R">Runchu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yining Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yujia Qin</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+X">Xin Cong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated exceptional coding capability.
However, as another critical component of programming proficiency, the
debugging capability of LLMs remains relatively unexplored. Previous
evaluations of LLMs' debugging ability are significantly limited by the risk of
data leakage, the scale of the dataset, and the variety of tested bugs. To
overcome these deficiencies, we introduce `DebugBench', an LLM debugging
benchmark consisting of 4,253 instances. It covers four major bug categories
and 18 minor types in C++, Java, and Python. To construct DebugBench, we
collect code snippets from the LeetCode community, implant bugs into source
data with GPT-4, and assure rigorous quality checks. We evaluate two commercial
and three open-source models in a zero-shot scenario. We find that (1) while
closed-source models like GPT-4 exhibit inferior debugging performance compared
to humans, open-source models such as Code Llama fail to attain any pass rate
scores; (2) the complexity of debugging notably fluctuates depending on the bug
category; (3) incorporating runtime feedback has a clear impact on debugging
performance which is not always helpful. As an extension, we also compare LLM
debugging and code generation, revealing a strong correlation between them for
closed-source models. These findings will benefit the development of LLMs in
debugging.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04626" title="Abstract">arXiv:2401.04626</a> [<a href="/pdf/2401.04626" title="Download PDF">pdf</a>, <a href="/format/2401.04626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel OMNeT++-based Simulation Tool for Vehicular Cloud Computing in  ETSI MEC-compliant 5G Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feraudo%2C+A">Angelo Feraudo</a>, 
<a href="/search/cs?searchtype=author&query=Calvio%2C+A">Alessandro Calvio</a>, 
<a href="/search/cs?searchtype=author&query=Bellavista%2C+P">Paolo Bellavista</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Vehicular cloud computing is gaining popularity thanks to the rapid
advancements in next generation wireless communication networks. Similarly,
Edge Computing, along with its standard proposals such as European
Telecommunications Standards Institute (ETSI) Multi-access Edge Computing
(MEC), will play a vital role in these scenarios, by enabling the execution of
cloud-based services at the edge of the network. Together, these solutions have
the potential to create real micro-datacenters at the network edge, favoring
several benefits like minimal latency, real-time data processing, and data
locality. However, the research community has not yet the opportunity to use
integrated simulation frameworks for the easy testing of applications that
exploit both the vehicular cloud paradigm and MEC-compliant 5G deployment
environments. In this paper, we present our simulation tool as a platform for
researchers and engineers to design, test, and enhance applications utilizing
the concepts of vehicular and edge cloud. Our platform significantly extends
OMNet++ and Simu5G, and implements our ETSI MEC-compliant architecture that
leverages resources provided by far-edge nodes. In addition, the paper analyzes
and reports performance results for our simulation platform, as well as
provides a use case where our simulator is used to support the design, test,
and validation of an algorithm to distribute MEC application components on
vehicular cloud resources.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04628" title="Abstract">arXiv:2401.04628</a> [<a href="/pdf/2401.04628" title="Download PDF">pdf</a>, <a href="/ps/2401.04628" title="Download PostScript">ps</a>, <a href="/format/2401.04628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Neuron Representations of Hierarchical Concepts in Spiking Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lynch%2C+N+A">Nancy A. Lynch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We describe how hierarchical concepts can be represented in three types of
layered neural networks. The aim is to support recognition of the concepts when
partial information about the concepts is presented, and also when some of the
neurons in the network might fail. Our failure model involves initial random
failures. The three types of networks are: feed-forward networks with high
connectivity, feed-forward networks with low connectivity, and layered networks
with low connectivity and with both forward edges and "lateral" edges within
layers. In order to achieve fault-tolerance, the representations all use
multiple representative neurons for each concept. We show how recognition can
work in all three of these settings, and quantify how the probability of
correct recognition depends on several parameters, including the number of
representatives and the neuron failure probability. We also discuss how these
representations might be learned, in all three types of networks. For the
feed-forward networks, the learning algorithms are similar to ones used in [4],
whereas for networks with lateral edges, the algorithms are generally inspired
by work on the assembly calculus [3, 6, 7].
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04631" title="Abstract">arXiv:2401.04631</a> [<a href="/pdf/2401.04631" title="Download PDF">pdf</a>, <a href="/format/2401.04631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Multi-agent Learning framework for Information  Gathering with Local Gaussian Processes for Water Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luis%2C+S+Y">Samuel Yanes Luis</a>, 
<a href="/search/cs?searchtype=author&query=Shutin%2C+D">Dmitriy Shutin</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+J+M">Juan Marchal G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Reina%2C+D+G">Daniel Guti&#xe9;rrez Reina</a>, 
<a href="/search/cs?searchtype=author&query=Mar%C3%ADn%2C+S+T">Sergio Toral Mar&#xed;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The conservation of hydrological resources involves continuously monitoring
their contamination. A multi-agent system composed of autonomous surface
vehicles is proposed in this paper to efficiently monitor the water quality. To
achieve a safe control of the fleet, the fleet policy should be able to act
based on measurements and to the the fleet state. It is proposed to use Local
Gaussian Processes and Deep Reinforcement Learning to jointly obtain effective
monitoring policies. Local Gaussian processes, unlike classical global Gaussian
processes, can accurately model the information in a dissimilar spatial
correlation which captures more accurately the water quality information. A
Deep convolutional policy is proposed, that bases the decisions on the
observation on the mean and variance of this model, by means of an information
gain reward. Using a Double Deep Q-Learning algorithm, agents are trained to
minimize the estimation error in a safe manner thanks to a Consensus-based
heuristic. Simulation results indicate an improvement of up to 24% in terms of
the mean absolute error with the proposed models. Also, training results with
1-3 agents indicate that our proposed approach returns 20% and 24% smaller
average estimation errors for, respectively, monitoring water quality variables
and monitoring algae blooms, as compared to state-of-the-art approaches
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04632" title="Abstract">arXiv:2401.04632</a> [<a href="/pdf/2401.04632" title="Download PDF">pdf</a>, <a href="/format/2401.04632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypercomplex neural network in time series forecasting of stock data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kycia%2C+R">Rados&#x142;aw Kycia</a>, 
<a href="/search/cs?searchtype=author&query=Niemczynowicz%2C+A">Agnieszka Niemczynowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The three classes of architectures for time series prediction were tested.
They differ by input layers which contain either convolutional, LSTM, or dense
hypercomplex layers for 4D algebras. The input was four related Stock Market
time series, and the prediction of one of them is expected. The optimization of
hyperparameters related to the classes of architectures was performed in order
to compare the best neural networks within the class. The results show that in
most cases, the architecture with a hypercomplex dense layer provides similar
MAE accuracy to other architectures, however, with considerably less trainable
parameters. Thanks to it, hypercomplex neural networks can be learned and
process data faster than the other tested architectures. Moreover, the order of
the input time series has an impact on effectively.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04636" title="Abstract">arXiv:2401.04636</a> [<a href="/pdf/2401.04636" title="Download PDF">pdf</a>, <a href="/format/2401.04636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Target Detection Performance of a Molecular Communication Network  with Multiple Mobile Nanomachines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabu%2C+N+V">Nithin V. Sabu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A+K">Abhishek K. Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A network of nanomachines (NMs) can be used to build a target detection
system for a variety of promising applications. They have the potential to
detect toxic chemicals, infectious bacteria, and biomarkers of dangerous
diseases such as cancer within the human body. Many diseases and health
disorders can be detected early and efficiently treated in the future by
utilizing these systems. To fully grasp the potential of these systems,
mathematical analysis is required. This paper describes an analytical framework
for modeling and analyzing the performance of target detection systems composed
of multiple mobile nanomachines of varying sizes with passive/absorbing
boundaries. We consider both direct contact detection, in which NMs must
physically contact the target to detect it, and indirect sensing, in which NMs
must detect the marker molecules emitted by the target. The detection
performance of such systems is calculated for degradable and non-degradable
targets, as well as mobile and stationary targets. The derived expressions
provide various insights, such as the effect of NM density and target
degradation on detection probability.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04637" title="Abstract">arXiv:2401.04637</a> [<a href="/pdf/2401.04637" title="Download PDF">pdf</a>, <a href="/format/2401.04637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying Large Language Models API to Issue Classification Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aracena%2C+G">Gabriel Aracena</a>, 
<a href="/search/cs?searchtype=author&query=Luster%2C+K">Kyle Luster</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+F">Fabio Santos</a>, 
<a href="/search/cs?searchtype=author&query=Steinmacher%2C+I">Igor Steinmacher</a>, 
<a href="/search/cs?searchtype=author&query=Gerosa%2C+M+A">Marco A. Gerosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure, NLBSE and ICSE conference submission, ACM formatted, pre print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Effective prioritization of issue reports is crucial in software engineering
to optimize resource allocation and address critical problems promptly.
However, the manual classification of issue reports for prioritization is
laborious and lacks scalability. Alternatively, many open source software (OSS)
projects employ automated processes for this task, albeit relying on
substantial datasets for adequate training. This research seeks to devise an
automated approach that ensures reliability in issue prioritization, even when
trained on smaller datasets. Our proposed methodology harnesses the power of
Generative Pre-trained Transformers (GPT), recognizing their potential to
efficiently handle this task. By leveraging the capabilities of such models, we
aim to develop a robust system for prioritizing issue reports accurately,
mitigating the necessity for extensive training data while maintaining
reliability. In our research, we have developed a reliable GPT-based approach
to accurately label and prioritize issue reports with a reduced training
dataset. By reducing reliance on massive data requirements and focusing on
few-shot fine-tuning, our methodology offers a more accessible and efficient
solution for issue prioritization in software engineering. Our model predicted
issue types in individual projects up to 93.2% in precision, 95% in recall, and
89.3% in F1-score.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04638" title="Abstract">arXiv:2401.04638</a> [<a href="/pdf/2401.04638" title="Download PDF">pdf</a>, <a href="/format/2401.04638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation Algorithms for Minimizing Congestion in Demand-Aware  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenkai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Dinitz%2C+M">Michael Dinitz</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+K">Klaus-Tycho Foerster</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Long Luo</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+S">Stefan Schmid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Emerging reconfigurable optical communication technologies allow to enhance
datacenter topologies with demand-aware links optimized towards traffic
patterns. This paper studies the algorithmic problem of jointly optimizing
topology and routing in such demand-aware networks to minimize congestion,
along two dimensions: (1) splittable or unsplittable flows, and (2) whether
routing is segregated, i.e., whether routes can or cannot combine both
demand-aware and demand-oblivious (static) links.
<br />For splittable and segregated routing, we show that the problem is generally
$2$-approximable, but APX-hard even for uniform demands induced by a bipartite
demand graph. For unsplittable and segregated routing, we establish upper and
lower bounds of $O\left(\log m/ \log\log m \right)$ and $\Omega\left(\log m/
\log\log m \right)$, respectively, for polynomial-time approximation
algorithms, where $m$ is the number of static links. We further reveal that
under un-/splittable and non-segregated routing, even for demands of a single
source (resp., destination), the problem cannot be approximated better than
$\Omega\left(\frac{c_{\max}}{c_{\min}} \right)$ unless P=NP, where $c_{\max}$
(resp., $c_{\min}$) denotes the maximum (resp., minimum) capacity. It remains
NP-hard for uniform capacities, but is tractable for a single commodity and
uniform capacities.
<br />Our trace-driven simulations show a significant reduction in network
congestion compared to existing solutions.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04647" title="Abstract">arXiv:2401.04647</a> [<a href="/pdf/2401.04647" title="Download PDF">pdf</a>, <a href="/format/2401.04647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Ante-Hoc Explainable Models through Generative Adversarial  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+T">Tanmay Garg</a>, 
<a href="/search/cs?searchtype=author&query=Vemuri%2C+D">Deepika Vemuri</a>, 
<a href="/search/cs?searchtype=author&query=Balasubramanian%2C+V+N">Vineeth N Balasubramanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted in Human-Centric Representation Learning workshop at AAAI 2024 (<a href="https://hcrl-workshop.github.io/2024/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a novel concept learning framework for enhancing model
interpretability and performance in visual classification tasks. Our approach
appends an unsupervised explanation generator to the primary classifier network
and makes use of adversarial training. During training, the explanation module
is optimized to extract visual concepts from the classifier's latent
representations, while the GAN-based module aims to discriminate images
generated from concepts, from true images. This joint training scheme enables
the model to implicitly align its internally learned concepts with
human-interpretable visual properties. Comprehensive experiments demonstrate
the robustness of our approach, while producing coherent concept activations.
We analyse the learned concepts, showing their semantic concordance with object
parts and visual attributes. We also study how perturbations in the adversarial
training protocol impact both classification and concept acquisition. In
summary, this work presents a significant step towards building inherently
interpretable deep vision models with task-aligned concept representations - a
key enabler for developing trustworthy AI for real-world perception tasks.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04648" title="Abstract">arXiv:2401.04648</a> [<a href="/pdf/2401.04648" title="Download PDF">pdf</a>, <a href="/format/2401.04648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel framework for generalization of deep hidden physics models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kag%2C+V">Vijay Kag</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+B">Birupaksha Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Analysis of PDEs (math.AP)

</div>
<p class="mathjax">Modelling of systems where the full system information is unknown is an oft
encountered problem for various engineering and industrial applications, as
it's either impossible to consider all the complex physics involved or simpler
models are considered to keep within the limits of the available resources.
Recent advances in greybox modelling like the deep hidden physics models
address this space by combining data and physics. However, for most real-life
applications, model generalizability is a key issue, as retraining a model for
every small change in system inputs and parameters or modification in domain
configuration can render the model economically unviable. In this work we
present a novel enhancement to the idea of hidden physics models which can
generalize for changes in system inputs, parameters and domains. We also show
that this approach holds promise in system discovery as well and helps learn
the hidden physics for the changed system inputs, parameters and domain
configuration.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04649" title="Abstract">arXiv:2401.04649</a> [<a href="/pdf/2401.04649" title="Download PDF">pdf</a>, <a href="/format/2401.04649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From axial C-hedra to general P-nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nawratil%2C+G">Georg Nawratil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We give a full classification of continuous flexible discrete axial
cone-nets, which are called axial C-hedra. The obtained result can also be used
to construct their semi-discrete analogs. Moreover, we identify a novel
subclass within the determined class of (semi-)discrete axial cone-nets, whose
members are named axial P-nets as they fulfill the proportion (P) of the
intercept theorem. Known special cases of these axial P-nets are the smooth and
discrete conic crease patterns with reflecting rule lines. By using a
parallelism operation one can even generalize axial P-nets. The resulting
general P-nets constitute a rich novel class of continuous flexible
(semi-)discrete surfaces, which allow direct access to their spatial shapes by
three control polylines. This intuitive method makes them suitable for
transformable design tasks using interactive tools.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04650" title="Abstract">arXiv:2401.04650</a> [<a href="/pdf/2401.04650" title="Download PDF">pdf</a>, <a href="/format/2401.04650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hold &#x27;em and Fold &#x27;em: Towards Human-scale, Feedback-Controlled Soft  Origami Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mensah%2C+I+A">Immanuel Ampomah Mensah</a>, 
<a href="/search/cs?searchtype=author&query=Healey%2C+J">Jessica Healey</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Celina Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lacunza%2C+A">Andrea Lacunza</a>, 
<a href="/search/cs?searchtype=author&query=Hanson%2C+N">Nathaniel Hanson</a>, 
<a href="/search/cs?searchtype=author&query=Dorsey%2C+K+L">Kristen L. Dorsey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">An underdeveloped capability in soft robotics is proprioceptive feedback
control, where soft actuators can be sensed and controlled using only sensors
on the robot's body. Additionally, soft actuators are often unable to support
human-scale loads due to the extremely compliant materials in use. Developing
both feedback control and the ability to actuate under large loads (e.g. 500 N)
are key capacities required to move soft robotics into everyday applications.
In this work, we independently demonstrate these key factors towards
controlling and actuating human-scale loads: proprioceptive (embodied) feedback
control of a soft, pneumatically-actuated origami robot; and actuation of these
origami origami robots under a person's weight in an open-loop configuration.
In both demonstrations, the actuators are controlled by internal fluidic
pressure. Capacitive sensors patterned onto the robot provide position
estimation and serve as input to a feedback controller. We demonstrate position
control of a single actuator during stepped setpoints and sinusoidal trajectory
following, with root mean square error (RMSE) below 4 mm. We also showcase the
actuator's potential towards human-scale robotics as an "origami balance board"
by joining three actuators into an open-loop controlled system with a platform
that varies its height, roll, and pitch. This work contributes to the field of
soft robotics by demonstrating closed-loop feedback position control without
visual tracking as an input and lightweight, soft actuators that can support a
person's weight. The project repository, including videos, CAD files, and ROS
code, is available at https://parses-lab.github.io/kresling_control.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04651" title="Abstract">arXiv:2401.04651</a> [<a href="/pdf/2401.04651" title="Download PDF">pdf</a>, <a href="/format/2401.04651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Prompt Segment Anything Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiaxing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segment Anything Models (SAMs) like SEEM and SAM have demonstrated great
potential in learning to segment anything. The core design of SAMs lies with
Promptable Segmentation, which takes a handcrafted prompt as input and returns
the expected segmentation mask. SAMs work with two types of prompts including
spatial prompts (e.g., points) and semantic prompts (e.g., texts), which work
together to prompt SAMs to segment anything on downstream datasets. Despite the
important role of prompts, how to acquire suitable prompts for SAMs is largely
under-explored. In this work, we examine the architecture of SAMs and identify
two challenges for learning effective prompts for SAMs. To this end, we propose
spatial-semantic prompt learning (SSPrompt) that learns effective semantic and
spatial prompts for better SAMs. Specifically, SSPrompt introduces spatial
prompt learning and semantic prompt learning, which optimize spatial prompts
and semantic prompts directly over the embedding space and selectively leverage
the knowledge encoded in pre-trained prompt encoders. Extensive experiments
show that SSPrompt achieves superior image segmentation performance
consistently across multiple widely adopted datasets.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04655" title="Abstract">arXiv:2401.04655</a> [<a href="/pdf/2401.04655" title="Download PDF">pdf</a>, <a href="/ps/2401.04655" title="Download PostScript">ps</a>, <a href="/format/2401.04655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DepressionEmo: A novel dataset for multilabel classification of  depression emotions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A+B+S">Abu Bakar Siddiqur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Ta%2C+H">Hoang-Thang Ta</a>, 
<a href="/search/cs?searchtype=author&query=Najjar%2C+L">Lotfollah Najjar</a>, 
<a href="/search/cs?searchtype=author&query=Azadmanesh%2C+A">Azad Azadmanesh</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6n%C3%BCl%2C+A+S">Ali Saffet G&#xf6;n&#xfc;l</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Emotions are integral to human social interactions, with diverse responses
elicited by various situational contexts. Particularly, the prevalence of
negative emotional states has been correlated with negative outcomes for mental
health, necessitating a comprehensive analysis of their occurrence and impact
on individuals. In this paper, we introduce a novel dataset named DepressionEmo
designed to detect 8 emotions associated with depression by 6037 examples of
long Reddit user posts. This dataset was created through a majority vote over
inputs by zero-shot classifications from pre-trained models and validating the
quality by annotators and ChatGPT, exhibiting an acceptable level of interrater
reliability between annotators. The correlation between emotions, their
distribution over time, and linguistic analysis are conducted on DepressionEmo.
Besides, we provide several text classification methods classified into two
groups: machine learning methods such as SVM, XGBoost, and Light GBM; and deep
learning methods such as BERT, GAN-BERT, and BART. The pretrained BART model,
bart-base allows us to obtain the highest F1- Macro of 0.76, showing its
outperformance compared to other methods evaluated in our analysis. Across all
emotions, the highest F1-Macro value is achieved by suicide intent, indicating
a certain value of our dataset in identifying emotions in individuals with
depression symptoms through text analysis. The curated dataset is publicly
available at: https://github.com/abuBakarSiddiqurRahman/DepressionEmo.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04658" title="Abstract">arXiv:2401.04658</a> [<a href="/pdf/2401.04658" title="Download PDF">pdf</a>, <a href="/format/2401.04658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence  Lengths in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weigao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuyang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. Yiran Zhong is the corresponding author. The source code is available at <a href="https://github.com/OpenNLPLab/lightning-attention">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Linear attention is an efficient attention mechanism that has recently
emerged as a promising alternative to conventional softmax attention. With its
ability to process tokens in linear computational complexities, linear
attention, in theory, can handle sequences of unlimited length without
sacrificing speed, i.e., maintaining a constant training speed for various
sequence lengths with a fixed memory consumption. However, due to the issue
with cumulative summation (cumsum), current linear attention algorithms cannot
demonstrate their theoretical advantage in a causal setting. In this paper, we
present Lightning Attention-2, the first linear attention implementation that
enables linear attention to realize its theoretical computational benefits. To
achieve this, we leverage the thought of tiling, separately handling the
intra-block and inter-block components in linear attention calculation.
Specifically, we utilize the conventional attention computation mechanism for
the intra-blocks and apply linear attention kernel tricks for the inter-blocks.
A tiling technique is adopted through both forward and backward procedures to
take full advantage of the GPU hardware. We implement our algorithm in Triton
to make it IO-aware and hardware-friendly. Various experiments are conducted on
different model sizes and sequence lengths. Lightning Attention-2 retains
consistent training and inference speed regardless of input sequence length and
is significantly faster than other attention mechanisms. The source code is
available at https://github.com/OpenNLPLab/lightning-attention.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04660" title="Abstract">arXiv:2401.04660</a> [<a href="/pdf/2401.04660" title="Download PDF">pdf</a>, <a href="/format/2401.04660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Data-driven Unknown-input Observers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wei%2C+Y">Yuzhou Wei</a>, 
<a href="/search/eess?searchtype=author&query=Disar%C3%B2%2C+G">Giorgia Disar&#xf2;</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wenjie Liu</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+J">Jian Sun</a>, 
<a href="/search/eess?searchtype=author&query=Valcher%2C+M+E">Maria Elena Valcher</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Gang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Unknown inputs related to, e.g., sensor aging, modeling errors, or device
bias, represent a major concern in wireless sensor networks, as they degrade
the state estimation performance. To improve the performance, unknown-input
observers (UIOs) have been proposed. Most of the results available to design
UIOs are based on explicit system models, which can be difficult or impossible
to obtain in real-world applications. Data-driven techniques, on the other
hand, have become a viable alternative for the design and analysis of unknown
systems using only data. In this context, a novel data-driven distributed
unknown-input observer (D-DUIO) for an unknown linear system is developed,
which leverages solely some data collected offline, without any prior knowledge
of the system matrices. In the paper, first, the design of a DUIO is
investigated by resorting to a traditional model-based approach. By resorting
to a Lyapunov equation, it is proved that under some conditions, the state
estimates at all nodes of the DUIO achieve consensus and collectively converge
to the state of the system. Moving to a data-driven approach, it is shown that
the input/output/state trajectories of the system are compatible with the
equations of a D-DUIO, and this allows, under suitable assumptions, to express
the matrices of a possible DUIO in terms of the matrices of pre-collected data.
Then, necessary and sufficient conditions for the existence of the proposed
D-DUIO are given. Finally, the efficacy of the D-DUIO is illustrated by means
of numerical examples.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04662" title="Abstract">arXiv:2401.04662</a> [<a href="/pdf/2401.04662" title="Download PDF">pdf</a>, <a href="/format/2401.04662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Devil Behind the Mirror: Tracking the Campaigns of Cryptocurrency  Abuses on the Dark Web
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+P">Pengcheng Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kailong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiapu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yajin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangdong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The dark web has emerged as the state-of-the-art solution for enhanced
anonymity. Just like a double-edged sword, it also inadvertently becomes the
safety net and breeding ground for illicit activities. Among them,
cryptocurrencies have been prevalently abused to receive illicit income while
evading regulations. Despite the continuing efforts to combat illicit
activities, there is still a lack of an in-depth understanding regarding the
characteristics and dynamics of cryptocurrency abuses on the dark web. In this
work, we conduct a multi-dimensional and systematic study to track
cryptocurrency-related illicit activities and campaigns on the dark web. We
first harvest a dataset of 4,923 cryptocurrency-related onion sites with over
130K pages. Then, we detect and extract the illicit blockchain transactions to
characterize the cryptocurrency abuses, targeting features from
single/clustered addresses and illicit campaigns. Throughout our study, we have
identified 2,564 illicit sites with 1,189 illicit blockchain addresses, which
account for 90.8 BTC in revenue. Based on their inner connections, we further
identify 66 campaigns behind them. Our exploration suggests that illicit
activities on the dark web have strong correlations, which can guide us to
identify new illicit blockchain addresses and onions, and raise alarms at the
early stage of their deployment.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04663" title="Abstract">arXiv:2401.04663</a> [<a href="/pdf/2401.04663" title="Download PDF">pdf</a>, <a href="/format/2401.04663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Deep Fourier Residual method via overlapping domain  decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Taylor%2C+J+M">Jamie M. Taylor</a>, 
<a href="/search/math?searchtype=author&query=Bastidas%2C+M">Manuela Bastidas</a>, 
<a href="/search/math?searchtype=author&query=Calo%2C+V+M">Victor M. Calo</a>, 
<a href="/search/math?searchtype=author&query=Pardo%2C+D">David Pardo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Deep Fourier Residual (DFR) method is a specific type of variational
physics-informed neural networks (VPINNs). It provides a robust neural
network-based solution to partial differential equations (PDEs). The DFR
strategy is based on approximating the dual norm of the weak residual of a PDE.
This is equivalent to minimizing the energy norm of the error. To compute the
dual of the weak residual norm, the DFR method employs an orthonormal spectral
basis of the test space, which is known for rectangles or cuboids for multiple
function spaces.
<br />In this work, we extend the DFR method with ideas of traditional domain
decomposition (DD). This enables two improvements: (a) to solve problems in
more general polygonal domains, and (b) to develop an adaptive refinement
technique in the test space using a Dofler marking algorithm. In the former
case, we show that under non-restrictive assumptions we retain the desirable
equivalence between the employed loss function and the H1-error, numerically
demonstrating adherence to explicit bounds in the case of the L-shaped domain
problem. In the latter, we show how refinement strategies lead to potentially
significant improvements against a reference, classical DFR implementation with
a test function space of significantly lower dimensionality, allowing us to
better approximate singular solutions at a more reasonable computational cost.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04666" title="Abstract">arXiv:2401.04666</a> [<a href="/pdf/2401.04666" title="Download PDF">pdf</a>, <a href="/ps/2401.04666" title="Download PostScript">ps</a>, <a href="/format/2401.04666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmark Analysis of Various Pre-trained Deep Learning Models on ASSIRA  Cats and Dogs Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Himel%2C+G+M+S">Galib Muhammad Shahriar Himel</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+M">Md. Masudul Islam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As the most basic application and implementation of deep learning, image
classification has grown in popularity. Various datasets are provided by
renowned data science communities for benchmarking machine learning algorithms
and pre-trained models. The ASSIRA Cats &amp; Dogs dataset is one of them and is
being used in this research for its overall acceptance and benchmark standards.
A comparison of various pre-trained models is demonstrated by using different
types of optimizers and loss functions. Hyper-parameters are changed to gain
the best result from a model. By applying this approach, we have got higher
accuracy without major changes in the training model. To run the experiment, we
used three different computer architectures: a laptop equipped with NVIDIA
GeForce GTX 1070, a laptop equipped with NVIDIA GeForce RTX 3080Ti, and a
desktop equipped with NVIDIA GeForce RTX 3090. The acquired results demonstrate
supremacy in terms of accuracy over the previously done experiments on this
dataset. From this experiment, the highest accuracy which is 99.65% is gained
using the NASNet Large.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04669" title="Abstract">arXiv:2401.04669</a> [<a href="/pdf/2401.04669" title="Download PDF">pdf</a>, <a href="/format/2401.04669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer-Learning-Based Autotuning Using Gaussian Copula
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Randall%2C+T">Thomas Randall</a> (1), 
<a href="/search/cs?searchtype=author&query=Koo%2C+J">Jaehoon Koo</a> (2), 
<a href="/search/cs?searchtype=author&query=Videau%2C+B">Brice Videau</a> (3), 
<a href="/search/cs?searchtype=author&query=Kruse%2C+M">Michael Kruse</a> (3), 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingfu Wu</a> (3), 
<a href="/search/cs?searchtype=author&query=Hovland%2C+P">Paul Hovland</a> (3), 
<a href="/search/cs?searchtype=author&query=Hall%2C+M">Mary Hall</a> (4), 
<a href="/search/cs?searchtype=author&query=Ge%2C+R">Rong Ge</a> (1), 
<a href="/search/cs?searchtype=author&query=Balaprakash%2C+P">Prasanna Balaprakash</a> (5) ((1) Clemson University, (2) Hanyang University, (3) Argonne National Laboratory, (4) University of Utah, (5) Oak Ridge National Laboratory)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, 7 tables, the definitive version of this work is published in the Proceedings of the ACM International Conference on Supercomputing 2023, available at <a href="https://dl.acm.org/doi/10.1145/3577193.3593712">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 37th International Conference on Supercomputing
  (2023) 37-49
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">As diverse high-performance computing (HPC) systems are built, many
opportunities arise for applications to solve larger problems than ever before.
Given the significantly increased complexity of these HPC systems and
application tuning, empirical performance tuning, such as autotuning, has
emerged as a promising approach in recent years. Despite its effectiveness,
autotuning is often a computationally expensive approach. Transfer learning
(TL)-based autotuning seeks to address this issue by leveraging the data from
prior tuning. Current TL methods for autotuning spend significant time modeling
the relationship between parameter configurations and performance, which is
ineffective for few-shot (that is, few empirical evaluations) tuning on new
tasks. We introduce the first generative TL-based autotuning approach based on
the Gaussian copula (GC) to model the high-performing regions of the search
space from prior data and then generate high-performing configurations for new
tasks. This allows a sampling-based approach that maximizes few-shot
performance and provides the first probabilistic estimation of the few-shot
budget for effective TL-based autotuning. We compare our generative TL approach
with state-of-the-art autotuning techniques on several benchmarks. We find that
the GC is capable of achieving 64.37% of peak few-shot performance in its first
evaluation. Furthermore, the GC model can determine a few-shot transfer budget
that yields up to 33.39$\times$ speedup, a dramatic improvement over the
20.58$\times$ speedup using prior techniques.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04670" title="Abstract">arXiv:2401.04670</a> [<a href="/pdf/2401.04670" title="Download PDF">pdf</a>, <a href="/format/2401.04670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modified Levenberg-Marquardt Algorithm For Tensor CP Decomposition in  Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Karim%2C+R+G">Ramin Goudarzi Karim</a>, 
<a href="/search/math?searchtype=author&query=Dulal%2C+D">Dipak Dulal</a>, 
<a href="/search/math?searchtype=author&query=Navasca%2C+C">Carmeliza Navasca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on (DCC 2024) 2024 Data Compression Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper explores a new version of the Levenberg-Marquardt algorithm used
for Tensor Canonical Polyadic (CP) decomposition with an emphasis on image
compression and reconstruction. Tensor computation, especially CP
decomposition, holds significant applications in data compression and analysis.
In this study, we formulate CP as a nonlinear least squares optimization
problem. Then, we present an iterative Levenberg-Marquardt (LM) based algorithm
for computing the CP decomposition. Ultimately, we test the algorithm on
various datasets, including randomly generated tensors and RGB images. The
proposed method proves to be both efficient and effective, offering a reduced
computational burden when compared to the traditional Levenberg-Marquardt
technique.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04675" title="Abstract">arXiv:2401.04675</a> [<a href="/pdf/2401.04675" title="Download PDF">pdf</a>, <a href="/format/2401.04675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Duplication-Free Codes for Disjoint or Equal-Length Errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenjun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+M">Moshe Schwartz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Motivated by applications in DNA storage, we study a setting in which strings
are affected by tandem-duplication errors. In particular, we look at two
settings: disjoint tandem-duplication errors, and equal-length
tandem-duplication errors. We construct codes, with positive asymptotic rate,
for the two settings, as well as for their combination. Our constructions are
duplication-free codes, comprising codewords that do not contain tandem
duplications of specific lengths. Additionally, our codes generalize previous
constructions, containing them as special cases.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04679" title="Abstract">arXiv:2401.04679</a> [<a href="/pdf/2401.04679" title="Download PDF">pdf</a>, <a href="/format/2401.04679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikdan%2C+M">Mahdi Nikdan</a>, 
<a href="/search/cs?searchtype=author&query=Tabesh%2C+S">Soroush Tabesh</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We investigate parameter-efficient fine-tuning (PEFT) methods that can
provide good accuracy under limited computational and memory budgets in the
context of large language models (LLMs). We present a new PEFT method called
Robust Adaptation (RoSA) inspired by robust principal component analysis (PCA)
that jointly trains $\textit{low-rank}$ and $\textit{highly-sparse}$ components
on top of a set of fixed pretrained weights to efficiently approximate the
performance of a full-fine-tuning (FFT) solution. Across a series of
challenging generative tasks such as grade-school math and SQL query
generation, which require fine-tuning for good performance, we show that RoSA
outperforms both LoRA and pure sparse fine-tuning, at the same parameter
budget. We provide system support for RoSA to complement the training
algorithm, specifically in the form of sparse GPU kernels which enable memory-
and computationally-efficient training. Our code will be made available at
https://github.com/IST-DASLab/RoSA}{\texttt{https://github.com/IST-DASLab/RoSA
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04680" title="Abstract">arXiv:2401.04680</a> [<a href="/pdf/2401.04680" title="Download PDF">pdf</a>, <a href="/format/2401.04680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoordGate: Efficiently Computing Spatially-Varying Convolutions in  Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Howard%2C+S">Sunny Howard</a>, 
<a href="/search/cs?searchtype=author&query=Norreys%2C+P">Peter Norreys</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%B6pp%2C+A">Andreas D&#xf6;pp</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Optical imaging systems are inherently limited in their resolution due to the
point spread function (PSF), which applies a static, yet spatially-varying,
convolution to the image. This degradation can be addressed via Convolutional
Neural Networks (CNNs), particularly through deblurring techniques. However,
current solutions face certain limitations in efficiently computing
spatially-varying convolutions. In this paper we propose CoordGate, a novel
lightweight module that uses a multiplicative gate and a coordinate encoding
network to enable efficient computation of spatially-varying convolutions in
CNNs. CoordGate allows for selective amplification or attenuation of filters
based on their spatial position, effectively acting like a locally connected
neural network. The effectiveness of the CoordGate solution is demonstrated
within the context of U-Nets and applied to the challenging problem of image
deblurring. The experimental results show that CoordGate outperforms
conventional approaches, offering a more robust and spatially aware solution
for CNNs in various computer vision applications.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04682" title="Abstract">arXiv:2401.04682</a> [<a href="/pdf/2401.04682" title="Download PDF">pdf</a>, <a href="/format/2401.04682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixture of multilayer stochastic block models for multiview clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Santiago%2C+K">Kylliann De Santiago</a>, 
<a href="/search/cs?searchtype=author&query=Szafranski%2C+M">Marie Szafranski</a>, 
<a href="/search/cs?searchtype=author&query=Ambroise%2C+C">Christophe Ambroise</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this work, we propose an original method for aggregating multiple
clustering coming from different sources of information. Each partition is
encoded by a co-membership matrix between observations. Our approach uses a
mixture of multilayer Stochastic Block Models (SBM) to group co-membership
matrices with similar information into components and to partition observations
into different clusters, taking into account their specificities within the
components. The identifiability of the model parameters is established and a
variational Bayesian EM algorithm is proposed for the estimation of these
parameters. The Bayesian framework allows for selecting an optimal number of
clusters and components. The proposed approach is compared using synthetic data
with consensus clustering and tensor-based algorithms for community detection
in large-scale complex networks. Finally, the method is utilized to analyze
global food trading networks, leading to structures of interest.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04691" title="Abstract">arXiv:2401.04691</a> [<a href="/pdf/2401.04691" title="Download PDF">pdf</a>, <a href="/format/2401.04691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-based Mapping of the Conservation Status of Orchid Assemblages at  Global Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Estopinan%2C+J">Joaquim Estopinan</a>, 
<a href="/search/cs?searchtype=author&query=Servajean%2C+M">Maximilien Servajean</a>, 
<a href="/search/cs?searchtype=author&query=Bonnet%2C+P">Pierre Bonnet</a>, 
<a href="/search/cs?searchtype=author&query=Joly%2C+A">Alexis Joly</a>, 
<a href="/search/cs?searchtype=author&query=Munoz%2C+F">Fran&#xe7;ois Munoz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures. Website URL: <a href="https://mapviewer.plantnet.org/?config=apps/store/orchid-status.xml">this https URL</a> Data and code: <a href="https://figshare.com/s/15404886eb3b62363a5f">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Although increasing threats on biodiversity are now widely recognised, there
are no accurate global maps showing whether and where species assemblages are
at risk. We hereby assess and map at kilometre resolution the conservation
status of the iconic orchid family, and discuss the insights conveyed at
multiple scales. We introduce a new Deep Species Distribution Model trained on
1M occurrences of 14K orchid species to predict their assemblages at global
scale and at kilometre resolution. We propose two main indicators of the
conservation status of the assemblages: (i) the proportion of threatened
species, and (ii) the status of the most threatened species in the assemblage.
We show and analyze the variation of these indicators at World scale and in
relation to currently protected areas in Sumatra island. Global and interactive
maps available online show the indicators of conservation status of orchid
assemblages, with sharp spatial variations at all scales. The highest level of
threat is found at Madagascar and the neighbouring islands. In Sumatra, we
found good correspondence of protected areas with our indicators, but
supplementing current IUCN assessments with status predictions results in
alarming levels of species threat across the island. Recent advances in deep
learning enable reliable mapping of the conservation status of species
assemblages on a global scale. As an umbrella taxon, orchid family provides a
reference for identifying vulnerable ecosystems worldwide, and prioritising
conservation actions both at international and local levels.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04692" title="Abstract">arXiv:2401.04692</a> [<a href="/pdf/2401.04692" title="Download PDF">pdf</a>, <a href="/format/2401.04692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Evaluation of Animated Scatter Plot Transitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+N">Nils Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Dennig%2C+F+L">Frederik L. Dennig</a>, 
<a href="/search/cs?searchtype=author&query=Brandt%2C+V">Vincent Brandt</a>, 
<a href="/search/cs?searchtype=author&query=Keim%2C+D+A">Daniel A. Keim</a>, 
<a href="/search/cs?searchtype=author&query=Weiskopf%2C+D">Daniel Weiskopf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Scatter plots are popular for displaying 2D data, but in practice, many data
sets have more than two dimensions. For the analysis of such multivariate data,
it is often necessary to switch between scatter plots of different dimension
pairs, e.g., in a scatter plot matrix (SPLOM). Alternative approaches include a
"grand tour" for an overview of the entire data set or creating artificial axes
from dimensionality reduction (DR). A cross-cutting concern in all techniques
is the ability of viewers to find correspondence between data points in
different views. Previous work proposed animations to preserve the mental map
between view changes and to trace points as well as clusters between scatter
plots of the same underlying data set. In this paper, we evaluate a variety of
spline- and rotation-based view transitions in a crowdsourced user study
focusing on ecological validity. Using the study results, we assess each
animation's suitability for tracing points and clusters across view changes. We
evaluate whether the order of horizontal and vertical rotation is relevant for
task accuracy. The results show that rotations with an orthographic camera or
staged expansion of a depth axis significantly outperform all other animation
techniques for the traceability of individual points. Further, we provide a
ranking of the animated transition techniques for traceability of individual
points. However, we could not find any significant differences for the
traceability of clusters. Furthermore, we identified differences by animation
direction that could guide further studies to determine potential confounds for
these differences. We publish the study data for reuse and provide the
animation framework as a D3.js plug-in.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04694" title="Abstract">arXiv:2401.04694</a> [<a href="/pdf/2401.04694" title="Download PDF">pdf</a>, <a href="/ps/2401.04694" title="Download PostScript">ps</a>, <a href="/format/2401.04694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling dynamic crack branching in unsaturated porous media through  multi-phase micro-periporomechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pashazad%2C+H">Hossein Pashazad</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+X">Xiaoyu Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Dynamic crack branching in unsaturated porous media holds significant
relevance in various fields, including geotechnical engineering, geosciences,
and petroleum engineering. This article presents a numerical investigation into
dynamic crack branching in unsaturated porous media using a recently developed
coupled micro-periporomechanics paradigm. This paradigm extends the
periporomechanics model by incorporating the micro-rotation of the solid
skeleton. Within this framework, each material point is equipped with three
degrees of freedom: displacement, micro-rotation, and fluid pressure.
Consistent with the Cosserat continuum theory, a length scale associated with
the micro-rotation of material points is inherently integrated into the model.
This study encompasses several key aspects: (1) Validation of the coupled
micro-periporomechanics paradigm for effectively modeling crack branching in
deformable porous media, (2) Examination of the transition from a single branch
to multiple branches in porous media under drained conditions, (3) Simulation
of single crack branching in unsaturated porous media under dynamic loading
conditions, and (4) Investigation of multiple crack branching in unsaturated
porous media under dynamic loading conditions. The numerical results obtained
in this study are systematically analyzed to elucidate the factors that
influence dynamic crack branching in porous media subjected to dynamic loading.
Furthermore, the comprehensive numerical findings underscore the efficacy and
robustness of the coupled micro-periporomechanics paradigm in accurately
modeling dynamic crack branching in variably saturated porous media.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04695" title="Abstract">arXiv:2401.04695</a> [<a href="/pdf/2401.04695" title="Download PDF">pdf</a>, <a href="/format/2401.04695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering  with Multi-Granularity Answers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yona%2C+G">Gal Yona</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+R">Roee Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Geva%2C+M">Mor Geva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Factual questions typically can be answered correctly at different levels of
granularity. For example, both ``August 4, 1961'' and ``1961'' are correct
answers to the question ``When was Barack Obama born?''. Standard question
answering (QA) evaluation protocols, however, do not explicitly take this into
account and compare a predicted answer against answers of a single granularity
level. In this work, we propose GRANOLA QA, a novel evaluation setting where a
predicted answer is evaluated in terms of accuracy and informativeness against
a set of multi-granularity answers. We present a simple methodology for
enriching existing datasets with multi-granularity answers, and create
GRANOLA-EQ, a multi-granularity version of the EntityQuestions dataset. We
evaluate a range of decoding methods on GRANOLA-EQ, including a new algorithm,
called Decoding with Response Aggregation (DRAG), that is geared towards
aligning the response granularity with the model's uncertainty. Our experiments
show that large language models with standard decoding tend to generate
specific answers, which are often incorrect. In contrast, when evaluated on
multi-granularity answers, DRAG yields a nearly 20 point increase in accuracy
on average, which further increases for rare entities. Overall, this reveals
that standard evaluation and decoding schemes may significantly underestimate
the knowledge encapsulated in LMs.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04700" title="Abstract">arXiv:2401.04700</a> [<a href="/pdf/2401.04700" title="Download PDF">pdf</a>, <a href="/format/2401.04700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Editing Can Hurt General Abilities of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jia-Chen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao-Xiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun-Yu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Pan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zhen-Hua Ling</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advances in large language models (LLMs) have opened up new paradigms
for accessing the knowledge stored in their parameters. One critical challenge
that has emerged is the presence of hallucinations in LLM outputs due to false
or outdated knowledge. Since retraining LLMs with updated information is
resource-intensive, there has been a growing interest in model editing.
However, many model editing methods, while effective in various scenarios, tend
to overemphasize aspects such as efficacy, generalization, and locality in
editing performance, often overlooking potential side effects on the general
abilities of LLMs. In this paper, we raise concerns that the improvement of
model factuality may come at the cost of a significant degradation of these
general abilities, which is not conducive to the sustainable development of
LLMs. Systematically, we analyze side effects by evaluating four popular
editing methods on two LLMs across eight representative task categories.
Extensive empirical research reveals that model editing does improve model
factuality but at the expense of substantially impairing general abilities.
Therefore, we advocate for more research efforts to minimize the loss of
general abilities acquired during LLM pre-training and to ultimately preserve
them during model editing.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04701" title="Abstract">arXiv:2401.04701</a> [<a href="/pdf/2401.04701" title="Download PDF">pdf</a>, <a href="/format/2401.04701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiRace: Accurate and Fast Source-Level Race Checking of GPU Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacobson%2C+J">John Jacobson</a>, 
<a href="/search/cs?searchtype=author&query=Burtscher%2C+M">Martin Burtscher</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+G">Ganesh Gopalakrishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Data races are egregious parallel programming bugs on CPUs. They are even
worse on GPUs due to the hierarchical thread and memory structure, which makes
it possible to write code that is correctly synchronized within a thread group
while not being correct across groups. Thus far, all major data-race checkers
for GPUs suffer from at least one of the following problems: they do not check
races in global memory, do not work on recent GPUs, scale poorly, have not been
extensively tested, miss simple data races, or are not dependable without
detailed knowledge of the compiler.
<br />Our new data-race detection tool, HiRace, overcomes these limitations. Its
key novelty is an innovative parallel finite-state machine that condenses an
arbitrarily long access history into a constant-length state, thus allowing it
to handle large and long-running programs. HiRace is a dynamic tool that checks
for thread-group shared memory and global device memory races. It utilizes
source-code instrumentation, thus avoiding driver, compiler, and hardware
dependencies. We evaluate it on a modern calibrated data-race benchmark suite.
On the 580 tested CUDA kernels, 346 of which contain data races, HiRace finds
races missed by other tools without false alarms and is more than 10 times
faster on average than the current state of the art, while incurring only half
the memory overhead.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04705" title="Abstract">arXiv:2401.04705</a> [<a href="/pdf/2401.04705" title="Download PDF">pdf</a>, <a href="/format/2401.04705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EV-EcoSim: A grid-aware co-simulation platform for the design and  optimization of electric vehicle charging infrastructure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Balogun%2C+E">Emmanuel Balogun</a>, 
<a href="/search/eess?searchtype=author&query=Buechler%2C+E">Elizabeth Buechler</a>, 
<a href="/search/eess?searchtype=author&query=Bhela%2C+S">Siddharth Bhela</a>, 
<a href="/search/eess?searchtype=author&query=Onori%2C+S">Simona Onori</a>, 
<a href="/search/eess?searchtype=author&query=Rajagopal%2C+R">Ram Rajagopal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication at the IEEE Transactions on Smart Grid
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Multiagent Systems (cs.MA); Mathematical Software (cs.MS); Software Engineering (cs.SE); Optimization and Control (math.OC)

</div>
<p class="mathjax">To enable the electrification of transportation systems, it is important to
understand how technologies such as grid storage, solar photovoltaic systems,
and control strategies can aid the deployment of electric vehicle charging at
scale. In this work, we present EV-EcoSim, a co-simulation platform that
couples electric vehicle charging, battery systems, solar photovoltaic systems,
grid transformers, control strategies, and power distribution systems, to
perform cost quantification and analyze the impacts of electric vehicle
charging on the grid. This python-based platform can run a receding horizon
control scheme for real-time operation and a one-shot control scheme for
planning problems, with multi-timescale dynamics for different systems to
simulate realistic scenarios. We demonstrate the utility of EV-EcoSim through a
case study focused on economic evaluation of battery size to reduce electricity
costs while considering impacts of fast charging on the power distribution
grid. We present qualitative and quantitative evaluations on the battery size
in tabulated results. The tabulated results delineate the trade-offs between
candidate battery sizing solutions, providing comprehensive insights for
decision-making under uncertainty. Additionally, we demonstrate the
implications of the battery controller model fidelity on the system costs and
show that the fidelity of the battery controller can completely change
decisions made when planning an electric vehicle charging site.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04707" title="Abstract">arXiv:2401.04707</a> [<a href="/pdf/2401.04707" title="Download PDF">pdf</a>, <a href="/format/2401.04707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RNA-TransCrypt: Image Encryption Using Chaotic RNA Encoding, Novel  Transformative Substitution, and Tailored Cryptographic Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+S">Muhammad Shahbaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+J">Jawad Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Al-Dubai%2C+A">Ahmed Al-Dubai</a>, 
<a href="/search/cs?searchtype=author&query=Ghaleb%2C+B">Baraq Ghaleb</a>, 
<a href="/search/cs?searchtype=author&query=Pitropakis%2C+N">Nikolaos Pitropakis</a>, 
<a href="/search/cs?searchtype=author&query=Buchanan%2C+W+J">William J. Buchanan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Given the security concerns of Internet of Things (IoT) networks and limited
computational resources of IoT devices, this paper presents RNA-TransCrypt, a
novel image encryption scheme that is not only highly secure but also efficient
and lightweight. RNA-TransCrypt integrates the biocryptographic properties of
RNA encoding with the non-linearity and unpredictability of chaos theory. This
scheme introduces three novel contributions: 1) the two-base RNA encoding
method, which transforms the image into RNA strands-like sequence, ensuring
efficient scrambling; 2) the transformative substitution technique, which
transforms the s-box values before replacing the pixel values, and is
responsible for making the scheme lightweight; and 3) three mathematical
cryptographic operations designed especially for image encryption that ensure
the effective transformation of the s-box values, resulting in a new outcome
even for the same input values. These modules are key-dependent, utilizing
chaotic keys generated by the De Jong Fractal Map and the Van der Pol
Oscillator. Extensive security analysis, including histogram analysis,
correlation analysis, and the results of the statistical security parameters
obtained from the Gray-Level Co-occurrence Matrix (GLCM) validate the efficacy
of the proposed scheme in encrypting input images with close-to-ideal results
of 7.997 entropy and 0.0006 correlation.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04714" title="Abstract">arXiv:2401.04714</a> [<a href="/pdf/2401.04714" title="Download PDF">pdf</a>, <a href="/format/2401.04714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bin Packing under Random-Order: Breaking the Barrier of 3/2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hebbar%2C+A">Anish Hebbar</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Arindam Khan</a>, 
<a href="/search/cs?searchtype=author&query=Sreenivas%2C+K+V+N">K. V. N. Sreenivas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Best-Fit is one of the most prominent and practically used algorithms for the
bin packing problem, where a set of items with associated sizes needs to be
packed in the minimum number of unit-capacity bins. Kenyon [SODA '96] studied
online bin packing under random-order arrival, where the adversary chooses the
list of items, but the items arrive one by one according to an arrival order
drawn uniformly randomly from the set of all permutations of the items.
Kenyon's seminal result established an upper bound of $1.5$ and a lower bound
of $1.08$ on the random-order ratio of Best-Fit, and it was conjectured that
the true ratio is $\approx 1.15$. The conjecture, if true, will also imply that
Best-Fit (on randomly permuted input) has the best performance guarantee among
all the widely-used simple algorithms for (offline) bin packing. This
conjecture has remained one of the major open problems in the area, as
highlighted in the recent survey on random-order models by Gupta and Singla
[Beyond the Worst-Case Analysis of Algorithms '20]. Recently, Albers et al.
[Algorithmica '21] improved the upper bound to $1.25$ for the special case when
all the item sizes are greater than $1/3$, and they improve the lower bound to
$1.1$. Ayyadevara et al. [ICALP '22] obtained an improved result for the
special case when all the item sizes lie in $(1/4, 1/2]$, which corresponds to
the $3$-partition problem. The upper bound of $3/2$ for the general case,
however, has remained unimproved.
<br />In this paper, we make the first progress towards the conjecture, by showing
that Best-Fit achieves a random-order ratio of at most $1.5 - \varepsilon$, for
a small constant $\varepsilon&gt;0$. Furthermore, we establish an improved lower
bound of $1.144$ on the random-order ratio of Best-Fit, nearly reaching the
conjectured ratio.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04716" title="Abstract">arXiv:2401.04716</a> [<a href="/pdf/2401.04716" title="Download PDF">pdf</a>, <a href="/format/2401.04716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Resource Vision Challenges for Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunhua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Doughty%2C+H">Hazel Doughty</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G.M. Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Low-resource settings are well-established in natural language processing,
where many languages lack sufficient data for machine learning at scale.
However, low-resource problems are under-explored in computer vision. In this
paper, we strive to address this gap and explore the challenges of low-resource
image tasks with vision foundation models. Thus, we first collect a benchmark
of genuinely low-resource image data, covering historic maps, circuit diagrams,
and mechanical drawings. These low-resource settings all share the three
challenges of data scarcity, fine-grained differences, and the distribution
shift from natural images to the specialized domain of interest. While existing
foundation models have shown impressive generalizability, we find they cannot
transfer well to our low-resource tasks. To begin to tackle the challenges of
low-resource vision, we introduce one simple baseline per challenge.
Specifically, we propose to i) enlarge the data space by generative models, ii)
adopt the best sub-kernels to encode local regions for fine-grained difference
discovery and iii) learn attention for specialized domains. Experiments on the
three low-resource data sources in our benchmark demonstrate our proposals
already provide a better baseline than common transfer learning, data
augmentation, and fine-grained methods. This highlights the unique
characteristics and challenges of low-resource vision for foundation models
that warrant further investigation. Project website:
https://xiaobai1217.github.io/Low-Resource-Vision/.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04718" title="Abstract">arXiv:2401.04718</a> [<a href="/pdf/2401.04718" title="Download PDF">pdf</a>, <a href="/format/2401.04718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jump Cut Smoothing for Talking Heads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaojuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+T">Taesung Park</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shechtman%2C+E">Eli Shechtman</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richard Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://morphcut.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A jump cut offers an abrupt, sometimes unwanted change in the viewing
experience. We present a novel framework for smoothing these jump cuts, in the
context of talking head videos. We leverage the appearance of the subject from
the other source frames in the video, fusing it with a mid-level representation
driven by DensePose keypoints and face landmarks. To achieve motion, we
interpolate the keypoints and landmarks between the end frames around the cut.
We then use an image translation network from the keypoints and source frames,
to synthesize pixels. Because keypoints can contain errors, we propose a
cross-modal attention scheme to select and pick the most appropriate source
amongst multiple options for each key point. By leveraging this mid-level
representation, our method can achieve stronger results than a strong video
interpolation baseline. We demonstrate our method on various jump cuts in the
talking head videos, such as cutting filler words, pauses, and even random
cuts. Our experiments show that we can achieve seamless transitions, even in
the challenging cases where the talking head rotates or moves drastically in
the jump cut.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04720" title="Abstract">arXiv:2401.04720</a> [<a href="/pdf/2401.04720" title="Download PDF">pdf</a>, <a href="/format/2401.04720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-resource finetuning of foundation models beats state-of-the-art in  histopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roth%2C+B">Benedikt Roth</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+V">Valentin Koch</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+S+J">Sophia J. Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Schnabel%2C+J+A">Julia A. Schnabel</a>, 
<a href="/search/cs?searchtype=author&query=Marr%2C+C">Carsten Marr</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+T">Tingying Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To handle the large scale of whole slide images in computational pathology,
most approaches first tessellate the images into smaller patches, extract
features from these patches, and finally aggregate the feature vectors with
weakly-supervised learning. The performance of this workflow strongly depends
on the quality of the extracted features. Recently, foundation models in
computer vision showed that leveraging huge amounts of data through supervised
or self-supervised learning improves feature quality and generalizability for a
variety of tasks. In this study, we benchmark the most popular vision
foundation models as feature extractors for histopathology data. We evaluate
the models in two settings: slide-level classification and patch-level
classification. We show that foundation models are a strong baseline. Our
experiments demonstrate that by finetuning a foundation model on a single GPU
for only two hours or three days depending on the dataset, we can match or
outperform state-of-the-art feature extractors for computational pathology.
These findings imply that even with little resources one can finetune a feature
extractor tailored towards a specific downstream task and dataset. This is a
considerable shift from the current state, where only few institutions with
large amounts of resources and datasets are able to train a feature extractor.
We publish all code used for training and evaluation as well as the finetuned
models.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04727" title="Abstract">arXiv:2401.04727</a> [<a href="/pdf/2401.04727" title="Download PDF">pdf</a>, <a href="/format/2401.04727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Adversarial Training at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongru Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> tech report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The machine learning community has witnessed a drastic change in the training
pipeline, pivoted by those ''foundation models'' with unprecedented scales.
However, the field of adversarial training is lagging behind, predominantly
centered around small model sizes like ResNet-50, and tiny and low-resolution
datasets like CIFAR-10. To bridge this transformation gap, this paper provides
a modern re-examination with adversarial training, investigating its potential
benefits when applied at scale. Additionally, we introduce an efficient and
effective training strategy to enable adversarial training with giant models
and web-scale data at an affordable computing cost. We denote this newly
introduced framework as AdvXL.
<br />Empirical results demonstrate that AdvXL establishes new state-of-the-art
robust accuracy records under AutoAttack on ImageNet-1K. For example, by
training on DataComp-1B dataset, our AdvXL empowers a vanilla ViT-g model to
substantially surpass the previous records of $l_{\infty}$-, $l_{2}$-, and
$l_{1}$-robust accuracy by margins of 11.4%, 14.2% and 12.9%, respectively.
This achievement posits AdvXL as a pioneering approach, charting a new
trajectory for the efficient training of robust visual representations at
significantly larger scales. Our code is available at
https://github.com/UCSC-VLAA/AdvXL.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04728" title="Abstract">arXiv:2401.04728</a> [<a href="/pdf/2401.04728" title="Download PDF">pdf</a>, <a href="/format/2401.04728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar  Creation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mihajlovic%2C+M">Marko Mihajlovic</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaofei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Prokudin%2C+S">Sergey Prokudin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siyu Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://xiyichen.github.io/morphablediffusion/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advances in generative diffusion models have enabled the previously
unfeasible capability of generating 3D assets from a single input image or a
text prompt. In this work, we aim to enhance the quality and functionality of
these models for the task of creating controllable, photorealistic human
avatars. We achieve this by integrating a 3D morphable model into the
state-of-the-art multiview-consistent diffusion approach. We demonstrate that
accurate conditioning of a generative pipeline on the articulated 3D model
enhances the baseline model performance on the task of novel view synthesis
from a single image. More importantly, this integration facilitates a seamless
and accurate incorporation of facial expression and body pose control into the
generation process. To the best of our knowledge, our proposed framework is the
first diffusion model to enable the creation of fully 3D-consistent,
animatable, and photorealistic human avatars from a single image of an unseen
subject; extensive quantitative and qualitative evaluations demonstrate the
advantages of our approach over existing state-of-the-art avatar creation
models on both novel view and novel expression synthesis tasks.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04729" title="Abstract">arXiv:2401.04729</a> [<a href="/pdf/2401.04729" title="Download PDF">pdf</a>, <a href="/format/2401.04729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effect of Contextual Information on Human Delegation Behavior in  Human-AI collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spitzer%2C+P">Philipp Spitzer</a>, 
<a href="/search/cs?searchtype=author&query=Holstein%2C+J">Joshua Holstein</a>, 
<a href="/search/cs?searchtype=author&query=Hemmer%2C+P">Patrick Hemmer</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%B6ssing%2C+M">Michael V&#xf6;ssing</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChl%2C+N">Niklas K&#xfc;hl</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+D">Dominik Martin</a>, 
<a href="/search/cs?searchtype=author&query=Satzger%2C+G">Gerhard Satzger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The constantly increasing capabilities of artificial intelligence (AI) open
new possibilities for human-AI collaboration. One promising approach to
leverage existing complementary capabilities is allowing humans to delegate
individual instances to the AI. However, enabling humans to delegate instances
effectively requires them to assess both their own and the AI's capabilities in
the context of the given task. In this work, we explore the effects of
providing contextual information on human decisions to delegate instances to an
AI. We find that providing participants with contextual information
significantly improves the human-AI team performance. Additionally, we show
that the delegation behavior changes significantly when participants receive
varying types of contextual information. Overall, this research advances the
understanding of human-AI interaction in human delegation and provides
actionable insights for designing more effective collaborative systems.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04730" title="Abstract">arXiv:2401.04730</a> [<a href="/pdf/2401.04730" title="Download PDF">pdf</a>, <a href="/format/2401.04730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Baseline for Spoken Language to Sign Language Translation with  3D Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+R">Ronglai Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fangyun Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zenggui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mak%2C+B">Brian Mak</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaolong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The objective of this paper is to develop a functional system for translating
spoken languages into sign languages, referred to as Spoken2Sign translation.
The Spoken2Sign task is orthogonal and complementary to traditional sign
language to spoken language (Sign2Spoken) translation. To enable Spoken2Sign
translation, we present a simple baseline consisting of three steps: 1)
creating a gloss-video dictionary using existing Sign2Spoken benchmarks; 2)
estimating a 3D sign for each sign video in the dictionary; 3) training a
Spoken2Sign model, which is composed of a Text2Gloss translator, a sign
connector, and a rendering module, with the aid of the yielded gloss-3D sign
dictionary. The translation results are then displayed through a sign avatar.
As far as we know, we are the first to present the Spoken2Sign task in an
output format of 3D signs. In addition to its capability of Spoken2Sign
translation, we also demonstrate that two by-products of our approach-3D
keypoint augmentation and multi-view understanding-can assist in keypoint-based
sign language understanding. Code and models will be available at
https://github.com/FangyunWei/SLRT
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed, 10 Jan 24</h3>
<dl>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03791" title="Abstract">arXiv:2312.03791</a> (cross-list from quant-ph) [<a href="/pdf/2312.03791" title="Download PDF">pdf</a>, <a href="/format/2312.03791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Quantum Computational Mechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+B">Burigede Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ortiz%2C+M">Michael Ortiz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cirak%2C+F">Fehmi Cirak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">The advent of quantum computers, operating on entirely different physical
principles and abstractions from those of classical digital computers, sets
forth a new computing paradigm that can potentially result in game-changing
efficiencies and computational performance. Specifically, the ability to
simultaneously evolve the state of an entire quantum system leads to quantum
parallelism and interference. Despite these prospects, opportunities to bring
quantum computing to bear on problems of computational mechanics remain largely
unexplored. In this work, we demonstrate how quantum computing can indeed be
used to solve representative volume element (RVE) problems in computational
homogenisation with polylogarithmic complexity of~$ \mathcal{O}((\log N)^c)$,
compared to~$\mathcal{O}(N^c)$ in classical computing. Thus, our quantum RVE
solver attains exponential acceleration with respect to classical solvers,
bringing concurrent multiscale computing closer to practicality. The proposed
quantum RVE solver combines conventional algorithms such as a fixed-point
iteration for a homogeneous reference material and the Fast Fourier Transform
(FFT). However, the quantum computing reformulation of these algorithms
requires a fundamental paradigm shift and a complete rethinking and overhaul of
the classical implementation. We employ or develop several techniques,
including the Quantum Fourier Transform (QFT), quantum encoding of polynomials,
classical piecewise Chebyshev approximation of functions and an auxiliary
algorithm for implementing the fixed-point iteration and show that, indeed, an
efficient implementation of RVE solvers on quantum computers is possible. We
additionally provide theoretical proofs and numerical evidence confirming the
anticipated~$ \mathcal{O} \left ((\log N)^c \right) $ complexity of the
proposed solver.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14848" title="Abstract">arXiv:2312.14848</a> (cross-list from astro-ph.HE) [<a href="/pdf/2312.14848" title="Download PDF">pdf</a>, <a href="/format/2312.14848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Isolated pulsar population synthesis with simulation-based inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Graber%2C+V">Vanessa Graber</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ronchi%2C+M">Michele Ronchi</a>, 
<a href="/search/astro-ph?searchtype=author&query=Pardo-Araujo%2C+C">Celsa Pardo-Araujo</a>, 
<a href="/search/astro-ph?searchtype=author&query=Rea%2C+N">Nanda Rea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 14 figures, 5 tables, 2 appendices, comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Astrophysical Phenomena (astro-ph.HE)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We combine pulsar population synthesis with simulation-based inference to
constrain the magneto-rotational properties of isolated Galactic radio pulsars.
We first develop a flexible framework to model neutron-star birth properties
and evolution, focusing on their dynamical, rotational and magnetic
characteristics. In particular, we sample initial magnetic-field strengths,
$B$, and spin periods, $P$, from log-normal distributions and capture the
late-time magnetic-field decay with a power law. Each log-normal is described
by a mean, $\mu_{\log B}, \mu_{\log P}$, and standard deviation, $\sigma_{\log
B}, \sigma_{\log P}$, while the power law is characterized by the index,
$a_{\rm late}$, resulting in five free parameters. We subsequently model the
stars' radio emission and observational biases to mimic detections with three
radio surveys, and produce a large database of synthetic $P$-$\dot{P}$ diagrams
by varying our input parameters. We then follow a simulation-based inference
approach that focuses on neural posterior estimation and employ this database
to train deep neural networks to directly infer the posterior distributions of
the five model parameters. After successfully validating these individual
neural density estimators on simulated data, we use an ensemble of networks to
infer the posterior distributions for the observed pulsar population. We obtain
$\mu_{\log B} = 13.10^{+0.08}_{-0.10}$, $\sigma_{\log B} =
0.45^{+0.05}_{-0.05}$ and $\mu_{\log P} = -1.00^{+0.26}_{-0.21}$, $\sigma_{\log
P} = 0.38^{+0.33}_{-0.18}$ for the log-normal distributions, and $a_{\rm late}
= -1.80^{+0.65}_{-0.61}$ for the power law at $95\%$ credible interval. Our
approach represents a crucial step towards robust statistical inference for
complex population-synthesis frameworks and forms the basis for future
multi-wavelength analyses of Galactic pulsars.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04125" title="Abstract">arXiv:2401.04125</a> (cross-list from physics.ao-ph) [<a href="/pdf/2401.04125" title="Download PDF">pdf</a>, <a href="/format/2401.04125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepPhysiNet: Bridging Deep Learning and Atmospheric Physics for  Accurate and Continuous Weather Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Li%2C+W">Wenyuan Li</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+Z">Zili Liu</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+K">Keyan Chen</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/physics?searchtype=author&query=Liang%2C+S">Shunlin Liang</a>, 
<a href="/search/physics?searchtype=author&query=Zou%2C+Z">Zhengxia Zou</a>, 
<a href="/search/physics?searchtype=author&query=Shi%2C+Z">Zhenwei Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate weather forecasting holds significant importance to human
activities. Currently, there are two paradigms for weather forecasting:
Numerical Weather Prediction (NWP) and Deep Learning-based Prediction (DLP).
NWP utilizes atmospheric physics for weather modeling but suffers from poor
data utilization and high computational costs, while DLP can learn weather
patterns from vast amounts of data directly but struggles to incorporate
physical laws. Both paradigms possess their respective strengths and
weaknesses, and are incompatible, because physical laws adopted in NWP describe
the relationship between coordinates and meteorological variables, while DLP
directly learns the relationships between meteorological variables without
consideration of coordinates. To address these problems, we introduce the
DeepPhysiNet framework, incorporating physical laws into deep learning models
for accurate and continuous weather system modeling. First, we construct
physics networks based on multilayer perceptrons (MLPs) for individual
meteorological variable, such as temperature, pressure, and wind speed. Physics
networks establish relationships between variables and coordinates by taking
coordinates as input and producing variable values as output. The physical laws
in the form of Partial Differential Equations (PDEs) can be incorporated as a
part of loss function. Next, we construct hyper-networks based on deep learning
methods to directly learn weather patterns from a large amount of
meteorological data. The output of hyper-networks constitutes a part of the
weights for the physics networks. Experimental results demonstrate that, upon
successful integration of physical laws, DeepPhysiNet can accomplish multiple
tasks simultaneously, not only enhancing forecast accuracy but also obtaining
continuous spatiotemporal resolution results, which is unattainable by either
the NWP or DLP.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04127" title="Abstract">arXiv:2401.04127</a> (cross-list from eess.AS) [<a href="/pdf/2401.04127" title="Download PDF">pdf</a>, <a href="/format/2401.04127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using perceptive subbands analysis to perform audio scenes cartography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Millot%2C+L">Laurent Millot</a> (IDEAC), 
<a href="/search/eess?searchtype=author&query=Pel%C3%A9%2C+G">G&#xe9;rard Pel&#xe9;</a> (IDEAC), 
<a href="/search/eess?searchtype=author&query=Elliq%2C+M">Mohammed Elliq</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 118th Convention of the Audio Engineering Society, Audio
  Engineering Society, May 2005, Barcelone (Espagne), Spain
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP); Classical Physics (physics.class-ph)

</div>
<p class="mathjax">Audio scene cartography for real or simulated stereo recordings is presented.
This audio scene analysis is performed doing successively: a perceptive
10-subbands analysis, calculation of temporal laws for relative delays and
gains between both channels of each subband using a short-time cons\-tant scene
assumption and channels inter-correlation which permit to follow a mobile
source in its moves, calculation of global and subbands histograms whose peaks
give the incidence information for fixed sources. Audio scenes composed of 2 to
4 fixed sources or with a fixed source and a mobile one have been already
successfully tested. Further extensions and applications will be discussed.
Audio illustrations of audio scenes, subband analysis and demonstration of
real-time stereo recording simulations will be given.Paper 6340 presented at
the 118th Convention of the Audio Engineering Society, Barcelona, 2005
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04153" title="Abstract">arXiv:2401.04153</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2401.04153" title="Download PDF">pdf</a>, <a href="/format/2401.04153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FTLE for Flow Ensembles by Optimal Domain Displacement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zimmermann%2C+J">Janos Zimmermann</a>, 
<a href="/search/physics?searchtype=author&query=Motejat%2C+M">Michael Motejat</a>, 
<a href="/search/physics?searchtype=author&query=R%C3%B6ssl%2C+C">Christian R&#xf6;ssl</a>, 
<a href="/search/physics?searchtype=author&query=Theisel%2C+H">Holger Theisel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">FTLE (Finite Time Lyapunov Exponent) computation is one of the standard
approaches to Lagrangian flow analysis. The main features of interest in FTLE
fields are ridges that represent hyperbolic Lagrangian Coherent Structures.
FTLE ridges tend to become sharp and crisp with increasing integration time,
where the sharpness of the ridges is an indicator of the strength of
separation. The additional consideration of uncertainty in flows leads to more
blurred ridges in the FTLE fields. There are multiple causes for such blurred
ridges: either the locations of the ridges are uncertain, or the strength of
the ridges is uncertain, or there is low uncertainty but weak separation.
Existing approaches for uncertain FTLE computation are unable to distinguish
these different sources of uncertainty in the ridges. We introduce a new
approach to define and visualize FTLE fields for flow ensembles. Before
computing and comparing FTLE fields for the ensemble members, we compute
optimal displacements of the domains to mutually align the ridges of the
ensemble members as much as possible. We do so in a way that an explicit
geometry extraction and alignment of the ridges is not necessary. The
additional consideration of these displacements allows for a visual distinction
between uncertainty in ridge location, ridge sharpness, and separation
strength. We apply the approach to several synthetic and real ensemble data
sets.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04155" title="Abstract">arXiv:2401.04155</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.04155" title="Download PDF">pdf</a>, <a href="/ps/2401.04155" title="Download PostScript">ps</a>, <a href="/format/2401.04155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large language models in bioinformatics: applications and perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+J">Jiajia Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+M">Mengyuan Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Yu%2C+Y">Yankai Yu</a>, 
<a href="/search/q-bio?searchtype=author&query=Xu%2C+H">Haixia Xu</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+K">Kang Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+X">Xiaobo Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) are a class of artificial intelligence models
based on deep learning, which have great performance in various tasks,
especially in natural language processing (NLP). Large language models
typically consist of artificial neural networks with numerous parameters,
trained on large amounts of unlabeled input using self-supervised or
semi-supervised learning. However, their potential for solving bioinformatics
problems may even exceed their proficiency in modeling human language. In this
review, we will present a summary of the prominent large language models used
in natural language processing, such as BERT and GPT, and focus on exploring
the applications of large language models at different omics levels in
bioinformatics, mainly including applications of large language models in
genomics, transcriptomics, proteomics, drug discovery and single cell analysis.
Finally, this review summarizes the potential and prospects of large language
models in solving bioinformatic problems.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04168" title="Abstract">arXiv:2401.04168</a> (cross-list from astro-ph.EP) [<a href="/pdf/2401.04168" title="Download PDF">pdf</a>, <a href="/format/2401.04168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlopPITy: Enabling self-consistent exoplanet atmospheric retrievals with  machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Mart%C3%ADnez%2C+F+A">Francisco Ard&#xe9;vol Mart&#xed;nez</a>, 
<a href="/search/astro-ph?searchtype=author&query=Min%2C+M">Michiel Min</a>, 
<a href="/search/astro-ph?searchtype=author&query=Huppenkothen%2C+D">Daniela Huppenkothen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kamp%2C+I">Inga Kamp</a>, 
<a href="/search/astro-ph?searchtype=author&query=Palmer%2C+P+I">Paul I. Palmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at A&amp;A
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Interpreting the observations of exoplanet atmospheres to constrain physical
and chemical properties is typically done using Bayesian retrieval techniques.
Because these methods require many model computations, a compromise is made
between model complexity and run time. Reaching this compromise leads to the
simplification of many physical and chemical processes (e.g. parameterised
temperature structure). Here we implement and test sequential neural posterior
estimation (SNPE), a machine learning inference algorithm, for exoplanet
atmospheric retrievals. The goal is to speed up retrievals so they can be run
with more computationally expensive atmospheric models, such as those computing
the temperature structure using radiative transfer. We generate 100 synthetic
observations using ARCiS (ARtful Modeling Code for exoplanet Science, an
atmospheric modelling code with the flexibility to compute models in varying
degrees of complexity) and perform retrievals on them to test the faithfulness
of the SNPE posteriors. The faithfulness quantifies whether the posteriors
contain the ground truth as often as we expect. We also generate a synthetic
observation of a cool brown dwarf using the self-consistent capabilities of
ARCiS and run a retrieval with self-consistent models to showcase the
possibilities that SNPE opens. We find that SNPE provides faithful posteriors
and is therefore a reliable tool for exoplanet atmospheric retrievals. We are
able to run a self-consistent retrieval of a synthetic brown dwarf spectrum
using only 50,000 forward model evaluations. We find that SNPE can speed up
retrievals between $\sim2\times$ and $\geq10\times$ depending on the
computational load of the forward model, the dimensionality of the observation,
and the signal-to-noise ratio of the observation. We make the code publicly
available for the community on Github.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04190" title="Abstract">arXiv:2401.04190</a> (cross-list from astro-ph.CO) [<a href="/pdf/2401.04190" title="Download PDF">pdf</a>, <a href="/ps/2401.04190" title="Download PostScript">ps</a>, <a href="/format/2401.04190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is it possible to know cosmological fine-tuning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=D%C3%ADaz-Pach%C3%B3n%2C+D+A">Daniel Andr&#xe9;s D&#xed;az-Pach&#xf3;n</a>, 
<a href="/search/astro-ph?searchtype=author&query=H%C3%B6ssjer%2C+O">Ola H&#xf6;ssjer</a>, 
<a href="/search/astro-ph?searchtype=author&query=Mathew%2C+C">Calvin Mathew</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Information Theory (cs.IT); Methodology (stat.ME)

</div>
<p class="mathjax">Fine-tuning studies whether some physical parameters, or relevant ratios
between them, are located within so-called life-permitting intervals of small
probability outside of which carbon-based life would not be possible. Recent
developments have found estimates of these probabilities that circumvent
previous concerns of measurability and selection bias. However, the question
remains if fine-tuning can indeed be known. Using a mathematization of the
epistemological concepts of learning and knowledge acquisition, we argue that
most examples that have been touted as fine-tuned cannot be formally assessed
as such. Nevertheless, fine-tuning can be known when the physical parameter is
seen as a random variable and it is supported in the nonnegative real line,
provided the size of the life-permitting interval is small in relation to the
observed value of the parameter.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04191" title="Abstract">arXiv:2401.04191</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2401.04191" title="Download PDF">pdf</a>, <a href="/format/2401.04191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Hopfield Networks in the Teacher-Student Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Th%C3%A9riault%2C+R">Robin Th&#xe9;riault</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tantari%2C+D">Daniele Tantari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Machine Learning (cs.LG); Mathematical Physics (math-ph)

</div>
<p class="mathjax">Dense Hopfield networks are known for their feature to prototype transition
and adversarial robustness. However, previous theoretical studies have been
mostly concerned with their storage capacity. We bridge this gap by studying
the phase diagram of p-body Hopfield networks in the teacher-student setting of
an unsupervised learning problem, uncovering ferromagnetic phases reminiscent
of the prototype and feature learning regimes. On the Nishimori line, we find
the critical size of the training set necessary for efficient pattern
retrieval. Interestingly, we find that that the paramagnetic to ferromagnetic
transition of the teacher-student setting coincides with the paramagnetic to
spin-glass transition of the direct model, i.e. with random patterns. Outside
of the Nishimori line, we investigate the learning performance in relation to
the inference temperature and dataset noise. Moreover, we show that using a
larger p for the student than the teacher gives the student an extensive
tolerance to noise. We then derive a closed-form expression measuring the
adversarial robustness of such a student at zero temperature, corroborating the
positive correlation between number of parameters and robustness observed in
large neural networks. We also use our model to clarify why the prototype phase
of modern Hopfield networks is adversarially robust.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04212" title="Abstract">arXiv:2401.04212</a> (cross-list from physics.space-ph) [<a href="/pdf/2401.04212" title="Download PDF">pdf</a>, <a href="/format/2401.04212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Machine Learning-Based Approach to Predict Space Object  Density Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Rodriguez-Fernandez%2C+V">Victor Rodriguez-Fernandez</a>, 
<a href="/search/physics?searchtype=author&query=Sarangerel%2C+S">Sumiyajav Sarangerel</a>, 
<a href="/search/physics?searchtype=author&query=Siew%2C+P+M">Peng Mun Siew</a>, 
<a href="/search/physics?searchtype=author&query=Machuca%2C+P">Pablo Machuca</a>, 
<a href="/search/physics?searchtype=author&query=Jang%2C+D">Daniel Jang</a>, 
<a href="/search/physics?searchtype=author&query=Linares%2C+R">Richard Linares</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 AIAA SciTech Forum, 8-12 January 2024, Orlando, FL, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Space Physics (physics.space-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With the rapid increase in the number of Anthropogenic Space Objects (ASOs),
Low Earth Orbit (LEO) is facing significant congestion, thereby posing
challenges to space operators and risking the viability of the space
environment for varied uses. Current models for examining this evolution, while
detailed, are computationally demanding. To address these issues, we propose a
novel machine learning-based model, as an extension of the MIT Orbital Capacity
Tool (MOCAT). This advanced model is designed to accelerate the propagation of
ASO density distributions, and it is trained on hundreds of simulations
generated by an established and accurate model of the space environment
evolution. We study how different deep learning-based solutions can potentially
be good candidates for ASO propagation and manage the high-dimensionality of
the data. To assess the model's capabilities, we conduct experiments in long
term forecasting scenarios (around 100 years), analyze how and why the
performance degrades over time, and discuss potential solutions to make this
solution better.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04232" title="Abstract">arXiv:2401.04232</a> (cross-list from eess.SP) [<a href="/pdf/2401.04232" title="Download PDF">pdf</a>, <a href="/format/2401.04232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating an Executive Summary of a Time Series: The Tendency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alves%2C+C">Caio Alves</a>, 
<a href="/search/eess?searchtype=author&query=Restrepo%2C+J+M">Juan M. Restrepo</a>, 
<a href="/search/eess?searchtype=author&query=Ramirez%2C+J+M">Jorge M. Ramirez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this paper we revisit the problem of decomposing a signal into a tendency
and a residual. The tendency describes an executive summary of a signal that
encapsulates its notable characteristics while disregarding seemingly random,
less interesting aspects. Building upon the Intrinsic Time Decomposition (ITD)
and information-theoretical analysis, we introduce two alternative procedures
for selecting the tendency from the ITD baselines. The first is based on the
maximum extrema prominence, namely the maximum difference between extrema
within each baseline. Specifically this method selects the tendency as the
baseline from which an ITD step would produce the largest decline of the
maximum prominence. The second method uses the rotations from the ITD and
selects the tendency as the last baseline for which the associated rotation is
statistically stationary. We delve into a comparative analysis of the
information content and interpretability of the tendencies obtained by our
proposed methods and those obtained through conventional low-pass filtering
schemes, particularly the Hodrik-Prescott (HP) filter. Our findings underscore
a fundamental distinction in the nature and interpretability of these
tendencies, highlighting their context-dependent utility with emphasis in
multi-scale signals. Through a series of real-world applications, we
demonstrate the computational robustness and practical utility of our proposed
tendencies, emphasizing their adaptability and relevance in diverse time series
contexts.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04237" title="Abstract">arXiv:2401.04237</a> (cross-list from math.OC) [<a href="/pdf/2401.04237" title="Download PDF">pdf</a>, <a href="/ps/2401.04237" title="Download PostScript">ps</a>, <a href="/format/2401.04237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A learning-based mathematical programming formulation for the automatic  configuration of optimization solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Iommazzo%2C+G">Gabriele Iommazzo</a>, 
<a href="/search/math?searchtype=author&query=D%27Ambrosio%2C+C">Claudia D&#x27;Ambrosio</a>, 
<a href="/search/math?searchtype=author&query=Frangioni%2C+A">Antonio Frangioni</a>, 
<a href="/search/math?searchtype=author&query=Liberti%2C+L">Leo Liberti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a methodology, based on machine learning and optimization, for
selecting a solver configuration for a given instance. First, we employ a set
of solved instances and configurations in order to learn a performance function
of the solver. Secondly, we formulate a mixed-integer nonlinear program where
the objective/constraints explicitly encode the learnt information, and which
we solve, upon the arrival of an unknown instance, to find the best solver
configuration for that instance, based on the performance function. The main
novelty of our approach lies in the fact that the configuration set search
problem is formulated as a mathematical program, which allows us to a) enforce
hard dependence and compatibility constraints on the configurations, and b)
solve it efficiently with off-the-shelf optimization tools.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04242" title="Abstract">arXiv:2401.04242</a> (cross-list from math.CT) [<a href="/pdf/2401.04242" title="Download PDF">pdf</a>, <a href="/ps/2401.04242" title="Download PostScript">ps</a>, <a href="/format/2401.04242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automata and coalgebras in categories of species
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Loregian%2C+F">Fosco Loregian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Hom. Il. 18.371-376
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We study generalized automata (in the sense of Ad\'amek-Trnkov\'a) in Joyal's
category of (set-valued) combinatorial species, and as an important preliminary
step, we study coalgebras for its derivative endofunctor $\partial$ and for the
`Euler homogeneity operator' $L\circ\partial$ arising from the adjunction
$L\dashv\partial\dashv R$.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04244" title="Abstract">arXiv:2401.04244</a> (cross-list from eess.IV) [<a href="/pdf/2401.04244" title="Download PDF">pdf</a>, <a href="/format/2401.04244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Turbulence Mitigation: A Translational Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xingguang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chimitt%2C+N">Nicholas Chimitt</a>, 
<a href="/search/eess?searchtype=author&query=Chi%2C+Y">Yiheng Chi</a>, 
<a href="/search/eess?searchtype=author&query=Mao%2C+Z">Zhiyuan Mao</a>, 
<a href="/search/eess?searchtype=author&query=Chan%2C+S+H">Stanley H. Chan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page <a href="https://xg416.github.io/DATUM/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recovering images distorted by atmospheric turbulence is a challenging
inverse problem due to the stochastic nature of turbulence. Although numerous
turbulence mitigation (TM) algorithms have been proposed, their efficiency and
generalization to real-world dynamic scenarios remain severely limited.
Building upon the intuitions of classical TM algorithms, we present the Deep
Atmospheric TUrbulence Mitigation network (DATUM). DATUM aims to overcome major
challenges when transitioning from classical to deep learning approaches. By
carefully integrating the merits of classical multi-frame TM methods into a
deep network structure, we demonstrate that DATUM can efficiently perform
long-range temporal aggregation using a recurrent fashion, while deformable
attention and temporal-channel attention seamlessly facilitate pixel
registration and lucky imaging. With additional supervision, tilt and blur
degradation can be jointly mitigated. These inductive biases empower DATUM to
significantly outperform existing methods while delivering a tenfold increase
in processing speed. A large-scale training dataset, ATSyn, is presented as a
co-invention to enable generalization in real turbulence. Our code and datasets
will be available at
\href{https://xg416.github.io/DATUM}{\textcolor{pink}{https://xg416.github.io/DATUM}}
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04283" title="Abstract">arXiv:2401.04283</a> (cross-list from eess.AS) [<a href="/pdf/2401.04283" title="Download PDF">pdf</a>, <a href="/ps/2401.04283" title="Download PostScript">ps</a>, <a href="/format/2401.04283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FADI-AEC: Fast Score Based Diffusion Model Guided by Far-end Signal for  Acoustic Echo Cancellation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+L">Li Wan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yun Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yiteng Huang</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+M">Ming Sun</a>, 
<a href="/search/eess?searchtype=author&query=Luan%2C+J">James Luan</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yangyang Shi</a>, 
<a href="/search/eess?searchtype=author&query=Lei%2C+X">Xin Lei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Despite the potential of diffusion models in speech enhancement, their
deployment in Acoustic Echo Cancellation (AEC) has been restricted. In this
paper, we propose DI-AEC, pioneering a diffusion-based stochastic regeneration
approach dedicated to AEC. Further, we propose FADI-AEC, fast score-based
diffusion AEC framework to save computational demands, making it favorable for
edge devices. It stands out by running the score model once per frame,
achieving a significant surge in processing efficiency. Apart from that, we
introduce a novel noise generation technique where far-end signals are
utilized, incorporating both far-end and near-end signals to refine the score
model's accuracy. We test our proposed method on the ICASSP2023 Microsoft deep
echo cancellation challenge evaluation dataset, where our method outperforms
some of the end-to-end methods and other diffusion based echo cancellation
methods.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04286" title="Abstract">arXiv:2401.04286</a> (cross-list from stat.ML) [<a href="/pdf/2401.04286" title="Download PDF">pdf</a>, <a href="/ps/2401.04286" title="Download PostScript">ps</a>, <a href="/format/2401.04286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Consistency of Wide and Deep ReLU Neural Networks and Minimax  Optimal Convergence Rates for Kolmogorov-Donoho Optimal Function Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ko%2C+H">Hyunouk Ko</a>, 
<a href="/search/stat?searchtype=author&query=Huo%2C+X">Xiaoming Huo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we first extend the result of FL93 and prove universal
consistency for a classification rule based on wide and deep ReLU neural
networks trained on the logistic loss. Unlike the approach in FL93 that
decomposes the estimation and empirical error, we directly analyze the
classification risk based on the observation that a realization of a neural
network that is wide enough is capable of interpolating an arbitrary number of
points. Secondly, we give sufficient conditions for a class of probability
measures under which classifiers based on neural networks achieve minimax
optimal rates of convergence. Our result is motivated from the practitioner's
observation that neural networks are often trained to achieve 0 training error,
which is the case for our proposed neural network classifiers. Our proofs hinge
on recent developments in empirical risk minimization and on approximation
rates of deep ReLU neural networks for various function classes of interest.
Applications to classical function spaces of smoothness illustrate the
usefulness of our result.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04372" title="Abstract">arXiv:2401.04372</a> (cross-list from stat.ML) [<a href="/pdf/2401.04372" title="Download PDF">pdf</a>, <a href="/ps/2401.04372" title="Download PostScript">ps</a>, <a href="/format/2401.04372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable generative modeling using diffusion maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gottwald%2C+G">Georg Gottwald</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+F">Fengyi Li</a>, 
<a href="/search/stat?searchtype=author&query=Marzouk%2C+Y">Youssef Marzouk</a>, 
<a href="/search/stat?searchtype=author&query=Reich%2C+S">Sebastian Reich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 25 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Computation (stat.CO)

</div>
<p class="mathjax">We consider the problem of sampling from an unknown distribution for which
only a sufficiently large number of training samples are available. Such
settings have recently drawn considerable interest in the context of generative
modelling. In this paper, we propose a generative model combining diffusion
maps and Langevin dynamics. Diffusion maps are used to approximate the drift
term from the available training samples, which is then implemented in a
discrete-time Langevin sampler to generate new samples. By setting the kernel
bandwidth to match the time step size used in the unadjusted Langevin
algorithm, our method effectively circumvents any stability issues typically
associated with time-stepping stiff stochastic differential equations. More
precisely, we introduce a novel split-step scheme, ensuring that the generated
samples remain within the convex hull of the training samples. Our framework
can be naturally extended to generate conditional samples. We demonstrate the
performance of our proposed scheme through experiments on synthetic datasets
with increasing dimensions and on a stochastic subgrid-scale parametrization
conditional sampling problem.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04430" title="Abstract">arXiv:2401.04430</a> (cross-list from eess.SP) [<a href="/pdf/2401.04430" title="Download PDF">pdf</a>, <a href="/format/2401.04430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Intelligent Surface-Enabled Downlink NOMA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dogukan%2C+A+T">Ali Tugberk Dogukan</a>, 
<a href="/search/eess?searchtype=author&query=Arslan%2C+E">Emre Arslan</a>, 
<a href="/search/eess?searchtype=author&query=Basar%2C+E">Ertugrul Basar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 13 figures, transaction journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Reconfigurable intelligent surfaces (RISs) bring great potential to the
advancement of 6G and beyond wireless communication technologies. RISs
introduce a great degree of flexibility, allowing some sort of virtual control
over the wireless channel. Exploiting the flexibility introduced by RISs, we
propose a novel RIS-enabled downlink (DL) non-orthogonal multiple access (NOMA)
scheme where NOMA is enabled over-the-air rather than at the base station (BS)
or the receiver (Rx). Here, the RIS is partitioned into distinctive groups
where each part of the RIS serves a different user equipment (UE) to perform
multiple accessing. The BS transmits an unmodulated signal to the RIS, and each
partition modulates the impinging signal over-the-air by introducing a phase
shift according to the incoming information bits to serve the corresponding UE.
First, the end-to-end system model for the proposed system is presented.
Furthermore, outage probability calculations, theoretical error probability
analysis, and bit error rate (BER) derivations are discussed and reinforced
with comprehensive computer simulation results.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04431" title="Abstract">arXiv:2401.04431</a> (cross-list from physics.ins-det) [<a href="/pdf/2401.04431" title="Download PDF">pdf</a>, <a href="/ps/2401.04431" title="Download PostScript">ps</a>, <a href="/format/2401.04431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sea wave data reconstruction using micro-seismic measurements and  machine learning methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Iafolla%2C+L">Lorenzo Iafolla</a>, 
<a href="/search/physics?searchtype=author&query=Fiorenza%2C+E">Emiliano Fiorenza</a>, 
<a href="/search/physics?searchtype=author&query=Chiappini%2C+M">Massimo Chiappini</a>, 
<a href="/search/physics?searchtype=author&query=Carmisciano%2C+C">Cosmo Carmisciano</a>, 
<a href="/search/physics?searchtype=author&query=Iafolla%2C+V+A">Valerio Antonio Iafolla</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Front. Mar. Sci., 17 February 2022, Sec. Ocean Observation, Volume
  9 - 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Detectors (physics.ins-det)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Sea wave monitoring is key in many applications in oceanography such as the
validation of weather and wave models. Conventional in situ solutions are based
on moored buoys whose measurements are often recognized as a standard. However,
being exposed to a harsh environment, they are not reliable, need frequent
maintenance, and the datasets feature many gaps. To overcome the previous
limitations, we propose a system including a buoy, a micro-seismic measuring
station, and a machine learning algorithm. The working principle is based on
measuring the micro-seismic signals generated by the sea waves. Thus, the
machine learning algorithm will be trained to reconstruct the missing buoy data
from the micro-seismic data. As the micro-seismic station can be installed
indoor, it assures high reliability while the machine learning algorithm
provides accurate reconstruction of the missing buoy data. In this work, we
present the methods to process the data, develop and train the machine learning
algorithm, and assess the reconstruction accuracy. As a case of study, we used
experimental data collected in 2014 from the Northern Tyrrhenian Sea
demonstrating that the data reconstruction can be done both for significant
wave height and wave period. The proposed approach was inspired from Data
Science, whose methods were the foundation for the new solutions presented in
this work. For example, estimating the period of the sea waves, often not
discussed in previous works, was relatively simple with machine learning. In
conclusion, the experimental results demonstrated that the new system can
overcome the reliability issues of the buoy keeping the same accuracy.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04436" title="Abstract">arXiv:2401.04436</a> (cross-list from math.AP) [<a href="/pdf/2401.04436" title="Download PDF">pdf</a>, <a href="/format/2401.04436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Payne-Whitham model of urban traffic networks in the presence of  traffic lights and its application to traffic optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=van+Dissel%2C+M+C">Mauritz Cartier van Dissel</a>, 
<a href="/search/math?searchtype=author&query=Gora%2C+P">Pawe&#x142; Gora</a>, 
<a href="/search/math?searchtype=author&query=Manea%2C+D">Drago&#x15f; Manea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Urban road transport is a major civilisational and economic challenge,
affecting quality of life and economic activity. Addressing these challenges
requires a multidisciplinary approach and sustainable urban planning strategies
to mitigate the negative effects of traffic in cities. In this paper, we will
introduce an extension of one of the most popular macroscopic traffic
simulation models, the Payne-Whitham model. We will investigate how this model,
originally designed to model highway traffic on straight road segments, can be
adapted to more realistic conditions with arbitrary road network graphs and
multiple intersections with traffic signals. Furthermore, we will showcase the
practical application of this extension in experiments aimed at optimising
traffic signal settings. For computational reasons, these experiments involve
the adoption of surrogate models for approximating our extended Payne-Whitham
model, and subsequently, we utilise various optimisation algorithms, e.g.
SLSQP, resulting in the identification of traffic signal settings that enhance
the average speed of cars, thereby facilitating smoother traffic flow.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04447" title="Abstract">arXiv:2401.04447</a> (cross-list from eess.AS) [<a href="/pdf/2401.04447" title="Download PDF">pdf</a>, <a href="/format/2401.04447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Incremental Learning for Multi-Label Audio Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mulimani%2C+M">Manjunath Mulimani</a>, 
<a href="/search/eess?searchtype=author&query=Mesaros%2C+A">Annamaria Mesaros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In this paper, we propose a method for class-incremental learning of
potentially overlapping sounds for solving a sequence of multi-label audio
classification tasks. We design an incremental learner that learns new classes
independently of the old classes. To preserve knowledge about the old classes,
we propose a cosine similarity-based distillation loss that minimizes
discrepancy in the feature representations of subsequent learners, and use it
along with a Kullback-Leibler divergence-based distillation loss that minimizes
discrepancy in their respective outputs. Experiments are performed on a dataset
with 50 sound classes, with an initial classification task containing 30 base
classes and 4 incremental phases of 5 classes each. After each phase, the
system is tested for multi-label classification with the entire set of classes
learned so far. The proposed method obtains an average F1-score of 40.9% over
the five phases, ranging from 45.2% in phase 0 on 30 classes, to 36.3% in phase
4 on 50 classes. Average performance degradation over incremental phases is
only 0.7 percentage points from the initial F1-score of 45.2%.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04478" title="Abstract">arXiv:2401.04478</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.04478" title="Download PDF">pdf</a>, <a href="/format/2401.04478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TwinBooster: Synergising Large Language Models with Barlow Twins and  Gradient Boosting for Enhanced Molecular Property Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Schuh%2C+M+G">Maximilian G. Schuh</a>, 
<a href="/search/q-bio?searchtype=author&query=Boldini%2C+D">Davide Boldini</a>, 
<a href="/search/q-bio?searchtype=author&query=Sieber%2C+S+A">Stephan A. Sieber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The success of drug discovery and development relies on the precise
prediction of molecular activities and properties. While in silico molecular
property prediction has shown remarkable potential, its use has been limited so
far to assays for which large amounts of data are available. In this study, we
use a fine-tuned large language model to integrate biological assays based on
their textual information, coupled with Barlow Twins, a Siamese neural network
using a novel self-supervised learning approach. This architecture uses both
assay information and molecular fingerprints to extract the true molecular
information. TwinBooster enables the prediction of properties of unseen
bioassays and molecules by providing state-of-the-art zero-shot learning tasks.
Remarkably, our artificial intelligence pipeline shows excellent performance on
the FS-Mol benchmark. This breakthrough demonstrates the application of deep
learning to critical property prediction tasks where data is typically scarce.
By accelerating the early identification of active molecules in drug discovery
and development, this method has the potential to help streamline the
identification of novel therapeutics.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04511" title="Abstract">arXiv:2401.04511</a> (cross-list from eess.AS) [<a href="/pdf/2401.04511" title="Download PDF">pdf</a>, <a href="/format/2401.04511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero Shot Audio to Audio Emotion Transfer With Speaker Disentanglement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dutta%2C+S">Soumya Dutta</a>, 
<a href="/search/eess?searchtype=author&query=Ganapathy%2C+S">Sriram Ganapathy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">The problem of audio-to-audio (A2A) style transfer involves replacing the
style features of the source audio with those from the target audio while
preserving the content related attributes of the source audio. In this paper,
we propose an efficient approach, termed as Zero-shot Emotion Style Transfer
(ZEST), that allows the transfer of emotional content present in the given
source audio with the one embedded in the target audio while retaining the
speaker and speech content from the source. The proposed system builds upon
decomposing speech into semantic tokens, speaker representations and emotion
embeddings. Using these factors, we propose a framework to reconstruct the
pitch contour of the given speech signal and train a decoder that reconstructs
the speech signal. The model is trained using a self-supervision based
reconstruction loss. During conversion, the emotion embedding is alone derived
from the target audio, while rest of the factors are derived from the source
audio. In our experiments, we show that, even without using parallel training
data or labels from the source or target audio, we illustrate zero shot emotion
transfer capabilities of the proposed ZEST model using objective and subjective
quality evaluations.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04535" title="Abstract">arXiv:2401.04535</a> (cross-list from stat.ML) [<a href="/pdf/2401.04535" title="Download PDF">pdf</a>, <a href="/format/2401.04535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Deep Sobolev Regression: Estimation, Variable Selection  and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ding%2C+Z">Zhao Ding</a>, 
<a href="/search/stat?searchtype=author&query=Duan%2C+C">Chenguang Duan</a>, 
<a href="/search/stat?searchtype=author&query=Jiao%2C+Y">Yuling Jiao</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+J+Z">Jerry Zhijian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose SDORE, a semi-supervised deep Sobolev regressor, for the
nonparametric estimation of the underlying regression function and its
gradient. SDORE employs deep neural networks to minimize empirical risk with
gradient norm regularization, allowing computation of the gradient norm on
unlabeled data. We conduct a comprehensive analysis of the convergence rates of
SDORE and establish a minimax optimal rate for the regression function.
Crucially, we also derive a convergence rate for the associated plug-in
gradient estimator, even in the presence of significant domain shift. These
theoretical findings offer valuable prior guidance for selecting regularization
parameters and determining the size of the neural network, while showcasing the
provable advantage of leveraging unlabeled data in semi-supervised learning. To
the best of our knowledge, SDORE is the first provable neural network-based
approach that simultaneously estimates the regression function and its
gradient, with diverse applications including nonparametric variable selection
and inverse problems. The effectiveness of SDORE is validated through an
extensive range of numerical simulations and real data analysis.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04553" title="Abstract">arXiv:2401.04553</a> (cross-list from stat.ML) [<a href="/pdf/2401.04553" title="Download PDF">pdf</a>, <a href="/format/2401.04553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Recursive Feature Machines provably recover low-rank matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Radhakrishnan%2C+A">Adityanarayanan Radhakrishnan</a>, 
<a href="/search/stat?searchtype=author&query=Belkin%2C+M">Mikhail Belkin</a>, 
<a href="/search/stat?searchtype=author&query=Drusvyatskiy%2C+D">Dmitriy Drusvyatskiy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A fundamental problem in machine learning is to understand how neural
networks make accurate predictions, while seemingly bypassing the curse of
dimensionality. A possible explanation is that common training algorithms for
neural networks implicitly perform dimensionality reduction - a process called
feature learning. Recent work posited that the effects of feature learning can
be elicited from a classical statistical estimator called the average gradient
outer product (AGOP). The authors proposed Recursive Feature Machines (RFMs) as
an algorithm that explicitly performs feature learning by alternating between
(1) reweighting the feature vectors by the AGOP and (2) learning the prediction
function in the transformed space. In this work, we develop the first
theoretical guarantees for how RFM performs dimensionality reduction by
focusing on the class of overparametrized problems arising in sparse linear
regression and low-rank matrix recovery. Specifically, we show that RFM
restricted to linear models (lin-RFM) generalizes the well-studied Iteratively
Reweighted Least Squares (IRLS) algorithm. Our results shed light on the
connection between feature learning in neural networks and classical sparse
recovery algorithms. In addition, we provide an implementation of lin-RFM that
scales to matrices with millions of missing entries. Our implementation is
faster than the standard IRLS algorithm as it is SVD-free. It also outperforms
deep linear networks for sparse linear regression and low-rank matrix
completion.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04554" title="Abstract">arXiv:2401.04554</a> (cross-list from math.CO) [<a href="/pdf/2401.04554" title="Download PDF">pdf</a>, <a href="/format/2401.04554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HIST-Critical Graphs and Malkevitch&#x27;s Conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goedgebeur%2C+J">Jan Goedgebeur</a>, 
<a href="/search/math?searchtype=author&query=Noguchi%2C+K">Kenta Noguchi</a>, 
<a href="/search/math?searchtype=author&query=Renders%2C+J">Jarne Renders</a>, 
<a href="/search/math?searchtype=author&query=Zamfirescu%2C+C+T">Carol T. Zamfirescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In a given graph, a HIST is a spanning tree without $2$-valent vertices.
Motivated by developing a better understanding of HIST-free graphs, i.e. graphs
containing no HIST, in this article's first part we study HIST-critical graphs,
i.e. HIST-free graphs in which every vertex-deleted subgraph does contain a
HIST (e.g. a triangle). We give an almost complete characterisation of the
orders for which these graphs exist and present an infinite family of planar
examples which are $3$-connected and in which nearly all vertices are
$4$-valent. This leads naturally to the second part in which we investigate
planar $4$-regular graphs with and without HISTs, motivated by a conjecture of
Malkevitch, which we computationally verify up to order $22$. First we
enumerate HISTs in antiprisms, whereafter we present planar $4$-regular graphs
with and without HISTs, obtained via line graphs.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04556" title="Abstract">arXiv:2401.04556</a> (cross-list from physics.soc-ph) [<a href="/pdf/2401.04556" title="Download PDF">pdf</a>, <a href="/format/2401.04556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Discrete-Time Networked SIV Epidemic Model with Polar Opinion  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Xu%2C+Q">Qiulin Xu</a>, 
<a href="/search/physics?searchtype=author&query=Ishii%2C+H">Hideaki Ishii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper studies novel epidemic spreading problems influenced by opinion
evolution in social networks, where the opinions reflect the public health
concerns. A coupled bilayer network is proposed, where the epidemics spread
over several communities through a physical network layer while the opinions
evolve over the same communities through a social network layer. The epidemic
spreading process is described by a susceptible-infected-vigilant (SIV) model,
which introduces opinion-dependent epidemic vigilance state compared with the
classical epidemic models. The opinion process is modeled by a polar opinion
dynamics model, which includes infection prevalence and human stubbornness into
the opinion evolution. By introducing an opinion-dependent reproduction number,
we analyze the stability of disease-free and endemic equilibria and derive
sufficient conditions for their global asymptotic stability. We also discuss
the mutual effects between epidemic eradication and opinion consensus, and the
possibility of suppressing epidemic by intervening in the opinions or
implementing public health strategies. Simulations are conducted to verify the
theoretical results and demonstrate the feasibility of epidemic suppression.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04570" title="Abstract">arXiv:2401.04570</a> (cross-list from eess.IV) [<a href="/pdf/2401.04570" title="Download PDF">pdf</a>, <a href="/format/2401.04570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Automatic Cascaded Model for Hemorrhagic Stroke Segmentation and  Hemorrhagic Volume Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+W">Weijin Xu</a>, 
<a href="/search/eess?searchtype=author&query=Sha%2C+Z">Zhuang Sha</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Huihua Yang</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+R">Rongcai Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhanying Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+R">Ruisheng Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SWITCH2023: Stroke Workshop on Imaging and Treatment CHallenges, a workshop at MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Hemorrhagic Stroke (HS) has a rapid onset and is a serious condition that
poses a great health threat. Promptly and accurately delineating the bleeding
region and estimating the volume of bleeding in Computer Tomography (CT) images
can assist clinicians in treatment planning, leading to improved treatment
outcomes for patients. In this paper, a cascaded 3D model is constructed based
on UNet to perform a two-stage segmentation of the hemorrhage area in CT images
from rough to fine, and the hemorrhage volume is automatically calculated from
the segmented area. On a dataset with 341 cases of hemorrhagic stroke CT scans,
the proposed model provides high-quality segmentation outcome with higher
accuracy (DSC 85.66%) and better computation efficiency (6.2 second per sample)
when compared to the traditional Tada formula with respect to hemorrhage volume
estimation.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04579" title="Abstract">arXiv:2401.04579</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.04579" title="Download PDF">pdf</a>, <a href="/ps/2401.04579" title="Download PostScript">ps</a>, <a href="/format/2401.04579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Network for Explainable Prediction of Non-Imaging Phenotypes  using Anatomical Multi-View Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+Y">Yuqian Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Xue%2C+T">Tengfei Xue</a>, 
<a href="/search/q-bio?searchtype=author&query=Zekelman%2C+L">Leo Zekelman</a>, 
<a href="/search/q-bio?searchtype=author&query=Makris%2C+N">Nikos Makris</a>, 
<a href="/search/q-bio?searchtype=author&query=Rathi%2C+Y">Yogesh Rathi</a>, 
<a href="/search/q-bio?searchtype=author&query=Cai%2C+W">Weidong Cai</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Donnell%2C+L+J+O">Lauren J. O&#x27; Donnell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 The Medical Image Computing and Computer Assisted Intervention Society workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Large datasets often contain multiple distinct feature sets, or views, that
offer complementary information that can be exploited by multi-view learning
methods to improve results. We investigate anatomical multi-view data, where
each brain anatomical structure is described with multiple feature sets. In
particular, we focus on sets of white matter microstructure and connectivity
features from diffusion MRI, as well as sets of gray matter area and thickness
features from structural MRI. We investigate machine learning methodology that
applies multi-view approaches to improve the prediction of non-imaging
phenotypes, including demographics (age), motor (strength), and cognition
(picture vocabulary). We present an explainable multi-view network (EMV-Net)
that can use different anatomical views to improve prediction performance. In
this network, each individual anatomical view is processed by a view-specific
feature extractor and the extracted information from each view is fused using a
learnable weight. This is followed by a wavelet transform-based module to
obtain complementary information across views which is then applied to
calibrate the view-specific information. Additionally, the calibrator produces
an attention-based calibration score to indicate anatomical structures'
importance for interpretation.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04653" title="Abstract">arXiv:2401.04653</a> (cross-list from math.OC) [<a href="/pdf/2401.04653" title="Download PDF">pdf</a>, <a href="/format/2401.04653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-certified Input-constrained NMPC via Koopman Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wu%2C+L">Liang Wu</a>, 
<a href="/search/math?searchtype=author&query=Ganko%2C+K">Krystian Ganko</a>, 
<a href="/search/math?searchtype=author&query=Braatz%2C+R+D">Richard D. Braatz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, submitted into 8th IFAC Conference on Nonlinear Model Predictive Control NMPC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Determining solving-time certificates of nonlinear model predictive control
(NMPC) implementations is a pressing requirement when deploying NMPC in
production environments. Such a certificate guarantees that the NMPC controller
returns a solution before the next sampling time. However, NMPC formulations
produce nonlinear programs (NLPs) for which it is very difficult to derive
their solving-time certificates. Our previous work, Wu and Braatz (2023),
challenged this limitation with a proposed input-constrained MPC algorithm
having exact iteration complexity but was restricted to linear MPC
formulations. This work extends the algorithm to solve input-constrained NMPC
problems, by using the Koopman operator and a condensing MPC technique. We
illustrate the algorithm performance on a high-dimensional, nonlinear partial
differential equation (PDE) control case study, in which we theoretically and
numerically certify the solving time to be less than the sampling time.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04674" title="Abstract">arXiv:2401.04674</a> (cross-list from math.AP) [<a href="/pdf/2401.04674" title="Download PDF">pdf</a>, <a href="/format/2401.04674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving the Scattering Problem for Open Wave-Guides, III: Radiation  Conditions and Uniqueness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Epstein%2C+C+L">Charles L. Epstein</a>, 
<a href="/search/math?searchtype=author&query=Mazzeo%2C+R">Rafe Mazzeo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Mathematical Physics (math-ph); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper continues the analysis of the scattering problem for a network of
open wave-guides started in [<a href="/abs/2302.04353">arXiv:2302.04353</a>, <a href="/abs/2310.05816">arXiv:2310.05816</a>]. In this part
we present explicit, physically motivated radiation conditions that ensure
uniqueness of the solution to the scattering problem. These conditions stem
from a 2000 paper of A. Vasy on 3-body Schrodinger operators; we discuss
closely related conditions from a 1994 paper of H. Isozaki. Vasy's paper also
proves the existence of the limiting absorption resolvents, and that the
limiting solutions satisfy the radiation conditions. The statements of these
results require a calculus of pseudodifferential operators, called the 3-body
scattering calculus, which is briefly introduced here. We show that the
solutions to the model problem obtained in <a href="/abs/2302.04353">arXiv:2302.04353</a> satisfy these
radiation conditions, which makes it possible to prove uniqueness, and
therefore existence, for the system of Fredholm integral equations introduced
in that paper.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04722" title="Abstract">arXiv:2401.04722</a> (cross-list from eess.IV) [<a href="/pdf/2401.04722" title="Download PDF">pdf</a>, <a href="/format/2401.04722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> U-Mamba: Enhancing Long-range Dependency for Biomedical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+F">Feifei Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Bo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Convolutional Neural Networks (CNNs) and Transformers have been the most
popular architectures for biomedical image segmentation, but both of them have
limited ability to handle long-range dependencies because of inherent locality
or computational complexity. To address this challenge, we introduce U-Mamba, a
general-purpose network for biomedical image segmentation. Inspired by the
State Space Sequence Models (SSMs), a new family of deep sequence models known
for their strong capability in handling long sequences, we design a hybrid
CNN-SSM block that integrates the local feature extraction power of
convolutional layers with the abilities of SSMs for capturing the long-range
dependency. Moreover, U-Mamba enjoys a self-configuring mechanism, allowing it
to automatically adapt to various datasets without manual intervention. We
conduct extensive experiments on four diverse tasks, including the 3D abdominal
organ segmentation in CT and MR images, instrument segmentation in endoscopy
images, and cell segmentation in microscopy images. The results reveal that
U-Mamba outperforms state-of-the-art CNN-based and Transformer-based
segmentation networks across all tasks. This opens new avenues for efficient
long-range dependency modeling in biomedical image analysis. The code, models,
and data are publicly available at https://wanglab.ai/u-mamba.html.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04726" title="Abstract">arXiv:2401.04726</a> (cross-list from physics.soc-ph) [<a href="/pdf/2401.04726" title="Download PDF">pdf</a>, <a href="/format/2401.04726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted degrees and truncated derived bibliographic networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Batagelj%2C+V">Vladimir Batagelj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
<p class="mathjax">Large bibliographic networks are sparse -- the average node degree is small.
This is not necessarily true for their product -- in some cases, it can
``explode'' (it is not sparse, increases in time and space complexity). An
approach in such cases is to reduce the complexity of the problem by limiting
our attention to a selected subset of important nodes and computing with
corresponding truncated networks. The nodes can be selected by different
criteria. An option is to consider the most important nodes in the derived
network -- nodes with the largest weighted degree. It turns out that the
weighted degrees in the derived network can be computed efficiently without
computing the derived network itself.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed, 10 Jan 24</h3>
<dl>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1904.05572" title="Abstract">arXiv:1904.05572</a> (replaced) [<a href="/pdf/1904.05572" title="Download PDF">pdf</a>, <a href="/format/1904.05572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Android Platform Security Model (2023)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mayrhofer%2C+R">Ren&#xe9; Mayrhofer</a>, 
<a href="/search/cs?searchtype=author&query=Stoep%2C+J+V">Jeffrey Vander Stoep</a>, 
<a href="/search/cs?searchtype=author&query=Brubaker%2C+C">Chad Brubaker</a>, 
<a href="/search/cs?searchtype=author&query=Hackborn%2C+D">Dianne Hackborn</a>, 
<a href="/search/cs?searchtype=author&query=Bonn%C3%A9%2C+B">Bram Bonn&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Tuncay%2C+G+S">G&#xfc;liz Seray Tuncay</a>, 
<a href="/search/cs?searchtype=author&query=Jover%2C+R+P">Roger Piqueras Jover</a>, 
<a href="/search/cs?searchtype=author&query=Specter%2C+M+A">Michael A. Specter</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transactions on Privacy and Security, Volume 24, Issue 3,
  Article No. 19, 2021, pp 1-35
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Operating Systems (cs.OS)

</div>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.09385" title="Abstract">arXiv:2102.09385</a> (replaced) [<a href="/pdf/2102.09385" title="Download PDF">pdf</a>, <a href="/ps/2102.09385" title="Download PostScript">ps</a>, <a href="/format/2102.09385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of stochastic gradient descent schemes for  Lojasiewicz-landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dereich%2C+S">Steffen Dereich</a>, 
<a href="/search/cs?searchtype=author&query=Kassing%2C+S">Sebastian Kassing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.05206" title="Abstract">arXiv:2109.05206</a> (replaced) [<a href="/pdf/2109.05206" title="Download PDF">pdf</a>, <a href="/ps/2109.05206" title="Download PostScript">ps</a>, <a href="/format/2109.05206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PHPQ: Pyramid Hybrid Pooling Quantization for Efficient Fine-Grained  Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Ziyun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Pattern Recognition Letters
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition Letters, Volume 178, 2024, Pages 106-114
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.02220" title="Abstract">arXiv:2112.02220</a> (replaced) [<a href="/pdf/2112.02220" title="Download PDF">pdf</a>, <a href="/format/2112.02220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capacity Results for Multiple-Input Multiple-Output Optical Wireless  Communication With Per-Antenna Intensity Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ru-Han Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jia-Ning Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.04156" title="Abstract">arXiv:2201.04156</a> (replaced) [<a href="/pdf/2201.04156" title="Download PDF">pdf</a>, <a href="/ps/2201.04156" title="Download PostScript">ps</a>, <a href="/format/2201.04156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Faithful and Quantitative Notion of Distant Reduction for the  Lambda-Calculus with Generalized Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santo%2C+J+E">Jos&#xe9; Esp&#xed;rito Santo</a> (1), 
<a href="/search/cs?searchtype=author&query=Kesner%2C+D">Delia Kesner</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Peyrot%2C+L">Lo&#xef;c Peyrot</a> (2) ((1) Centro de Matem&#xe1;tica, Universidade do Minho, Portugal, (2) Universit&#xe9; de Paris, CNRS, IRIF, France, (3) Institut Universitaire de France, France)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.10838" title="Abstract">arXiv:2201.10838</a> (replaced) [<a href="/pdf/2201.10838" title="Download PDF">pdf</a>, <a href="/format/2201.10838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Logistic Regression Training with A Faster Gradient  Variant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiang%2C+J">John Chiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The basic work of this paper, $\texttt{quadratic gradient}$ and the enhanced full batch NAG, was nearly finished in September 2019. The initial version of this paper was written in April 2020, rejected by ICANN 2020. The enhanced mini-batch NAG was introduced into this paper in September 2020 and later rejected by a special issue on the journal FGCS 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.12577" title="Abstract">arXiv:2201.12577</a> (replaced) [<a href="/pdf/2201.12577" title="Download PDF">pdf</a>, <a href="/format/2201.12577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Volley Revolver: A Novel Matrix-Encoding Method for Privacy-Preserving  Neural Networks (Inference)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiang%2C+J">John Chiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The encoding method we proposed in this work, $\texttt{Volley Revolver}$, is particularly tailored for privacy-preserving neural networks. There is a good chance that it can be used to assist the private neural networks training, in which case for the backpropagation algorithm of the fully-connected layer the first matrix $A$ is revolved while the second matrix $B$ is settled to be still
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.01891" title="Abstract">arXiv:2202.01891</a> (replaced) [<a href="/pdf/2202.01891" title="Download PDF">pdf</a>, <a href="/format/2202.01891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted Isolation and Random Cut Forest Algorithms for Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeom%2C+S">Sijin Yeom</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jae-Hun Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 28 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.09212" title="Abstract">arXiv:2202.09212</a> (replaced) [<a href="/pdf/2202.09212" title="Download PDF">pdf</a>, <a href="/format/2202.09212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecule Generation for Drug Design: a Graph Learning Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nianzu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huaijin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Kaipeng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.01982" title="Abstract">arXiv:2205.01982</a> (replaced) [<a href="/pdf/2205.01982" title="Download PDF">pdf</a>, <a href="/format/2205.01982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifelong Ensemble Learning based on Multiple Representations for  Few-Shot Object Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+H">Hamidreza Kasaei</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+S">Songsong Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted for publication in the Robotics and Autonomous Systems journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.05140" title="Abstract">arXiv:2205.05140</a> (replaced) [<a href="/pdf/2205.05140" title="Download PDF">pdf</a>, <a href="/format/2205.05140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RotorTM: A Flexible Simulator for Aerial Transportation and Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Loianno%2C+G">Giuseppe Loianno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in the IEEE Transactions on Robotics (T-RO), 2024. Please cite the paper using appropriate formats
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Robotics (T-RO), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.10347" title="Abstract">arXiv:2205.10347</a> (replaced) [<a href="/pdf/2205.10347" title="Download PDF">pdf</a>, <a href="/format/2205.10347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diverse super-resolution with pretrained deep hiererarchical VAEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prost%2C+J">Jean Prost</a>, 
<a href="/search/cs?searchtype=author&query=Houdard%2C+A">Antoine Houdard</a>, 
<a href="/search/cs?searchtype=author&query=Almansa%2C+A">Andr&#xe9;s Almansa</a>, 
<a href="/search/cs?searchtype=author&query=Papadakis%2C+N">Nicolas Papadakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages , 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.13131" title="Abstract">arXiv:2205.13131</a> (replaced) [<a href="/pdf/2205.13131" title="Download PDF">pdf</a>, <a href="/ps/2205.13131" title="Download PostScript">ps</a>, <a href="/format/2205.13131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Evolution of A.I. and Machine Learning: Towards a Meta-level  Measuring and Understanding Impact, Influence, and Leadership at Premier A.I.  Conferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Audibert%2C+R+B">Rafael B. Audibert</a>, 
<a href="/search/cs?searchtype=author&query=Lemos%2C+H">Henrique Lemos</a>, 
<a href="/search/cs?searchtype=author&query=Avelar%2C+P">Pedro Avelar</a>, 
<a href="/search/cs?searchtype=author&query=Tavares%2C+A+R">Anderson R. Tavares</a>, 
<a href="/search/cs?searchtype=author&query=Lamb%2C+L+C">Lu&#xed;s C. Lamb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 125 pages, 57 figures, 11 tables. Published in The Journal of Applied Logics - IFCoLog Journal of Logics and their Applications
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Applied Logics, IfCoLog Journal of Logics and their
  Applications, Vol. 10 No. 5 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14912" title="Abstract">arXiv:2205.14912</a> (replaced) [<a href="/pdf/2205.14912" title="Download PDF">pdf</a>, <a href="/format/2205.14912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2S2: Encoding-Enhanced Sequence-to-Sequence Pretraining for Language  Understanding and Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Q">Qihuang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Juhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TKDE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.03107" title="Abstract">arXiv:2206.03107</a> (replaced) [<a href="/pdf/2206.03107" title="Download PDF">pdf</a>, <a href="/format/2206.03107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A probabilistic representation of the solution to a 1D evolution  equation in a medium with negative index
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Bonnetier%2C+%C3%89">&#xc9;ric Bonnetier</a> (IF), 
<a href="/search/math-ph?searchtype=author&query=Etor%C3%A9%2C+P">Pierre Etor&#xe9;</a> (IPS), 
<a href="/search/math-ph?searchtype=author&query=Martinez%2C+M">Miguel Martinez</a> (LAMA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Numerical Analysis (math.NA); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14068" title="Abstract">arXiv:2206.14068</a> (replaced) [<a href="/pdf/2206.14068" title="Download PDF">pdf</a>, <a href="/format/2206.14068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FuSeBMC v4: Improving code coverage with smart seeds via BMC, fuzzing  and static analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshmrany%2C+K+M">Kaled M. Alshmrany</a>, 
<a href="/search/cs?searchtype=author&query=Aldughaim%2C+M">Mohannad Aldughaim</a>, 
<a href="/search/cs?searchtype=author&query=Bhayat%2C+A">Ahmed Bhayat</a>, 
<a href="/search/cs?searchtype=author&query=Cordeiro%2C+L+C">Lucas C. Cordeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, In The Formal Aspects of Computing Journal (FAC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13795" title="Abstract">arXiv:2207.13795</a> (replaced) [<a href="/pdf/2207.13795" title="Download PDF">pdf</a>, <a href="/format/2207.13795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sectored DRAM: A Practical Energy-Efficient and High-Performance  Fine-Grained DRAM Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Bostanci%2C+F+N">F. Nisa Bostanci</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+G+F">Geraldo F. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Tugrul%2C+Y+C">Yahya Can Tugrul</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+R">Rahul Bera</a>, 
<a href="/search/cs?searchtype=author&query=Yaglikci%2C+A+G">A. Giray Yaglikci</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+H">Hasan Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Ergin%2C+O">Oguz Ergin</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08891" title="Abstract">arXiv:2209.08891</a> (replaced) [<a href="/pdf/2209.08891" title="Download PDF">pdf</a>, <a href="/format/2209.08891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Cultural Biases via Homoglyphs in Text-to-Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Struppek%2C+L">Lukas Struppek</a>, 
<a href="/search/cs?searchtype=author&query=Hintersdorf%2C+D">Dominik Hintersdorf</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+F">Felix Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Brack%2C+M">Manuel Brack</a>, 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the Journal of Artificial Intelligence Research (JAIR)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Artificial Intelligence Research (JAIR), Vol. 78 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11209" title="Abstract">arXiv:2209.11209</a> (replaced) [<a href="/pdf/2209.11209" title="Download PDF">pdf</a>, <a href="/format/2209.11209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Approximation Algorithms by Generalizing the Primal-Dual Method  Beyond Uncrossable Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+I">Ishan Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Cheriyan%2C+J">Joseph Cheriyan</a>, 
<a href="/search/cs?searchtype=author&query=Grout%2C+L">Logan Grout</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahimpur%2C+S">Sharat Ibrahimpur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated v3, improved exposition at a few points, results and proofs are the same
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11462" title="Abstract">arXiv:2209.11462</a> (replaced) [<a href="/pdf/2209.11462" title="Download PDF">pdf</a>, <a href="/ps/2209.11462" title="Download PostScript">ps</a>, <a href="/format/2209.11462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coding-Enhanced Cooperative Jamming for Secret Communication: The MIMO  Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kai-Kit Wong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinfei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures. Accepted for publication in IEEE Transactions on Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12407" title="Abstract">arXiv:2209.12407</a> (replaced) [<a href="/pdf/2209.12407" title="Download PDF">pdf</a>, <a href="/format/2209.12407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entailment Semantics Can Be Extracted from an Ideal Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merrill%2C+W">William Merrill</a>, 
<a href="/search/cs?searchtype=author&query=Warstadt%2C+A">Alex Warstadt</a>, 
<a href="/search/cs?searchtype=author&query=Linzen%2C+T">Tal Linzen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CONLL 2022. Updated Dec 4, 2023 and Jan 8, 2024 with erratum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14065" title="Abstract">arXiv:2209.14065</a> (replaced) [<a href="/pdf/2209.14065" title="Download PDF">pdf</a>, <a href="/format/2209.14065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LL-GNN: Low Latency Graph Neural Networks on FPGAs for High Energy  Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Que%2C+Z">Zhiqiang Que</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hongxiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Loo%2C+M">Marcus Loo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">He Li</a>, 
<a href="/search/cs?searchtype=author&query=Blott%2C+M">Michaela Blott</a>, 
<a href="/search/cs?searchtype=author&query=Pierini%2C+M">Maurizio Pierini</a>, 
<a href="/search/cs?searchtype=author&query=Tapper%2C+A">Alexander Tapper</a>, 
<a href="/search/cs?searchtype=author&query=Luk%2C+W">Wayne Luk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ACM Transactions on Embedded Computing Systems (TECS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Instrumentation and Detectors (physics.ins-det)

</div>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08387" title="Abstract">arXiv:2210.08387</a> (replaced) [<a href="/pdf/2210.08387" title="Download PDF">pdf</a>, <a href="/format/2210.08387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Varying Semidefinite Programming: Path Following a Burer-Monteiro  Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bellon%2C+A">Antonio Bellon</a>, 
<a href="/search/math?searchtype=author&query=Dressler%2C+M">Mareike Dressler</a>, 
<a href="/search/math?searchtype=author&query=Kungurtsev%2C+V">Vyacheslav Kungurtsev</a>, 
<a href="/search/math?searchtype=author&query=Marecek%2C+J">Jakub Marecek</a>, 
<a href="/search/math?searchtype=author&query=Uschmajew%2C+A">Andr&#xe9; Uschmajew</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16906" title="Abstract">arXiv:2210.16906</a> (replaced) [<a href="/pdf/2210.16906" title="Download PDF">pdf</a>, <a href="/format/2210.16906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DyG2Vec: Efficient Representation Learning for Dynamic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alomrani%2C+M+A">Mohammad Ali Alomrani</a>, 
<a href="/search/cs?searchtype=author&query=Biparva%2C+M">Mahdi Biparva</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingxue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Coates%2C+M">Mark Coates</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Transactions on Machine Learning Research, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06797" title="Abstract">arXiv:2211.06797</a> (replaced) [<a href="/pdf/2211.06797" title="Download PDF">pdf</a>, <a href="/format/2211.06797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Video Coding for Machines via Satisfied Machine Ratio  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shanshe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chuanmin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Siwei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wen Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14555" title="Abstract">arXiv:2211.14555</a> (replaced) [<a href="/pdf/2211.14555" title="Download PDF">pdf</a>, <a href="/format/2211.14555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution Free Prediction Sets for Node Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Clarkson%2C+J">Jase Clarkson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared at ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15374" title="Abstract">arXiv:2211.15374</a> (replaced) [<a href="/pdf/2211.15374" title="Download PDF">pdf</a>, <a href="/format/2211.15374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of Surface Defects on Solar PV Panels and Wind Turbine  Blades using Attention based Deep Learning Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+D">Divyanshi Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+K+V+S+M">K. Victor Sam Moses Babu</a>, 
<a href="/search/cs?searchtype=author&query=Yemula%2C+P+K">Pradeep Kumar Yemula</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+P">Pratyush Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+M">Mayukha Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04458" title="Abstract">arXiv:2212.04458</a> (replaced) [<a href="/pdf/2212.04458" title="Download PDF">pdf</a>, <a href="/format/2212.04458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General-Purpose In-Context Learning by Meta-Learning Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirsch%2C+L">Louis Kirsch</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+J">James Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Sohl-Dickstein%2C+J">Jascha Sohl-Dickstein</a>, 
<a href="/search/cs?searchtype=author&query=Metz%2C+L">Luke Metz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the NeurIPS 2022 Workshop on Meta-Learning. Full version currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06640" title="Abstract">arXiv:2212.06640</a> (replaced) [<a href="/pdf/2212.06640" title="Download PDF">pdf</a>, <a href="/format/2212.06640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interaction graph-based characterization of quantum benchmarks for  improving quantum circuit mapping techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bandi%C4%87%2C+M">Medina Bandi&#x107;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Almudever%2C+C+G">Carmen G. Almudever</a>, 
<a href="/search/quant-ph?searchtype=author&query=Feld%2C+S">Sebastian Feld</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Quantum Machine Intelligence 5, Article number: 40 (2023), 5-40
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00950" title="Abstract">arXiv:2301.00950</a> (replaced) [<a href="/pdf/2301.00950" title="Download PDF">pdf</a>, <a href="/format/2301.00950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Continuous Conditional Generative Neural Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiwook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minhyeok Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC 2023 (Accepted)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02607" title="Abstract">arXiv:2301.02607</a> (replaced) [<a href="/pdf/2301.02607" title="Download PDF">pdf</a>, <a href="/ps/2301.02607" title="Download PostScript">ps</a>, <a href="/format/2301.02607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-Driven Gaussian Process Filter for Electrocardiogram Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dumitru%2C+M">Mircea Dumitru</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Q">Qiao Li</a>, 
<a href="/search/eess?searchtype=author&query=Alday%2C+E+A+P">Erick Andres Perez Alday</a>, 
<a href="/search/eess?searchtype=author&query=Rad%2C+A+B">Ali Bahrami Rad</a>, 
<a href="/search/eess?searchtype=author&query=Clifford%2C+G+D">Gari D. Clifford</a>, 
<a href="/search/eess?searchtype=author&query=Sameni%2C+R">Reza Sameni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03221" title="Abstract">arXiv:2301.03221</a> (replaced) [<a href="/pdf/2301.03221" title="Download PDF">pdf</a>, <a href="/format/2301.03221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing Matroids over the Reals is $\exists \mathbb R$-complete
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+E">Eunjung Kim</a>, 
<a href="/search/cs?searchtype=author&query=de+Mesmay%2C+A">Arnaud de Mesmay</a>, 
<a href="/search/cs?searchtype=author&query=Miltzow%2C+T">Tillmann Miltzow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2 and v3: Minor changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13337" title="Abstract">arXiv:2301.13337</a> (replaced) [<a href="/e-print/2301.13337" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAFD: Domain Adaptation via Feature Disentanglement for Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhize Wu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Changjiang Du</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+L">Le Zou</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Ming Tan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F">Fan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Nian%2C+F">Fudong Nian</a>, 
<a href="/search/cs?searchtype=author&query=Weise%2C+T">Thomas Weise</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update the experimental results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01680" title="Abstract">arXiv:2302.01680</a> (replaced) [<a href="/pdf/2302.01680" title="Download PDF">pdf</a>, <a href="/format/2302.01680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Stage Constrained Actor-Critic for Short Video Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Q">Qingpeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhenghai Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wanqi Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuchang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+R">Ruohan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+T">Tianyou Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wentao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Kun Gai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code Available at <a href="https://github.com/AIDefender/TSCAC.">this https URL</a> arXiv admin note: substantial text overlap with <a href="/abs/2205.13248">arXiv:2205.13248</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Web Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06188" title="Abstract">arXiv:2302.06188</a> (replaced) [<a href="/pdf/2302.06188" title="Download PDF">pdf</a>, <a href="/format/2302.06188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing SMT-based Weighted Model Integration by Structure Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spallitta%2C+G">Giuseppe Spallitta</a>, 
<a href="/search/cs?searchtype=author&query=Masina%2C+G">Gabriele Masina</a>, 
<a href="/search/cs?searchtype=author&query=Morettin%2C+P">Paolo Morettin</a>, 
<a href="/search/cs?searchtype=author&query=Passerini%2C+A">Andrea Passerini</a>, 
<a href="/search/cs?searchtype=author&query=Sebastiani%2C+R">Roberto Sebastiani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09580" title="Abstract">arXiv:2302.09580</a> (replaced) [<a href="/pdf/2302.09580" title="Download PDF">pdf</a>, <a href="/format/2302.09580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-separable Covariance Kernels for Spatiotemporal Gaussian Processes  based on a Hybrid Spectral Method and the Harmonic Oscillator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hristopulos%2C+D+T">Dionissios T.Hristopulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 12 figures, five appendices, Supplement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09717" title="Abstract">arXiv:2302.09717</a> (replaced) [<a href="/pdf/2302.09717" title="Download PDF">pdf</a>, <a href="/ps/2302.09717" title="Download PostScript">ps</a>, <a href="/format/2302.09717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinating Multiple Intelligent Reflecting Surfaces without Channel  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+W">Wenhai Lai</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+K">Kaiming Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhi-Quan Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Signal Processing 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10639" title="Abstract">arXiv:2302.10639</a> (replaced) [<a href="/pdf/2302.10639" title="Download PDF">pdf</a>, <a href="/format/2302.10639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Handling Long and Richly Constrained Tasks through Constrained  Hierarchical Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuxiao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Arunesh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Varakantham%2C+P">Pradeep Varakantham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00323" title="Abstract">arXiv:2303.00323</a> (replaced) [<a href="/pdf/2303.00323" title="Download PDF">pdf</a>, <a href="/format/2303.00323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeFNet: Deconstructed Strategy for Multi-step Fabric Folding Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ningquan Gu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruhan He</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lianqing Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06165" title="Abstract">arXiv:2303.06165</a> (replaced) [<a href="/pdf/2303.06165" title="Download PDF">pdf</a>, <a href="/format/2303.06165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Model Predictive Control for Cooperative Transportation and  Manipulation of Cable Suspended Payloads with Multiple Quadrotors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Loianno%2C+G">Giuseppe Loianno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been presented in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023. Please cite the paper with the appropriate formats
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07545" title="Abstract">arXiv:2303.07545</a> (replaced) [<a href="/pdf/2303.07545" title="Download PDF">pdf</a>, <a href="/format/2303.07545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit and Explicit Commonsense for Multi-sentence Video Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chou%2C+S">Shih-Han Chou</a>, 
<a href="/search/cs?searchtype=author&query=Little%2C+J+J">James J. Little</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+L">Leonid Sigal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is under consideration at Computer Vision and Image Understanding Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08945" title="Abstract">arXiv:2303.08945</a> (replaced) [<a href="/pdf/2303.08945" title="Download PDF">pdf</a>, <a href="/format/2303.08945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concepts of Dimension for Convex Geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Knauer%2C+K">Kolja Knauer</a>, 
<a href="/search/math?searchtype=author&query=Trotter%2C+W+T">William T. Trotter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12447" title="Abstract">arXiv:2303.12447</a> (replaced) [<a href="/pdf/2303.12447" title="Download PDF">pdf</a>, <a href="/format/2303.12447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSRX: A novel Crossover Operator for a Genetic Algorithm applied to the  Traveling Salesperson Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uray%2C+M">Martin Uray</a>, 
<a href="/search/cs?searchtype=author&query=Wintersteller%2C+S">Stefan Wintersteller</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+S">Stefan Huber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this contribution is published and is available online at <a href="https://doi.org/10.1007/978-3-031-42171-6_3">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15225" title="Abstract">arXiv:2303.15225</a> (replaced) [<a href="/pdf/2303.15225" title="Download PDF">pdf</a>, <a href="/format/2303.15225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GP-PCS: One-shot Feature-Preserving Point Cloud Simplification with  Gaussian Processes on Riemannian Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pathak%2C+S">Stuti Pathak</a>, 
<a href="/search/cs?searchtype=author&query=McDonald%2C+T+M">Thomas M. McDonald</a>, 
<a href="/search/cs?searchtype=author&query=Sels%2C+S">Seppe Sels</a>, 
<a href="/search/cs?searchtype=author&query=Penne%2C+R">Rudi Penne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17408" title="Abstract">arXiv:2303.17408</a> (replaced) [<a href="/pdf/2303.17408" title="Download PDF">pdf</a>, <a href="/format/2303.17408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P-Transformer: A Prompt-based Multimodal Transformer Architecture For  Medical Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruan%2C+Y">Yucheng Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+X">Xiang Lan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+D+J">Daniel J. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+H+R">Hairil Rizal Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Mengling Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01075" title="Abstract">arXiv:2304.01075</a> (replaced) [<a href="/pdf/2304.01075" title="Download PDF">pdf</a>, <a href="/format/2304.01075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Prediction Regions for Time Series using Linear  Complementarity Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cleaveland%2C+M">Matthew Cleaveland</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+I">Insup Lee</a>, 
<a href="/search/eess?searchtype=author&query=Pappas%2C+G+J">George J. Pappas</a>, 
<a href="/search/eess?searchtype=author&query=Lindemann%2C+L">Lars Lindemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01561" title="Abstract">arXiv:2304.01561</a> (replaced) [<a href="/pdf/2304.01561" title="Download PDF">pdf</a>, <a href="/format/2304.01561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal rates of approximation by shallow ReLU$^k$ neural networks and  applications to nonparametric regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yang%2C+Y">Yunfei Yang</a>, 
<a href="/search/stat?searchtype=author&query=Zhou%2C+D">Ding-Xuan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version 3 improves some approximation bounds by using recent results from <a href="/abs/2307.15285">arXiv:2307.15285</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01899" title="Abstract">arXiv:2304.01899</a> (replaced) [<a href="/pdf/2304.01899" title="Download PDF">pdf</a>, <a href="/format/2304.01899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Class Feature Augmentation for Class Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaeyoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bohyung Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04232" title="Abstract">arXiv:2304.04232</a> (replaced) [<a href="/pdf/2304.04232" title="Download PDF">pdf</a>, <a href="/format/2304.04232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate Adaptation in Delay-Sensitive and Energy-Constrained Large-Scale  IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emara%2C+M">Mostafa Emara</a>, 
<a href="/search/cs?searchtype=author&query=Kouzayha%2C+N">Nour Kouzayha</a>, 
<a href="/search/cs?searchtype=author&query=ElSawy%2C+H">Hesham ElSawy</a>, 
<a href="/search/cs?searchtype=author&query=Al-Naffouri%2C+T+Y">Tareq Y. Al-Naffouri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06910" title="Abstract">arXiv:2304.06910</a> (replaced) [<a href="/pdf/2304.06910" title="Download PDF">pdf</a>, <a href="/format/2304.06910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HCAM -- Hierarchical Cross Attention Model for Multi-modal Emotion  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dutta%2C+S">Soumya Dutta</a>, 
<a href="/search/eess?searchtype=author&query=Ganapathy%2C+S">Sriram Ganapathy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10819" title="Abstract">arXiv:2304.10819</a> (replaced) [<a href="/pdf/2304.10819" title="Download PDF">pdf</a>, <a href="/format/2304.10819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auditing and Generating Synthetic Data with Controllable Trust  Trade-offs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belgodere%2C+B">Brian Belgodere</a>, 
<a href="/search/cs?searchtype=author&query=Dognin%2C+P">Pierre Dognin</a>, 
<a href="/search/cs?searchtype=author&query=Ivankay%2C+A">Adam Ivankay</a>, 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+I">Igor Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Mroueh%2C+Y">Youssef Mroueh</a>, 
<a href="/search/cs?searchtype=author&query=Mojsilovic%2C+A">Aleksandra Mojsilovic</a>, 
<a href="/search/cs?searchtype=author&query=Navratil%2C+J">Jiri Navratil</a>, 
<a href="/search/cs?searchtype=author&query=Nitsure%2C+A">Apoorva Nitsure</a>, 
<a href="/search/cs?searchtype=author&query=Padhi%2C+I">Inkit Padhi</a>, 
<a href="/search/cs?searchtype=author&query=Rigotti%2C+M">Mattia Rigotti</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+J">Jerret Ross</a>, 
<a href="/search/cs?searchtype=author&query=Schiff%2C+Y">Yair Schiff</a>, 
<a href="/search/cs?searchtype=author&query=Vedpathak%2C+R">Radhika Vedpathak</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+R+A">Richard A. Young</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12422" title="Abstract">arXiv:2304.12422</a> (replaced) [<a href="/pdf/2304.12422" title="Download PDF">pdf</a>, <a href="/format/2304.12422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Source to Multi-Target Decentralized Federated Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Su Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hosseinalipour%2C+S">Seyyedali Hosseinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Transactions on Cognitive Communications and Networking
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12760" title="Abstract">arXiv:2304.12760</a> (replaced) [<a href="/pdf/2304.12760" title="Download PDF">pdf</a>, <a href="/format/2304.12760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Spiking Neurons with High Efficiency and Ability to Learn  Long-term Dependencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+W">Wei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhaofei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhaokun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Ding Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhengyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Masquelier%2C+T">Timoth&#xe9;e Masquelier</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yonghong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12858" title="Abstract">arXiv:2304.12858</a> (replaced) [<a href="/pdf/2304.12858" title="Download PDF">pdf</a>, <a href="/format/2304.12858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unpaired Image Translation to Mitigate Domain Shift in Liquid Argon Time  Projection Chamber Detector Responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Huang%2C+Y">Yi Huang</a>, 
<a href="/search/hep-ex?searchtype=author&query=Torbunov%2C+D">Dmitrii Torbunov</a>, 
<a href="/search/hep-ex?searchtype=author&query=Viren%2C+B">Brett Viren</a>, 
<a href="/search/hep-ex?searchtype=author&query=Yu%2C+H">Haiwang Yu</a>, 
<a href="/search/hep-ex?searchtype=author&query=Huang%2C+J">Jin Huang</a>, 
<a href="/search/hep-ex?searchtype=author&query=Lin%2C+M">Meifeng Lin</a>, 
<a href="/search/hep-ex?searchtype=author&query=Ren%2C+Y">Yihui Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14811" title="Abstract">arXiv:2304.14811</a> (replaced) [<a href="/pdf/2304.14811" title="Download PDF">pdf</a>, <a href="/format/2304.14811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRF-LiDAR: Generating Realistic LiDAR Point Clouds with Neural Radiance  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feihu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+S">Shaochen Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03292" title="Abstract">arXiv:2305.03292</a> (replaced) [<a href="/pdf/2305.03292" title="Download PDF">pdf</a>, <a href="/format/2305.03292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedNC: A Secure and Efficient Federated Learning Method with Network  Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuchen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+P">Pingyi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Letaief%2C+K+B">Khaled B. Letaief</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chenghui Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05440" title="Abstract">arXiv:2305.05440</a> (replaced) [<a href="/pdf/2305.05440" title="Download PDF">pdf</a>, <a href="/format/2305.05440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Screen Content Coding in VVC Using Soft Context Formation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Och%2C+H">Hannah Och</a> (1), 
<a href="/search/eess?searchtype=author&query=Uddehal%2C+S+R">Shabhrish Reddy Uddehal</a> (1 and 2), 
<a href="/search/eess?searchtype=author&query=Strutz%2C+T">Tilo Strutz</a> (2), 
<a href="/search/eess?searchtype=author&query=Kaup%2C+A">Andr&#xe9; Kaup</a> (1) ((1) Friedrich-Alexander Universit&#xe4;t Erlangen-N&#xfc;rnberg, (2) Hochschule f&#xfc;r angewandte Wissenschaften Coburg)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, 2 tables; accepted for IEEE International Conference on Acoustics, Speech and Signal Processing 2024 (IEEE ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05973" title="Abstract">arXiv:2305.05973</a> (replaced) [<a href="/pdf/2305.05973" title="Download PDF">pdf</a>, <a href="/format/2305.05973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Query Generation for Privacy-Preserving Deep Retrieval Systems  using Differentially Private Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carranza%2C+A+G">Aldo Gael Carranza</a>, 
<a href="/search/cs?searchtype=author&query=Farahani%2C+R">Rezsa Farahani</a>, 
<a href="/search/cs?searchtype=author&query=Ponomareva%2C+N">Natalia Ponomareva</a>, 
<a href="/search/cs?searchtype=author&query=Kurakin%2C+A">Alex Kurakin</a>, 
<a href="/search/cs?searchtype=author&query=Jagielski%2C+M">Matthew Jagielski</a>, 
<a href="/search/cs?searchtype=author&query=Nasr%2C+M">Milad Nasr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07525" title="Abstract">arXiv:2305.07525</a> (replaced) [<a href="/pdf/2305.07525" title="Download PDF">pdf</a>, <a href="/ps/2305.07525" title="Download PostScript">ps</a>, <a href="/format/2305.07525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Truthful Two-Facility Location with Candidate Locations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanellopoulos%2C+P">Panagiotis Kanellopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Voudouris%2C+A+A">Alexandros A. Voudouris</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongsen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08738" title="Abstract">arXiv:2305.08738</a> (replaced) [<a href="/pdf/2305.08738" title="Download PDF">pdf</a>, <a href="/ps/2305.08738" title="Download PostScript">ps</a>, <a href="/format/2305.08738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Based Combinatorial Optimization for Optimal Sensor Placement in  Civil Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Silva%2C+G+S+M">Gabriel San Martin Silva</a>, 
<a href="/search/eess?searchtype=author&query=Droguett%2C+E+L">Enrique Lopez Droguett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10406" title="Abstract">arXiv:2305.10406</a> (replaced) [<a href="/pdf/2305.10406" title="Download PDF">pdf</a>, <a href="/format/2305.10406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhuliawala%2C+S">Shehzaad Dhuliawala</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+C">Carl Allen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TMLR: <a href="https://openreview.net/forum?id=EWv9XGOpB3">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12021" title="Abstract">arXiv:2305.12021</a> (replaced) [<a href="/pdf/2305.12021" title="Download PDF">pdf</a>, <a href="/format/2305.12021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Secure and Robust Approach for Distance-Based Mutual Positioning of  Unmanned Aerial Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Han%2C+B">Bin Han</a>, 
<a href="/search/eess?searchtype=author&query=Schotten%2C+H+D">Hans D. Schotten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the IEEE WCNC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13035" title="Abstract">arXiv:2305.13035</a> (replaced) [<a href="/pdf/2305.13035" title="Download PDF">pdf</a>, <a href="/format/2305.13035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alabdulmohsin%2C+I">Ibrahim Alabdulmohsin</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaohua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+A">Alexander Kolesnikov</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+L">Lucas Beyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, 9 tables. Version 2: Layout fixes
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Conference on Neural Information Processing Systems (NeurIPS
  2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14093" title="Abstract">arXiv:2305.14093</a> (replaced) [<a href="/pdf/2305.14093" title="Download PDF">pdf</a>, <a href="/format/2305.14093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised 3D Open-vocabulary Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kunhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+F">Fangneng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Muyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yingchen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15747" title="Abstract">arXiv:2305.15747</a> (replaced) [<a href="/pdf/2305.15747" title="Download PDF">pdf</a>, <a href="/format/2305.15747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Union Subgraph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaxing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Aihu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+Q">Qingtian Bian</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+V+P">Vijay Prakash Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Y">Yiping Ke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16645" title="Abstract">arXiv:2305.16645</a> (replaced) [<a href="/pdf/2305.16645" title="Download PDF">pdf</a>, <a href="/format/2305.16645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Summarizing Stream Data for Memory-Constrained Online Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jianyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16713" title="Abstract">arXiv:2305.16713</a> (replaced) [<a href="/pdf/2305.16713" title="Download PDF">pdf</a>, <a href="/format/2305.16713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReConPatch : Contrastive Patch Representation Learning for Industrial  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyun%2C+J">Jeeho Hyun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+G">Giyoung Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+H">Seung Hwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+K">Kyunghoon Bae</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B+J">Byung Jun Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, supplementary added. Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024, pp. 2052-2061
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF Winter Conference on Applications of
  Computer Vision (WACV), 2024, pp. 2052-2061
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17630" title="Abstract">arXiv:2305.17630</a> (replaced) [<a href="/pdf/2305.17630" title="Download PDF">pdf</a>, <a href="/ps/2305.17630" title="Download PostScript">ps</a>, <a href="/format/2305.17630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving quantum optimal control problems using projection-operator-based  Newton steps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shao%2C+J">Jieqiu Shao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Naris%2C+M">Mantas Naris</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hauser%2C+J">John Hauser</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nicotra%2C+M+M">Marco M. Nicotra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. A 109 (2024) 012609
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00461" title="Abstract">arXiv:2306.00461</a> (replaced) [<a href="/pdf/2306.00461" title="Download PDF">pdf</a>, <a href="/format/2306.00461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disjoint Partial Enumeration without Blocking Clauses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spallitta%2C+G">Giuseppe Spallitta</a>, 
<a href="/search/cs?searchtype=author&query=Sebastiani%2C+R">Roberto Sebastiani</a>, 
<a href="/search/cs?searchtype=author&query=Biere%2C+A">Armin Biere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02285" title="Abstract">arXiv:2306.02285</a> (replaced) [<a href="/pdf/2306.02285" title="Download PDF">pdf</a>, <a href="/format/2306.02285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clarify Confused Nodes Through Separated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiajun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shengbo Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chenxuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shanqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Q">Qi Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoniu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06734" title="Abstract">arXiv:2306.06734</a> (replaced) [<a href="/pdf/2306.06734" title="Download PDF">pdf</a>, <a href="/ps/2306.06734" title="Download PostScript">ps</a>, <a href="/format/2306.06734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLE-based Device Activity Detection under Rician Fading for Massive  Grant-free Access with Perfect and Imperfect Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Ying Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Feng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Lianghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jun Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07551" title="Abstract">arXiv:2306.07551</a> (replaced) [<a href="/pdf/2306.07551" title="Download PDF">pdf</a>, <a href="/ps/2306.07551" title="Download PostScript">ps</a>, <a href="/format/2306.07551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Explicit Constant-Degree Lossless Expanders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Golowich%2C+L">Louis Golowich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Edits to exposition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11614" title="Abstract">arXiv:2306.11614</a> (replaced) [<a href="/pdf/2306.11614" title="Download PDF">pdf</a>, <a href="/ps/2306.11614" title="Download PostScript">ps</a>, <a href="/format/2306.11614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the power of counting the total number of computation paths of NPTMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakali%2C+E">Eleni Bakali</a>, 
<a href="/search/cs?searchtype=author&query=Chalki%2C+A">Aggeliki Chalki</a>, 
<a href="/search/cs?searchtype=author&query=Kanellopoulos%2C+S">Sotiris Kanellopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Pagourtzis%2C+A">Aris Pagourtzis</a>, 
<a href="/search/cs?searchtype=author&query=Zachos%2C+S">Stathis Zachos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11980" title="Abstract">arXiv:2306.11980</a> (replaced) [<a href="/pdf/2306.11980" title="Download PDF">pdf</a>, <a href="/format/2306.11980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-based Smart Reply (LSR): Enhancing Collaborative Performance with  ChatGPT-mediated Smart Reply System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bastola%2C+A">Ashish Bastola</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hembree%2C+J">Judsen Hembree</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+P">Pooja Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+E">Emma Dixon</a>, 
<a href="/search/cs?searchtype=author&query=Razi%2C+A">Abolfazl Razi</a>, 
<a href="/search/cs?searchtype=author&query=McNeese%2C+N">Nathan McNeese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12867" title="Abstract">arXiv:2306.12867</a> (replaced) [<a href="/pdf/2306.12867" title="Download PDF">pdf</a>, <a href="/ps/2306.12867" title="Download PostScript">ps</a>, <a href="/format/2306.12867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wind Noise Reduction with a Diffusion-based Stochastic Regeneration  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lemercier%2C+J">Jean-Marie Lemercier</a>, 
<a href="/search/eess?searchtype=author&query=Thiemann%2C+J">Joachim Thiemann</a>, 
<a href="/search/eess?searchtype=author&query=Koning%2C+R">Raphael Koning</a>, 
<a href="/search/eess?searchtype=author&query=Gerkmann%2C+T">Timo Gerkmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to VDE 15th ITG conference on Speech Communication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16741" title="Abstract">arXiv:2306.16741</a> (replaced) [<a href="/pdf/2306.16741" title="Download PDF">pdf</a>, <a href="/format/2306.16741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Model for Endoscopy Video Analysis via Large-scale  Self-supervised Pre-train
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023 camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17486" title="Abstract">arXiv:2306.17486</a> (replaced) [<a href="/pdf/2306.17486" title="Download PDF">pdf</a>, <a href="/format/2306.17486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multigrid-Augmented Deep Learning Preconditioners for the Helmholtz  Equation using Compact Implicit Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lerer%2C+B">Bar Lerer</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Yair%2C+I">Ido Ben-Yair</a>, 
<a href="/search/cs?searchtype=author&query=Treister%2C+E">Eran Treister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to SIAM Journal on Scientific Computing Copper Mountain Special Section on Multigrid Methods 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03004" title="Abstract">arXiv:2307.03004</a> (replaced) [<a href="/pdf/2307.03004" title="Download PDF">pdf</a>, <a href="/ps/2307.03004" title="Download PostScript">ps</a>, <a href="/format/2307.03004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and design of model predictive control frameworks for dynamic  operation -- An overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=K%C3%B6hler%2C+J">Johannes K&#xf6;hler</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthas A. M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Allg%C3%B6wer%2C+F">Frank Allg&#xf6;wer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the accepted version of the paper in Annual Reviews in Control, 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Annual Reviews in Control (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03992" title="Abstract">arXiv:2307.03992</a> (replaced) [<a href="/pdf/2307.03992" title="Download PDF">pdf</a>, <a href="/format/2307.03992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stimulating the Diffusion Model for Image Denoising via Adaptive  Embedding and Ensembling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tong Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hansen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lizhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hua Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages,14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04500" title="Abstract">arXiv:2307.04500</a> (replaced) [<a href="/pdf/2307.04500" title="Download PDF">pdf</a>, <a href="/ps/2307.04500" title="Download PostScript">ps</a>, <a href="/format/2307.04500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Academic Plan Derived from Articulation Agreements: A  Preliminary Experiment on Human-Generated and (Hypothetical)  Algorithm-Generated Academic Plans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+V">David V. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Doroudi%2C+S">Shayan Doroudi</a>, 
<a href="/search/cs?searchtype=author&query=Epstein%2C+D+A">Daniel A. Epstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06093" title="Abstract">arXiv:2307.06093</a> (replaced) [<a href="/pdf/2307.06093" title="Download PDF">pdf</a>, <a href="/format/2307.06093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Laplace Model Selection Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J+A">Jihao Andreas Lin</a>, 
<a href="/search/cs?searchtype=author&query=Antor%C3%A1n%2C+J">Javier Antor&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Advances in Approximate Bayesian Inference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11075" title="Abstract">arXiv:2307.11075</a> (replaced) [<a href="/pdf/2307.11075" title="Download PDF">pdf</a>, <a href="/format/2307.11075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Photonic Component Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Witt%2C+D">Donald Witt</a>, 
<a href="/search/physics?searchtype=author&query=Young%2C+J">Jeff Young</a>, 
<a href="/search/physics?searchtype=author&query=Chrostowski%2C+L">Lukas Chrostowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published version: 9 pages, 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> APL Photonics 8, 106101 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Machine Learning (cs.LG); Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11423" title="Abstract">arXiv:2307.11423</a> (replaced) [<a href="/pdf/2307.11423" title="Download PDF">pdf</a>, <a href="/format/2307.11423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention to Entropic Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=En%C3%9Flin%2C+T">Torsten En&#xdf;lin</a>, 
<a href="/search/cs?searchtype=author&query=Weidinger%2C+C">Carolin Weidinger</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+P">Philipp Frank</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 4 figures, re-submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12602" title="Abstract">arXiv:2307.12602</a> (replaced) [<a href="/pdf/2307.12602" title="Download PDF">pdf</a>, <a href="/ps/2307.12602" title="Download PostScript">ps</a>, <a href="/format/2307.12602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shortest two disjoint paths in conservative graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlotter%2C+I">Ildik&#xf3; Schlotter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A version of this paper has been accepted to the 41st International Symposium on Theoretical Aspects of Computer Science (STACS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14277" title="Abstract">arXiv:2307.14277</a> (replaced) [<a href="/pdf/2307.14277" title="Download PDF">pdf</a>, <a href="/format/2307.14277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G2L: Semantically Aligned and Uniform Video Grounding via Geodesic and  Game Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Meng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xuxin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yuexian Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023 oral, release the code
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15557" title="Abstract">arXiv:2307.15557</a> (replaced) [<a href="/pdf/2307.15557" title="Download PDF">pdf</a>, <a href="/format/2307.15557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic algorithms for k-center on graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruciani%2C+E">Emilio Cruciani</a>, 
<a href="/search/cs?searchtype=author&query=Forster%2C+S">Sebastian Forster</a>, 
<a href="/search/cs?searchtype=author&query=Goranci%2C+G">Gramoz Goranci</a>, 
<a href="/search/cs?searchtype=author&query=Nazari%2C+Y">Yasamin Nazari</a>, 
<a href="/search/cs?searchtype=author&query=Skarlatos%2C+A">Antonis Skarlatos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02053" title="Abstract">arXiv:2308.02053</a> (replaced) [<a href="/pdf/2308.02053" title="Download PDF">pdf</a>, <a href="/format/2308.02053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Unequal Opportunities of Large Language Models: Revealing  Demographic Bias through Job Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salinas%2C+A">Abel Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+P+V">Parth Vipul Shah</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuzhong Huang</a>, 
<a href="/search/cs?searchtype=author&query=McCormack%2C+R">Robert McCormack</a>, 
<a href="/search/cs?searchtype=author&query=Morstatter%2C+F">Fred Morstatter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EAAMO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02377" title="Abstract">arXiv:2308.02377</a> (replaced) [<a href="/pdf/2308.02377" title="Download PDF">pdf</a>, <a href="/ps/2308.02377" title="Download PostScript">ps</a>, <a href="/format/2308.02377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sowing &#x27;Seeds of Doubt&#x27;: Cottage Industries of Election and Medical  Misinformation in Brazil and the United States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassoun%2C+A">Amelia Hassoun</a>, 
<a href="/search/cs?searchtype=author&query=Borenstein%2C+G">Gabrielle Borenstein</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+B">Beth Goldberg</a>, 
<a href="/search/cs?searchtype=author&query=McAuliffe%2C+J">Jacob McAuliffe</a>, 
<a href="/search/cs?searchtype=author&query=Osborn%2C+K">Katy Osborn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 13 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05082" title="Abstract">arXiv:2308.05082</a> (replaced) [<a href="/pdf/2308.05082" title="Download PDF">pdf</a>, <a href="/format/2308.05082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning of discrete models of variational PDEs from data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Offen%2C+C">Christian Offen</a>, 
<a href="/search/math?searchtype=author&query=Ober-Bl%C3%B6baum%2C+S">Sina Ober-Bl&#xf6;baum</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Chaos 34 (1), 013104 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09767" title="Abstract">arXiv:2308.09767</a> (replaced) [<a href="/pdf/2308.09767" title="Download PDF">pdf</a>, <a href="/ps/2308.09767" title="Download PostScript">ps</a>, <a href="/format/2308.09767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Stochastic Rewards Reduce to Deterministic Rewards in Online  Bipartite Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Udwani%2C+R">Rajan Udwani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10393" title="Abstract">arXiv:2308.10393</a> (replaced) [<a href="/pdf/2308.10393" title="Download PDF">pdf</a>, <a href="/format/2308.10393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposition-based Hierarchical Task Allocation and Planning for  Multi-Robots under Hierarchical Temporal Logic Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xusheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaojun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13838" title="Abstract">arXiv:2308.13838</a> (replaced) [<a href="/pdf/2308.13838" title="Download PDF">pdf</a>, <a href="/format/2308.13838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Price-Discrimination Game for Distributed Resource Management in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Halvin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guopeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14512" title="Abstract">arXiv:2308.14512</a> (replaced) [<a href="/pdf/2308.14512" title="Download PDF">pdf</a>, <a href="/ps/2308.14512" title="Download PostScript">ps</a>, <a href="/format/2308.14512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A time-causal and time-recursive analogue of the Gabor transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lindeberg%2C+T">Tony Lindeberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 figures, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15053" title="Abstract">arXiv:2308.15053</a> (replaced) [<a href="/pdf/2308.15053" title="Download PDF">pdf</a>, <a href="/format/2308.15053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Text-based Dialogue State Tracker for Spoken Dialogues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jaeseok Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Seunghyun Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+R">Ran Han</a>, 
<a href="/search/cs?searchtype=author&query=Bang%2C+J">Jeonguk Bang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kee-Eung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, In Proceedings of The Eleventh Dialog System Technology Challenge, Association for Computational Linguistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15197" title="Abstract">arXiv:2308.15197</a> (replaced) [<a href="/pdf/2308.15197" title="Download PDF">pdf</a>, <a href="/format/2308.15197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where Would I Go Next? Large Language Models as Human Mobility  Predictors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinglei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zichao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T">Tao Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Major changes: Used the entire FSQ-NYC dataset (table 1). Used Geolife for ablation study (figure 5). Incorporated time-unknown prediction performance (table 2), robustness testing(section 5.6), and ethical statement (appendix). Reformatted the paper using double column template
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16031" title="Abstract">arXiv:2308.16031</a> (replaced) [<a href="/pdf/2308.16031" title="Download PDF">pdf</a>, <a href="/format/2308.16031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking the Interference and Fading Gridlock in Backscatter  Communications: State-of-the-Art, Design Challenges, and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Bowen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Haiyang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gongpu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tellambura%2C+C">Chintha Tellambura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02281" title="Abstract">arXiv:2309.02281</a> (replaced) [<a href="/pdf/2309.02281" title="Download PDF">pdf</a>, <a href="/ps/2309.02281" title="Download PostScript">ps</a>, <a href="/format/2309.02281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> s-ID: Causal Effect Identification in a Sub-Population
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abouei%2C+A+M">Amir Mohammad Abouei</a>, 
<a href="/search/cs?searchtype=author&query=Mokhtarian%2C+E">Ehsan Mokhtarian</a>, 
<a href="/search/cs?searchtype=author&query=Kiyavash%2C+N">Negar Kiyavash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 15 figures, 1 table, To appear in AAAI 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06143" title="Abstract">arXiv:2309.06143</a> (replaced) [<a href="/pdf/2309.06143" title="Download PDF">pdf</a>, <a href="/format/2309.06143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Generalization Capability of Deep Learning-Based Nuclei  Instance Segmentation by Non-deterministic Train Time and Deterministic Test  Time Stain Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mahbod%2C+A">Amirreza Mahbod</a>, 
<a href="/search/eess?searchtype=author&query=Dorffner%2C+G">Georg Dorffner</a>, 
<a href="/search/eess?searchtype=author&query=Ellinger%2C+I">Isabella Ellinger</a>, 
<a href="/search/eess?searchtype=author&query=Woitek%2C+R">Ramona Woitek</a>, 
<a href="/search/eess?searchtype=author&query=Hatamikia%2C+S">Sepideh Hatamikia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Computational and Structural Biotechnology Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06212" title="Abstract">arXiv:2309.06212</a> (replaced) [<a href="/pdf/2309.06212" title="Download PDF">pdf</a>, <a href="/format/2309.06212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-term drought prediction using deep neural networks based on  geospatial weather data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grabar%2C+V">Vsevolod Grabar</a>, 
<a href="/search/cs?searchtype=author&query=Marusov%2C+A">Alexander Marusov</a>, 
<a href="/search/cs?searchtype=author&query=Maximov%2C+Y">Yury Maximov</a>, 
<a href="/search/cs?searchtype=author&query=Sotiriadi%2C+N">Nazar Sotiriadi</a>, 
<a href="/search/cs?searchtype=author&query=Bulkin%2C+A">Alexander Bulkin</a>, 
<a href="/search/cs?searchtype=author&query=Zaytsev%2C+A">Alexey Zaytsev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06858" title="Abstract">arXiv:2309.06858</a> (replaced) [<a href="/pdf/2309.06858" title="Download PDF">pdf</a>, <a href="/format/2309.06858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMALG: An Enhanced Mandarin Lombard Grid Corpus with Meaningful  Sentences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingmu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+W">Weiping Tu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Song Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06861" title="Abstract">arXiv:2309.06861</a> (replaced) [<a href="/pdf/2309.06861" title="Download PDF">pdf</a>, <a href="/format/2309.06861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TTD Configurations for Near-Field Beamforming: Parallel, Serial, or  Hybrid?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xidong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Schober%2C+R">Robert Schober</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07254" title="Abstract">arXiv:2309.07254</a> (replaced) [<a href="/pdf/2309.07254" title="Download PDF">pdf</a>, <a href="/format/2309.07254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigate Replication and Copying in Diffusion Models with Generalized  Caption and Dual Fusion Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dake Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Beerel%2C+P+A">Peter A. Beerel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08876" title="Abstract">arXiv:2309.08876</a> (replaced) [<a href="/pdf/2309.08876" title="Download PDF">pdf</a>, <a href="/ps/2309.08876" title="Download PostScript">ps</a>, <a href="/format/2309.08876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoder-only Architecture for Speech Recognition with CTC Prompts and  Text Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tsunoo%2C+E">Emiru Tsunoo</a>, 
<a href="/search/eess?searchtype=author&query=Futami%2C+H">Hayato Futami</a>, 
<a href="/search/eess?searchtype=author&query=Kashiwagi%2C+Y">Yosuke Kashiwagi</a>, 
<a href="/search/eess?searchtype=author&query=Arora%2C+S">Siddhant Arora</a>, 
<a href="/search/eess?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11282" title="Abstract">arXiv:2309.11282</a> (replaced) [<a href="/pdf/2309.11282" title="Download PDF">pdf</a>, <a href="/format/2309.11282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Dataspace Connector Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dam%2C+T">Tobias Dam</a>, 
<a href="/search/cs?searchtype=author&query=Klausner%2C+L+D">Lukas Daniel Klausner</a>, 
<a href="/search/cs?searchtype=author&query=Neumaier%2C+S">Sebastian Neumaier</a>, 
<a href="/search/cs?searchtype=author&query=Priebe%2C+T">Torsten Priebe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, CEUR-WS: <a href="https://ceur-ws.org/Vol-3606/paper41.pdf">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2nd Italian Conference on Big Data and Data
  Science (ITADATA 2023), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13016" title="Abstract">arXiv:2309.13016</a> (replaced) [<a href="/pdf/2309.13016" title="Download PDF">pdf</a>, <a href="/format/2309.13016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Deep Gradient Leakage via Inversion Influence Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haobo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Junyuan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yuyang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi%2C+M">Mehrdad Mahdavi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiayu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 18 figures, accepted to NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14089" title="Abstract">arXiv:2309.14089</a> (replaced) [<a href="/pdf/2309.14089" title="Download PDF">pdf</a>, <a href="/format/2309.14089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiSinger: Bilingual Singing Voice Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Huali Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yueqian Lin</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yao Shi</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+P">Peng Sun</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14345" title="Abstract">arXiv:2309.14345</a> (replaced) [<a href="/pdf/2309.14345" title="Download PDF">pdf</a>, <a href="/format/2309.14345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias Testing and Mitigation in LLM-based Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Dong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+Q">Qingwen Bu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Heming Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Title changed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14618" title="Abstract">arXiv:2309.14618</a> (replaced) [<a href="/pdf/2309.14618" title="Download PDF">pdf</a>, <a href="/format/2309.14618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication games, sequential equilibrium, and mediators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geffner%2C+I">Ivan Geffner</a>, 
<a href="/search/cs?searchtype=author&query=Halpern%2C+J+Y">Joseph Y. Halpern</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15216" title="Abstract">arXiv:2309.15216</a> (replaced) [<a href="/pdf/2309.15216" title="Download PDF">pdf</a>, <a href="/ps/2309.15216" title="Download PostScript">ps</a>, <a href="/format/2309.15216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Study of Filters and Deep Learning Models to predict  Diabetic Retinopathy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muddaluru%2C+R+V">Roshan Vasu Muddaluru</a>, 
<a href="/search/cs?searchtype=author&query=Thoguluva%2C+S+R">Sharvaani Ravikumar Thoguluva</a>, 
<a href="/search/cs?searchtype=author&query=Prabha%2C+S">Shruti Prabha</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+T+K">Tanuja Konda Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Palaniswamy%2C+D+S">Dr. Suja Palaniswamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, I2CT , 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15244" title="Abstract">arXiv:2309.15244</a> (replaced) [<a href="/pdf/2309.15244" title="Download PDF">pdf</a>, <a href="/format/2309.15244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homotopy Relaxation Training Algorithms for Infinite-Width Two-Layer  ReLU Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yahong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qipin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+W">Wenrui Hao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04343" title="Abstract">arXiv:2310.04343</a> (replaced) [<a href="/pdf/2310.04343" title="Download PDF">pdf</a>, <a href="/format/2310.04343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Geometry Guided Protein Sequence and Backbone Structure  Co-Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhenqiao Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunlong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenxian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06441" title="Abstract">arXiv:2310.06441</a> (replaced) [<a href="/pdf/2310.06441" title="Download PDF">pdf</a>, <a href="/ps/2310.06441" title="Download PostScript">ps</a>, <a href="/format/2310.06441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stepwise functional refoundation of relational concept analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Euzenat%2C+J">J&#xe9;r&#xf4;me Euzenat</a> (MOEX )
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> euzenat2023a
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06763" title="Abstract">arXiv:2310.06763</a> (replaced) [<a href="/pdf/2310.06763" title="Download PDF">pdf</a>, <a href="/format/2310.06763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FABind: Fast and Accurate Protein-Ligand Binding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+Q">Qizhi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kaiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lijun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yingce Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shufang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kun He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tie-Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Neural Information Processing Systems 2023 (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07132" title="Abstract">arXiv:2310.07132</a> (replaced) [<a href="/pdf/2310.07132" title="Download PDF">pdf</a>, <a href="/format/2310.07132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk Assessment and Statistical Significance in the Age of Foundation  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nitsure%2C+A">Apoorva Nitsure</a>, 
<a href="/search/cs?searchtype=author&query=Mroueh%2C+Y">Youssef Mroueh</a>, 
<a href="/search/cs?searchtype=author&query=Rigotti%2C+M">Mattia Rigotti</a>, 
<a href="/search/cs?searchtype=author&query=Greenewald%2C+K">Kristjan Greenewald</a>, 
<a href="/search/cs?searchtype=author&query=Belgodere%2C+B">Brian Belgodere</a>, 
<a href="/search/cs?searchtype=author&query=Yurochkin%2C+M">Mikhail Yurochkin</a>, 
<a href="/search/cs?searchtype=author&query=Navratil%2C+J">Jiri Navratil</a>, 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+I">Igor Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+J">Jerret Ross</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Risk Management (q-fin.RM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09388" title="Abstract">arXiv:2310.09388</a> (replaced) [<a href="/pdf/2310.09388" title="Download PDF">pdf</a>, <a href="/format/2310.09388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CORN: Co-Trained Full- And No-Reference Speech Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Manocha%2C+P">Pranay Manocha</a>, 
<a href="/search/eess?searchtype=author&query=Williamson%2C+D">Donald Williamson</a>, 
<a href="/search/eess?searchtype=author&query=Finkelstein%2C+A">Adam Finkelstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11204" title="Abstract">arXiv:2310.11204</a> (replaced) [<a href="/pdf/2310.11204" title="Download PDF">pdf</a>, <a href="/format/2310.11204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Video Deepfake Detection: A DCT-Based Approach with  Patch-Level Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guarnera%2C+L">Luca Guarnera</a> (1), 
<a href="/search/cs?searchtype=author&query=Manganello%2C+S">Salvatore Manganello</a> (1), 
<a href="/search/cs?searchtype=author&query=Battiato%2C+S">Sebastiano Battiato</a> (1) ((1) University of Catania)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11650" title="Abstract">arXiv:2310.11650</a> (replaced) [<a href="/pdf/2310.11650" title="Download PDF">pdf</a>, <a href="/format/2310.11650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VKIE: The Application of Key Information Extraction on Video Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+S">Siyu An</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Haoyuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Di Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12081" title="Abstract">arXiv:2310.12081</a> (replaced) [<a href="/pdf/2310.12081" title="Download PDF">pdf</a>, <a href="/format/2310.12081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical  Optimal Transport Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Haoran Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dixin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongteng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12803" title="Abstract">arXiv:2310.12803</a> (replaced) [<a href="/pdf/2310.12803" title="Download PDF">pdf</a>, <a href="/format/2310.12803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentations for Improved (Large) Language Model Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feder%2C+A">Amir Feder</a>, 
<a href="/search/cs?searchtype=author&query=Wald%2C+Y">Yoav Wald</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Claudia Shi</a>, 
<a href="/search/cs?searchtype=author&query=Saria%2C+S">Suchi Saria</a>, 
<a href="/search/cs?searchtype=author&query=Blei%2C+D">David Blei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14242" title="Abstract">arXiv:2310.14242</a> (replaced) [<a href="/pdf/2310.14242" title="Download PDF">pdf</a>, <a href="/format/2310.14242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composition and substitution of Regularity Structures B-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bruned%2C+Y">Yvain Bruned</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Rings and Algebras (math.RA)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14665" title="Abstract">arXiv:2310.14665</a> (replaced) [<a href="/pdf/2310.14665" title="Download PDF">pdf</a>, <a href="/format/2310.14665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Read Disturbance in High Bandwidth Memory: An Experimental  Analysis of Real HBM2 DRAM Chips
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Osseiran%2C+M">Majd Osseiran</a>, 
<a href="/search/cs?searchtype=author&query=Yaglikci%2C+A+G">Abdullah Giray Yaglikci</a>, 
<a href="/search/cs?searchtype=author&query=Tugrul%2C+Y+C">Yahya Can Tugrul</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haocong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Rhyner%2C+S">Steve Rhyner</a>, 
<a href="/search/cs?searchtype=author&query=Salami%2C+B">Behzad Salami</a>, 
<a href="/search/cs?searchtype=author&query=Luna%2C+J+G">Juan Gomez Luna</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of an earlier DSN Disrupt 2023 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17279" title="Abstract">arXiv:2310.17279</a> (replaced) [<a href="/pdf/2310.17279" title="Download PDF">pdf</a>, <a href="/format/2310.17279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Logical Forms improve fidelity in Table-to-Text generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alonso%2C+I">I&#xf1;igo Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Agirre%2C+E">Eneko Agirre</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems with Applications, Volume 238, Part D, 15 March
  2024, 121869
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17974" title="Abstract">arXiv:2310.17974</a> (replaced) [<a href="/e-print/2310.17974" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model  for Fault Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeren Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jinwen Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The logical flow and background of the article need significant revisions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19991" title="Abstract">arXiv:2310.19991</a> (replaced) [<a href="/pdf/2310.19991" title="Download PDF">pdf</a>, <a href="/format/2310.19991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Minghao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Venkataraman%2C+S">Shivaram Venkataraman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02960" title="Abstract">arXiv:2311.02960</a> (replaced) [<a href="/pdf/2311.02960" title="Download PDF">pdf</a>, <a href="/format/2311.02960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Deep Representation Learning via Layerwise Feature  Compression and Discrimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yaras%2C+C">Can Yaras</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Balzano%2C+L">Laura Balzano</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Q">Qing Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 61 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03600" title="Abstract">arXiv:2311.03600</a> (replaced) [<a href="/pdf/2311.03600" title="Download PDF">pdf</a>, <a href="/format/2311.03600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and Efficient Continual Learning from Demonstration via a  Hypernetwork-generated Stable Dynamics Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Auddy%2C+S">Sayantan Auddy</a>, 
<a href="/search/cs?searchtype=author&query=Hollenstein%2C+J">Jakob Hollenstein</a>, 
<a href="/search/cs?searchtype=author&query=Saveriano%2C+M">Matteo Saveriano</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-S%C3%A1nchez%2C+A">Antonio Rodr&#xed;guez-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Piater%2C+J">Justus Piater</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is currently under peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03975" title="Abstract">arXiv:2311.03975</a> (replaced) [<a href="/pdf/2311.03975" title="Download PDF">pdf</a>, <a href="/format/2311.03975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive 3D Geometry-based Stochastic Channel Prediction for 3D DL  Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zarour%2C+M">Mervat Zarour</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiuheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+S">Sergiy Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Schotten%2C+H+D">Hans D. Schotten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE copyright. This work has been submitted to the IEEE conference for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08516" title="Abstract">arXiv:2311.08516</a> (replaced) [<a href="/pdf/2311.08516" title="Download PDF">pdf</a>, <a href="/format/2311.08516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs cannot find reasoning errors, but can correct them!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyen%2C+G">Gladys Tyen</a>, 
<a href="/search/cs?searchtype=author&query=Mansoor%2C+H">Hassan Mansoor</a>, 
<a href="/search/cs?searchtype=author&query=C%C4%83rbune%2C+V">Victor C&#x103;rbune</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peter Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mak%2C+T">Tony Mak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09088" title="Abstract">arXiv:2311.09088</a> (replaced) [<a href="/pdf/2311.09088" title="Download PDF">pdf</a>, <a href="/format/2311.09088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-ML: Collaborative Machine Learning Model Building for Developing  Dataset Design Practices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tseng%2C+T">Tiffany Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Davidson%2C+M+J">Matt J. Davidson</a>, 
<a href="/search/cs?searchtype=author&query=Morales-Navarro%2C+L">Luis Morales-Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+K">Jennifer King Chen</a>, 
<a href="/search/cs?searchtype=author&query=Delaney%2C+V">Victoria Delaney</a>, 
<a href="/search/cs?searchtype=author&query=Leibowitz%2C+M">Mark Leibowitz</a>, 
<a href="/search/cs?searchtype=author&query=Beason%2C+J">Jazbo Beason</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+R+B">R. Benjamin Shapiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12241" title="Abstract">arXiv:2311.12241</a> (replaced) [<a href="/pdf/2311.12241" title="Download PDF">pdf</a>, <a href="/format/2311.12241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InteraSSort: Interactive Assortment Planning Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karra%2C+S+R">Saketh Reddy Karra</a>, 
<a href="/search/cs?searchtype=author&query=Tulabandhula%2C+T">Theja Tulabandhula</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13964" title="Abstract">arXiv:2311.13964</a> (replaced) [<a href="/pdf/2311.13964" title="Download PDF">pdf</a>, <a href="/format/2311.13964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Interactive Segmentation of Medical Images: A Systematic Review and  Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Marinov%2C+Z">Zdravko Marinov</a>, 
<a href="/search/eess?searchtype=author&query=J%C3%A4ger%2C+P+F">Paul F. J&#xe4;ger</a>, 
<a href="/search/eess?searchtype=author&query=Egger%2C+J">Jan Egger</a>, 
<a href="/search/eess?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/eess?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 8 figures, 10 tables; Zdravko Marinov and Paul F. J\"ager and co-first authors; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14295" title="Abstract">arXiv:2311.14295</a> (replaced) [<a href="/pdf/2311.14295" title="Download PDF">pdf</a>, <a href="/ps/2311.14295" title="Download PostScript">ps</a>, <a href="/format/2311.14295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Active RIS in NOMA Networks with Hardware Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xinwei Yue</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Meiqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+C">Chongjun Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tian Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tianwei Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18248" title="Abstract">arXiv:2311.18248</a> (replaced) [<a href="/pdf/2311.18248" title="Download PDF">pdf</a>, <a href="/format/2311.18248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+A">Anwen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yaya Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiabo Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qinghao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Q">Qi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01022" title="Abstract">arXiv:2312.01022</a> (replaced) [<a href="/pdf/2312.01022" title="Download PDF">pdf</a>, <a href="/format/2312.01022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advanced Large Language Model (LLM)-Driven Verilog Development:  Enhancing Power, Performance, and Area Optimization in Code Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thorat%2C+K">Kiran Thorat</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiahui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hongwu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Bin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jeff Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01424" title="Abstract">arXiv:2312.01424</a> (replaced) [<a href="/pdf/2312.01424" title="Download PDF">pdf</a>, <a href="/format/2312.01424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Batch Hop-Constrained s-t Simple Path Query Processing in Large Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Long Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+K">Kongzhang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xuemin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01468" title="Abstract">arXiv:2312.01468</a> (replaced) [<a href="/pdf/2312.01468" title="Download PDF">pdf</a>, <a href="/format/2312.01468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiaoyu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zizhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yushi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenyuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01592" title="Abstract">arXiv:2312.01592</a> (replaced) [<a href="/pdf/2312.01592" title="Download PDF">pdf</a>, <a href="/format/2312.01592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expand BERT Representation with Visual Information via Grounded Language  Learning with Multimodal Partial Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Cong-Duy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu-Le%2C+T">The-Anh Vu-Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+T">Tho Quan</a>, 
<a href="/search/cs?searchtype=author&query=Tuan%2C+L+A">Luu Anh Tuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01840" title="Abstract">arXiv:2312.01840</a> (replaced) [<a href="/e-print/2312.01840" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An AI-based solution for the cold start and data sparsity problems in  the recommendation systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sumit%2C+S+S">Shahriar Shakir Sumit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> want to do experiment on proposed methods
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01964" title="Abstract">arXiv:2312.01964</a> (replaced) [<a href="/e-print/2312.01964" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantics-aware Motion Retargeting with Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haodong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">ZhiKe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haocheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+L">Lei Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaofei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhensong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+R">Rong Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Due to the company policy, this paper should be marked as withdrawn
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02828" title="Abstract">arXiv:2312.02828</a> (replaced) [<a href="/pdf/2312.02828" title="Download PDF">pdf</a>, <a href="/ps/2312.02828" title="Download PostScript">ps</a>, <a href="/format/2312.02828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Rates for Stochastic Approximation: Biased Noise with  Unbounded Variance, and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Karandikar%2C+R+L">Rajeeva L. Karandikar</a>, 
<a href="/search/stat?searchtype=author&query=Vidyasagar%2C+M">M. Vidyasagar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03393" title="Abstract">arXiv:2312.03393</a> (replaced) [<a href="/pdf/2312.03393" title="Download PDF">pdf</a>, <a href="/format/2312.03393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PS$^3$: Precise Patch Presence Test based on Semantic Symbolic Signature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Q">Qi Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanping Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03975" title="Abstract">arXiv:2312.03975</a> (replaced) [<a href="/pdf/2312.03975" title="Download PDF">pdf</a>, <a href="/ps/2312.03975" title="Download PostScript">ps</a>, <a href="/format/2312.03975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The classification of Boolean degree $1$ functions in high-dimensional  finite vector spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ihringer%2C+F">Ferdinand Ihringer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages; added a reference in Section 4; corrected the arXiv version of the abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04265" title="Abstract">arXiv:2312.04265</a> (replaced) [<a href="/pdf/2312.04265" title="Download PDF">pdf</a>, <a href="/format/2312.04265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stronger, Fewer, &amp; Superior: Harnessing Vision Foundation Models for  Domain Generalized Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhixiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianle Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+P">Pengyang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Ben Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jinjin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04333" title="Abstract">arXiv:2312.04333</a> (replaced) [<a href="/pdf/2312.04333" title="Download PDF">pdf</a>, <a href="/format/2312.04333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Bigger and Deeper Always Better? Probing LLaMA Across Scales and  Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Ning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shining Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Linjun Shou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04377" title="Abstract">arXiv:2312.04377</a> (replaced) [<a href="/pdf/2312.04377" title="Download PDF">pdf</a>, <a href="/format/2312.04377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HARQ-IR Aided Short Packet Communications: BLER Analysis and Throughput  Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+F">Fuchao He</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanghua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaofan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xinrong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shaodan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04412" title="Abstract">arXiv:2312.04412</a> (replaced) [<a href="/pdf/2312.04412" title="Download PDF">pdf</a>, <a href="/ps/2312.04412" title="Download PostScript">ps</a>, <a href="/format/2312.04412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing Elementary Federated Learning Algorithms Leveraging the  ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popovic%2C+M">Miroslav Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+M">Marko Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Kastelan%2C+I">Ivan Kastelan</a>, 
<a href="/search/cs?searchtype=author&query=Djukic%2C+M">Miodrag Djukic</a>, 
<a href="/search/cs?searchtype=author&query=Basicevic%2C+I">Ilija Basicevic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 6 tables, submitted to TELFOR 2023, Published by IEEE Xplore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07302" title="Abstract">arXiv:2312.07302</a> (replaced) [<a href="/pdf/2312.07302" title="Download PDF">pdf</a>, <a href="/format/2312.07302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Knowledge Representation to Knowledge Organization and Back
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giunchiglia%2C+F">Fausto Giunchiglia</a>, 
<a href="/search/cs?searchtype=author&query=Bagchi%2C+M">Mayukh Bagchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Information (iConference) 2024 - Wisdom, Well-being, Win-win - Springer LNCS, Springer Cham Switzerland
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Digital Libraries (cs.DL)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07476" title="Abstract">arXiv:2312.07476</a> (replaced) [<a href="/pdf/2312.07476" title="Download PDF">pdf</a>, <a href="/format/2312.07476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparable Demonstrations are Important in In-Context Learning: A Novel  Perspective on Demonstration Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Caoyun Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jidong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yitian Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hao He</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaohui Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09085" title="Abstract">arXiv:2312.09085</a> (replaced) [<a href="/pdf/2312.09085" title="Download PDF">pdf</a>, <a href="/format/2312.09085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Earth is Flat because...: Investigating LLMs&#x27; Belief towards  Misinformation via Persuasive Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rongwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+S">Brian S. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shujian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weiyan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhixuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09559" title="Abstract">arXiv:2312.09559</a> (replaced) [<a href="/pdf/2312.09559" title="Download PDF">pdf</a>, <a href="/format/2312.09559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STEAM &amp; MoSAFE: SOTIF Error-and-Failure Model &amp; Analysis for AI-Enabled  Driving Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Czarnecki%2C+K">Krzysztof Czarnecki</a>, 
<a href="/search/cs?searchtype=author&query=Kuwajima%2C+H">Hiroshi Kuwajima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 13 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11535" title="Abstract">arXiv:2312.11535</a> (replaced) [<a href="/pdf/2312.11535" title="Download PDF">pdf</a>, <a href="/format/2312.11535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customize-It-3D: High-Quality 3D Creation from A Single Image Using  Subject-Specific Knowledge Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Nan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Ting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://nnanhuang.github.io/projects/customize-it-3d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11714" title="Abstract">arXiv:2312.11714</a> (replaced) [<a href="/pdf/2312.11714" title="Download PDF">pdf</a>, <a href="/format/2312.11714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Transformer: Integrating Local and Global Features for Better Time  Series Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuansan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wijewickrema%2C+S">Sudanthi Wijewickrema</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Bester%2C+C">Christofer Bester</a>, 
<a href="/search/cs?searchtype=author&query=O%27Leary%2C+S">Stephen O&#x27;Leary</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+J">James Bailey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures and 16 tables. SDM24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12698" title="Abstract">arXiv:2312.12698</a> (replaced) [<a href="/pdf/2312.12698" title="Download PDF">pdf</a>, <a href="/format/2312.12698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stand-Up Indulgent Gathering on Lines for Myopic Luminous Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bramas%2C+Q">Quentin Bramas</a>, 
<a href="/search/cs?searchtype=author&query=Kakugawa%2C+H">Hirotsugu Kakugawa</a>, 
<a href="/search/cs?searchtype=author&query=Kamei%2C+S">Sayaka Kamei</a>, 
<a href="/search/cs?searchtype=author&query=Lamani%2C+A">Anissa Lamani</a>, 
<a href="/search/cs?searchtype=author&query=Ooshita%2C+F">Fukuhito Ooshita</a>, 
<a href="/search/cs?searchtype=author&query=Shibata%2C+M">Masahiro Shibata</a>, 
<a href="/search/cs?searchtype=author&query=Tixeuil%2C+S">S&#xe9;bastien Tixeuil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14367" title="Abstract">arXiv:2312.14367</a> (replaced) [<a href="/pdf/2312.14367" title="Download PDF">pdf</a>, <a href="/ps/2312.14367" title="Download PostScript">ps</a>, <a href="/format/2312.14367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A force-based higher-order shear beam element model with rational shear  stress distribution for accurate analyses of FG sandwich beams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Suiyin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14725" title="Abstract">arXiv:2312.14725</a> (replaced) [<a href="/pdf/2312.14725" title="Download PDF">pdf</a>, <a href="/format/2312.14725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Text-to-SQL Translation for Financial System Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yewei Song</a>, 
<a href="/search/cs?searchtype=author&query=Ezzini%2C+S">Saad Ezzini</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xunzhu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lothritz%2C+C">Cedric Lothritz</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+J">Jacques Klein</a>, 
<a href="/search/cs?searchtype=author&query=Bissyand%C3%A9%2C+T">Tegawend&#xe9; Bissyand&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Boytsov%2C+A">Andrey Boytsov</a>, 
<a href="/search/cs?searchtype=author&query=Ble%2C+U">Ulrick Ble</a>, 
<a href="/search/cs?searchtype=author&query=Goujon%2C+A">Anne Goujon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, ICSE-SEIP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15041" title="Abstract">arXiv:2312.15041</a> (replaced) [<a href="/pdf/2312.15041" title="Download PDF">pdf</a>, <a href="/format/2312.15041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> W4-Groups: Modeling the Who, What, When and Where of Group Behavior via  Mobility Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atrey%2C+A">Akanksha Atrey</a>, 
<a href="/search/cs?searchtype=author&query=Zakaria%2C+C">Camellia Zakaria</a>, 
<a href="/search/cs?searchtype=author&query=Balan%2C+R">Rajesh Balan</a>, 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+P">Prashant Shenoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15144" title="Abstract">arXiv:2312.15144</a> (replaced) [<a href="/pdf/2312.15144" title="Download PDF">pdf</a>, <a href="/format/2312.15144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal Decoupling Contrastive Learning for Skeleton-based  Human Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaojie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianqin Yin</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yonghao Dang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15224" title="Abstract">arXiv:2312.15224</a> (replaced) [<a href="/pdf/2312.15224" title="Download PDF">pdf</a>, <a href="/format/2312.15224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Powered Hierarchical Language Agent for Real-time Human-AI  Coordination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiaxuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuqing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qingmin Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accpeted by AAMAS 2024. More demonstrations can be seen on our website <a href="https://sites.google.com/view/overcooked-hla/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15731" title="Abstract">arXiv:2312.15731</a> (replaced) [<a href="/pdf/2312.15731" title="Download PDF">pdf</a>, <a href="/format/2312.15731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive FSS: A Novel Few-Shot Segmentation Framework via Prototype  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinagyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yisi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haoran Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianxiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16964" title="Abstract">arXiv:2312.16964</a> (replaced) [<a href="/pdf/2312.16964" title="Download PDF">pdf</a>, <a href="/ps/2312.16964" title="Download PostScript">ps</a>, <a href="/format/2312.16964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for Optimally Shifting Intervals under Intersection Graph  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Droguett%2C+N+H">Nicol&#xe1;s Honorato Droguett</a>, 
<a href="/search/cs?searchtype=author&query=Kurita%2C+K">Kazuhiro Kurita</a>, 
<a href="/search/cs?searchtype=author&query=Hanaka%2C+T">Tesshu Hanaka</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+H">Hirotaka Ono</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17673" title="Abstract">arXiv:2312.17673</a> (replaced) [<a href="/pdf/2312.17673" title="Download PDF">pdf</a>, <a href="/format/2312.17673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jatmo: Prompt Injection Defense by Task-Specific Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piet%2C+J">Julien Piet</a>, 
<a href="/search/cs?searchtype=author&query=Alrashed%2C+M">Maha Alrashed</a>, 
<a href="/search/cs?searchtype=author&query=Sitawarin%2C+C">Chawin Sitawarin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zeming Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+E">Elizabeth Sun</a>, 
<a href="/search/cs?searchtype=author&query=Alomair%2C+B">Basel Alomair</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+D">David Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00155" title="Abstract">arXiv:2401.00155</a> (replaced) [<a href="/pdf/2401.00155" title="Download PDF">pdf</a>, <a href="/format/2401.00155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comprehensive framework for occluded human pose estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Linhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinxin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kedong Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00622" title="Abstract">arXiv:2401.00622</a> (replaced) [<a href="/pdf/2401.00622" title="Download PDF">pdf</a>, <a href="/format/2401.00622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Class-Incremental Learning with New-Class Augmented  Self-Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianliu He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Min Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuefeng Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00897" title="Abstract">arXiv:2401.00897</a> (replaced) [<a href="/pdf/2401.00897" title="Download PDF">pdf</a>, <a href="/format/2401.00897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Modeling for Self-supervised Representation Learning on Vision  and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Luyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zedong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lirong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Baigui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint v2 (fix typos and citations). GitHub project at <a href="https://github.com/Lupin1998/Awesome-MIM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01275" title="Abstract">arXiv:2401.01275</a> (replaced) [<a href="/pdf/2401.01275" title="Download PDF">pdf</a>, <a href="/format/2401.01275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+Q">Quan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shilong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zihang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01286" title="Abstract">arXiv:2401.01286</a> (replaced) [<a href="/pdf/2401.01286" title="Download PDF">pdf</a>, <a href="/format/2401.01286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study of Knowledge Editing for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yunzhi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Bozhong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shumin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zekun Xi</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shengyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jintian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yuansheng Ni</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jia-Chen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengjun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Lei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaowei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ongoing work; 52 pages, 282 citations; benchmark is available at <a href="https://huggingface.co/datasets/zjunlp/KnowEdit">this https URL</a> code is available at <a href="https://github.com/zjunlp/EasyEdit">this https URL</a> paper list is available at <a href="https://github.com/zjunlp/KnowledgeEditingPapers">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01756" title="Abstract">arXiv:2401.01756</a> (replaced) [<a href="/pdf/2401.01756" title="Download PDF">pdf</a>, <a href="/format/2401.01756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzzy Logic Controller Design for Mobile Robot Outdoor Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wondosen%2C+A">A. Wondosen</a>, 
<a href="/search/cs?searchtype=author&query=Shiferaw%2C+D">Dereje Shiferaw</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01854" title="Abstract">arXiv:2401.01854</a> (replaced) [<a href="/pdf/2401.01854" title="Download PDF">pdf</a>, <a href="/format/2401.01854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Instruction Tuning With Just a Pinch of Multilinguality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaham%2C+U">Uri Shaham</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+J">Jonathan Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+R">Roee Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Szpektor%2C+I">Idan Szpektor</a>, 
<a href="/search/cs?searchtype=author&query=Tsarfaty%2C+R">Reut Tsarfaty</a>, 
<a href="/search/cs?searchtype=author&query=Eyal%2C+M">Matan Eyal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01990" title="Abstract">arXiv:2401.01990</a> (replaced) [<a href="/pdf/2401.01990" title="Download PDF">pdf</a>, <a href="/format/2401.01990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feizi%2C+A">Aarash Feizi</a>, 
<a href="/search/cs?searchtype=author&query=Balestriero%2C+R">Randall Balestriero</a>, 
<a href="/search/cs?searchtype=author&query=Romero-Soriano%2C+A">Adriana Romero-Soriano</a>, 
<a href="/search/cs?searchtype=author&query=Rabbany%2C+R">Reihaneh Rabbany</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02032" title="Abstract">arXiv:2401.02032</a> (replaced) [<a href="/pdf/2401.02032" title="Download PDF">pdf</a>, <a href="/format/2401.02032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionEdge: Diffusion Probabilistic Model for Crisp Edge Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yunfan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuhang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+R">Renjiao Yi</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhiping Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02431" title="Abstract">arXiv:2401.02431</a> (replaced) [<a href="/pdf/2401.02431" title="Download PDF">pdf</a>, <a href="/format/2401.02431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Execution time budget assignment for mixed criticality systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khelassi%2C+M+A">Mohamed Amine Khelassi</a> (LIGM), 
<a href="/search/cs?searchtype=author&query=Abdedda%C3%AFm%2C+Y">Yasmina Abdedda&#xef;m</a> (LIGM)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 10th International Workshop on Mixed Criticality Systems at the
  Real Time Systems Symposium (RTSS 2023), IEEE, Dec 2023, Taipei, Taiwan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02615" title="Abstract">arXiv:2401.02615</a> (replaced) [<a href="/pdf/2401.02615" title="Download PDF">pdf</a>, <a href="/format/2401.02615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdvSQLi: Generating Adversarial SQL Injections against Real-world  WAF-as-a-service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zhenqing Qu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+X">Xiang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chunming Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Information Forensics and Security (IEEE TIFS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02791" title="Abstract">arXiv:2401.02791</a> (replaced) [<a href="/pdf/2401.02791" title="Download PDF">pdf</a>, <a href="/format/2401.02791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Semi-supervised Tool Detection in Minimally Invasive Surgery  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujii%2C+R">Ryo Fujii</a>, 
<a href="/search/cs?searchtype=author&query=Hachiuma%2C+R">Ryo Hachiuma</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+H">Hideo Saito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02948" title="Abstract">arXiv:2401.02948</a> (replaced) [<a href="/pdf/2401.02948" title="Download PDF">pdf</a>, <a href="/format/2401.02948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hashing Modulo Context-Sensitive $&#x3b1;$-Equivalence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blaauwbroek%2C+L">Lasse Blaauwbroek</a>, 
<a href="/search/cs?searchtype=author&query=Ol%C5%A1%C3%A1k%2C+M">Miroslav Ol&#x161;&#xe1;k</a>, 
<a href="/search/cs?searchtype=author&query=Geuvers%2C+H">Herman Geuvers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02949" title="Abstract">arXiv:2401.02949</a> (replaced) [<a href="/pdf/2401.02949" title="Download PDF">pdf</a>, <a href="/format/2401.02949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph2Tac: Learning Hierarchical Representations of Math Concepts in  Theorem proving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rute%2C+J">Jason Rute</a>, 
<a href="/search/cs?searchtype=author&query=Ol%C5%A1%C3%A1k%2C+M">Miroslav Ol&#x161;&#xe1;k</a>, 
<a href="/search/cs?searchtype=author&query=Blaauwbroek%2C+L">Lasse Blaauwbroek</a>, 
<a href="/search/cs?searchtype=author&query=Massolo%2C+F+I+S">Fidel Ivan Schaposnik Massolo</a>, 
<a href="/search/cs?searchtype=author&query=Piepenbrock%2C+J">Jelle Piepenbrock</a>, 
<a href="/search/cs?searchtype=author&query=Pestun%2C+V">Vasily Pestun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02950" title="Abstract">arXiv:2401.02950</a> (replaced) [<a href="/pdf/2401.02950" title="Download PDF">pdf</a>, <a href="/format/2401.02950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Tactician&#x27;s Web of Large-Scale Formal Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blaauwbroek%2C+L">Lasse Blaauwbroek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02994" title="Abstract">arXiv:2401.02994</a> (replaced) [<a href="/pdf/2401.02994" title="Download PDF">pdf</a>, <a href="/format/2401.02994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blending Is All You Need: Cheaper, Better Alternative to  Trillion-Parameters LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaoding Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liusie%2C+A">Adian Liusie</a>, 
<a href="/search/cs?searchtype=author&query=Raina%2C+V">Vyas Raina</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Beauchamp%2C+W">William Beauchamp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03140" title="Abstract">arXiv:2401.03140</a> (replaced) [<a href="/pdf/2401.03140" title="Download PDF">pdf</a>, <a href="/format/2401.03140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Sampling in Diffusion Models through Switching Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yujin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinseong Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hoki Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaewook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Saeroom Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03256" title="Abstract">arXiv:2401.03256</a> (replaced) [<a href="/pdf/2401.03256" title="Download PDF">pdf</a>, <a href="/format/2401.03256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Incrementally Expanding Approach for Updating PageRank on Dynamic  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03369" title="Abstract">arXiv:2401.03369</a> (replaced) [<a href="/pdf/2401.03369" title="Download PDF">pdf</a>, <a href="/format/2401.03369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Representation Learning for Molecular Property Prediction:  Sequence, Graph, Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Jiang%2C+T">Tianyi Jiang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+J">Jinhuan Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Xuan%2C+Q">Qi Xuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03398" title="Abstract">arXiv:2401.03398</a> (replaced) [<a href="/pdf/2401.03398" title="Download PDF">pdf</a>, <a href="/format/2401.03398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amplifying robotics capacities with a human touch: An immersive  low-latency panoramic remote system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kang Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dewei Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhaoyuan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03512" title="Abstract">arXiv:2401.03512</a> (replaced) [<a href="/pdf/2401.03512" title="Download PDF">pdf</a>, <a href="/format/2401.03512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token-free LLMs Can Generate Chinese Classical Poetry with More Accurate  Format
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chengyue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+L">Lei Zang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaotuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+C">Chenyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03514" title="Abstract">arXiv:2401.03514</a> (replaced) [<a href="/pdf/2401.03514" title="Download PDF">pdf</a>, <a href="/format/2401.03514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROIC-DM: Robust Text Inference and Classification via Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shilong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tieke He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03728" title="Abstract">arXiv:2401.03728</a> (replaced) [<a href="/pdf/2401.03728" title="Download PDF">pdf</a>, <a href="/format/2401.03728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Lagrangian Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xiao%2C+S">Shanshan Xiao</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+Y">Yifa Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03729" title="Abstract">arXiv:2401.03729</a> (replaced) [<a href="/pdf/2401.03729" title="Download PDF">pdf</a>, <a href="/format/2401.03729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Butterfly Effect of Altering Prompts: How Small Changes and  Jailbreaks Affect Large Language Model Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salinas%2C+A">Abel Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Morstatter%2C+F">Fred Morstatter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03736" title="Abstract">arXiv:2401.03736</a> (replaced) [<a href="/pdf/2401.03736" title="Download PDF">pdf</a>, <a href="/format/2401.03736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lessons Learned: Reproducibility, Replicability, and When to Stop
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomez%2C+M+S">Milton S. Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Beucler%2C+T">Tom Beucler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main Text: 6 pages with 2 Figures Supplementary Text: 7 Pages with 3 figures and 3 tables Submitted to AMS AIES Lessons Learned (<a href="https://journals.ametsoc.org/view/journals/aies/aies-overview.xml">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03800" title="Abstract">arXiv:2401.03800</a> (replaced) [<a href="/pdf/2401.03800" title="Download PDF">pdf</a>, <a href="/format/2401.03800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MvKSR: Multi-view Knowledge-guided Scene Recovery for Hazy and Rainy  Degradation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuxu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yu Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03836" title="Abstract">arXiv:2401.03836</a> (replaced) [<a href="/pdf/2401.03836" title="Download PDF">pdf</a>, <a href="/format/2401.03836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WidthFormer: Toward Efficient Transformer-based BEV View Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenhongyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tianwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lichao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Crowley%2C+E+J">Elliot J. Crowley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03868" title="Abstract">arXiv:2401.03868</a> (replaced) [<a href="/pdf/2401.03868" title="Download PDF">pdf</a>, <a href="/format/2401.03868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlightLLM: Efficient Large Language Model Inference with a Complete  Mapping Flow on FPGAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Shulin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guohao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Tianyu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hanbo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yadong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jintao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zehao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+K">Kairui Wen</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xuefei Ning</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to FPGA'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03885" title="Abstract">arXiv:2401.03885</a> (replaced) [<a href="/pdf/2401.03885" title="Download PDF">pdf</a>, <a href="/ps/2401.03885" title="Download PostScript">ps</a>, <a href="/format/2401.03885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperspectral Image Denoising via Spatial-Spectral Recurrent Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fu%2C+G">Guanyiman Fu</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+F">Fengchao Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jiantao Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+Y">Yuntao Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03913" title="Abstract">arXiv:2401.03913</a> (replaced) [<a href="/pdf/2401.03913" title="Download PDF">pdf</a>, <a href="/format/2401.03913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Wasserstein Graph Distance Based on Distributions of Probabilistic  Node Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scholkemper%2C+M">Michael Scholkemper</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChn%2C+D">Damin K&#xfc;hn</a>, 
<a href="/search/cs?searchtype=author&query=Nabbefeld%2C+G">Gerion Nabbefeld</a>, 
<a href="/search/cs?searchtype=author&query=Musall%2C+S">Simon Musall</a>, 
<a href="/search/cs?searchtype=author&query=Kampa%2C+B">Bj&#xf6;rn Kampa</a>, 
<a href="/search/cs?searchtype=author&query=Schaub%2C+M+T">Michael T. Schaub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03988" title="Abstract">arXiv:2401.03988</a> (replaced) [<a href="/pdf/2401.03988" title="Download PDF">pdf</a>, <a href="/ps/2401.03988" title="Download PostScript">ps</a>, <a href="/format/2401.03988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Primer on Temporal Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A+U">Aniq Ur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Coon%2C+J+P">Justin P. Coon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 47 equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM); Social and Information Networks (cs.SI); Signal Processing (eess.SP)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item222">Cross-lists</a></li>
<li><a href="#item255">Replacements</a></li>
</ul>
<small>[ total of 446 entries:  <b>1-446</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2401">2401</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
