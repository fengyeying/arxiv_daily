<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri 29 Dec 23  to  Mon  1 Jan 24, announced Tue,  2 Jan 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item306">Cross-lists</a></li>
<li><a href="#item361">Replacements</a></li>
</ul>
<small>[ total of 583 entries:  <b>1-583</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue,  2 Jan 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00004" title="Abstract">arXiv:2401.00004</a> [<a href="/pdf/2401.00004" title="Download PDF">pdf</a>, <a href="/ps/2401.00004" title="Download PostScript">ps</a>, <a href="/format/2401.00004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Informational non-reductionist theory of consciousness that providing  maximum accuracy of reality prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vityaev%2C+E+E">E.E. Vityaev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">The paper considers a non-reductionist theory of consciousness, which is not
reducible to theories of reality and to physiological or psychological
theories. Following D.I.Dubrovsky's "informational approach" to the "Mind-Brain
Problem", we consider the reality through the prism of information about
observed phenomena, which, in turn, is perceived by subjective reality through
sensations, perceptions, feelings, etc., which, in turn, are information about
the corresponding brain processes. Within this framework the following
principle of the Information Theory of Consciousness (ITS) development is put
forward: the brain discovers all possible causal relations in the external
world and makes all possible inferences by them. The paper shows that ITS built
on this principle: (1) also base on the information laws of the structure of
external world; (2) explains the structure and functioning of the brain
functional systems and cellular ensembles; (3) ensures maximum accuracy of
predictions and the anticipation of reality; (4) resolves emerging
contradictions and (5) is an information theory of the brain's reflection of
reality.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00005" title="Abstract">arXiv:2401.00005</a> [<a href="/pdf/2401.00005" title="Download PDF">pdf</a>, <a href="/ps/2401.00005" title="Download PostScript">ps</a>, <a href="/format/2401.00005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consciousness as a logically consistent and prognostic model of reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vityaev%2C+E">Evgenii Vityaev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The work demonstrates that brain might reflect the external world causal
relationships in the form of a logically consistent and prognostic model of
reality, which shows up as consciousness. The paper analyses and solves the
problem of statistical ambiguity and provides a formal model of causal
relationships as probabilistic maximally specific rules. We suppose that brain
makes all possible inferences from causal relationships. We prove that the
suggested formal model has a property of an unambiguous inference: from
consistent premises we infer a consistent conclusion. It enables a set of all
inferences to form a consistent model of the perceived world. Causal
relationships may create fixed points of cyclic inter-predictable properties.
We consider the "natural" classification introduced by John St. Mill and
demonstrate that a variety of fixed points of the objects' attributes forms a
"natural" classification of the external world. Then we consider notions of
"natural" categories and causal models of categories, introduced by Eleanor
Rosch and Bob Rehder and demonstrate that fixed points of causal relationships
between objects attributes, which we perceive, formalize these notions. If the
"natural" classification describes the objects of the external world, and
"natural" concepts the perception of these objects, then the theory of
integrated information, introduced by G. Tononi, describes the information
processes of the brain for "natural" concepts formation that reflects the
"natural" classification. We argue that integrated information provides high
accuracy of the objects identification. A computer-based experiment is provided
that illustrates fixed points formation for coded digits.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00006" title="Abstract">arXiv:2401.00006</a> [<a href="/pdf/2401.00006" title="Download PDF">pdf</a>, <a href="/format/2401.00006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Open-Ended Embodied Agent via Language-Policy Bidirectional  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+S">Shaopeng Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fuxian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Ming Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jing Hou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Building open-ended learning agents involves challenges in pre-trained
language model (LLM) and reinforcement learning (RL) approaches. LLMs struggle
with context-specific real-time interactions, while RL methods face efficiency
issues for exploration. To this end, we propose OpenContra, a co-training
framework that cooperates LLMs and GRL to construct an open-ended agent capable
of comprehending arbitrary human instructions. The implementation comprises two
stages: (1) fine-tuning an LLM to translate human instructions into structured
goals, and curriculum training a goal-conditioned RL policy to execute
arbitrary goals; (2) collaborative training to make the LLM and RL policy learn
to adapt each, achieving open-endedness on instruction space. We conduct
experiments on Contra, a battle royale FPS game with a complex and vast goal
space. The results show that an agent trained with OpenContra comprehends
arbitrary human instructions and completes goals with a high completion ratio,
which proves that OpenContra may be the first practical solution for
constructing open-ended embodied agents.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00007" title="Abstract">arXiv:2401.00007</a> [<a href="/pdf/2401.00007" title="Download PDF">pdf</a>, <a href="/ps/2401.00007" title="Download PostScript">ps</a>, <a href="/format/2401.00007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling arousal potential of epistemic emotions using Bayesian  information gain: Inquiry cycle driven by free energy fluctuations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yanagisawa%2C+H">Hideyoshi Yanagisawa</a>, 
<a href="/search/cs?searchtype=author&query=Honda%2C+S">Shimon Honda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Theory (cs.IT); Neurons and Cognition (q-bio.NC); Applications (stat.AP)

</div>
<p class="mathjax">Epistemic emotions, such as curiosity and interest, drive the inquiry
process. This study proposes a novel formulation of epistemic emotions such as
curiosity and interest using two types of information gain generated by the
principle of free energy minimization: Kullback-Leibler divergence(KLD) from
Bayesian posterior to prior, which represents free energy reduction in
recognition, and Bayesian surprise (BS), which represents the expected
information gain by Bayesian prior update. By applying a Gaussian generative
model with an additional uniform likelihood, we found that KLD and BS form an
upward-convex function of surprise (minimized free energy and prediction
error), similar to Berlyne's arousal potential functions, or the Wundt curve.
We consider that the alternate maximization of BS and KLD generates an ideal
inquiry cycle to approach the optimal arousal level with fluctuations in
surprise, and that curiosity and interest drive to facilitate the cyclic
process. We exhaustively analyzed the effects of prediction uncertainty (prior
variance) and observation uncertainty (likelihood variance) on the peaks of the
information gain function as optimal surprises. The results show that greater
prediction uncertainty, meaning an open-minded attitude, and less observational
uncertainty, meaning precise observation with attention, are expected to
provide greater information gains through a greater range of exploration. The
proposed mathematical framework unifies the free energy principle of the brain
and the arousal potential theory to explain the Wundt curve as an information
gain function and suggests an ideal inquiry process driven by epistemic
emotions.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00009" title="Abstract">arXiv:2401.00009</a> [<a href="/pdf/2401.00009" title="Download PDF">pdf</a>, <a href="/format/2401.00009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turing&#x27;s Test, a Beautiful Thought Experiment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gon%C3%A7alves%2C+B">Bernardo Gon&#xe7;alves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8.4K words, 9 pages, 3 figures, 3 text boxes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In the wake of large language models, there has been a resurgence of claims
and questions about the Turing test and its value for AI, which are reminiscent
of decades of practical "Turing" tests. If AI were quantum physics, by now
several "Schr\"odinger's" cats could have been killed. Better late than never,
it is time for a historical reconstruction of Turing's beautiful thought
experiment. In this paper I present a wealth of evidence, including new
archival sources, give original answers to several open questions about
Turing's 1950 paper, and address the core question of the value of Turing's
test.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00010" title="Abstract">arXiv:2401.00010</a> [<a href="/pdf/2401.00010" title="Download PDF">pdf</a>, <a href="/format/2401.00010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Professional Network Matters: Connections Empower Person-Job Fit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lun Du</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuxuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shi Han</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yanbin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guangming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Online recruitment platforms typically employ Person-Job Fit models in the
core service that automatically match suitable job seekers with appropriate job
positions. While existing works leverage historical or contextual information,
they often disregard a crucial aspect: job seekers' social relationships in
professional networks. This paper emphasizes the importance of incorporating
professional networks into the Person-Job Fit model. Our innovative approach
consists of two stages: (1) defining a Workplace Heterogeneous Information
Network (WHIN) to capture heterogeneous knowledge, including professional
connections and pre-training representations of various entities using a
heterogeneous graph neural network; (2) designing a Contextual Social Attention
Graph Neural Network (CSAGNN) that supplements users' missing information with
professional connections' contextual information. We introduce a job-specific
attention mechanism in CSAGNN to handle noisy professional networks, leveraging
pre-trained entity representations from WHIN. We demonstrate the effectiveness
of our approach through experimental evaluations conducted across three
real-world recruitment datasets from LinkedIn, showing superior performance
compared to baseline models.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00011" title="Abstract">arXiv:2401.00011</a> [<a href="/pdf/2401.00011" title="Download PDF">pdf</a>, <a href="/format/2401.00011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning of networked spreading models from noisy and incomplete data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilinski%2C+M">Mateusz Wilinski</a>, 
<a href="/search/cs?searchtype=author&query=Lokhov%2C+A+Y">Andrey Y. Lokhov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent years have seen a lot of progress in algorithms for learning
parameters of spreading dynamics from both full and partial data. Some of the
remaining challenges include model selection under the scenarios of unknown
network structure, noisy data, missing observations in time, as well as an
efficient incorporation of prior information to minimize the number of samples
required for an accurate learning. Here, we introduce a universal learning
method based on scalable dynamic message-passing technique that addresses these
challenges often encountered in real data. The algorithm leverages available
prior knowledge on the model and on the data, and reconstructs both network
structure and parameters of a spreading model. We show that a linear
computational complexity of the method with the key model parameters makes the
algorithm scalable to large network instances.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00013" title="Abstract">arXiv:2401.00013</a> [<a href="/pdf/2401.00013" title="Download PDF">pdf</a>, <a href="/format/2401.00013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HITSnDIFFs: From Truth Discovery to Ability Discovery by Recovering  Matrices with the Consecutive Ones Property
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Subhodeep Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+R">R Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Gatterbauer%2C+W">Wolfgang Gatterbauer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 14 figures, long version of of ICDE 2024 conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Databases (cs.DB); Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
<p class="mathjax">We analyze a general problem in a crowd-sourced setting where one user asks a
question (also called item) and other users return answers (also called labels)
for this question. Different from existing crowd sourcing work which focuses on
finding the most appropriate label for the question (the "truth"), our problem
is to determine a ranking of the users based on their ability to answer
questions. We call this problem "ability discovery" to emphasize the connection
to and duality with the more well-studied problem of "truth discovery".
<br />To model items and their labels in a principled way, we draw upon Item
Response Theory (IRT) which is the widely accepted theory behind standardized
tests such as SAT and GRE. We start from an idealized setting where the
relative performance of users is consistent across items and better users
choose better fitting labels for each item. We posit that a principled
algorithmic solution to our more general problem should solve this ideal
setting correctly and observe that the response matrices in this setting obey
the Consecutive Ones Property (C1P). While C1P is well understood
algorithmically with various discrete algorithms, we devise a novel variant of
the HITS algorithm which we call "HITSNDIFFS" (or HND), and prove that it can
recover the ideal C1P-permutation in case it exists. Unlike fast combinatorial
algorithms for finding the consecutive ones permutation (if it exists), HND
also returns an ordering when such a permutation does not exist. Thus it
provides a principled heuristic for our problem that is guaranteed to return
the correct answer in the ideal setting. Our experiments show that HND produces
user rankings with robustly high accuracy compared to state-of-the-art truth
discovery methods. We also show that our novel variant of HITS scales better in
the number of users than ABH, the only prior spectral C1P reconstruction
algorithm.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00015" title="Abstract">arXiv:2401.00015</a> [<a href="/pdf/2401.00015" title="Download PDF">pdf</a>, <a href="/format/2401.00015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Reinforcement Learning-based Energy Arbitrage Strategies  in Imbalance Settlement Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madahi%2C+S+S+K">Seyed Soroush Karimi Madahi</a>, 
<a href="/search/cs?searchtype=author&query=Claessens%2C+B">Bert Claessens</a>, 
<a href="/search/cs?searchtype=author&query=Develder%2C+C">Chris Develder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Growth in the penetration of renewable energy sources makes supply more
uncertain and leads to an increase in the system imbalance. This trend,
together with the single imbalance pricing, opens an opportunity for balance
responsible parties (BRPs) to perform energy arbitrage in the imbalance
settlement mechanism. To this end, we propose a battery control framework based
on distributional reinforcement learning (DRL). Our proposed control framework
takes a risk-sensitive perspective, allowing BRPs to adjust their risk
preferences: we aim to optimize a weighted sum of the arbitrage profit and a
risk measure while constraining the daily number of cycles for the battery. We
assess the performance of our proposed control framework using the Belgian
imbalance prices of 2022 and compare two state-of-the-art RL methods, deep Q
learning and soft actor-critic. Results reveal that the distributional soft
actor-critic method can outperform other methods. Moreover, we note that our
fully risk-averse agent appropriately learns to hedge against the risk related
to the unknown imbalance price by (dis)charging the battery only when the agent
is more certain about the price.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00017" title="Abstract">arXiv:2401.00017</a> [<a href="/pdf/2401.00017" title="Download PDF">pdf</a>, <a href="/format/2401.00017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QAOA on Hamiltonian Cycle problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhuoyang Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">I use QAOA to solve the Hamiltonian Circle problem. First, inspired by Lucas,
I define the QUBO form of Hamiltonian Cycle and transform it to a quantum
circuit by embedding the problem of $n$ vertices to an encoding of $(n-1)^2$
qubits. Then, I calcluate the spectrum of the cost hamiltonian for both
triangle case and square case and justify my definition. I also write a python
program to generate the cost hamiltonian automatically for finding the
hamiltonian cycle in an arbitrary graph. I test the correctess of the
hamailtonian by analyze their energy spectrums. Since the $(n-1)^2$ embedding
limit my simulation of graph size to be less than $5$, I decide to test the
correctness, only for small and simple graph in this project. I implement the
QAOA algorithm using qiskit and run the simulation for the triangle case and
the square case, which are easy to test the correctness, both with and without
noise. A very interesting result I got is that for the square case, the QAOA
get much better result on a noisy simulator than a noiseless simulator. The
explanation for this phenomena require further investigation, perhaps quantum
noise can actually be helpful, rather than harmful in the annealing algorithms.
I also use two different kinds of mixer, $R_x$ mixer and $R_y$ circuit to run
the simulation. It turns out that $R_x$ mixer performs much better than $R_y$
mixer in this problem.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00020" title="Abstract">arXiv:2401.00020</a> [<a href="/pdf/2401.00020" title="Download PDF">pdf</a>, <a href="/format/2401.00020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-driven platform for systematic nomenclature and intelligent knowledge  acquisition of natural medicinal materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zijie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yongjing Yin</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+C">Chaojun Kong</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+T">Tiange Chi</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wufan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tian Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 pages, 7 figures, 10 supplementary figures, 1 table, 1 supplementary table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Natural Medicinal Materials (NMMs) have a long history of global clinical
applications, accompanied by extensive informational records. Despite their
significant impact on healthcare, the field faces a major challenge: the
non-standardization of NMM knowledge, stemming from historical complexities and
causing limitations in broader applications. To address this, we introduce a
Systematic Nomenclature for NMMs, underpinned by ShennongAlpha, an AI-driven
platform designed for intelligent knowledge acquisition. This nomenclature
system enables precise identification and differentiation of NMMs.
ShennongAlpha, cataloging over ten thousand NMMs with standardized bilingual
information, enhances knowledge management and application capabilities,
thereby overcoming traditional barriers. Furthermore, it pioneers AI-empowered
conversational knowledge acquisition and standardized machine translation.
These synergistic innovations mark the first major advance in integrating
domain-specific NMM knowledge with AI, propelling research and applications
across both NMM and AI fields while establishing a groundbreaking precedent in
this crucial area.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00021" title="Abstract">arXiv:2401.00021</a> [<a href="/pdf/2401.00021" title="Download PDF">pdf</a>, <a href="/ps/2401.00021" title="Download PostScript">ps</a>, <a href="/format/2401.00021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conceptual Mutation Testing for Student Programming Misconceptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasad%2C+S">Siddhartha Prasad</a> (Brown University, USA), 
<a href="/search/cs?searchtype=author&query=Greenman%2C+B">Ben Greenman</a> (Brown University, USA), 
<a href="/search/cs?searchtype=author&query=Nelson%2C+T">Tim Nelson</a> (Brown University, USA), 
<a href="/search/cs?searchtype=author&query=Krishnamurthi%2C+S">Shriram Krishnamurthi</a> (Brown University, USA)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 2, Article 7
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Context: Students often misunderstand programming problem descriptions. This
can lead them to solve the wrong problem, which creates frustration, obstructs
learning, and imperils grades. Researchers have found that students can be made
to better understand the problem by writing examples before they start
programming. These examples are checked against correct and wrong
implementations -- analogous to mutation testing -- provided by course staff.
Doing so results in better student understanding of the problem as well as
better test suites to accompany the program, both of which are desirable
educational outcomes.
<br />Inquiry: Producing mutant implementations requires care. If there are too
many, or they are too obscure, students will end up spending a lot of time on
an unproductive task and also become frustrated. Instead, we want a small
number of mutants that each correspond to common problem misconceptions. This
paper presents a workflow with partial automation to produce mutants of this
form which, notably, are not those produced by mutation-testing tools.
<br />Approach: We comb through student tests that fail a correct implementation.
The student misconceptions are embedded in these failures. We then use methods
to semantically cluster these failures. These clusters are then translated into
conceptual mutants. These can then be run against student data to determine
whether we they are better than prior methods. Some of these processes also
enjoy automation.
<br />Knowledge: We find that student misconceptions illustrated by failing tests
can be operationalized by the above process. The resulting mutants do much
better at identifying student misconceptions.
<br />Grounding: Our findings are grounded in a manual analysis of student examples
and a quantitative evaluation of both our clustering techniques and our process
for making conceptual mutants. The clustering evaluation compares against a
ground truth using standard cluster-correspondence measures, while the mutant
evaluation examines how conceptual mutants perform against student data.
<br />Importance: Our work contributes a workflow, with some automation, to reduce
the cost and increase the effectiveness of generating conceptually interesting
mutants. Such mutants can both improve learning outcomes and reduce student
frustration, leading to better educational outcomes. In the process, we also
identify a variation of mutation testing not commonly discussed in the software
literature.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00025" title="Abstract">arXiv:2401.00025</a> [<a href="/pdf/2401.00025" title="Download PDF">pdf</a>, <a href="/format/2401.00025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Any-point Trajectory Modeling for Policy Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chuan Wen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xingyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+J">John So</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Learning from demonstration is a powerful method for teaching robots new
skills, and more demonstration data often improves policy learning. However,
the high cost of collecting demonstration data is a significant bottleneck.
Videos, as a rich data source, contain knowledge of behaviors, physics, and
semantics, but extracting control-specific information from them is challenging
due to the lack of action labels. In this work, we introduce a novel framework,
Any-point Trajectory Modeling (ATM), that utilizes video demonstrations by
pre-training a trajectory model to predict future trajectories of arbitrary
points within a video frame. Once trained, these trajectories provide detailed
control guidance, enabling the learning of robust visuomotor policies with
minimal action-labeled data. Our method's effectiveness is demonstrated across
130 simulation tasks, focusing on language-conditioned manipulation tasks.
Visualizations and code are available at:
\url{https://xingyu-lin.github.io/atm}.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00027" title="Abstract">arXiv:2401.00027</a> [<a href="/pdf/2401.00027" title="Download PDF">pdf</a>, <a href="/format/2401.00027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Multi-scale Network with Learnable Discrete Wavelet Transform  for Blind Motion Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+T">Tianheng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Hanlin Bai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guoying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Coarse-to-fine schemes are widely used in traditional single-image motion
deblur; however, in the context of deep learning, existing multi-scale
algorithms not only require the use of complex modules for feature fusion of
low-scale RGB images and deep semantics, but also manually generate
low-resolution pairs of images that do not have sufficient confidence. In this
work, we propose a multi-scale network based on single-input and
multiple-outputs(SIMO) for motion deblurring. This simplifies the complexity of
algorithms based on a coarse-to-fine scheme. To alleviate restoration defects
impacting detail information brought about by using a multi-scale architecture,
we combine the characteristics of real-world blurring trajectories with a
learnable wavelet transform module to focus on the directional continuity and
frequency features of the step-by-step transitions between blurred images to
sharp images. In conclusion, we propose a multi-scale network with a learnable
discrete wavelet transform (MLWNet), which exhibits state-of-the-art
performance on multiple real-world deblurred datasets, in terms of both
subjective and objective quality as well as computational efficiency.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00028" title="Abstract">arXiv:2401.00028</a> [<a href="/pdf/2401.00028" title="Download PDF">pdf</a>, <a href="/format/2401.00028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Scaling Law for OCR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rang%2C+M">Miao Rang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+Z">Zhenni Bi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chuanjian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The laws of model size, data volume, computation and model performance have
been extensively studied in the field of Natural Language Processing (NLP).
However, the scaling laws in Optical Character Recognition (OCR) have not yet
been investigated. To address this, we conducted comprehensive studies that
involved examining the correlation between performance and the scale of models,
data volume and computation in the field of text recognition.Conclusively, the
study demonstrates smooth power laws between performance and model size, as
well as training data volume, when other influencing factors are held constant.
Additionally, we have constructed a large-scale dataset called REBU-Syn, which
comprises 6 million real samples and 18 million synthetic samples. Based on our
scaling law and new dataset, we have successfully trained a scene text
recognition model, achieving a new state-ofthe-art on 6 common test benchmarks
with a top-1 average accuracy of 97.42%.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00029" title="Abstract">arXiv:2401.00029</a> [<a href="/pdf/2401.00029" title="Download PDF">pdf</a>, <a href="/format/2401.00029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6D-Diff: A Keypoint Diffusion Framework for 6D Object Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Li Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Haoxuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yujun Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Estimating the 6D object pose from a single RGB image often involves noise
and indeterminacy due to challenges such as occlusions and cluttered
backgrounds. Meanwhile, diffusion models have shown appealing performance in
generating high-quality images from random noise with high indeterminacy
through step-by-step denoising. Inspired by their denoising capability, we
propose a novel diffusion-based framework (6D-Diff) to handle the noise and
indeterminacy in object pose estimation for better performance. In our
framework, to establish accurate 2D-3D correspondence, we formulate 2D
keypoints detection as a reverse diffusion (denoising) process. To facilitate
such a denoising process, we design a Mixture-of-Cauchy-based forward diffusion
process and condition the reverse process on the object features. Extensive
experiments on the LM-O and YCB-V datasets demonstrate the effectiveness of our
framework.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00031" title="Abstract">arXiv:2401.00031</a> [<a href="/pdf/2401.00031" title="Download PDF">pdf</a>, <a href="/format/2401.00031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Pretraining for Decision Foundation Model: Formulation,  Pipeline and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoqian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jianbin Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junge Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Decision-making is a dynamic process requiring perception, memory, and
reasoning to make choices and find optimal policies. Traditional approaches to
decision-making suffer from sample efficiency and generalization, while
large-scale self-supervised pretraining has enabled fast adaptation with
fine-tuning or few-shot learning in language and vision. We thus argue to
integrate knowledge acquired from generic large-scale self-supervised
pretraining into downstream decision-making problems. We propose
Pretrain-Then-Adapt pipeline and survey recent work on data collection,
pretraining objectives and adaptation strategies for decision-making
pretraining and downstream inference. Finally, we identify critical challenges
and future directions for developing decision foundation model with the help of
generic and flexible self-supervised pretraining.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00033" title="Abstract">arXiv:2401.00033</a> [<a href="/pdf/2401.00033" title="Download PDF">pdf</a>, <a href="/format/2401.00033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Modeling Design Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rudolph%2C+M">Maja Rudolph</a>, 
<a href="/search/cs?searchtype=author&query=Kurz%2C+S">Stefan Kurz</a>, 
<a href="/search/cs?searchtype=author&query=Rakitsch%2C+B">Barbara Rakitsch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Design patterns provide a systematic way to convey solutions to recurring
modeling challenges. This paper introduces design patterns for hybrid modeling,
an approach that combines modeling based on first principles with data-driven
modeling techniques. While both approaches have complementary advantages there
are often multiple ways to combine them into a hybrid model, and the
appropriate solution will depend on the problem at hand. In this paper, we
provide four base patterns that can serve as blueprints for combining
data-driven components with domain knowledge into a hybrid approach. In
addition, we also present two composition patterns that govern the combination
of the base patterns into more complex hybrid models. Each design pattern is
illustrated by typical use cases from application areas such as climate
modeling, engineering, and physics.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00036" title="Abstract">arXiv:2401.00036</a> [<a href="/pdf/2401.00036" title="Download PDF">pdf</a>, <a href="/format/2401.00036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete Distribution Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://Discrete-Distribution-Networks.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a novel generative model, the Discrete Distribution Networks
(DDN), that approximates data distribution using hierarchical discrete
distributions. We posit that since the features within a network inherently
contain distributional information, liberating the network from a single output
to concurrently generate multiple samples proves to be highly effective.
Therefore, DDN fits the target distribution, including continuous ones, by
generating multiple discrete sample points. To capture finer details of the
target data, DDN selects the output that is closest to the Ground Truth (GT)
from the coarse results generated in the first layer. This selected output is
then fed back into the network as a condition for the second layer, thereby
generating new outputs more similar to the GT. As the number of DDN layers
increases, the representational space of the outputs expands exponentially, and
the generated samples become increasingly similar to the GT. This hierarchical
output pattern of discrete distributions endows DDN with two intriguing
properties: highly compressed representation and more general zero-shot
conditional generation. We demonstrate the efficacy of DDN and these intriguing
properties through experiments on CIFAR-10 and FFHQ.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00052" title="Abstract">arXiv:2401.00052</a> [<a href="/pdf/2401.00052" title="Download PDF">pdf</a>, <a href="/format/2401.00052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatEd: A Chatbot Leveraging ChatGPT for an Enhanced Learning Experience  in Higher Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kevin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+J">Jason Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+R">Ramon Lawrence</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at INTED2024 - 18th annual International Technology, Education and Development Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">With the rapid evolution of Natural Language Processing (NLP), Large Language
Models (LLMs) like ChatGPT have emerged as powerful tools capable of
transforming various sectors. Their vast knowledge base and dynamic interaction
capabilities represent significant potential in improving education by
operating as a personalized assistant. However, the possibility of generating
incorrect, biased, or unhelpful answers are a key challenge to resolve when
deploying LLMs in an education context. This work introduces an innovative
architecture that combines the strengths of ChatGPT with a traditional
information retrieval based chatbot framework to offer enhanced student support
in higher education. Our empirical evaluations underscore the high promise of
this approach.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00055" title="Abstract">arXiv:2401.00055</a> [<a href="/pdf/2401.00055" title="Download PDF">pdf</a>, <a href="/format/2401.00055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Algorithmic Recourse by Collective Action
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Creager%2C+E">Elliot Creager</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in the ICML 2021 Workshop on Algorithmic Recourse
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Research on algorithmic recourse typically considers how an individual can
reasonably change an unfavorable automated decision when interacting with a
fixed decision-making system. This paper focuses instead on the online setting,
where system parameters are updated dynamically according to interactions with
data subjects. Beyond the typical individual-level recourse, the online setting
opens up new ways for groups to shape system decisions by leveraging the
parameter update rule. We show empirically that recourse can be improved when
users coordinate by jointly computing their feature perturbations, underscoring
the importance of collective action in mitigating adverse automated decisions.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00057" title="Abstract">arXiv:2401.00057</a> [<a href="/pdf/2401.00057" title="Download PDF">pdf</a>, <a href="/format/2401.00057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization properties of contrastive world models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+K">Kandan Ramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Cotton%2C+R+J">R. James Cotton</a>, 
<a href="/search/cs?searchtype=author&query=Pitkow%2C+X">Xaq Pitkow</a>, 
<a href="/search/cs?searchtype=author&query=Tolias%2C+A+S">Andreas S. Tolias</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the NeurIPS 2023 Workshop: Self-Supervised Learning - Theory and Practice
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent work on object-centric world models aim to factorize representations
in terms of objects in a completely unsupervised or self-supervised manner.
Such world models are hypothesized to be a key component to address the
generalization problem. While self-supervision has shown improved performance
however, OOD generalization has not been systematically and explicitly tested.
In this paper, we conduct an extensive study on the generalization properties
of contrastive world model. We systematically test the model under a number of
different OOD generalization scenarios such as extrapolation to new object
attributes, introducing new conjunctions or new attributes. Our experiments
show that the contrastive world model fails to generalize under the different
OOD tests and the drop in performance depends on the extent to which the
samples are OOD. When visualizing the transition updates and convolutional
feature maps, we observe that any changes in object attributes (such as
previously unseen colors, shapes, or conjunctions of color and shape) breaks
down the factorization of object representations. Overall, our work highlights
the importance of object-centric representations for generalization and current
models are limited in their capacity to learn such representations required for
human-level generalization.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00058" title="Abstract">arXiv:2401.00058</a> [<a href="/pdf/2401.00058" title="Download PDF">pdf</a>, <a href="/ps/2401.00058" title="Download PostScript">ps</a>, <a href="/format/2401.00058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the language of the sharing economy: Building trust and  reducing privacy concern on Airbnb in German and English
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zarifis%2C+A">Alex Zarifis</a>, 
<a href="/search/cs?searchtype=author&query=Ingham%2C+R">Richard Ingham</a>, 
<a href="/search/cs?searchtype=author&query=Kroenung%2C+J">Julia Kroenung</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Cogent Business &amp; Management (2019), vol.6, iss.1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The text in the profile of those offering their properties in England in
English and in Germany in German, are compared to explore whether trust is
built, and privacy concerns are reduced in the same way. Six methods of
building trust are used by the landlords: (1) the level of formality, (2)
distance and proximity, (3) emotiveness and humor, (4) being assertive and
passive aggressive, (5) conformity to the platform language style and
terminology and (6) setting boundaries. Privacy concerns are not usually
reduced directly as this is left to the platform. The findings indicate that
language has a limited influence and the platform norms and habits are the
biggest influence.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00062" title="Abstract">arXiv:2401.00062</a> [<a href="/pdf/2401.00062" title="Download PDF">pdf</a>, <a href="/format/2401.00062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Computing for Organizational Effectiveness: From Organization  Theory to Practice through Semantics-Based Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizk%2C+M">Mena Rizk</a>, 
<a href="/search/cs?searchtype=author&query=Rosu%2C+D">Daniela Rosu</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+M">Mark Fox</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">A critical function of an organization is to foster the level of integration
(coordination and cooperation) necessary to achieve its objectives. The need to
coordinate and motivation to cooperate emerges from the myriad dependencies
between an organization's members and their work. Therefore, to reason about
solutions to coordination and cooperation problems requires a robust
representation that includes the underlying dependencies. We find that such a
representation remains missing from formal organizational models, and we
leverage semantics to bridge this gap. Drawing on well-established
organizational research and our extensive fieldwork with one of North America's
largest municipalities, (1) we introduce an ontology, formalized in first-order
logic, that operationalizes concepts like outcome, reward, and epistemic
dependence, and their links to potential integration risks; and (2) present
real-world applications of this ontology to analyze and support integration in
complex government infrastructure projects. Our ontology is implemented and
validated in both Z3 and OWL. Key features of our model include inferable
dependencies, explainable coordination and cooperation risks, and actionable
insights on how dependency structures within an organization can be altered to
mitigate the risks. Conceptualizing real-world challenges like incentive
misalignment, free-riding, and subgoal optimization in terms of dependency
structures, our semantics-based approach represents a novel method for
modelling and enhancing coordination and cooperation. Integrated within a
decision-support system, our model may serve as an impactful aid for
organizational design and effectiveness. More broadly, our approach underscores
the transformative potential of semantics in deriving tangible, real-world
value from existing organization theory.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00067" title="Abstract">arXiv:2401.00067</a> [<a href="/pdf/2401.00067" title="Download PDF">pdf</a>, <a href="/format/2401.00067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Particle-Based Shape Modeling for Arbitrary Regions-of-Interest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+A">Alan Morris</a>, 
<a href="/search/cs?searchtype=author&query=Elhabian%2C+S+Y">Shireen Y. Elhabian</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Shape in Medical Imaging (ShapeMI 2023), p47_54, Springer Nature
  Switzerland
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Statistical Shape Modeling (SSM) is a quantitative method for analyzing
morphological variations in anatomical structures. These analyses often
necessitate building models on targeted anatomical regions of interest to focus
on specific morphological features. We propose an extension to \particle-based
shape modeling (PSM), a widely used SSM framework, to allow shape modeling to
arbitrary regions of interest. Existing methods to define regions of interest
are computationally expensive and have topological limitations. To address
these shortcomings, we use mesh fields to define free-form constraints, which
allow for delimiting arbitrary regions of interest on shape surfaces.
Furthermore, we add a quadratic penalty method to the model optimization to
enable computationally efficient enforcement of any combination of
cutting-plane and free-form constraints. We demonstrate the effectiveness of
this method on a challenging synthetic dataset and two medical datasets.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00073" title="Abstract">arXiv:2401.00073</a> [<a href="/pdf/2401.00073" title="Download PDF">pdf</a>, <a href="/format/2401.00073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonasymptotic Regret Analysis of Adaptive Linear Quadratic Control with  Model Misspecification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+B+D">Bruce D. Lee</a>, 
<a href="/search/eess?searchtype=author&query=Rantzer%2C+A">Anders Rantzer</a>, 
<a href="/search/eess?searchtype=author&query=Matni%2C+N">Nikolai Matni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The strategy of pre-training a large model on a diverse dataset, then
fine-tuning for a particular application has yielded impressive results in
computer vision, natural language processing, and robotic control. This
strategy has vast potential in adaptive control, where it is necessary to
rapidly adapt to changing conditions with limited data. Toward concretely
understanding the benefit of pre-training for adaptive control, we study the
adaptive linear quadratic control problem in the setting where the learner has
prior knowledge of a collection of basis matrices for the dynamics. This basis
is misspecified in the sense that it cannot perfectly represent the dynamics of
the underlying data generating process. We propose an algorithm that uses this
prior knowledge, and prove upper bounds on the expected regret after $T$
interactions with the system. In the regime where $T$ is small, the upper
bounds are dominated by a term scales with either $\texttt{poly}(\log T)$ or
$\sqrt{T}$, depending on the prior knowledge available to the learner. When $T$
is large, the regret is dominated by a term that grows with $\delta T$, where
$\delta$ quantifies the level of misspecification. This linear term arises due
to the inability to perfectly estimate the underlying dynamics using the
misspecified basis, and is therefore unavoidable unless the basis matrices are
also adapted online. However, it only dominates for large $T$, after the
sublinear terms arising due to the error in estimating the weights for the
basis matrices become negligible. We provide simulations that validate our
analysis. Our simulations also show that offline data from a collection of
related systems can be used as part of a pre-training stage to estimate a
misspecified dynamics basis, which is in turn used by our adaptive controller.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00080" title="Abstract">arXiv:2401.00080</a> [<a href="/pdf/2401.00080" title="Download PDF">pdf</a>, <a href="/format/2401.00080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large-Scale Re-identification Analysis in Sporting Scenarios: the  Betrayal of Reaching a Critical Point
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Freire-Obreg%C3%B3n%2C+D">David Freire-Obreg&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Lorenzo-Navarro%2C+J">Javier Lorenzo-Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Santana%2C+O+J">Oliverio J. Santana</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Sosa%2C+D">Daniel Hern&#xe1;ndez-Sosa</a>, 
<a href="/search/cs?searchtype=author&query=Castrill%C3%B3n-Santana%2C+M">Modesto Castrill&#xf3;n-Santana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 7th International Joint Conference on Biometrics (IJCB 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Re-identifying participants in ultra-distance running competitions can be
daunting due to the extensive distances and constantly changing terrain. To
overcome these challenges, computer vision techniques have been developed to
analyze runners' faces, numbers on their bibs, and clothing. However, our study
presents a novel gait-based approach for runners' re-identification (re-ID) by
leveraging various pre-trained human action recognition (HAR) models and loss
functions. Our results show that this approach provides promising results for
re-identifying runners in ultra-distance competitions. Furthermore, we
investigate the significance of distinct human body movements when athletes are
approaching their endurance limits and their potential impact on re-ID
accuracy. Our study examines how the recognition of a runner's gait is affected
by a competition's critical point (CP), defined as a moment of severe fatigue
and the point where the finish line comes into view, just a few kilometers away
from this location. We aim to determine how this CP can improve the accuracy of
athlete re-ID. Our experimental results demonstrate that gait recognition can
be significantly enhanced (up to a 9% increase in mAP) as athletes approach
this point. This highlights the potential of utilizing gait recognition in
real-world scenarios, such as ultra-distance competitions or long-duration
surveillance tasks.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00081" title="Abstract">arXiv:2401.00081</a> [<a href="/pdf/2401.00081" title="Download PDF">pdf</a>, <a href="/format/2401.00081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Data Applications in Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potluru%2C+V+K">Vamsi K. Potluru</a>, 
<a href="/search/cs?searchtype=author&query=Borrajo%2C+D">Daniel Borrajo</a>, 
<a href="/search/cs?searchtype=author&query=Coletta%2C+A">Andrea Coletta</a>, 
<a href="/search/cs?searchtype=author&query=Dalmasso%2C+N">Niccol&#xf2; Dalmasso</a>, 
<a href="/search/cs?searchtype=author&query=El-Laham%2C+Y">Yousef El-Laham</a>, 
<a href="/search/cs?searchtype=author&query=Fons%2C+E">Elizabeth Fons</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M">Mohsen Ghassemi</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+S">Sriram Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Gosai%2C+V">Vikesh Gosai</a>, 
<a href="/search/cs?searchtype=author&query=Krea%C4%8Di%C4%87%2C+E">Eleonora Krea&#x10d;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Mani%2C+G">Ganapathy Mani</a>, 
<a href="/search/cs?searchtype=author&query=Obitayo%2C+S">Saheed Obitayo</a>, 
<a href="/search/cs?searchtype=author&query=Paramanand%2C+D">Deepak Paramanand</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+N">Natraj Raman</a>, 
<a href="/search/cs?searchtype=author&query=Solonin%2C+M">Mikhail Solonin</a>, 
<a href="/search/cs?searchtype=author&query=Sood%2C+S">Srijan Sood</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haibei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Veloso%2C+M">Manuela Veloso</a>, 
<a href="/search/cs?searchtype=author&query=Balch%2C+T">Tucker Balch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, journal submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; General Finance (q-fin.GN)

</div>
<p class="mathjax">Synthetic data has made tremendous strides in various commercial settings
including finance, healthcare, and virtual reality. We present a broad overview
of prototypical applications of synthetic data in the financial sector and in
particular provide richer details for a few select ones. These cover a wide
variety of data modalities including tabular, time-series, event-series, and
unstructured arising from both markets and retail financial applications. Since
finance is a highly regulated industry, synthetic data is a potential approach
for dealing with issues related to privacy, fairness, and explainability.
Various metrics are utilized in evaluating the quality and effectiveness of our
approaches in these applications. We conclude with open directions in synthetic
data in the context of the financial domain.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00085" title="Abstract">arXiv:2401.00085</a> [<a href="/pdf/2401.00085" title="Download PDF">pdf</a>, <a href="/format/2401.00085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A dimension reduction approach for loss valuation in credit risk  modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jian He</a>, 
<a href="/search/cs?searchtype=author&query=Khedher%2C+A">Asma Khedher</a>, 
<a href="/search/cs?searchtype=author&query=Spreij%2C+P">Peter Spreij</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Computation (stat.CO)

</div>
<p class="mathjax">This paper addresses the ``curse of dimensionality'' in the loss valuation of
credit risk models. A dimension reduction methodology based on the Bayesian
filter and smoother is proposed. This methodology is designed to achieve a fast
and accurate loss valuation algorithm in credit risk modelling, but it can also
be extended to valuation models of other risk types. The proposed methodology
is generic, robust and can easily be implemented. Moreover, the accuracy of the
proposed methodology in the estimation of expected loss and value-at-risk is
illustrated by numerical experiments. The results suggest that, compared to the
currently most used PCA approach, the proposed methodology provides more
accurate estimation of expected loss and value-at-risk of a loss distribution.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00086" title="Abstract">arXiv:2401.00086</a> [<a href="/pdf/2401.00086" title="Download PDF">pdf</a>, <a href="/format/2401.00086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Policy Administration Cost in an Active Learning Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Si Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fong%2C+P+W+L">Philip W. L. Fong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes a computational model for policy administration. As an
organization evolves, new users and resources are gradually placed under the
mediation of the access control model. Each time such new entities are added,
the policy administrator must deliberate on how the access control policy shall
be revised to reflect the new reality. A well-designed access control model
must anticipate such changes so that the administration cost does not become
prohibitive when the organization scales up. Unfortunately, past Access Control
research does not offer a formal way to quantify the cost of policy
administration. In this work, we propose to model ongoing policy administration
in an active learning framework. Administration cost can be quantified in terms
of query complexity. We demonstrate the utility of this approach by applying it
to the evolution of protection domains. We also modelled different policy
administration strategies in our framework. This allowed us to formally
demonstrate that domain-based policies have a cost advantage over access
control matrices because of the use of heuristic reasoning when the policy
evolves. To the best of our knowledge, this is the first work to employ an
active learning framework to study the cost of policy deliberation and
demonstrate the cost advantage of heuristic policy administration.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00087" title="Abstract">arXiv:2401.00087</a> [<a href="/pdf/2401.00087" title="Download PDF">pdf</a>, <a href="/ps/2401.00087" title="Download PostScript">ps</a>, <a href="/format/2401.00087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Asynchronous Scheme for Rollback Recovery in Message-Passing  Concurrent Programming Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vidal%2C+G">Germ&#xe1;n Vidal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing (SAC '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Rollback recovery strategies are well-known in concurrent and distributed
systems. In this context, recovering from unexpected failures is even more
relevant given the non-deterministic nature of execution, which means that it
is practically impossible to foresee all possible process interactions.
<br />In this work, we consider a message-passing concurrent programming language
where processes interact through message sending and receiving, but shared
memory is not allowed. In this context, we design a checkpoint-based rollback
recovery strategy that does not need a central coordination. For this purpose,
we extend the language with three new operators: check, commit, and rollback.
Furthermore, our approach is purely asynchronous, which is an essential
ingredient to developing a source-to-source program instrumentation
implementing a rollback recovery strategy.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00093" title="Abstract">arXiv:2401.00093</a> [<a href="/pdf/2401.00093" title="Download PDF">pdf</a>, <a href="/format/2401.00093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness-Enhancing Vehicle Rebalancing in the Ride-hailing System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaotong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hanyong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+D">Dingyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yunhan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinhua Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The rapid growth of the ride-hailing industry has revolutionized urban
transportation worldwide. Despite its benefits, equity concerns arise as
underserved communities face limited accessibility to affordable ride-hailing
services. A key issue in this context is the vehicle rebalancing problem, where
idle vehicles are moved to areas with anticipated demand. Without equitable
approaches in demand forecasting and rebalancing strategies, these practices
can further deepen existing inequities. In the realm of ride-hailing, three
main facets of fairness are recognized: algorithmic fairness, fairness to
drivers, and fairness to riders. This paper focuses on enhancing both
algorithmic and rider fairness through a novel vehicle rebalancing method. We
introduce an approach that combines a Socio-Aware Spatial-Temporal Graph
Convolutional Network (SA-STGCN) for refined demand prediction and a
fairness-integrated Matching-Integrated Vehicle Rebalancing (MIVR) model for
subsequent vehicle rebalancing. Our methodology is designed to reduce
prediction discrepancies and ensure equitable service provision across diverse
regions. The effectiveness of our system is evaluated using simulations based
on real-world ride-hailing data. The results suggest that our proposed method
enhances both accuracy and fairness in forecasting ride-hailing demand,
ultimately resulting in more equitable vehicle rebalancing in subsequent
operations. Specifically, the algorithm developed in this study effectively
reduces the standard deviation and average customer wait times by 6.48% and
0.49%, respectively. This achievement signifies a beneficial outcome for
ride-hailing platforms, striking a balance between operational efficiency and
fairness.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00094" title="Abstract">arXiv:2401.00094</a> [<a href="/pdf/2401.00094" title="Download PDF">pdf</a>, <a href="/format/2401.00094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Enhanced Negatives for Training Language-Based Object  Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shiyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Long Zhao</a>, 
<a href="/search/cs?searchtype=author&query=G%2C+V+K+B">Vijay Kumar B.G</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+Y">Yumin Suh</a>, 
<a href="/search/cs?searchtype=author&query=Metaxas%2C+D+N">Dimitris N. Metaxas</a>, 
<a href="/search/cs?searchtype=author&query=Chandraker%2C+M">Manmohan Chandraker</a>, 
<a href="/search/cs?searchtype=author&query=Schulter%2C+S">Samuel Schulter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The recent progress in language-based open-vocabulary object detection can be
largely attributed to finding better ways of leveraging large-scale data with
free-form text annotations. Training such models with a discriminative
objective function has proven successful, but requires good positive and
negative samples. However, the free-form nature and the open vocabulary of
object descriptions make the space of negatives extremely large. Prior works
randomly sample negatives or use rule-based techniques to build them. In
contrast, we propose to leverage the vast knowledge built into modern
generative models to automatically build negatives that are more relevant to
the original data. Specifically, we use large-language-models to generate
negative text descriptions, and text-to-image diffusion models to also generate
corresponding negative images. Our experimental analysis confirms the relevance
of the generated negative data, and its use in language-based detectors
improves performance on two complex benchmarks.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00095" title="Abstract">arXiv:2401.00095</a> [<a href="/pdf/2401.00095" title="Download PDF">pdf</a>, <a href="/format/2401.00095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Essay Scoring in a Brazilian Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matsuoka%2C+F+A">Felipe Akio Matsuoka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents a novel Automatic Essay Scoring (AES) algorithm tailored
for the Portuguese-language essays of Brazil's Exame Nacional do Ensino M\'edio
(ENEM), addressing the challenges in traditional human grading systems. Our
approach leverages advanced deep learning techniques to align closely with
human grading criteria, targeting efficiency and scalability in evaluating
large volumes of student essays. This research not only responds to the
logistical and financial constraints of manual grading in Brazilian educational
assessments but also promises to enhance fairness and consistency in scoring,
marking a significant step forward in the application of AES in large-scale
academic settings.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00104" title="Abstract">arXiv:2401.00104</a> [<a href="/pdf/2401.00104" title="Download PDF">pdf</a>, <a href="/format/2401.00104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal State Distillation for Explainable Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenhao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xufeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fryen%2C+T">Thilo Fryen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Jae Hee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengdi Li</a>, 
<a href="/search/cs?searchtype=author&query=Magg%2C+S">Sven Magg</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://lukaswill.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Reinforcement learning (RL) is a powerful technique for training intelligent
agents, but understanding why these agents make specific decisions can be quite
challenging. This lack of transparency in RL models has been a long-standing
problem, making it difficult for users to grasp the reasons behind an agent's
behaviour. Various approaches have been explored to address this problem, with
one promising avenue being reward decomposition (RD). RD is appealing as it
sidesteps some of the concerns associated with other methods that attempt to
rationalize an agent's behaviour in a post-hoc manner. RD works by exposing
various facets of the rewards that contribute to the agent's objectives during
training. However, RD alone has limitations as it primarily offers insights
based on sub-rewards and does not delve into the intricate cause-and-effect
relationships that occur within an RL agent's neural model. In this paper, we
present an extension of RD that goes beyond sub-rewards to provide more
informative explanations. Our approach is centred on a causal learning
framework that leverages information-theoretic measures for explanation
objectives that encourage three crucial properties of causal factors:
\emph{causal sufficiency}, \emph{sparseness}, and \emph{orthogonality}. These
properties help us distill the cause-and-effect relationships between the
agent's states and actions or rewards, allowing for a deeper understanding of
its decision-making processes. Our framework is designed to generate local
explanations and can be applied to a wide range of RL tasks with multiple
reward channels. Through a series of experiments, we demonstrate that our
approach offers more meaningful and insightful explanations for the agent's
action selections.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00109" title="Abstract">arXiv:2401.00109</a> [<a href="/pdf/2401.00109" title="Download PDF">pdf</a>, <a href="/format/2401.00109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint symbolic aggregate approximation of time series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinye Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB); Distributed, Parallel, and Cluster Computing (cs.DC); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">The increasing availability of temporal data poses a challenge to time-series
and signal-processing domains due to its high numerosity and complexity.
Symbolic representation outperforms raw data in a variety of engineering
applications due to its storage efficiency, reduced numerosity, and noise
reduction. The most recent symbolic aggregate approximation technique called
ABBA demonstrates outstanding performance in preserving essential shape
information of time series and enhancing the downstream applications. However,
ABBA cannot handle multiple time series with consistent symbols, i.e., the same
symbols from distinct time series are not identical. Also, working with
appropriate ABBA digitization involves the tedious task of tuning the
hyperparameters, such as the number of symbols or tolerance. Therefore, we
present a joint symbolic aggregate approximation that has symbolic consistency,
and show how the hyperparameter of digitization can itself be optimized
alongside the compression tolerance ahead of time. Besides, we propose a novel
computing paradigm that enables parallel computing of symbolic approximation.
The extensive experiments demonstrate its superb performance and outstanding
speed regarding symbolic approximation and reconstruction.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00110" title="Abstract">arXiv:2401.00110</a> [<a href="/pdf/2401.00110" title="Download PDF">pdf</a>, <a href="/format/2401.00110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Model with Perceptual Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shanchuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models trained with mean squared error loss tend to generate
unrealistic samples. Current state-of-the-art models rely on classifier-free
guidance to improve sample quality, yet its surprising effectiveness is not
fully understood. In this paper, We show that the effectiveness of
classifier-free guidance partly originates from it being a form of implicit
perceptual guidance. As a result, we can directly incorporate perceptual loss
in diffusion training to improve sample quality. Since the score matching
objective used in diffusion training strongly resembles the denoising
autoencoder objective used in unsupervised training of perceptual networks, the
diffusion model itself is a perceptual network and can be used to generate
meaningful perceptual loss. We propose a novel self-perceptual objective that
results in diffusion models capable of generating more realistic samples. For
conditional generation, our method only improves sample quality without
entanglement with the conditional input and therefore does not sacrifice sample
diversity. Our method can also improve sample quality for unconditional
generation, which was not possible with classifier-free guidance before.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00112" title="Abstract">arXiv:2401.00112</a> [<a href="/pdf/2401.00112" title="Download PDF">pdf</a>, <a href="/format/2401.00112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Smart Retrofitting and Performance Anomaly Detection for a  Sensorized Vessel: A Maritime Industry Experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+M+H">Mahshid Helali Moghadam</a>, 
<a href="/search/cs?searchtype=author&query=Rzymowski%2C+M">Mateusz Rzymowski</a>, 
<a href="/search/cs?searchtype=author&query=Kulas%2C+L">Lukasz Kulas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The integration of sensorized vessels, enabling real-time data collection and
machine learning-driven data analysis marks a pivotal advancement in the
maritime industry. This transformative technology not only can enhance safety,
efficiency, and sustainability but also usher in a new era of cost-effective
and smart maritime transportation in our increasingly interconnected world.
This study presents a deep learning-driven anomaly detection system augmented
with interpretable machine learning models for identifying performance
anomalies in an industrial sensorized vessel, called TUCANA. We Leverage a
human-in-the-loop unsupervised process that involves utilizing standard and
Long Short-Term Memory (LSTM) autoencoders augmented with interpretable
surrogate models, i.e., random forest and decision tree, to add transparency
and interpretability to the results provided by the deep learning models. The
interpretable models also enable automated rule generation for translating the
inference into human-readable rules. Additionally, the process also includes
providing a projection of the results using t-distributed stochastic neighbor
embedding (t-SNE), which helps with a better understanding of the structure and
relationships within the data and assessment of the identified anomalies. We
empirically evaluate the system using real data acquired from the vessel TUCANA
and the results involve achieving over 80% precision and 90% recall with the
LSTM model used in the process. The interpretable models also provide logical
rules aligned with expert thinking, and the t-SNE-based projection enhances
interpretability. Our system demonstrates that the proposed approach can be
used effectively in real-world scenarios, offering transparency and precision
in performance anomaly detection.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00121" title="Abstract">arXiv:2401.00121</a> [<a href="/pdf/2401.00121" title="Download PDF">pdf</a>, <a href="/format/2401.00121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Contour Integral-Based Algorithm for Computing Generalized Singular  Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yuqi Liu</a>, 
<a href="/search/math?searchtype=author&query=Shan%2C+X">Xinyu Shan</a>, 
<a href="/search/math?searchtype=author&query=Shao%2C+M">Meiyue Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a contour integral-based algorithm for computing a few singular
values of a matrix or a few generalized singular values of a matrix pencil.
Mathematically, the generalized singular values of a matrix pencil are the
eigenvalues of an equivalent Hermitian-definite matrix pencil, known as the
Jordan-Wielandt matrix pencil. However, direct application of the FEAST solver
does not fully exploit the structure of this problem. We analyze several
projection strategies on the Jordan-Wielandt matrix pencil, and propose an
effective and robust scheme tailored to GSVD. Both theoretical analysis and
numerical experiments demonstrate that our algorithm achieves rapid convergence
and satisfactory accuracy.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00125" title="Abstract">arXiv:2401.00125</a> [<a href="/pdf/2401.00125" title="Download PDF">pdf</a>, <a href="/format/2401.00125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Assist: Enhancing Closed-Loop Planning with Language-Based Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharan%2C+S+P">S P Sharan</a>, 
<a href="/search/cs?searchtype=author&query=Pittaluga%2C+F">Francesco Pittaluga</a>, 
<a href="/search/cs?searchtype=author&query=G%2C+V+K+B">Vijay Kumar B G</a>, 
<a href="/search/cs?searchtype=author&query=Chandraker%2C+M">Manmohan Chandraker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Although planning is a crucial component of the autonomous driving stack,
researchers have yet to develop robust planning algorithms that are capable of
safely handling the diverse range of possible driving scenarios. Learning-based
planners suffer from overfitting and poor long-tail performance. On the other
hand, rule-based planners generalize well, but might fail to handle scenarios
that require complex driving maneuvers. To address these limitations, we
investigate the possibility of leveraging the common-sense reasoning
capabilities of Large Language Models (LLMs) such as GPT4 and Llama2 to
generate plans for self-driving vehicles. In particular, we develop a novel
hybrid planner that leverages a conventional rule-based planner in conjunction
with an LLM-based planner. Guided by commonsense reasoning abilities of LLMs,
our approach navigates complex scenarios which existing planners struggle with,
produces well-reasoned outputs while also remaining grounded through working
alongside the rule-based approach. Through extensive evaluation on the nuPlan
benchmark, we achieve state-of-the-art performance, outperforming all existing
pure learning- and rule-based methods across most metrics. Our code will be
available at https://llmassist.github.io.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00127" title="Abstract">arXiv:2401.00127</a> [<a href="/pdf/2401.00127" title="Download PDF">pdf</a>, <a href="/format/2401.00127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing Boundaries: Exploring Zero Shot Object Classification with Large  Multimodal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+A">Ashhadul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+M+R">Md. Rafiul Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Zaghouani%2C+W">Wajdi Zaghouani</a>, 
<a href="/search/cs?searchtype=author&query=Belhaouari%2C+S+B">Samir Brahim Belhaouari</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+Z">Zubair Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,6 figures, 4 tables, Accepted on The International Symposium on Foundation and Large Language Models (FLLM2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> https://fllm-conference.org/2023/
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">$ $The synergy of language and vision models has given rise to Large Language
and Vision Assistant models (LLVAs), designed to engage users in rich
conversational experiences intertwined with image-based queries. These
comprehensive multimodal models seamlessly integrate vision encoders with Large
Language Models (LLMs), expanding their applications in general-purpose
language and visual comprehension. The advent of Large Multimodal Models (LMMs)
heralds a new era in Artificial Intelligence (AI) assistance, extending the
horizons of AI utilization. This paper takes a unique perspective on LMMs,
exploring their efficacy in performing image classification tasks using
tailored prompts designed for specific datasets. We also investigate the LLVAs
zero-shot learning capabilities. Our study includes a benchmarking analysis
across four diverse datasets: MNIST, Cats Vs. Dogs, Hymnoptera (Ants Vs. Bees),
and an unconventional dataset comprising Pox Vs. Non-Pox skin images. The
results of our experiments demonstrate the model's remarkable performance,
achieving classification accuracies of 85\%, 100\%, 77\%, and 79\% for the
respective datasets without any fine-tuning. To bolster our analysis, we assess
the model's performance post fine-tuning for specific tasks. In one instance,
fine-tuning is conducted over a dataset comprising images of faces of children
with and without autism. Prior to fine-tuning, the model demonstrated a test
accuracy of 55\%, which significantly improved to 83\% post fine-tuning. These
results, coupled with our prior findings, underscore the transformative
potential of LLVAs and their versatile applications in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00128" title="Abstract">arXiv:2401.00128</a> [<a href="/pdf/2401.00128" title="Download PDF">pdf</a>, <a href="/ps/2401.00128" title="Download PostScript">ps</a>, <a href="/format/2401.00128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying intra-tumoral genetic heterogeneity of glioblastoma toward  precision medicine using MRI and a data-inclusive machine learning algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lujia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hairong Wang</a>, 
<a href="/search/cs?searchtype=author&query=D%27Angelo%2C+F">Fulvio D&#x27;Angelo</a>, 
<a href="/search/cs?searchtype=author&query=Curtin%2C+L">Lee Curtin</a>, 
<a href="/search/cs?searchtype=author&query=Sereduk%2C+C+P">Christopher P. Sereduk</a>, 
<a href="/search/cs?searchtype=author&query=De+Leon%2C+G">Gustavo De Leon</a>, 
<a href="/search/cs?searchtype=author&query=Singleton%2C+K+W">Kyle W. Singleton</a>, 
<a href="/search/cs?searchtype=author&query=Urcuyo%2C+J">Javier Urcuyo</a>, 
<a href="/search/cs?searchtype=author&query=Hawkins-Daarud%2C+A">Andrea Hawkins-Daarud</a>, 
<a href="/search/cs?searchtype=author&query=Jackson%2C+P+R">Pamela R. Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+C">Chandan Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Zimmerman%2C+R+S">Richard S. Zimmerman</a>, 
<a href="/search/cs?searchtype=author&query=Patra%2C+D+P">Devi P. Patra</a>, 
<a href="/search/cs?searchtype=author&query=Bendok%2C+B+R">Bernard R. Bendok</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K+A">Kris A. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Nakaji%2C+P">Peter Nakaji</a>, 
<a href="/search/cs?searchtype=author&query=Donev%2C+K">Kliment Donev</a>, 
<a href="/search/cs?searchtype=author&query=Baxter%2C+L+C">Leslie C. Baxter</a>, 
<a href="/search/cs?searchtype=author&query=Mruga%C5%82a%2C+M+M">Maciej M. Mruga&#x142;a</a>, 
<a href="/search/cs?searchtype=author&query=Ceccarelli%2C+M">Michele Ceccarelli</a>, 
<a href="/search/cs?searchtype=author&query=Iavarone%2C+A">Antonio Iavarone</a>, 
<a href="/search/cs?searchtype=author&query=Swanson%2C+K+R">Kristin R. Swanson</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+N+L">Nhan L. Tran</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L+S">Leland S. Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC)

</div>
<p class="mathjax">Glioblastoma (GBM) is one of the most aggressive and lethal human cancers.
Intra-tumoral genetic heterogeneity poses a significant challenge for
treatment. Biopsy is invasive, which motivates the development of non-invasive,
MRI-based machine learning (ML) models to quantify intra-tumoral genetic
heterogeneity for each patient. This capability holds great promise for
enabling better therapeutic selection to improve patient outcomes. We proposed
a novel Weakly Supervised Ordinal Support Vector Machine (WSO-SVM) to predict
regional genetic alteration status within each GBM tumor using MRI. WSO-SVM was
applied to a unique dataset of 318 image-localized biopsies with spatially
matched multiparametric MRI from 74 GBM patients. The model was trained to
predict the regional genetic alteration of three GBM driver genes (EGFR,
PDGFRA, and PTEN) based on features extracted from the corresponding region of
five MRI contrast images. For comparison, a variety of existing ML algorithms
were also applied. The classification accuracy of each gene was compared
between the different algorithms. The SHapley Additive exPlanations (SHAP)
method was further applied to compute contribution scores of different contrast
images. Finally, the trained WSO-SVM was used to generate prediction maps
within the tumoral area of each patient to help visualize the intra-tumoral
genetic heterogeneity. This study demonstrated the feasibility of using MRI and
WSO-SVM to enable non-invasive prediction of intra-tumoral regional genetic
alteration for each GBM patient, which can inform future adaptive therapies for
individualized oncology.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00132" title="Abstract">arXiv:2401.00132</a> [<a href="/pdf/2401.00132" title="Download PDF">pdf</a>, <a href="/format/2401.00132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive learning-based agent modeling for deep reinforcement  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenhao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yu-Cheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Teng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-agent systems often require agents to collaborate with or compete
against other agents with diverse goals, behaviors, or strategies. Agent
modeling is essential when designing adaptive policies for intelligent machine
agents in multiagent systems, as this is the means by which the ego agent
understands other agents' behavior and extracts their meaningful policy
representations. These representations can be used to enhance the ego agent's
adaptive policy which is trained by reinforcement learning. However, existing
agent modeling approaches typically assume the availability of local
observations from other agents (modeled agents) during training or a long
observation trajectory for policy adaption. To remove these constrictive
assumptions and improve agent modeling performance, we devised a Contrastive
Learning-based Agent Modeling (CLAM) method that relies only on the local
observations from the ego agent during training and execution. With these
observations, CLAM is capable of generating consistent high-quality policy
representations in real-time right from the beginning of each episode. We
evaluated the efficacy of our approach in both cooperative and competitive
multi-agent environments. Our experiments demonstrate that our approach
achieves state-of-the-art on both cooperative and competitive tasks,
highlighting the potential of contrastive learning-based agent modeling for
enhancing reinforcement learning.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00134" title="Abstract">arXiv:2401.00134</a> [<a href="/pdf/2401.00134" title="Download PDF">pdf</a>, <a href="/format/2401.00134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unicron: Economizing Self-Healing LLM Training at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tao He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xue Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+K">Kun Qian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Training large-scale language models is increasingly critical in various
domains, but it is hindered by frequent failures, leading to significant time
and economic costs. Current failure recovery methods in cloud-based settings
inadequately address the diverse and complex scenarios that arise, focusing
narrowly on erasing downtime for individual tasks without considering the
overall cost impact on a cluster. We introduce Unicron, a workload manager
designed for efficient self-healing in large-scale language model training.
Unicron optimizes the training process by minimizing failure-related costs
across multiple concurrent tasks within a cluster. Its key features include
in-band error detection for real-time error identification without extra
overhead, a dynamic cost-aware plan generation mechanism for optimal
reconfiguration, and an efficient transition strategy to reduce downtime during
state changes. Deployed on a 128-GPU distributed cluster, Unicron demonstrates
up to a 1.9x improvement in training efficiency over state-of-the-art methods,
significantly reducing failure recovery costs and enhancing the reliability of
large-scale language model training.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00137" title="Abstract">arXiv:2401.00137</a> [<a href="/pdf/2401.00137" title="Download PDF">pdf</a>, <a href="/format/2401.00137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSL-OTA: Unveiling Backdoor Threats in Self-Supervised Learning for  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Changchun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Liming Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Run Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenhao Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The extensive adoption of Self-supervised learning (SSL) has led to an
increased security threat from backdoor attacks. While existing research has
mainly focused on backdoor attacks in image classification, there has been
limited exploration into their implications for object detection. In this work,
we propose the first backdoor attack designed for object detection tasks in SSL
scenarios, termed Object Transform Attack (SSL-OTA). SSL-OTA employs a trigger
capable of altering predictions of the target object to the desired category,
encompassing two attacks: Data Poisoning Attack (NA) and Dual-Source Blending
Attack (DSBA). NA conducts data poisoning during downstream fine-tuning of the
object detector, while DSBA additionally injects backdoors into the pre-trained
encoder. We establish appropriate metrics and conduct extensive experiments on
benchmark datasets, demonstrating the effectiveness and utility of our proposed
attack. Notably, both NA and DSBA achieve high attack success rates (ASR) at
extremely low poisoning rates (0.5%). The results underscore the importance of
considering backdoor threats in SSL-based object detection and contribute a
novel perspective to the field.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00139" title="Abstract">arXiv:2401.00139</a> [<a href="/pdf/2401.00139" title="Download PDF">pdf</a>, <a href="/format/2401.00139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Knowledge All Large Language Models Needed for Causal Reasoning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hengrui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Rui Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A Python implementation of our proposed method is available at <a href="https://github.com/ncsulsj/Causal_LLM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">This paper explores the causal reasoning of large language models (LLMs) to
enhance their interpretability and reliability in advancing artificial
intelligence. Despite the proficiency of LLMs in a range of tasks, their
potential for understanding causality requires further exploration. We propose
a novel causal attribution model that utilizes "do-operators" for constructing
counterfactual scenarios, allowing us to systematically quantify the influence
of input numerical data and LLMs' pre-existing knowledge on their causal
reasoning processes. Our newly developed experimental setup assesses LLMs'
reliance on contextual information and inherent knowledge across various
domains. Our evaluation reveals that LLMs' causal reasoning ability depends on
the context and domain-specific knowledge provided, and supports the argument
that "knowledge is, indeed, what LLMs principally require for sound causal
reasoning". On the contrary, in the absence of knowledge, LLMs still maintain a
degree of causal reasoning using the available numerical data, albeit with
limitations in the calculations.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00141" title="Abstract">arXiv:2401.00141</a> [<a href="/pdf/2401.00141" title="Download PDF">pdf</a>, <a href="/format/2401.00141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realizing Open and Decentralized Marketplace for Exchanging Data of  Expected IoT Behaviors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M">Minzhao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Gharakheili%2C+H+H">Hassan Habibi Gharakheili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript is the full version of our paper [1] accepted to the IEEE/IFIP NOMS 2024 conference. IEEE/IFIP NOMS, Seoul, South Korea, May 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Databases (cs.DB)

</div>
<p class="mathjax">With rising concerns about the security of IoT devices, network operators
need better ways to handle potential risks. Luckily, IoT devices show
consistent patterns in how they communicate. But despite previous efforts, it
remains unclear how knowledge of these patterns can be made available. As data
marketplaces become popular in different domains, this paper1 proposes creating
a special marketplace focused on IoT cybersecurity. The goal is to openly share
knowledge about IoT devices' behavior, using structured data formats like
Manufacturer Usage Description (MUD) files. To make this work, we employ
technologies like blockchain and smart contracts to build a practical and
secure foundation for sharing and accessing important information about how IoT
devices should behave on the network. Our contributions are two-fold. (1) We
identify the essential features of an effective marketplace for sharing data
related to the expected behaviors of IoT devices. We develop a smart contract
on the Ethereum blockchain with five concrete functions; and, (2) We implement
a prototype of our marketplace in a private chain environment-our codes are
publicly released. We demonstrate how effectively our marketplace functions
through experiments involving MUD files from consumer IoT devices. Our
marketplace enables suppliers and consumers to share MUD data on the Ethereum
blockchain for under a hundred dollars, promoting accessibility and
participation.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00143" title="Abstract">arXiv:2401.00143</a> [<a href="/pdf/2401.00143" title="Download PDF">pdf</a>, <a href="/ps/2401.00143" title="Download PostScript">ps</a>, <a href="/format/2401.00143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synced Parallel Control Paths for Multi-Task System Operation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mirafzal%2C+B">Behrooz Mirafzal</a>, 
<a href="/search/eess?searchtype=author&query=Fateh%2C+F">Fariba Fateh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Numerous systems require the capability to switch their operational modes
seamlessly without any disruptions. The "Synced Parallel Control Paths" method
is an innovative control system architecture designed for seamless mode
switching. It features multiple parallel control paths: the primary path for
essential operational references, and the auxiliary paths that continuously
align with the primary, ensuring synchronized operation. This reduces
operational disruptions common in traditional systems during mode transitions.
This approach enhances system stability, reliability, and adaptability, making
it a significant advancement in control technology for a variety of dynamic
systems.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00148" title="Abstract">arXiv:2401.00148</a> [<a href="/pdf/2401.00148" title="Download PDF">pdf</a>, <a href="/format/2401.00148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPatch: A Triggered Physical Adversarial Patch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenjun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiaoyu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yushi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shibo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in 32nd USENIX Security Symposium (USENIX Security 23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Autonomous vehicles increasingly utilize the vision-based perception module
to acquire information about driving environments and detect obstacles. Correct
detection and classification are important to ensure safe driving decisions.
Existing works have demonstrated the feasibility of fooling the perception
models such as object detectors and image classifiers with printed adversarial
patches. However, most of them are indiscriminately offensive to every passing
autonomous vehicle. In this paper, we propose TPatch, a physical adversarial
patch triggered by acoustic signals. Unlike other adversarial patches, TPatch
remains benign under normal circumstances but can be triggered to launch a
hiding, creating or altering attack by a designed distortion introduced by
signal injection attacks towards cameras. To avoid the suspicion of human
drivers and make the attack practical and robust in the real world, we propose
a content-based camouflage method and an attack robustness enhancement method
to strengthen it. Evaluations with three object detectors, YOLO V3/V5 and
Faster R-CNN, and eight image classifiers demonstrate the effectiveness of
TPatch in both the simulation and the real world. We also discuss possible
defenses at the sensor, algorithm, and system levels.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00151" title="Abstract">arXiv:2401.00151</a> [<a href="/pdf/2401.00151" title="Download PDF">pdf</a>, <a href="/format/2401.00151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CamPro: Camera-based Anti-Facial Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenjun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiani Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yushi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiaoyu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NDSS Symposium 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The proliferation of images captured from millions of cameras and the
advancement of facial recognition (FR) technology have made the abuse of FR a
severe privacy threat. Existing works typically rely on obfuscation, synthesis,
or adversarial examples to modify faces in images to achieve anti-facial
recognition (AFR). However, the unmodified images captured by camera modules
that contain sensitive personally identifiable information (PII) could still be
leaked. In this paper, we propose a novel approach, CamPro, to capture inborn
AFR images. CamPro enables well-packed commodity camera modules to produce
images that contain little PII and yet still contain enough information to
support other non-sensitive vision applications, such as person detection.
Specifically, CamPro tunes the configuration setup inside the camera image
signal processor (ISP), i.e., color correction matrix and gamma correction, to
achieve AFR, and designs an image enhancer to keep the image quality for
possible human viewers. We implemented and validated CamPro on a
proof-of-concept camera, and our experiments demonstrate its effectiveness on
ten state-of-the-art black-box FR models. The results show that CamPro images
can significantly reduce face identification accuracy to 0.3\% while having
little impact on the targeted non-sensitive vision application. Furthermore, we
find that CamPro is resilient to adaptive attackers who have re-trained their
FR models using images generated by CamPro, even with full knowledge of
privacy-preserving ISP parameters.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00154" title="Abstract">arXiv:2401.00154</a> [<a href="/pdf/2401.00154" title="Download PDF">pdf</a>, <a href="/ps/2401.00154" title="Download PostScript">ps</a>, <a href="/format/2401.00154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AClassiHonk: A System Framework to Annotate and Classify Vehicular Honk  from Road Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maitya%2C+B">Biswajit Maitya</a>, 
<a href="/search/cs?searchtype=author&query=Alima%2C+A">Abdul Alima</a>, 
<a href="/search/cs?searchtype=author&query=Charana%2C+P+S+R">Popuri Sree Rama Charana</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabartib%2C+A">Amlan Chakrabartib</a>, 
<a href="/search/cs?searchtype=author&query=Nandia%2C+S">Subrata Nandia</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjeea%2C+S">Sanghita Bhattacharjeea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Recent studies emphasize that vehicular honking contributes to over 50% of
noise pollution in developing urban and suburban areas. Frequent honking
negatively impacts health, road safety, and the environment. Recognizing and
classifying different vehicle honks could offer valuable insights into
environmental noise pollution. Existing research on outdoor sound
classification and honk detection lacks the ability to classify honks based on
vehicle types, limiting contextual information inference for locations, areas,
or traffic. Therefore, it becomes imperative to design a system that can detect
and classify honks of different types of vehicles from which we can infer some
contextual information. In this paper, we have developed a novel framework
AClassiHonk that performs raw vehicular honk sensing, data labeling and
classifies the honk into three major groups, i.e., light-weight vehicles,
medium-weight vehicles, and heavy-weight vehicles. We collected the raw audio
samples of different vehicular honking based on spatio-temporal characteristics
and converted them into spectrogram images. We have proposed a deep
learning-based Multi-label Autoencoder model (MAE) for automated labeling of
the unlabeled data samples, which provides 97.64% accuracy in contrast to
existing deep learning-based data labeling methods. Further, we have used
various pre-trained models, namely Inception V3, ResNet50, MobileNet,
ShuffleNet, and proposed an Ensembled Transfer Learning model (EnTL) for
vehicle honks classification and performed comparative analysis. Results reveal
that EnTL exhibits the best performance compared to pre-trained models and
achieves 96.72% accuracy in our dataset. In addition, we have identified a
context of a location based on these classified honk signatures in a city.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00155" title="Abstract">arXiv:2401.00155</a> [<a href="/pdf/2401.00155" title="Download PDF">pdf</a>, <a href="/format/2401.00155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comprehensive framework for occluded human pose estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Linhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinxin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kedong Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Occlusion presents a significant challenge in human pose estimation. The
challenges posed by occlusion can be attributed to the following factors: 1)
Data: The collection and annotation of occluded human pose samples are
relatively challenging. 2) Feature: Occlusion can cause feature confusion due
to the high similarity between the target person and interfering individuals.
3) Inference: Robust inference becomes challenging due to the loss of complete
body structural information. The existing methods designed for occluded human
pose estimation usually focus on addressing only one of these factors. In this
paper, we propose a comprehensive framework DAG (Data, Attention, Graph) to
address the performance degradation caused by occlusion. Specifically, we
introduce the mask joints with instance paste data augmentation technique to
simulate occlusion scenarios. Additionally, an Adaptive Discriminative
Attention Module (ADAM) is proposed to effectively enhance the features of
target individuals. Furthermore, we present the Feature-Guided Multi-Hop GCN
(FGMP-GCN) to fully explore the prior knowledge of body structure and improve
pose estimation results. Through extensive experiments conducted on three
benchmark datasets for occluded human pose estimation, we demonstrate that the
proposed method outperforms existing methods. Code and data will be publicly
available.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00158" title="Abstract">arXiv:2401.00158</a> [<a href="/pdf/2401.00158" title="Download PDF">pdf</a>, <a href="/format/2401.00158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained  Language Models for Question Answering over Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jinhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP-23-Main; simple but effective SOTA on CWQ under a weak-supervised setting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Question Answering over Knowledge Graph (KGQA) aims to seek answer entities
for the natural language question from a large-scale Knowledge Graph~(KG). To
better perform reasoning on KG, recent work typically adopts a pre-trained
language model~(PLM) to model the question, and a graph neural network~(GNN)
based module to perform multi-hop reasoning on the KG. Despite the
effectiveness, due to the divergence in model architecture, the PLM and GNN are
not closely integrated, limiting the knowledge sharing and fine-grained feature
interactions. To solve it, we aim to simplify the above two-module approach,
and develop a more capable PLM that can directly support subgraph reasoning for
KGQA, namely ReasoningLM. In our approach, we propose a subgraph-aware
self-attention mechanism to imitate the GNN for performing structured
reasoning, and also adopt an adaptation tuning strategy to adapt the model
parameters with 20,000 subgraphs with synthesized questions. After adaptation,
the PLM can be parameter-efficient fine-tuned on downstream tasks. Experiments
show that ReasoningLM surpasses state-of-the-art models by a large margin, even
with fewer updated parameters and less training data. Our codes and data are
publicly available at~\url{https://github.com/RUCAIBox/ReasoningLM}.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00161" title="Abstract">arXiv:2401.00161</a> [<a href="/pdf/2401.00161" title="Download PDF">pdf</a>, <a href="/format/2401.00161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffHybrid-UQ: Uncertainty Quantification for Differentiable Hybrid  Neural Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhare%2C+D">Deepak Akhare</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tengfei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian-Xun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The hybrid neural differentiable models mark a significant advancement in the
field of scientific machine learning. These models, integrating numerical
representations of known physics into deep neural networks, offer enhanced
predictive capabilities and show great potential for data-driven modeling of
complex physical systems. However, a critical and yet unaddressed challenge
lies in the quantification of inherent uncertainties stemming from multiple
sources. Addressing this gap, we introduce a novel method, DiffHybrid-UQ, for
effective and efficient uncertainty propagation and estimation in hybrid neural
differentiable models, leveraging the strengths of deep ensemble Bayesian
learning and nonlinear transformations. Specifically, our approach effectively
discerns and quantifies both aleatoric uncertainties, arising from data noise,
and epistemic uncertainties, resulting from model-form discrepancies and data
sparsity. This is achieved within a Bayesian model averaging framework, where
aleatoric uncertainties are modeled through hybrid neural models. The unscented
transformation plays a pivotal role in enabling the flow of these uncertainties
through the nonlinear functions within the hybrid model. In contrast, epistemic
uncertainties are estimated using an ensemble of stochastic gradient descent
(SGD) trajectories. This approach offers a practical approximation to the
posterior distribution of both the network parameters and the physical
parameters. Notably, the DiffHybrid-UQ framework is designed for simplicity in
implementation and high scalability, making it suitable for parallel computing
environments. The merits of the proposed method have been demonstrated through
problems governed by both ordinary and partial differentiable equations.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00162" title="Abstract">arXiv:2401.00162</a> [<a href="/pdf/2401.00162" title="Download PDF">pdf</a>, <a href="/format/2401.00162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Optimization with Smooth Guidance Rewards Learned from  Sparse-Reward Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guojian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Faguo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyuan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 23 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The sparsity of reward feedback remains a challenging problem in online deep
reinforcement learning (DRL). Previous approaches have utilized temporal credit
assignment (CA) to achieve impressive results in multiple hard tasks. However,
many CA methods relied on complex architectures or introduced sensitive
hyperparameters to estimate the impact of state-action pairs. Meanwhile, the
premise of the feasibility of CA methods is to obtain trajectories with sparse
rewards, which can be troublesome in sparse-reward environments with large
state spaces. To tackle these problems, we propose a simple and efficient
algorithm called Policy Optimization with Smooth Guidance (POSG) that leverages
a small set of sparse-reward demonstrations to make reliable and effective
long-term credit assignments while efficiently facilitating exploration. The
key idea is that the relative impact of state-action pairs can be indirectly
estimated using offline demonstrations rather than directly leveraging the
sparse reward trajectories generated by the agent. Specifically, we first
obtain the trajectory importance by considering both the trajectory-level
distance to demonstrations and the returns of the relevant trajectories. Then,
the guidance reward is calculated for each state-action pair by smoothly
averaging the importance of the trajectories through it, merging the
demonstration's distribution and reward information. We theoretically analyze
the performance improvement bound caused by smooth guidance rewards and derive
a new worst-case lower bound on the performance improvement. Extensive results
demonstrate POSG's significant advantages in control performance and
convergence speed compared to benchmark DRL algorithms. Notably, the specific
metrics and quantifiable results are investigated to demonstrate the
superiority of POSG.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00163" title="Abstract">arXiv:2401.00163</a> [<a href="/pdf/2401.00163" title="Download PDF">pdf</a>, <a href="/format/2401.00163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A clean-label graph backdoor attack method in node classification task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xiaogang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Ming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yujing Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dongdong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Backdoor attacks in the traditional graph neural networks (GNNs) field are
easily detectable due to the dilemma of confusing labels. To explore the
backdoor vulnerability of GNNs and create a more stealthy backdoor attack
method, a clean-label graph backdoor attack method(CGBA) in the node
classification task is proposed in this paper. Differently from existing
backdoor attack methods, CGBA requires neither modification of node labels nor
graph structure. Specifically, to solve the problem of inconsistency between
the contents and labels of the samples, CGBA selects poisoning samples in a
specific target class and uses the label of sample as the target label (i.e.,
clean-label) after injecting triggers into the target samples. To guarantee the
similarity of neighboring nodes, the raw features of the nodes are elaborately
picked as triggers to further improve the concealment of the triggers.
Extensive experiments results show the effectiveness of our method. When the
poisoning rate is 0.04, CGBA can achieve an average attack success rate of
87.8%, 98.9%, 89.1%, and 98.5%, respectively.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00164" title="Abstract">arXiv:2401.00164</a> [<a href="/pdf/2401.00164" title="Download PDF">pdf</a>, <a href="/ps/2401.00164" title="Download PostScript">ps</a>, <a href="/format/2401.00164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Stream Inclusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruess%2C+H">Harald Ruess</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We study solutions to systems of stream inclusions 'f in T(f)', where T is
assumed to be causal in the sense that elements in output streams are
determined by a finite history of inputs. For solving these inclusions we
develop a correspondence of causality and contraction with respect to the
prefix distance on streams. Now, based on this causality-contraction
correspondence, we apply fixpoint principles for the spherically complete
ultrametric space of streams to obtain solutions for causal stream inclusions.
The underlying fixpoint iterations induce fixpoint induction principles for
reasoning about solutions of causal stream inclusions. In addition, these
fixpoint approximations induce anytime algorithms for computing finite stream
prefixes of solutions. We illustrate the use of these developments for some
central concepts of system design.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00165" title="Abstract">arXiv:2401.00165</a> [<a href="/pdf/2401.00165" title="Download PDF">pdf</a>, <a href="/format/2401.00165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating the Impact of False Negatives in Dense Retrieval with  Contrastive Confidence Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yeqin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Cam-Tu Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In open-domain Question Answering (QA), dense retrieval is crucial for
finding relevant passages for answer generation. Typically, contrastive
learning is used to train a retrieval model that maps passages and queries to
the same semantic space. The objective is to make similar ones closer and
dissimilar ones further apart. However, training such a system is challenging
due to the false negative issue, where relevant passages may be missed during
data annotation. Hard negative sampling, which is commonly used to improve
contrastive learning, can introduce more noise in training. This is because
hard negatives are those closer to a given query, and thus more likely to be
false negatives. To address this issue, we propose a novel contrastive
confidence regularizer for Noise Contrastive Estimation (NCE) loss, a commonly
used loss for dense retrieval. Our analysis shows that the regularizer helps
dense retrieval models be more robust against false negatives with a
theoretical guarantee. Additionally, we propose a model-agnostic method to
filter out noisy negative passages in the dataset, improving any downstream
dense retrieval models. Through experiments on three datasets, we demonstrate
that our method achieves better retrieval performance in comparison to existing
state-of-the-art dense retrieval systems.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00166" title="Abstract">arXiv:2401.00166</a> [<a href="/pdf/2401.00166" title="Download PDF">pdf</a>, <a href="/ps/2401.00166" title="Download PostScript">ps</a>, <a href="/format/2401.00166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Block-Level MU-MISO Interference Exploitation Precoding: Optimal  Structure and Explicit Duality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xuewen Liao</a>, 
<a href="/search/cs?searchtype=author&query=Masouros%2C+C">Christos Masouros</a>, 
<a href="/search/cs?searchtype=author&query=Swindlehurst%2C+A+L">A. L. Swindlehurst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper investigates block-level interference exploitation (IE) precoding
for multi-user multiple-input single-output (MU-MISO) downlink systems. To
overcome the need for symbol-level IE precoding to frequently update the
precoding matrix, we propose to jointly optimize all the precoders or transmit
signals within a transmission block. The resultant precoders only need to be
updated once per block, and while not necessarily constant over all the symbol
slots, we refer to the technique as block-level slot-variant IE precoding.
Through a careful examination of the optimal structure and the explicit duality
inherent in block-level power minimization (PM) and
signal-to-interference-plus-noise ratio (SINR) balancing (SB) problems, we
discover that the joint optimization can be decomposed into subproblems with
smaller variable sizes. As a step further, we propose block-level
slot-invariant IE precoding by adding a structural constraint on the
slot-variant IE precoding to maintain a constant precoder throughout the block.
A novel linear precoder for IE is further presented, and we prove that the
proposed slot-variant and slot-invariant IE precoding share an identical
solution when the number of symbol slots does not exceed the number of users.
Numerical simulations demonstrate that the proposed precoders achieve a
significant complexity reduction compared against benchmark schemes, without
sacrificing performance.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00167" title="Abstract">arXiv:2401.00167</a> [<a href="/pdf/2401.00167" title="Download PDF">pdf</a>, <a href="/format/2401.00167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Partial Symmetry for Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Rongye Shi</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+P">Pu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yongkai Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Simin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+S">Shuhao Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenjun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024. arXiv admin note: text overlap with <a href="/abs/2307.16186">arXiv:2307.16186</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Incorporating symmetry as an inductive bias into multi-agent reinforcement
learning (MARL) has led to improvements in generalization, data efficiency, and
physical consistency. While prior research has succeeded in using perfect
symmetry prior, the realm of partial symmetry in the multi-agent domain remains
unexplored. To fill in this gap, we introduce the partially symmetric Markov
game, a new subclass of the Markov game. We then theoretically show that the
performance error introduced by utilizing symmetry in MARL is bounded, implying
that the symmetry prior can still be useful in MARL even in partial symmetry
situations. Motivated by this insight, we propose the Partial Symmetry
Exploitation (PSE) framework that is able to adaptively incorporate symmetry
prior in MARL under different symmetry-breaking conditions. Specifically, by
adaptively adjusting the exploitation of symmetry, our framework is able to
achieve superior sample efficiency and overall performance of MARL algorithms.
Extensive experiments are conducted to demonstrate the superior performance of
the proposed framework over baselines. Finally, we implement the proposed
framework in real-world multi-robot testbed to show its superiority.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00168" title="Abstract">arXiv:2401.00168</a> [<a href="/pdf/2401.00168" title="Download PDF">pdf</a>, <a href="/format/2401.00168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiform Evolution for High-Dimensional Problems with Low Effective  Dimensionality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yaqing Hou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Piao%2C+H">Haiyin Piao</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+H">Hongwei Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">In this paper, we scale evolutionary algorithms to high-dimensional
optimization problems that deceptively possess a low effective dimensionality
(certain dimensions do not significantly affect the objective function). To
this end, an instantiation of the multiform optimization paradigm is presented,
where multiple low-dimensional counterparts of a target high-dimensional task
are generated via random embeddings. Since the exact relationship between the
auxiliary (low-dimensional) tasks and the target is a priori unknown, a
multiform evolutionary algorithm is developed for unifying all formulations
into a single multi-task setting. The resultant joint optimization enables the
target task to efficiently reuse solutions evolved across various
low-dimensional searches via cross-form genetic transfers, hence speeding up
overall convergence characteristics. To validate the overall efficacy of our
proposed algorithmic framework, comprehensive experimental studies are carried
out on well-known continuous benchmark functions as well as a set of practical
problems in the hyper-parameter tuning of machine learning models and deep
learning models in classification tasks and Predator-Prey games, respectively.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00170" title="Abstract">arXiv:2401.00170</a> [<a href="/pdf/2401.00170" title="Download PDF">pdf</a>, <a href="/ps/2401.00170" title="Download PostScript">ps</a>, <a href="/format/2401.00170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L3Cube-MahaSocialNER: A Social Media based Marathi NER Dataset and BERT  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+H">Harsh Chaudhari</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+A">Anuja Patil</a>, 
<a href="/search/cs?searchtype=author&query=Lavekar%2C+D">Dhanashree Lavekar</a>, 
<a href="/search/cs?searchtype=author&query=Khairnar%2C+P">Pranav Khairnar</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R">Raviraj Joshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Forum for Information Retrieval Evaluation (FIRE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work introduces the L3Cube-MahaSocialNER dataset, the first and largest
social media dataset specifically designed for Named Entity Recognition (NER)
in the Marathi language. The dataset comprises 18,000 manually labeled
sentences covering eight entity classes, addressing challenges posed by social
media data, including non-standard language and informal idioms. Deep learning
models, including CNN, LSTM, BiLSTM, and Transformer models, are evaluated on
the individual dataset with IOB and non-IOB notations. The results demonstrate
the effectiveness of these models in accurately recognizing named entities in
Marathi informal text. The L3Cube-MahaSocialNER dataset offers user-centric
information extraction and supports real-time applications, providing a
valuable resource for public opinion analysis, news, and marketing on social
media platforms. We also show that the zero-shot results of the regular NER
model are poor on the social NER test set thus highlighting the need for more
social NER datasets. The datasets and models are publicly available at
https://github.com/l3cube-pune/MarathiNLP
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00171" title="Abstract">arXiv:2401.00171</a> [<a href="/pdf/2401.00171" title="Download PDF">pdf</a>, <a href="/format/2401.00171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis of a Spectral Numerical Method for a Peridynamic  Formulation of Richards&#x27; Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Difonzo%2C+F+V">Fabio V. Difonzo</a>, 
<a href="/search/math?searchtype=author&query=Pellegrino%2C+S+F">Sabrina F. Pellegrino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study the implementation of a Chebyshev spectral method with forward Euler
integrator to investigate a peridynamic nonlocal formulation of Richards'
equation. We prove the convergence of the fully-discretization of the model
showing the existence and uniqueness of a solution to the weak formulation of
the method by using the compactness properties of the approximated solution and
exploiting the stability of the numerical scheme. We further support our
results through numerical simulations, using initial conditions with different
order of smoothness, showing reliability and robustness of the theoretical
findings presented in the paper.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00175" title="Abstract">arXiv:2401.00175</a> [<a href="/pdf/2401.00175" title="Download PDF">pdf</a>, <a href="/format/2401.00175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Trust Challenges in Blockchain Oracles Using Asymmetric  Byzantine Quorums
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+F">Fahad Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Titouna%2C+C">Chafiq Titouna</a>, 
<a href="/search/cs?searchtype=author&query=Nait-Abdesselam%2C+F">Farid Nait-Abdesselam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Distributed Computing in Blockchain Technology (BCT) hinges on a trust
assumption among independent nodes. Without a third-party interface or what is
known as a Blockchain Oracle, it can not interact with the external world. This
Oracle plays a crucial role by feeding extrinsic data into the Blockchain,
ensuring that Smart Contracts operate accurately in real time. The Oracle
problem arises from the inherent difficulty in verifying the truthfulness of
the data sourced by these Oracles. The genuineness of a Blockchain Oracle is
paramount, as it directly influences the Blockchain's reliability, credibility,
and scalability. To tackle these challenges, a strategy rooted in Byzantine
fault tolerance {\phi} is introduced. Furthermore, an autonomous system for
sustainability and audibility, built on heuristic detection, is put forth. The
effectiveness and precision of the proposed strategy outperformed existing
methods using two real-world datasets, aimed to meet the authenticity standards
for Blockchain Oracles.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00177" title="Abstract">arXiv:2401.00177</a> [<a href="/pdf/2401.00177" title="Download PDF">pdf</a>, <a href="/ps/2401.00177" title="Download PostScript">ps</a>, <a href="/format/2401.00177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principle Interference in Technical and Scientific Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qani%2C+M+I">Mohammad Ibrahim Qani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; History and Philosophy of Physics (physics.hist-ph)

</div>
<p class="mathjax">In this article, I will explore the nature of interference in translation,
especially in technical and scientific texts, using a descriptivist approach. I
will have a brief overview of the historical excursion of interference in
technical and scientific translation. My aim is to explain this phenomenon and
its causes with all its paradoxes, instead of simply condemning it as an
example of supposedly bad translation. Thus, I will focus on its status in the
bibliography of translation, on the motives for and consequences of
interference in specialized translation, as well as on the nature of the
arguments given for and against this phenomenon. Therefore the relationship
between different societies has always been possible with the act of
translation. When civilizations are examined throughout history, it is seen
that the dissemination of knowledge among different societies has been achieved
by translation. These societies have often become aware of the advancements in
technology and science by means of translation. Therefore; translation becomes
very significant in technical contact between societies and humans. Since the
translation of technical texts is the preliminary scope of this thesis, it will
be beneficial to have a brief look at the history of technical translation in
the world.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00180" title="Abstract">arXiv:2401.00180</a> [<a href="/pdf/2401.00180" title="Download PDF">pdf</a>, <a href="/format/2401.00180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auxiliary Network-Enabled Attack Detection and Resilient Control of  Islanded AC Microgrid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vaishnav%2C+V">Vaibhav Vaishnav</a>, 
<a href="/search/eess?searchtype=author&query=Jain%2C+A">Anoop Jain</a>, 
<a href="/search/eess?searchtype=author&query=Sharma%2C+D">Dushyant Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a cyber-resilient distributed control strategy equipped
with attack detection capabilities for islanded AC microgrids in the presence
of bounded stealthy cyber attacks affecting both frequency and power
information exchanged among neighboring distributed generators (DGs). The
proposed control methodology relies on the construction of an auxiliary layer
and the establishment of effective inter-layer cooperation between the actual
DGs in the control layer and the virtual DGs in the auxiliary layer. This
cooperation aims to achieve robust frequency restoration and proportional
active power-sharing. It is shown that the in situ presence of a concealed
auxiliary layer not only guarantees resilience against stealthy bounded attacks
on both frequency and power-sharing but also facilitates a network-enabled
attack identification mechanism. The paper provides rigorous proof of the
stability of the closed-loop system and derives bounds for frequency and power
deviations under attack conditions, offering insights into the impact of the
attack signal, control and pinning gains, and network connectivity on the
system's convergence properties. The performance of the proposed controllers is
illustrated by simulating a networked islanded AC microgrid in a Simulink
environment showcasing both attributes of attack resilience and attack
detection.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00186" title="Abstract">arXiv:2401.00186</a> [<a href="/pdf/2401.00186" title="Download PDF">pdf</a>, <a href="/format/2401.00186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Explanation Against Linear Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lakkapragada%2C+A">Anish Lakkapragada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for NeurIPS 2023, New in ML Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Linear Regression and neural networks are widely used to model data. Neural
networks distinguish themselves from linear regression with their use of
activation functions that enable modeling nonlinear functions. The standard
argument for these activation functions is that without them, neural networks
only can model a line. However, a novel explanation we propose in this paper
for the impracticality of neural networks without activation functions, or
linear neural networks, is that they actually reduce both training and testing
performance. Having more parameters makes LNNs harder to optimize, and thus
they require more training iterations than linear regression to even
potentially converge to the optimal solution. We prove this hypothesis through
an analysis of the optimization of an LNN and rigorous testing comparing the
performance between both LNNs and linear regression on synthethic, noisy
datasets.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00192" title="Abstract">arXiv:2401.00192</a> [<a href="/pdf/2401.00192" title="Download PDF">pdf</a>, <a href="/format/2401.00192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time and Security-Aware Precoding in RIS-Empowered Multi-User  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adam%2C+A+B+M">Abuzar B. M. Adam</a>, 
<a href="/search/cs?searchtype=author&query=Ouamri%2C+M+A">Mohamed Amine Ouamri</a>, 
<a href="/search/cs?searchtype=author&query=Muthanna%2C+M+S+A">Mohammed Saleh Ali Muthanna</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingwang Li</a>, 
<a href="/search/cs?searchtype=author&query=Elhassan%2C+M+A+M">Mohammed A. M. Elhassan</a>, 
<a href="/search/cs?searchtype=author&query=Muthanna%2C+A">Ammar Muthanna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this letter, we propose a deep-unfolding-based framework (DUNet) to
maximize the secrecy rate in reconfigurable intelligent surface (RIS) empowered
multi-user wireless networks. To tailor DUNet, first we relax the problem,
decouple it into beamforming and phase shift subproblems, and propose an
alternative optimization (AO) based solution for the relaxed problem. Second,
we apply Karush-Kuhn-Tucker (KKT) conditions to obtain a closed-form solutions
for the beamforming and the phase shift. Using deep-unfolding mechanism, we
transform the closed-form solutions into a deep learning model (i.e., DUNet)
that achieves a comparable performance to that of AO in terms of accuracy and
about 25.6 times faster.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00193" title="Abstract">arXiv:2401.00193</a> [<a href="/pdf/2401.00193" title="Download PDF">pdf</a>, <a href="/format/2401.00193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KAXAI: An Integrated Environment for Knowledge Analysis and Explainable  AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barua%2C+S">Saikat Barua</a>, 
<a href="/search/cs?searchtype=author&query=Momen%2C+D+S">Dr. Sifat Momen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Mathematical Software (cs.MS)

</div>
<p class="mathjax">In order to fully harness the potential of machine learning, it is crucial to
establish a system that renders the field more accessible and less daunting for
individuals who may not possess a comprehensive understanding of its
intricacies. The paper describes the design of a system that integrates AutoML,
XAI, and synthetic data generation to provide a great UX design for users. The
system allows users to navigate and harness the power of machine learning while
abstracting its complexities and providing high usability. The paper proposes
two novel classifiers, Logistic Regression Forest and Support Vector Tree, for
enhanced model performance, achieving 96\% accuracy on a diabetes dataset and
93\% on a survey dataset. The paper also introduces a model-dependent local
interpreter called MEDLEY and evaluates its interpretation against LIME,
Greedy, and Parzen. Additionally, the paper introduces LLM-based synthetic data
generation, library-based data generation, and enhancing the original dataset
with GAN. The findings on synthetic data suggest that enhancing the original
dataset with GAN is the most reliable way to generate synthetic data, as
evidenced by KS tests, standard deviation, and feature importance. The authors
also found that GAN works best for quantitative datasets.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00194" title="Abstract">arXiv:2401.00194</a> [<a href="/pdf/2401.00194" title="Download PDF">pdf</a>, <a href="/ps/2401.00194" title="Download PostScript">ps</a>, <a href="/format/2401.00194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Identifiability from Modulo Measurements under DFT Sensing Matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+F">Fengzhong Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Soh%2C+D+W">De Wen Soh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Unlimited sampling was recently introduced to deal with the clipping or
saturation of measurements where a modulo operator is applied before sampling.
In this paper, we investigate the identifiability of the model where
measurements are acquired under a discrete Fourier transform (DFT) sensing
matrix first followed by a modulo operator (modulo-DFT). Firstly, based on the
theorems of cyclotomic polynomials, we derive a sufficient condition for
uniquely identifying the original signal in modulo-DFT. Additionally, for
periodic bandlimited signals (PBSs) under unlimited sampling which can be
viewed as a special case of modulo-DFT, the necessary and sufficient condition
for the unique recovery of the original signal are provided. Moreover, we show
that when the oversampling factor exceeds $3(1+1/P)$, PBS is always
identifiable from the modulo samples, where $P$ is the number of harmonics
including the fundamental component in the positive frequency part.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00195" title="Abstract">arXiv:2401.00195</a> [<a href="/pdf/2401.00195" title="Download PDF">pdf</a>, <a href="/ps/2401.00195" title="Download PostScript">ps</a>, <a href="/format/2401.00195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information acquisition in Adapt/Exchange decisions: When do people  check alternative solution principles?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+R">Romy M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Pohl%2C+M">Maria Pohl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Many problems can be solved in two ways: either by adapting an existing
solution, or by exchanging it for a new one. To investigate under what
conditions people consider new solutions, we traced their information
acquisition processes in a simulated mechanical engineering task. Within a
multi-step optimisation procedure, participants could either adapt the
properties of a currently used machine component, or exchange this component
for a new one. They had the opportunity to check whether the solutions met a
set of requirements, which was varied systematically. We investigated whether
participants would consistently check both solutions, or whether they would
satisfice, ignoring the new solution as long as the current one was good
enough. The results clearly refuted consistent checking, but only partly
confirmed satisficing. On the one hand, participants indeed checked the new
solution least often when the current one was applicable without problems. On
the other hand, in this case the new solution still was not fully ignored.
However, the latter finding could be traced back to a few participants who
diverged from our anticipated strategy of first checking the current solution,
and directly went for the new one. The results suggest that in Adapt/Exchange
decisions, people do not usually check both solutions in an unbiased manner,
but rely on existing solutions as long as they are good enough.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00200" title="Abstract">arXiv:2401.00200</a> [<a href="/pdf/2401.00200" title="Download PDF">pdf</a>, <a href="/format/2401.00200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Gamified Framework to Assist Therapists with the ABA Therapy for  Autism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cordioli%2C+M">Matteo Cordioli</a>, 
<a href="/search/cs?searchtype=author&query=Delfino%2C+L">Laura Delfino</a>, 
<a href="/search/cs?searchtype=author&query=Romani%2C+A">Alessia Romani</a>, 
<a href="/search/cs?searchtype=author&query=Mortini%2C+E">Elisa Mortini</a>, 
<a href="/search/cs?searchtype=author&query=Lanzi%2C+P+L">Pier Luca Lanzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We present a framework to assist therapists and children with autism spectrum
disorder in their Applied Behavioral Analysis (ABA) therapy. The framework was
designed in collaboration with Spazio Autismo, an autism center in Mantova,
Italy. The framework is a first step toward transitioning from the current
paper-based to fully digital-supported therapy. We evaluated the framework over
four months with 18 children diagnosed with classic autism, ranging from 4 to 7
years old. The framework integrates a mobile app that children and therapists
use during the sessions with a backend for managing therapy workflow and
monitoring progress. Our preliminary results show that the framework can
improve the efficacy of the therapy sessions, reducing non-therapeutic time,
increasing patient focus, and quickening the completion of the assigned
objectives. It can also support therapists in preparing learning materials,
data acquisition, and reporting. Finally, the framework demonstrated improved
privacy and security of patients' data while maintaining reliability.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00205" title="Abstract">arXiv:2401.00205</a> [<a href="/pdf/2401.00205" title="Download PDF">pdf</a>, <a href="/ps/2401.00205" title="Download PostScript">ps</a>, <a href="/format/2401.00205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consumer Manipulation via Online Behavioral Advertising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zard%2C+L">Lex Zard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Online behavioral advertising (OBA) has a significant role in the digital
economy. It allows advertisers to target consumers categorized according to
their algorithmically inferred interests based on their behavioral data. As
Alphabet and Meta gatekeep the Internet with their digital platforms and
channel most of the consumer attention online, they are best placed to execute
OBA and earn profits far exceeding fair estimations. There are increasing
concerns that gatekeepers achieve such profitability at the expense of
consumers, advertisers, and publishers who are dependent on their services to
access the Internet. In particular, some claim that OBA systematically exploits
consumers' decision-making vulnerabilities, creating internet infrastructure
and relevant markets that optimize for consumer manipulation.
<br />Intuitively, consumer manipulation via OBA comes in tension with the ideal of
consumer autonomy in liberal democracies. Nevertheless, academia has largely
overlooked this phenomenon and instead has primarily focused on privacy and
discrimination concerns of OBA. This article redirects academic discourse and
regulatory focus on consumer manipulation via OBA. In doing so, first, this
article elaborates on how OBA works. Second, it constructs an analytic
framework for understanding manipulation. Third, it applies the theory of
manipulation to OBA. As a result, this article illustrates the extent to which
OBA leads to consumer manipulation. Crucially, this article is purely analytic
and avoids normative evaluation of consumer manipulation via OBA. Evaluating
consumer manipulation harms of OBA is an equally important but separate task
and is pursued in another publication.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00207" title="Abstract">arXiv:2401.00207</a> [<a href="/pdf/2401.00207" title="Download PDF">pdf</a>, <a href="/format/2401.00207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A unified structure-preserving parametric finite element method for  anisotropic surface diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bao%2C+W">Weizhu Bao</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yifei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose and analyze a unified structure-preserving parametric finite
element method (SP-PFEM) for the anisotropic surface diffusion of curves in two
dimensions $(d=2)$ and surfaces in three dimensions $(d=3)$ with an arbitrary
anisotropic surface energy density $\gamma(\boldsymbol{n})$, where
$\boldsymbol{n}\in \mathbb{S}^{d-1}$ represents the outward unit vector. By
introducing a novel unified surface energy matrix
$\boldsymbol{G}_k(\boldsymbol{n})$ depending on $\gamma(\boldsymbol{n})$, the
Cahn--Hoffman $\boldsymbol{\xi}$-vector and a stabilizing function
$k(\boldsymbol{n}):\ \mathbb{S}^{d-1}\to {\mathbb R}$, we obtain a unified and
conservative variational formulation for the anisotropic surface diffusion via
different surface differential operators including the surface gradient
operator, the surface divergence operator and the surface Laplace--Beltrami
operator. A SP-PFEM discretization is presented for the variational problem. In
order to establish the unconditional energy stability of the proposed SP-PFEM
under a very mild condition on $\gamma(\boldsymbol{n})$, we propose a new
framework via {\sl local energy estimate} for proving energy
stability/structure-preserving properties of the parametric finite element
method for the anisotropic surface diffusion. This framework sheds light on how
to prove unconditional energy stability of other numerical methods for
geometric partial differential equations. Extensive numerical results are
reported to demonstrate the efficiency and accuracy as well as
structure-preserving properties of the proposed SP-PFEM for the anisotropic
surface diffusion with arbitrary anisotropic surface energy density
$\gamma(\boldsymbol{n})$ arising from different applications.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00208" title="Abstract">arXiv:2401.00208</a> [<a href="/pdf/2401.00208" title="Download PDF">pdf</a>, <a href="/format/2401.00208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inpaint4DNeRF: Promptable Spatio-Temporal NeRF Inpainting with  Generative Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Han Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haosen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruoxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current Neural Radiance Fields (NeRF) can generate photorealistic novel
views. For editing 3D scenes represented by NeRF, with the advent of generative
models, this paper proposes Inpaint4DNeRF to capitalize on state-of-the-art
stable diffusion models (e.g., ControlNet) for direct generation of the
underlying completed background content, regardless of static or dynamic. The
key advantages of this generative approach for NeRF inpainting are twofold.
First, after rough mask propagation, to complete or fill in previously occluded
content, we can individually generate a small subset of completed images with
plausible content, called seed images, from which simple 3D geometry proxies
can be derived. Second and the remaining problem is thus 3D multiview
consistency among all completed images, now guided by the seed images and their
3D proxies. Without other bells and whistles, our generative Inpaint4DNeRF
baseline framework is general which can be readily extended to 4D dynamic
NeRFs, where temporal consistency can be naturally handled in a similar way as
our multiview consistency.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00209" title="Abstract">arXiv:2401.00209</a> [<a href="/pdf/2401.00209" title="Download PDF">pdf</a>, <a href="/ps/2401.00209" title="Download PostScript">ps</a>, <a href="/format/2401.00209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI and Tempo Estimation: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luck%2C+G">Geoff Luck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The author's goal in this paper is to explore how artificial intelligence
(AI) has been utilised to inform our understanding of and ability to estimate
at scale a critical aspect of musical creativity - musical tempo. The central
importance of tempo to musical creativity can be seen in how it is used to
express specific emotions (Eerola and Vuoskoski 2013), suggest particular
musical styles (Li and Chan 2011), influence perception of expression (Webster
and Weir 2005) and mediate the urge to move one's body in time to the music
(Burger et al. 2014). Traditional tempo estimation methods typically detect
signal periodicities that reflect the underlying rhythmic structure of the
music, often using some form of autocorrelation of the amplitude envelope
(Lartillot and Toiviainen 2007). Recently, AI-based methods utilising
convolutional or recurrent neural networks (CNNs, RNNs) on spectral
representations of the audio signal have enjoyed significant improvements in
accuracy (Aarabi and Peeters 2022). Common AI-based techniques include those
based on probability (e.g., Bayesian approaches, hidden Markov models (HMM)),
classification and statistical learning (e.g., support vector machines (SVM)),
and artificial neural networks (ANNs) (e.g., self-organising maps (SOMs), CNNs,
RNNs, deep learning (DL)). The aim here is to provide an overview of some of
the more common AI-based tempo estimation algorithms and to shine a light on
notable benefits and potential drawbacks of each. Limitations of AI in this
field in general are also considered, as is the capacity for such methods to
account for idiosyncrasies inherent in tempo perception, i.e., how well
AI-based approaches are able to think and act like humans.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00210" title="Abstract">arXiv:2401.00210</a> [<a href="/pdf/2401.00210" title="Download PDF">pdf</a>, <a href="/format/2401.00210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Problem of Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hristova%2C+T">Tsvetelina Hristova</a>, 
<a href="/search/cs?searchtype=author&query=Magee%2C+L">Liam Magee</a>, 
<a href="/search/cs?searchtype=author&query=Soldatic%2C+K">Karen Soldatic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Large Language Models produce sequences learned as statistical patterns from
large corpora. In order not to reproduce corpus biases, after initial training
models must be aligned with human values, preferencing certain continuations
over others. Alignment, which can be viewed as the superimposition of normative
structure onto a statistical model, reveals a conflicted and complex
interrelationship between language and technology. This relationship shapes
theories of language, linguistic practice and subjectivity, which are
especially relevant to the current sophistication in artificially produced
text. We examine this practice of structuration as a two-way interaction
between users and models by analysing how ChatGPT4 redacts perceived
`anomalous' language in fragments of Joyce's Ulysses and the new linguistic
practice of prompt engineering. We then situate this alignment problem
historically, revisiting earlier postwar linguistic debates which counterposed
two views of meaning: as discrete structures, and as continuous probability
distributions. We discuss the largely occluded work of the Moscow Linguistic
School, which sought to reconcile this opposition. Our attention to the Moscow
School and later related arguments by Searle and Kristeva casts the problem of
alignment in a new light: as one involving attention to the social
structuration of linguistic practice, including structuration of anomalies
that, like the Joycean text, exist in defiance of expressive conventions. These
debates around the communicative orientation toward language can help explain
some of the contemporary behaviours and interdependencies that take place
between users and LLMs.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00211" title="Abstract">arXiv:2401.00211</a> [<a href="/pdf/2401.00211" title="Download PDF">pdf</a>, <a href="/format/2401.00211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-TI: Open Traffic Intelligence with Augmented Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Da%2C+L">Longchao Da</a>, 
<a href="/search/cs?searchtype=author&query=Liou%2C+K">Kuanru Liou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tiejin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuesong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiangyong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yezhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages main content, 8 pages appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Transportation has greatly benefited the cities' development in the modern
civilization process. Intelligent transportation, leveraging advanced computer
algorithms, could further increase people's daily commuting efficiency.
However, intelligent transportation, as a cross-discipline, often requires
practitioners to comprehend complicated algorithms and obscure neural networks,
bringing a challenge for the advanced techniques to be trusted and deployed in
practical industries. Recognizing the expressiveness of the pre-trained large
language models, especially the potential of being augmented with abilities to
understand and execute intricate commands, we introduce Open-TI. Serving as a
bridge to mitigate the industry-academic gap, Open-TI is an innovative model
targeting the goal of Turing Indistinguishable Traffic Intelligence, it is
augmented with the capability to harness external traffic analysis packages
based on existing conversations. Marking its distinction, Open-TI is the first
method capable of conducting exhaustive traffic analysis from scratch -
spanning from map data acquisition to the eventual execution in complex
simulations. Besides, Open-TI is able to conduct task-specific embodiment like
training and adapting the traffic signal control policies (TSC), explore demand
optimizations, etc. Furthermore, we explored the viability of LLMs directly
serving as control agents, by understanding the expected intentions from
Open-TI, we designed an agent-to-agent communication mode to support Open-TI
conveying messages to ChatZero (control agent), and then the control agent
would choose from the action space to proceed the execution. We eventually
provide the formal implementation structure, and the open-ended design invites
further community-driven enhancements.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00212" title="Abstract">arXiv:2401.00212</a> [<a href="/pdf/2401.00212" title="Download PDF">pdf</a>, <a href="/format/2401.00212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Multi-Agent Reinforcement Learning for Distributed  Multi-Robot Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sebastian%2C+E">Eduardo Sebastian</a>, 
<a href="/search/cs?searchtype=author&query=Duong%2C+T">Thai Duong</a>, 
<a href="/search/cs?searchtype=author&query=Atanasov%2C+N">Nikolay Atanasov</a>, 
<a href="/search/cs?searchtype=author&query=Montijano%2C+E">Eduardo Montijano</a>, 
<a href="/search/cs?searchtype=author&query=Sagues%2C+C">Carlos Sagues</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is under review at IEEE T-RO
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">The networked nature of multi-robot systems presents challenges in the
context of multi-agent reinforcement learning. Centralized control policies do
not scale with increasing numbers of robots, whereas independent control
policies do not exploit the information provided by other robots, exhibiting
poor performance in cooperative-competitive tasks. In this work we propose a
physics-informed reinforcement learning approach able to learn distributed
multi-robot control policies that are both scalable and make use of all the
available information to each robot. Our approach has three key
characteristics. First, it imposes a port-Hamiltonian structure on the policy
representation, respecting energy conservation properties of physical robot
systems and the networked nature of robot team interactions. Second, it uses
self-attention to ensure a sparse policy representation able to handle
time-varying information at each robot from the interaction graph. Third, we
present a soft actor-critic reinforcement learning algorithm parameterized by
our self-attention port-Hamiltonian control policy, which accounts for the
correlation among robots during training while overcoming the need of value
function factorization. Extensive simulations in different multi-robot
scenarios demonstrate the success of the proposed approach, surpassing previous
multi-robot reinforcement learning solutions in scalability, while achieving
similar or superior performance (with averaged cumulative reward up to x2
greater than the state-of-the-art with robot teams x6 larger than the number of
robots at training time).
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00228" title="Abstract">arXiv:2401.00228</a> [<a href="/pdf/2401.00228" title="Download PDF">pdf</a>, <a href="/format/2401.00228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel-in-time Multilevel Krylov Methods: A Prototype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Erlangga%2C+Y+A">Yogi A. Erlangga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents a parallel-in-time multilevel iterative method for
solving differential algebraic equation, arising from a discretization of
linear time-dependent partial differential equation. The core of the method is
the multilevel Krylov method, introduced by Erlangga and Nabben~{\it [SIAM J.
Sci. Comput., 30(2008), pp. 1572--1595]}. In the method, special time
restriction and interpolation operators are proposed to coarsen the time grid
and to map functions between fine and coarse time grids. The resulting Galerkin
coarse-grid system can be interpreted as time integration of an equivalent
differential algebraic equation associated with a larger time step and a
modified $\theta$-scheme. A perturbed coarse time-grid matrix is used on the
coarsest level to decouple the coarsest-level system, allowing full
parallelization of the method. Within this framework, spatial coarsening can be
included in a natural way, reducing further the size of the coarsest grid
problem to solve. Numerical results are presented for the 1- and 2-dimensional
heat equation using {\it simulated} parallel implementation, suggesting the
potential computational speed-up of up to 9 relative to the single-processor
implementation and the speed-up of about 3 compared to the sequential
$\theta$-scheme.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00230" title="Abstract">arXiv:2401.00230</a> [<a href="/pdf/2401.00230" title="Download PDF">pdf</a>, <a href="/format/2401.00230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer Multivariate Forecasting: Less is More?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingjing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Caesar Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Fang Li</a>, 
<a href="/search/cs?searchtype=author&query=Bouvry%2C+P">Pascal Bouvry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the domain of multivariate forecasting, transformer models stand out as
powerful apparatus, displaying exceptional capabilities in handling messy
datasets from real-world contexts. However, the inherent complexity of these
datasets, characterized by numerous variables and lengthy temporal sequences,
poses challenges, including increased noise and extended model runtime. This
paper focuses on reducing redundant information to elevate forecasting accuracy
while optimizing runtime efficiency. We propose a novel transformer forecasting
framework enhanced by Principal Component Analysis (PCA) to tackle this
challenge. The framework is evaluated by five state-of-the-art (SOTA) models
and four diverse real-world datasets. Our experimental results demonstrate the
framework's ability to minimize prediction errors across all models and
datasets while significantly reducing runtime. From the model perspective, one
of the PCA-enhanced models: PCA+Crossformer, reduces mean square errors (MSE)
by 33.3% and decreases runtime by 49.2% on average. From the dataset
perspective, the framework delivers 14.3% MSE and 76.6% runtime reduction on
Electricity datasets, as well as 4.8% MSE and 86.9% runtime reduction on
Traffic datasets. This study aims to advance various SOTA models and enhance
transformer-based time series forecasting for intricate data.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00236" title="Abstract">arXiv:2401.00236</a> [<a href="/pdf/2401.00236" title="Download PDF">pdf</a>, <a href="/ps/2401.00236" title="Download PostScript">ps</a>, <a href="/format/2401.00236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneously determine elastic impedance and shape by a Newton-type  iterative method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sun%2C+Y">Yao Sun</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+P">Pan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper focuses on the inverse elastic impedance and the geometry problem
by a Cauchy data pair on the access part of the boundary in a two-dimensional
case. Through the decomposition of the displacement, the problem is transform
the solution of into a coupled boundary value problem that involves two scalar
Helmholtz equations. Firstly, a uniqueness result is given, and a non-iterative
algorithm is proposed to solve the data completion problem using a Cauchy data
pair on a known part of the solution domain's boundary. Next, we introduce a
Newton-type iterative method for reconstructing the boundary and the impedance
function using the completion data on the unknown boundary, which is governed
by a specific type of boundary conditions. Finally, we provide several examples
to demonstrate the effectiveness and accuracy of the proposed method.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00237" title="Abstract">arXiv:2401.00237</a> [<a href="/pdf/2401.00237" title="Download PDF">pdf</a>, <a href="/format/2401.00237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Approach for Defect Detection of Wind Turbine Blade Using  Virtual Reality and Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rabbi%2C+M+F">Md Fazle Rabbi</a>, 
<a href="/search/cs?searchtype=author&query=Emon%2C+S+H">Solayman Hossain Emon</a>, 
<a href="/search/cs?searchtype=author&query=Nishat%2C+E+M">Ehtesham Mahmud Nishat</a>, 
<a href="/search/cs?searchtype=author&query=Tzu-Liang">Tzu-Liang</a> (Bill)
<a href="/search/cs?searchtype=author&query=Tseng">Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Ferdoushi%2C+A">Atira Ferdoushi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chun-Che Huang</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+F">Md Fashiar Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Wind turbines are subjected to continuous rotational stresses and unusual
external forces such as storms, lightning, strikes by flying objects, etc.,
which may cause defects in turbine blades. Hence, it requires a periodical
inspection to ensure proper functionality and avoid catastrophic failure. The
task of inspection is challenging due to the remote location and inconvenient
reachability by human inspection. Researchers used images with cropped defects
from the wind turbine in the literature. They neglected possible background
biases, which may hinder real-time and autonomous defect detection using aerial
vehicles such as drones or others. To overcome such challenges, in this paper,
we experiment with defect detection accuracy by having the defects with the
background using a two-step deep-learning methodology. In the first step, we
develop virtual models of wind turbines to synthesize the near-reality images
for four types of common defects - cracks, leading edge erosion, bending, and
light striking damage. The Unity perception package is used to generate wind
turbine blade defects images with variations in background, randomness, camera
angle, and light effects. In the second step, a customized U-Net architecture
is trained to classify and segment the defect in turbine blades. The outcomes
of U-Net architecture have been thoroughly tested and compared with 5-fold
validation datasets. The proposed methodology provides reasonable defect
detection accuracy, making it suitable for autonomous and remote inspection
through aerial vehicles.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00238" title="Abstract">arXiv:2401.00238</a> [<a href="/pdf/2401.00238" title="Download PDF">pdf</a>, <a href="/format/2401.00238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Evaluate Coreference in Literary Texts?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duron-Tejedor%2C+A">Ana-Isabel Duron-Tejedor</a>, 
<a href="/search/cs?searchtype=author&query=Amsili%2C+P">Pascal Amsili</a>, 
<a href="/search/cs?searchtype=author&query=Poibeau%2C+T">Thierry Poibeau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented as a poster at the conference CHR2023 (non archival)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this short paper, we examine the main metrics used to evaluate textual
coreference and we detail some of their limitations. We show that a unique
score cannot represent the full complexity of the problem at stake, and is thus
uninformative, or even misleading. We propose a new way of evaluating
coreference, taking into account the context (in our case, the analysis of
fictions, esp. novels). More specifically, we propose to distinguish long
coreference chains (corresponding to main characters), from short ones
(corresponding to secondary characters), and singletons (isolated elements).
This way, we hope to get more interpretable and thus more informative results
through evaluation.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00241" title="Abstract">arXiv:2401.00241</a> [<a href="/pdf/2401.00241" title="Download PDF">pdf</a>, <a href="/ps/2401.00241" title="Download PostScript">ps</a>, <a href="/format/2401.00241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Super-resolution Reconstruction Network based on Enhanced Swin  Transformer via Alternating Aggregation of Local-Global Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingpin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Changhui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hanrong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Binhui Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Swin Transformer image super-resolution reconstruction network only
relies on the long-range relationship of window attention and shifted window
attention to explore features. This mechanism has two limitations. On the one
hand, it only focuses on global features while ignoring local features. On the
other hand, it is only concerned with spatial feature interactions while
ignoring channel features and channel interactions, thus limiting its
non-linear mapping ability. To address the above limitations, this paper
proposes enhanced Swin Transformer modules via alternating aggregation of
local-global features. In the local feature aggregation stage, this paper
introduces shift convolution to realize the interaction between local spatial
information and channel information. This paper proposes a block sparse global
perception module in the global feature aggregation stage. This module
organizes the spatial information first, then sends the recombination
information into a spatial gating unit to implement the further interaction of
spatial and channel information. Then, a multi-scale self-attention module and
a low-parameter residual channel attention module are introduced to realize
information aggregation at different scales. Finally, the proposed network is
validated on five publicly available datasets. The experimental results show
that the proposed network outperforms the other state-of-the-art
super-resolution networks.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00243" title="Abstract">arXiv:2401.00243</a> [<a href="/pdf/2401.00243" title="Download PDF">pdf</a>, <a href="/format/2401.00243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Penalized Reinforcement Learning from Human Feedback with  Diverse Reward LoRA Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuanzhao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kele Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Dawei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huaimin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reinforcement learning from human feedback (RLHF) emerges as a promising
paradigm for aligning large language models (LLMs). However, a notable
challenge in RLHF is overoptimization, where beyond a certain threshold, the
pursuit of higher rewards leads to a decline in human preferences. In this
paper, we observe the weakness of KL regularization which is commonly employed
in existing RLHF methods to address overoptimization. To mitigate this
limitation, we scrutinize the RLHF objective in the offline dataset and propose
uncertainty-penalized RLHF (UP-RLHF), which incorporates uncertainty
regularization during RL-finetuning. To enhance the uncertainty quantification
abilities for reward models, we first propose a diverse low-rank adaptation
(LoRA) ensemble by maximizing the nuclear norm of LoRA matrix concatenations.
Then we optimize policy models utilizing penalized rewards, determined by both
rewards and uncertainties provided by the diverse reward LoRA ensembles. Our
experimental results, based on two real human preference datasets, showcase the
effectiveness of diverse reward LoRA ensembles in quantifying reward
uncertainty. Additionally, uncertainty regularization in UP-RLHF proves to be
pivotal in mitigating overoptimization, thereby contributing to the overall
performance.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00246" title="Abstract">arXiv:2401.00246</a> [<a href="/pdf/2401.00246" title="Download PDF">pdf</a>, <a href="/format/2401.00246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Large Language Model for Speech Synthesis: An Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+H">Hongkun Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Long Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shujie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shujie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Large language models (LLMs) have made significant advancements in natural
language processing and are concurrently extending the language ability to
other modalities, such as speech and vision. Nevertheless, most of the previous
work focuses on prompting LLMs with perception abilities like auditory
comprehension, and the effective approach for augmenting LLMs with speech
synthesis capabilities remains ambiguous. In this paper, we conduct a
comprehensive empirical exploration of boosting LLMs with the ability to
generate speech, by combining pre-trained LLM LLaMA/OPT and text-to-speech
synthesis model VALL-E. We compare three integration methods between LLMs and
speech synthesis models, including directly fine-tuned LLMs, superposed layers
of LLMs and VALL-E, and coupled LLMs and VALL-E using LLMs as a powerful text
encoder. Experimental results show that, using LoRA method to fine-tune LLMs
directly to boost the speech synthesis capability does not work well, and
superposed LLMs and VALL-E can improve the quality of generated speech both in
speaker similarity and word error rate (WER). Among these three methods,
coupled methods leveraging LLMs as the text encoder can achieve the best
performance, making it outperform original speech synthesis models with a
consistently better speaker similarity and a significant (10.9%) WER reduction.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00247" title="Abstract">arXiv:2401.00247</a> [<a href="/pdf/2401.00247" title="Download PDF">pdf</a>, <a href="/format/2401.00247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing the Limits and Capabilities of Diffusion Models for the Anatomic  Editing of Digital Twins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadry%2C+K">Karim Kadry</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shreya Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Nezami%2C+F+R">Farhad R. Nezami</a>, 
<a href="/search/cs?searchtype=author&query=Edelman%2C+E+R">Elazer R. Edelman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Numerical simulations can model the physical processes that govern
cardiovascular device deployment. When such simulations incorporate digital
twins; computational models of patient-specific anatomy, they can expedite and
de-risk the device design process. Nonetheless, the exclusive use of
patient-specific data constrains the anatomic variability which can be
precisely or fully explored. In this study, we investigate the capacity of
Latent Diffusion Models (LDMs) to edit digital twins to create anatomic
variants, which we term digital siblings. Digital twins and their corresponding
siblings can serve as the basis for comparative simulations, enabling the study
of how subtle anatomic variations impact the simulated deployment of
cardiovascular devices, as well as the augmentation of virtual cohorts for
device assessment. However, while diffusion models have been characterized in
their ability to edit natural images, their capacity to anatomically edit
digital twins has yet to be studied. Using a case example centered on 3D
digital twins of cardiac anatomy, we implement various methods for generating
digital siblings and characterize them through morphological and topological
analyses. We specifically edit digital twins to introduce anatomic variation at
different spatial scales and within localized regions, demonstrating the
existence of bias towards common anatomic features. We further show that such
anatomic bias can be leveraged for virtual cohort augmentation through
selective editing, partially alleviating issues related to dataset imbalance
and lack of diversity. Our experimental framework thus delineates the limits
and capabilities of using latent diffusion models in synthesizing anatomic
variation for in silico trials.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00248" title="Abstract">arXiv:2401.00248</a> [<a href="/pdf/2401.00248" title="Download PDF">pdf</a>, <a href="/format/2401.00248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promoting Segment Anything Model towards Highly Accurate Dichotomous  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+K">Keren Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qijun Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Segmenting any object represents a crucial step towards achieving artificial
general intelligence, and the "Segment Anything Model" (SAM) has significantly
advanced the development of foundational models in computer vision. We have
high expectations regarding whether SAM can enhance highly accurate dichotomous
image segmentation. In fact, the evidence presented in this article
demonstrates that by inputting SAM with simple prompt boxes and utilizing the
results output by SAM as input for IS5Net, we can greatly improve the
effectiveness of highly accurate dichotomous image segmentation.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00254" title="Abstract">arXiv:2401.00254</a> [<a href="/pdf/2401.00254" title="Download PDF">pdf</a>, <a href="/format/2401.00254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Image Modeling via Dynamic Token Morphing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taekyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongyoon Han</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+B">Byeongho Heo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Masked Image Modeling (MIM) arises as a promising option for Vision
Transformers among various self-supervised learning (SSL) methods. The essence
of MIM lies in token-wise masked patch predictions, with targets patchified
from images; or generated by pre-trained tokenizers or models. We argue targets
from the pre-trained models usually exhibit spatial inconsistency, which makes
it excessively challenging for the model to follow to learn more discriminative
representations. To mitigate the issue, we introduce a novel self-supervision
signal based on Dynamic Token Morphing (DTM), which dynamically aggregates
contextually related tokens. DTM can be generally applied to various SSL
frameworks, yet we propose a simple MIM that employs DTM to effectively improve
the performance barely introducing extra training costs. Our experiments on
ImageNet-1K and ADE20K evidently demonstrate the superiority of our methods.
Furthermore, the comparative evaluation of iNaturalist and Fine-grained Visual
Classification datasets further validates the transferability of our method on
various downstream tasks. Our code will be released publicly.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00256" title="Abstract">arXiv:2401.00256</a> [<a href="/pdf/2401.00256" title="Download PDF">pdf</a>, <a href="/ps/2401.00256" title="Download PostScript">ps</a>, <a href="/format/2401.00256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergeometric-Type Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tabuguia%2C+B+T">Bertrand Teguia Tabuguia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We introduce hypergeometric-type sequences. They are linear combinations of
interlaced hypergeometric sequences (of arbitrary interlacements). We prove
that they form a subring of the ring of holonomic sequences. An interesting
family of sequences in this class are those defined by trigonometric functions
with linear arguments in the index and $\pi$, such as Chebyshev polynomials,
$\left(\sin^2\left(n\,\pi/4\right)\cdot\cos\left(n\,\pi/6\right)\right)_n$, and
compositions like $\left(\sin\left(\cos(n\pi/3)\pi\right)\right)_n$.
<br />We describe an algorithm that computes a hypergeometric-type normal form of a
given holonomic $n\text{th}$ term whenever it exists. Our implementation
enables us to generate several identities for terms defined via trigonometric
functions.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00260" title="Abstract">arXiv:2401.00260</a> [<a href="/pdf/2401.00260" title="Download PDF">pdf</a>, <a href="/format/2401.00260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GazeCLIP: Towards Enhancing Gaze Estimation via Text Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+H">Hao Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chuanghui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunhua Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Over the past decade, visual gaze estimation has garnered growing attention
within the research community, thanks to its wide-ranging application
scenarios. While existing estimation approaches have achieved remarkable
success in enhancing prediction accuracy, they primarily infer gaze directions
from single-image signals and discard the huge potentials of the currently
dominant text guidance. Notably, visual-language collaboration has been
extensively explored across a range of visual tasks, such as image synthesis
and manipulation, leveraging the remarkable transferability of large-scale
Contrastive Language-Image Pre-training (CLIP) model. Nevertheless, existing
gaze estimation approaches ignore the rich semantic cues conveyed by linguistic
signals and priors in CLIP feature space, thereby yielding performance
setbacks. In pursuit of making up this gap, we delve deeply into the text-eye
collaboration protocol and introduce a novel gaze estimation framework in this
paper, referred to as GazeCLIP. Specifically, we intricately design a
linguistic description generator to produce text signals with coarse
directional cues. Additionally, a CLIP-based backbone that excels in
characterizing text-eye pairs for gaze estimation is presented. This is
followed by the implementation of a fine-grained multi-modal fusion module
aimed at modeling the interrelationships between heterogeneous inputs.
Extensive experiments on three challenging datasets demonstrate the superiority
of the proposed GazeCLIP which surpasses the previous approaches and achieves
the state-of-the-art estimation accuracy.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00268" title="Abstract">arXiv:2401.00268</a> [<a href="/pdf/2401.00268" title="Download PDF">pdf</a>, <a href="/format/2401.00268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COMMA: Co-Articulated Multi-Modal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lianyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Liqing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zekang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+C">Chi-Man Pun</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI2024. Code is available at <a href="https://github.com/hulianyuyy/COMMA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pretrained large-scale vision-language models such as CLIP have demonstrated
excellent generalizability over a series of downstream tasks. However, they are
sensitive to the variation of input text prompts and need a selection of prompt
templates to achieve satisfactory performance. Recently, various methods have
been proposed to dynamically learn the prompts as the textual inputs to avoid
the requirements of laboring hand-crafted prompt engineering in the fine-tuning
process. We notice that these methods are suboptimal in two aspects. First, the
prompts of the vision and language branches in these methods are usually
separated or uni-directionally correlated. Thus, the prompts of both branches
are not fully correlated and may not provide enough guidance to align the
representations of both branches. Second, it's observed that most previous
methods usually achieve better performance on seen classes but cause
performance degeneration on unseen classes compared to CLIP. This is because
the essential generic knowledge learned in the pretraining stage is partly
forgotten in the fine-tuning process. In this paper, we propose Co-Articulated
Multi-Modal Learning (COMMA) to handle the above limitations. Especially, our
method considers prompts from both branches to generate the prompts to enhance
the representation alignment of both branches. Besides, to alleviate forgetting
about the essential knowledge, we minimize the feature discrepancy between the
learned prompts and the embeddings of hand-crafted prompts in the pre-trained
CLIP in the late transformer layers. We evaluate our method across three
representative tasks of generalization to novel classes, new target datasets
and unseen domain shifts. Experimental results demonstrate the superiority of
our method by exhibiting a favorable performance boost upon all tasks with high
efficiency.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00271" title="Abstract">arXiv:2401.00271</a> [<a href="/pdf/2401.00271" title="Download PDF">pdf</a>, <a href="/format/2401.00271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HybridGait: A Benchmark for Spatial-Temporal Cloth-Changing Gait  Recognition with Hybrid Explorations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yilan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chunlin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+R">Ruiyang Ha</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing gait recognition benchmarks mostly include minor clothing variations
in the laboratory environments, but lack persistent changes in appearance over
time and space. In this paper, we propose the first in-the-wild benchmark
CCGait for cloth-changing gait recognition, which incorporates diverse clothing
changes, indoor and outdoor scenes, and multi-modal statistics over 92 days. To
further address the coupling effect of clothing and viewpoint variations, we
propose a hybrid approach HybridGait that exploits both temporal dynamics and
the projected 2D information of 3D human meshes. Specifically, we introduce a
Canonical Alignment Spatial-Temporal Transformer (CA-STT) module to encode
human joint position-aware features, and fully exploit 3D dense priors via a
Silhouette-guided Deformation with 3D-2D Appearance Projection (SilD) strategy.
Our contributions are twofold: we provide a challenging benchmark CCGait that
captures realistic appearance changes across an expanded and space, and we
propose a hybrid framework HybridGait that outperforms prior works on CCGait
and Gait3D benchmarks. Our project page is available at
https://github.com/HCVLab/HybridGait.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00272" title="Abstract">arXiv:2401.00272</a> [<a href="/pdf/2401.00272" title="Download PDF">pdf</a>, <a href="/format/2401.00272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-space Hierarchical Learning for Goal-guided Conversational  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Can Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zeming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+D">Dejing Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Neurocomputing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Proactively and naturally guiding the dialog from the non-recommendation
context (e.g., Chit-chat) to the recommendation scenario (e.g., Music) is
crucial for the Conversational Recommender System (CRS). Prior studies mainly
focus on planning the next dialog goal~(e.g., chat on a movie star) conditioned
on the previous dialog. However, we find the dialog goals can be simultaneously
observed at different levels, which can be utilized to improve CRS. In this
paper, we propose Dual-space Hierarchical Learning (DHL) to leverage
multi-level goal sequences and their hierarchical relationships for
conversational recommendation. Specifically, we exploit multi-level goal
sequences from both the representation space and the optimization space. In the
representation space, we propose the hierarchical representation learning where
a cross attention module derives mutually enhanced multi-level goal
representations. In the optimization space, we devise the hierarchical weight
learning to reweight lower-level goal sequences, and introduce bi-level
optimization for stable update. Additionally, we propose a soft labeling
strategy to guide optimization gradually. Experiments on two real-world
datasets verify the effectiveness of our approach. Code and data are available
here.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00276" title="Abstract">arXiv:2401.00276</a> [<a href="/pdf/2401.00276" title="Download PDF">pdf</a>, <a href="/format/2401.00276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Second-Order Uncertainty Quantification: Variance-Based Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sale%2C+Y">Yusuf Sale</a>, 
<a href="/search/cs?searchtype=author&query=Hofman%2C+P">Paul Hofman</a>, 
<a href="/search/cs?searchtype=author&query=Wimmer%2C+L">Lisa Wimmer</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCllermeier%2C+E">Eyke H&#xfc;llermeier</a>, 
<a href="/search/cs?searchtype=author&query=Nagler%2C+T">Thomas Nagler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Uncertainty quantification is a critical aspect of machine learning models,
providing important insights into the reliability of predictions and aiding the
decision-making process in real-world applications. This paper proposes a novel
way to use variance-based measures to quantify uncertainty on the basis of
second-order distributions in classification problems. A distinctive feature of
the measures is the ability to reason about uncertainties on a class-based
level, which is useful in situations where nuanced decision-making is required.
Recalling some properties from the literature, we highlight that the
variance-based measures satisfy important (axiomatic) properties. In addition
to this axiomatic approach, we present empirical results showing the measures
to be effective and competitive to commonly used entropy-based measures.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00280" title="Abstract">arXiv:2401.00280</a> [<a href="/pdf/2401.00280" title="Download PDF">pdf</a>, <a href="/format/2401.00280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing TTP Analysis: Harnessing the Power of Encoder-Only and  Decoder-Only Language Models with Retrieval Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fayyazi%2C+R">Reza Fayyazi</a>, 
<a href="/search/cs?searchtype=author&query=Taghdimi%2C+R">Rozhina Taghdimi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S+J">Shanchieh Jay Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Tactics, Techniques, and Procedures (TTPs) outline the methods attackers use
to exploit vulnerabilities. The interpretation of TTPs in the MITRE ATT&amp;CK
framework can be challenging for cybersecurity practitioners due to presumed
expertise, complex dependencies, and inherent ambiguity. Meanwhile,
advancements with Large Language Models (LLMs) have led to recent surge in
studies exploring its uses in cybersecurity operations. This leads us to
question how well encoder-only (e.g., RoBERTa) and decoder-only (e.g., GPT-3.5)
LLMs can comprehend and summarize TTPs to inform analysts of the intended
purposes (i.e., tactics) of a cyberattack procedure. The state-of-the-art LLMs
have shown to be prone to hallucination by providing inaccurate information,
which is problematic in critical domains like cybersecurity. Therefore, we
propose the use of Retrieval Augmented Generation (RAG) techniques to extract
relevant contexts for each cyberattack procedure for decoder-only LLMs (without
fine-tuning). We further contrast such approach against supervised fine-tuning
(SFT) of encoder-only LLMs. Our results reveal that both the direct-use of
decoder-only LLMs (i.e., its pre-trained knowledge) and the SFT of encoder-only
LLMs offer inaccurate interpretation of cyberattack procedures. Significant
improvements are shown when RAG is used for decoder-only LLMs, particularly
when directly relevant context is found. This study further sheds insights on
the limitations and capabilities of using RAG for LLMs in interpreting TTPs.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00282" title="Abstract">arXiv:2401.00282</a> [<a href="/pdf/2401.00282" title="Download PDF">pdf</a>, <a href="/format/2401.00282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Generative Symbolic Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holt%2C+S">Samuel Holt</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhaozhi Qian</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the proceedings of the Eleventh International Conference on Learning Representations (ICLR 2023). <a href="https://iclr.cc/virtual/2023/poster/11782">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Learning Representations (ICLR), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Symbolic regression (SR) aims to discover concise closed-form mathematical
equations from data, a task fundamental to scientific discovery. However, the
problem is highly challenging because closed-form equations lie in a complex
combinatorial search space. Existing methods, ranging from heuristic search to
reinforcement learning, fail to scale with the number of input variables. We
make the observation that closed-form equations often have structural
characteristics and invariances (e.g., the commutative law) that could be
further exploited to build more effective symbolic regression solutions.
Motivated by this observation, our key contribution is to leverage pre-trained
deep generative models to capture the intrinsic regularities of equations,
thereby providing a solid foundation for subsequent optimization steps. We show
that our novel formalism unifies several prominent approaches of symbolic
regression and offers a new perspective to justify and improve on the previous
ad hoc designs, such as the usage of cross-entropy loss during pre-training.
Specifically, we propose an instantiation of our framework, Deep Generative
Symbolic Regression (DGSR). In our experiments, we show that DGSR achieves a
higher recovery rate of true equations in the setting of a larger number of
input variables, and it is more computationally efficient at inference time
than state-of-the-art RL symbolic regression solutions.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00283" title="Abstract">arXiv:2401.00283</a> [<a href="/pdf/2401.00283" title="Download PDF">pdf</a>, <a href="/format/2401.00283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Space Communications: The Last Piece of 6G Space-Air-Ground-Sea  Integrated Network Puzzle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongshan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+K">Keke Ying</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Ziwei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingjing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+R">Rui Na</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhongxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gaojie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yikun Mei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+T">Tianqi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dezhi Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This article presents a comprehensive study on the emerging near-space
communications (NS-COM) within the context of space-air-ground-sea integrated
network (SAGSIN). Specifically, we firstly explore the recent technical
developments of NS-COM, followed by the discussions about motivations behind
integrating NS-COM into SAGSIN. To further demonstrate the necessity of NS-COM,
a comparative analysis between the NS-COM network and other counterparts in
SAGSIN is conducted, covering aspects of deployment, coverage and channel
characteristics. Afterwards, the technical aspects of NS-COM, including channel
modeling, random access, channel estimation, array-based beam management and
joint network optimization, are examined in detail. Furthermore, we explore the
potential applications of NS-COM, such as structural expansion in SAGSIN
communications, remote and urgent communications, weather monitoring and carbon
neutrality. Finally, some promising research avenues are identified, including
near-space-ground direct links, reconfigurable multiple input multiple output
(MIMO) array, federated learning assisted NS-COM, maritime communication and
free space optical (FSO) communication. Overall, this paper highlights that the
NS-COM plays an indispensable role in the SAGSIN puzzle, providing substantial
performance and coverage enhancement to the traditional SAGSIN architecture.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00284" title="Abstract">arXiv:2401.00284</a> [<a href="/pdf/2401.00284" title="Download PDF">pdf</a>, <a href="/format/2401.00284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation is all you need. Prompting Generative Large Language Models  for Annotation Tasks in the Social Sciences. A Primer using Open Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+M">Maximilian Weber</a>, 
<a href="/search/cs?searchtype=author&query=Reichardt%2C+M">Merle Reichardt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper explores the use of open generative Large Language Models (LLMs)
for annotation tasks in the social sciences. The study highlights the
challenges associated with proprietary models, such as limited reproducibility
and privacy concerns, and advocates for the adoption of open (source) models
that can be operated on independent devices. Two examples of annotation tasks,
sentiment analysis in tweets and identification of leisure activities in
childhood aspirational essays are provided. The study evaluates the performance
of different prompting strategies and models (neural-chat-7b-v3-2,
Starling-LM-7B-alpha, openchat_3.5, zephyr-7b-alpha and zephyr-7b-beta). The
results indicate the need for careful validation and tailored prompt
engineering. The study highlights the advantages of open models for data
privacy and reproducibility.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00285" title="Abstract">arXiv:2401.00285</a> [<a href="/pdf/2401.00285" title="Download PDF">pdf</a>, <a href="/format/2401.00285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BusReF: Infrared-Visible images registration and fusion focus on  reconstructible area using one set of features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaojun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kittler%2C+J">Josef Kittler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In a scenario where multi-modal cameras are operating together, the problem
of working with non-aligned images cannot be avoided. Yet, existing image
fusion algorithms rely heavily on strictly registered input image pairs to
produce more precise fusion results, as a way to improve the performance of
downstream high-level vision tasks. In order to relax this assumption, one can
attempt to register images first. However, the existing methods for registering
multiple modalities have limitations, such as complex structures and reliance
on significant semantic information. This paper aims to address the problem of
image registration and fusion in a single framework, called BusRef. We focus on
Infrared-Visible image registration and fusion task (IVRF). In this framework,
the input unaligned image pairs will pass through three stages: Coarse
registration, Fine registration and Fusion. It will be shown that the unified
approach enables more robust IVRF. We also propose a novel training and
evaluation strategy, involving the use of masks to reduce the influence of
non-reconstructible regions on the loss functions, which greatly improves the
accuracy and robustness of the fusion task. Last but not least, a
gradient-aware fusion network is designed to preserve the complementary
information. The advanced performance of this algorithm is demonstrated by
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00286" title="Abstract">arXiv:2401.00286</a> [<a href="/pdf/2401.00286" title="Download PDF">pdf</a>, <a href="/ps/2401.00286" title="Download PostScript">ps</a>, <a href="/format/2401.00286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Threat Hunting: A Future Paradigm for AI-Driven Threat  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sindiramutty%2C+S+R">Siva Raja Sindiramutty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The evolution of cybersecurity has spurred the emergence of autonomous threat
hunting as a pivotal paradigm in the realm of AI-driven threat intelligence.
This review navigates through the intricate landscape of autonomous threat
hunting, exploring its significance and pivotal role in fortifying cyber
defense mechanisms. Delving into the amalgamation of artificial intelligence
(AI) and traditional threat intelligence methodologies, this paper delineates
the necessity and evolution of autonomous approaches in combating contemporary
cyber threats. Through a comprehensive exploration of foundational AI-driven
threat intelligence, the review accentuates the transformative influence of AI
and machine learning on conventional threat intelligence practices. It
elucidates the conceptual framework underpinning autonomous threat hunting,
spotlighting its components, and the seamless integration of AI algorithms
within threat hunting processes.. Insightful discussions on challenges
encompassing scalability, interpretability, and ethical considerations in
AI-driven models enrich the discourse. Moreover, through illuminating case
studies and evaluations, this paper showcases real-world implementations,
underscoring success stories and lessons learned by organizations adopting
AI-driven threat intelligence. In conclusion, this review consolidates key
insights, emphasizing the substantial implications of autonomous threat hunting
for the future of cybersecurity. It underscores the significance of continual
research and collaborative efforts in harnessing the potential of AI-driven
approaches to fortify cyber defenses against evolving threats.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00287" title="Abstract">arXiv:2401.00287</a> [<a href="/pdf/2401.00287" title="Download PDF">pdf</a>, <a href="/format/2401.00287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Art of Defending: A Systematic Evaluation and Analysis of LLM  Defense Strategies on Safety and Over-Defensiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varshney%2C+N">Neeraj Varshney</a>, 
<a href="/search/cs?searchtype=author&query=Dolin%2C+P">Pavel Dolin</a>, 
<a href="/search/cs?searchtype=author&query=Seth%2C+A">Agastya Seth</a>, 
<a href="/search/cs?searchtype=author&query=Baral%2C+C">Chitta Baral</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As Large Language Models (LLMs) play an increasingly pivotal role in natural
language processing applications, their safety concerns become critical areas
of NLP research. This paper presents Safety and Over-Defensiveness Evaluation
(SODE) benchmark: a collection of diverse safe and unsafe prompts with
carefully designed evaluation methods that facilitate systematic evaluation,
comparison, and analysis over 'safety' and 'over-defensiveness.' With SODE, we
study a variety of LLM defense strategies over multiple state-of-the-art LLMs,
which reveals several interesting and important findings, such as (a) the
widely popular 'self-checking' techniques indeed improve the safety against
unsafe inputs, but this comes at the cost of extreme over-defensiveness on the
safe inputs, (b) providing a safety instruction along with in-context exemplars
(of both safe and unsafe inputs) consistently improves safety and also
mitigates undue over-defensiveness of the models, (c) providing contextual
knowledge easily breaks the safety guardrails and makes the models more
vulnerable to generating unsafe responses. Overall, our work reveals numerous
such critical findings that we believe will pave the way and facilitate further
research in improving the safety of LLMs.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00288" title="Abstract">arXiv:2401.00288</a> [<a href="/pdf/2401.00288" title="Download PDF">pdf</a>, <a href="/format/2401.00288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Code Intelligence: Survey, Benchmark and Toolkit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yao Wan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yang He</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+Z">Zhangqian Bi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianguo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yulei Sui</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hai Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Code intelligence leverages machine learning techniques to extract knowledge
from extensive code corpora, with the aim of developing intelligent tools to
improve the quality and productivity of computer programming. Currently, there
is already a thriving research community focusing on code intelligence, with
efforts ranging from software engineering, machine learning, data mining,
natural language processing, and programming languages. In this paper, we
conduct a comprehensive literature review on deep learning for code
intelligence, from the aspects of code representation learning, deep learning
techniques, and application tasks. We also benchmark several state-of-the-art
neural models for code intelligence, and provide an open-source toolkit
tailored for the rapid prototyping of deep-learning-based code intelligence
models. In particular, we inspect the existing code intelligence models under
the basis of code representation learning, and provide a comprehensive overview
to enhance comprehension of the present state of code intelligence.
Furthermore, we publicly release the source code and data resources to provide
the community with a ready-to-use benchmark, which can facilitate the
evaluation and comparison of existing and future code intelligence models
(https://xcodemind.github.io). At last, we also point out several challenging
and promising directions for future research.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00289" title="Abstract">arXiv:2401.00289</a> [<a href="/pdf/2401.00289" title="Download PDF">pdf</a>, <a href="/ps/2401.00289" title="Download PostScript">ps</a>, <a href="/format/2401.00289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASL Champ!: A Virtual Reality Game with Deep-Learning Driven Sign  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+S">Md Shahinur Alam</a>, 
<a href="/search/cs?searchtype=author&query=Lamberton%2C+J">Jason Lamberton</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Leannah%2C+C">Carly Leannah</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+S">Sarah Miller</a>, 
<a href="/search/cs?searchtype=author&query=Palagano%2C+J">Joseph Palagano</a>, 
<a href="/search/cs?searchtype=author&query=de+Bastion%2C+M">Myles de Bastion</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+H+L">Heather L. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Malzkuhn%2C+M">Melissa Malzkuhn</a>, 
<a href="/search/cs?searchtype=author&query=Quandt%2C+L+C">Lorna C. Quandt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We developed an American Sign Language (ASL) learning platform in a Virtual
Reality (VR) environment to facilitate immersive interaction and real-time
feedback for ASL learners. We describe the first game to use an interactive
teaching style in which users learn from a fluent signing avatar and the first
implementation of ASL sign recognition using deep learning within the VR
environment. Advanced motion-capture technology powers an expressive ASL
teaching avatar within an immersive three-dimensional environment. The teacher
demonstrates an ASL sign for an object, prompting the user to copy the sign.
Upon the user's signing, a third-party plugin executes the sign recognition
process alongside a deep learning model. Depending on the accuracy of a user's
sign production, the avatar repeats the sign or introduces a new one. We
gathered a 3D VR ASL dataset from fifteen diverse participants to power the
sign recognition model. The proposed deep learning model's training,
validation, and test accuracy are 90.12%, 89.37%, and 86.66%, respectively. The
functional prototype can teach sign language vocabulary and be successfully
adapted as an interactive ASL learning platform in VR.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00290" title="Abstract">arXiv:2401.00290</a> [<a href="/pdf/2401.00290" title="Download PDF">pdf</a>, <a href="/format/2401.00290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Red Teaming for Large Language Models At Scale: Tackling Hallucinations  on Mathematics Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buszydlik%2C+A">Aleksander Buszydlik</a>, 
<a href="/search/cs?searchtype=author&query=Dobiczek%2C+K">Karol Dobiczek</a>, 
<a href="/search/cs?searchtype=author&query=Oko%C5%84%2C+M+T">Micha&#x142; Teodor Oko&#x144;</a>, 
<a href="/search/cs?searchtype=author&query=Skublicki%2C+K">Konrad Skublicki</a>, 
<a href="/search/cs?searchtype=author&query=Lippmann%2C+P">Philip Lippmann</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to The ART of Safety: Workshop on Adversarial testing and Red-Teaming for generative AI (IJCNLP-AACL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider the problem of red teaming LLMs on elementary calculations and
algebraic tasks to evaluate how various prompting techniques affect the quality
of outputs. We present a framework to procedurally generate numerical questions
and puzzles, and compare the results with and without the application of
several red teaming techniques. Our findings suggest that even though
structured reasoning and providing worked-out examples slow down the
deterioration of the quality of answers, the gpt-3.5-turbo and gpt-4 models are
not well suited for elementary calculations and reasoning tasks, also when
being red teamed.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00297" title="Abstract">arXiv:2401.00297</a> [<a href="/pdf/2401.00297" title="Download PDF">pdf</a>, <a href="/ps/2401.00297" title="Download PostScript">ps</a>, <a href="/format/2401.00297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Reinforcement Learning Routing Algorithm for Congestion Control  in Complex Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yajadda%2C+S+H">Seyed Hassan Yajadda</a>, 
<a href="/search/cs?searchtype=author&query=Safaei%2C+F">Farshad Safaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures, under review at Journal of Systems Science &amp; Complexity
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite technological advancements, the significance of interdisciplinary
subjects like complex networks has grown. Exploring communication within these
networks is crucial, with traffic becoming a key concern due to the expanding
population and increased need for connections. Congestion tends to originate in
specific network areas but quickly proliferates throughout. Consequently,
understanding the transition from a flow-free state to a congested state is
vital. Numerous studies have delved into comprehending the emergence and
control of congestion in complex networks, falling into three general
categories: soft strategies, hard strategies, and resource allocation
strategies. This article introduces a routing algorithm leveraging
reinforcement learning to address two primary objectives: congestion control
and optimizing path length based on the shortest path algorithm, ultimately
enhancing network throughput compared to previous methods. Notably, the
proposed method proves effective not only in Barab\'asi-Albert scale-free
networks but also in other network models such as Watts-Strogatz (small-world)
and Erd\"os-R\'enyi (random network). Simulation experiment results demonstrate
that, across various traffic scenarios and network topologies, the proposed
method can enhance efficiency criteria by up to 30% while reducing maximum node
congestion by five times.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00298" title="Abstract">arXiv:2401.00298</a> [<a href="/pdf/2401.00298" title="Download PDF">pdf</a>, <a href="/ps/2401.00298" title="Download PostScript">ps</a>, <a href="/format/2401.00298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principal-Agent Reward Shaping in MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ben-Porat%2C+O">Omer Ben-Porat</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+Y">Yishay Mansour</a>, 
<a href="/search/cs?searchtype=author&query=Moshkovitz%2C+M">Michal Moshkovitz</a>, 
<a href="/search/cs?searchtype=author&query=Taitler%2C+B">Boaz Taitler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of a paper accepted to AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Principal-agent problems arise when one party acts on behalf of another,
leading to conflicts of interest. The economic literature has extensively
studied principal-agent problems, and recent work has extended this to more
complex scenarios such as Markov Decision Processes (MDPs). In this paper, we
further explore this line of research by investigating how reward shaping under
budget constraints can improve the principal's utility. We study a two-player
Stackelberg game where the principal and the agent have different reward
functions, and the agent chooses an MDP policy for both players. The principal
offers an additional reward to the agent, and the agent picks their policy
selfishly to maximize their reward, which is the sum of the original and the
offered reward. Our results establish the NP-hardness of the problem and offer
polynomial approximation algorithms for two classes of instances: Stochastic
trees and deterministic decision processes with a finite horizon.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00313" title="Abstract">arXiv:2401.00313</a> [<a href="/pdf/2401.00313" title="Download PDF">pdf</a>, <a href="/format/2401.00313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matching of Users and Creators in Two-Sided Markets with Departures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huttenlocher%2C+D">Daniel Huttenlocher</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hannah Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+L">Liang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Ozdaglar%2C+A">Asuman Ozdaglar</a>, 
<a href="/search/cs?searchtype=author&query=Siderius%2C+J">James Siderius</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI); General Economics (econ.GN)

</div>
<p class="mathjax">Many online platforms of today, including social media sites, are two-sided
markets bridging content creators and users. Most of the existing literature on
platform recommendation algorithms largely focuses on user preferences and
decisions, and does not simultaneously address creator incentives. We propose a
model of content recommendation that explicitly focuses on the dynamics of
user-content matching, with the novel property that both users and creators may
leave the platform permanently if they do not experience sufficient engagement.
In our model, each player decides to participate at each time step based on
utilities derived from the current match: users based on alignment of the
recommended content with their preferences, and creators based on their
audience size. We show that a user-centric greedy algorithm that does not
consider creator departures can result in arbitrarily poor total engagement,
relative to an algorithm that maximizes total engagement while accounting for
two-sided departures. Moreover, in stark contrast to the case where only users
or only creators leave the platform, we prove that with two-sided departures,
approximating maximum total engagement within any constant factor is NP-hard.
We present two practical algorithms, one with performance guarantees under mild
assumptions on user preferences, and another that tends to outperform
algorithms that ignore two-sided departures in practice.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00315" title="Abstract">arXiv:2401.00315</a> [<a href="/pdf/2401.00315" title="Download PDF">pdf</a>, <a href="/format/2401.00315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bidirectional Temporal Plan Graph: Enabling Switchable Passing Orders  for More Efficient Multi-Agent Path Finding Plan Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yifan Su</a>, 
<a href="/search/cs?searchtype=author&query=Veerapaneni%2C+R">Rishi Veerapaneni</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaoyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
<p class="mathjax">The Multi-Agent Path Finding (MAPF) problem involves planning collision-free
paths for multiple agents in a shared environment. The majority of MAPF solvers
rely on the assumption that an agent can arrive at a specific location at a
specific timestep. However, real-world execution uncertainties can cause agents
to deviate from this assumption, leading to collisions and deadlocks. Prior
research solves this problem by having agents follow a Temporal Plan Graph
(TPG), enforcing a consistent passing order at every location as defined in the
MAPF plan. However, we show that TPGs are overly strict because, in some
circumstances, satisfying the passing order requires agents to wait
unnecessarily, leading to longer execution time. To overcome this issue, we
introduce a new graphical representation called a Bidirectional Temporal Plan
Graph (BTPG), which allows switching passing orders during execution to avoid
unnecessary waiting time. We design two anytime algorithms for constructing a
BTPG: BTPG-na\"ive and BTPG-optimized. Experimental results show that following
BTPGs consistently outperforms following TPGs, reducing unnecessary waits by
8-20%.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00316" title="Abstract">arXiv:2401.00316</a> [<a href="/pdf/2401.00316" title="Download PDF">pdf</a>, <a href="/ps/2401.00316" title="Download PostScript">ps</a>, <a href="/format/2401.00316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RASP for LSASS: Preventing Mimikatz-Related Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Revazova%2C+A">Anna Revazova</a>, 
<a href="/search/cs?searchtype=author&query=Korkin%2C+I">Igor Korkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Operating Systems (cs.OS)

</div>
<p class="mathjax">The Windows authentication infrastructure relies on the Local Security
Authority (LSA) system, with its integral component being lsass.exe.
Regrettably, this framework is not impervious, presenting vulnerabilities that
attract threat actors with malicious intent. By exploiting documented
vulnerabilities sourced from the CVE database or leveraging sophisticated tools
such as mimikatz, adversaries can successfully compromise user password-address
information.
<br />In this comprehensive analysis, we delve into proactive measures aimed at
fortifying the local authentication subsystem against potential threats.
Moreover, we present empirical evidence derived from practical assessments of
various defensive methodologies, including those articulated previously. This
examination not only underscores the importance of proactive security measures
but also assesses the practical efficacy of these strategies in real-world
contexts.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00320" title="Abstract">arXiv:2401.00320</a> [<a href="/pdf/2401.00320" title="Download PDF">pdf</a>, <a href="/format/2401.00320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DXAI: Explaining Classification by Image Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadar%2C+E">Elnatan Kadar</a>, 
<a href="/search/cs?searchtype=author&query=Gilboa%2C+G">Guy Gilboa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a new way to explain and to visualize neural network
classification through a decomposition-based explainable AI (DXAI). Instead of
providing an explanation heatmap, our method yields a decomposition of the
image into class-agnostic and class-distinct parts, with respect to the data
and chosen classifier. Following a fundamental signal processing paradigm of
analysis and synthesis, the original image is the sum of the decomposed parts.
We thus obtain a radically different way of explaining classification. The
class-agnostic part ideally is composed of all image features which do not
posses class information, where the class-distinct part is its complementary.
This new visualization can be more helpful and informative in certain
scenarios, especially when the attributes are dense, global and additive in
nature, for instance, when colors or textures are essential for class
distinction. Code is available at https://github.com/dxai2024/dxai.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00329" title="Abstract">arXiv:2401.00329</a> [<a href="/pdf/2401.00329" title="Download PDF">pdf</a>, <a href="/format/2401.00329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Burstiness of Distributed Machine Learning Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luangsomboon%2C+N">Natchanon Luangsomboon</a>, 
<a href="/search/cs?searchtype=author&query=Fazel%2C+F">Fahimeh Fazel</a>, 
<a href="/search/cs?searchtype=author&query=Liebeherr%2C+J">J&#xf6;rg Liebeherr</a>, 
<a href="/search/cs?searchtype=author&query=Sobhani%2C+A">Ashkan Sobhani</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+S">Shichao Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xingjun Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Traffic from distributed training of machine learning (ML) models makes up a
large and growing fraction of the traffic mix in enterprise data centers. While
work on distributed ML abounds, the network traffic generated by distributed ML
has received little attention. Using measurements on a testbed network, we
investigate the traffic characteristics generated by the training of the
ResNet-50 neural network with an emphasis on studying its short-term
burstiness. For the latter we propose metrics that quantify traffic burstiness
at different time scales. Our analysis reveals that distributed ML traffic
exhibits a very high degree of burstiness on short time scales, exceeding a
60:1 peak-to-mean ratio on time intervals as long as 5~ms. We observe that
training software orchestrates transmissions in such a way that burst
transmissions from different sources within the same application do not result
in congestion and packet losses. An extrapolation of the measurement data to
multiple applications underscores the challenges of distributed ML traffic for
congestion and flow control algorithms.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00330" title="Abstract">arXiv:2401.00330</a> [<a href="/pdf/2401.00330" title="Download PDF">pdf</a>, <a href="/format/2401.00330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Two-Phase Offline Deep Reinforcement Learning from Preference  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinglun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gagandeep Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we consider the offline preference-based reinforcement learning
problem. We focus on the two-phase learning approach that is prevalent in
previous reinforcement learning from human preference works. We find a
challenge in applying two-phase learning in the offline PBRL setting that the
learned utility model can be too hard for the learning agent to optimize during
the second learning phase. To overcome the challenge, we propose a two-phasing
learning approach under behavior regularization through action clipping. The
insight is that the state-actions which are poorly covered by the dataset can
only provide limited information and increase the complexity of the problem in
the second learning phase. Our method ignores such state-actions during the
second learning phase to achieve higher learning efficiency. We empirically
verify that our method has high learning efficiency on a variety of datasets in
robotic control environments.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00331" title="Abstract">arXiv:2401.00331</a> [<a href="/pdf/2401.00331" title="Download PDF">pdf</a>, <a href="/format/2401.00331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotically proved numerical coupling of a 2D flexural porous plate  with the 3D Stokes fluid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krier%2C+M">Maxime Krier</a>, 
<a href="/search/math?searchtype=author&query=Orlik%2C+J">Julia Orlik</a>, 
<a href="/search/math?searchtype=author&query=Panasenko%2C+G">Grigory Panasenko</a>, 
<a href="/search/math?searchtype=author&query=Steiner%2C+K">Konrad Steiner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">This paper presents an efficient coupling of the 3D Stokes flow interacting
with an effective perforated periodic heterogeneous anisotropic 2D plate. The
effective model was obtained by the asymptotic analysis in earlier works and
here an effective numerical algorithm is given. By $Q_3$ or bi-cubic spacial
interpolation the time-dependent problem was reduced to an algebraic system of
ordinary differential equation in time. Different examples were given,
demonstrating the influence of the structural plate parameters on the solution.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00334" title="Abstract">arXiv:2401.00334</a> [<a href="/pdf/2401.00334" title="Download PDF">pdf</a>, <a href="/format/2401.00334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainability-Driven Leaf Disease Classification using Adversarial  Training and Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Echim%2C+S">Sebastian-Vasile Echim</a>, 
<a href="/search/cs?searchtype=author&query=T%C4%83iatu%2C+I">Iulian-Marius T&#x103;iatu</a>, 
<a href="/search/cs?searchtype=author&query=Cercel%2C+D">Dumitru-Clementin Cercel</a>, 
<a href="/search/cs?searchtype=author&query=Pop%2C+F">Florin Pop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, Accepted by ICAART 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work focuses on plant leaf disease classification and explores three
crucial aspects: adversarial training, model explainability, and model
compression. The models' robustness against adversarial attacks is enhanced
through adversarial training, ensuring accurate classification even in the
presence of threats. Leveraging explainability techniques, we gain insights
into the model's decision-making process, improving trust and transparency.
Additionally, we explore model compression techniques to optimize computational
efficiency while maintaining classification performance. Through our
experiments, we determine that on a benchmark dataset, the robustness can be
the price of the classification accuracy with performance reductions of 3%-20%
for regular tests and gains of 50%-70% for adversarial attack tests. We also
demonstrate that a student model can be 15-25 times more computationally
efficient for a slight performance reduction, distilling the knowledge of more
complex models.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00335" title="Abstract">arXiv:2401.00335</a> [<a href="/pdf/2401.00335" title="Download PDF">pdf</a>, <a href="/ps/2401.00335" title="Download PostScript">ps</a>, <a href="/format/2401.00335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Hebbian learning rules for associative memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lansner%2C+A">Anders Lansner</a>, 
<a href="/search/cs?searchtype=author&query=Ravichandran%2C+N+B">Naresh B Ravichandran</a>, 
<a href="/search/cs?searchtype=author&query=Herman%2C+P">Pawel Herman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Associative memory or content addressable memory is an important component
function in computer science and information processing and is a key concept in
cognitive and computational brain science. Many different neural network
architectures and learning rules have been proposed to model associative memory
of the brain while investigating key functions like pattern completion and
rivalry, noise reduction, and storage capacity. A less investigated but
important function is prototype extraction where the training set comprises
pattern instances generated by distorting prototype patterns and the task of
the trained network is to recall the correct prototype pattern given a new
instance. In this paper we characterize these different aspects of associative
memory performance and benchmark six different learning rules on storage
capacity and prototype extraction. We consider only models with Hebbian
plasticity that operate on sparse distributed representations with unit
activities in the interval [0,1]. We evaluate both non-modular and modular
network architectures and compare performance when trained and tested on
different kinds of sparse random binary pattern sets, including correlated
ones. We show that covariance learning has a robust but low storage capacity
under these conditions and that the Bayesian Confidence Propagation learning
rule (BCPNN) is superior with a good margin in all cases except one, reaching a
three times higher composite score than the second best learning rule tested.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00338" title="Abstract">arXiv:2401.00338</a> [<a href="/pdf/2401.00338" title="Download PDF">pdf</a>, <a href="/ps/2401.00338" title="Download PostScript">ps</a>, <a href="/format/2401.00338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Rapid Scoping Review and Conceptual Analysis of the Educational  Metaverse in the Global South: Socio-Technical Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Anmol Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This paper presents a conceptual insight into the Design of the Metaverse to
facilitate educational transformation in selected developing nations within the
Global South regions, e.g., India. These regions are often afflicted with
socio-economic challenges but rich in cultural diversity. By utilizing a
socio-technical design approach, this study explores the specific needs and
opportunities presented by these diverse settings. A rapid scoping review of
the scant existing literature is conducted to provide fundamental insights. A
novel design methodology was formulated that utilized ChatGPT for ideation,
brainstorming, and literature survey query generation. This paper aims not only
to shed light on the educational possibilities enabled by the Metaverse but
also to highlight design considerations unique to the Global South.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00343" title="Abstract">arXiv:2401.00343</a> [<a href="/pdf/2401.00343" title="Download PDF">pdf</a>, <a href="/format/2401.00343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHARE: Single-view Human Adversarial REconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Revankar%2C+S">Shreelekha Revankar</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+S">Shijia Liao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Junbang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Huaishu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Ming Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The accuracy of 3D Human Pose and Shape reconstruction (HPS) from an image is
progressively improving. Yet, no known method is robust across all image
distortion. To address issues due to variations of camera poses, we introduce
SHARE, a novel fine-tuning method that utilizes adversarial data augmentation
to enhance the robustness of existing HPS techniques. We perform a
comprehensive analysis on the impact of camera poses on HPS reconstruction
outcomes. We first generated large-scale image datasets captured systematically
from diverse camera perspectives. We then established a mapping between camera
poses and reconstruction errors as a continuous function that characterizes the
relationship between camera poses and HPS quality. Leveraging this
representation, we introduce RoME (Regions of Maximal Error), a novel sampling
technique for our adversarial fine-tuning method.
<br />The SHARE framework is generalizable across various single-view HPS methods
and we demonstrate its performance on HMR, SPIN, PARE, CLIFF and ExPose. Our
results illustrate a reduction in mean joint errors across single-view HPS
techniques, for images captured from multiple camera positions without
compromising their baseline performance. In many challenging cases, our method
surpasses the performance of existing models, highlighting its practical
significance for diverse real-world applications.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00353" title="Abstract">arXiv:2401.00353</a> [<a href="/pdf/2401.00353" title="Download PDF">pdf</a>, <a href="/format/2401.00353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EXPLORE -- Explainable Song Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arun%2C+A">Abhinav Arun</a>, 
<a href="/search/cs?searchtype=author&query=Soni%2C+M">Mehul Soni</a>, 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+P">Palash Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Saksham Arora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This study explores the development of an explainable music recommendation
system with enhanced user control. Leveraging a hybrid of collaborative
filtering and content-based filtering, we address the challenges of opaque
recommendation logic and lack of user influence on results. We present a novel
approach combining advanced algorithms and an interactive user interface. Our
methodology integrates Spotify data with user preference analytics to tailor
music suggestions. Evaluation through RMSE and user studies underscores the
efficacy and user satisfaction with our system. The paper concludes with
potential directions for future enhancements in group recommendations and
dynamic feedback integration.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00356" title="Abstract">arXiv:2401.00356</a> [<a href="/pdf/2401.00356" title="Download PDF">pdf</a>, <a href="/format/2401.00356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Driver Agency in RideSharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adenuga%2C+I">Iyadunni Adenuga</a>, 
<a href="/search/cs?searchtype=author&query=Hanrahan%2C+B">Benjamin Hanrahan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Agency is an important human characteristic that users of automated complex
technologies are usually denied. This affects the user's experience leading to
decreased satisfaction and productivity. In this paper, we consider the
ridesharing context and interviewed 7 drivers to understand the controls that
would improve the agency they feel. The results show that they desire
transparency, community and an effective ability to seek redress.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00364" title="Abstract">arXiv:2401.00364</a> [<a href="/pdf/2401.00364" title="Download PDF">pdf</a>, <a href="/format/2401.00364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Finite Time Bounds of Two-Time-Scale Linear Stochastic  Approximation with Markovian Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haque%2C+S+U">Shaan Ul Haque</a>, 
<a href="/search/cs?searchtype=author&query=Khodadadian%2C+S">Sajad Khodadadian</a>, 
<a href="/search/cs?searchtype=author&query=Maguluri%2C+S+T">Siva Theja Maguluri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">Stochastic approximation (SA) is an iterative algorithm to find the fixed
point of an operator given noisy samples of this operator. SA appears in many
areas such as optimization and Reinforcement Learning (RL). When implemented in
practice, the noise that appears in the update of RL algorithms is naturally
Markovian. Furthermore, in some settings, such as gradient TD, SA is employed
in a two-time-scale manner. The mix of Markovian noise along with the
two-time-scale structure results in an algorithm which is complex to analyze
theoretically. In this paper, we characterize a tight convergence bound for the
iterations of linear two-time-scale SA with Markovian noise. Our results show
the convergence behavior of this algorithm given various choices of step sizes.
Applying our result to the well-known TDC algorithm, we show the first
$O(1/\epsilon)$ sample complexity for the convergence of this algorithm,
outperforming all the previous work. Similarly, our results can be applied to
establish the convergence behavior of a variety of RL algorithms, such as
TD-learning with Polyak averaging, GTD, and GTD2.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00365" title="Abstract">arXiv:2401.00365</a> [<a href="/pdf/2401.00365" title="Download PDF">pdf</a>, <a href="/format/2401.00365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HQ-VAE: Hierarchical Discrete Representation Learning with Variational  Bayes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takida%2C+Y">Yuhta Takida</a>, 
<a href="/search/cs?searchtype=author&query=Ikemiya%2C+Y">Yukara Ikemiya</a>, 
<a href="/search/cs?searchtype=author&query=Shibuya%2C+T">Takashi Shibuya</a>, 
<a href="/search/cs?searchtype=author&query=Shimada%2C+K">Kazuki Shimada</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+W">Woosung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+C">Chieh-Hsin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Murata%2C+N">Naoki Murata</a>, 
<a href="/search/cs?searchtype=author&query=Uesaka%2C+T">Toshimitsu Uesaka</a>, 
<a href="/search/cs?searchtype=author&query=Uchida%2C+K">Kengo Uchida</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wei-Hsiang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages with 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Vector quantization (VQ) is a technique to deterministically learn features
with discrete codebook representations. It is commonly performed with a
variational autoencoding model, VQ-VAE, which can be further extended to
hierarchical structures for making high-fidelity reconstructions. However, such
hierarchical extensions of VQ-VAE often suffer from the codebook/layer collapse
issue, where the codebook is not efficiently used to express the data, and
hence degrades reconstruction accuracy. To mitigate this problem, we propose a
novel unified framework to stochastically learn hierarchical discrete
representation on the basis of the variational Bayes framework, called
hierarchically quantized variational autoencoder (HQ-VAE). HQ-VAE naturally
generalizes the hierarchical variants of VQ-VAE, such as VQ-VAE-2 and
residual-quantized VAE (RQ-VAE), and provides them with a Bayesian training
scheme. Our comprehensive experiments on image datasets show that HQ-VAE
enhances codebook usage and improves reconstruction performance. We also
validated HQ-VAE in terms of its applicability to a different modality with an
audio dataset.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00366" title="Abstract">arXiv:2401.00366</a> [<a href="/pdf/2401.00366" title="Download PDF">pdf</a>, <a href="/ps/2401.00366" title="Download PostScript">ps</a>, <a href="/format/2401.00366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Argumentation in Waltz&#x27;s &quot;Emerging Structure of International Politics&#x27;&#x27;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolska%2C+M">Magdalena Wolska</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%B6hlich%2C+B">Bernd Fr&#xf6;hlich</a>, 
<a href="/search/cs?searchtype=author&query=Girgensohn%2C+K">Katrin Girgensohn</a>, 
<a href="/search/cs?searchtype=author&query=Gholiagha%2C+S">Sassan Gholiagha</a>, 
<a href="/search/cs?searchtype=author&query=Kiesel%2C+D">Dora Kiesel</a>, 
<a href="/search/cs?searchtype=author&query=Neyer%2C+J">J&#xfc;rgen Neyer</a>, 
<a href="/search/cs?searchtype=author&query=Riehmann%2C+P">Patrick Riehmann</a>, 
<a href="/search/cs?searchtype=author&query=Sienknecht%2C+M">Mitja Sienknecht</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+B">Benno Stein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present an annotation scheme for argumentative and domain-specific aspects
of scholarly articles on the theory of International Relations. At
argumentation level we identify Claims and Support/Attack relations. At domain
level we model discourse content in terms of Theory and Data-related
statements. We annotate Waltz's 1993 text on structural realism and show that
our scheme can be reliably applied by domain experts enables insights on two
research questions on justifications of claims.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00368" title="Abstract">arXiv:2401.00368</a> [<a href="/pdf/2401.00368" title="Download PDF">pdf</a>, <a href="/format/2401.00368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Text Embeddings with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaolong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linjun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Majumder%2C+R">Rangan Majumder</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">In this paper, we introduce a novel and simple method for obtaining
high-quality text embeddings using only synthetic data and less than 1k
training steps. Unlike existing methods that often depend on multi-stage
intermediate pre-training with billions of weakly-supervised text pairs,
followed by fine-tuning with a few labeled datasets, our method does not
require building complex training pipelines or relying on manually collected
datasets that are often constrained by task diversity and language coverage. We
leverage proprietary LLMs to generate diverse synthetic data for hundreds of
thousands of text embedding tasks across nearly 100 languages. We then
fine-tune open-source decoder-only LLMs on the synthetic data using standard
contrastive loss. Experiments demonstrate that our method achieves strong
performance on highly competitive text embedding benchmarks without using any
labeled data. Furthermore, when fine-tuned with a mixture of synthetic and
labeled data, our model sets new state-of-the-art results on the BEIR and MTEB
benchmarks.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00369" title="Abstract">arXiv:2401.00369</a> [<a href="/pdf/2401.00369" title="Download PDF">pdf</a>, <a href="/format/2401.00369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of biologically plausible neuron models for regression with  spiking neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=De+Florio%2C+M">Mario De Florio</a>, 
<a href="/search/math?searchtype=author&query=Kahana%2C+A">Adar Kahana</a>, 
<a href="/search/math?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper explores the impact of biologically plausible neuron models on the
performance of Spiking Neural Networks (SNNs) for regression tasks. While SNNs
are widely recognized for classification tasks, their application to Scientific
Machine Learning and regression remains underexplored. We focus on the membrane
component of SNNs, comparing four neuron models: Leaky Integrate-and-Fire,
FitzHugh-Nagumo, Izhikevich, and Hodgkin-Huxley. We investigate their effect on
SNN accuracy and efficiency for function regression tasks, by using Euler and
Runge-Kutta 4th-order approximation schemes. We show how more biologically
plausible neuron models improve the accuracy of SNNs while reducing the number
of spikes in the system. The latter represents an energetic gain on actual
neuromorphic chips since it directly reflects the amount of energy required for
the computations.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00370" title="Abstract">arXiv:2401.00370</a> [<a href="/pdf/2401.00370" title="Download PDF">pdf</a>, <a href="/format/2401.00370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UGPNet: Universal Generative Prior for Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hwayoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+K">Kyoungkook Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyeongmin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seung-Hwan Baek</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Sunghyun Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Recent image restoration methods can be broadly categorized into two classes:
(1) regression methods that recover the rough structure of the original image
without synthesizing high-frequency details and (2) generative methods that
synthesize perceptually-realistic high-frequency details even though the
resulting image deviates from the original structure of the input. While both
directions have been extensively studied in isolation, merging their benefits
with a single framework has been rarely studied. In this paper, we propose
UGPNet, a universal image restoration framework that can effectively achieve
the benefits of both approaches by simply adopting a pair of an existing
regression model and a generative model. UGPNet first restores the image
structure of a degraded input using a regression model and synthesizes a
perceptually-realistic image with a generative model on top of the regressed
output. UGPNet then combines the regressed output and the synthesized output,
resulting in a final result that faithfully reconstructs the structure of the
original image in addition to perceptually-realistic textures. Our extensive
experiments on deblurring, denoising, and super-resolution demonstrate that
UGPNet can successfully exploit both regression and generative methods for
high-fidelity image restoration.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00371" title="Abstract">arXiv:2401.00371</a> [<a href="/pdf/2401.00371" title="Download PDF">pdf</a>, <a href="/ps/2401.00371" title="Download PostScript">ps</a>, <a href="/format/2401.00371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Granularity Representation Learning for Sketch-based Dynamic Face  Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Dawei Dai</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Shiyu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In specific scenarios, face sketch can be used to identify a person. However,
drawing a face sketch often requires exceptional skill and is time-consuming,
limiting its widespread applications in actual scenarios. The new framework of
sketch less face image retrieval (SLFIR)[1] attempts to overcome the barriers
by providing a means for humans and machines to interact during the drawing
process. Considering SLFIR problem, there is a large gap between a partial
sketch with few strokes and any whole face photo, resulting in poor performance
at the early stages. In this study, we propose a multigranularity (MG)
representation learning (MGRL) method to address the SLFIR problem, in which we
learn the representation of different granularity regions for a partial sketch,
and then, by combining all MG regions of the sketches and images, the final
distance was determined. In the experiments, our method outperformed
state-of-the-art baselines in terms of early retrieval on two accessible
datasets. Codes are available at https://github.com/ddw2AIGROUP2CQUPT/MGRL.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00374" title="Abstract">arXiv:2401.00374</a> [<a href="/pdf/2401.00374" title="Download PDF">pdf</a>, <a href="/format/2401.00374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMAGE: Towards Unified Holistic Co-Speech Gesture Generation via Masked  Audio Gesture Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Becherini%2C+G">Giorgio Becherini</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yichen Peng</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+M">Mingyang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">You Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+X">Xuefei Zhe</a>, 
<a href="/search/cs?searchtype=author&query=Iwamoto%2C+N">Naoya Iwamoto</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://pantomatrix.github.io/EMAGE/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose EMAGE, a framework to generate full-body human gestures from audio
and masked gestures, encompassing facial, local body, hands, and global
movements. To achieve this, we first introduce BEATX (BEAT-SMPLX-FLAME), a new
mesh-level holistic co-speech dataset. BEATX combines MoShed SMPLX body with
FLAME head parameters and further refines the modeling of head, neck, and
finger movements, offering a community-standardized, high-quality 3D motion
captured dataset. EMAGE leverages masked body gesture priors during training to
boost inference performance. It involves a Masked Audio Gesture Transformer,
facilitating joint training on audio-to-gesture generation and masked gesture
reconstruction to effectively encode audio and body gesture hints. Encoded body
hints from masked gestures are then separately employed to generate facial and
body movements. Moreover, EMAGE adaptively merges speech features from the
audio's rhythm and content and utilizes four compositional VQ-VAEs to enhance
the results' fidelity and diversity. Experiments demonstrate that EMAGE
generates holistic gestures with state-of-the-art performance and is flexible
in accepting predefined spatial-temporal gesture inputs, generating complete,
audio-synchronized results. Our code and dataset are available at
https://pantomatrix.github.io/EMAGE/
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00375" title="Abstract">arXiv:2401.00375</a> [<a href="/pdf/2401.00375" title="Download PDF">pdf</a>, <a href="/ps/2401.00375" title="Download PostScript">ps</a>, <a href="/format/2401.00375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape-programmable Adaptive Multi-material Microrobots for Biomedical  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+L">Liyuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Li Fang</a>, 
<a href="/search/cs?searchtype=author&query=Cappelleri%2C+D+J">David J. Cappelleri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Flagellated microorganisms can swim at low Reynolds numbers and adapt to
changes in their environment. Specifically, the flagella can switch their
shapes or modes through gene expression. In the past decade, efforts have been
made to fabricate and investigate rigid types of microrobots without any
adaptation to the environments. More recently, obtaining adaptive microrobots
mimicking real microorganisms is getting more attention. However, even though
some adaptive microrobots achieved by hydrogels have emerged, the swimming
behaviors of the microrobots before and after the environment-induced
deformations are not predicted in a systematic standardized way. In this work,
experiments, finite element analysis, and dynamic modeling are presented
together to realize a complete understanding of these adaptive microrobots. The
above three parts are cross-verified proving the success of using such methods,
facilitating the bio-applications with shape-programmable and even swimming
performance-programmable microrobots. Moreover, an application of targeted
object delivery using the proposed microrobot has been successfully
demonstrated. Finally, cytotoxicity tests are performed to prove the potential
for using the proposed microrobot for biomedical applications.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00379" title="Abstract">arXiv:2401.00379</a> [<a href="/pdf/2401.00379" title="Download PDF">pdf</a>, <a href="/format/2401.00379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DREAM: Debugging and Repairing AutoML Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+J">Juan Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shiqing Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep Learning models have become an integrated component of modern software
systems. In response to the challenge of model design, researchers proposed
Automated Machine Learning (AutoML) systems, which automatically search for
model architecture and hyperparameters for a given task. Like other software
systems, existing AutoML systems suffer from bugs. We identify two common and
severe bugs in AutoML, performance bug (i.e., searching for the desired model
takes an unreasonably long time) and ineffective search bug (i.e., AutoML
systems are not able to find an accurate enough model). After analyzing the
workflow of AutoML, we observe that existing AutoML systems overlook potential
opportunities in search space, search method, and search feedback, which
results in performance and ineffective search bugs. Based on our analysis, we
design and implement DREAM, an automatic debugging and repairing system for
AutoML systems. It monitors the process of AutoML to collect detailed feedback
and automatically repairs bugs by expanding search space and leveraging a
feedback-driven search strategy. Our evaluation results show that DREAM can
effectively and efficiently repair AutoML bugs.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00383" title="Abstract">arXiv:2401.00383</a> [<a href="/pdf/2401.00383" title="Download PDF">pdf</a>, <a href="/format/2401.00383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Evoked Emotions in Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altarawneh%2C+E">Enas Altarawneh</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Ameeta Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Jenkin%2C+M">Michael Jenkin</a>, 
<a href="/search/cs?searchtype=author&query=Papagelis%2C+M">Manos Papagelis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding and predicting the emotional trajectory in multi-party
multi-turn conversations is of great significance. Such information can be
used, for example, to generate empathetic response in human-machine interaction
or to inform models of pre-emptive toxicity detection. In this work, we
introduce the novel problem of Predicting Emotions in Conversations (PEC) for
the next turn (n+1), given combinations of textual and/or emotion input up to
turn n. We systematically approach the problem by modeling three dimensions
inherently connected to evoked emotions in dialogues, including (i) sequence
modeling, (ii) self-dependency modeling, and (iii) recency modeling. These
modeling dimensions are then incorporated into two deep neural network
architectures, a sequence model and a graph convolutional network model. The
former is designed to capture the sequence of utterances in a dialogue, while
the latter captures the sequence of utterances and the network formation of
multi-party dialogues. We perform a comprehensive empirical evaluation of the
various proposed models for addressing the PEC problem. The results indicate
(i) the importance of the self-dependency and recency model dimensions for the
prediction task, (ii) the quality of simpler sequence models in short
dialogues, (iii) the importance of the graph neural models in improving the
predictions in long dialogues.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00385" title="Abstract">arXiv:2401.00385</a> [<a href="/pdf/2401.00385" title="Download PDF">pdf</a>, <a href="/format/2401.00385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Order-one strong convergence of numerical methods for SDEs without  globally monotone coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dai%2C+L">Lei Dai</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xiaojie Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">To obtain strong convergence rates of numerical schemes, an overwhelming
majority of existing works impose a global monotonicity condition on
coefficients of SDEs. On the contrary, a majority of SDEs from applications do
not have globally monotone coefficients. As a recent breakthrough, the authors
of [Hutzenthaler, Jentzen, Ann. Probab., 2020] originally presented a
perturbation theory for stochastic differential equations (SDEs), which is
crucial to recovering strong convergence rates of numerical schemes in a
non-globally monotone setting. However, only a convergence rate of order $1/2$
was obtained there for time-stepping schemes such as a stopped increment-tamed
Euler-Maruyama (SITEM) method. As an open problem, a natural question was
raised by the aforementioned work as to whether higher convergence rate than
$1/2$ can be obtained when higher order schemes are used. The present work
attempts to solve the tough problem. To this end, we develop some new
perturbation estimates that are able to reveal the order-one strong convergence
of numerical methods. As the first application of the newly developed
estimates, we identify the expected order-one pathwise uniformly strong
convergence of the SITEM method for additive noise driven SDEs and
multiplicative noise driven second order SDEs with non-globally monotone
coefficients. As the other application, we propose and analyze a positivity
preserving explicit Milstein-type method for Lotka-Volterra competition model
driven by multi-dimensional noise, with a pathwise uniformly strong convergence
rate of order one recovered under mild assumptions. These obtained results are
completely new and significantly improve the existing theory. Numerical
experiments are also provided to confirm the theoretical findings.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00388" title="Abstract">arXiv:2401.00388</a> [<a href="/pdf/2401.00388" title="Download PDF">pdf</a>, <a href="/format/2401.00388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusionMind -- Improving question and answering with external context  fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Shreyas Verma</a>, 
<a href="/search/cs?searchtype=author&query=Parmar%2C+M">Manoj Parmar</a>, 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+P">Palash Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Porwal%2C+S">Sanchita Porwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Answering questions using pre-trained language models (LMs) and knowledge
graphs (KGs) presents challenges in identifying relevant knowledge and
performing joint reasoning.We compared LMs (fine-tuned for the task) with the
previously published QAGNN method for the Question-answering (QA) objective and
further measured the impact of additional factual context on the QAGNN
performance. The QAGNN method employs LMs to encode QA context and estimate KG
node importance, and effectively update the question choice entity
representations using Graph Neural Networks (GNNs). We further experimented
with enhancing the QA context encoding by incorporating relevant knowledge
facts for the question stem. The models are trained on the OpenbookQA dataset,
which contains ~6000 4-way multiple choice questions and is widely used as a
benchmark for QA tasks. Through our experimentation, we found that
incorporating knowledge facts context led to a significant improvement in
performance. In contrast, the addition of knowledge graphs to language models
resulted in only a modest increase. This suggests that the integration of
contextual knowledge facts may be more impactful for enhancing question
answering performance compared to solely adding knowledge graphs.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00390" title="Abstract">arXiv:2401.00390</a> [<a href="/pdf/2401.00390" title="Download PDF">pdf</a>, <a href="/format/2401.00390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Horizontal Federated Computer Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandal%2C+P+K">Paul K. Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Leo%2C+C">Cole Leo</a>, 
<a href="/search/cs?searchtype=author&query=Hurley%2C+C">Connor Hurley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the modern world, the amount of visual data recorded has been rapidly
increasing. In many cases, data is stored in geographically distinct locations
and thus requires a large amount of time and space to consolidate. Sometimes,
there are also regulations for privacy protection which prevent data
consolidation. In this work, we present federated implementations for object
detection and recognition using a federated Faster R-CNN (FRCNN) and image
segmentation using a federated Fully Convolutional Network (FCN). Our FRCNN was
trained on 5000 examples of the COCO2017 dataset while our FCN was trained on
the entire train set of the CamVid dataset. The proposed federated models
address the challenges posed by the increasing volume and decentralized nature
of visual data, offering efficient solutions in compliance with privacy
regulations.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00391" title="Abstract">arXiv:2401.00391</a> [<a href="/pdf/2401.00391" title="Download PDF">pdf</a>, <a href="/format/2401.00391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Safety-Critical Closed-loop Traffic Simulation via Guided  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">Wei-Jer Chang</a>, 
<a href="/search/cs?searchtype=author&query=Pittaluga%2C+F">Francesco Pittaluga</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Chandraker%2C+M">Manmohan Chandraker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Evaluating the performance of autonomous vehicle planning algorithms
necessitates simulating long-tail traffic scenarios. Traditional methods for
generating safety-critical scenarios often fall short in realism and
controllability. Furthermore, these techniques generally neglect the dynamics
of agent interactions. To mitigate these limitations, we introduce a novel
closed-loop simulation framework rooted in guided diffusion models. Our
approach yields two distinct advantages: 1) the generation of realistic
long-tail scenarios that closely emulate real-world conditions, and 2) enhanced
controllability, enabling more comprehensive and interactive evaluations. We
achieve this through novel guidance objectives that enhance road progress while
lowering collision and off-road rates. We develop a novel approach to simulate
safety-critical scenarios through an adversarial term in the denoising process,
which allows the adversarial agent to challenge a planner with plausible
maneuvers, while all agents in the scene exhibit reactive and realistic
behaviors. We validate our framework empirically using the NuScenes dataset,
demonstrating improvements in both realism and controllability. These findings
affirm that guided diffusion models provide a robust and versatile foundation
for safety-critical, interactive traffic simulation, extending their utility
across the broader landscape of autonomous driving. For additional resources
and demonstrations, visit our project page at https://safe-sim.github.io.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00393" title="Abstract">arXiv:2401.00393</a> [<a href="/pdf/2401.00393" title="Download PDF">pdf</a>, <a href="/ps/2401.00393" title="Download PostScript">ps</a>, <a href="/format/2401.00393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Model-Driven Synthetic Training Image Generation: An Approach  to Cognition in Rail Defect Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdousi%2C+R">Rahatara Ferdousi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chunsheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+A">M. Anwar Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Laamarti%2C+F">Fedwa Laamarti</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+S">M. Shamim Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 13 figures, Springer Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Recent advancements in cognitive computing, with the integration of deep
learning techniques, have facilitated the development of intelligent cognitive
systems (ICS). This is particularly beneficial in the context of rail defect
detection, where the ICS would emulate human-like analysis of image data for
defect patterns. Despite the success of Convolutional Neural Networks (CNN) in
visual defect classification, the scarcity of large datasets for rail defect
detection remains a challenge due to infrequent accident events that would
result in defective parts and images. Contemporary researchers have addressed
this data scarcity challenge by exploring rule-based and generative data
augmentation models. Among these, Variational Autoencoder (VAE) models can
generate realistic data without extensive baseline datasets for noise modeling.
This study proposes a VAE-based synthetic image generation technique for rail
defects, incorporating weight decay regularization and image reconstruction
loss to prevent overfitting. The proposed method is applied to create a
synthetic dataset for the Canadian Pacific Railway (CPR) with just 50 real
samples across five classes. Remarkably, 500 synthetic samples are generated
with a minimal reconstruction loss of 0.021. A Visual Transformer (ViT) model
underwent fine-tuning using this synthetic CPR dataset, achieving high accuracy
rates (98%-99%) in classifying the five defect classes. This research offers a
promising solution to the data scarcity challenge in rail defect detection,
showcasing the potential for robust ICS development in this domain.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00396" title="Abstract">arXiv:2401.00396</a> [<a href="/pdf/2401.00396" title="Download PDF">pdf</a>, <a href="/format/2401.00396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAGTruth: A Hallucination Corpus for Developing Trustworthy  Retrieval-Augmented Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuanhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Juno Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Siliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shum%2C+K">Kashun Shum</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+C">Cheng Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Randy Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Juntong Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Retrieval-augmented generation (RAG) has become a main technique for
alleviating hallucinations in large language models (LLMs). Despite the
integration of RAG, LLMs may still present unsupported or contradictory claims
to the retrieved contents. In order to develop effective hallucination
prevention strategies under RAG, it is important to create benchmark datasets
that can measure the extent of hallucination. This paper presents RAGTruth, a
corpus tailored for analyzing word-level hallucinations in various domains and
tasks within the standard RAG frameworks for LLM applications. RAGTruth
comprises nearly 18,000 naturally generated responses from diverse LLMs using
RAG. These responses have undergone meticulous manual annotations at both the
individual cases and word levels, incorporating evaluations of hallucination
intensity. We not only benchmark hallucination frequencies across different
LLMs, but also critically assess the effectiveness of several existing
hallucination detection methodologies. Furthermore, we show that using a
high-quality dataset such as RAGTruth, it is possible to finetune a relatively
small LLM and achieve a competitive level of performance in hallucination
detection when compared to the existing prompt-based approaches using
state-of-the-art large language models such as GPT-4.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00401" title="Abstract">arXiv:2401.00401</a> [<a href="/pdf/2401.00401" title="Download PDF">pdf</a>, <a href="/format/2401.00401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplayer Battle Game-Inspired Optimizer for Complex Optimization  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuefeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Rui Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Various popular multiplayer battle royale games share a lot of common
elements. Drawing from our observations, we summarized these shared
characteristics and subsequently proposed a novel heuristic algorithm named
multiplayer battle game-inspired optimizer (MBGO). The proposed MBGO
streamlines mainstream multiplayer battle royale games into two discrete
phases: movement and battle. Specifically, the movement phase incorporates the
principles of commonly encountered ``safe zones'' to incentivize participants
to relocate to areas with a higher survival potential. The battle phase
simulates a range of strategies adopted by players in various situations to
enhance the diversity of the population. To evaluate and analyze the
performance of the proposed MBGO, we executed it alongside eight other
algorithms, including three classics and five latest ones, across multiple
diverse dimensions within the CEC2017 and CEC2020 benchmark functions. In
addition, we employed several industrial design problems to evaluate the
scalability and practicality of the proposed MBGO. The results of the
statistical analysis reveal that the novel MBGO demonstrates significant
competitiveness, excelling not only in convergence speed, but also in achieving
high levels of convergence accuracy across both benchmark functions and
real-world problems.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00403" title="Abstract">arXiv:2401.00403</a> [<a href="/pdf/2401.00403" title="Download PDF">pdf</a>, <a href="/format/2401.00403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Client-wise Modality Selection for Balanced Multi-modal Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yunfeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenchao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+P">Penghui Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,6 figures,2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">Selecting proper clients to participate in the iterative federated learning
(FL) rounds is critical to effectively harness a broad range of distributed
datasets. Existing client selection methods simply consider the variability
among FL clients with uni-modal data, however, have yet to consider clients
with multi-modalities. We reveal that traditional client selection scheme in
MFL may suffer from a severe modality-level bias, which impedes the
collaborative exploitation of multi-modal data, leading to insufficient local
data exploration and global aggregation. To tackle this challenge, we propose a
Client-wise Modality Selection scheme for MFL (CMSFed) that can comprehensively
utilize information from each modality via avoiding such client selection bias
caused by modality imbalance. Specifically, in each MFL round, the local data
from different modalities are selectively employed to participate in local
training and aggregation to mitigate potential modality imbalance of the global
model. To approximate the fully aggregated model update in a balanced way, we
introduce a novel local training loss function to enhance the weak modality and
align the divergent feature spaces caused by inconsistent modality adoption
strategies for different clients simultaneously. Then, a modality-level
gradient decoupling method is designed to derive respective submodular
functions to maintain the gradient diversity during the selection progress and
balance MFL according to local modality imbalance in each iteration. Our
extensive experiments showcase the superiority of CMSFed over baselines and its
effectiveness in multi-modal data exploitation.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00405" title="Abstract">arXiv:2401.00405</a> [<a href="/pdf/2401.00405" title="Download PDF">pdf</a>, <a href="/format/2401.00405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Single-View 3D Shape Retrieval to Occlusions and Unseen  Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qirui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ritchie%2C+D">Daniel Ritchie</a>, 
<a href="/search/cs?searchtype=author&query=Savva%2C+M">Manolis Savva</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+A+X">Angel X. Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single-view 3D shape retrieval is a challenging task that is increasingly
important with the growth of available 3D data. Prior work that has studied
this task has not focused on evaluating how realistic occlusions impact
performance, and how shape retrieval methods generalize to scenarios where
either the target 3D shape database contains unseen shapes, or the input image
contains unseen objects. In this paper, we systematically evaluate single-view
3D shape retrieval along three different axes: the presence of object
occlusions and truncations, generalization to unseen 3D shape data, and
generalization to unseen objects in the input images. We standardize two
existing datasets of real images and propose a dataset generation pipeline to
produce a synthetic dataset of scenes with multiple objects exhibiting
realistic occlusions. Our experiments show that training on occlusion-free data
as was commonly done in prior work leads to significant performance degradation
for inputs with occlusion. We find that that by first pretraining on our
synthetic dataset with occlusions and then finetuning on real data, we can
significantly outperform models from prior work and demonstrate robustness to
both unseen 3D shapes and unseen objects.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00406" title="Abstract">arXiv:2401.00406</a> [<a href="/pdf/2401.00406" title="Download PDF">pdf</a>, <a href="/ps/2401.00406" title="Download PostScript">ps</a>, <a href="/format/2401.00406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-cost Geometry-based Eye Gaze Detection using Facial Landmarks  Generated through Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+E+E">Esther Enhui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J+E">John Enzhou Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Joseph Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jacob Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Runzhou Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Introduction: In the realm of human-computer interaction and behavioral
research, accurate real-time gaze estimation is critical. Traditional methods
often rely on expensive equipment or large datasets, which are impractical in
many scenarios. This paper introduces a novel, geometry-based approach to
address these challenges, utilizing consumer-grade hardware for broader
applicability. Methods: We leverage novel face landmark detection neural
networks capable of fast inference on consumer-grade chips to generate accurate
and stable 3D landmarks of the face and iris. From these, we derive a small set
of geometry-based descriptors, forming an 8-dimensional manifold representing
the eye and head movements. These descriptors are then used to formulate linear
equations for predicting eye-gaze direction. Results: Our approach demonstrates
the ability to predict gaze with an angular error of less than 1.9 degrees,
rivaling state-of-the-art systems while operating in real-time and requiring
negligible computational resources. Conclusion: The developed method marks a
significant step forward in gaze estimation technology, offering a highly
accurate, efficient, and accessible alternative to traditional systems. It
opens up new possibilities for real-time applications in diverse fields, from
gaming to psychological research.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00408" title="Abstract">arXiv:2401.00408</a> [<a href="/pdf/2401.00408" title="Download PDF">pdf</a>, <a href="/ps/2401.00408" title="Download PostScript">ps</a>, <a href="/format/2401.00408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing greatest common divisor of several parametric univariate  polynomials via generalized subresultant polynomials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Hoon Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">In this paper, we tackle the following problem: compute the gcd for several
univariate polynomials with parametric coefficients. It amounts to partitioning
the parameter space into ``cells'' so that the gcd has a uniform expression
over each cell and constructing a uniform expression of gcd in each cell. We
tackle the problem as follows. We begin by making a natural and obvious
extension of subresultant polynomials of two polynomials to several
polynomials. Then we develop the following structural theories about them.
<br />1. We generalize Sylvester's theory to several polynomials, in order to
obtain an elegant relationship between generalized subresultant polynomials and
the gcd of several polynomials, yielding an elegant algorithm.
<br />2. We generalize Habicht's theory to several polynomials, in order to obtain
a systematic relationship between generalized subresultant polynomials and
pseudo-remainders, yielding an efficient algorithm.
<br />Using the generalized theories, we present a simple (structurally elegant)
algorithm which is significantly more efficient (both in the output size and
computing time) than algorithms based on previous approaches.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00409" title="Abstract">arXiv:2401.00409</a> [<a href="/pdf/2401.00409" title="Download PDF">pdf</a>, <a href="/format/2401.00409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-stream Hybrid CNN-Transformer Network for Skeleton-based Human  Interaction Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+R">Ruoqi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianqin Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human Interaction Recognition is the process of identifying interactive
actions between multiple participants in a specific situation. The aim is to
recognise the action interactions between multiple entities and their meaning.
Many single Convolutional Neural Network has issues, such as the inability to
capture global instance interaction features or difficulty in training, leading
to ambiguity in action semantics. In addition, the computational complexity of
the Transformer cannot be ignored, and its ability to capture local information
and motion features in the image is poor. In this work, we propose a Two-stream
Hybrid CNN-Transformer Network (THCT-Net), which exploits the local specificity
of CNN and models global dependencies through the Transformer. CNN and
Transformer simultaneously model the entity, time and space relationships
between interactive entities respectively. Specifically, Transformer-based
stream integrates 3D convolutions with multi-head self-attention to learn
inter-token correlations; We propose a new multi-branch CNN framework for
CNN-based streams that automatically learns joint spatio-temporal features from
skeleton sequences. The convolutional layer independently learns the local
features of each joint neighborhood and aggregates the features of all joints.
And the raw skeleton coordinates as well as their temporal difference are
integrated with a dual-branch paradigm to fuse the motion features of the
skeleton. Besides, a residual structure is added to speed up training
convergence. Finally, the recognition results of the two branches are fused
using parallel splicing. Experimental results on diverse and challenging
datasets, demonstrate that the proposed method can better comprehend and infer
the meaning and context of various actions, outperforming state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00413" title="Abstract">arXiv:2401.00413</a> [<a href="/pdf/2401.00413" title="Download PDF">pdf</a>, <a href="/format/2401.00413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time FJ/MAC PDE Solvers via Tensorized, Back-Propagation-Free  Optical PINN Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yequan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+X">Xian Xian</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinling Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhixiong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kurczveil%2C+G">Geza Kurczveil</a>, 
<a href="/search/cs?searchtype=author&query=Beausoleil%2C+R+G">Raymond G. Beausoleil</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ML with New Compute Paradigms (MLNCP) at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Emerging Technologies (cs.ET); Signal Processing (eess.SP)

</div>
<p class="mathjax">Solving partial differential equations (PDEs) numerically often requires huge
computing time, energy cost, and hardware resources in practical applications.
This has limited their applications in many scenarios (e.g., autonomous
systems, supersonic flows) that have a limited energy budget and require near
real-time response. Leveraging optical computing, this paper develops an
on-chip training framework for physics-informed neural networks (PINNs), aiming
to solve high-dimensional PDEs with fJ/MAC photonic power consumption and
ultra-low latency. Despite the ultra-high speed of optical neural networks,
training a PINN on an optical chip is hard due to (1) the large size of
photonic devices, and (2) the lack of scalable optical memory devices to store
the intermediate results of back-propagation (BP). To enable realistic optical
PINN training, this paper presents a scalable method to avoid the BP process.
We also employ a tensor-compressed approach to improve the convergence and
scalability of our optical PINN training. This training framework is designed
with tensorized optical neural networks (TONN) for scalable inference
acceleration and MZI phase-domain tuning for \textit{in-situ} optimization. Our
simulation results of a 20-dim HJB PDE show that our photonic accelerator can
reduce the number of MZIs by a factor of $1.17\times 10^3$, with only $1.36$ J
and $1.15$ s to solve this equation. This is the first real-size optical PINN
training framework that can be applied to solve high-dimensional PDEs.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00414" title="Abstract">arXiv:2401.00414</a> [<a href="/pdf/2401.00414" title="Download PDF">pdf</a>, <a href="/format/2401.00414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is It Possible to Backdoor Face Forgery Detection with Natural Triggers?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoxuan Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Ziwen He</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks have significantly improved the performance of face
forgery detection models in discriminating Artificial Intelligent Generated
Content (AIGC). However, their security is significantly threatened by the
injection of triggers during model training (i.e., backdoor attacks). Although
existing backdoor defenses and manual data selection can mitigate those using
human-eye-sensitive triggers, such as patches or adversarial noises, the more
challenging natural backdoor triggers remain insufficiently researched. To
further investigate natural triggers, we propose a novel analysis-by-synthesis
backdoor attack against face forgery detection models, which embeds natural
triggers in the latent space. We thoroughly study such backdoor vulnerability
from two perspectives: (1) Model Discrimination (Optimization-Based Trigger):
we adopt a substitute detection model and find the trigger by minimizing the
cross-entropy loss; (2) Data Distribution (Custom Trigger): we manipulate the
uncommon facial attributes in the long-tailed distribution to generate poisoned
samples without the supervision from detection models. Furthermore, to
completely evaluate the detection models towards the latest AIGC, we utilize
both state-of-the-art StyleGAN and Stable Diffusion for trigger generation.
Finally, these backdoor triggers introduce specific semantic features to the
generated poisoned samples (e.g., skin textures and smile), which are more
natural and robust. Extensive experiments show that our method is superior from
three levels: (1) Attack Success Rate: ours achieves a high attack success rate
(over 99%) and incurs a small model accuracy drop (below 0.2%) with a low
poisoning rate (less than 3%); (2) Backdoor Defense: ours shows better robust
performance when faced with existing backdoor defense methods; (3) Human
Inspection: ours is less human-eye-sensitive from a comprehensive user study.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00416" title="Abstract">arXiv:2401.00416</a> [<a href="/pdf/2401.00416" title="Download PDF">pdf</a>, <a href="/format/2401.00416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVFAP: Self-supervised Video Facial Affect Perceiver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Licai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zheng Lian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kexin Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yu He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haiyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Trans. on Affective Computing (February 8, 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
<p class="mathjax">Video-based facial affect analysis has recently attracted increasing
attention owing to its critical role in human-computer interaction. Previous
studies mainly focus on developing various deep learning architectures and
training them in a fully supervised manner. Although significant progress has
been achieved by these supervised methods, the longstanding lack of large-scale
high-quality labeled data severely hinders their further improvements.
Motivated by the recent success of self-supervised learning in computer vision,
this paper introduces a self-supervised approach, termed Self-supervised Video
Facial Affect Perceiver (SVFAP), to address the dilemma faced by supervised
methods. Specifically, SVFAP leverages masked facial video autoencoding to
perform self-supervised pre-training on massive unlabeled facial videos.
Considering that large spatiotemporal redundancy exists in facial videos, we
propose a novel temporal pyramid and spatial bottleneck Transformer as the
encoder of SVFAP, which not only enjoys low computational cost but also
achieves excellent performance. To verify the effectiveness of our method, we
conduct experiments on nine datasets spanning three downstream tasks, including
dynamic facial expression recognition, dimensional emotion recognition, and
personality recognition. Comprehensive results demonstrate that SVFAP can learn
powerful affect-related representations via large-scale self-supervised
pre-training and it significantly outperforms previous state-of-the-art methods
on all datasets. Codes will be available at https://github.com/sunlicai/SVFAP.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00419" title="Abstract">arXiv:2401.00419</a> [<a href="/pdf/2401.00419" title="Download PDF">pdf</a>, <a href="/format/2401.00419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation algorithms for Job Scheduling with reconfigurable  resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berg%C3%A9%2C+P">Pierre Berg&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Chaikovskaia%2C+M">Mari Chaikovskaia</a>, 
<a href="/search/cs?searchtype=author&query=Gayon%2C+J">Jean-Philippe Gayon</a>, 
<a href="/search/cs?searchtype=author&query=Quilliot%2C+A">Alain Quilliot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We consider here the MultiBot problem for the scheduling and the resource
parametrization of jobs related to the production or the transportation of
different products inside a given time horizon. Those jobs must meet known in
advance demands. The time horizon is divided into several discrete identical
periods representing each the time needed to proceed a job. The objective is to
find a parametrization and a schedule for the jobs in such a way they require
as less resources as possible. Though this problem derived from the applicative
context of reconfigurable robots, we focus here on fundamental issues. We show
that the resulting strongly NP-hard Multibot problem may be handled in a greedy
way with an approximation ratio of $\frac{4}{3}$.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00420" title="Abstract">arXiv:2401.00420</a> [<a href="/pdf/2401.00420" title="Download PDF">pdf</a>, <a href="/format/2401.00420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynCDR : Training Cross Domain Retrieval Models with Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Samarth Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>, 
<a href="/search/cs?searchtype=author&query=Saligrama%2C+V">Venkatesh Saligrama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In cross-domain retrieval, a model is required to identify images from the
same semantic category across two visual domains. For instance, given a sketch
of an object, a model needs to retrieve a real image of it from an online
store's catalog. A standard approach for such a problem is learning a feature
space of images where Euclidean distances reflect similarity. Even without
human annotations, which may be expensive to acquire, prior methods function
reasonably well using unlabeled images for training. Our problem constraint
takes this further to scenarios where the two domains do not necessarily share
any common categories in training data. This can occur when the two domains in
question come from different versions of some biometric sensor recording
identities of different people. We posit a simple solution, which is to
generate synthetic data to fill in these missing category examples across
domains. This, we do via category preserving translation of images from one
visual domain to another. We compare approaches specifically trained for this
translation for a pair of domains, as well as those that can use large-scale
pre-trained text-to-image diffusion models via prompts, and find that the
latter can generate better replacement synthetic data, leading to more accurate
cross-domain retrieval models. Code for our work is available at
https://github.com/samarth4149/SynCDR .
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00421" title="Abstract">arXiv:2401.00421</a> [<a href="/pdf/2401.00421" title="Download PDF">pdf</a>, <a href="/format/2401.00421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Text to Pixels: A Context-Aware Semantic Synergy Solution for  Infrared and Visible Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yang Zou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhiying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Long Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures, 3 tables, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the rapid progression of deep learning technologies, multi-modality
image fusion has become increasingly prevalent in object detection tasks.
Despite its popularity, the inherent disparities in how different sources
depict scene content make fusion a challenging problem. Current fusion
methodologies identify shared characteristics between the two modalities and
integrate them within this shared domain using either iterative optimization or
deep learning architectures, which often neglect the intricate semantic
relationships between modalities, resulting in a superficial understanding of
inter-modal connections and, consequently, suboptimal fusion outcomes. To
address this, we introduce a text-guided multi-modality image fusion method
that leverages the high-level semantics from textual descriptions to integrate
semantics from infrared and visible images. This method capitalizes on the
complementary characteristics of diverse modalities, bolstering both the
accuracy and robustness of object detection. The codebook is utilized to
enhance a streamlined and concise depiction of the fused intra- and
inter-domain dynamics, fine-tuned for optimal performance in detection tasks.
We present a bilevel optimization strategy that establishes a nexus between the
joint problem of fusion and detection, optimizing both processes concurrently.
Furthermore, we introduce the first dataset of paired infrared and visible
images accompanied by text prompts, paving the way for future research.
Extensive experiments on several datasets demonstrate that our method not only
produces visually superior fusion results but also achieves a higher detection
mAP over existing methods, achieving state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00422" title="Abstract">arXiv:2401.00422</a> [<a href="/pdf/2401.00422" title="Download PDF">pdf</a>, <a href="/ps/2401.00422" title="Download PostScript">ps</a>, <a href="/format/2401.00422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting the Curse of Dimensionality from Distance Concentration and  Manifold Effect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dehua Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+Z">Zhipeng Gui</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huayi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The characteristics and interpretability of data become more abstract and
complex as the dimensionality increases. Common patterns and relationships that
hold in in low-dimensional space may fail to hold in higher-dimensional space.
This phenomenon leads to a decreasing performance for the regression,
classification or clustering models or algorithms, which is known as curse of
dimensionality. Curse of dimensionality can be attributed to many causes. In
this paper, we first summarize five challenges associated with manipulating
high-dimensional data, and explains the potential causes for the failure of
regression, classification or clustering tasks. Subsequently, we delve into two
major causes of the curse of dimensionality, distance concentration and
manifold effect, by performing theoretical and empirical analyses. The results
demonstrate that nearest neighbor search (NNS) using three typical distance
measurements, Minkowski distance, Chebyshev distance, and cosine distance,
becomes meaningless as the dimensionality increases. Meanwhile, the data
incorporates more redundant features, and the variance contribution of
principal component analysis (PCA) is skewed towards a few dimensions. By
interpreting the causes of the curse of dimensionality, we can better
understand the limitations of current models and algorithms, and drive to
improve the performance of data analysis and machine learning tasks in
high-dimensional space.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00423" title="Abstract">arXiv:2401.00423</a> [<a href="/pdf/2401.00423" title="Download PDF">pdf</a>, <a href="/format/2401.00423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MSGNet: Learning Multi-Scale Inter-Series Correlations for Multivariate  Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wanlin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianggen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianshuai Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuankai Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multivariate time series forecasting poses an ongoing challenge across
various disciplines. Time series data often exhibit diverse intra-series and
inter-series correlations, contributing to intricate and interwoven
dependencies that have been the focus of numerous studies. Nevertheless, a
significant research gap remains in comprehending the varying inter-series
correlations across different time scales among multiple time series, an area
that has received limited attention in the literature. To bridge this gap, this
paper introduces MSGNet, an advanced deep learning model designed to capture
the varying inter-series correlations across multiple time scales using
frequency domain analysis and adaptive graph convolution. By leveraging
frequency domain analysis, MSGNet effectively extracts salient periodic
patterns and decomposes the time series into distinct time scales. The model
incorporates a self-attention mechanism to capture intra-series dependencies,
while introducing an adaptive mixhop graph convolution layer to autonomously
learn diverse inter-series correlations within each time scale. Extensive
experiments are conducted on several real-world datasets to showcase the
effectiveness of MSGNet. Furthermore, MSGNet possesses the ability to
automatically learn explainable multi-scale inter-series correlations,
exhibiting strong generalization capabilities even when applied to
out-of-distribution samples.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00424" title="Abstract">arXiv:2401.00424</a> [<a href="/pdf/2401.00424" title="Download PDF">pdf</a>, <a href="/format/2401.00424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SDIF-DA: A Shallow-to-Deep Interaction Framework with Data Augmentation  for Multi-modal Intent Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shijue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Libo Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+G">Geng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruifeng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multi-modal intent detection aims to utilize various modalities to understand
the user's intentions, which is essential for the deployment of dialogue
systems in real-world scenarios. The two core challenges for multi-modal intent
detection are (1) how to effectively align and fuse different features of
modalities and (2) the limited labeled multi-modal intent training data. In
this work, we introduce a shallow-to-deep interaction framework with data
augmentation (SDIF-DA) to address the above challenges. Firstly, SDIF-DA
leverages a shallow-to-deep interaction module to progressively and effectively
align and fuse features across text, video, and audio modalities. Secondly, we
propose a ChatGPT-based data augmentation approach to automatically augment
sufficient training data. Experimental results demonstrate that SDIF-DA can
effectively align and fuse multi-modal features by achieving state-of-the-art
performance. In addition, extensive analyses show that the introduced data
augmentation approach can successfully distill knowledge from the large
language model.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00426" title="Abstract">arXiv:2401.00426</a> [<a href="/pdf/2401.00426" title="Download PDF">pdf</a>, <a href="/format/2401.00426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> keqing: knowledge-based question answering is a nature chain-of-thought  mentor of LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaojie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yishi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinrun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Lei Feng</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have exhibited remarkable performance on various
natural language processing (NLP) tasks, especially for question answering.
However, in the face of problems beyond the scope of knowledge, these LLMs tend
to talk nonsense with a straight face, where the potential solution could be
incorporating an Information Retrieval (IR) module and generating response
based on these retrieved knowledge. In this paper, we present a novel framework
to assist LLMs, such as ChatGPT, to retrieve question-related structured
information on the knowledge graph, and demonstrate that Knowledge-based
question answering (Keqing) could be a nature Chain-of-Thought (CoT) mentor to
guide the LLM to sequentially find the answer entities of a complex question
through interpretable logical chains. Specifically, the workflow of Keqing will
execute decomposing a complex question according to predefined templates,
retrieving candidate entities on knowledge graph, reasoning answers of
sub-questions, and finally generating response with reasoning paths, which
greatly improves the reliability of LLM's response. The experimental results on
KBQA datasets show that Keqing can achieve competitive performance and
illustrate the logic of answering each question.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00429" title="Abstract">arXiv:2401.00429</a> [<a href="/pdf/2401.00429" title="Download PDF">pdf</a>, <a href="/format/2401.00429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deeper and Wider Networks for Performance Metrics Prediction in  Communication Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+X">Xiaobing Pei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In today's era, users have increasingly high expectations regarding the
performance and efficiency of communication networks. Network operators aspire
to achieve efficient network planning, operation, and optimization through
Digital Twin Networks (DTN). The effectiveness of DTN heavily relies on the
network model, with graph neural networks (GNN) playing a crucial role in
network modeling. However, existing network modeling methods still lack a
comprehensive understanding of communication networks. In this paper, we
propose DWNet (Deeper and Wider Networks), a heterogeneous graph neural network
modeling method based on data-driven approaches that aims to address end-to-end
latency and jitter prediction in network models. This method stands out due to
two distinctive features: firstly, it introduces deeper levels of state
participation in the message passing process; secondly, it extensively
integrates relevant features during the feature fusion process. Through
experimental validation and evaluation, our model achieves higher prediction
accuracy compared to previous research achievements, particularly when dealing
with unseen network topologies during model training. Our model not only
provides more accurate predictions but also demonstrates stronger
generalization capabilities across diverse topological structures.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00430" title="Abstract">arXiv:2401.00430</a> [<a href="/pdf/2401.00430" title="Download PDF">pdf</a>, <a href="/format/2401.00430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain-Conditional Multimodal Synthesis: A Survey and Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mai%2C+W">Weijian Mai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+P">Pengfei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhijun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In the era of Artificial Intelligence Generated Content (AIGC), conditional
multimodal synthesis technologies (e.g., text-to-image, text-to-video,
text-to-audio, etc) are gradually reshaping the natural content in the real
world. The key to multimodal synthesis technology is to establish the mapping
relationship between different modalities. Brain signals, serving as potential
reflections of how the brain interprets external information, exhibit a
distinctive One-to-Many correspondence with various external modalities. This
correspondence makes brain signals emerge as a promising guiding condition for
multimodal content synthesis. Brian-conditional multimodal synthesis refers to
decoding brain signals back to perceptual experience, which is crucial for
developing practical brain-computer interface systems and unraveling complex
mechanisms underlying how the brain perceives and comprehends external stimuli.
This survey comprehensively examines the emerging field of AIGC-based
Brain-conditional Multimodal Synthesis, termed AIGC-Brain, to delineate the
current landscape and future directions. To begin, related brain neuroimaging
datasets, functional brain regions, and mainstream generative models are
introduced as the foundation of AIGC-Brain decoding and analysis. Next, we
provide a comprehensive taxonomy for AIGC-Brain decoding models and present
task-specific representative work and detailed implementation strategies to
facilitate comparison and in-depth analysis. Quality assessments are then
introduced for both qualitative and quantitative evaluation. Finally, this
survey explores insights gained, providing current challenges and outlining
prospects of AIGC-Brain. Being the inaugural survey in this domain, this paper
paves the way for the progress of AIGC-Brain research, offering a foundational
overview to guide future work.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00431" title="Abstract">arXiv:2401.00431</a> [<a href="/pdf/2401.00431" title="Download PDF">pdf</a>, <a href="/format/2401.00431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wild2Avatar: Rendering Humans Behind Occlusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tiange Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+A">Adam Sun</a>, 
<a href="/search/cs?searchtype=author&query=Delp%2C+S">Scott Delp</a>, 
<a href="/search/cs?searchtype=author&query=Kozuka%2C+K">Kazuki Kozuka</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Adeli%2C+E">Ehsan Adeli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Rendering the visual appearance of moving humans from occluded monocular
videos is a challenging task. Most existing research renders 3D humans under
ideal conditions, requiring a clear and unobstructed scene. Those methods
cannot be used to render humans in real-world scenes where obstacles may block
the camera's view and lead to partial occlusions. In this work, we present
Wild2Avatar, a neural rendering approach catered for occluded in-the-wild
monocular videos. We propose occlusion-aware scene parameterization for
decoupling the scene into three parts - occlusion, human, and background.
Additionally, extensive objective functions are designed to help enforce the
decoupling of the human from both the occlusion and the background and to
ensure the completeness of the human model. We verify the effectiveness of our
approach with experiments on in-the-wild videos.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00434" title="Abstract">arXiv:2401.00434</a> [<a href="/pdf/2401.00434" title="Download PDF">pdf</a>, <a href="/format/2401.00434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoGalactica: A Scientific Large Language Model in Geoscience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouhan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Cheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Le Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yutong Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhongmou He</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuanyuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Beiya Dai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yunchong Song</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Boyi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+T">Tao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Luoyi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yunqiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenghu Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have achieved huge success for their general
knowledge and ability to solve a wide spectrum of tasks in natural language
processing (NLP). Due to their impressive abilities, LLMs have shed light on
potential inter-discipline applications to foster scientific discoveries of a
specific domain by using artificial intelligence (AI for science, AI4S). In the
meantime, utilizing NLP techniques in geoscience research and practice is wide
and convoluted, contributing from knowledge extraction and document
classification to question answering and knowledge discovery. In this work, we
take the initial step to leverage LLM for science, through a rather
straightforward approach. We try to specialize an LLM into geoscience, by
further pre-training the model with a vast amount of texts in geoscience, as
well as supervised fine-tuning (SFT) the resulting model with our custom
collected instruction tuning dataset. These efforts result in a model
GeoGalactica consisting of 30 billion parameters. To our best knowledge, it is
the largest language model for the geoscience domain. More specifically,
GeoGalactica is from further pre-training of Galactica. We train GeoGalactica
over a geoscience-related text corpus containing 65 billion tokens curated from
extensive data sources in the big science project Deep-time Digital Earth
(DDE), preserving as the largest geoscience-specific text corpus. Then we
fine-tune the model with 1 million pairs of instruction-tuning data consisting
of questions that demand professional geoscience knowledge to answer. In this
technical report, we will illustrate in detail all aspects of GeoGalactica,
including data collection, data cleaning, base model selection, pre-training,
SFT, and evaluation. We open-source our data curation tools and the checkpoints
of GeoGalactica during the first 3/4 of pre-training.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00435" title="Abstract">arXiv:2401.00435</a> [<a href="/pdf/2401.00435" title="Download PDF">pdf</a>, <a href="/format/2401.00435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bidirectional Trained Tree-Structured Decoder for Handwritten  Mathematical Expression Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hanbo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Pengfei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiefeng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jun Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Handwritten Mathematical Expression Recognition (HMER) task is a critical
branch in the field of OCR. Recent studies have demonstrated that incorporating
bidirectional context information significantly improves the performance of
HMER models. However, existing methods fail to effectively utilize
bidirectional context information during the inference stage. Furthermore,
current bidirectional training methods are primarily designed for string
decoders and cannot adequately generalize to tree decoders, which offer
superior generalization capabilities and structural analysis capacity. In order
to overcome these limitations, we propose the Mirror-Flipped Symbol Layout Tree
(MF-SLT) and Bidirectional Asynchronous Training (BAT) structure. Our method
extends the bidirectional training strategy to the tree decoder, allowing for
more effective training by leveraging bidirectional information. Additionally,
we analyze the impact of the visual and linguistic perception of the HMER model
separately and introduce the Shared Language Modeling (SLM) mechanism. Through
the SLM, we enhance the model's robustness and generalization when dealing with
visual ambiguity, particularly in scenarios with abundant training data. Our
approach has been validated through extensive experiments, demonstrating its
ability to achieve new state-of-the-art results on the CROHME 2014, 2016, and
2019 datasets, as well as the HME100K dataset. The code used in our experiments
will be publicly available.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00436" title="Abstract">arXiv:2401.00436</a> [<a href="/pdf/2401.00436" title="Download PDF">pdf</a>, <a href="/format/2401.00436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-PCR: Diffusion-Based Correspondence Searching in Doubly Stochastic  Matrix Space for Point Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qianliang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haobo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yaqing Ding</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Efficiently finding optimal correspondences between point clouds is crucial
for solving both rigid and non-rigid point cloud registration problems.
Existing methods often rely on geometric or semantic feature embedding to
establish correspondences and estimate transformations or flow fields.
Recently, state-of-the-art methods have employed RAFT-like iterative updates to
refine the solution. However, these methods have certain limitations. Firstly,
their iterative refinement design lacks transparency, and their iterative
updates follow a fixed path during the refinement process, which can lead to
suboptimal results. Secondly, these methods overlook the importance of refining
or optimizing correspondences (or matching matrices) as a precursor to solving
transformations or flow fields. They typically compute candidate
correspondences based on distances in the point feature space. However, they
only project the candidate matching matrix into some matrix space once with
Sinkhorn or dual softmax operations to obtain final correspondences. This
one-shot projected matching matrix may be far from the globally optimal one,
and these approaches do not consider the distribution of the target matching
matrix. In this paper, we propose a novel approach that exploits the Denoising
Diffusion Model to predict a searching gradient for the optimal matching matrix
within the Doubly Stochastic Matrix Space. During the reverse denoising
process, our method iteratively searches for better solutions along this
denoising gradient, which points towards the maximum likelihood direction of
the target matching matrix. Our method offers flexibility by allowing the
search to start from any initial matching matrix provided by the online
backbone or white noise. Experimental evaluations on the 3DMatch/3DLoMatch and
4DMatch/4DLoMatch datasets demonstrate the effectiveness of our newly designed
framework.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00437" title="Abstract">arXiv:2401.00437</a> [<a href="/pdf/2401.00437" title="Download PDF">pdf</a>, <a href="/format/2401.00437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BatchEval: Towards Human-like Text Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+P">Peiwen Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shaoxiong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinglin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Boyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Significant progress has been made in automatic text evaluation with the
introduction of large language models (LLMs) as evaluators. However, current
sample-wise evaluation paradigm suffers from the following issues: (1)
Sensitive to prompt design; (2) Poor resistance to noise; (3) Inferior ensemble
performance with static reference. Inspired by the fact that humans treat both
criterion definition and inter sample comparison as references for evaluation,
we propose BatchEval, a paradigm that conducts batch-wise evaluation
iteratively to alleviate the above problems. We explore variants under this
paradigm and confirm the optimal settings are two stage procedure with
heterogeneous batch composition strategy and decimal scoring format.
Comprehensive experiments across 3 LLMs on 4 text evaluation tasks demonstrate
that BatchEval outperforms state-of-the-art methods by 10.5% on Pearson
correlations with only 64% API cost on average. Further analyses have been
conducted to verify the robustness, generalization, and working mechanism of
BatchEval.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00438" title="Abstract">arXiv:2401.00438</a> [<a href="/pdf/2401.00438" title="Download PDF">pdf</a>, <a href="/format/2401.00438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SFGANS Self-supervised Future Generator for human ActioN Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berman%2C+O">Or Berman</a>, 
<a href="/search/cs?searchtype=author&query=Goldbraikh%2C+A">Adam Goldbraikh</a>, 
<a href="/search/cs?searchtype=author&query=Laufer%2C+S">Shlomi Laufer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The ability to locate and classify action segments in long untrimmed video is
of particular interest to many applications such as autonomous cars, robotics
and healthcare applications. Today, the most popular pipeline for action
segmentation is composed of encoding the frames into feature vectors, which are
then processed by a temporal model for segmentation. In this paper we present a
self-supervised method that comes in the middle of the standard pipeline and
generated refined representations of the original feature vectors. Experiments
show that this method improves the performance of existing models on different
sub-tasks of action segmentation, even without additional hyper parameter
tuning.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00440" title="Abstract">arXiv:2401.00440</a> [<a href="/pdf/2401.00440" title="Download PDF">pdf</a>, <a href="/format/2401.00440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSGAN: An Optical-to-SAR Dual Conditional GAN for Optical based SAR  Temporal Shifting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rangzan%2C+M">Moien Rangzan</a>, 
<a href="/search/cs?searchtype=author&query=Attarchi%2C+S">Sara Attarchi</a>, 
<a href="/search/cs?searchtype=author&query=Gloaguen%2C+R">Richard Gloaguen</a>, 
<a href="/search/cs?searchtype=author&query=Alavipanah%2C+S+K">Seyed Kazem Alavipanah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In contrast to the well-investigated field of SAR-to-Optical translation,
this study explores the lesser-investigated domain of Optical-to-SAR
translation, a challenging field due to the ill-posed nature of this
translation. The complexity arises as a single optical data can have multiple
SAR representations based on the SAR viewing geometry. We propose a novel
approach, termed SAR Temporal Shifting, which inputs an optical data from the
desired timestamp along with a SAR data from a different temporal point but
with a consistent viewing geometry as the expected SAR data, both complemented
with a change map of optical data during the intervening period. This model
modifies the SAR data based on the changes observed in optical data to generate
the SAR data for the desired timestamp. Our model, a dual conditional
Generative Adversarial Network (GAN), named Temporal Shifting GAN (TSGAN),
incorporates a siamese encoder in both the Generator and the Discriminator. To
prevent the model from overfitting on the input SAR data, we employed a change
weighted loss function. Our approach surpasses traditional translation methods
by eliminating the GAN's fiction phenomenon, particularly in unchanged regions,
resulting in higher SSIM and PSNR in these areas. Additionally, modifications
to the Pix2Pix architecture and the inclusion of attention mechanisms have
enhanced the model's performance on all regions of the data. This research
paves the way for leveraging legacy optical datasets, the most abundant and
longstanding source of Earth datary data, extending their use to SAR domains
and temporal analyses. To foster further research, we provide the code,
datasets used in our study, and a framework for generating paired SAR-Optical
datasets for new regions of interest. These resources are available on
github.com/moienr/TemporalGAN
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00442" title="Abstract">arXiv:2401.00442</a> [<a href="/pdf/2401.00442" title="Download PDF">pdf</a>, <a href="/ps/2401.00442" title="Download PostScript">ps</a>, <a href="/format/2401.00442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Overview of Fish-Eye Camera Distortion Correction  Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">De-Wei Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun-Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhao-Yuan Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; General Literature (cs.GL)

</div>
<p class="mathjax">The fisheye camera, with its unique wide field of view and other
characteristics, has found extensive applications in various fields. However,
the fisheye camera suffers from significant distortion compared to pinhole
cameras, resulting in distorted images of captured objects. Fish-eye camera
distortion is a common issue in digital image processing, requiring effective
correction techniques to enhance image quality. This review provides a
comprehensive overview of various methods used for fish-eye camera distortion
correction. The article explores the polynomial distortion model, which
utilizes polynomial functions to model and correct radial distortions.
Additionally, alternative approaches such as panorama mapping, grid mapping,
direct methods, and deep learning-based methods are discussed. The review
highlights the advantages, limitations, and recent advancements of each method,
enabling readers to make informed decisions based on their specific needs.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00443" title="Abstract">arXiv:2401.00443</a> [<a href="/pdf/2401.00443" title="Download PDF">pdf</a>, <a href="/ps/2401.00443" title="Download PostScript">ps</a>, <a href="/format/2401.00443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Energy Efficiency Modelling in Large-scale Networks: An  Expert Knowledge and ML-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=L%C3%B3pez-P%C3%A9rez%2C+D">D L&#xf3;pez-P&#xe9;rez</a>, 
<a href="/search/eess?searchtype=author&query=De+Domenico%2C+A">A De Domenico</a>, 
<a href="/search/eess?searchtype=author&query=Piovesan%2C+N">N Piovesan</a>, 
<a href="/search/eess?searchtype=author&query=Debbah%2C+M+.">M . Debbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The energy consumption of mobile networks poses a critical challenge.
Mitigating this concern necessitates the deployment and optimization of network
energy-saving solutions, such as carrier shutdown, to dynamically manage
network resources. Traditional optimization approaches encounter complexity due
to factors like the large number of cells, stochastic traffic, channel
variations, and intricate trade-offs. This paper introduces the simulated
reality of communication networks (SRCON) framework, a novel, data-driven
modeling paradigm that harnesses live network data and employs a blend of
machine learning (ML)- and expert-based models. These mix of models accurately
characterizes the functioning of network components, and predicts network
energy efficiency and user equipment (UE) quality of service for any energy
carrier shutdown configuration in a specific network. Distinguishing itself
from existing methods, SRCON eliminates the reliance on expensive expert
knowledge, drive testing, or incomplete maps for predicting network
performance. This paper details the pipeline employed by SRCON to decompose the
large network energy efficiency modeling problem into ML and expert-based
submodels. It demonstrates how, by embracing stochasticity, and carefully
crafting the relationship between such submodels, the overall computational
complexity can be reduced and prediction accuracy enhanced. Results derived
from real network data underscore the paradigm shift introduced by SRCON,
showcasing significant gains over a state-of-the art method used by a operator
for network energy efficiency modeling. The reliability of this local,
data-driven modeling of the network proves to be a key asset for network
energy-saving optimization.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00445" title="Abstract">arXiv:2401.00445</a> [<a href="/pdf/2401.00445" title="Download PDF">pdf</a>, <a href="/ps/2401.00445" title="Download PostScript">ps</a>, <a href="/format/2401.00445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Efficient Power Control for Multiple-Task Split Inference in  UAVs: A Tiny Learning-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenxi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+M">Min Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+T">Tianshu Chu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiandong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
<p class="mathjax">The limited energy and computing resources of unmanned aerial vehicles (UAVs)
hinder the application of aerial artificial intelligence. The utilization of
split inference in UAVs garners significant attention due to its effectiveness
in mitigating computing and energy requirements. However, achieving
energy-efficient split inference in UAVs remains complex considering of various
crucial parameters such as energy level and delay constraints, especially
involving multiple tasks. In this paper, we present a two-timescale approach
for energy minimization in split inference, where discrete and continuous
variables are segregated into two timescales to reduce the size of action space
and computational complexity. This segregation enables the utilization of tiny
reinforcement learning (TRL) for selecting discrete transmission modes for
sequential tasks. Moreover, optimization programming (OP) is embedded between
TRL's output and reward function to optimize the continuous transmit power.
Specifically, we replace the optimization of transmit power with that of
transmission time to decrease the computational complexity of OP since we
reveal that energy consumption monotonically decreases with increasing
transmission time. The replacement significantly reduces the feasible region
and enables a fast solution according to the closed-form expression for optimal
transmit power. Simulation results show that the proposed algorithm can achieve
a higher probability of successful task completion with lower energy
consumption.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00447" title="Abstract">arXiv:2401.00447</a> [<a href="/pdf/2401.00447" title="Download PDF">pdf</a>, <a href="/format/2401.00447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Clustering for STAR-RIS Assisted Full-Duplex NOMA Communication  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salem%2C+A">Abdelhamid Salem</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kai-Kit Wong</a>, 
<a href="/search/cs?searchtype=author&query=Chae%2C+C">Chan-Byoung Chae</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yangyang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2309.15037">arXiv:2309.15037</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In contrast to conventional reconfigurable intelligent surface (RIS),
simultaneous transmitting and reflecting reconfigurable intelligent surface
(STAR-RIS) has been proposed recently to enlarge the serving area from 180o to
360o coverage. This work considers the performance of a STAR-RIS aided
full-duplex (FD) non-orthogonal multiple access (NOMA) communication systems.
The STAR-RIS is implemented at the cell-edge to assist the cell-edge users,
while the cell-center users can communicate directly with a FD base station
(BS). We first introduce new user clustering schemes for the downlink and
uplink transmissions. Then, based on the proposed transmission schemes
closed-form expressions of the ergodic rates in the downlink and uplink modes
are derived taking into account the system impairments caused by the self
interference at the FD-BS and the imperfect successive interference
cancellation (SIC). Moreover, an optimization problem to maximize the total
sum-rate is formulated and solved by optimizing the amplitudes and the
phase-shifts of the STAR-RIS elements and allocating the transmit power
efficiently. The performance of the proposed user clustering schemes and the
optimal STAR-RIS design are investigated through numerical results
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00448" title="Abstract">arXiv:2401.00448</a> [<a href="/pdf/2401.00448" title="Download PDF">pdf</a>, <a href="/format/2401.00448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Chinchilla-Optimal: Accounting for Inference in Language Model  Scaling Laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sardana%2C+N">Nikhil Sardana</a>, 
<a href="/search/cs?searchtype=author&query=Frankle%2C+J">Jonathan Frankle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, To appear in the 3rd NeurIPS Workshop on Efficient Natural Language and Speech Processing (ENLSP), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language model (LLM) scaling laws are empirical formulas that estimate
changes in model quality as a result of increasing parameter count and training
data. However, these formulas, including the popular DeepMind Chinchilla
scaling laws, neglect to include the cost of inference. We modify the
Chinchilla scaling laws to calculate the optimal LLM parameter count and
pre-training data size to train and deploy a model of a given quality and
inference demand. We conduct our analysis both in terms of a compute budget and
real-world costs and find that LLM researchers expecting reasonably large
inference demand (~1B requests) should train models smaller and longer than
Chinchilla-optimal.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00449" title="Abstract">arXiv:2401.00449</a> [<a href="/pdf/2401.00449" title="Download PDF">pdf</a>, <a href="/format/2401.00449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Digital Accessibility to Industry Professionals using the  Community of Practice Framework: An Experience Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=PD%2C+P">Parthasarathy PD</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Swaroop Joshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in International Conference on Software Engineering (ICSE'24), Software Engineering Education and Training Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Despite recent initiatives aimed at improving accessibility, the field of
digital accessibility remains markedly behind contemporary advancements in the
software industry as a large number of real world software and web applications
continue to fall short of accessibility requirements. A persisting skills
deficit within the existing technology workforce has been an enduring
impediment, hindering organizations from delivering truly accessible software
products. This, in turn, elevates the risk of isolating and excluding a
substantial portion of potential users. In this paper, we report lessons
learned from a training program for teaching digital accessibility using the
Communities of Practice (CoP) framework to industry professionals. We recruited
66 participants from a large multi-national software company and assigned them
to two groups: one participating in a CoP and the other using self-paced
learning. We report experiences from designing the training program, conducting
the actual training, and assessing the efficiency of the two approaches. Based
on these findings, we provide recommendations for practitioners in Learning and
Development teams and educators in designing accessibility courses for industry
professionals.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00451" title="Abstract">arXiv:2401.00451</a> [<a href="/pdf/2401.00451" title="Download PDF">pdf</a>, <a href="/format/2401.00451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Need of Accessibility Education in the Software Industry:  Insights from a Survey of Software Professionals in India
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%2C+P+P">Parthasarathy P D</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Swaroop Joshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in International Conference on Software Engineering (ICSE'24), Software Engineering Education and Training Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">A UserWay study in 2021 indicates that an annual global e-commerce revenue
loss of approximately $16 billion can be attributed to inaccessible websites
and applications. According to the 2023 WebAIM study, only 3.7% of the world's
top one million website homepages are fully accessible. This shows that many
software developers use poor coding practices that don't adhere to the Web
Content Accessibility Guidelines (WCAG). This research centers on software
professionals and their role in addressing accessibility. This work seeks to
understand (a) who within the software development community actively practices
accessibility, (b) when and how accessibility is considered in the software
development lifecycle, (c) the various challenges encountered in building
accessible software, and (d) the resources required by software professionals
to enhance product accessibility. Our survey of 269 software professionals from
India sheds light on the pressing need for accessibility education within the
software industry. A substantial majority (69.9%, N=269) of respondents express
the need for training materials, workshops, and bootcamps to enhance their
accessibility skills. We present a list of actionable recommendations that can
be implemented within the industry to promote accessibility awareness and
skills. We also open source our raw data for further research, encouraging
continued exploration in this domain.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00454" title="Abstract">arXiv:2401.00454</a> [<a href="/pdf/2401.00454" title="Download PDF">pdf</a>, <a href="/format/2401.00454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum and Classical Communication Complexity of Permutation-Invariant  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Ziyi Guan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yunqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+P">Penghui Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zekun Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in STACS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">This paper gives a nearly tight characterization of the quantum communication
complexity of the permutation-invariant Boolean functions. With such a
characterization, we show that the quantum and randomized communication
complexity of the permutation-invariant Boolean functions are quadratically
equivalent (up to a logarithmic factor). Our results extend a recent line of
research regarding query complexity \cite{AA14, Cha19, BCG+20} to communication
complexity, showing symmetry prevents exponential quantum speedups.
<br />Furthermore, we show the Log-rank Conjecture holds for any non-trivial total
permutation-invariant Boolean function. Moreover, we establish a relationship
between the quantum/classical communication complexity and the approximate rank
of permutation-invariant Boolean functions. This implies the correctness of the
Log-approximate-rank Conjecture for permutation-invariant Boolean functions in
both randomized and quantum settings (up to a logarithmic factor).
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00456" title="Abstract">arXiv:2401.00456</a> [<a href="/pdf/2401.00456" title="Download PDF">pdf</a>, <a href="/format/2401.00456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double-well Net for Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+R">Raymond Chan</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+X">Xue-Cheng Tai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this study, our goal is to integrate classical mathematical models with
deep neural networks by introducing two novel deep neural network models for
image segmentation known as Double-well Nets. Drawing inspiration from the
Potts model, our models leverage neural networks to represent a region force
functional. We extend the well-know MBO (Merriman-Bence-Osher) scheme to solve
the Potts model. The widely recognized Potts model is approximated using a
double-well potential and then solved by an operator-splitting method, which
turns out to be an extension of the well-known MBO scheme. Subsequently, we
replace the region force functional in the Potts model with a UNet-type
network, which is data-driven, and also introduce control variables to enhance
effectiveness. The resulting algorithm is a neural network activated by a
function that minimizes the double-well potential. What sets our proposed
Double-well Nets apart from many existing deep learning methods for image
segmentation is their strong mathematical foundation. They are derived from the
network approximation theory and employ the MBO scheme to approximately solve
the Potts model. By incorporating mathematical principles, Double-well Nets
bridge the MBO scheme and neural networks, and offer an alternative perspective
for designing networks with mathematical backgrounds. Through comprehensive
experiments, we demonstrate the performance of Double-well Nets, showcasing
their superior accuracy and robustness compared to state-of-the-art neural
networks. Overall, our work represents a valuable contribution to the field of
image segmentation by combining the strengths of classical variational models
and deep neural networks. The Double-well Nets introduce an innovative approach
that leverages mathematical foundations to enhance segmentation performance.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00460" title="Abstract">arXiv:2401.00460</a> [<a href="/pdf/2401.00460" title="Download PDF">pdf</a>, <a href="/format/2401.00460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RainSD: Rain Style Diversification Module for Image Synthesis  Enhancement using Feature-Level Style Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H">Hyeonjae Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Junghyun Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taesoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+S">Sungho Son</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungki Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+G">Gyeungho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+Y">Yongseob Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Autonomous driving technology nowadays targets to level 4 or beyond, but the
researchers are faced with some limitations for developing reliable driving
algorithms in diverse challenges. To promote the autonomous vehicles to spread
widely, it is important to address safety issues on this technology. Among
various safety concerns, the sensor blockage problem by severe weather
conditions can be one of the most frequent threats for multi-task learning
based perception algorithms during autonomous driving. To handle this problem,
the importance of the generation of proper datasets is becoming more
significant. In this paper, a synthetic road dataset with sensor blockage
generated from real road dataset BDD100K is suggested in the format of BDD100K
annotation. Rain streaks for each frame were made by an experimentally
established equation and translated utilizing the image-to-image translation
network based on style transfer. Using this dataset, the degradation of the
diverse multi-task networks for autonomous driving, such as lane detection,
driving area segmentation, and traffic object detection, has been thoroughly
evaluated and analyzed. The tendency of the performance degradation of deep
neural network-based perception systems for autonomous vehicle has been
analyzed in depth. Finally, we discuss the limitation and the future directions
of the deep neural network-based perception algorithms and autonomous driving
dataset generation based on image-to-image translation.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00463" title="Abstract">arXiv:2401.00463</a> [<a href="/pdf/2401.00463" title="Download PDF">pdf</a>, <a href="/format/2401.00463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Local Representations of Self-supervised Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vanyan%2C+A">Ani Vanyan</a>, 
<a href="/search/cs?searchtype=author&query=Barseghyan%2C+A">Alvard Barseghyan</a>, 
<a href="/search/cs?searchtype=author&query=Tamazyan%2C+H">Hakob Tamazyan</a>, 
<a href="/search/cs?searchtype=author&query=Huroyan%2C+V">Vahan Huroyan</a>, 
<a href="/search/cs?searchtype=author&query=Khachatrian%2C+H">Hrant Khachatrian</a>, 
<a href="/search/cs?searchtype=author&query=Danelljan%2C+M">Martin Danelljan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present a comparative analysis of various self-supervised
Vision Transformers (ViTs), focusing on their local representative power.
Inspired by large language models, we examine the abilities of ViTs to perform
various computer vision tasks with little to no fine-tuning. We design an
evaluation framework to analyze the quality of local, i.e. patch-level,
representations in the context of few-shot semantic segmentation, instance
identification, object retrieval, and tracking. We discover that contrastive
learning based methods like DINO produce more universal patch representations
that can be immediately applied for downstream tasks with no parameter tuning,
compared to masked image modeling. The embeddings learned using the latter
approach, e.g. in masked autoencoders, have high variance features that harm
distance-based algorithms, such as k-NN, and do not contain useful information
for most downstream tasks. Furthermore, we demonstrate that removing these
high-variance features enhances k-NN by providing an analysis of the benchmarks
for this work and for Scale-MAE, a recent extension of masked autoencoders.
Finally, we find an object instance retrieval setting where DINOv2, a model
pretrained on two orders of magnitude more data, performs worse than its less
compute-intensive counterpart DINO.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00465" title="Abstract">arXiv:2401.00465</a> [<a href="/pdf/2401.00465" title="Download PDF">pdf</a>, <a href="/ps/2401.00465" title="Download PostScript">ps</a>, <a href="/format/2401.00465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> V2X communication coverage analysis for connected vehicles in  intelligent transportation networks: A case study for the city of Xanthi,  Greece
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bazinas%2C+E">Evangelos Bazinas</a>, 
<a href="/search/cs?searchtype=author&query=Gregoriades%2C+A">Andreas Gregoriades</a>, 
<a href="/search/cs?searchtype=author&query=Raspopoulos%2C+M">Marios Raspopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Georgiades%2C+M">Michael Georgiades</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Wireless World Research Forum, Meeting 49, March 28th-30th 2023, Pozna\'n, Poland, Towards sustainable and automated communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Intelligent transportation systems (ITS) have been developed to improve
traffic flow, efficiency, and safety in transportation. Technological
advancements in communication such as the Vehicle-to-Everything (V2X),
Vehicle-to-Vehicle (V2V) and Vehicle-to Infrastructure (V2I) enable the
real-time exchange of information between vehicles and other entities on the
road network, and thus play a significant role in their safety and efficiency.
This paper presents a simulation study that models V2V and V2I communication to
identify the most suitable range of data transmission between vehicles and
infrastructure. The provincial city of Xanthi, Greece is used as a cases study,
and the goal is to evaluate whether the proposed placement of Road Side Unit
(RSU) provided adequate communication coverage on the city's road network. An
analysis through different scenarios identified improvements in traffic
management, driving behavior and environmental conditions under different RSU
coverage. The results highlight that the communication range of 400 meters is
the most adequate option for optimum traffic management in the city of Xanthi.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00466" title="Abstract">arXiv:2401.00466</a> [<a href="/pdf/2401.00466" title="Download PDF">pdf</a>, <a href="/format/2401.00466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Symbolic Music Alignment with Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peter%2C+S+D">Silvan David Peter</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 24th International Society for Music
  Information Retrieval Conference, {ISMIR} 2023, Milan, Italy, November 5-9,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Symbolic Music Alignment is the process of matching performed MIDI notes to
corresponding score notes. In this paper, we introduce a reinforcement learning
(RL)-based online symbolic music alignment technique. The RL agent - an
attention-based neural network - iteratively estimates the current score
position from local score and performance contexts. For this symbolic alignment
task, environment states can be sampled exhaustively and the reward is dense,
rendering a formulation as a simplified offline RL problem straightforward. We
evaluate the trained agent in three ways. First, in its capacity to identify
correct score positions for sampled test contexts; second, as the core
technique of a complete algorithm for symbolic online note-wise alignment; and
finally, as a real-time symbolic score follower. We further investigate the
pitch-based score and performance representations used as the agent's inputs.
To this end, we develop a second model, a two-step Dynamic Time Warping
(DTW)-based offline alignment algorithm leveraging the same input
representation. The proposed model outperforms a state-of-the-art reference
model of offline symbolic music alignment.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00468" title="Abstract">arXiv:2401.00468</a> [<a href="/pdf/2401.00468" title="Download PDF">pdf</a>, <a href="/format/2401.00468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain and Deep Learning-Based IDS for Securing SDN-Enabled  Industrial IoT Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poorazad%2C+S+K">Samira Kamali Poorazad</a>, 
<a href="/search/cs?searchtype=author&query=Benza%C4%B1d%2C+C">Chafika Benza&#x131;d</a>, 
<a href="/search/cs?searchtype=author&query=Taleb%2C+T">Tarik Taleb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The industrial Internet of Things (IIoT) involves the integration of Internet
of Things (IoT) technologies into industrial settings. However, given the high
sensitivity of the industry to the security of industrial control system
networks and IIoT, the use of software-defined networking (SDN) technology can
provide improved security and automation of communication processes. Despite
this, the architecture of SDN can give rise to various security threats.
Therefore, it is of paramount importance to consider the impact of these
threats on SDN-based IIoT environments. Unlike previous research, which focused
on security in IIoT and SDN architectures separately, we propose an integrated
method including two components that work together seamlessly for better
detecting and preventing security threats associated with SDN-based IIoT
architectures. The two components consist in a convolutional neural
network-based Intrusion Detection System (IDS) implemented as an SDN
application and a Blockchain-based system (BS) to empower application layer and
network layer security, respectively. A significant advantage of the proposed
method lies in jointly minimizing the impact of attacks such as command
injection and rule injection on SDN-based IIoT architecture layers. The
proposed IDS exhibits superior classification accuracy in both binary and
multiclass categories.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00471" title="Abstract">arXiv:2401.00471</a> [<a href="/pdf/2401.00471" title="Download PDF">pdf</a>, <a href="/format/2401.00471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sounding Out Reconstruction Error-Based Evaluation of Generative Models  of Expressive Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peter%2C+S+D">Silvan David Peter</a>, 
<a href="/search/cs?searchtype=author&query=Cancino-Chac%C3%B3n%2C+C+E">Carlos Eduardo Cancino-Chac&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Karystinaios%2C+E">Emmanouil Karystinaios</a>, 
<a href="/search/cs?searchtype=author&query=Widmer%2C+G">Gerhard Widmer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 10th International Conference on Digital Libraries for Musicology,
  November 10, 2023, Milan, Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Generative models of expressive piano performance are usually assessed by
comparing their predictions to a reference human performance. A generative
algorithm is taken to be better than competing ones if it produces performances
that are closer to a human reference performance. However, expert human
performers can (and do) interpret music in different ways, making for different
possible references, and quantitative closeness is not necessarily aligned with
perceptual similarity, raising concerns about the validity of this evaluation
approach. In this work, we present a number of experiments that shed light on
this problem. Using precisely measured high-quality performances of classical
piano music, we carry out a listening test indicating that listeners can
sometimes perceive subtle performance difference that go unnoticed under
quantitative evaluation. We further present tests that indicate that such
evaluation frameworks show a lot of variability in reliability and validity
across different reference performances and pieces. We discuss these results
and their implications for quantitative evaluation, and hope to foster a
critical appreciation of the uncertainties involved in quantitative assessments
of such performances within the wider music information retrieval (MIR)
community.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00473" title="Abstract">arXiv:2401.00473</a> [<a href="/pdf/2401.00473" title="Download PDF">pdf</a>, <a href="/format/2401.00473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emulating insect brains for neuromorphic navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schreiber%2C+K">Korbinian Schreiber</a>, 
<a href="/search/cs?searchtype=author&query=Wunderlich%2C+T">Timo Wunderlich</a>, 
<a href="/search/cs?searchtype=author&query=Spilger%2C+P">Philipp Spilger</a>, 
<a href="/search/cs?searchtype=author&query=Billaudelle%2C+S">Sebastian Billaudelle</a>, 
<a href="/search/cs?searchtype=author&query=Cramer%2C+B">Benjamin Cramer</a>, 
<a href="/search/cs?searchtype=author&query=Stradmann%2C+Y">Yannik Stradmann</a>, 
<a href="/search/cs?searchtype=author&query=Pehle%2C+C">Christian Pehle</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+E">Eric M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Petrovici%2C+M+A">Mihai A. Petrovici</a>, 
<a href="/search/cs?searchtype=author&query=Schemmel%2C+J">Johannes Schemmel</a>, 
<a href="/search/cs?searchtype=author&query=Meier%2C+K">Karlheinz Meier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Bees display the remarkable ability to return home in a straight line after
meandering excursions to their environment. Neurobiological imaging studies
have revealed that this capability emerges from a path integration mechanism
implemented within the insect's brain. In the present work, we emulate this
neural network on the neuromorphic mixed-signal processor BrainScaleS-2 to
guide bees, virtually embodied on a digital co-processor, back to their home
location after randomly exploring their environment. To realize the underlying
neural integrators, we introduce single-neuron spike-based short-term memory
cells with axo-axonic synapses. All entities, including environment, sensory
organs, brain, actuators, and the virtual body, run autonomously on a single
BrainScaleS-2 microchip. The functioning network is fine-tuned for better
precision and reliability through an evolution strategy. As BrainScaleS-2
emulates neural processes 1000 times faster than biology, 4800 consecutive bee
journeys distributed over 320 generations occur within only half an hour on a
single neuromorphic core.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00474" title="Abstract">arXiv:2401.00474</a> [<a href="/pdf/2401.00474" title="Download PDF">pdf</a>, <a href="/format/2401.00474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistically Checkable Reconfiguration Proofs and Inapproximability  of Reconfiguration Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirahara%2C+S">Shuichi Hirahara</a>, 
<a href="/search/cs?searchtype=author&query=Ohsaka%2C+N">Naoto Ohsaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Motivated by the inapproximability of reconfiguration problems, we present a
new PCP-type characterization of PSPACE, which we call a probabilistically
checkable reconfiguration proof (PCRP): Any PSPACE computation can be encoded
into an exponentially long sequence of polynomially long proofs such that every
adjacent pair of the proofs differs in at most one bit, and every proof can be
probabilistically checked by reading a constant number of bits.
<br />Using the new characterization, we prove PSPACE-completeness of approximate
versions of many reconfiguration problems, such as the Maxmin $3$-SAT
Reconfiguration problem. This resolves the open problem posed by Ito, Demaine,
Harvey, Papadimitriou, Sideri, Uehara, and Uno (ISAAC 2008; Theor. Comput. Sci.
2011) as well as the Reconfiguration Inapproximability Hypothesis by Ohsaka
(STACS 2023) affirmatively. We also present PSPACE-completeness of
approximating the Maxmin Clique Reconfiguration problem to within a factor of
$n^\epsilon$ for some constant $\epsilon &gt; 0$.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00475" title="Abstract">arXiv:2401.00475</a> [<a href="/pdf/2401.00475" title="Download PDF">pdf</a>, <a href="/format/2401.00475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E-chat: Emotion-sensitive Spoken Dialogue System with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hongfei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuhao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+B">Bingshen Mu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This study focuses on emotion-sensitive spoken dialogue in human-machine
speech interaction. With the advancement of Large Language Models (LLMs),
dialogue systems can handle multimodal data, including audio. Recent models
have enhanced the understanding of complex audio signals through the
integration of various audio events. However, they are unable to generate
appropriate responses based on emotional speech. To address this, we introduce
the Emotional chat Model (E-chat), a novel spoken dialogue system capable of
comprehending and responding to emotions conveyed from speech. This model
leverages an emotion embedding extracted by a speech encoder, combined with
LLMs, enabling it to respond according to different emotional contexts.
Additionally, we introduce the E-chat200 dataset, designed explicitly for
emotion-sensitive spoken dialogue. In various evaluation metrics, E-chat
consistently outperforms baseline LLMs, demonstrating its potential in
emotional comprehension and human-machine interaction.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00477" title="Abstract">arXiv:2401.00477</a> [<a href="/pdf/2401.00477" title="Download PDF">pdf</a>, <a href="/format/2401.00477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coding for Gaussian Two-Way Channels: Linear and Learning-Based  Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junghoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taejoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A+B">Anindya Bijoy Das</a>, 
<a href="/search/cs?searchtype=author&query=Hosseinalipour%2C+S">Seyyedali Hosseinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Love%2C+D+J">David J. Love</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Although user cooperation cannot improve the capacity of Gaussian two-way
channels (GTWCs) with independent noises, it can improve communication
reliability. In this work, we aim to enhance and balance the communication
reliability in GTWCs by minimizing the sum of error probabilities via joint
design of encoders and decoders at the users. We first formulate general
encoding/decoding functions, where the user cooperation is captured by the
coupling of user encoding processes. The coupling effect renders the
encoder/decoder design non-trivial, requiring effective decoding to capture
this effect, as well as efficient power management at the encoders within power
constraints. To address these challenges, we propose two different two-way
coding strategies: linear coding and learning-based coding. For linear coding,
we propose optimal linear decoding and discuss new insights on encoding
regarding user cooperation to balance reliability. We then propose an efficient
algorithm for joint encoder/decoder design. For learning-based coding, we
introduce a novel recurrent neural network (RNN)-based coding architecture,
where we propose interactive RNNs and a power control layer for encoding, and
we incorporate bi-directional RNNs with an attention mechanism for decoding.
Through simulations, we show that our two-way coding methodologies outperform
conventional channel coding schemes (that do not utilize user cooperation)
significantly in sum-error performance. We also demonstrate that our linear
coding excels at high signal-to-noise ratios (SNRs), while our RNN-based coding
performs best at low SNRs. We further investigate our two-way coding strategies
in terms of power distribution, two-way coding benefit, different coding rates,
and block-length gain.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00490" title="Abstract">arXiv:2401.00490</a> [<a href="/pdf/2401.00490" title="Download PDF">pdf</a>, <a href="/format/2401.00490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel Density Estimation for Multiclass Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moreo%2C+A">Alejandro Moreo</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez%2C+P">Pablo Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=del+Coz%2C+J+J">Juan Jos&#xe9; del Coz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Several disciplines, like the social sciences, epidemiology, sentiment
analysis, or market research, are interested in knowing the distribution of the
classes in a population rather than the individual labels of the members
thereof. Quantification is the supervised machine learning task concerned with
obtaining accurate predictors of class prevalence, and to do so particularly in
the presence of label shift. The distribution-matching (DM) approaches
represent one of the most important families among the quantification methods
that have been proposed in the literature so far. Current DM approaches model
the involved populations by means of histograms of posterior probabilities. In
this paper, we argue that their application to the multiclass setting is
suboptimal since the histograms become class-specific, thus missing the
opportunity to model inter-class information that may exist in the data. We
propose a new representation mechanism based on multivariate densities that we
model via kernel density estimation (KDE). The experiments we have carried out
show our method, dubbed KDEy, yields superior quantification performance with
respect to previous DM approaches. We also investigate the KDE-based
representation within the maximum likelihood framework and show KDEy often
shows superior performance with respect to the expectation-maximization method
for quantification, arguably the strongest contender in the quantification
arena to date.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00493" title="Abstract">arXiv:2401.00493</a> [<a href="/pdf/2401.00493" title="Download PDF">pdf</a>, <a href="/ps/2401.00493" title="Download PostScript">ps</a>, <a href="/format/2401.00493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced variance random batch methods for nonlocal PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pareschi%2C+L">Lorenzo Pareschi</a>, 
<a href="/search/math?searchtype=author&query=Zanella%2C+M">Mattia Zanella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Adaptation and Self-Organizing Systems (nlin.AO)

</div>
<p class="mathjax">Random Batch Methods (RBM) for mean-field interacting particle systems enable
the reduction of the quadratic computational cost associated with particle
interactions to a near-linear cost. The essence of these algorithms lies in the
random partitioning of the particle ensemble into smaller batches at each time
step. The interaction of each particle within these batches is then evolved
until the subsequent time step. This approach effectively decreases the
computational cost by an order of magnitude while increasing the amount of
fluctuations due to the random partitioning. In this work, we propose a
variance reduction technique for RBM applied to nonlocal PDEs of Fokker-Planck
type based on a control variate strategy. The core idea is to construct a
surrogate model that can be computed on the full set of particles at a linear
cost while maintaining enough correlations with the original particle dynamics.
Examples from models of collective behavior in opinion spreading and swarming
dynamics demonstrate the great potential of the present approach.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00496" title="Abstract">arXiv:2401.00496</a> [<a href="/pdf/2401.00496" title="Download PDF">pdf</a>, <a href="/format/2401.00496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAR-RARP50: Segmentation of surgical instrumentation and Action  Recognition on Robot-Assisted Radical Prostatectomy Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Psychogyios%2C+D">Dimitrios Psychogyios</a>, 
<a href="/search/cs?searchtype=author&query=Colleoni%2C+E">Emanuele Colleoni</a>, 
<a href="/search/cs?searchtype=author&query=Van+Amsterdam%2C+B">Beatrice Van Amsterdam</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chih-Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shu-Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuchong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+F">Fucang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+B">Baosheng Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guotai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Boels%2C+M">Maxence Boels</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+J">Jiayu Huo</a>, 
<a href="/search/cs?searchtype=author&query=Sparks%2C+R">Rachel Sparks</a>, 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+P">Prokar Dasgupta</a>, 
<a href="/search/cs?searchtype=author&query=Granados%2C+A">Alejandro Granados</a>, 
<a href="/search/cs?searchtype=author&query=Ourselin%2C+S">Sebastien Ourselin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengya Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">An Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Long Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hongliang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+A">Atsushi Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Harai%2C+Y">Yuriko Harai</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+Y">Yuto Ishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Hayashi%2C+K">Kazuyuki Hayashi</a>, 
<a href="/search/cs?searchtype=author&query=Simoens%2C+J">Jente Simoens</a>, 
<a href="/search/cs?searchtype=author&query=DeBacker%2C+P">Pieter DeBacker</a>, 
<a href="/search/cs?searchtype=author&query=Cisternino%2C+F">Francesco Cisternino</a>, 
<a href="/search/cs?searchtype=author&query=Furnari%2C+G">Gabriele Furnari</a>, 
<a href="/search/cs?searchtype=author&query=Mottrie%2C+A">Alex Mottrie</a>, 
<a href="/search/cs?searchtype=author&query=Ferraguti%2C+F">Federica Ferraguti</a>, 
<a href="/search/cs?searchtype=author&query=Kondo%2C+S">Satoshi Kondo</a>, 
<a href="/search/cs?searchtype=author&query=Kasai%2C+S">Satoshi Kasai</a>, 
<a href="/search/cs?searchtype=author&query=Hirasawa%2C+K">Kousuke Hirasawa</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Soohee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+H">Seung Hyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+E">Kyu Eun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+H">Hyoun-Joong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+K">Kui Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Shan An</a>, 
<a href="/search/cs?searchtype=author&query=Krell%2C+S">Stefanie Krell</a>, 
<a href="/search/cs?searchtype=author&query=Bodenstedt%2C+S">Sebastian Bodenstedt</a>, 
<a href="/search/cs?searchtype=author&query=Ayobi%2C+N">Nicolas Ayobi</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+A">Alejandra Perez</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+S">Santiago Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Puentes%2C+J">Juanita Puentes</a>, 
<a href="/search/cs?searchtype=author&query=Arbelaez%2C+P">Pablo Arbelaez</a>, 
<a href="/search/cs?searchtype=author&query=Mohareri%2C+O">Omid Mohareri</a>, 
<a href="/search/cs?searchtype=author&query=Stoyanov%2C+D">Danail Stoyanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Surgical tool segmentation and action recognition are fundamental building
blocks in many computer-assisted intervention applications, ranging from
surgical skills assessment to decision support systems. Nowadays,
learning-based action recognition and segmentation approaches outperform
classical methods, relying, however, on large, annotated datasets. Furthermore,
action recognition and tool segmentation algorithms are often trained and make
predictions in isolation from each other, without exploiting potential
cross-task relationships. With the EndoVis 2022 SAR-RARP50 challenge, we
release the first multimodal, publicly available, in-vivo, dataset for surgical
action recognition and semantic instrumentation segmentation, containing 50
suturing video segments of Robotic Assisted Radical Prostatectomy (RARP). The
aim of the challenge is twofold. First, to enable researchers to leverage the
scale of the provided dataset and develop robust and highly accurate
single-task action recognition and tool segmentation approaches in the surgical
domain. Second, to further explore the potential of multitask-based learning
approaches and determine their comparative advantage against their single-task
counterparts. A total of 12 teams participated in the challenge, contributing 7
action recognition methods, 9 instrument segmentation techniques, and 4
multitask approaches that integrated both action recognition and instrument
segmentation.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00503" title="Abstract">arXiv:2401.00503</a> [<a href="/pdf/2401.00503" title="Download PDF">pdf</a>, <a href="/format/2401.00503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Viz: A QLoRA-based Copyright Marketplace for Legally Compliant  Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+D">Dipankar Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper aims to introduce and analyze the Viz system in a comprehensive
way, a novel system architecture that integrates Quantized Low-Rank Adapters
(QLoRA) to fine-tune large language models (LLM) within a legally compliant and
resource efficient marketplace. Viz represents a significant contribution to
the field of artificial intelligence, particularly in addressing the challenges
of computational efficiency, legal compliance, and economic sustainability in
the utilization and monetization of LLMs. The paper delineates the scholarly
discourse and developments that have informed the creation of Viz, focusing
primarily on the advancements in LLM models, copyright issues in AI training
(NYT case, 2023), and the evolution of model fine-tuning techniques,
particularly low-rank adapters and quantized low-rank adapters, to create a
sustainable and economically compliant framework for LLM utilization. The
economic model it proposes benefits content creators, AI developers, and
end-users, delineating a harmonious integration of technology, economy, and
law, offering a comprehensive solution to the complex challenges of today's AI
landscape.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00504" title="Abstract">arXiv:2401.00504</a> [<a href="/pdf/2401.00504" title="Download PDF">pdf</a>, <a href="/ps/2401.00504" title="Download PostScript">ps</a>, <a href="/format/2401.00504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HSC-GPT: A Large Language Model for Human Settlements Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ran%2C+C">Chen Ran</a>, 
<a href="/search/cs?searchtype=author&query=Xueqi%2C+Y">Yao Xueqi</a>, 
<a href="/search/cs?searchtype=author&query=Xuhui%2C+J">Jiang Xuhui</a>, 
<a href="/search/cs?searchtype=author&query=Zhengqi%2C+H">Han Zhengqi</a>, 
<a href="/search/cs?searchtype=author&query=Jingze%2C+G">Guo Jingze</a>, 
<a href="/search/cs?searchtype=author&query=Xianyue%2C+Z">Zhang Xianyue</a>, 
<a href="/search/cs?searchtype=author&query=Chunyu%2C+L">Lin Chunyu</a>, 
<a href="/search/cs?searchtype=author&query=Chumin%2C+L">Liu Chumin</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Z">Zhao Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zeke%2C+L">Lian Zeke</a>, 
<a href="/search/cs?searchtype=author&query=Jingjing%2C+Z">Zhang Jingjing</a>, 
<a href="/search/cs?searchtype=author&query=Keke%2C+L">Li Keke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The field of human settlement construction encompasses a range of spatial
designs and management tasks, including urban planning and landscape
architecture design. These tasks involve a plethora of instructions and
descriptions presented in natural language, which are essential for
understanding design requirements and producing effective design solutions.
Recent research has sought to integrate natural language processing (NLP) and
generative artificial intelligence (AI) into human settlement construction
tasks. Due to the efficient processing and analysis capabilities of AI with
data, significant successes have been achieved in design within this domain.
However, this task still faces several fundamental challenges. The semantic
information involved includes complex spatial details, diverse data source
formats, high sensitivity to regional culture, and demanding requirements for
innovation and rigor in work scenarios. These factors lead to limitations when
applying general generative AI in this field, further exacerbated by a lack of
high-quality data for model training. To address these challenges, this paper
first proposes HSC-GPT, a large-scale language model framework specifically
designed for tasks in human settlement construction, considering the unique
characteristics of this domain.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00512" title="Abstract">arXiv:2401.00512</a> [<a href="/pdf/2401.00512" title="Download PDF">pdf</a>, <a href="/ps/2401.00512" title="Download PostScript">ps</a>, <a href="/format/2401.00512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A parametricity-based formalization of semi-simplicial and semi-cubical  sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herbelin%2C+H">Hugo Herbelin</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandra%2C+R">Ramkumar Ramachandra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Associated formalization in Coq at <a href="https://github.com/artagnon/bonak">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Semi-simplicial and semi-cubical sets are commonly defined as presheaves over
respectively, the semi-simplex or semi-cube category. Homotopy Type Theory then
popularized an alternative definition, where the set of n-simplices or n-cubes
are instead regrouped into the families of the fibers over their faces, leading
to a characterization we call indexed. Moreover, it is known that
semi-simplicial and semi-cubical sets are related to iterated Reynolds
parametricity, respectively in its unary and binary variants. We exploit this
correspondence to develop an original uniform indexed definition of both
augmented semi-simplicial and semi-cubical sets, and fully formalize it in Coq.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00515" title="Abstract">arXiv:2401.00515</a> [<a href="/pdf/2401.00515" title="Download PDF">pdf</a>, <a href="/format/2401.00515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Analysis of Vulnerabilities Life Cycle in Golang Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jinchang Hu</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lyuye Zhang</a> (2), 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengwei Liu</a> (2), 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sen Yang</a> (3), 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Song Huang</a> (1), 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a> (2) ((1) College of Command and Control Engineering, Army Engineering University of PLA, NanJing, China. (2) Continental-NTU Corporate Lab, Nanyang Technological University, Singapore, Singapore. (3) Academy of Military Science, BeiJing, China.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, 46th International Conference on Software Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Open-source software (OSS) greatly facilitates program development for
developers. However, the high number of vulnerabilities in open-source software
is a major concern, including in Golang, a relatively new programming language.
In contrast to other commonly used OSS package managers, Golang presents a
distinctive feature whereby commits are prevalently used as dependency versions
prior to their integration into official releases. This attribute can prove
advantageous to users, as patch commits can be implemented in a timely manner
before the releases. However, Golang employs a decentralized mechanism for
managing dependencies, whereby dependencies are upheld and distributed in
separate repositories. This approach can result in delays in the dissemination
of patches and unresolved vulnerabilities.
<br />To tackle the aforementioned concern, a comprehensive investigation was
undertaken to examine the life cycle of vulnerability in Golang, commencing
from its introduction and culminating with its rectification. To this end, a
framework was established by gathering data from diverse sources and
systematically amalgamating them with an algorithm to compute the lags in
vulnerability patching. It turned out that 66.10% of modules in the Golang
ecosystem were affected by vulnerabilities. Within the vulnerability life
cycle, we found two kinds of lag impeding the propagation of vulnerability
fixing. By analyzing reasons behind non-lagged and lagged vulnerabilities,
timely releasing and indexing patch versions could significantly enhance
ecosystem security.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00521" title="Abstract">arXiv:2401.00521</a> [<a href="/pdf/2401.00521" title="Download PDF">pdf</a>, <a href="/format/2401.00521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-spatial Multi-temporal Air Quality Forecasting with Integrated  Monitoring and Reanalysis Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuxiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaodan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jinyue Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP)

</div>
<p class="mathjax">Accurate air quality forecasting is crucial for public health, environmental
monitoring and protection, and urban planning. However, existing methods fail
to effectively utilize multi-scale information, both spatially and temporally.
Spatially, there is a lack of integration between individual monitoring
stations and city-wide scales. Temporally, the periodic nature of air quality
variations is often overlooked or inadequately considered. To address these
limitations, we present a novel Multi-spatial Multi-temporal air quality
forecasting method based on Graph Convolutional Networks and Gated Recurrent
Units (M2G2), bridging the gap in air quality forecasting across spatial and
temporal scales. The proposed framework consists of two modules: Multi-scale
Spatial GCN (MS-GCN) for spatial information fusion and Multi-scale Temporal
GRU(MT-GRU) for temporal information integration. In the spatial dimension, the
MS-GCN module employs a bidirectional learnable structure and a residual
structure, enabling comprehensive information exchange between individual
monitoring stations and the city-scale graph. Regarding the temporal dimension,
the MT-GRU module adaptively combines information from different temporal
scales through parallel hidden states. Leveraging meteorological indicators and
four air quality indicators, we present comprehensive comparative analyses and
ablation experiments, showcasing the higher accuracy of M2G2 in comparison to
nine currently available advanced approaches across all aspects. The
improvements of M2G2 over the second-best method on RMSE of the 24h/48h/72h are
as follows: PM2.5: (7.72%, 6.67%, 10.45%); PM10: (6.43%, 5.68%, 7.73%); NO2:
(5.07%, 7.76%, 16.60%); O3: (6.46%, 6.86%, 9.79%). Furthermore, we demonstrate
the effectiveness of each module of M2G2 by ablation study.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00524" title="Abstract">arXiv:2401.00524</a> [<a href="/pdf/2401.00524" title="Download PDF">pdf</a>, <a href="/format/2401.00524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effect of Optimizer, Initializer, and Architecture of Hypernetworks on  Continual Learning from Demonstration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Auddy%2C+S">Sayantan Auddy</a>, 
<a href="/search/cs?searchtype=author&query=Bergner%2C+S">Sebastian Bergner</a>, 
<a href="/search/cs?searchtype=author&query=Piater%2C+J">Justus Piater</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In continual learning from demonstration (CLfD), a robot learns a sequence of
real-world motion skills continually from human demonstrations. Recently,
hypernetworks have been successful in solving this problem. In this paper, we
perform an exploratory study of the effects of different optimizers,
initializers, and network architectures on the continual learning performance
of hypernetworks for CLfD. Our results show that adaptive learning rate
optimizers work well, but initializers specially designed for hypernetworks
offer no advantages for CLfD. We also show that hypernetworks that are capable
of stable trajectory predictions are robust to different network architectures.
Our open-source code is available at
https://github.com/sebastianbergner/ExploringCLFD.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00525" title="Abstract">arXiv:2401.00525</a> [<a href="/pdf/2401.00525" title="Download PDF">pdf</a>, <a href="/ps/2401.00525" title="Download PostScript">ps</a>, <a href="/format/2401.00525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pack and Measure: An Effective Approach for Influence Propagation in  Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abu-Khzam%2C+F+N">Faisal N. Abu-Khzam</a>, 
<a href="/search/cs?searchtype=author&query=Matar%2C+G+B">Ghinwa Bou Matar</a>, 
<a href="/search/cs?searchtype=author&query=Thoumi%2C+S">Sergio Thoumi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The Influence Maximization problem under the Independent Cascade model (IC)
is considered. The problem asks for a minimal set of vertices to serve as "seed
set" from which a maximum influence propagation is expected. New seed-set
selection methods are introduced based on the notions of a $d$-packing and
vertex centrality. In particular, we focus on selecting seed-vertices that are
far apart and whose influence-values are the highest in their local
communities. Our best results are achieved via an initial computation of a
$d$-Packing followed by selecting either vertices of high degree or high
centrality in their respective closed neighborhoods. This overall "Pack and
Measure" approach proves highly effective as a seed selection method.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00529" title="Abstract">arXiv:2401.00529</a> [<a href="/pdf/2401.00529" title="Download PDF">pdf</a>, <a href="/format/2401.00529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphGPT: Graph Learning with Generative Pre-trained Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qifang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Weidong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoxiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce \textit{GraphGPT}, a novel model for Graph learning by
self-supervised Generative Pre-training Transformers. Our model transforms each
graph or sampled subgraph into a sequence of tokens representing the node, edge
and attributes reversibly using the Eulerian path first. Then we feed the
tokens into a standard transformer decoder and pre-train it with the
next-token-prediction (NTP) task. Lastly, we fine-tune the GraphGPT model with
the supervised tasks. This intuitive, yet effective model achieves superior or
close results to the state-of-the-art methods for the graph-, edge- and
node-level tasks on the large scale molecular dataset PCQM4Mv2, the
protein-protein association dataset ogbl-ppa and the ogbn-proteins dataset from
the Open Graph Benchmark (OGB). Furthermore, the generative pre-training
enables us to train GraphGPT up to 400M+ parameters with consistently
increasing performance, which is beyond the capability of GNNs and previous
graph transformers. The source code and pre-trained checkpoints will be
released soon\footnote{\url{https://github.com/alibaba/graph-gpt}} to pave the
way for the graph foundation model research, and also to assist the scientific
discovery in pharmaceutical, chemistry, material and bio-informatics domains,
etc.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00532" title="Abstract">arXiv:2401.00532</a> [<a href="/pdf/2401.00532" title="Download PDF">pdf</a>, <a href="/format/2401.00532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Necessity of Metalearning: Learning Suitable Parameterizations  for Learning Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamidi%2C+M">Massinissa Hamidi</a>, 
<a href="/search/cs?searchtype=author&query=Osmani%2C+A">Aomar Osmani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper we will discuss metalearning and how we can go beyond the
current classical learning paradigm. We will first address the importance of
inductive biases in the learning process and what is at stake: the quantities
of data necessary to learn. We will subsequently see the importance of choosing
suitable parameterizations to end up with well-defined learning processes.
Especially since in the context of real-world applications, we face numerous
biases due, e.g., to the specificities of sensors, the heterogeneity of data
sources, the multiplicity of points of view, etc. This will lead us to the idea
of exploiting the structuring of the concepts to be learned in order to
organize the learning process that we published previously. We conclude by
discussing the perspectives around parameter-tying schemes and the emergence of
universal aspects in the models thus learned.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00533" title="Abstract">arXiv:2401.00533</a> [<a href="/pdf/2401.00533" title="Download PDF">pdf</a>, <a href="/ps/2401.00533" title="Download PostScript">ps</a>, <a href="/format/2401.00533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of the complex block Jacobi methods under the generalized  serial pivot strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Begovic%2C+E">Erna Begovic</a>, 
<a href="/search/math?searchtype=author&query=Hari%2C+V">Vjeran Hari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The paper considers the convergence of the complex block Jacobi
diagonalization methods under the large set of the generalized serial pivot
strategies. The global convergence of the block methods for Hermitian, normal
and $J$-Hermitian matrices is proven. In order to obtain the convergence
results for the block methods that solve other eigenvalue problems, such as the
generalized eigenvalue problem, we consider the convergence of a general block
iterative process which uses the complex block Jacobi annihilators and
operators.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00534" title="Abstract">arXiv:2401.00534</a> [<a href="/pdf/2401.00534" title="Download PDF">pdf</a>, <a href="/format/2401.00534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Financial Time-Series Forecasting: Towards Synergizing Performance And  Interpretability Within a Hybrid Machine Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kexin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chufeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+D">Danqing Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">In the realm of cryptocurrency, the prediction of Bitcoin prices has garnered
substantial attention due to its potential impact on financial markets and
investment strategies. This paper propose a comparative study on hybrid machine
learning algorithms and leverage on enhancing model interpretability.
Specifically, linear regression(OLS, LASSO), long-short term memory(LSTM),
decision tree regressors are introduced. Through the grounded experiments, we
observe linear regressor achieves the best performance among candidate models.
For the interpretability, we carry out a systematic overview on the
preprocessing techniques of time-series statistics, including decomposition,
auto-correlational function, exponential triple forecasting, which aim to
excavate latent relations and complex patterns appeared in the financial
time-series forecasting. We believe this work may derive more attention and
inspire more researches in the realm of time-series analysis and its realistic
applications.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00536" title="Abstract">arXiv:2401.00536</a> [<a href="/pdf/2401.00536" title="Download PDF">pdf</a>, <a href="/format/2401.00536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Task, Multi-Modal Approach for Predicting Categorical and  Dimensional Emotions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ispas%2C+A">Alex-R&#x103;zvan Ispas</a>, 
<a href="/search/cs?searchtype=author&query=Deschamps-Berger%2C+T">Th&#xe9;o Deschamps-Berger</a>, 
<a href="/search/cs?searchtype=author&query=Devillers%2C+L">Laurence Devillers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Companion Publication of the 25th International Conference on Multimodal Interaction (pp. 311-317)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Speech emotion recognition (SER) has received a great deal of attention in
recent years in the context of spontaneous conversations. While there have been
notable results on datasets like the well known corpus of naturalistic dyadic
conversations, IEMOCAP, for both the case of categorical and dimensional
emotions, there are few papers which try to predict both paradigms at the same
time. Therefore, in this work, we aim to highlight the performance contribution
of multi-task learning by proposing a multi-task, multi-modal system that
predicts categorical and dimensional emotions. The results emphasise the
importance of cross-regularisation between the two types of emotions. Our
approach consists of a multi-task, multi-modal architecture that uses parallel
feature refinement through self-attention for the feature of each modality. In
order to fuse the features, our model introduces a set of learnable bridge
tokens that merge the acoustic and linguistic features with the help of
cross-attention. Our experiments for categorical emotions on 10-fold validation
yield results comparable to the current state-of-the-art. In our configuration,
our multi-task approach provides better results compared to learning each
paradigm separately. On top of that, our best performing model achieves a high
result for valence compared to the previous multi-task experiments.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00544" title="Abstract">arXiv:2401.00544</a> [<a href="/pdf/2401.00544" title="Download PDF">pdf</a>, <a href="/format/2401.00544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reliable Knowledge Processing Framework for Combustion Science using  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vansh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+V">Venkat Raman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages and 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This research explores the integration of large language models (LLMs) into
scientific data assimilation, focusing on combustion science as a case study.
Leveraging foundational models integrated with Retrieval-Augmented Generation
(RAG) framework, the study introduces an approach to process diverse combustion
research data, spanning experimental studies, simulations, and literature. The
multifaceted nature of combustion research emphasizes the critical role of
knowledge processing in navigating and extracting valuable information from a
vast and diverse pool of sources. The developed approach minimizes
computational and economic expenses while optimizing data privacy and accuracy.
It incorporates prompt engineering and offline open-source LLMs, offering user
autonomy in selecting base models. The study provides a thorough examination of
text segmentation strategies, conducts comparative studies between LLMs, and
explores various optimized prompts to demonstrate the effectiveness of the
framework. By incorporating an external database, the framework outperforms a
conventional LLM in generating accurate responses and constructing robust
arguments. Additionally, the study delves into the investigation of optimized
prompt templates for the purpose of efficient extraction of scientific
literature. The research addresses concerns related to hallucinations and false
research articles by introducing a custom workflow developed with a detection
algorithm to filter out inaccuracies. Despite identified areas for improvement,
the framework consistently delivers accurate domain-specific responses with
minimal human oversight. The prompt-agnostic approach introduced holds promise
for future deliberations. The study underscores the significance of integrating
LLMs and knowledge processing techniques in scientific research, providing a
foundation for advancements in data assimilation and utilization.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00546" title="Abstract">arXiv:2401.00546</a> [<a href="/pdf/2401.00546" title="Download PDF">pdf</a>, <a href="/format/2401.00546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AllSpark: a multimodal spatiotemporal general model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Run Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiujun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">YanSheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dapeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shizhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiayi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haifeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages, 16 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">For a long time, due to the high heterogeneity in structure and semantics
among various spatiotemporal modal data, the joint interpretation of multimodal
spatiotemporal data has been an extremely challenging problem. The primary
challenge resides in striking a trade-off between the cohesion and autonomy of
diverse modalities, and this trade-off exhibits a progressively nonlinear
nature as the number of modalities expands. We introduce the Language as
Reference Framework (LaRF), a fundamental principle for constructing a
multimodal unified model, aiming to strike a trade-off between the cohesion and
autonomy among different modalities. We propose a multimodal spatiotemporal
general artificial intelligence model, called AllSpark. Our model integrates
thirteen different modalities into a unified framework, including 1D (text,
code), 2D (RGB, infrared, SAR, multispectral, hyperspectral, tables, graphs,
trajectory, oblique photography), and 3D (point clouds, videos) modalities. To
achieve modal cohesion, AllSpark uniformly maps diverse modal features to the
language modality. In addition, we design modality-specific prompts to guide
multi-modal large language models in accurately perceiving multimodal data. To
maintain modality autonomy, AllSpark introduces modality-specific encoders to
extract the tokens of various spatiotemporal modalities. And modal bridge is
employed to achieve dimensional projection from each modality to the language
modality. Finally, observing a gap between the model's interpretation and
downstream tasks, we designed task heads to enhance the model's generalization
capability on specific downstream tasks. Experiments indicate that AllSpark
achieves competitive accuracy in modalities such as RGB and trajectory compared
to state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00547" title="Abstract">arXiv:2401.00547</a> [<a href="/pdf/2401.00547" title="Download PDF">pdf</a>, <a href="/ps/2401.00547" title="Download PostScript">ps</a>, <a href="/format/2401.00547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Learning for Ambiguous Chance Constrained Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madhusudanarao%2C+A+C">A Ch Madhusudanarao</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rahul Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We study chance constrained optimization problems $\min_x f(x)$ s.t.
$P(\left\{ \theta: g(x,\theta)\le 0 \right\})\ge 1-\epsilon$ where $\epsilon\in
(0,1)$ is the violation probability, when the distribution $P$ is not known to
the decision maker (DM). When the DM has access to a set of distributions
$\mathcal{U}$ such that $P$ is contained in $\mathcal{U}$, then the problem is
known as the ambiguous chance-constrained problem \cite{erdougan2006ambiguous}.
We study ambiguous chance-constrained problem for the case when $\mathcal{U}$
is of the form $\left\{\mu:\frac{\mu (y)}{\nu(y)}\leq C, \forall y\in\Theta,
\mu(y)\ge 0\right\}$, where $\nu$ is a ``reference distribution.'' We show that
in this case the original problem can be ``well-approximated'' by a sampled
problem in which $N$ i.i.d. samples of $\theta$ are drawn from $\nu$, and the
original constraint is replaced with $g(x,\theta_i)\le 0,~i=1,2,\ldots,N$. We
also derive the sample complexity associated with this approximation, i.e., for
$\epsilon,\delta&gt;0$ the number of samples which must be drawn from $\nu$ so
that with a probability greater than $1-\delta$ (over the randomness of $\nu$),
the solution obtained by solving the sampled program yields an
$\epsilon$-feasible solution for the original chance constrained problem.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00551" title="Abstract">arXiv:2401.00551</a> [<a href="/pdf/2401.00551" title="Download PDF">pdf</a>, <a href="/format/2401.00551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalist FaceX via Learning Unified Facial Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yue Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yanhao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Ying Tai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://diffusion-facex.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work presents FaceX framework, a novel facial generalist model capable
of handling diverse facial tasks simultaneously. To achieve this goal, we
initially formulate a unified facial representation for a broad spectrum of
facial editing tasks, which macroscopically decomposes a face into fundamental
identity, intra-personal variation, and environmental factors. Based on this,
we introduce Facial Omni-Representation Decomposing (FORD) for seamless
manipulation of various facial components, microscopically decomposing the core
aspects of most facial editing tasks. Furthermore, by leveraging the prior of a
pretrained StableDiffusion (SD) to enhance generation quality and accelerate
training, we design Facial Omni-Representation Steering (FORS) to first
assemble unified facial representations and then effectively steer the SD-aware
generation process by the efficient Facial Representation Controller (FRC).
%Without any additional features, Our versatile FaceX achieves competitive
performance compared to elaborate task-specific models on popular facial
editing tasks. Full codes and models will be available at
https://github.com/diffusion-facex/FaceX.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00561" title="Abstract">arXiv:2401.00561</a> [<a href="/pdf/2401.00561" title="Download PDF">pdf</a>, <a href="/format/2401.00561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QGLAB: A MATLAB Package for Computations on Quantum Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goodman%2C+R+H">Roy H. Goodman</a>, 
<a href="/search/math?searchtype=author&query=Conte%2C+G">Grace Conte</a>, 
<a href="/search/math?searchtype=author&query=Marzuola%2C+J+L">Jeremy L. Marzuola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 23 figures, Comments Welcome! Code associated with this publication available at <a href="https://github.com/manroygood/Quantum-Graphs/tree/master">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We describe QGLAB, a new MATLAB package for analyzing partial differential
equations on quantum graphs. The software is built on the existing,
object-oriented MATLAB directed-graph class, inheriting its structure and
adding additional easy-to-use features. The package allows one to construct a
quantum graph and accurately compute the spectrum of elliptic operators,
solutions to Poisson problems, the linear and nonlinear time evolution of a
variety of PDEs, the continuation of branches of steady states (including
locating and switching branches at bifurcations) and more. It uses a unified
framework to implement finite-difference and Chebyshev discretizations of
differential operators on a quantum graph. For simplicity, the package
overloads many built-in MATLAB functions to work on the class.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00563" title="Abstract">arXiv:2401.00563</a> [<a href="/pdf/2401.00563" title="Download PDF">pdf</a>, <a href="/format/2401.00563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KernelGPT: Enhanced Kernel Fuzzing via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zijie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Bugs in operating system kernels can affect billions of devices and users all
over the world. As a result, a large body of research has been focused on
kernel fuzzing, i.e., automatically generating syscall (system call) sequences
to detect potential kernel bugs or vulnerabilities. Syzkaller, one of the most
widely studied kernel fuzzers, aims to generate valid syscall sequences based
on predefined specifications written in syzlang, a domain-specific language for
defining syscalls, their arguments, and the relationships between them. While
there has been existing work trying to automate Syzkaller specification
generation, this still remains largely manual work and a large number of
important syscalls are still uncovered. In this paper, we propose KernelGPT,
the first approach to automatically inferring Syzkaller specifications via
Large Language Models (LLMs) for enhanced kernel fuzzing. Our basic insight is
that LLMs have seen massive kernel code, documentation, and use cases during
pre-training, and thus can automatically distill the necessary information for
making valid syscalls. More specifically, KernelGPT leverages an iterative
approach to automatically infer all the necessary specification components, and
further leverages the validation feedback to repair/refine the initial
specifications. Our preliminary results demonstrate that KernelGPT can help
Syzkaller achieve higher coverage and find multiple previously unknown bugs.
Moreover, we also received a request from the Syzkaller team to upstream
specifications inferred by KernelGPT.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00575" title="Abstract">arXiv:2401.00575</a> [<a href="/pdf/2401.00575" title="Download PDF">pdf</a>, <a href="/format/2401.00575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Networks Against (and For) Self-Training: Classification with  Small Labeled and Large Unlabeled Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karisani%2C+P">Payam Karisani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACL Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We propose a semi-supervised text classifier based on self-training using one
positive and one negative property of neural networks. One of the weaknesses of
self-training is the semantic drift problem, where noisy pseudo-labels
accumulate over iterations and consequently the error rate soars. In order to
tackle this challenge, we reshape the role of pseudo-labels and create a
hierarchical order of information. In addition, a crucial step in self-training
is to use the classifier confidence prediction to select the best candidate
pseudo-labels. This step cannot be efficiently done by neural networks, because
it is known that their output is poorly calibrated. To overcome this challenge,
we propose a hybrid metric to replace the plain confidence measurement. Our
metric takes into account the prediction uncertainty via a subsampling
technique. We evaluate our model in a set of five standard benchmarks, and show
that it significantly outperforms a set of ten diverse baseline models.
Furthermore, we show that the improvement achieved by our model is additive to
language model pretraining, which is a widely used technique for using
unlabeled documents. Our code is available at
https://github.com/p-karisani/RST.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00578" title="Abstract">arXiv:2401.00578</a> [<a href="/pdf/2401.00578" title="Download PDF">pdf</a>, <a href="/ps/2401.00578" title="Download PostScript">ps</a>, <a href="/format/2401.00578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Error in Matrix Completion: Approximately Low-Rank Structures and  Missing Blocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Capponi%2C+A">Agostino Capponi</a>, 
<a href="/search/cs?searchtype=author&query=Stojnic%2C+M">Mihailo Stojnic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 figures. arXiv admin note: text overlap with <a href="/abs/2301.00793">arXiv:2301.00793</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We study the completion of approximately low rank matrices with entries
missing not at random (MNAR). In the context of typical large-dimensional
statistical settings, we establish a framework for the performance analysis of
the nuclear norm minimization ($\ell_1^*$) algorithm. Our framework produces
\emph{exact} estimates of the worst-case residual root mean squared error and
the associated phase transitions (PT), with both exhibiting remarkably simple
characterizations. Our results enable to {\it precisely} quantify the impact of
key system parameters, including data heterogeneity, size of the missing block,
and deviation from ideal low rankness, on the accuracy of $\ell_1^*$-based
matrix completion. To validate our theoretical worst-case RMSE estimates, we
conduct numerical simulations, demonstrating close agreement with their
numerical counterparts.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00579" title="Abstract">arXiv:2401.00579</a> [<a href="/pdf/2401.00579" title="Download PDF">pdf</a>, <a href="/format/2401.00579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Effectiveness of Instruction Tuning in Biomedical Language  Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rohanian%2C+O">Omid Rohanian</a>, 
<a href="/search/cs?searchtype=author&query=Nouriborji%2C+M">Mohammadmahdi Nouriborji</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+D+A">David A. Clifton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs), particularly those similar to ChatGPT, have
significantly influenced the field of Natural Language Processing (NLP). While
these models excel in general language tasks, their performance in
domain-specific downstream tasks such as biomedical and clinical Named Entity
Recognition (NER), Relation Extraction (RE), and Medical Natural Language
Inference (NLI) is still evolving. In this context, our study investigates the
potential of instruction tuning for biomedical language processing, applying
this technique to two general LLMs of substantial scale. We present a
comprehensive, instruction-based model trained on a dataset that consists of
approximately $200,000$ instruction-focused samples. This dataset represents a
carefully curated compilation of existing data, meticulously adapted and
reformatted to align with the specific requirements of our instruction-based
tasks. This initiative represents an important step in utilising such models to
achieve results on par with specialised encoder-only models like BioBERT and
BioClinicalBERT for various classical biomedical NLP tasks. Our work includes
an analysis of the dataset's composition and its impact on model performance,
providing insights into the intricacies of instruction tuning. By sharing our
codes, models, and the distinctively assembled instruction-based dataset, we
seek to encourage ongoing research and development in this area.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00582" title="Abstract">arXiv:2401.00582</a> [<a href="/pdf/2401.00582" title="Download PDF">pdf</a>, <a href="/format/2401.00582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis of Embedding Layers and Similarity Scores using Siamese  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bingi%2C+Y">Yash Bingi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yiqiao Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Lanugage Models (LLMs) are gaining increasing popularity in a variety
of use cases, from language understanding and writing to assistance in
application development. One of the most important aspects for optimal
funcionality of LLMs is embedding layers. Word embeddings are distributed
representations of words in a continuous vector space. In the context of LLMs,
words or tokens from the input text are transformed into high-dimensional
vectors using unique algorithms specific to the model. Our research examines
the embedding algorithms from leading companies in the industry, such as
OpenAI, Google's PaLM, and BERT. Using medical data, we have analyzed
similarity scores of each embedding layer, observing differences in performance
among each algorithm. To enhance each model and provide an additional encoding
layer, we also implemented Siamese Neural Networks. After observing changes in
performance with the addition of the model, we measured the carbon footage per
epoch of training. The carbon footprint associated with large language models
(LLMs) is a significant concern, and should be taken into consideration when
selecting algorithms for a variety of use cases. Overall, our research compared
the accuracy different, leading embedding algorithms and their carbon footage,
allowing for a holistic review of each embedding algorithm.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00583" title="Abstract">arXiv:2401.00583</a> [<a href="/pdf/2401.00583" title="Download PDF">pdf</a>, <a href="/format/2401.00583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Privacy and Practicality of Objective Perturbation for  Differentially Private Linear Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Redberg%2C+R">Rachel Redberg</a>, 
<a href="/search/cs?searchtype=author&query=Koskela%2C+A">Antti Koskela</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In the arena of privacy-preserving machine learning, differentially private
stochastic gradient descent (DP-SGD) has outstripped the objective perturbation
mechanism in popularity and interest. Though unrivaled in versatility, DP-SGD
requires a non-trivial privacy overhead (for privately tuning the model's
hyperparameters) and a computational complexity which might be extravagant for
simple models such as linear and logistic regression. This paper revamps the
objective perturbation mechanism with tighter privacy analyses and new
computational tools that boost it to perform competitively with DP-SGD on
unconstrained convex generalized linear problems.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00588" title="Abstract">arXiv:2401.00588</a> [<a href="/pdf/2401.00588" title="Download PDF">pdf</a>, <a href="/format/2401.00588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness in Serving Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Ying Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shiyi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dacheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+D">Danyang Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">High-demand LLM inference services (e.g., ChatGPT and BARD) support a wide
range of requests from short chat conversations to long document reading. To
ensure that all client requests are processed fairly, most major LLM inference
services have request rate limits, to ensure that no client can dominate the
request queue. However, this rudimentary notion of fairness also results in
under-utilization of the resources and poor client experience when there is
spare capacity. While there is a rich literature on fair scheduling, serving
LLMs presents new challenges due to their unpredictable request lengths and
their unique batching characteristics on parallel accelerators. This paper
introduces the definition of LLM serving fairness based on a cost function that
accounts for the number of input and output tokens processed. To achieve
fairness in serving, we propose a novel scheduling algorithm, the Virtual Token
Counter (VTC), a fair scheduler based on the continuous batching mechanism. We
prove a 2x tight upper bound on the service difference between two backlogged
clients, adhering to the requirement of work-conserving. Through extensive
experiments, we demonstrate the superior performance of VTC in ensuring
fairness, especially in contrast to other baseline methods, which exhibit
shortcomings under various conditions.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00593" title="Abstract">arXiv:2401.00593</a> [<a href="/pdf/2401.00593" title="Download PDF">pdf</a>, <a href="/format/2401.00593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplicity bias, algorithmic probability, and the random logistic map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamzi%2C+B">Boumediene Hamzi</a>, 
<a href="/search/cs?searchtype=author&query=Dingle%2C+K">Kamaludin Dingle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Dynamical Systems (math.DS); Chaotic Dynamics (nlin.CD); Machine Learning (stat.ML)

</div>
<p class="mathjax">Simplicity bias is an intriguing phenomenon prevalent in various input-output
maps, characterized by a preference for simpler, more regular, or symmetric
outputs. Notably, these maps typically feature high-probability outputs with
simple patterns, whereas complex patterns are exponentially less probable. This
bias has been extensively examined and attributed to principles derived from
algorithmic information theory and algorithmic probability. In a significant
advancement, it has been demonstrated that the renowned logistic map
$x_{k+1}=\mu x_k(1-x_k)$, and other one-dimensional maps exhibit simplicity
bias when conceptualized as input-output systems. Building upon this
foundational work, our research delves into the manifestations of simplicity
bias within the random logistic map, specifically focusing on scenarios
involving additive noise. This investigation is driven by the overarching goal
of formulating a comprehensive theory for the prediction and analysis of time
series.Our primary contributions are multifaceted. We discover that simplicity
bias is observable in the random logistic map for specific ranges of $\mu$ and
noise magnitudes. Additionally, we find that this bias persists even with the
introduction of small measurement noise, though it diminishes as noise levels
increase. Our studies also revisit the phenomenon of noise-induced chaos,
particularly when $\mu=3.83$, revealing its characteristics through
complexity-probability plots. Intriguingly, we employ the logistic map to
underscore a paradoxical aspect of data analysis: more data adhering to a
consistent trend can occasionally lead to reduced confidence in extrapolation
predictions, challenging conventional wisdom.We propose that adopting a
probability-complexity perspective in analyzing dynamical systems could
significantly enrich statistical learning theories related to series
prediction.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00595" title="Abstract">arXiv:2401.00595</a> [<a href="/pdf/2401.00595" title="Download PDF">pdf</a>, <a href="/format/2401.00595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State of What Art? A Call for Multi-Prompt LLM Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mizrahi%2C+M">Moran Mizrahi</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+G">Guy Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Malkin%2C+D">Dan Malkin</a>, 
<a href="/search/cs?searchtype=author&query=Dror%2C+R">Rotem Dror</a>, 
<a href="/search/cs?searchtype=author&query=Shahaf%2C+D">Dafna Shahaf</a>, 
<a href="/search/cs?searchtype=author&query=Stanovsky%2C+G">Gabriel Stanovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advances in large language models (LLMs) have led to the development
of various evaluation benchmarks. These benchmarks typically rely on a single
instruction template for evaluating all LLMs on a specific task. In this paper,
we comprehensively analyze the brittleness of results obtained via
single-prompt evaluations across 6.5M instances, involving 20 different LLMs
and 39 tasks from 3 benchmarks. To improve robustness of the analysis, we
propose to evaluate LLMs with a set of diverse prompts instead. We discuss
tailored evaluation metrics for specific use cases (e.g., LLM developers vs.
developers interested in a specific downstream task), ensuring a more reliable
and meaningful assessment of LLM capabilities. We then implement these criteria
and conduct evaluations of multiple models, providing insights into the true
strengths and limitations of current LLMs.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00604" title="Abstract">arXiv:2401.00604</a> [<a href="/pdf/2401.00604" title="Download PDF">pdf</a>, <a href="/format/2401.00604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SteinDreamer: Variance Reduction for Text-to-3D Score Distillation via  Stein Identity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiwen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dejia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+S">Sreyas Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Iandola%2C+F">Forrest Iandola</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+R">Rakesh Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yilei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vita-group.github.io/SteinDreamer/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Score distillation has emerged as one of the most prevalent approaches for
text-to-3D asset synthesis. Essentially, score distillation updates 3D
parameters by lifting and back-propagating scores averaged over different
views. In this paper, we reveal that the gradient estimation in score
distillation is inherent to high variance. Through the lens of variance
reduction, the effectiveness of SDS and VSD can be interpreted as applications
of various control variates to the Monte Carlo estimator of the distilled
score. Motivated by this rethinking and based on Stein's identity, we propose a
more general solution to reduce variance for score distillation, termed Stein
Score Distillation (SSD). SSD incorporates control variates constructed by
Stein identity, allowing for arbitrary baseline functions. This enables us to
include flexible guidance priors and network architectures to explicitly
optimize for variance reduction. In our experiments, the overall pipeline,
dubbed SteinDreamer, is implemented by instantiating the control variate with a
monocular depth estimator. The results suggest that SSD can effectively reduce
the distillation variance and consistently improve visual quality for both
object- and scene-level generation. Moreover, we demonstrate that SteinDreamer
achieves faster convergence than existing methods due to more stable gradient
updates.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00605" title="Abstract">arXiv:2401.00605</a> [<a href="/pdf/2401.00605" title="Download PDF">pdf</a>, <a href="/format/2401.00605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Multi-Object Tracking Under Limited Field of View  Heterogeneous Sensors with Density Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+H">Hoa Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Leong%2C+A+S">Alex S. Leong</a>, 
<a href="/search/cs?searchtype=author&query=Panicker%2C+S">Sabita Panicker</a>, 
<a href="/search/cs?searchtype=author&query=Baker%2C+R">Robin Baker</a>, 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+D+C">Damith C. Ranasinghe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider the problem of tracking multiple, unknown, and time-varying
numbers of objects using a distributed network of heterogeneous sensors. In an
effort to derive a formulation for practical settings, we consider limited and
unknown sensor field-of-views (FoVs), sensors with limited local computational
resources and communication channel capacity. The resulting distributed
multi-object tracking algorithm involves solving an NP-hard multidimensional
assignment problem either optimally for small-size problems or sub-optimally
for general practical problems. For general problems, we propose an efficient
distributed multi-object tracking algorithm that performs track-to-track fusion
using a clustering-based analysis of the state space transformed into a density
space to mitigate the complexity of the assignment problem. The proposed
algorithm can more efficiently group local track estimates for fusion than
existing approaches. To ensure we achieve globally consistent identities for
tracks across a network of nodes as objects move between FoVs, we develop a
graph-based algorithm to achieve label consensus and minimise track
segmentation. Numerical experiments with a synthetic and a real-world
trajectory dataset demonstrate that our proposed method is significantly more
computationally efficient than state-of-the-art solutions, achieving similar
tracking accuracy and bandwidth requirements but with improved label
consistency.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00608" title="Abstract">arXiv:2401.00608</a> [<a href="/pdf/2401.00608" title="Download PDF">pdf</a>, <a href="/format/2401.00608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bringing Back the Context: Camera Trap Species Identification as Link  Prediction on Multimodal Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pahuja%2C+V">Vardaan Pahuja</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Weidi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Cheng-Hao Tu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong-You Chen</a>, 
<a href="/search/cs?searchtype=author&query=Berger-Wolf%2C+T">Tanya Berger-Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+C">Charles Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Song Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wei-Lun Chao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Camera traps are valuable tools in animal ecology for biodiversity monitoring
and conservation. However, challenges like poor generalization to deployment at
new unseen locations limit their practical application. Images are naturally
associated with heterogeneous forms of context possibly in different
modalities. In this work, we leverage the structured context associated with
the camera trap images to improve out-of-distribution generalization for the
task of species identification in camera traps. For example, a photo of a wild
animal may be associated with information about where and when it was taken, as
well as structured biology knowledge about the animal species. While typically
overlooked by existing work, bringing back such context offers several
potential benefits for better image understanding, such as addressing data
scarcity and enhancing generalization. However, effectively integrating such
heterogeneous context into the visual domain is a challenging problem. To
address this, we propose a novel framework that reformulates species
classification as link prediction in a multimodal knowledge graph (KG). This
framework seamlessly integrates various forms of multimodal context for visual
recognition. We apply this framework for out-of-distribution species
classification on the iWildCam2020-WILDS and Snapshot Mountain Zebra datasets
and achieve competitive performance with state-of-the-art approaches.
Furthermore, our framework successfully incorporates biological taxonomy for
improved generalization and enhances sample efficiency for recognizing
under-represented species.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00609" title="Abstract">arXiv:2401.00609</a> [<a href="/pdf/2401.00609" title="Download PDF">pdf</a>, <a href="/format/2401.00609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Personality, Persona, and Profile in Conversational Agents  and Chatbots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sutcliffe%2C+R">Richard Sutcliffe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 6 tables, 207 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a review of personality in neural conversational agents (CAs),
also called chatbots. First, we define Personality, Persona, and Profile. We
explain all personality schemes which have been used in CAs, and list models
under the scheme(s) which they use. Second we describe 21 datasets which have
been developed in recent CA personality research. Third, we define the methods
used to embody personality in a CA, and review recent models using them.
Fourth, we survey some relevant reviews on CAs, personality, and related
topics. Finally, we draw conclusions and identify some research challenges for
this important emerging field.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00610" title="Abstract">arXiv:2401.00610</a> [<a href="/pdf/2401.00610" title="Download PDF">pdf</a>, <a href="/format/2401.00610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A High School Camp on Algorithms and Coding in Jamaica
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fokum%2C+D+T">Daniel T. Fokum</a>, 
<a href="/search/cs?searchtype=author&query=Shui%2C+Z+C">Zaria Chen Shui</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+K">Kerene Wright</a>, 
<a href="/search/cs?searchtype=author&query=Paradise%2C+O">Orr Paradise</a>, 
<a href="/search/cs?searchtype=author&query=Mansingh%2C+G">Gunjan Mansingh</a>, 
<a href="/search/cs?searchtype=author&query=Coore%2C+D">Daniel Coore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Proceedings of the 55th ACM Technical Symposium on Computer Science Education (SIGCSE), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This is a report on JamCoders, a four-week long computer-science camp for
high school students in Jamaica. The camp teaches college-level coding and
algorithms, and targets academically excellent students in grades 9--11 (ages
14--17). Qualitative assessment shows that the camp was, in general terms, a
success. We reflect on the background and academic structure of the camp and
share key takeaways on designing and operating a successful camp. We analyze
data collected before, during and after the camp and map the effects of
demographic differences on student performance in camp. We conclude with a
discussion on possible improvements on our approach.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00616" title="Abstract">arXiv:2401.00616</a> [<a href="/pdf/2401.00616" title="Download PDF">pdf</a>, <a href="/format/2401.00616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GD^2-NeRF: Generative Detail Compensation via GAN and Diffusion for  One-shot Generalizable Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Shuai Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we focus on the One-shot Novel View Synthesis (O-NVS) task
which targets synthesizing photo-realistic novel views given only one reference
image per scene. Previous One-shot Generalizable Neural Radiance Fields
(OG-NeRF) methods solve this task in an inference-time finetuning-free manner,
yet suffer the blurry issue due to the encoder-only architecture that highly
relies on the limited reference image. On the other hand, recent
diffusion-based image-to-3d methods show vivid plausible results via distilling
pre-trained 2D diffusion models into a 3D representation, yet require tedious
per-scene optimization. Targeting these issues, we propose the GD^2-NeRF, a
Generative Detail compensation framework via GAN and Diffusion that is both
inference-time finetuning-free and with vivid plausible details. In detail,
following a coarse-to-fine strategy, GD^2-NeRF is mainly composed of a
One-stage Parallel Pipeline (OPP) and a 3D-consistent Detail Enhancer
(Diff3DE). At the coarse stage, OPP first efficiently inserts the GAN model
into the existing OG-NeRF pipeline for primarily relieving the blurry issue
with in-distribution priors captured from the training dataset, achieving a
good balance between sharpness (LPIPS, FID) and fidelity (PSNR, SSIM). Then, at
the fine stage, Diff3DE further leverages the pre-trained image diffusion
models to complement rich out-distribution details while maintaining decent 3D
consistency. Extensive experiments on both the synthetic and real-world
datasets show that GD$^2$-NeRF noticeably improves the details while without
per-scene finetuning.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00617" title="Abstract">arXiv:2401.00617</a> [<a href="/pdf/2401.00617" title="Download PDF">pdf</a>, <a href="/format/2401.00617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Improved Proxy-based Deep Metric Learning via Data-Augmented  Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+L">Li Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+K">Kien Hua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep Metric Learning (DML) plays an important role in modern computer vision
research, where we learn a distance metric for a set of image representations.
Recent DML techniques utilize the proxy to interact with the corresponding
image samples in the embedding space. However, existing proxy-based DML methods
focus on learning individual proxy-to-sample distance while the overall
distribution of samples and proxies lacks attention. In this paper, we present
a novel proxy-based DML framework that focuses on aligning the sample and proxy
distributions to improve the efficiency of proxy-based DML losses.
Specifically, we propose the Data-Augmented Domain Adaptation (DADA) method to
adapt the domain gap between the group of samples and proxies. To the best of
our knowledge, we are the first to leverage domain adaptation to boost the
performance of proxy-based DML. We show that our method can be easily plugged
into existing proxy-based DML losses. Our experiments on benchmarks, including
the popular CUB-200-2011, CARS196, Stanford Online Products, and In-Shop
Clothes Retrieval, show that our learning algorithm significantly improves the
existing proxy losses and achieves superior results compared to the existing
methods.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00622" title="Abstract">arXiv:2401.00622</a> [<a href="/pdf/2401.00622" title="Download PDF">pdf</a>, <a href="/format/2401.00622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Class-Incremental Learning with New-Class Augmented  Self-Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianliu He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Min Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuefeng Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated Learning (FL) enables collaborative model training among
participants while guaranteeing the privacy of raw data. Mainstream FL
methodologies overlook the dynamic nature of real-world data, particularly its
tendency to grow in volume and diversify in classes over time. This oversight
results in FL methods suffering from catastrophic forgetting, where models
inadvertently discard previously learned information upon assimilating new
data. In response to this challenge, we propose a novel Federated
Class-Incremental Learning (FCIL) method, named FCIL with New-Class Augmented
Self-Distillation (FedNASD). FedNASD combines new class scores, which are
inferred from current models, with historical models' predictions. Based on the
combined past and present knowledge, it incorporates self-distillation over
models on clients, aiming to achieve effective knowledge transfer from
historical models to current models. Theoretical analysis demonstrates that
FedNASD is equivalent to modeling old class scores as conditional probabilities
in the absence of new classes. Additionally, it reconciles the predictions of
new classes with current models to refine the conditional probabilities of
historical scores where new classes do not exist. Empirical experiments
demonstrate the superiority of FedNASD over four baseline algorithms in
reducing the average forgetting rate and boosting global accuracy.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00625" title="Abstract">arXiv:2401.00625</a> [<a href="/pdf/2401.00625" title="Download PDF">pdf</a>, <a href="/ps/2401.00625" title="Download PostScript">ps</a>, <a href="/format/2401.00625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Efficiency: A Systematic Survey of Resource-Efficient Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangji Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+Z">Zheng Chai</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C">Chen Ling</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiaying Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Nan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+T">Tingwei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Ziyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mengdan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yue Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. GitHub repo: <a href="https://github.com/tiingweii-shii/Awesome-Resource-Efficient-LLM-Papers">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The burgeoning field of Large Language Models (LLMs), exemplified by
sophisticated models like OpenAI's ChatGPT, represents a significant
advancement in artificial intelligence. These models, however, bring forth
substantial challenges in the high consumption of computational, memory,
energy, and financial resources, especially in environments with limited
resource capabilities. This survey aims to systematically address these
challenges by reviewing a broad spectrum of techniques designed to enhance the
resource efficiency of LLMs. We categorize methods based on their optimization
focus: computational, memory, energy, financial, and network resources and
their applicability across various stages of an LLM's lifecycle, including
architecture design, pretraining, finetuning, and system design. Additionally,
the survey introduces a nuanced categorization of resource efficiency
techniques by their specific resource types, which uncovers the intricate
relationships and mappings between various resources and corresponding
optimization techniques. A standardized set of evaluation metrics and datasets
is also presented to facilitate consistent and fair comparisons across
different models and techniques. By offering a comprehensive overview of the
current sota and identifying open research avenues, this survey serves as a
foundational reference for researchers and practitioners, aiding them in
developing more sustainable and efficient LLMs in a rapidly evolving landscape.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00629" title="Abstract">arXiv:2401.00629</a> [<a href="/pdf/2401.00629" title="Download PDF">pdf</a>, <a href="/format/2401.00629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarially Trained Actor Critic for offline CMDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Honghao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiyue Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Arnob Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose a Safe Adversarial Trained Actor Critic (SATAC) algorithm for
offline reinforcement learning (RL) with general function approximation in the
presence of limited data coverage. SATAC operates as a two-player Stackelberg
game featuring a refined objective function. The actor (leader player)
optimizes the policy against two adversarially trained value critics (follower
players), who focus on scenarios where the actor's performance is inferior to
the behavior policy. Our framework provides both theoretical guarantees and a
robust deep-RL implementation. Theoretically, we demonstrate that when the
actor employs a no-regret optimization oracle, SATAC achieves two guarantees:
(i) For the first time in the offline RL setting, we establish that SATAC can
produce a policy that outperforms the behavior policy while maintaining the
same level of safety, which is critical to designing an algorithm for offline
RL. (ii) We demonstrate that the algorithm guarantees policy improvement across
a broad range of hyperparameters, indicating its practical robustness.
Additionally, we offer a practical version of SATAC and compare it with
existing state-of-the-art offline safe-RL algorithms in continuous control
environments. SATAC outperforms all baselines across a range of tasks, thus
validating the theoretical performance.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00631" title="Abstract">arXiv:2401.00631</a> [<a href="/pdf/2401.00631" title="Download PDF">pdf</a>, <a href="/format/2401.00631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinated Deep Neural Networks: A Versatile Edge Offloading Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maleki%2C+A">Alireza Maleki</a>, 
<a href="/search/cs?searchtype=author&query=Shah-Mansouri%2C+H">Hamed Shah-Mansouri</a>, 
<a href="/search/cs?searchtype=author&query=Khalaj%2C+B+H">Babak H. Khalaj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">As artificial intelligence (AI) applications continue to expand, there is a
growing need for deep neural network (DNN) models. Although DNN models deployed
at the edge are promising to provide AI as a service with low latency, their
cooperation is yet to be explored. In this paper, we consider the DNN service
providers share their computing resources as well as their models' parameters
and allow other DNNs to offload their computations without mirroring. We
propose a novel algorithm called coordinated DNNs on edge (\textbf{CoDE}) that
facilitates coordination among DNN services by creating multi-task DNNs out of
individual models. CoDE aims to find the optimal path that results in the
lowest possible cost, where the cost reflects the inference delay, model
accuracy, and local computation workload. With CoDE, DNN models can make new
paths for inference by using their own or other models' parameters. We then
evaluate the performance of CoDE through numerical experiments. The results
demonstrate a $75\%$ reduction in the local service computation workload while
degrading the accuracy by only $2\%$ and having the same inference time in a
balanced load condition. Under heavy load, CoDE can further decrease the
inference time by $30\%$ while the accuracy is reduced by only $4\%$.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00632" title="Abstract">arXiv:2401.00632</a> [<a href="/pdf/2401.00632" title="Download PDF">pdf</a>, <a href="/format/2401.00632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TBDD: A New Trust-based, DRL-driven Framework for Blockchain Sharding in  IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zixu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guangsheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Caijun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+W">Wei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R+P">Ren Ping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Reeves%2C+A">Andrew Reeves</a>, 
<a href="/search/cs?searchtype=author&query=Georgalas%2C+N">Nektarios Georgalas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Integrating sharded blockchain with IoT presents a solution for trust issues
and optimized data flow. Sharding boosts blockchain scalability by dividing its
nodes into parallel shards, yet it's vulnerable to the $1\%$ attacks where
dishonest nodes target a shard to corrupt the entire blockchain. Balancing
security with scalability is pivotal for such systems. Deep Reinforcement
Learning (DRL) adeptly handles dynamic, complex systems and multi-dimensional
optimization. This paper introduces a Trust-based and DRL-driven
(\textsc{TbDd}) framework, crafted to counter shard collusion risks and
dynamically adjust node allocation, enhancing throughput while maintaining
network security. With a comprehensive trust evaluation mechanism,
\textsc{TbDd} discerns node types and performs targeted resharding against
potential threats. The model maximizes tolerance for dishonest nodes, optimizes
node movement frequency, ensures even node distribution in shards, and balances
sharding risks. Rigorous evaluations prove \textsc{TbDd}'s superiority over
conventional random-, community-, and trust-based sharding methods in shard
risk equilibrium and reducing cross-shard transactions.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00633" title="Abstract">arXiv:2401.00633</a> [<a href="/pdf/2401.00633" title="Download PDF">pdf</a>, <a href="/format/2401.00633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Discprecncies between Perturbation Evaluations of Graph Neural  Network Attributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+R">Razieh Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=Dizaji%2C+A">Alireza Dizaji</a>, 
<a href="/search/cs?searchtype=author&query=Khakzar%2C+A">Ashkan Khakzar</a>, 
<a href="/search/cs?searchtype=author&query=Kazi%2C+A">Anees Kazi</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Neural networks are increasingly finding their way into the realm of graphs
and modeling relationships between features. Concurrently graph neural network
explanation approaches are being invented to uncover relationships between the
nodes of the graphs. However, there is a disparity between the existing
attribution methods, and it is unclear which attribution to trust. Therefore
research has introduced evaluation experiments that assess them from different
perspectives. In this work, we assess attribution methods from a perspective
not previously explored in the graph domain: retraining. The core idea is to
retrain the network on important (or not important) relationships as identified
by the attributions and evaluate how networks can generalize based on these
relationships. We reformulate the retraining framework to sidestep issues
lurking in the previous formulation and propose guidelines for correct
analysis. We run our analysis on four state-of-the-art GNN attribution methods
and five synthetic and real-world graph classification datasets. The analysis
reveals that attributions perform variably depending on the dataset and the
network. Most importantly, we observe that the famous GNNExplainer performs
similarly to an arbitrary designation of edge importance. The study concludes
that the retraining evaluation cannot be used as a generalized benchmark and
recommends it as a toolset to evaluate attributions on a specifically addressed
network, dataset, and sparsity.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00637" title="Abstract">arXiv:2401.00637</a> [<a href="/pdf/2401.00637" title="Download PDF">pdf</a>, <a href="/ps/2401.00637" title="Download PostScript">ps</a>, <a href="/format/2401.00637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear vibration of a dipteran flight robot system with rotational  geometric nonlinearity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yanwei Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 24 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">The dipteran flight mechanism of the insects is commonly used to design the
nonlinear flight robot system. However, the dynamic response of the click
mechanism of the nonlinear robot system with multiple stability still unclear.
In this paper, a novel dipteran robot model with click mechanism proposed based
on the multiple stability of snap-through buckling. The motion of equation of
the nonlinear flight robot system is obtained by using the Euler-Lagrange
equation. The nonlinear potential energy, the elastic force, equilibrium
bifurcation, as well as equilibrium stability are investigated to show the
multiple stability characteristics. The transient sets of bifurcation and
persistent set of regions in the system parameter plane and the corresponding
phase portraits are obtained with multiple stability of single and double well
behaviors. Then, the periodic free vibration response are defined by the
analytical solution of three kinds of elliptical functions, as well as the
amplitude frequency responses are investigated by numerical integration. Based
on the topological equivalent method, the chaotic thresholds of the homo-clinic
orbits for the chaotic vibration of harmonic forced robot system are derived to
show the chaotic parametric condition. Finally, the prototype of nonlinear
flapping robot is manufactured and the experimental system is setup. The
nonlinear static moment of force curves, periodic response and dynamic flight
vibration of dipteran robot system are carried out. It is shown that the test
results are agree well with the theoretical analysis and numerical simulation.
Those result have the potential application for the structure design of the
efficient flight robot.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00639" title="Abstract">arXiv:2401.00639</a> [<a href="/pdf/2401.00639" title="Download PDF">pdf</a>, <a href="/format/2401.00639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry Depth Consistency in RGBD Relative Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sourav Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Chien%2C+C">Chiang-Heng Chien</a>, 
<a href="/search/cs?searchtype=author&query=Kimia%2C+B">Benjamin Kimia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Relative pose estimation for RGBD cameras is crucial in a number of
applications. Previous approaches either rely on the RGB aspect of the images
to estimate pose thus not fully making use of depth in the estimation process
or estimate pose from the 3D cloud of points that each image produces, thus not
making full use of RGB information. This paper shows that if one pair of
correspondences is hypothesized from the RGB-based ranked-ordered
correspondence list, then the space of remaining correspondences is restricted
to corresponding pairs of curves nested around the hypothesized correspondence,
implicitly capturing depth consistency. This simple Geometric Depth Constraint
(GDC) significantly reduces potential matches. In effect this becomes a filter
on possible correspondences that helps reduce the number of outliers and thus
expedites RANSAC significantly. As such, the same budget of time allows for
more RANSAC iterations and therefore additional robustness and a significant
speedup. In addition, the paper proposed a Nested RANSAC approach that also
speeds up the process, as shown through experiments on TUM, ICL-NUIM, and RGBD
Scenes v2 datasets.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00642" title="Abstract">arXiv:2401.00642</a> [<a href="/pdf/2401.00642" title="Download PDF">pdf</a>, <a href="/format/2401.00642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Anti-microbial Resistance using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoo%2C+H">Hyunwoo Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Sokhansanj%2C+B">Bahrad Sokhansanj</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+J+R">James R. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Rosen%2C+G">Gail Rosen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">During times of increasing antibiotic resistance and the spread of infectious
diseases like COVID-19, it is important to classify genes related to antibiotic
resistance. As natural language processing has advanced with transformer-based
language models, many language models that learn characteristics of nucleotide
sequences have also emerged. These models show good performance in classifying
various features of nucleotide sequences. When classifying nucleotide
sequences, not only the sequence itself, but also various background knowledge
is utilized. In this study, we use not only a nucleotide sequence-based
language model but also a text language model based on PubMed articles to
reflect more biological background knowledge in the model. We propose a method
to fine-tune the nucleotide sequence language model and the text language model
based on various databases of antibiotic resistance genes. We also propose an
LLM-based augmentation technique to supplement the data and an ensemble method
to effectively combine the two models. We also propose a benchmark for
evaluating the model. Our method achieved better performance than the
nucleotide sequence language model in the drug resistance class prediction.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00644" title="Abstract">arXiv:2401.00644</a> [<a href="/pdf/2401.00644" title="Download PDF">pdf</a>, <a href="/format/2401.00644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEWP: Deep Expansion Learning for Wind Power Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanjie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuanchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TKDD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Wind is one kind of high-efficient, environmentally-friendly and
cost-effective energy source. Wind power, as one of the largest renewable
energy in the world, has been playing a more and more important role in
supplying electricity. Though growing dramatically in recent years, the amount
of generated wind power can be directly or latently affected by multiple
uncertain factors, such as wind speed, wind direction, temperatures, etc. More
importantly, there exist very complicated dependencies of the generated power
on the latent composition of these multiple time-evolving variables, which are
always ignored by existing works and thus largely hinder the prediction
performances. To this end, we propose DEWP, a novel Deep Expansion learning for
Wind Power forecasting framework to carefully model the complicated
dependencies with adequate expressiveness. DEWP starts with a stack-by-stack
architecture, where each stack is composed of (i) a variable expansion block
that makes use of convolutional layers to capture dependencies among multiple
variables; (ii) a time expansion block that applies Fourier series and
backcast/forecast mechanism to learn temporal dependencies in sequential
patterns. These two tailored blocks expand raw inputs into different latent
feature spaces which can model different levels of dependencies of
time-evolving sequential data. Moreover, we propose an inference block
corresponding for each stack, which applies multi-head self-attentions to
acquire attentive features and maps expanded latent representations into
generated wind power. In addition, to make DEWP more expressive in handling
deep neural architectures, we adapt doubly residue learning to process
stack-by-stack outputs. Finally, we present extensive experiments in the
real-world wind power forecasting application on two datasets from two
different turbines to demonstrate the effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00650" title="Abstract">arXiv:2401.00650</a> [<a href="/pdf/2401.00650" title="Download PDF">pdf</a>, <a href="/format/2401.00650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Invariant Generation for Solidity Smart Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chengxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li.%2C+Y">Yi Li.</a> (Nanyang Technological University, Singapore)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Smart contracts are computer programs running on blockchains to automate the
transaction execution between users. The absence of contract specifications
poses a real challenge to the correctness verification of smart contracts.
Program invariants are properties that are always preserved throughout the
execution, which characterize an important aspect of the program behaviors. In
this paper, we propose a novel invariant generation framework, INVCON+, for
Solidity smart contracts. INVCON+ extends the existing invariant detector,
InvCon, to automatically produce verified contract invariants based on both
dynamic inference and static verification. Unlike INVCON+, InvCon only produces
likely invariants, which have a high probability to hold, yet are still not
verified against the contract code. Particularly, INVCON+ is able to infer more
expressive invariants that capture richer semantic relations of contract code.
We evaluate INVCON+ on 361 ERC20 and 10 ERC721 real-world contracts, as well as
common ERC20 vulnerability benchmarks. The experimental results indicate that
INVCON+ efficiently produces high-quality invariant specifications, which can
be used to secure smart contracts from common vulnerabilities.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00651" title="Abstract">arXiv:2401.00651</a> [<a href="/pdf/2401.00651" title="Download PDF">pdf</a>, <a href="/format/2401.00651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRWE: Inductive Random Walk for Joint Inference of Identity and Position  Network Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+M">Meng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+D">Dit-Yan Yeung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Network embedding, which maps graphs to distributed representations, is a
unified framework for various graph inference tasks. According to the topology
properties (e.g., structural roles and community memberships of nodes) to be
preserved, it can be categorized into the identity and position embedding.
However, existing methods can only capture one type of property. Some
approaches can support the inductive inference that generalizes the embedding
model to new nodes or graphs but relies on the availability of attributes. Due
to the complicated correlations between topology and attributes, it is unclear
for some inductive methods which type of property they can capture. In this
study, we explore a unified framework for the joint inductive inference of
identity and position embeddings without attributes. An inductive random walk
embedding (IRWE) method is proposed, which combines multiple attention units to
handle the random walk on graph topology and simultaneously derives identity
and position embeddings that are jointly optimized. In particular, we
demonstrate that some random walk statistics can be informative features to
characterize node identities and positions while supporting the inductive
embedding inference. Experiments validate the superior performance of IRWE
beyond various baselines for the transductive and inductive inference of
identity and position embeddings.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00652" title="Abstract">arXiv:2401.00652</a> [<a href="/pdf/2401.00652" title="Download PDF">pdf</a>, <a href="/format/2401.00652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Covert Hiding to Visual Editing: Robust Generative Video  Steganography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xueying Mao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaoxiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wanli Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhenliang Gan</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+Q">Qichao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhenxing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinpeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traditional video steganography methods are based on modifying the covert
space for embedding, whereas we propose an innovative approach that embeds
secret message within semantic feature for steganography during the video
editing process. Although existing traditional video steganography methods
display a certain level of security and embedding capacity, they lack adequate
robustness against common distortions in online social networks (OSNs). In this
paper, we introduce an end-to-end robust generative video steganography network
(RoGVS), which achieves visual editing by modifying semantic feature of videos
to embed secret message. We employ face-swapping scenario to showcase the
visual editing effects. We first design a secret message embedding module to
adaptively hide secret message into the semantic feature of videos. Extensive
experiments display that the proposed RoGVS method applied to facial video
datasets demonstrate its superiority over existing video and image
steganography techniques in terms of both robustness and capacity.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00653" title="Abstract">arXiv:2401.00653</a> [<a href="/pdf/2401.00653" title="Download PDF">pdf</a>, <a href="/format/2401.00653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROMPT-IML: Image Manipulation Localization with Pre-trained Foundation  Models Through Prompt Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuntao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuzhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+Q">Qichao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhenxing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deceptive images can be shared in seconds with social networking services,
posing substantial risks. Tampering traces, such as boundary artifacts and
high-frequency information, have been significantly emphasized by massive
networks in the Image Manipulation Localization (IML) field. However, they are
prone to image post-processing operations, which limit the generalization and
robustness of existing methods. We present a novel Prompt-IML framework. We
observe that humans tend to discern the authenticity of an image based on both
semantic and high-frequency information, inspired by which, the proposed
framework leverages rich semantic knowledge from pre-trained visual foundation
models to assist IML. We are the first to design a framework that utilizes
visual foundation models specially for the IML task. Moreover, we design a
Feature Alignment and Fusion module to align and fuse features of semantic
features with high-frequency features, which aims at locating tampered regions
from multiple perspectives. Experimental results demonstrate that our model can
achieve better performance on eight typical fake image datasets and outstanding
robustness.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00656" title="Abstract">arXiv:2401.00656</a> [<a href="/pdf/2401.00656" title="Download PDF">pdf</a>, <a href="/format/2401.00656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable iterative data-adaptive RKHS regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+H">Haibo Li</a>, 
<a href="/search/math?searchtype=author&query=Feng%2C+J">Jinchao Feng</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+F">Fei Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present iDARR, a scalable iterative Data-Adaptive RKHS Regularization
method, for solving ill-posed linear inverse problems. The method searches for
solutions in subspaces where the true solution can be identified, with the
data-adaptive RKHS penalizing the spaces of small singular values. At the core
of the method is a new generalized Golub-Kahan bidiagonalization procedure that
recursively constructs orthonormal bases for a sequence of RKHS-restricted
Krylov subspaces. The method is scalable with a complexity of $O(kmn)$ for
$m$-by-$n$ matrices with $k$ denoting the iteration numbers. Numerical tests on
the Fredholm integral equation and 2D image deblurring show that it outperforms
the widely used $L^2$ and $l^2$ norms, producing stable accurate solutions
consistently converging when the noise level decays.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00658" title="Abstract">arXiv:2401.00658</a> [<a href="/pdf/2401.00658" title="Download PDF">pdf</a>, <a href="/format/2401.00658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Cloud in the Air
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yulin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+C">Chenghong Bian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Li Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qianqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gunduz%2C+D">Deniz Gunduz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Signal Processing (eess.SP)

</div>
<p class="mathjax">Acquisition and processing of point clouds (PCs) is a crucial enabler for
many emerging applications reliant on 3D spatial data, such as robot
navigation, autonomous vehicles, and augmented reality. In most scenarios, PCs
acquired by remote sensors must be transmitted to an edge server for fusion,
segmentation, or inference. Wireless transmission of PCs not only puts on
increased burden on the already congested wireless spectrum, but also confronts
a unique set of challenges arising from the irregular and unstructured nature
of PCs. In this paper, we meticulously delineate these challenges and offer a
comprehensive examination of existing solutions while candidly acknowledging
their inherent limitations. In response to these intricacies, we proffer four
pragmatic solution frameworks, spanning advanced techniques, hybrid schemes,
and distributed data aggregation approaches. In doing so, our goal is to chart
a path toward efficient, reliable, and low-latency wireless PC transmission.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00659" title="Abstract">arXiv:2401.00659</a> [<a href="/pdf/2401.00659" title="Download PDF">pdf</a>, <a href="/ps/2401.00659" title="Download PostScript">ps</a>, <a href="/format/2401.00659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advanced Dataset Discovery: When Multi-Query-Dataset Cardinality  Estimation Matters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tingting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shixun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Z">Zhifeng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Culpepper%2C+J+S">J. Shane Culpepper</a>, 
<a href="/search/cs?searchtype=author&query=Arablouei%2C+R">Reza Arablouei</a>, 
<a href="/search/cs?searchtype=author&query=Dedeoglu%2C+V">Volkan Dedeoglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">As available data increases, so too does the demand to dataset discovery.
Existing studies often yield coarse-grained results where significant
information overlaps and non-relevant data occur. They also implicitly assume
that a user can purchase all datasets found, which is rarely true in practice.
Therefore, achieving dataset discovery results with less redundancy using
fine-grained information needs and a budget is desirable. To achieve this, we
study the problem of finding a set of datasets that maximize distinctiveness
based on a user's fine-grained information needs and a base dataset while
keeping the total price of the datasets within a budget. The user's
fine-grained information needs are expressed as a query set and the
distinctiveness for a set of datasets, which is the number of distinct tuples
produced by the query set on the datasets which do not overlap with the base
dataset. First, we prove the NP-hardness of this problem. Then, we develop a
greedy algorithm that achieves an approximation of (1-e^{-1})/2. But this
algorithm is neither efficient nor scalable as it frequently computes the exact
distinctiveness during dataset selection, which requires every tuple for the
query result overlap in multiple datasets to be tested. To this end, we propose
an efficient and effective machine-learning-based (ML-based) algorithm to
estimate the distinctiveness for a set of datasets, without the need for
testing every tuple. The proposed algorithm is the first to support cardinality
estimation (CE) for a query set on multiple datasets, as previous studies only
support CE for a single query on a single dataset, and cannot effectively
identify query result overlaps in multiple datasets. Extensive experiments
using five real-world data pools demonstrate that our greedy algorithm using
ML-based distinctiveness estimation outperforms all other baselines in both
effectiveness and efficiency.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00661" title="Abstract">arXiv:2401.00661</a> [<a href="/pdf/2401.00661" title="Download PDF">pdf</a>, <a href="/ps/2401.00661" title="Download PostScript">ps</a>, <a href="/format/2401.00661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Dynamic Pricing Policy for Electric Vehicles: Reinforcement  learning approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bae%2C+S">Sangjun Bae</a>, 
<a href="/search/eess?searchtype=author&query=Kulcsar%2C+B">Balazs Kulcsar</a>, 
<a href="/search/eess?searchtype=author&query=Gros%2C+S">Sebastien Gros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">With the increasing number of fast-electric vehicle charging stations
(fast-EVCSs) and the popularization of information technology, electricity
price competition between fast-EVCSs is highly expected, in which the
utilization of public and/or privacy-preserved information will play a crucial
role. Self-interest electric vehicle (EV) users, on the other hand, try to
select a fast-EVCS for charging in a way to maximize their utilities based on
electricity price, estimated waiting time, and their state of charge. While
existing studies have largely focused on finding equilibrium prices, this study
proposes a personalized dynamic pricing policy (PeDP) for a fast-EVCS to
maximize revenue using a reinforcement learning (RL) approach. We first propose
a multiple fast-EVCSs competing simulation environment to model the selfish
behavior of EV users using a game-based charging station selection model with a
monetary utility function. In the environment, we propose a Q-learning-based
PeDP to maximize fast-EVCS' revenue. Through numerical simulations based on the
environment: (1) we identify the importance of waiting time in the EV charging
market by comparing the classic Bertrand competition model with the proposed
PeDP for fast-EVCSs (from the system perspective); (2) we evaluate the
performance of the proposed PeDP and analyze the effects of the information on
the policy (from the service provider perspective); and (3) it can be seen that
privacy-preserved information sharing can be misused by artificial
intelligence-based PeDP in a certain situation in the EV charging market (from
the customer perspective).
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00662" title="Abstract">arXiv:2401.00662</a> [<a href="/pdf/2401.00662" title="Download PDF">pdf</a>, <a href="/format/2401.00662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Pre-trained ASR System Fine-tuning for Dysarthric Speech  Recognition using Adversarial Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huimeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zengrui Jin</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+M">Mengzhe Geng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shujie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guinan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianzi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haoning Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xunying Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automatic recognition of dysarthric speech remains a highly challenging task
to date. Neuro-motor conditions and co-occurring physical disabilities create
difficulty in large-scale data collection for ASR system development. Adapting
SSL pre-trained ASR models to limited dysarthric speech via data-intensive
parameter fine-tuning leads to poor generalization. To this end, this paper
presents an extensive comparative study of various data augmentation approaches
to improve the robustness of pre-trained ASR model fine-tuning to dysarthric
speech. These include: a) conventional speaker-independent perturbation of
impaired speech; b) speaker-dependent speed perturbation, or GAN-based
adversarial perturbation of normal, control speech based on their time
alignment against parallel dysarthric speech; c) novel Spectral basis GAN-based
adversarial data augmentation operating on non-parallel data. Experiments
conducted on the UASpeech corpus suggest GAN-based data augmentation
consistently outperforms fine-tuned Wav2vec2.0 and HuBERT models using no data
augmentation and speed perturbation across different data expansion operating
points by statistically significant word error rate (WER) reductions up to
2.01% and 0.96% absolute (9.03% and 4.63% relative) respectively on the
UASpeech test set of 16 dysarthric speakers. After cross-system outputs
rescoring, the best system produced the lowest published WER of 16.53% (46.47%
on very low intelligibility) on UASpeech.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00663" title="Abstract">arXiv:2401.00663</a> [<a href="/pdf/2401.00663" title="Download PDF">pdf</a>, <a href="/format/2401.00663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 1st Place Solution for 5th LSVOS Challenge: Referring Video Object  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhuoyan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yicheng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent transformer-based models have dominated the Referring Video Object
Segmentation (RVOS) task due to the superior performance. Most prior works
adopt unified DETR framework to generate segmentation masks in
query-to-instance manner. In this work, we integrate strengths of that leading
RVOS models to build up an effective paradigm. We first obtain binary mask
sequences from the RVOS models. To improve the consistency and quality of
masks, we propose Two-Stage Multi-Model Fusion strategy. Each stage rationally
ensembles RVOS models based on framework design as well as training strategy,
and leverages different video object segmentation (VOS) models to enhance mask
coherence by object propagation mechanism. Our method achieves 75.7% J&amp;F on
Ref-Youtube-VOS validation set and 70% J&amp;F on test set, which ranks 1st place
on 5th Large-scale Video Object Segmentation Challenge (ICCV 2023) track 3.
Code is available at https://github.com/RobertLuo1/iccv2023_RVOS_Challenge.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00670" title="Abstract">arXiv:2401.00670</a> [<a href="/pdf/2401.00670" title="Download PDF">pdf</a>, <a href="/format/2401.00670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid physics-informed metabolic cybergenetics: process rates augmented  with machine-learning surrogates informed by flux balance analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Espinel-R%C3%ADos%2C+S">Sebasti&#xe1;n Espinel-R&#xed;os</a>, 
<a href="/search/eess?searchtype=author&query=Avalos%2C+J+L">Jos&#xe9; L. Avalos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 10 figures, journal submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Metabolic cybergenetics is a promising concept that interfaces gene
expression and cellular metabolism with computers for real-time dynamic
metabolic control. The focus is on control at the transcriptional level,
serving as a means to modulate intracellular metabolic fluxes. Recent
strategies in this field have employed constraint-based dynamic models for
process optimization, control, and estimation. However, this results in bilevel
dynamic optimization problems, which pose considerable numerical and conceptual
challenges. In this study, we present an alternative hybrid physics-informed
dynamic modeling framework for metabolic cybergenetics, aimed at simplifying
optimization, control, and estimation tasks. By utilizing machine-learning
surrogates, our approach effectively embeds the physics of metabolic networks
into the process rates of structurally simpler macro-kinetic models coupled
with gene expression. These surrogates, informed by flux balance analysis, link
the domains of manipulatable intracellular enzymes to metabolic exchange
fluxes. This ensures that critical knowledge captured by the system's metabolic
network is preserved. The resulting models can be integrated into metabolic
cybergenetic schemes involving single-level optimizations. Additionally, the
hybrid modeling approach maintains the number of system states at a necessary
minimum, easing the burden of process monitoring and estimation. Our hybrid
physics-informed metabolic cybergenetic framework is demonstrated using a
computational case study on the optogenetically-assisted production of
itaconate by $\textit{Escherichia coli}$.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00672" title="Abstract">arXiv:2401.00672</a> [<a href="/pdf/2401.00672" title="Download PDF">pdf</a>, <a href="/format/2401.00672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthogonal Blocking Kaczmarz Algorithm Based on Preprocessing Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liang%2C+Y">Yu-Fang Liang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Hou-Biao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 10 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we propose an orthogonal block wise Kaczmarz (POBK) algorithm
based on preprocessing techniques to solve large-scale sparse linear systems
$Ax=f$. Firstly, the Reverse Cuthill McKee Algorithm (RCM) algorithm is used to
preprocess the linear system, and then a new partitioning strategy is proposed
to divide orthogonal blocks into one category, in order to accelerate the
convergence rate of the Kaczmarz algorithm. The convergence of the POBK
algorithm has been theoretically proven, and a theoretical analysis of its
faster convergence is also provided. In addition, the experimental results
confirm that this algorithm is far superior to GRBK, RBK(k), and GREBK(k)
algorithms in both iteration steps (IT) and CPU time aspects.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00676" title="Abstract">arXiv:2401.00676</a> [<a href="/pdf/2401.00676" title="Download PDF">pdf</a>, <a href="/format/2401.00676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digger: Detecting Copyright Content Mis-usage in Large Language Model  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haodong Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+G">Gelei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kailong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuekang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guoai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guosheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pre-training, which utilizes extensive and varied datasets, is a critical
factor in the success of Large Language Models (LLMs) across numerous
applications. However, the detailed makeup of these datasets is often not
disclosed, leading to concerns about data security and potential misuse. This
is particularly relevant when copyrighted material, still under legal
protection, is used inappropriately, either intentionally or unintentionally,
infringing on the rights of the authors.
<br />In this paper, we introduce a detailed framework designed to detect and
assess the presence of content from potentially copyrighted books within the
training datasets of LLMs. This framework also provides a confidence estimation
for the likelihood of each content sample's inclusion. To validate our
approach, we conduct a series of simulated experiments, the results of which
affirm the framework's effectiveness in identifying and addressing instances of
content misuse in LLM training processes. Furthermore, we investigate the
presence of recognizable quotes from famous literary works within these
datasets. The outcomes of our study have significant implications for ensuring
the ethical use of copyrighted materials in the development of LLMs,
highlighting the need for more transparent and responsible data management
practices in this field.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00678" title="Abstract">arXiv:2401.00678</a> [<a href="/pdf/2401.00678" title="Download PDF">pdf</a>, <a href="/format/2401.00678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General-purpose foundation models for increased autonomy in  robot-assisted surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidgall%2C+S">Samuel Schmidgall</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+W">Ji Woong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kuntz%2C+A">Alan Kuntz</a>, 
<a href="/search/cs?searchtype=author&query=Ghazi%2C+A+E">Ahmed Ezzat Ghazi</a>, 
<a href="/search/cs?searchtype=author&query=Krieger%2C+A">Axel Krieger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">The dominant paradigm for end-to-end robot learning focuses on optimizing
task-specific objectives that solve a single robotic problem such as picking up
an object or reaching a target position. However, recent work on high-capacity
models in robotics has shown promise toward being trained on large collections
of diverse and task-agnostic datasets of video demonstrations. These models
have shown impressive levels of generalization to unseen circumstances,
especially as the amount of data and the model complexity scale. Surgical robot
systems that learn from data have struggled to advance as quickly as other
fields of robot learning for a few reasons: (1) there is a lack of existing
large-scale open-source data to train models, (2) it is challenging to model
the soft-body deformations that these robots work with during surgery because
simulation cannot match the physical and visual complexity of biological
tissue, and (3) surgical robots risk harming patients when tested in clinical
trials and require more extensive safety measures. This perspective article
aims to provide a path toward increasing robot autonomy in robot-assisted
surgery through the development of a multi-modal, multi-task,
vision-language-action model for surgical robots. Ultimately, we argue that
surgical robots are uniquely positioned to benefit from general-purpose models
and provide three guiding actions toward increased autonomy in robot-assisted
surgery.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00681" title="Abstract">arXiv:2401.00681</a> [<a href="/pdf/2401.00681" title="Download PDF">pdf</a>, <a href="/ps/2401.00681" title="Download PostScript">ps</a>, <a href="/format/2401.00681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Procrastination in Crowdsourcing Via Efficient Scheduling  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Debnath%2C+N">Naren Debnath</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+S">Sajal Mukhopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Xhafa%2C+F">Fatos Xhafa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Several works related to crowdsourcing have been proposed in the direction
where the task executors are to perform the tasks within the stipulated
deadlines. Though the deadlines are set, it may be a practical scenario that
majority of the task executors submit the tasks as late as possible. This
situation where the task executors may delay their task submission is termed as
procrastination in behavioural economics. In many applications, these late
submission of tasks may be problematic for task requesters. In literature, how
to prevent this procrastination within the deadline is not addressed in
crowdsourcing scenario. However, in a bipartite graph setting one
procrastination aware scheduling is proposed but balanced job distribution in
different slots (also termed as schedules) is not considered there. In this
paper, a procrastination aware scheduling of jobs is proliferated by proposing
an (randomized) algorithm in crowdsourcing scenario (also applicable in mobile
and spatial crowdsourcing). Our algorithm ensures that balancing of jobs in
different schedules are maintained. Our scheme is compared with the existing
algorithm through extensive simulation and in terms of balancing effect, our
proposed algorithm outperforms the existing one. Analytically it is shown that
our proposed algorithm maintains the balanced distribution.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00683" title="Abstract">arXiv:2401.00683</a> [<a href="/pdf/2401.00683" title="Download PDF">pdf</a>, <a href="/ps/2401.00683" title="Download PostScript">ps</a>, <a href="/format/2401.00683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotically Optimal Sequence Sets With Low/Zero Ambiguity Zone  Properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Liying Tian</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiaoshi Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yubo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Sequences with low/zero ambiguity zone (LAZ/ZAZ) properties are useful for
modern wireless communication and radar systems operating in mobile
environments. This paper first presents a new family of ZAZ sequence sets by
generalizing an earlier construction of zero correlation zone (ZCZ) sequences
arising from perfect nonlinear functions. We then introduce a second family of
ZAZ sequence sets with comb-like spectrum, whereby the local Doppler resilience
is ensured by their inherent spectral nulls in the frequency-domain. Finally,
LAZ sequence sets are obtained thanks to its connection with a novel class of
mapping functions. These proposed unimodular ZAZ and LAZ sets are cyclically
distinct and asymptotically optimal with respect to the existing theoretical
bounds.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00685" title="Abstract">arXiv:2401.00685</a> [<a href="/pdf/2401.00685" title="Download PDF">pdf</a>, <a href="/format/2401.00685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Federated Learning for LEO Constellations  Integrated with HAPs Using Hybrid NOMA-OFDM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elmahallawy%2C+M">Mohamed Elmahallawy</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ramadan%2C+K">Khaled Ramadan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Space AI has become increasingly important and sometimes even necessary for
government, businesses, and society. An active research topic under this
mission is integrating federated learning (FL) with satellite communications
(SatCom) so that numerous low Earth orbit (LEO) satellites can collaboratively
train a machine learning model. However, the special communication environment
of SatCom leads to a very slow FL training process up to days and weeks. This
paper proposes NomaFedHAP, a novel FL-SatCom approach tailored to LEO
satellites, that (1) utilizes high-altitude platforms (HAPs) as distributed
parameter servers (PS) to enhance satellite visibility, and (2) introduces
non-orthogonal multiple access (NOMA) into LEO to enable fast and
bandwidth-efficient model transmissions. In addition, NomaFedHAP includes (3) a
new communication topology that exploits HAPs to bridge satellites among
different orbits to mitigate the Doppler shift, and (4) a new FL model
aggregation scheme that optimally balances models between different orbits and
shells. Moreover, we (5) derive a closed-form expression of the outage
probability for satellites in near and far shells, as well as for the entire
system. Our extensive simulations have validated the mathematical analysis and
demonstrated the superior performance of NomaFedHAP in achieving fast and
efficient FL model convergence with high accuracy as compared to the
state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00688" title="Abstract">arXiv:2401.00688</a> [<a href="/pdf/2401.00688" title="Download PDF">pdf</a>, <a href="/format/2401.00688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring community structure in attributed hypergraphs using stochastic  block models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakajima%2C+K">Kazuki Nakajima</a>, 
<a href="/search/cs?searchtype=author&query=Uno%2C+T">Takeaki Uno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 11 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hypergraphs are a representation of complex systems involving interactions
among more than two entities and allow to investigation of higher-order
structure and dynamics in real-world complex systems. Community structure is a
common property observed in empirical networks in various domains. Stochastic
block models have been employed to investigate community structure in networks.
Node attribute data, often accompanying network data, has been found to
potentially enhance the learning of community structure in dyadic networks. In
this study, we develop a statistical framework that incorporates node attribute
data into the learning of community structure in a hypergraph, employing a
stochastic block model. We demonstrate that our model, which we refer to as
HyperNEO, enhances the learning of community structure in synthetic and
empirical hypergraphs when node attributes are sufficiently associated with the
communities. Furthermore, we found that applying a dimensionality reduction
method, UMAP, to the learned representations obtained using stochastic block
models, including our model, maps nodes into a two-dimensional vector space
while largely preserving community structure in empirical hypergraphs. We
expect that our framework will broaden the investigation and understanding of
higher-order community structure in real-world complex systems.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00689" title="Abstract">arXiv:2401.00689</a> [<a href="/pdf/2401.00689" title="Download PDF">pdf</a>, <a href="/format/2401.00689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large language model for Bible sentiment analysis: Sermon on the Mount
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vora%2C+M">Mahek Vora</a>, 
<a href="/search/cs?searchtype=author&query=Blau%2C+T">Tom Blau</a>, 
<a href="/search/cs?searchtype=author&query=Kachhwal%2C+V">Vansh Kachhwal</a>, 
<a href="/search/cs?searchtype=author&query=Solo%2C+A+M+G">Ashu M. G. Solo</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+R">Rohitash Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The revolution of natural language processing via large language models has
motivated its use in multidisciplinary areas that include social sciences and
humanities and more specifically, comparative religion. Sentiment analysis
provides a mechanism to study the emotions expressed in text. Recently,
sentiment analysis has been used to study and compare translations of the
Bhagavad Gita, which is a fundamental and sacred Hindu text. In this study, we
use sentiment analysis for studying selected chapters of the Bible. These
chapters are known as the Sermon on the Mount. We utilize a pre-trained
language model for sentiment analysis by reviewing five translations of the
Sermon on the Mount, which include the King James version, the New
International Version, the New Revised Standard Version, the Lamsa Version, and
the Basic English Version. We provide a chapter-by-chapter and verse-by-verse
comparison using sentiment and semantic analysis and review the major
sentiments expressed. Our results highlight the varying sentiments across the
chapters and verses. We found that the vocabulary of the respective
translations is significantly different. We detected different levels of
humour, optimism, and empathy in the respective chapters that were used by
Jesus to deliver his message.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00690" title="Abstract">arXiv:2401.00690</a> [<a href="/pdf/2401.00690" title="Download PDF">pdf</a>, <a href="/format/2401.00690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Large Language Models on Controllable Generation under  Diversified Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Benfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Quan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhendong Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While large language models (LLMs) have exhibited impressive
instruction-following capabilities, it is still unclear whether and to what
extent they can respond to explicit constraints that might be entailed in
various instructions. As a significant aspect of LLM alignment, it is thus
important to formulate such a specialized set of instructions as well as
investigate the resulting behavior of LLMs. To address this vacancy, we propose
a new benchmark CoDI-Eval to systematically and comprehensively evaluate LLMs'
responses to instructions with various constraints. We construct a large
collection of constraints-attributed instructions as a test suite focused on
both generalization and coverage. Specifically, we advocate an instruction
diversification process to synthesize diverse forms of constraint expression
and also deliberate the candidate task taxonomy with even finer-grained
sub-categories. Finally, we automate the entire evaluation process to
facilitate further developments. Different from existing studies on
controllable text generation, CoDI-Eval extends the scope to the prevalent
instruction-following paradigm for the first time. We provide extensive
evaluations of representative LLMs (e.g., ChatGPT, Vicuna) on CoDI-Eval,
revealing their limitations in following instructions with specific constraints
and there is still a significant gap between open-source and commercial
closed-source LLMs. We believe this benchmark will facilitate research into
improving the controllability of LLMs' responses to instructions. Our data and
code are available at https://github.com/Xt-cyh/CoDI-Eval.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00695" title="Abstract">arXiv:2401.00695</a> [<a href="/pdf/2401.00695" title="Download PDF">pdf</a>, <a href="/format/2401.00695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Credible Teacher for Semi-Supervised Object Detection in Open Scene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Jingyu Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accpet by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-Supervised Object Detection (SSOD) has achieved resounding success by
leveraging unlabeled data to improve detection performance. However, in Open
Scene Semi-Supervised Object Detection (O-SSOD), unlabeled data may contains
unknown objects not observed in the labeled data, which will increase
uncertainty in the model's predictions for known objects. It is detrimental to
the current methods that mainly rely on self-training, as more uncertainty
leads to the lower localization and classification precision of pseudo labels.
To this end, we propose Credible Teacher, an end-to-end framework. Credible
Teacher adopts an interactive teaching mechanism using flexible labels to
prevent uncertain pseudo labels from misleading the model and gradually reduces
its uncertainty through the guidance of other credible pseudo labels. Empirical
results have demonstrated our method effectively restrains the adverse effect
caused by O-SSOD and significantly outperforms existing counterparts.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00698" title="Abstract">arXiv:2401.00698</a> [<a href="/pdf/2401.00698" title="Download PDF">pdf</a>, <a href="/ps/2401.00698" title="Download PostScript">ps</a>, <a href="/format/2401.00698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models aren&#x27;t all that you need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holla%2C+K+V">Kiran Voderhobli Holla</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+C">Chaithanya Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Aryan Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper describes the architecture and systems built towards solving the
SemEval 2023 Task 2: MultiCoNER II (Multilingual Complex Named Entity
Recognition) [1]. We evaluate two approaches (a) a traditional Conditional
Random Fields model and (b) a Large Language Model (LLM) fine-tuned with a
customized head and compare the two approaches. The novel ideas explored are:
1) Decaying auxiliary loss (with residual) - where we train the model on an
auxiliary task of Coarse-Grained NER and include this task as a part of the
loss function 2) Triplet token blending - where we explore ways of blending the
embeddings of neighboring tokens in the final NER layer prior to prediction 3)
Task-optimal heads - where we explore a variety of custom heads and learning
rates for the final layer of the LLM. We also explore multiple LLMs including
GPT-3 and experiment with a variety of dropout and other hyperparameter
settings before arriving at our final model which achieves micro &amp; macro f1 of
0.85/0.84 (on dev) and 0.67/0.61 on the test data . We show that while
pre-trained LLMs, by themselves, bring about a large improvement in scores as
compared to traditional models, we also demonstrate that tangible improvements
to the Macro-F1 score can be made by augmenting the LLM with additional
feature/loss/model engineering techniques described above.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00700" title="Abstract">arXiv:2401.00700</a> [<a href="/pdf/2401.00700" title="Download PDF">pdf</a>, <a href="/ps/2401.00700" title="Download PostScript">ps</a>, <a href="/format/2401.00700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An attempt to generate new bridge types from latent space of generative  adversarial network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Try to generate new bridge types using generative artificial intelligence
technology. Symmetric structured image dataset of three-span beam bridge, arch
bridge, cable-stayed bridge and suspension bridge are used . Based on Python
programming language, TensorFlow and Keras deep learning platform framework ,
as well as Wasserstein loss function and Lipschitz constraints, generative
adversarial network is constructed and trained. From the obtained low
dimensional bridge-type latent space sampling, new bridge types with asymmetric
structures can be generated. Generative adversarial network can create new
bridge types by organically combining different structural components on the
basis of human original bridge types. It has a certain degree of human original
ability. Generative artificial intelligence technology can open up imagination
space and inspire humanity.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00701" title="Abstract">arXiv:2401.00701</a> [<a href="/pdf/2401.00701" title="Download PDF">pdf</a>, <a href="/format/2401.00701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient and Effective Text-to-Video Retrieval with  Coarse-to-Fine Visual Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+K">Kaibin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yanhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinglin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Quan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Han Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, text-to-video retrieval methods based on CLIP have
experienced rapid development. The primary direction of evolution is to exploit
the much wider gamut of visual and textual cues to achieve alignment.
Concretely, those methods with impressive performance often design a heavy
fusion block for sentence (words)-video (frames) interaction, regardless of the
prohibitive computation complexity. Nevertheless, these approaches are not
optimal in terms of feature utilization and retrieval efficiency. To address
this issue, we adopt multi-granularity visual feature learning, ensuring the
model's comprehensiveness in capturing visual content features spanning from
abstract to detailed levels during the training phase. To better leverage the
multi-granularity features, we devise a two-stage retrieval architecture in the
retrieval phase. This solution ingeniously balances the coarse and fine
granularity of retrieval content. Moreover, it also strikes a harmonious
equilibrium between retrieval effectiveness and efficiency. Specifically, in
training phase, we design a parameter-free text-gated interaction block (TIB)
for fine-grained video representation learning and embed an extra Pearson
Constraint to optimize cross-modal representation learning. In retrieval phase,
we use coarse-grained video representations for fast recall of top-k
candidates, which are then reranked by fine-grained video representations.
Extensive experiments on four benchmarks demonstrate the efficiency and
effectiveness. Notably, our method achieves comparable performance with the
current state-of-the-art methods while being nearly 50 times faster.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00708" title="Abstract">arXiv:2401.00708</a> [<a href="/pdf/2401.00708" title="Download PDF">pdf</a>, <a href="/format/2401.00708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Nonlocal Self-Similarity from Continuous Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yisi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xile Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Nonlocal self-similarity (NSS) is an important prior that has been
successfully applied in multi-dimensional data processing tasks, e.g., image
and video recovery. However, existing NSS-based methods are solely suitable for
meshgrid data such as images and videos, but are not suitable for emerging
off-meshgrid data, e.g., point cloud and climate data. In this work, we revisit
the NSS from the continuous representation perspective and propose a novel
Continuous Representation-based NonLocal method (termed as CRNL), which has two
innovative features as compared with classical nonlocal methods. First, based
on the continuous representation, our CRNL unifies the measure of
self-similarity for on-meshgrid and off-meshgrid data and thus is naturally
suitable for both of them. Second, the nonlocal continuous groups can be more
compactly and efficiently represented by the coupled low-rank function
factorization, which simultaneously exploits the similarity within each group
and across different groups, while classical nonlocal methods neglect the
similarity across groups. This elaborately designed coupled mechanism allows
our method to enjoy favorable performance over conventional NSS methods in
terms of both effectiveness and efficiency. Extensive multi-dimensional data
processing experiments on-meshgrid (e.g., image inpainting and image denoising)
and off-meshgrid (e.g., climate data prediction and point cloud recovery)
validate the versatility, effectiveness, and efficiency of our CRNL as compared
with state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00710" title="Abstract">arXiv:2401.00710</a> [<a href="/pdf/2401.00710" title="Download PDF">pdf</a>, <a href="/format/2401.00710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Integer Sort: Theory and Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaojun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Dhulipala%2C+L">Laxman Dhulipala</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yihan Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Integer sorting is a fundamental problem in computer science. This paper
studies parallel integer sort both in theory and in practice. In theory, we
show tighter bounds for a class of existing practical integer sort algorithms,
which provides a solid theoretical foundation for their widespread usage in
practice and strong performance. In practice, we design a new integer sorting
algorithm, \textsf{DovetailSort}, that is theoretically-efficient and has good
practical performance.
<br />In particular, \textsf{DovetailSort} overcomes a common challenge in existing
parallel integer sorting algorithms, which is the difficulty of detecting and
taking advantage of duplicate keys. The key insight in \textsf{DovetailSort} is
to combine algorithmic ideas from both integer- and comparison-sorting
algorithms. In our experiments, \textsf{DovetailSort} achieves competitive or
better performance than existing state-of-the-art parallel integer and
comparison sorting algorithms on various synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00711" title="Abstract">arXiv:2401.00711</a> [<a href="/pdf/2401.00711" title="Download PDF">pdf</a>, <a href="/format/2401.00711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2Avatar: Text to 3D Human Avatar Generation with Codebook-Driven  Body Controllable Attribute
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chaoqun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuqin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ronghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+A">Achun Bao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yachao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generating 3D human models directly from text helps reduce the cost and time
of character modeling. However, achieving multi-attribute controllable and
realistic 3D human avatar generation is still challenging due to feature
coupling and the scarcity of realistic 3D human avatar datasets. To address
these issues, we propose Text2Avatar, which can generate realistic-style 3D
avatars based on the coupled text prompts. Text2Avatar leverages a discrete
codebook as an intermediate feature to establish a connection between text and
avatars, enabling the disentanglement of features. Furthermore, to alleviate
the scarcity of realistic style 3D human avatar data, we utilize a pre-trained
unconditional 3D human avatar generation model to obtain a large amount of 3D
avatar pseudo data, which allows Text2Avatar to achieve realistic style
generation. Experimental results demonstrate that our method can generate
realistic 3D avatars from coupled textual data, which is challenging for other
existing methods in this field.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00713" title="Abstract">arXiv:2401.00713</a> [<a href="/pdf/2401.00713" title="Download PDF">pdf</a>, <a href="/format/2401.00713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Graph Neural Networks in Intelligent Transportation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hourun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yusheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhengyang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">YiFang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhiping Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiaqi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yiyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Ming Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Intelligent Transportation System (ITS) is vital in improving traffic
congestion, reducing traffic accidents, optimizing urban planning, etc.
However, due to the complexity of the traffic network, traditional machine
learning and statistical methods are relegated to the background. With the
advent of the artificial intelligence era, many deep learning frameworks have
made remarkable progress in various fields and are now considered effective
methods in many areas. As a deep learning method, Graph Neural Networks (GNNs)
have emerged as a highly competitive method in the ITS field since 2019 due to
their strong ability to model graph-related problems. As a result, more and
more scholars pay attention to the applications of GNNs in transportation
domains, which have shown excellent performance. However, most of the research
in this area is still concentrated on traffic forecasting, while other ITS
domains, such as autonomous vehicles and urban planning, still require more
attention. This paper aims to review the applications of GNNs in six
representative and emerging ITS domains: traffic forecasting, autonomous
vehicles, traffic signal control, transportation safety, demand prediction, and
parking management. We have reviewed extensive graph-related studies from 2018
to 2023, summarized their methods, features, and contributions, and presented
them in informative tables or lists. Finally, we have identified the challenges
of applying GNNs to ITS and suggested potential future directions.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00717" title="Abstract">arXiv:2401.00717</a> [<a href="/pdf/2401.00717" title="Download PDF">pdf</a>, <a href="/ps/2401.00717" title="Download PostScript">ps</a>, <a href="/format/2401.00717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HENO-MAC: Hybrid Energy Harvesting-based Energy Neutral Operation MAC  Protocol for Delay-Sensitive IoT Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarang%2C+S">Sohail Sarang</a>, 
<a href="/search/cs?searchtype=author&query=Stojanovi%C4%87%2C+G+M">Goran M Stojanovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Drieberg%2C+M">Micheal Drieberg</a>, 
<a href="/search/cs?searchtype=author&query=Jeoti%2C+V">Varun Jeoti</a>, 
<a href="/search/cs?searchtype=author&query=Valkama%2C+M">Mikko Valkama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for presentation at the IEEE Wireless Communications and Networking Conference (WCNC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The Internet of Things (IoT) technology uses small and cost-effective sensors
for various applications, such as Industrial IoT. However, these sensor nodes
are powered by fixed-size batteries, which creates a trade-off between network
performance and long-term sustainability. Moreover, some applications require
the network to provide a certain level of service, such as a lower delay for
critical data, while ensuring the operational reliability of sensor nodes. To
address this energy challenge, external energy harvesting sources, such as
solar and wind, offer promising and eco-friendly solutions. However, the
available energy from a single energy source is insufficient to meet these
requirements. This drives the utilization of a hybrid energy harvesting
approach, such as the integration of solar and wind energy harvesters, to
increase the amount of harvested energy. Nevertheless, to fully utilize the
available energy, which is dynamic in nature, the sensor node must adapt its
operation to ensure sustainable operation and enhanced network performance.
Therefore, this paper proposes a hybrid energy harvesting-based energy neutral
operation (ENO) medium access control (MAC) protocol, called HENO-MAC, that
allows the receiver node to harvest energy from the solar-wind harvesters and
adapt its duty cycle accordingly. The performance of the proposed HENO-MAC was
evaluated using the latest realistic solar and wind data for two consecutive
days in GreenCastalia. The simulation results demonstrate that the duty cycle
mechanism of HENO-MAC effectively utilizes the harvested energy to achieve ENO
and uses the available energy resources efficiently to reduce the packet delay
for all packets and the highest priority packet by up to 28.5% and 27.3%,
respectively, when compared with other existing MAC protocols.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00719" title="Abstract">arXiv:2401.00719</a> [<a href="/pdf/2401.00719" title="Download PDF">pdf</a>, <a href="/format/2401.00719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth Map Denoising Network and Lightweight Fusion Network for Enhanced  3D Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruizhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Junlan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weihong Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Pattern Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the increasing availability of consumer depth sensors, 3D face
recognition (FR) has attracted more and more attention. However, the data
acquired by these sensors are often coarse and noisy, making them impractical
to use directly. In this paper, we introduce an innovative Depth map denoising
network (DMDNet) based on the Denoising Implicit Image Function (DIIF) to
reduce noise and enhance the quality of facial depth images for low-quality 3D
FR. After generating clean depth faces using DMDNet, we further design a
powerful recognition network called Lightweight Depth and Normal Fusion network
(LDNFNet), which incorporates a multi-branch fusion block to learn unique and
complementary features between different modalities such as depth and normal
images. Comprehensive experiments conducted on four distinct low-quality
databases demonstrate the effectiveness and robustness of our proposed methods.
Furthermore, when combining DMDNet and LDNFNet, we achieve state-of-the-art
results on the Lock3DFace database.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00722" title="Abstract">arXiv:2401.00722</a> [<a href="/pdf/2401.00722" title="Download PDF">pdf</a>, <a href="/format/2401.00722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BRAU-Net++: U-Shaped Hybrid CNN-Transformer Network for Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+L">Libin Lan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pengzhou Cai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaojuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongmei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yudong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 9 tables code: <a href="https://github.com/Caipengzhou/BRAU-Netplusplus">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate medical image segmentation is essential for clinical quantification,
disease diagnosis, treatment planning and many other applications. Both
convolution-based and transformer-based u-shaped architectures have made
significant success in various medical image segmentation tasks. The former can
efficiently learn local information of images while requiring much more
image-specific inductive biases inherent to convolution operation. The latter
can effectively capture long-range dependency at different feature scales using
self-attention, whereas it typically encounters the challenges of quadratic
compute and memory requirements with sequence length increasing. To address
this problem, through integrating the merits of these two paradigms in a
well-designed u-shaped architecture, we propose a hybrid yet effective
CNN-Transformer network, named BRAU-Net++, for an accurate medical image
segmentation task. Specifically, BRAU-Net++ uses bi-level routing attention as
the core building block to design our u-shaped encoder-decoder structure, in
which both encoder and decoder are hierarchically constructed, so as to learn
global semantic information while reducing computational complexity.
Furthermore, this network restructures skip connection by incorporating
channel-spatial attention which adopts convolution operations, aiming to
minimize local spatial information loss and amplify global
dimension-interaction of multi-scale features. Extensive experiments on three
public benchmark datasets demonstrate that our proposed approach surpasses
other state-of-the-art methods including its baseline: BRAU-Net under almost
all evaluation metrics. We achieve the average Dice-Similarity Coefficient
(DSC) of 82.47, 90.10, and 92.94 on Synapse multi-organ segmentation, ISIC-2018
Challenge, and CVC-ClinicDB, as well as the mIoU of 84.01 and 88.17 on
ISIC-2018 Challenge and CVC-ClinicDB, respectively.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00729" title="Abstract">arXiv:2401.00729</a> [<a href="/pdf/2401.00729" title="Download PDF">pdf</a>, <a href="/format/2401.00729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NightRain: Nighttime Video Deraining via Adaptive-Rain-Removal and  Adaptive-Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Beibei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yeying Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wending Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shunli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+R">Robby Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing deep-learning-based methods for nighttime video deraining rely on
synthetic data due to the absence of real-world paired data. However, the
intricacies of the real world, particularly with the presence of light effects
and low-light regions affected by noise, create significant domain gaps,
hampering synthetic-trained models in removing rain streaks properly and
leading to over-saturation and color shifts. Motivated by this, we introduce
NightRain, a novel nighttime video deraining method with adaptive-rain-removal
and adaptive-correction. Our adaptive-rain-removal uses unlabeled rain videos
to enable our model to derain real-world rain videos, particularly in regions
affected by complex light effects. The idea is to allow our model to obtain
rain-free regions based on the confidence scores. Once rain-free regions and
the corresponding regions from our input are obtained, we can have region-based
paired real data. These paired data are used to train our model using a
teacher-student framework, allowing the model to iteratively learn from less
challenging regions to more challenging regions. Our adaptive-correction aims
to rectify errors in our model's predictions, such as over-saturation and color
shifts. The idea is to learn from clear night input training videos based on
the differences or distance between those input videos and their corresponding
predictions. Our model learns from these differences, compelling our model to
correct the errors. From extensive experiments, our method demonstrates
state-of-the-art performance. It achieves a PSNR of 26.73dB, surpassing
existing nighttime video deraining methods by a substantial margin of 13.7%.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00730" title="Abstract">arXiv:2401.00730</a> [<a href="/pdf/2401.00730" title="Download PDF">pdf</a>, <a href="/format/2401.00730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The PML-Method for a Scattering Problem for a Local Perturbation of an  Open Periodic Waveguide
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kirsch%2C+A">Andreas Kirsch</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+R">Ruming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">The perfectly matched layers method is a well known truncation technique for
its efficiency and convenience in numerical implementations of wave scattering
problems in unbounded domains. In this paper, we study the convergence of the
perfectly matched layers (PML) for wave scattering from a local perturbation of
an open waveguide in the half space above the real line, where the refractive
index is a function which is periodic along the axis of the waveguide and
equals to one above a finite height. The problem is challenging due to the
existence of guided waves, and a typical way to deal with the difficulty is to
apply the limiting absorption principle. Based on the Floquet-Bloch transform
and a curve deformation theory, the solution from the limiting absorption
principle is rewritten as the integral of a coupled family of quasi-periodic
problems with respect to the quasi-periodicity parameter on a particularly
designed curve. By comparing the Dirichlet-to-Neumann maps on a straight line
above the locally perturbed periodic layer, we finally show that the PML method
converges exponentially with respect to the PML parameter. Finally, the
numerical examples are shown to illustrate the theoretical results.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00736" title="Abstract">arXiv:2401.00736</a> [<a href="/pdf/2401.00736" title="Download PDF">pdf</a>, <a href="/format/2401.00736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models, Image Super-Resolution And Everything: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moser%2C+B+B">Brian B. Moser</a>, 
<a href="/search/cs?searchtype=author&query=Shanbhag%2C+A+S">Arundhati S. Shanbhag</a>, 
<a href="/search/cs?searchtype=author&query=Raue%2C+F">Federico Raue</a>, 
<a href="/search/cs?searchtype=author&query=Frolov%2C+S">Stanislav Frolov</a>, 
<a href="/search/cs?searchtype=author&query=Palacio%2C+S">Sebastian Palacio</a>, 
<a href="/search/cs?searchtype=author&query=Dengel%2C+A">Andreas Dengel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); General Literature (cs.GL); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Diffusion Models (DMs) represent a significant advancement in image
Super-Resolution (SR), aligning technical image quality more closely with human
preferences and expanding SR applications. DMs address critical limitations of
previous methods, enhancing overall realism and details in SR images. However,
DMs suffer from color-shifting issues, and their high computational costs call
for efficient sampling alternatives, underscoring the challenge of balancing
computational efficiency and image quality. This survey gives an overview of
DMs applied to image SR and offers a detailed analysis that underscores the
unique characteristics and methodologies within this domain, distinct from
broader existing reviews in the field. It presents a unified view of DM
fundamentals and explores research directions, including alternative input
domains, conditioning strategies, guidance, corruption spaces, and zero-shot
methods. This survey provides insights into the evolution of image SR with DMs,
addressing current trends, challenges, and future directions in this rapidly
evolving field.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00737" title="Abstract">arXiv:2401.00737</a> [<a href="/pdf/2401.00737" title="Download PDF">pdf</a>, <a href="/format/2401.00737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Searching, fast and slow, through product catalogs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ubrangala%2C+D">Dayananda Ubrangala</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+J">Juhi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Rangappa%2C+S+K">Sharath Kumar Rangappa</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+K">Kiran R</a>, 
<a href="/search/cs?searchtype=author&query=Kondapalli%2C+R+P">Ravi Prasad Kondapalli</a>, 
<a href="/search/cs?searchtype=author&query=Bou%C3%A9%2C+L">Laurent Bou&#xe9;</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Microsoft Journal of Applied Research, Volume 20, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">String matching algorithms in the presence of abbreviations, such as in Stock
Keeping Unit (SKU) product catalogs, remains a relatively unexplored topic. In
this paper, we present a unified architecture for SKU search that provides both
a real-time suggestion system (based on a Trie data structure) as well as a
lower latency search system (making use of character level TF-IDF in
combination with language model vector embeddings) where users initiate the
search process explicitly. We carry out ablation studies that justify designing
a complex search system composed of multiple components to address the delicate
trade-off between speed and accuracy. Using SKU search in the Dynamics CRM as
an example, we show how our system vastly outperforms, in all aspects, the
results provided by the default search engine. Finally, we show how SKU
descriptions may be enhanced via generative text models (using gpt-3.5-turbo)
so that the consumers of the search results may get more context and a
generally better experience when presented with the results of their SKU
search.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00739" title="Abstract">arXiv:2401.00739</a> [<a href="/pdf/2401.00739" title="Download PDF">pdf</a>, <a href="/format/2401.00739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffMorph: Text-less Image Morphing with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+S">Shounak Chatterjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-conditioned image generation models are a prevalent use of AI image
synthesis, yet intuitively controlling output guided by an artist remains
challenging. Current methods require multiple images and textual prompts for
each object to specify them as concepts to generate a single customized image.
<br />On the other hand, our work, \verb|DiffMorph|, introduces a novel approach
that synthesizes images that mix concepts without the use of textual prompts.
Our work integrates a sketch-to-image module to incorporate user sketches as
input. \verb|DiffMorph| takes an initial image with conditioning artist-drawn
sketches to generate a morphed image.
<br />We employ a pre-trained text-to-image diffusion model and fine-tune it to
reconstruct each image faithfully. We seamlessly merge images and concepts from
sketches into a cohesive composition. The image generation capability of our
work is demonstrated through our results and a comparison of these with
prompt-based image generation.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00741" title="Abstract">arXiv:2401.00741</a> [<a href="/pdf/2401.00741" title="Download PDF">pdf</a>, <a href="/format/2401.00741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of  Large Language Models in Real-world Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Songyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Caishuang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yilong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sixian Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+S">Shihan Dou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing evaluations of tool learning primarily focus on validating the
alignment of selected tools for large language models (LLMs) with expected
outcomes. However, these approaches rely on a limited set of scenarios where
answers can be pre-determined, diverging from genuine needs. Furthermore, a
sole emphasis on outcomes disregards the intricate capabilities essential for
LLMs to effectively utilize tools. To tackle this issue, we propose ToolEyes, a
fine-grained system tailored for the evaluation of the LLMs' tool learning
capabilities in authentic scenarios. The system meticulously examines seven
real-world scenarios, analyzing five dimensions crucial to LLMs in tool
learning: format alignment, intent comprehension, behavior planning, tool
selection, and answer organization. Additionally, ToolEyes incorporates a tool
library boasting approximately 600 tools, serving as an intermediary between
LLMs and the physical world. Evaluations involving ten LLMs across three
categories reveal a preference for specific scenarios and limited cognitive
abilities in tool learning. Intriguingly, expanding the model size even
exacerbates the hindrance to tool learning. These findings offer instructive
insights aimed at advancing the field of tool learning. The data is available
att https://github.com/Junjie-Ye/ToolEyes.git.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00747" title="Abstract">arXiv:2401.00747</a> [<a href="/pdf/2401.00747" title="Download PDF">pdf</a>, <a href="/format/2401.00747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-time Approximation Scheme for Equilibriums of Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hongbo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+C">Chongkun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Bo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Bin Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Whether a PTAS (polynomial-time approximation scheme) exists for equilibriums
of games has been an open question, which relates to the practicality of
methods in algorithmic game theory and the problem of non-stationarity in
training and curse of dimensionality in multi-agent reinforcement learning.
This paper introduces our theory that implies a method that is sufficient and
necessary to be the PTAS for perfect equilibriums of dynamic games. The theory
consists of cone interior dynamic programming and primal-dual unbiased regret
minimization. The former enables the dynamic programming operator to
iteratively converge to a perfect equilibrium based on a concept called policy
cone. The latter enables the line search method to approximate a Nash
equilibrium based on two concepts called primal-dual bias and unbiased central
path, solving a subproblem of the former. Validity of our discovery is
cross-corroborated by a combination of theorem proofs, graphs of the three core
concepts, and experimental results.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00751" title="Abstract">arXiv:2401.00751</a> [<a href="/pdf/2401.00751" title="Download PDF">pdf</a>, <a href="/format/2401.00751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Translation Testing via Syntactic Tree Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+J">Juan Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weisong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haichuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM Transactions on Software Engineering and Methodology 2024 (TOSEM'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Machine translation systems have been widely adopted in our daily life,
making life easier and more convenient. Unfortunately, erroneous translations
may result in severe consequences, such as financial losses. This requires to
improve the accuracy and the reliability of machine translation systems.
However, it is challenging to test machine translation systems because of the
complexity and intractability of the underlying neural models. To tackle these
challenges, we propose a novel metamorphic testing approach by syntactic tree
pruning (STP) to validate machine translation systems. Our key insight is that
a pruned sentence should have similar crucial semantics compared with the
original sentence. Specifically, STP (1) proposes a core semantics-preserving
pruning strategy by basic sentence structure and dependency relations on the
level of syntactic tree representation; (2) generates source sentence pairs
based on the metamorphic relation; (3) reports suspicious issues whose
translations break the consistency property by a bag-of-words model. We further
evaluate STP on two state-of-the-art machine translation systems (i.e., Google
Translate and Bing Microsoft Translator) with 1,200 source sentences as inputs.
The results show that STP can accurately find 5,073 unique erroneous
translations in Google Translate and 5,100 unique erroneous translations in
Bing Microsoft Translator (400% more than state-of-the-art techniques), with
64.5% and 65.4% precision, respectively. The reported erroneous translations
vary in types and more than 90% of them cannot be found by state-of-the-art
techniques. There are 9,393 erroneous translations unique to STP, which is
711.9% more than state-of-the-art techniques. Moreover, STP is quite effective
to detect translation errors for the original sentences with a recall reaching
74.0%, improving state-of-the-art techniques by 55.1% on average.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00752" title="Abstract">arXiv:2401.00752</a> [<a href="/pdf/2401.00752" title="Download PDF">pdf</a>, <a href="/format/2401.00752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on Laguerre truncated polynomials and quadrature formula
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Garc%C3%ADa-Ardila%2C+J+C">Juan C. Garc&#xed;a-Ardila</a>, 
<a href="/search/math?searchtype=author&query=Marcell%C3%A1n%2C+F">Francisco Marcell&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this contribution we deal with Gaussian quadrature rules based on
orthogonal polynomials associated with a weight function $w(x)= x^{\alpha}
e^{-x}$ supported on an interval $(0,z)$, $z&gt;0.$ The modified Chebyshev
algorithm is used in order to test the accuracy in the computation of the
coefficients of the three-term recurrence relation, the zeros and weights, as
well as the dependence on the parameter $z.$
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00755" title="Abstract">arXiv:2401.00755</a> [<a href="/pdf/2401.00755" title="Download PDF">pdf</a>, <a href="/format/2401.00755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saliency-Aware Regularized Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+W">Wenjie Pei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weina Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongze Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weichao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinfan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guangming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangrong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Artificial Intelligence Journal with minor revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The crux of graph classification lies in the effective representation
learning for the entire graph. Typical graph neural networks focus on modeling
the local dependencies when aggregating features of neighboring nodes, and
obtain the representation for the entire graph by aggregating node features.
Such methods have two potential limitations: 1) the global node saliency w.r.t.
graph classification is not explicitly modeled, which is crucial since
different nodes may have different semantic relevance to graph classification;
2) the graph representation directly aggregated from node features may have
limited effectiveness to reflect graph-level information. In this work, we
propose the Saliency-Aware Regularized Graph Neural Network (SAR-GNN) for graph
classification, which consists of two core modules: 1) a traditional graph
neural network serving as the backbone for learning node features and 2) the
Graph Neural Memory designed to distill a compact graph representation from
node features of the backbone. We first estimate the global node saliency by
measuring the semantic similarity between the compact graph representation and
node features. Then the learned saliency distribution is leveraged to
regularize the neighborhood aggregation of the backbone, which facilitates the
message passing of features for salient nodes and suppresses the less relevant
nodes. Thus, our model can learn more effective graph representation. We
demonstrate the merits of SAR-GNN by extensive experiments on seven datasets
across various types of graph data. Code will be released.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00756" title="Abstract">arXiv:2401.00756</a> [<a href="/pdf/2401.00756" title="Download PDF">pdf</a>, <a href="/format/2401.00756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPRE: Multi-perspective Patient Representation Extractor for Disease  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Ziyue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiayi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wuman Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+R">Rita Tse</a>, 
<a href="/search/cs?searchtype=author&query=Pau%2C+G">Giovanni Pau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Patient representation learning based on electronic health records (EHR) is a
critical task for disease prediction. This task aims to effectively extract
useful information on dynamic features. Although various existing works have
achieved remarkable progress, the model performance can be further improved by
fully extracting the trends, variations, and the correlation between the trends
and variations in dynamic features. In addition, sparse visit records limit the
performance of deep learning models. To address these issues, we propose the
Multi-perspective Patient Representation Extractor (MPRE) for disease
prediction. Specifically, we propose Frequency Transformation Module (FTM) to
extract the trend and variation information of dynamic features in the
time-frequency domain, which can enhance the feature representation. In the 2D
Multi-Extraction Network (2D MEN), we form the 2D temporal tensor based on
trend and variation. Then, the correlations between trend and variation are
captured by the proposed dilated operation. Moreover, we propose the
First-Order Difference Attention Mechanism (FODAM) to calculate the
contributions of differences in adjacent variations to the disease diagnosis
adaptively. To evaluate the performance of MPRE and baseline methods, we
conduct extensive experiments on two real-world public datasets. The experiment
results show that MPRE outperforms state-of-the-art baseline methods in terms
of AUROC and AUPRC.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00757" title="Abstract">arXiv:2401.00757</a> [<a href="/pdf/2401.00757" title="Download PDF">pdf</a>, <a href="/format/2401.00757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A &amp; B == B &amp; A: Triggering Logical Reasoning Failures in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yuxuan Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiliu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Youliang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jen-tse Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pinjia He</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+W">Wenxiang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) have propelled Artificial
Intelligence (AI) to new heights, enabling breakthroughs in various tasks such
as writing assistance, code generation, and machine translation. A significant
distinction of advanced LLMs, such as ChatGPT, is their demonstrated ability to
"reason." However, evaluating the reasoning ability of LLMs remains a challenge
as most existing evaluations focus on their accuracy on the downstream tasks
rather than directly assessing their reasoning processes. Efforts have been
made to develop benchmarks and metrics to assess reasoning in LLMs, but they
suffer from data leakage or limited scope. In this paper, we introduce
LogicAsker, an automatic approach that comprehensively evaluates and improves
the logical reasoning abilities of LLMs under a set of atomic reasoning skills
based on propositional and predicate logic. The results provide insights into
LLMs' reasoning abilities and reveal the logical rules the LLMs did not learn
well. We evaluate LogicAsker on six widely deployed LLMs, including GPT-3,
ChatGPT, GPT-4, Bard, Vicuna, and Guanaco. The results show that test cases
from LogicAsker can find logical reasoning failures in different LLMs with a
rate of 25\% - 94\%. In addition, the test cases of LogicAsker can be further
used to design demonstration examples for in-context learning, which
effectively improves the logical reasoning ability of LLMs, e.g., 10\% for
GPT-4. As far as we know, our work is the first to create prompts based on
testing results to improve LLMs' formal reasoning ability effectively. All the
code, data, and results will be released for reproduction and future research.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00761" title="Abstract">arXiv:2401.00761</a> [<a href="/pdf/2401.00761" title="Download PDF">pdf</a>, <a href="/format/2401.00761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Earth is Flat? Unveiling Factual Errors in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Juluan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Youliang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jen-tse Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+W">Wenxiang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) like ChatGPT are foundational in various
applications due to their extensive knowledge from pre-training and
fine-tuning. Despite this, they are prone to generating factual and commonsense
errors, raising concerns in critical areas like healthcare, journalism, and
education to mislead users. Current methods for evaluating LLMs' veracity are
limited by test data leakage or the need for extensive human labor, hindering
efficient and accurate error detection. To tackle this problem, we introduce a
novel, automatic testing framework, FactChecker, aimed at uncovering factual
inaccuracies in LLMs. This framework involves three main steps: First, it
constructs a factual knowledge graph by retrieving fact triplets from a
large-scale knowledge database. Then, leveraging the knowledge graph,
FactChecker employs a rule-based approach to generates three types of questions
(Yes-No, Multiple-Choice, and WH questions) that involve single-hop and
multi-hop relations, along with correct answers. Lastly, it assesses the LLMs'
responses for accuracy using tailored matching strategies for each question
type. Our extensive tests on six prominent LLMs, including text-davinci-002,
text-davinci-003, ChatGPT~(gpt-3.5-turbo, gpt-4), Vicuna, and LLaMA-2, reveal
that FactChecker can trigger factual errors in up to 45\% of questions in these
models. Moreover, we demonstrate that FactChecker's test cases can improve
LLMs' factual accuracy through in-context learning and fine-tuning (e.g.,
llama-2-13b-chat's accuracy increase from 35.3\% to 68.5\%). We are making all
code, data, and results available for future research endeavors.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00762" title="Abstract">arXiv:2401.00762</a> [<a href="/pdf/2401.00762" title="Download PDF">pdf</a>, <a href="/ps/2401.00762" title="Download PostScript">ps</a>, <a href="/format/2401.00762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithm for globally identifiable reparametrizions of ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Falkensteiner%2C+S">Sebastian Falkensteiner</a>, 
<a href="/search/eess?searchtype=author&query=Ovchinnikov%2C+A">Alexey Ovchinnikov</a>, 
<a href="/search/eess?searchtype=author&query=Sendra%2C+J+R">J. Rafael Sendra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Symbolic Computation (cs.SC); Analysis of PDEs (math.AP)

</div>
<p class="mathjax">Structural global parameter identifiability indicates whether one can
determine a parameter's value in an ODE model from given inputs and outputs. If
a given model has parameters for which there is exactly one value, such
parameters are called identifiable. We present a procedure for replacing, if
possible, a given ODE model involving not identifiable parameters by an
equivalent one such that the new set of parameters is identifiable. We first
derive this as an algorithm for one-dimensional ODE models and then reuse this
approach for higher-dimensional models.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00763" title="Abstract">arXiv:2401.00763</a> [<a href="/pdf/2401.00763" title="Download PDF">pdf</a>, <a href="/format/2401.00763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Job, New Gender? Measuring the Social Bias in Image Generation  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Haonan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jen-tse Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yuxuan Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Youliang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Haoyi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">Image generation models can generate or edit images from a given text. Recent
advancements in image generation technology, exemplified by DALL-E and
Midjourney, have been groundbreaking. These advanced models, despite their
impressive capabilities, are often trained on massive Internet datasets, making
them susceptible to generating content that perpetuates social stereotypes and
biases, which can lead to severe consequences. Prior research on assessing bias
within image generation models suffers from several shortcomings, including
limited accuracy, reliance on extensive human labor, and lack of comprehensive
analysis. In this paper, we propose BiasPainter, a novel metamorphic testing
framework that can accurately, automatically and comprehensively trigger social
bias in image generation models. BiasPainter uses a diverse range of seed
images of individuals and prompts the image generation models to edit these
images using gender, race, and age-neutral queries. These queries span 62
professions, 39 activities, 57 types of objects, and 70 personality traits. The
framework then compares the edited images to the original seed images, focusing
on any changes related to gender, race, and age. BiasPainter adopts a testing
oracle that these characteristics should not be modified when subjected to
neutral prompts. Built upon this design, BiasPainter can trigger the social
bias and evaluate the fairness of image generation models. To evaluate the
effectiveness of BiasPainter, we use BiasPainter to test five widely-used
commercial image generation software and models, such as stable diffusion and
Midjourney. Experimental results show that 100\% of the generated test cases
can successfully trigger social bias in image generation models.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00765" title="Abstract">arXiv:2401.00765</a> [<a href="/pdf/2401.00765" title="Download PDF">pdf</a>, <a href="/format/2401.00765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HexE -- Securing Audio Contents in Voice Chat using Puzzle and Timestamp
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=A%2C+A">Aadhitya A</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages (single column), 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cryptography is the study of securing information. It is the physical process
that scrambles the information by rearrangement and substitution of content, so
that it becomes difficult for anyone to understand. In today's world, security
has become an inevitable part of our day-to-day life, right from normal
browsing to performing critical payment transactions. Hackers work endlessly to
break the security present in the apps/websites on which we perform day-to-day
operations and salvage valuable information. Because of this, many illegal
activities have taken place which affect the user. One such illegal activity is
tapping the voice communication between two users. If left unencrypted, the
communication between the users is compromised, thereby causing issues. One way
to prevent this act is to encrypt the audio in that the contents cannot have
tampered with unless the receiver has the valid key to decrypt it. The proposed
solution termed "HexE" aims to create a puzzle-based algorithm which would
encrypt and decrypt the audio files without manipulating the file header, thus
securing the contents. The algorithm works on an NxN SuDoKu-based puzzle which
is accepted both by the sender and receiver. Using the timestamp of the event
(UNIX based), a grid from the puzzle is chosen which in turn will act as the
key for both encryption and decryption. If the timestamp is slightly adjusted,
the process will end up in failure during decryption, thus ensuring
confidentiality. Another approach to secure the audio files is to implement
IPFS (Inter Planetary File System) alongside the puzzle algorithm in which the
encrypted audio is stored on it and the receiver can fetch the audio provided
if the valid IPFS Hash of the file is present. In this way, the audio file is
secured.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00766" title="Abstract">arXiv:2401.00766</a> [<a href="/pdf/2401.00766" title="Download PDF">pdf</a>, <a href="/format/2401.00766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bracketing is All You Need: Unifying Image Restoration and Enhancement  Tasks with Multi-Exposure Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuohao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Renlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zifei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">It is challenging but highly desired to acquire high-quality photos with
clear content in low-light environments. Although multi-image processing
methods (using burst, dual-exposure, or multi-exposure images) have made
significant progress in addressing this issue, they typically focus exclusively
on specific restoration or enhancement tasks, being insufficient in exploiting
multi-image. Motivated by that multi-exposure images are complementary in
denoising, deblurring, high dynamic range imaging, and super-resolution, we
propose to utilize bracketing photography to unify restoration and enhancement
tasks in this work. Due to the difficulty in collecting real-world pairs, we
suggest a solution that first pre-trains the model with synthetic paired data
and then adapts it to real-world unlabeled images. In particular, a temporally
modulated recurrent network (TMRNet) and self-supervised adaptation method are
proposed. Moreover, we construct a data simulation pipeline to synthesize pairs
and collect real-world images from 200 nighttime scenarios. Experiments on both
datasets show that our method performs favorably against the state-of-the-art
multi-image processing ones. The dataset, code, and pre-trained models are
available at https://github.com/cszhilu1998/BracketIRE.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00772" title="Abstract">arXiv:2401.00772</a> [<a href="/pdf/2401.00772" title="Download PDF">pdf</a>, <a href="/ps/2401.00772" title="Download PostScript">ps</a>, <a href="/format/2401.00772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for Improving the Automatically Synthesized Instruction Set  of an Extensible Processor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sovietov%2C+P">Peter Sovietov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Processors with extensible instruction sets are often used today as
programmable hardware accelerators for various domains. When extending RISC-V
and other similar extensible processor architectures, the task of designing
specialized instructions arises. This task can be solved automatically by using
instruction synthesis algorithms. In this paper, we consider algorithms that
can be used in addition to the known approaches and improve the synthesized
instruction sets by recomputing common operations (the result of which is
consumed by multiple operations) of a program inside clustered synthesized
instructions (common operations clustering algorithm), and by identifying
redundant (which have equivalents among the other instructions) synthesized
instructions (subsuming functions algorithm).
<br />Experimental evaluations of the developed algorithms are presented for the
tests from the domains of cryptography and three-dimensional graphics. For
Magma cipher test, the common operations clustering algorithm allows reducing
the size of the compiled code by 9%, and the subsuming functions algorithm
allows reducing the synthesized instruction set extension size by 2 times. For
AES cipher test, the common operations clustering algorithm allows reducing the
size of the compiled code by 10%, and the subsuming functions algorithm allows
reducing the synthesized instruction set extension size by 2.5 times. Finally,
for the instruction set extension from Volume Ray-Casting test, the additional
use of subsuming functions algorithm allows reducing problem-specific
instruction extension set size from 5 to only 2 instructions without losing its
functionality.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00773" title="Abstract">arXiv:2401.00773</a> [<a href="/pdf/2401.00773" title="Download PDF">pdf</a>, <a href="/format/2401.00773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Outlier Detection using Random Subspace and Subsampling  Ensembles of Dirichlet Process Mixtures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongwook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Juyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H+C">Hee Cheol Chung</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+S">Seonghyun Jeong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Probabilistic mixture models are acknowledged as a valuable tool for
unsupervised outlier detection owing to their interpretability and intuitive
grounding in statistical principles. Within this framework, Dirichlet process
mixture models emerge as a compelling alternative to conventional finite
mixture models for both clustering and outlier detection tasks. However,
despite their evident advantages, the widespread adoption of Dirichlet process
mixture models in unsupervised outlier detection has been hampered by
challenges related to computational inefficiency and sensitivity to outliers
during the construction of detectors. To tackle these challenges, we propose a
novel outlier detection method based on ensembles of Dirichlet process Gaussian
mixtures. The proposed method is a fully unsupervised algorithm that
capitalizes on random subspace and subsampling ensembles, not only ensuring
efficient computation but also enhancing the robustness of the resulting
outlier detector. Moreover, the proposed method leverages variational inference
for Dirichlet process mixtures to ensure efficient and fast computation.
Empirical studies with benchmark datasets demonstrate that our method
outperforms existing approaches for unsupervised outlier detection.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00776" title="Abstract">arXiv:2401.00776</a> [<a href="/pdf/2401.00776" title="Download PDF">pdf</a>, <a href="/format/2401.00776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Computing based Human-Robot Cognitive Fusion: A Medical Case Study  in the Autism Spectrum Disorder Therapy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by the 38th AAAI 2024 workshop: "Cooperative Multi-Agent Systems Decision-Making and Learning: From Individual Needs to Swarm Intelligence"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In recent years, edge computing has served as a paradigm that enables many
future technologies like AI, Robotics, IoT, and high-speed wireless sensor
networks (like 5G) by connecting cloud computing facilities and services to the
end users. Especially in medical and healthcare applications, it provides
remote patient monitoring and increases voluminous multimedia. From the
robotics angle, robot-assisted therapy (RAT) is an active-assistive robotic
technology in rehabilitation robotics, attracting many researchers to study and
benefit people with disability like autism spectrum disorder (ASD) children.
However, the main challenge of RAT is that the model capable of detecting the
affective states of ASD people exists and can recall individual preferences.
Moreover, involving expert diagnosis and recommendations to guide robots in
updating the therapy approach to adapt to different statuses and scenarios is a
crucial part of the ASD therapy process. This paper proposes the architecture
of edge cognitive computing by combining human experts and assisted robots
collaborating in the same framework to help ASD patients with long-term
support. By integrating the real-time computing and analysis of a new cognitive
robotic model for ASD therapy, the proposed architecture can achieve a seamless
remote diagnosis, round-the-clock symptom monitoring, emergency warning,
therapy alteration, and advanced assistance.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00778" title="Abstract">arXiv:2401.00778</a> [<a href="/pdf/2401.00778" title="Download PDF">pdf</a>, <a href="/ps/2401.00778" title="Download PostScript">ps</a>, <a href="/format/2401.00778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence analysis of Lawson&#x27;s iteration for the polynomial and  rational minimax approximations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+L">Lei-Hong Zhang</a>, 
<a href="/search/math?searchtype=author&query=Han%2C+S">Shanheng Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Lawson's iteration is a classical and effective method for solving the linear
(polynomial) minimax approximation in the complex plane. Extension of Lawson's
iteration for the rational minimax approximation with both computationally high
efficiency and theoretical guarantee is challenging. A recent work [L.-H.
Zhang, L. Yang, W. H. Yang and Y.-N. Zhang, A convex dual programming for the
rational minimax approximation and Lawson's iteration, 2023,
arxiv.org/pdf/2308.06991v1] reveals that Lawson's iteration can be viewed as a
method for solving the dual problem of the original rational minimax
approximation, and a new type of Lawson's iteration was proposed. Such a dual
problem is guaranteed to obtain the original minimax solution under Ruttan's
sufficient condition, and numerically, the proposed Lawson's iteration was
observed to converge monotonically with respect to the dual objective function.
In this paper, we perform theoretical convergence analysis for Lawson's
iteration for both the linear and rational minimax approximations. In
particular, we show that (i) for the linear minimax approximation, the
near-optimal Lawson exponent $\beta$ in Lawson's iteration is $\beta=1$, and
(ii) for the rational minimax approximation, the proposed Lawson's iteration
converges monotonically with respect to the dual objective function for any
sufficiently small $\beta&gt;0$, and the convergent solution fulfills the
complementary slackness: all nodes associated with positive weights achieve the
maximum error.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00779" title="Abstract">arXiv:2401.00779</a> [<a href="/pdf/2401.00779" title="Download PDF">pdf</a>, <a href="/format/2401.00779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Validity Change Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wenzel%2C+G">Georg Wenzel</a>, 
<a href="/search/cs?searchtype=author&query=Jatowt%2C+A">Adam Jatowt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Temporal validity is an important property of text that is useful for many
downstream applications, such as recommender systems, conversational AI, or
story understanding. Existing benchmarking tasks often require models to
identify the temporal validity duration of a single statement. However, in many
cases, additional contextual information, such as sentences in a story or posts
on a social media profile, can be collected from the available text stream.
This contextual information may greatly alter the duration for which a
statement is expected to be valid. We propose Temporal Validity Change
Prediction, a natural language processing task benchmarking the capability of
machine learning models to detect contextual statements that induce such
change. We create a dataset consisting of temporal target statements sourced
from Twitter and crowdsource sample context statements. We then benchmark a set
of transformer-based language models on our dataset. Finally, we experiment
with temporal validity duration prediction as an auxiliary task to improve the
performance of the state-of-the-art model.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00781" title="Abstract">arXiv:2401.00781</a> [<a href="/pdf/2401.00781" title="Download PDF">pdf</a>, <a href="/ps/2401.00781" title="Download PostScript">ps</a>, <a href="/format/2401.00781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Heterogeneous Treatment Effects of Crashes on Highway Traffic:  A Doubly Robust Causal Machine Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Z">Ziyuan Pu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhiyong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seunghyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiucheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ngoduy%2C+D">Dong Ngoduy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 13 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Highway traffic crashes exert a considerable impact on both transportation
systems and the economy. In this context, accurate and dependable emergency
responses are crucial for effective traffic management. However, the influence
of crashes on traffic status varies across diverse factors and may be biased
due to selection bias. Therefore, there arises a necessity to accurately
estimate the heterogeneous causal effects of crashes, thereby providing
essential insights to facilitate individual-level emergency decision-making.
This paper proposes a novel causal machine learning framework to estimate the
causal effect of different types of crashes on highway speed. The Neyman-Rubin
Causal Model (RCM) is employed to formulate this problem from a causal
perspective. The Conditional Shapley Value Index (CSVI) is proposed based on
causal graph theory to filter adverse variables, and the Structural Causal
Model (SCM) is then adopted to define the statistical estimand for causal
effects. The treatment effects are estimated by Doubly Robust Learning (DRL)
methods, which combine doubly robust causal inference with classification and
regression machine learning models. Experimental results from 4815 crashes on
Highway Interstate 5 in Washington State reveal the heterogeneous treatment
effects of crashes at varying distances and durations. The rear-end crashes
cause more severe congestion and longer durations than other types of crashes,
and the sideswipe crashes have the longest delayed impact. Additionally, the
findings show that rear-end crashes affect traffic greater at night, while
crash to objects has the most significant influence during peak hours.
Statistical hypothesis tests, error metrics based on matched "counterfactual
outcomes", and sensitive analyses are employed for assessment, and the results
validate the accuracy and effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00788" title="Abstract">arXiv:2401.00788</a> [<a href="/pdf/2401.00788" title="Download PDF">pdf</a>, <a href="/format/2401.00788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Astraios: Parameter-Efficient Instruction Tuning Code Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+T+Y">Terry Yue Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Zebaze%2C+A">Armel Zebaze</a>, 
<a href="/search/cs?searchtype=author&query=Suppattarachai%2C+N">Nitchakarn Suppattarachai</a>, 
<a href="/search/cs?searchtype=author&query=von+Werra%2C+L">Leandro von Werra</a>, 
<a href="/search/cs?searchtype=author&query=de+Vries%2C+H">Harm de Vries</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Muennighoff%2C+N">Niklas Muennighoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages (12 main), 19 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">The high cost of full-parameter fine-tuning (FFT) of Large Language Models
(LLMs) has led to a series of parameter-efficient fine-tuning (PEFT) methods.
However, it remains unclear which methods provide the best cost-performance
trade-off at different model scales. We introduce Astraios, a suite of 28
instruction-tuned OctoCoder models using 7 tuning methods and 4 model sizes up
to 16 billion parameters. Through investigations across 5 tasks and 8 different
datasets encompassing both code comprehension and code generation tasks, we
find that FFT generally leads to the best downstream performance across all
scales, and PEFT methods differ significantly in their efficacy based on the
model scale. LoRA usually offers the most favorable trade-off between cost and
performance. Further investigation into the effects of these methods on both
model robustness and code security reveals that larger models tend to
demonstrate reduced robustness and less security. At last, we explore the
relationships among updated parameters, cross-entropy loss, and task
performance. We find that the tuning effectiveness observed in small models
generalizes well to larger models, and the validation loss in instruction
tuning can be a reliable indicator of overall downstream performance.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00789" title="Abstract">arXiv:2401.00789</a> [<a href="/pdf/2401.00789" title="Download PDF">pdf</a>, <a href="/format/2401.00789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Augmented Egocentric Video Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jilan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yifei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junlin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuejie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Rui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding human actions from videos of first-person view poses
significant challenges. Most prior approaches explore representation learning
on egocentric videos only, while overlooking the potential benefit of
exploiting existing large-scale third-person videos. In this paper, (1) we
develop EgoInstructor, a retrieval-augmented multimodal captioning model that
automatically retrieves semantically relevant third-person instructional videos
to enhance the video captioning of egocentric videos. (2) For training the
cross-view retrieval module, we devise an automatic pipeline to discover
ego-exo video pairs from distinct large-scale egocentric and exocentric
datasets. (3) We train the cross-view retrieval module with a novel EgoExoNCE
loss that pulls egocentric and exocentric video features closer by aligning
them to shared text features that describe similar actions. (4) Through
extensive experiments, our cross-view retrieval module demonstrates superior
performance across seven benchmarks. Regarding egocentric video captioning,
EgoInstructor exhibits significant improvements by leveraging third-person
videos as references.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00793" title="Abstract">arXiv:2401.00793</a> [<a href="/pdf/2401.00793" title="Download PDF">pdf</a>, <a href="/format/2401.00793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jinglong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yehong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xin Mu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12pages, 15figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">With the growing use of large language models hosted on cloud platforms to
offer inference services, privacy concerns are escalating, especially
concerning sensitive data like investment plans and bank account details.
Secure Multi-Party Computing (SMPC) emerges as a promising solution to protect
the privacy of inference data and model parameters. However, the application of
SMPC in Privacy-Preserving Inference (PPI) for large language models,
particularly those based on the Transformer architecture, often leads to
considerable slowdowns or declines in performance. This is largely due to the
multitude of nonlinear operations in the Transformer architecture, which are
not well-suited to SMPC and are difficult to circumvent or optimize
effectively. To address this concern, we introduce an advanced optimization
framework called SecFormer, designed to strike an optimal balance between
performance and efficiency in PPI for Transformer models. By implementing
knowledge distillation techniques, we successfully eliminate the high-cost
exponential and maximum operations in PPI without sacrificing model
performance. Additionally, we have developed a suite of efficient SMPC
protocols that utilize segmented polynomials and Goldschmidt's method to handle
other complex nonlinear functions within PPI, such as GeLU, LayerNorm, and
Softmax. Our extensive experiments reveal that SecFormer outperforms MPCFormer
in performance, showing improvements of $5.6\%$ and $24.2\%$ for
BERT$_{\text{BASE}}$ and BERT$_{\text{LARGE}}$, respectively. In terms of
efficiency, SecFormer is 3.4 and 3.2 times faster than Puma, demonstrating its
effectiveness and speed.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00794" title="Abstract">arXiv:2401.00794</a> [<a href="/pdf/2401.00794" title="Download PDF">pdf</a>, <a href="/ps/2401.00794" title="Download PostScript">ps</a>, <a href="/format/2401.00794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Data in IoT-based Cloud Systems: A Comprehensive  Survey with AI Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhinakaran%2C+D">D. Dhinakaran</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+S+M+U">S.M. Udhaya Sankar</a>, 
<a href="/search/cs?searchtype=author&query=Selvaraj%2C+D">D. Selvaraj</a>, 
<a href="/search/cs?searchtype=author&query=Raja%2C+S+E">S. Edwin Raja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As the integration of Internet of Things devices with cloud computing
proliferates, the paramount importance of privacy preservation comes to the
forefront. This survey paper meticulously explores the landscape of privacy
issues in the dynamic intersection of IoT and cloud systems. The comprehensive
literature review synthesizes existing research, illuminating key challenges
and discerning emerging trends in privacy preserving techniques. The
categorization of diverse approaches unveils a nuanced understanding of
encryption techniques, anonymization strategies, access control mechanisms, and
the burgeoning integration of artificial intelligence. Notable trends include
the infusion of machine learning for dynamic anonymization, homomorphic
encryption for secure computation, and AI-driven access control systems. The
culmination of this survey contributes a holistic view, laying the groundwork
for understanding the multifaceted strategies employed in securing sensitive
data within IoT-based cloud environments. The insights garnered from this
survey provide a valuable resource for researchers, practitioners, and
policymakers navigating the complex terrain of privacy preservation in the
evolving landscape of IoT and cloud computing
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00797" title="Abstract">arXiv:2401.00797</a> [<a href="/pdf/2401.00797" title="Download PDF">pdf</a>, <a href="/format/2401.00797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distillation is All You Need for Practically Using Different Pre-trained  Recommendation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Ruobing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Leyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Pre-trained recommendation models (PRMs) have attracted widespread attention
recently. However, their totally different model structure, huge model size and
computation cost hinder their application in practical recommender systems.
Hence, it is highly essential to explore how to practically utilize PRMs in
real-world recommendations. In this paper, we propose a novel joint knowledge
distillation from different pre-trained recommendation models named PRM-KD for
recommendation, which takes full advantages of diverse PRMs as teacher models
for enhancing student models efficiently. Specifically, PRM-KD jointly distills
diverse informative knowledge from multiple representative PRMs such as
UniSRec, Recformer, and UniM^2Rec. The knowledge from the above PRMs are then
smartly integrated into the student recommendation model considering their
confidence and consistency. We further verify the universality of PRM-KD with
various types of student models, including sequential recommendation, feature
interaction, and graph-based models. Extensive experiments on five real-world
datasets demonstrate the effectiveness and efficacy of PRM-KD, which could be
viewed as an economical shortcut in practically and conveniently making full
use of different PRMs in online systems.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00806" title="Abstract">arXiv:2401.00806</a> [<a href="/pdf/2401.00806" title="Download PDF">pdf</a>, <a href="/format/2401.00806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise-Aware and Equitable Urban Air Traffic Management: An Optimization  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gao%2C+Z">Zhenyu Gao</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+Q">Qinshuang Wei</a>, 
<a href="/search/eess?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>, 
<a href="/search/eess?searchtype=author&query=Clarke%2C+J">John-Paul Clarke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Urban air mobility (UAM), a transformative concept for the transport of
passengers and cargo, faces several integration challenges in complex urban
environments. Community acceptance of aircraft noise is among the most
noticeable of these challenges when launching or scaling up a UAM system.
Properly managing community noise is fundamental to establishing a UAM system
that is environmentally and socially sustainable. In this work, we develop a
holistic and equitable approach to manage UAM air traffic and its community
noise impact in urban environments. The proposed approach is a hybrid approach
that considers a mix of different noise mitigation strategies, including
limiting the number of operations, cruising at higher altitudes, and ambient
noise masking. We tackle the problem through the lens of network system control
and formulate a multi-objective optimization model for managing traffic flow in
a multi-layer UAM network while concurrently pursuing demand fulfillment, noise
control, and energy saving. Further, we use a social welfare function in the
optimization model as the basis for the efficiency-fairness trade-off in both
demand fulfillment and noise control. We apply the proposed approach to a
comprehensive case study in the city of Austin and perform design trade-offs
through both visual and quantitative analyses.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00809" title="Abstract">arXiv:2401.00809</a> [<a href="/pdf/2401.00809" title="Download PDF">pdf</a>, <a href="/format/2401.00809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review on different techniques used to combat the non-IID and  heterogeneous nature of data in FL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iyer%2C+V+N">Venkataraman Natarajan Iyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated Learning (FL) is a machine-learning approach enabling collaborative
model training across multiple decentralized edge devices that hold local data
samples, all without exchanging these samples. This collaborative process
occurs under the supervision of a central server orchestrating the training or
via a peer-to-peer network. The significance of FL is particularly pronounced
in industries such as healthcare and finance, where data privacy holds
paramount importance. However, training a model under the Federated learning
setting brings forth several challenges, with one of the most prominent being
the heterogeneity of data distribution among the edge devices. The data is
typically non-independently and non-identically distributed (non-IID), thereby
presenting challenges to model convergence. This report delves into the issues
arising from non-IID and heterogeneous data and explores current algorithms
designed to address these challenges.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00811" title="Abstract">arXiv:2401.00811</a> [<a href="/pdf/2401.00811" title="Download PDF">pdf</a>, <a href="/format/2401.00811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PerSHOP -- A Persian dataset for shopping dialogue systems modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmoudi%2C+K">Keyvan Mahmoudi</a>, 
<a href="/search/cs?searchtype=author&query=Faili%2C+H">Heshaam Faili</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Nowadays, dialogue systems are used in many fields of industry and research.
There are successful instances of these systems, such as Apple Siri, Google
Assistant, and IBM Watson. Task-oriented dialogue system is a category of
these, that are used in specific tasks. They can perform tasks such as booking
plane tickets or making restaurant reservations. Shopping is one of the most
popular areas on these systems. The bot replaces the human salesperson and
interacts with the customers by speaking. To train the models behind the scenes
of these systems, annotated data is needed. In this paper, we developed a
dataset of dialogues in the Persian language through crowd-sourcing. We
annotated these dialogues to train a model. This dataset contains nearly 22k
utterances in 15 different domains and 1061 dialogues. This is the largest
Persian dataset in this field, which is provided freely so that future
researchers can use it. Also, we proposed some baseline models for natural
language understanding (NLU) tasks. These models perform two tasks for NLU:
intent classification and entity extraction. The F-1 score metric obtained for
intent classification is around 91% and for entity extraction is around 93%,
which can be a baseline for future research.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00812" title="Abstract">arXiv:2401.00812</a> [<a href="/pdf/2401.00812" title="Download PDF">pdf</a>, <a href="/format/2401.00812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code  Empowers Large Language Models to Serve as Intelligent Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Ke Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiateng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">John Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chaoqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+Y+R">Yi R. Fung</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sha Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiquan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+C">Chengxiang Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The prominent large language models (LLMs) of today differ from past language
models not only in size, but also in the fact that they are trained on a
combination of natural language and formal language (code). As a medium between
humans and computers, code translates high-level goals into executable steps,
featuring standard syntax, logical consistency, abstraction, and modularity. In
this survey, we present an overview of the various benefits of integrating code
into LLMs' training data. Specifically, beyond enhancing LLMs in code
generation, we observe that these unique properties of code help (i) unlock the
reasoning ability of LLMs, enabling their applications to a range of more
complex natural language tasks; (ii) steer LLMs to produce structured and
precise intermediate steps, which can then be connected to external execution
ends through function calls; and (iii) take advantage of code compilation and
execution environment, which also provides diverse feedback for model
improvement. In addition, we trace how these profound capabilities of LLMs,
brought by code, have led to their emergence as intelligent agents (IAs) in
situations where the ability to understand instructions, decompose goals, plan
and execute actions, and refine from feedback are crucial to their success on
downstream tasks. Finally, we present several key challenges and future
directions of empowering LLMs with code.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00814" title="Abstract">arXiv:2401.00814</a> [<a href="/pdf/2401.00814" title="Download PDF">pdf</a>, <a href="/format/2401.00814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agricultural 4.0 Leveraging on Technological Solutions: Study for Smart  Farming Sector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gyamfi%2C+E+K">Emmanuel Kojo Gyamfi</a>, 
<a href="/search/cs?searchtype=author&query=ElSayed%2C+Z">Zag ElSayed</a>, 
<a href="/search/cs?searchtype=author&query=Kropczynski%2C+J">Jess Kropczynski</a>, 
<a href="/search/cs?searchtype=author&query=Yakubu%2C+M+A">Mustapha Awinsongya Yakubu</a>, 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+N">Nelly Elsayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, under reviewing process
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">By 2050, it is predicted that there will be 9 billion people on the planet,
which will call for more production, lower costs, and the preservation of
natural resources. It is anticipated that atypical occurrences and climate
change will pose severe risks to agricultural output. It follows that a 70% or
more significant rise in food output is anticipated. Smart farming, often known
as agriculture 4.0, is a tech-driven revolution in agriculture with the goal of
raising industry production and efficiency. Four primary trends are responsible
for it: food waste, climate change, population shifts, and resource scarcity.
The agriculture industry is changing as a result of the adoption of emerging
technologies. Using cutting-edge technology like IoT, AI, and other sensors,
smart farming transforms traditional production methods and international
agricultural policies. The objective is to establish a value chain that is
optimized to facilitate enhanced monitoring and decreased labor expenses. The
agricultural sector has seen tremendous transformation as a result of the
fourth industrial revolution, which has combined traditional farming methods
with cutting-edge technology to increase productivity, sustainability, and
efficiency. To effectively utilize the potential of technology gadgets in the
agriculture sector, collaboration between governments, private sector entities,
and other stakeholders is necessary. This paper covers Agriculture 4.0, looks
at its possible benefits and drawbacks of the implementation methodologies,
compatibility, reliability, and investigates the several digital tools that are
being utilized to change the agriculture industry and how to mitigate the
challenges.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00816" title="Abstract">arXiv:2401.00816</a> [<a href="/pdf/2401.00816" title="Download PDF">pdf</a>, <a href="/format/2401.00816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLIMPSE: Generalized Local Imaging with MLPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khorashadizadeh%2C+A">AmirEhsan Khorashadizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Debarnot%2C+V">Valentin Debarnot</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianlin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dokmani%C4%87%2C+I">Ivan Dokmani&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Deep learning is the current de facto state of the art in tomographic
imaging. A common approach is to feed the result of a simple inversion, for
example the backprojection, to a convolutional neural network (CNN) which then
computes the reconstruction. Despite strong results on 'in-distribution' test
data similar to the training data, backprojection from sparse-view data
delocalizes singularities, so these approaches require a large receptive field
to perform well. As a consequence, they overfit to certain global structures
which leads to poor generalization on out-of-distribution (OOD) samples.
Moreover, their memory complexity and training time scale unfavorably with
image resolution, making them impractical for application at realistic clinical
resolutions, especially in 3D: a standard U-Net requires a substantial 140GB of
memory and 2600 seconds per epoch on a research-grade GPU when training on
1024x1024 images. In this paper, we introduce GLIMPSE, a local processing
neural network for computed tomography which reconstructs a pixel value by
feeding only the measurements associated with the neighborhood of the pixel to
a simple MLP. While achieving comparable or better performance with successful
CNNs like the U-Net on in-distribution test data, GLIMPSE significantly
outperforms them on OOD samples while maintaining a memory footprint almost
independent of image resolution; 5GB memory suffices to train on 1024x1024
images. Further, we built GLIMPSE to be fully differentiable, which enables
feats such as recovery of accurate projection angles if they are out of
calibration.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00819" title="Abstract">arXiv:2401.00819</a> [<a href="/pdf/2401.00819" title="Download PDF">pdf</a>, <a href="/format/2401.00819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Beamforming Through Joint Phase-Time Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yildiz%2C+O">Ozlem Yildiz</a>, 
<a href="/search/cs?searchtype=author&query=AlAmmouri%2C+A">Ahmad AlAmmouri</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+J">Jianhua Mo</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+Y">Younghan Nam</a>, 
<a href="/search/cs?searchtype=author&query=Erkip%2C+E">Elza Erkip</a>, 
<a href="/search/cs?searchtype=author&query=Jianzhong">Jianzhong</a> (Charlie)
<a href="/search/cs?searchtype=author&query=Zhang">Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">High-frequency wide-bandwidth cellular communications over mmW and sub-THz
offer the opportunity for high data rates, however, it also presents high
pathloss, resulting in limited coverage. To mitigate the coverage limitations,
high-gain beamforming is essential. Implementation of beamforming involves a
large number of antennas, which introduces analog beam constraint, i.e., only
one frequency-flat beam is generated per transceiver chain (TRx). Recently
introduced joint phase-time array (JPTA) architecture, which utilizes both true
time delay (TTD) units and phase shifters (PSs), alleviates analog beam
constraint by creating multiple frequency-dependent beams per TRx, for
scheduling multiple users at different directions in a frequency-division
manner. One class of previous studies offered solutions with "rainbow" beams,
which tend to allocate a small bandwidth per beam direction. Another class
focused on uniform linear array (ULA) antenna architecture, whose
frequency-dependent beams were designed along a single axis of either azimuth
or elevation direction. In this paper, we present a novel 3D beamforming
codebook design aimed at maximizing beamforming gain to steer radiation toward
desired azimuth and elevation directions, as well as across sub-bands
partitioned according to scheduled users' bandwidth requirements. We provide
both analytical solutions and iterative algorithms to design the PSs and TTD
units for a desired subband beam pattern. Through simulations of the
beamforming gain, we observe that our proposed solutions outperform the
state-of-the-art solutions reported elsewhere.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00820" title="Abstract">arXiv:2401.00820</a> [<a href="/pdf/2401.00820" title="Download PDF">pdf</a>, <a href="/format/2401.00820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Computational Framework for Behavioral Assessment of LLM Therapists
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiu%2C+Y+Y">Yu Ying Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Ashish Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+I+W">Inna Wanyin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+T">Tim Althoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The emergence of ChatGPT and other large language models (LLMs) has greatly
increased interest in utilizing LLMs as therapists to support individuals
struggling with mental health challenges. However, due to the lack of
systematic studies, our understanding of how LLM therapists behave, i.e., ways
in which they respond to clients, is significantly limited. Understanding their
behavior across a wide range of clients and situations is crucial to accurately
assess their capabilities and limitations in the high-risk setting of mental
health, where undesirable behaviors can lead to severe consequences. In this
paper, we propose BOLT, a novel computational framework to study the
conversational behavior of LLMs when employed as therapists. We develop an
in-context learning method to quantitatively measure the behavior of LLMs based
on 13 different psychotherapy techniques including reflections, questions,
solutions, normalizing, and psychoeducation. Subsequently, we compare the
behavior of LLM therapists against that of high- and low-quality human therapy,
and study how their behavior can be modulated to better reflect behaviors
observed in high-quality therapy. Our analysis of GPT and Llama-variants
reveals that these LLMs often resemble behaviors more commonly exhibited in
low-quality therapy rather than high-quality therapy, such as offering a higher
degree of problem-solving advice when clients share emotions, which is against
typical recommendations. At the same time, unlike low-quality therapy, LLMs
reflect significantly more upon clients' needs and strengths. Our analysis
framework suggests that despite the ability of LLMs to generate anecdotal
examples that appear similar to human therapists, LLM therapists are currently
not fully consistent with high-quality care, and thus require additional
research to ensure quality care.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00824" title="Abstract">arXiv:2401.00824</a> [<a href="/pdf/2401.00824" title="Download PDF">pdf</a>, <a href="/format/2401.00824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-Convolutional Autoencoder Ensembles for the Humanities,  Illustrated with a Study of the American Slave Trade
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lippincott%2C+T">Tom Lippincott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> More in-depth technical companion to "A general neural ensemble technique to support traditional scholarship", Digital Humanities 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We introduce a graph-aware autoencoder ensemble framework, with associated
formalisms and tooling, designed to facilitate deep learning for scholarship in
the humanities. By composing sub-architectures to produce a model isomorphic to
a humanistic domain we maintain interpretability while providing function
signatures for each sub-architectural choice, allowing both traditional and
computational researchers to collaborate without disrupting established
practices. We illustrate a practical application of our approach to a
historical study of the American post-Atlantic slave trade, and make several
specific technical contributions: a novel hybrid graph-convolutional
autoencoder mechanism, batching policies for common graph topologies, and
masking techniques for particular use-cases. The effectiveness of the framework
for broadening participation of diverse domains is demonstrated by a growing
suite of two dozen studies, both collaborations with humanists and established
tasks from machine learning literature, spanning a variety of fields and data
modalities. We make performance comparisons of several different architectural
choices and conclude with an ambitious list of imminent next steps for this
research.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00825" title="Abstract">arXiv:2401.00825</a> [<a href="/pdf/2401.00825" title="Download PDF">pdf</a>, <a href="/format/2401.00825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp-NeRF: Grid-based Fast Deblurring Neural Radiance Fields Using  Sharpness Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byeonghyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Howoong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+U">Usman Ali</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E">Eunbyung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Neural Radiance Fields (NeRF) have shown remarkable performance in neural
rendering-based novel view synthesis. However, NeRF suffers from severe visual
quality degradation when the input images have been captured under imperfect
conditions, such as poor illumination, defocus blurring, and lens aberrations.
Especially, defocus blur is quite common in the images when they are normally
captured using cameras. Although few recent studies have proposed to render
sharp images of considerably high-quality, yet they still face many key
challenges. In particular, those methods have employed a Multi-Layer Perceptron
(MLP) based NeRF, which requires tremendous computational time. To overcome
these shortcomings, this paper proposes a novel technique Sharp-NeRF -- a
grid-based NeRF that renders clean and sharp images from the input blurry
images within half an hour of training. To do so, we used several grid-based
kernels to accurately model the sharpness/blurriness of the scene. The
sharpness level of the pixels is computed to learn the spatially varying blur
kernels. We have conducted experiments on the benchmarks consisting of blurry
images and have evaluated full-reference and non-reference metrics. The
qualitative and quantitative results have revealed that our approach renders
the sharp novel views with vivid colors and fine details, and it has
considerably faster training time than the previous works. Our project page is
available at https://benhenryl.github.io/SharpNeRF/
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00828" title="Abstract">arXiv:2401.00828</a> [<a href="/pdf/2401.00828" title="Download PDF">pdf</a>, <a href="/format/2401.00828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Lattice Sampling of Quantum Field Theories via Neural Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%A1t%C3%A9%2C+B">B&#xe1;lint M&#xe1;t&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Fleuret%2C+F">Fran&#xe7;ois Fleuret</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; High Energy Physics - Lattice (hep-lat); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of sampling discrete field configurations $\phi$ from
the Boltzmann distribution $[d\phi] Z^{-1} e^{-S[\phi]}$, where $S$ is the
lattice-discretization of the continuous Euclidean action $\mathcal S$ of some
quantum field theory. Since such densities arise as the approximation of the
underlying functional density $[\mathcal D\phi(x)] \mathcal Z^{-1} e^{-\mathcal
S[\phi(x)]}$, we frame the task as an instance of operator learning. In
particular, we propose to approximate a time-dependent operator $\mathcal V_t$
whose time integral provides a mapping between the functional distributions of
the free theory $[\mathcal D\phi(x)] \mathcal Z_0^{-1} e^{-\mathcal
S_{0}[\phi(x)]}$ and of the target theory $[\mathcal D\phi(x)]\mathcal
Z^{-1}e^{-\mathcal S[\phi(x)]}$. Whenever a particular lattice is chosen, the
operator $\mathcal V_t$ can be discretized to a finite dimensional,
time-dependent vector field $V_t$ which in turn induces a continuous
normalizing flow between finite dimensional distributions over the chosen
lattice. This flow can then be trained to be a diffeormorphism between the
discretized free and target theories $[d\phi] Z_0^{-1} e^{-S_{0}[\phi]}$,
$[d\phi] Z^{-1}e^{-S[\phi]}$. We run experiments on the $\phi^4$-theory to
explore to what extent such operator-based flow architectures generalize to
lattice sizes they were not trained on and show that pretraining on smaller
lattices can lead to speedup over training only a target lattice size.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00830" title="Abstract">arXiv:2401.00830</a> [<a href="/pdf/2401.00830" title="Download PDF">pdf</a>, <a href="/format/2401.00830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Socially Compliant Control of Autonomous Vehicles with Application to  Eco-Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shian Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Control design of autonomous vehicles (AVs) has mostly focused on achieving a
prespecified goal for an individually controlled AV or for a swarm of
cooperatively controlled AVs. However, the impact of autonomous driving on
human-driven vehicles (HVs) has been largely ignored in AV controller
synthesis, which could result in egoistic AV behavior detrimental to the safety
of passengers and surrounding traffic. In this study we develop a general
framework for socially compliant control design of AVs with a useful metric of
social psychology, called social value orientation (SVO), allowing AVs to
leverage their impact on the behavior of the following HVs. This is critical
since AVs that behave in a socially compliant manner enable human drivers to
comprehend their actions and respond appropriately. Within the proposed
framework, we define the utilities of the controlled AV and its following
vehicle, to be maximized in a weighted fashion determined by the AV's SVO. The
utility maximization covers an array of design objectives given the goal of the
AV and the benefits for the following HV stemming from the courtesy of socially
compliant AV controls. An optimal control problem is then formulated to
maximize the utility function defined, which is numerically solved using
Pontryagin's minimum principle with optimality guarantees. The methodology
developed is applied to synthesize socially compliant control for eco-driving
of AVs. A set of numerical results are presented to show the mechanism and
effectiveness of the proposed approach using real-world experimental data
collected on Highway 55 in Minnesota.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00832" title="Abstract">arXiv:2401.00832</a> [<a href="/pdf/2401.00832" title="Download PDF">pdf</a>, <a href="/format/2401.00832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking the Next Step with Generative Artificial Intelligence: The  Transformative Role of Multimodal Large Language Models in Science Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bewersdorff%2C+A">Arne Bewersdorff</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+C">Christian Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Hornberger%2C+M">Marie Hornberger</a>, 
<a href="/search/cs?searchtype=author&query=Se%C3%9Fler%2C+K">Kathrin Se&#xdf;ler</a>, 
<a href="/search/cs?searchtype=author&query=Bannert%2C+M">Maria Bannert</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+E">Enkelejda Kasneci</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+G">Gjergji Kasneci</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Nerdel%2C+C">Claudia Nerdel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The integration of Artificial Intelligence (AI), particularly Large Language
Model (LLM)-based systems, in education has shown promise in enhancing teaching
and learning experiences. However, the advent of Multimodal Large Language
Models (MLLMs) like GPT-4 with vision (GPT-4V), capable of processing
multimodal data including text, sound, and visual inputs, opens a new era of
enriched, personalized, and interactive learning landscapes in education.
Grounded in theory of multimedia learning, this paper explores the
transformative role of MLLMs in central aspects of science education by
presenting exemplary innovative learning scenarios. Possible applications for
MLLMs could range from content creation to tailored support for learning,
fostering competencies in scientific practices, and providing assessment and
feedback. These scenarios are not limited to text-based and uni-modal formats
but can be multimodal, increasing thus personalization, accessibility, and
potential learning effectiveness. Besides many opportunities, challenges such
as data protection and ethical considerations become more salient, calling for
robust frameworks to ensure responsible integration. This paper underscores the
necessity for a balanced approach in implementing MLLMs, where the technology
complements rather than supplants the educator's role, ensuring thus an
effective and ethical use of AI in science education. It calls for further
research to explore the nuanced implications of MLLMs on the evolving role of
educators and to extend the discourse beyond science education to other
disciplines. Through the exploration of potentials, challenges, and future
implications, we aim to contribute to a preliminary understanding of the
transformative trajectory of MLLMs in science education and beyond.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00833" title="Abstract">arXiv:2401.00833</a> [<a href="/pdf/2401.00833" title="Download PDF">pdf</a>, <a href="/format/2401.00833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking RAFT for Efficient Optical Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eslami%2C+N">Navid Eslami</a>, 
<a href="/search/cs?searchtype=author&query=Arefi%2C+F">Farnoosh Arefi</a>, 
<a href="/search/cs?searchtype=author&query=Mansourian%2C+A+M">Amir M. Mansourian</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+S">Shohreh Kasaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite significant progress in deep learning-based optical flow methods,
accurately estimating large displacements and repetitive patterns remains a
challenge. The limitations of local features and similarity search patterns
used in these algorithms contribute to this issue. Additionally, some existing
methods suffer from slow runtime and excessive graphic memory consumption. To
address these problems, this paper proposes a novel approach based on the RAFT
framework. The proposed Attention-based Feature Localization (AFL) approach
incorporates the attention mechanism to handle global feature extraction and
address repetitive patterns. It introduces an operator for matching pixels with
corresponding counterparts in the second frame and assigning accurate flow
values. Furthermore, an Amorphous Lookup Operator (ALO) is proposed to enhance
convergence speed and improve RAFTs ability to handle large displacements by
reducing data redundancy in its search operator and expanding the search space
for similarity extraction. The proposed method, Efficient RAFT
(Ef-RAFT),achieves significant improvements of 10% on the Sintel dataset and 5%
on the KITTI dataset over RAFT. Remarkably, these enhancements are attained
with a modest 33% reduction in speed and a mere 13% increase in memory usage.
The code is available at: https://github.com/n3slami/Ef-RAFT
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00834" title="Abstract">arXiv:2401.00834</a> [<a href="/pdf/2401.00834" title="Download PDF">pdf</a>, <a href="/format/2401.00834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deblurring 3D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byeonghyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Howoong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+U">Usman Ali</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E">Eunbyung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent studies in Radiance Fields have paved the robust way for novel view
synthesis with their photorealistic rendering quality. Nevertheless, they
usually employ neural networks and volumetric rendering, which are costly to
train and impede their broad use in various real-time applications due to the
lengthy rendering time. Lately 3D Gaussians splatting-based approach has been
proposed to model the 3D scene, and it achieves remarkable visual quality while
rendering the images in real-time. However, it suffers from severe degradation
in the rendering quality if the training images are blurry. Blurriness commonly
occurs due to the lens defocusing, object motion, and camera shake, and it
inevitably intervenes in clean image acquisition. Several previous studies have
attempted to render clean and sharp images from blurry input images using
neural fields. The majority of those works, however, are designed only for
volumetric rendering-based neural radiance fields and are not straightforwardly
applicable to rasterization-based 3D Gaussian splatting methods. Thus, we
propose a novel real-time deblurring framework, deblurring 3D Gaussian
Splatting, using a small Multi-Layer Perceptron (MLP) that manipulates the
covariance of each 3D Gaussian to model the scene blurriness. While deblurring
3D Gaussian Splatting can still enjoy real-time rendering, it can reconstruct
fine and sharp details from blurry images. A variety of experiments have been
conducted on the benchmark, and the results have revealed the effectiveness of
our approach for deblurring. Qualitative results are available at
https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00847" title="Abstract">arXiv:2401.00847</a> [<a href="/pdf/2401.00847" title="Download PDF">pdf</a>, <a href="/format/2401.00847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mocap Everyone Everywhere: Lightweight Motion Capture With Smartwatches  and a Head-Mounted Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jiye Lee</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+H">Hanbyul Joo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://jiyewise.github.io/projects/MocapEvery/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present a lightweight and affordable motion capture method based on two
smartwatches and a head-mounted camera. In contrast to the existing approaches
that use six or more expert-level IMU devices, our approach is much more
cost-effective and convenient. Our method can make wearable motion capture
accessible to everyone everywhere, enabling 3D full-body motion capture in
diverse environments. As a key idea to overcome the extreme sparsity and
ambiguities of sensor inputs, we integrate 6D head poses obtained from the
head-mounted cameras for motion estimation. To enable capture in expansive
indoor and outdoor scenes, we propose an algorithm to track and update floor
level changes to define head poses, coupled with a multi-stage
Transformer-based regression module. We also introduce novel strategies
leveraging visual cues of egocentric images to further enhance the motion
capture quality while reducing ambiguities. We demonstrate the performance of
our method on various challenging scenarios, including complex outdoor
environments and everyday motions including object interactions and social
interactions among multiple individuals.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00849" title="Abstract">arXiv:2401.00849</a> [<a href="/pdf/2401.00849" title="Download PDF">pdf</a>, <a href="/format/2401.00849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COSMO: COntrastive Streamlined MultimOdal Model with Interleaved  Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A+J">Alex Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K+Q">Kevin Qinghong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages; Website: <a href="http://fingerrec.github.io/cosmo">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the evolution of Vision-Language Pre-training, shifting from short-text
comprehension to encompassing extended textual contexts is pivotal. Recent
autoregressive vision-language models like \cite{flamingo, palme}, leveraging
the long-context capability of Large Language Models, have excelled in few-shot
text generation tasks but face challenges in alignment tasks. Addressing this
gap, we introduce the contrastive loss into text generation models, presenting
the COntrastive-Streamlined MultimOdal framework (\ModelName), strategically
partitioning the language model into dedicated unimodal text processing and
adept multimodal data handling components. \ModelName, our unified framework,
merges unimodal and multimodal elements, enhancing model performance for tasks
involving textual and visual data while notably reducing learnable parameters.
However, these models demand extensive long-text datasets, yet the availability
of high-quality long-text video datasets remains limited. To bridge this gap,
this work introduces \VideoDatasetName, an inaugural interleaved video-text
dataset featuring comprehensive captions, marking a significant step forward.
Demonstrating its impact, we illustrate how \VideoDatasetName{} enhances model
performance in image-text tasks. With 34% learnable parameters and utilizing
72\% of the available data, our model demonstrates significant superiority over
OpenFlamingo~\cite{openflamingo}. For instance, in the 4-shot flickr captioning
task, performance notably improves from 57.2% to 65.\%. The contributions of
\ModelName{} and \VideoDatasetName{} are underscored by notable performance
gains across 14 diverse downstream datasets encompassing both image-text and
video-text tasks.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00850" title="Abstract">arXiv:2401.00850</a> [<a href="/pdf/2401.00850" title="Download PDF">pdf</a>, <a href="/format/2401.00850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refining Pre-Trained Motion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinglong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Harley%2C+A+W">Adam W. Harley</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L+J">Leonidas J. Guibas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Given the difficulty of manually annotating motion in video, the current best
motion estimation methods are trained with synthetic data, and therefore
struggle somewhat due to a train/test gap. Self-supervised methods hold the
promise of training directly on real video, but typically perform worse. These
include methods trained with warp error (i.e., color constancy) combined with
smoothness terms, and methods that encourage cycle-consistency in the estimates
(i.e., tracking backwards should yield the opposite trajectory as tracking
forwards). In this work, we take on the challenge of improving state-of-the-art
supervised models with self-supervised training. We find that when the
initialization is supervised weights, most existing self-supervision techniques
actually make performance worse instead of better, which suggests that the
benefit of seeing the new data is overshadowed by the noise in the training
signal. Focusing on obtaining a ``clean'' training signal from real-world
unlabelled video, we propose to separate label-making and training into two
distinct stages. In the first stage, we use the pre-trained model to estimate
motion in a video, and then select the subset of motion estimates which we can
verify with cycle-consistency. This produces a sparse but accurate
pseudo-labelling of the video. In the second stage, we fine-tune the model to
reproduce these outputs, while also applying augmentations on the input. We
complement this boot-strapping method with simple techniques that densify and
re-balance the pseudo-labels, ensuring that we do not merely train on ``easy''
tracks. We show that our method yields reliable gains over fully-supervised
methods in real videos, for both short-term (flow-based) and long-range
(multi-frame) pixel tracking.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue,  2 Jan 24</h3>
<dl>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1409.7291" title="Abstract">arXiv:1409.7291</a> (cross-list from physics.soc-ph) [<a href="/pdf/1409.7291" title="Download PDF">pdf</a>, <a href="/format/1409.7291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Hybrid Spreading in Metapopulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+C">Changwang Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Zhou%2C+S">Shi Zhou</a>, 
<a href="/search/physics?searchtype=author&query=Miller%2C+J+C">Joel C. Miller</a>, 
<a href="/search/physics?searchtype=author&query=Cox%2C+I+J">Ingemar J. Cox</a>, 
<a href="/search/physics?searchtype=author&query=Chain%2C+B+M">Benjamin M. Chain</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Scientific Reports. 2015 Apr 29;5:9924
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">Epidemic spreading phenomena are ubiquitous in nature and society. Examples
include the spreading of diseases, information, and computer viruses. Epidemics
can spread by local spreading, where infected nodes can only infect a limited
set of direct target nodes and global spreading, where an infected node can
infect every other node. In reality, many epidemics spread using a hybrid
mixture of both types of spreading. In this study we develop a theoretical
framework for studying hybrid epidemics, and examine the optimum balance
between spreading mechanisms in terms of achieving the maximum outbreak size.
We show the existence of critically hybrid epidemics where neither spreading
mechanism alone can cause a noticeable spread but a combination of the two
spreading mechanisms would produce an enormous outbreak. Our results provide
new strategies for maximising beneficial epidemics and estimating the worst
outcome of damaging hybrid epidemics.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1503.08992" title="Abstract">arXiv:1503.08992</a> (cross-list from q-bio.PE) [<a href="/pdf/1503.08992" title="Download PDF">pdf</a>, <a href="/format/1503.08992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid spreading mechanisms and T cell activation shape the dynamics of  HIV-1 infection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+C">Changwang Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+S">Shi Zhou</a>, 
<a href="/search/q-bio?searchtype=author&query=Groppelli%2C+E">Elisabetta Groppelli</a>, 
<a href="/search/q-bio?searchtype=author&query=Pellegrino%2C+P">Pierre Pellegrino</a>, 
<a href="/search/q-bio?searchtype=author&query=Williams%2C+I">Ian Williams</a>, 
<a href="/search/q-bio?searchtype=author&query=Borrow%2C+P">Persephone Borrow</a>, 
<a href="/search/q-bio?searchtype=author&query=Chain%2C+B+M">Benjamin M. Chain</a>, 
<a href="/search/q-bio?searchtype=author&query=Jolly%2C+C">Clare Jolly</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PLOS Computational Biology. 2015 Apr 2;11(4):e1004179
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Biological Physics (physics.bio-ph); Cell Behavior (q-bio.CB)

</div>
<p class="mathjax">HIV-1 can disseminate between susceptible cells by two mechanisms: cell-free
infection following fluid-phase diffusion of virions and by highly-efficient
direct cell-to-cell transmission at immune cell contacts. The contribution of
this hybrid spreading mechanism, which is also a characteristic of some
important computer worm outbreaks, to HIV-1 progression in vivo remains
unknown. Here we present a new mathematical model that explicitly incorporates
the ability of HIV-1 to use hybrid spreading mechanisms and evaluate the
consequences for HIV-1 pathogenenesis. The model captures the major phases of
the HIV-1 infection course of a cohort of treatment naive patients and also
accurately predicts the results of the Short Pulse Anti-Retroviral Therapy at
Seroconversion (SPARTAC) trial. Using this model we find that hybrid spreading
is critical to seed and establish infection, and that cell-to-cell spread and
increased CD4+ T cell activation are important for HIV-1 progression. Notably,
the model predicts that cell-to-cell spread becomes increasingly effective as
infection progresses and thus may present a considerable treatment barrier.
Deriving predictions of various treatments' influence on HIV-1 progression
highlights the importance of earlier intervention and suggests that treatments
effectively targeting cell-to-cell HIV-1 spread can delay progression to AIDS.
This study suggests that hybrid spreading is a fundamental feature of HIV
infection, and provides the mathematical framework incorporating this feature
with which to evaluate future therapeutic strategies.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00003" title="Abstract">arXiv:2401.00003</a> (cross-list from physics.optics) [<a href="/pdf/2401.00003" title="Download PDF">pdf</a>, <a href="/format/2401.00003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Inverse Design of Metamaterials with Functional Responses by  Interpretable Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+W+%22">Wei &quot;Wayne&quot; Chen</a>, 
<a href="/search/physics?searchtype=author&query=Sun%2C+R">Rachel Sun</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+D">Doksoo Lee</a>, 
<a href="/search/physics?searchtype=author&query=Portela%2C+C+M">Carlos M. Portela</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+W">Wei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Metamaterials with functional responses, such as wave-based responses or
deformation-induced property variation under external stimuli, can exhibit
varying properties or functionalities under different conditions. Herein, we
aim at rapid inverse design of these metamaterials to meet target qualitative
functional behaviors. This inverse problem is challenging due to its
intractability and the existence of non-unique solutions. Past works mainly
focus on deep-learning-based methods that are data-demanding, require
time-consuming training and hyperparameter tuning, and are non-interpretable.
To overcome these limitations, we propose the Random-forest-based Interpretable
Generative Inverse Design (RIGID), a single-shot inverse design method to
achieve the fast generation of metamaterial designs with on-demand functional
behaviors. Unlike most existing methods, by exploiting the interpretability of
the random forest, we eliminate the need to train an inverse model mapping
responses to designs. Based on the likelihood of target satisfaction derived
from the trained forward model, one can sample design solutions using Markov
chain Monte Carlo methods. The RIGID method therefore functions as a generative
model that captures the conditional distribution of satisfying solutions given
a design target. We demonstrate the effectiveness and efficiency of RIGID on
both acoustic and optical metamaterial design problems where only small
datasets (less than 250 training samples) are available. Synthetic design
problems are created to further illustrate and validate the mechanism of
likelihood estimation in RIGID. This work offers a new perspective on solving
on-demand inverse design problems, showcasing the potential for incorporating
interpretable machine learning into generative design and eliminating its large
data requirement.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00014" title="Abstract">arXiv:2401.00014</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.00014" title="Download PDF">pdf</a>, <a href="/format/2401.00014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource-Limited Automated Ki67 Index Estimation in Breast Cancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Gliozzo%2C+J">J. Gliozzo</a>, 
<a href="/search/q-bio?searchtype=author&query=Marin%C3%B2%2C+G">G. Marin&#xf2;</a>, 
<a href="/search/q-bio?searchtype=author&query=Bonometti%2C+A">A. Bonometti</a>, 
<a href="/search/q-bio?searchtype=author&query=Frasca%2C+M">M. Frasca</a>, 
<a href="/search/q-bio?searchtype=author&query=Malchiodi%2C+D">D. Malchiodi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The prediction of tumor progression and chemotherapy response has been
recently tackled exploiting Tumor Infiltrating Lymphocytes (TILs) and the
nuclear protein Ki67 as prognostic factors. Recently, deep neural networks
(DNNs) have been shown to achieve top results in estimating Ki67 expression and
simultaneous determination of intratumoral TILs score in breast cancer cells.
However, in the last ten years the extraordinary progress induced by deep
models proliferated at least as much as their resource demand. The exorbitant
computational costs required to query (and in some cases also to store) a deep
model represent a strong limitation in resource-limited contexts, like that of
IoT-based applications to support healthcare personnel. To this end, we propose
a resource consumption-aware DNN for the effective estimate of the percentage
of Ki67-positive cells in breast cancer screenings. Our approach reduced up to
75% and 89% the usage of memory and disk space respectively, up to 1.5x the
energy consumption, and preserved or improved the overall accuracy of a
benchmark state-of-the-art solution. Encouraged by such positive results, we
developed and structured the adopted framework so as to allow its general
purpose usage, along with a public software repository to support its usage.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00023" title="Abstract">arXiv:2401.00023</a> (cross-list from eess.IV) [<a href="/pdf/2401.00023" title="Download PDF">pdf</a>, <a href="/ps/2401.00023" title="Download PostScript">ps</a>, <a href="/format/2401.00023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CycleGAN Models for MRI Image Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Czobit%2C+C">Cassandra Czobit</a>, 
<a href="/search/eess?searchtype=author&query=Samavi%2C+R">Reza Samavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Image-to-image translation has gained popularity in the medical field to
transform images from one domain to another. Medical image synthesis via domain
transformation is advantageous in its ability to augment an image dataset where
images for a given class is limited. From the learning perspective, this
process contributes to data-oriented robustness of the model by inherently
broadening the model's exposure to more diverse visual data and enabling it to
learn more generalized features. In the case of generating additional
neuroimages, it is advantageous to obtain unidentifiable medical data and
augment smaller annotated datasets. This study proposes the development of a
CycleGAN model for translating neuroimages from one field strength to another
(e.g., 3 Tesla to 1.5). This model was compared to a model based on DCGAN
architecture. CycleGAN was able to generate the synthetic and reconstructed
images with reasonable accuracy. The mapping function from the source (3 Tesla)
to target domain (1.5 Tesla) performed optimally with an average PSNR value of
25.69 $\pm$ 2.49 dB and an MAE value of 2106.27 +/- 1218.37.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00035" title="Abstract">arXiv:2401.00035</a> (cross-list from physics.comp-ph) [<a href="/pdf/2401.00035" title="Download PDF">pdf</a>, <a href="/format/2401.00035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning About Structural Errors in Models of Complex Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wu%2C+J">Jin-Long Wu</a>, 
<a href="/search/physics?searchtype=author&query=Levine%2C+M+E">Matthew E. Levine</a>, 
<a href="/search/physics?searchtype=author&query=Schneider%2C+T">Tapio Schneider</a>, 
<a href="/search/physics?searchtype=author&query=Stuart%2C+A">Andrew Stuart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Complex dynamical systems are notoriously difficult to model because some
degrees of freedom (e.g., small scales) may be computationally unresolvable or
are incompletely understood, yet they are dynamically important. For example,
the small scales of cloud dynamics and droplet formation are crucial for
controlling climate, yet are unresolvable in global climate models.
Semi-empirical closure models for the effects of unresolved degrees of freedom
often exist and encode important domain-specific knowledge. Building on such
closure models and correcting them through learning the structural errors can
be an effective way of fusing data with domain knowledge. Here we describe a
general approach, principles, and algorithms for learning about structural
errors. Key to our approach is to include structural error models inside the
models of complex systems, for example, in closure models for unresolved
scales. The structural errors then map, usually nonlinearly, to observable
data. As a result, however, mismatches between model output and data are only
indirectly informative about structural errors, due to a lack of labeled pairs
of inputs and outputs of structural error models. Additionally, derivatives of
the model may not exist or be readily available. We discuss how structural
error models can be learned from indirect data with derivative-free Kalman
inversion algorithms and variants, how sparsity constraints enforce a "do no
harm" principle, and various ways of modeling structural errors. We also
discuss the merits of using non-local and/or stochastic error models. In
addition, we demonstrate how data assimilation techniques can assist the
learning about structural errors in non-ergodic systems. The concepts and
algorithms are illustrated in two numerical examples based on the Lorenz-96
system and a human glucose-insulin model.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00037" title="Abstract">arXiv:2401.00037</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.00037" title="Download PDF">pdf</a>, <a href="/format/2401.00037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Messenger and Non-Coding RNA Design via Expected Partition Function and  Continuous Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Dai%2C+N">Ning Dai</a>, 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+W+Y">Wei Yu Tang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+T">Tianshuo Zhou</a>, 
<a href="/search/q-bio?searchtype=author&query=Mathews%2C+D+H">David H. Mathews</a>, 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+L">Liang Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The tasks of designing messenger RNAs and non-coding RNAs are discrete
optimization problems, and several versions of these problems are NP-hard. As
an alternative to commonly used local search methods, we formulate these
problems as continuous optimization and develop a general framework for this
optimization based on a new concept of "expected partition function". The basic
idea is to start with a distribution over all possible candidate sequences, and
extend the objective function from a sequence to a distribution. We then use
gradient descent-based optimization methods to improve the extended objective
function, and the distribution will gradually shrink towards a one-hot sequence
(i.e., a single sequence). We consider two important case studies within this
framework, the mRNA design problem optimizing for partition function (i.e.,
ensemble free energy) and the non-coding RNA design problem optimizing for
conditional (i.e., Boltzmann) probability. In both cases, our approach
demonstrate promising preliminary results. We make our code available at
https://github.com/KuNyaa/RNA_Design_codebase.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00060" title="Abstract">arXiv:2401.00060</a> (cross-list from astro-ph.IM) [<a href="/pdf/2401.00060" title="Download PDF">pdf</a>, <a href="/format/2401.00060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing your Observatory&#x27;s Impact: Best Practices in Establishing and  Maintaining Observatory Bibliographies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Observatory+Bibliographers+Collaboration">Observatory Bibliographers Collaboration</a>: 
<a href="/search/astro-ph?searchtype=author&query=D%27Abrusco%2C+R">Raffaele D&#x27;Abrusco</a>, 
<a href="/search/astro-ph?searchtype=author&query=Gomez%2C+M">Monique Gomez</a>, 
<a href="/search/astro-ph?searchtype=author&query=Grothkopf%2C+U">Uta Grothkopf</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hunt%2C+S">Sharon Hunt</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kneale%2C+R">Ruth Kneale</a>, 
<a href="/search/astro-ph?searchtype=author&query=Konuma%2C+M">Mika Konuma</a>, 
<a href="/search/astro-ph?searchtype=author&query=Novacescu%2C+J">Jenny Novacescu</a>, 
<a href="/search/astro-ph?searchtype=author&query=Rebull%2C+L">Luisa Rebull</a>, 
<a href="/search/astro-ph?searchtype=author&query=Scire%2C+E">Elena Scire</a>, 
<a href="/search/astro-ph?searchtype=author&query=Scott%2C+E">Erin Scott</a>, 
<a href="/search/astro-ph?searchtype=author&query=Thompson%2C+D">Donna Thompson</a>, 
<a href="/search/astro-ph?searchtype=author&query=Utley%2C+L">Lance Utley</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wilkinson%2C+C">Christopher Wilkinson</a>, 
<a href="/search/astro-ph?searchtype=author&query=Winkelman%2C+S">Sherry Winkelman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 3 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Digital Libraries (cs.DL); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Observatories need to measure and evaluate the scientific output and overall
impact of their facilities. An observatory bibliography consists of the papers
published using that observatory's data, typically gathered by searching the
major journals for relevant keywords. Recently, the volume of literature and
methods by which the publications pool is evaluated has increased. Efficient
and standardized procedures are necessary to assign meaningful metadata; enable
user-friendly retrieval; and provide the opportunity to derive reports,
statistics, and visualizations to impart a deeper understanding of the research
output. In 2021, a group of observatory bibliographers from around the world
convened online to continue the discussions presented in Lagerstrom (2015). We
worked to extract general guidelines from our experiences, techniques, and
lessons learnt. The paper explores the development, application, and current
status of telescope bibliographies and future trends. This paper briefly
describes the methodologies employed in constructing databases, along with the
various bibliometric techniques used to analyze and interpret them. We explain
reasons for non-standardization and why it is essential for each observatory to
identify metadata and metrics that are meaningful for them; caution the
(over-)use of comparisons among facilities that are, ultimately, not comparable
through bibliometrics; and highlight the benefits of telescope bibliographies,
both for researchers within the astronomical community and for stakeholders
beyond the specific observatories. There is tremendous diversity in the ways
bibliographers track publications and maintain databases, due to parameters
such as resources, type of observatory, historical practices, and reporting
requirements to funders and outside agencies. However, there are also common
sets of Best Practices.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00065" title="Abstract">arXiv:2401.00065</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2401.00065" title="Download PDF">pdf</a>, <a href="/ps/2401.00065" title="Download PostScript">ps</a>, <a href="/format/2401.00065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Process Development for 3D Printing of New Metal Alloys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Guirguis%2C+D">David Guirguis</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tucker%2C+C">Conrad Tucker</a>, 
<a href="/search/cond-mat?searchtype=author&query=Beuth%2C+J">Jack Beuth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Addressing the uncertainty and variability in the quality of 3D printed
metals can further the wide spread use of this technology. Process mapping for
new alloys is crucial for determining optimal process parameters that
consistently produce acceptable printing quality. Process mapping is typically
performed by conventional methods and is used for the design of experiments and
ex situ characterization of printed parts. On the other hand, in situ
approaches are limited because their observable features are limited and they
require complex high-cost setups to obtain temperature measurements to boost
accuracy. Our method relaxes these limitations by incorporating the temporal
features of molten metal dynamics during laser-metal interactions using video
vision transformers and high-speed imaging. Our approach can be used in
existing commercial machines and can provide in situ process maps for efficient
defect and variability quantification. The generalizability of the approach is
demonstrated by performing cross-dataset evaluations on alloys with different
compositions and intrinsic thermofluid properties.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00071" title="Abstract">arXiv:2401.00071</a> (cross-list from math.PR) [<a href="/pdf/2401.00071" title="Download PDF">pdf</a>, <a href="/ps/2401.00071" title="Download PostScript">ps</a>, <a href="/format/2401.00071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shifted Composition II: Shift Harnack Inequalities and Curvature Upper  Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Altschuler%2C+J+M">Jason M. Altschuler</a>, 
<a href="/search/math?searchtype=author&query=Chewi%2C+S">Sinho Chewi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT); Analysis of PDEs (math.AP); Functional Analysis (math.FA)

</div>
<p class="mathjax">We apply the shifted composition rule -- an information-theoretic principle
introduced in our earlier work [AC23] -- to establish shift Harnack
inequalities for the Langevin diffusion. We obtain sharp constants for these
inequalities for the first time, allowing us to investigate their relationship
with other properties of the diffusion. Namely, we show that they are
equivalent to a sharp "local gradient-entropy" bound, and that they imply
curvature upper bounds in a compelling reflection of the Bakry-Emery theory of
curvature lower bounds. Finally, we show that the local gradient-entropy
inequality implies optimal concentration of the score, a.k.a. the logarithmic
gradient of the density.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00072" title="Abstract">arXiv:2401.00072</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2401.00072" title="Download PDF">pdf</a>, <a href="/format/2401.00072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine-learned models for magnetic materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Leszczy%C5%84ski%2C+P">Pawe&#x142; Leszczy&#x144;ski</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kutorasi%C5%84ski%2C+K">Kamil Kutorasi&#x144;ski</a>, 
<a href="/search/cond-mat?searchtype=author&query=Szewczyk%2C+M">Marcin Szewczyk</a>, 
<a href="/search/cond-mat?searchtype=author&query=Paw%C5%82owski%2C+J">Jaros&#x142;aw Paw&#x142;owski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a general framework for modeling materials using deep neural
networks. Material represented by multidimensional characteristics (that mimic
measurements) is used to train the neural autoencoder model in an unsupervised
manner. The encoder is trying to predict the material parameters of a
theoretical model, which is then used in a decoder part. The decoder, using the
predicted parameters, reconstructs the input characteristics. The neural model
is trained to capture a synthetically generated set of characteristics that can
cover a broad range of material behaviors, leading to a model that can
generalize on the underlying physics rather than just optimize the model
parameters for a single measurement. After setting up the model we prove its
usefulness in the complex problem of modeling magnetic materials in the
frequency and current (out-of-linear range) domains simultaneously.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00077" title="Abstract">arXiv:2401.00077</a> (cross-list from q-bio.NC) [<a href="/pdf/2401.00077" title="Download PDF">pdf</a>, <a href="/format/2401.00077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Maturity Model for Operations in Neuroscience Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Johnson%2C+E+C">Erik C. Johnson</a>, 
<a href="/search/q-bio?searchtype=author&query=Nguyen%2C+T+T">Thinh T. Nguyen</a>, 
<a href="/search/q-bio?searchtype=author&query=Dichter%2C+B+K">Benjamin K. Dichter</a>, 
<a href="/search/q-bio?searchtype=author&query=Zappulla%2C+F">Frank Zappulla</a>, 
<a href="/search/q-bio?searchtype=author&query=Kosma%2C+M">Montgomery Kosma</a>, 
<a href="/search/q-bio?searchtype=author&query=Gunalan%2C+K">Kabilar Gunalan</a>, 
<a href="/search/q-bio?searchtype=author&query=Halchenko%2C+Y+O">Yaroslav O. Halchenko</a>, 
<a href="/search/q-bio?searchtype=author&query=Neufeld%2C+S+Q">Shay Q. Neufeld</a>, 
<a href="/search/q-bio?searchtype=author&query=Schirner%2C+M">Michael Schirner</a>, 
<a href="/search/q-bio?searchtype=author&query=Ritter%2C+P">Petra Ritter</a>, 
<a href="/search/q-bio?searchtype=author&query=Martone%2C+M+E">Maryann E. Martone</a>, 
<a href="/search/q-bio?searchtype=author&query=Wester%2C+B">Brock Wester</a>, 
<a href="/search/q-bio?searchtype=author&query=Pestilli%2C+F">Franco Pestilli</a>, 
<a href="/search/q-bio?searchtype=author&query=Yatsenko%2C+D">Dimitri Yatsenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, one figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Scientists are adopting new approaches to scale up their activities and
goals. Progress in neurotechnologies, artificial intelligence, automation, and
tools for collaboration promises new bursts of discoveries. However, compared
to other disciplines and the industry, neuroscience laboratories have been slow
to adopt key technologies to support collaboration, reproducibility, and
automation. Drawing on progress in other fields, we define a roadmap for
implementing automated research workflows for diverse research teams. We
propose establishing a five-level capability maturity model for operations in
neuroscience research. Achieving higher levels of operational maturity requires
new technology-enabled methodologies, which we describe as ``SciOps''. The
maturity model provides guidelines for evaluating and upgrading operations in
multidisciplinary neuroscience teams.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00089" title="Abstract">arXiv:2401.00089</a> (cross-list from math.AG) [<a href="/pdf/2401.00089" title="Download PDF">pdf</a>, <a href="/ps/2401.00089" title="Download PostScript">ps</a>, <a href="/format/2401.00089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditions for eigenvalue configurations of two real symmetric matrices:  a symmetric function approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hong%2C+H">Hoon Hong</a>, 
<a href="/search/math?searchtype=author&query=Profili%2C+D">Daniel Profili</a>, 
<a href="/search/math?searchtype=author&query=Sendra%2C+J+R">J. Rafael Sendra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">For two real symmetric matrices, their eigenvalue configuration is the
arrangement of their eigenvalues on the real line. We study the problem of
determining a quantifier-free necessary and sufficient condition for two real
symmetric matrices to realize a given eigenvalue configuration as a
generalization of Descartes' rule of signs. We exploit the combinatorial
properties of our definition for eigenvalue configuration to reduce a
two-polynomial root counting problem into several single-polynomial root
counting problems of symmetric polynomials. We then leverage the fundamental
theorem of symmetric polynomials to derive a final quantifier-free necessary
and sufficient condition for two real symmetric matrices to realize a given
eigenvalue configuration.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00097" title="Abstract">arXiv:2401.00097</a> (cross-list from stat.ME) [<a href="/pdf/2401.00097" title="Download PDF">pdf</a>, <a href="/format/2401.00097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive identification with regularization and on-line hyperparameters  estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vau%2C+B">Bernard Vau</a>, 
<a href="/search/stat?searchtype=author&query=Airimitoaie%2C+T">Tudor-Bogdan Airimitoaie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://hal.science/hal-04337419">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents a regularized recursive identification algorithm with
simultaneous on-line estimation of both the model parameters and the algorithms
hyperparameters. A new kernel is proposed to facilitate the algorithm
development. The performance of this novel scheme is compared with that of the
recursive least-squares algorithm in simulation.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00108" title="Abstract">arXiv:2401.00108</a> (cross-list from math.OC) [<a href="/pdf/2401.00108" title="Download PDF">pdf</a>, <a href="/format/2401.00108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Optimization under Hidden Convexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fatkhullin%2C+I">Ilyas Fatkhullin</a>, 
<a href="/search/math?searchtype=author&query=He%2C+N">Niao He</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+Y">Yifan Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">In this work, we consider constrained stochastic optimization problems under
hidden convexity, i.e., those that admit a convex reformulation via non-linear
(but invertible) map $c(\cdot)$. A number of non-convex problems ranging from
optimal control, revenue and inventory management, to convex reinforcement
learning all admit such a hidden convex structure. Unfortunately, in the
majority of applications considered, the map $c(\cdot)$ is unavailable or
implicit; therefore, directly solving the convex reformulation is not possible.
On the other hand, the stochastic gradients with respect to the original
variable are often easy to obtain. Motivated by these observations, we examine
the basic projected stochastic (sub-) gradient methods for solving such
problems under hidden convexity. We provide the first sample complexity
guarantees for global convergence in smooth and non-smooth settings.
Additionally, in the smooth setting, we improve our results to the last iterate
convergence in terms of function value gap using the momentum variant of
projected stochastic gradient descent.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00122" title="Abstract">arXiv:2401.00122</a> (cross-list from stat.ML) [<a href="/pdf/2401.00122" title="Download PDF">pdf</a>, <a href="/format/2401.00122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SALSA: Sequential Approximate Leverage-Score Algorithm with Application  in Analyzing Big Time Series Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Eshragh%2C+A">Ali Eshragh</a>, 
<a href="/search/stat?searchtype=author&query=Yerbury%2C+L">Luke Yerbury</a>, 
<a href="/search/stat?searchtype=author&query=Nazari%2C+A">Asef Nazari</a>, 
<a href="/search/stat?searchtype=author&query=Roosta%2C+F">Fred Roosta</a>, 
<a href="/search/stat?searchtype=author&query=Mahoney%2C+M+W">Michael W. Mahoney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We develop a new efficient sequential approximate leverage score algorithm,
SALSA, using methods from randomized numerical linear algebra (RandNLA) for
large matrices. We demonstrate that, with high probability, the accuracy of
SALSA's approximations is within $(1 + O({\varepsilon}))$ of the true leverage
scores. In addition, we show that the theoretical computational complexity and
numerical accuracy of SALSA surpass existing approximations. These theoretical
results are subsequently utilized to develop an efficient algorithm, named
LSARMA, for fitting an appropriate ARMA model to large-scale time series data.
Our proposed algorithm is, with high probability, guaranteed to find the
maximum likelihood estimates of the parameters for the true underlying ARMA
model. Furthermore, it has a worst-case running time that significantly
improves those of the state-of-the-art alternatives in big data regimes.
Empirical results on large-scale data strongly support these theoretical
results and underscore the efficacy of our new approach.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00123" title="Abstract">arXiv:2401.00123</a> (cross-list from math.PR) [<a href="/pdf/2401.00123" title="Download PDF">pdf</a>, <a href="/ps/2401.00123" title="Download PostScript">ps</a>, <a href="/format/2401.00123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quick probability-oriented introduction to operator splitting methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vovchanskyi%2C+M+B">M.B. Vovchanskyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper is an extended and reworked version of a short course given by the
author at ''Uzbekistan-Ukrainian readings in stochastic processes'',
Tashkent-Kyiv, 2022, and was prepared for a special issue of ''Theory of
stochastic processes'', devoted to publishing lecture notes from the
aforementioned workshop.
<br />The survey is devoted to operator splitting methods in the abstract
formulation and their applications in probability. While the survey is focused
on multiplicative methods, the BCH formula is used to discuss exponential
splitting methods and a short informal introduction to additive splitting is
presented. We introduce frameworks and available deterministic and
probabilistic results and concentrate on constructing a wide picture of the
field of operator splitting methods, providing a rigorous description in the
setting of abstract Cauchy problems and an informal discussion for further and
parallel advances. Some limitations and common difficulties are listed, as well
as examples of works that provide solutions or hints. No new results are given.
The bibliography contains illustrative deterministic examples and a selection
of probability-related works.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00135" title="Abstract">arXiv:2401.00135</a> (cross-list from eess.IV) [<a href="/pdf/2401.00135" title="Download PDF">pdf</a>, <a href="/ps/2401.00135" title="Download PostScript">ps</a>, <a href="/format/2401.00135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Radon Prior: A Fully Unsupervised Framework for Sparse-View CT  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+S">Shuo Xu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yucheng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+G">Gang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+X">Xincheng Xiang</a>, 
<a href="/search/eess?searchtype=author&query=Cong%2C+P">Peng Cong</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yuewen Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures, Journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Although sparse-view computed tomography (CT) has significantly reduced
radiation dose, it also introduces severe artifacts which degrade the image
quality. In recent years, deep learning-based methods for inverse problems have
made remarkable progress and have become increasingly popular in CT
reconstruction. However, most of these methods suffer several limitations:
dependence on high-quality training data, weak interpretability, etc. In this
study, we propose a fully unsupervised framework called Deep Radon Prior (DRP),
inspired by Deep Image Prior (DIP), to address the aforementioned limitations.
DRP introduces a neural network as an implicit prior into the iterative method,
thereby realizing cross-domain gradient feedback. During the reconstruction
process, the neural network is progressively optimized in multiple stages to
narrow the solution space in radon domain for the under-constrained imaging
protocol, and the convergence of the proposed method has been discussed in this
work. Compared with the popular pre-trained method, the proposed framework
requires no dataset and exhibits superior interpretability and generalization
ability. The experimental results demonstrate that the proposed method can
generate detailed images while effectively suppressing image
artifacts.Meanwhile, DRP achieves comparable or better performance than the
supervised methods.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00159" title="Abstract">arXiv:2401.00159</a> (cross-list from eess.IV) [<a href="/pdf/2401.00159" title="Download PDF">pdf</a>, <a href="/format/2401.00159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic hip osteoarthritis grading with uncertainty estimation from  computed tomography using digitally-reconstructed radiographs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Masuda%2C+M">Masachika Masuda</a>, 
<a href="/search/eess?searchtype=author&query=Soufi%2C+M">Mazen Soufi</a>, 
<a href="/search/eess?searchtype=author&query=Otake%2C+Y">Yoshito Otake</a>, 
<a href="/search/eess?searchtype=author&query=Uemura%2C+K">Keisuke Uemura</a>, 
<a href="/search/eess?searchtype=author&query=Kono%2C+S">Sotaro Kono</a>, 
<a href="/search/eess?searchtype=author&query=Takashima%2C+K">Kazuma Takashima</a>, 
<a href="/search/eess?searchtype=author&query=Hamada%2C+H">Hidetoshi Hamada</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+Y">Yi Gu</a>, 
<a href="/search/eess?searchtype=author&query=Takao%2C+M">Masaki Takao</a>, 
<a href="/search/eess?searchtype=author&query=Okada%2C+S">Seiji Okada</a>, 
<a href="/search/eess?searchtype=author&query=Sugano%2C+N">Nobuhiko Sugano</a>, 
<a href="/search/eess?searchtype=author&query=Sato%2C+Y">Yoshinobu Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Progression of hip osteoarthritis (hip OA) leads to pain and disability,
likely leading to surgical treatment such as hip arthroplasty at the terminal
stage. The severity of hip OA is often classified using the Crowe and
Kellgren-Lawrence (KL) classifications. However, as the classification is
subjective, we aimed to develop an automated approach to classify the disease
severity based on the two grades using digitally-reconstructed radiographs
(DRRs) from CT images. Automatic grading of the hip OA severity was performed
using deep learning-based models. The models were trained to predict the
disease grade using two grading schemes, i.e., predicting the Crowe and KL
grades separately, and predicting a new ordinal label combining both grades and
representing the disease progression of hip OA. The models were trained in
classification and regression settings. In addition, the model uncertainty was
estimated and validated as a predictor of classification accuracy. The models
were trained and validated on a database of 197 hip OA patients, and externally
validated on 52 patients. The model accuracy was evaluated using exact class
accuracy (ECA), one-neighbor class accuracy (ONCA), and balanced accuracy.The
deep learning models produced a comparable accuracy of approximately 0.65 (ECA)
and 0.95 (ONCA) in the classification and regression settings. The model
uncertainty was significantly larger in cases with large classification errors
(P&lt;6e-3). In this study, an automatic approach for grading hip OA severity from
CT images was developed. The models have shown comparable performance with high
ONCA, which facilitates automated grading in large-scale CT databases and
indicates the potential for further disease progression analysis.
Classification accuracy was correlated with the model uncertainty, which would
allow for the prediction of classification errors.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00225" title="Abstract">arXiv:2401.00225</a> (cross-list from eess.AS) [<a href="/pdf/2401.00225" title="Download PDF">pdf</a>, <a href="/ps/2401.00225" title="Download PostScript">ps</a>, <a href="/format/2401.00225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing dysarthria speech feature representation with empirical mode  decomposition and Walsh-Hadamard transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhu%2C+T">Ting Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+S">Shufei Duan</a>, 
<a href="/search/eess?searchtype=author&query=Dingam%2C+C">Camille Dingam</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+H">Huizhi Liang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Dysarthria speech contains the pathological characteristics of vocal tract
and vocal fold, but so far, they have not yet been included in traditional
acoustic feature sets. Moreover, the nonlinearity and non-stationarity of
speech have been ignored. In this paper, we propose a feature enhancement
algorithm for dysarthria speech called WHFEMD. It combines empirical mode
decomposition (EMD) and fast Walsh-Hadamard transform (FWHT) to enhance
features. With the proposed algorithm, the fast Fourier transform of the
dysarthria speech is first performed and then followed by EMD to get intrinsic
mode functions (IMFs). After that, FWHT is used to output new coefficients and
to extract statistical features based on IMFs, power spectral density, and
enhanced gammatone frequency cepstral coefficients. To evaluate the proposed
approach, we conducted experiments on two public pathological speech databases
including UA Speech and TORGO. The results show that our algorithm performed
better than traditional features in classification. We achieved improvements of
13.8% (UA Speech) and 3.84% (TORGO), respectively. Furthermore, the
incorporation of an imbalanced classification algorithm to address data
imbalance has resulted in a 12.18% increase in recognition accuracy. This
algorithm effectively addresses the challenges of the imbalanced dataset and
non-linearity in dysarthric speech and simultaneously provides a robust
representation of the local pathological features of the vocal folds and
tracts.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00242" title="Abstract">arXiv:2401.00242</a> (cross-list from astro-ph.IM) [<a href="/pdf/2401.00242" title="Download PDF">pdf</a>, <a href="/format/2401.00242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Laboratory Experiments of Model-based Reinforcement Learning for  Adaptive Optics Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Nousiainen%2C+J">Jalo Nousiainen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Engler%2C+B">Byron Engler</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kasper%2C+M">Markus Kasper</a>, 
<a href="/search/astro-ph?searchtype=author&query=Rajani%2C+C">Chang Rajani</a>, 
<a href="/search/astro-ph?searchtype=author&query=Helin%2C+T">Tapio Helin</a>, 
<a href="/search/astro-ph?searchtype=author&query=Heritier%2C+C+T">C&#xe9;dric T. Heritier</a>, 
<a href="/search/astro-ph?searchtype=author&query=Quanz%2C+S+P">Sascha P. Quanz</a>, 
<a href="/search/astro-ph?searchtype=author&query=Glauser%2C+A+M">Adrian M. Glauser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in JATIS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Direct imaging of Earth-like exoplanets is one of the most prominent
scientific drivers of the next generation of ground-based telescopes.
Typically, Earth-like exoplanets are located at small angular separations from
their host stars, making their detection difficult. Consequently, the adaptive
optics (AO) system's control algorithm must be carefully designed to
distinguish the exoplanet from the residual light produced by the host star.
<br />A new promising avenue of research to improve AO control builds on
data-driven control methods such as Reinforcement Learning (RL). RL is an
active branch of the machine learning research field, where control of a system
is learned through interaction with the environment. Thus, RL can be seen as an
automated approach to AO control, where its usage is entirely a turnkey
operation. In particular, model-based reinforcement learning (MBRL) has been
shown to cope with both temporal and misregistration errors. Similarly, it has
been demonstrated to adapt to non-linear wavefront sensing while being
efficient in training and execution.
<br />In this work, we implement and adapt an RL method called Policy Optimization
for AO (PO4AO) to the GHOST test bench at ESO headquarters, where we
demonstrate a strong performance of the method in a laboratory environment. Our
implementation allows the training to be performed parallel to inference, which
is crucial for on-sky operation. In particular, we study the predictive and
self-calibrating aspects of the method. The new implementation on GHOST running
PyTorch introduces only around 700 microseconds in addition to hardware,
pipeline, and Python interface latency. We open-source well-documented code for
the implementation and specify the requirements for the RTC pipeline. We also
discuss the important hyperparameters of the method, the source of the latency,
and the possible paths for a lower latency implementation.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00269" title="Abstract">arXiv:2401.00269</a> (cross-list from math.OC) [<a href="/pdf/2401.00269" title="Download PDF">pdf</a>, <a href="/ps/2401.00269" title="Download PostScript">ps</a>, <a href="/format/2401.00269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Robust Scheduling of Electricity-Gas Systems Under Wind Power  Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+R">Rong-Peng Liu</a>, 
<a href="/search/math?searchtype=author&query=Hou%2C+Y">Yunhe Hou</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yujia Li</a>, 
<a href="/search/math?searchtype=author&query=Lei%2C+S">Shunbo Lei</a>, 
<a href="/search/math?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xiaozhe Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Trans. Power Syst., vol. 36, no. 6, pp. 5889-5900, Nov. 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper adopts a two-stage sample robust optimization (SRO) model to
address the wind power penetrated unit commitment optimal energy flow (UC-OEF)
problem for IEGSs. The two-stage SRO model can be approximately transformed
into a computationally efficient form. Specifically, we employ linear decision
rules to simplify the proposed UC-OEF model. Moreover, we further enhance the
tractability of the simplified model by exploring its structural features and,
accordingly, develop a solution method.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00273" title="Abstract">arXiv:2401.00273</a> (cross-list from eess.AS) [<a href="/pdf/2401.00273" title="Download PDF">pdf</a>, <a href="/ps/2401.00273" title="Download PostScript">ps</a>, <a href="/format/2401.00273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Zero-Shot Generalizability on Mandarin-English  Code-Switched ASR and Speech-to-text Translation of Recent Foundation Models  with Self-Supervision and Weak Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+C">Chih-Kai Yang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+K">Kuan-Po Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+K">Ke-Han Lu</a>, 
<a href="/search/eess?searchtype=author&query=Kuan%2C+C">Chun-Yi Kuan</a>, 
<a href="/search/eess?searchtype=author&query=Hsiao%2C+C">Chi-Yuan Hsiao</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024 Self-supervision in Audio, Speech and Beyond workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This work evaluated several cutting-edge large-scale foundation models based
on self-supervision or weak supervision, including SeamlessM4T, SeamlessM4T v2,
and Whisper-large-v3, on three code-switched corpora. We found that
self-supervised models can achieve performances close to the supervised model,
indicating the effectiveness of multilingual self-supervised pre-training. We
also observed that these models still have room for improvement as they kept
making similar mistakes and had unsatisfactory performances on modeling
intra-sentential code-switching. In addition, the validity of several variants
of Whisper was explored, and we concluded that they remained effective in a
code-switching scenario, and similar techniques for self-supervised models are
worth studying to boost the performance of code-switched tasks.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00275" title="Abstract">arXiv:2401.00275</a> (cross-list from eess.IV) [<a href="/pdf/2401.00275" title="Download PDF">pdf</a>, <a href="/format/2401.00275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An $\ell^1$-Plug-and-Play Approach for Magnetic Particle Imaging Using a  Zero Shot Denoiser with Validation on the 3D Open MPI Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gapyak%2C+V">Vladyslav Gapyak</a>, 
<a href="/search/eess?searchtype=author&query=Rentschler%2C+C">Corinna Rentschler</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%A4rz%2C+T">Thomas M&#xe4;rz</a>, 
<a href="/search/eess?searchtype=author&query=Weinmann%2C+A">Andreas Weinmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 73 pages, 4 figures, additional supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Magnetic particle imaging (MPI) is an emerging medical imaging modality which
has gained increasing interest in recent years. Among the benefits of MPI are
its high temporal resolution, and that the technique does not expose the
specimen to any kind of ionizing radiation. It is based on the non-linear
response of magnetic nanoparticles to an applied magnetic field. From the
electric signal measured in receive coils, the particle concentration has to be
reconstructed. Due to the ill-posedness of the reconstruction problem, various
regularization methods have been proposed for reconstruction ranging from early
stopping methods, via classical Tikhonov regularization and iterative methods
to modern machine learning approaches. In this work, we contribute to the
latter class: we propose a plug-and-play approach based on a generic zero-shot
denoiser with an $\ell^1$-prior. Moreover, we develop parameter selection
strategies. Finally, we quantitatively and qualitatively evaluate the proposed
algorithmic scheme on the 3D Open MPI data set with different levels of
preprocessing.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00314" title="Abstract">arXiv:2401.00314</a> (cross-list from eess.IV) [<a href="/pdf/2401.00314" title="Download PDF">pdf</a>, <a href="/format/2401.00314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAN-GA: A Generative Model based on Genetic Algorithm for Medical Image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=AbdulRazek%2C+M">M. AbdulRazek</a>, 
<a href="/search/eess?searchtype=author&query=Khoriba%2C+G">G. Khoriba</a>, 
<a href="/search/eess?searchtype=author&query=Belal%2C+M">M. Belal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures. Abstract published in Frontiers in Medical Technology, presented at the 27th Conference on Medical Image Understanding and Analysis 2023. DOI: 10.3389/978-2-8325-1231-9. URL: <a href="https://doi.org/10.3389/978-2-8325-1231-9">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 27th Conference on Medical Image Understanding and Analysis 2023,
  Frontiers, 2023, pp. 30-39
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Medical imaging is an essential tool for diagnosing and treating diseases.
However, lacking medical images can lead to inaccurate diagnoses and
ineffective treatments. Generative models offer a promising solution for
addressing medical image shortage problems due to their ability to generate new
data from existing datasets and detect anomalies in this data. Data
augmentation with position augmentation methods like scaling, cropping,
flipping, padding, rotation, and translation could lead to more overfitting in
domains with little data, such as medical image data. This paper proposes the
GAN-GA, a generative model optimized by embedding a genetic algorithm. The
proposed model enhances image fidelity and diversity while preserving
distinctive features. The proposed medical image synthesis approach improves
the quality and fidelity of medical images, an essential aspect of image
interpretation. To evaluate synthesized images: Frechet Inception Distance
(FID) is used. The proposed GAN-GA model is tested by generating Acute
lymphoblastic leukemia (ALL) medical images, an image dataset, and is the first
time to be used in generative models. Our results were compared to those of
InfoGAN as a baseline model. The experimental results show that the proposed
optimized GAN-GA enhances FID scores by about 6.8\%, especially in earlier
training epochs. The source code and dataset will be available at:
https://github.com/Mustafa-AbdulRazek/InfoGAN-GA.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00367" title="Abstract">arXiv:2401.00367</a> (cross-list from math.OC) [<a href="/pdf/2401.00367" title="Download PDF">pdf</a>, <a href="/ps/2401.00367" title="Download PostScript">ps</a>, <a href="/format/2401.00367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Special Stable Matrices and Their Non-square Counterpart
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Su%2C+S+W">Steven W. Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages; no figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this note, we discuss the extension of several important stable square
matrices, e.g., D-stable matrices, diagonal dominance matrices,
Volterra-Lyapunov stable matrices, to their corresponding non-square matrices.
The extension is motivated by some distributed control-related problems, such
as decentralized unconditional stability and decentralized integral
controllability for non-square processes. We will provide the connections of
conditions between these special square matrices and their associated
non-square counterparts. Some conjectures for these special matrices are
proposed for future research.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00381" title="Abstract">arXiv:2401.00381</a> (cross-list from q-bio.NC) [<a href="/pdf/2401.00381" title="Download PDF">pdf</a>, <a href="/format/2401.00381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling of Memory Mechanisms in Cerebral Cortex and Simulation of  Storage Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wei%2C+H">Hui Wei</a>, 
<a href="/search/q-bio?searchtype=author&query=Feng%2C+C">Chenyue Feng</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+J">Jianning Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">At the intersection of computation and cognitive science, graph theory is
utilized as a formalized description of complex relationships and structures.
Traditional graph models are often static, lacking dynamic and autonomous
behavioral patterns. They rely on algorithms with a global view, significantly
differing from biological neural networks, in which, to simulate information
storage and retrieval processes, the limitations of centralized algorithms must
be overcome. This study introduces a directed graph model that equips each node
with adaptive learning and decision-making capabilities, thereby facilitating
decentralized dynamic information storage and modeling and simulation of the
brain's memory process. We abstract different storage instances as directed
graph paths, transforming the storage of information into the assignment,
discrimination, and extraction of different paths. To address writing and
reading challenges, each node has a personalized adaptive learning ability. A
storage algorithm without a God's eye view is developed, where each node uses
its limited neighborhood information to facilitate the extension, formation,
solidification, and awakening of directed graph paths, achieving competitive,
reciprocal, and sustainable utilization of limited resources. Storage behavior
occurs in each node, with adaptive learning behaviors of nodes concretized in a
microcircuit centered around a variable resistor, simulating the
electrophysiological behavior of neurons. Under the constraints of neurobiology
on the anatomy and electrophysiology of biological neural networks, this model
offers a plausible explanation for the mechanism of memory realization,
providing a comprehensive, system-level experimental validation of the memory
trace theory.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00418" title="Abstract">arXiv:2401.00418</a> (cross-list from math.CO) [<a href="/pdf/2401.00418" title="Download PDF">pdf</a>, <a href="/ps/2401.00418" title="Download PostScript">ps</a>, <a href="/format/2401.00418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounds on the minimum distance of locally recoverable codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kurz%2C+S">Sascha Kurz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We consider locally recoverable codes (LRCs) and aim to determine the
smallest possible length $n=n_q(k,d,r)$ of a linear $[n,k,d]_q$-code with
locality $r$. For $k\le 7$ we exactly determine all values of $n_2(k,d,2)$ and
for $k\le 6$ we exactly determine all values of $n_2(k,d,1)$. For the ternary
field we also state a few numerical results. As a general result we prove that
$n_q(k,d,r)$ equals the Griesmer bound if the minimum Hamming distance $d$ is
sufficiently large and all other parameters are fixed.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00428" title="Abstract">arXiv:2401.00428</a> (cross-list from hep-ex) [<a href="/pdf/2401.00428" title="Download PDF">pdf</a>, <a href="/format/2401.00428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training towards significance with the decorrelated event classifier  transformer neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Kim%2C+J">Jaebak Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures, Submitted to journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Experimental particle physics uses machine learning for many of tasks, where
one application is to classify signal and background events. The classification
can be used to bin an analysis region to enhance the expected significance for
a mass resonance search. In natural language processing, one of the leading
neural network architectures is the transformer. In this work, an event
classifier transformer is proposed to bin an analysis region, in which the
network is trained with special techniques. The techniques developed here can
enhance the significance and reduce the correlation between the network's
output and the reconstructed mass. It is found that this trained network can
perform better than boosted decision trees and feed-forward networks.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00499" title="Abstract">arXiv:2401.00499</a> (cross-list from physics.chem-ph) [<a href="/pdf/2401.00499" title="Download PDF">pdf</a>, <a href="/ps/2401.00499" title="Download PostScript">ps</a>, <a href="/format/2401.00499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating High-Precision Force Fields for Molecular Dynamics  Simulations to Study Chemical Reaction Mechanisms using Molecular  Configuration Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yuan%2C+S">Sihao Yuan</a>, 
<a href="/search/physics?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/physics?searchtype=author&query=Xie%2C+Z">Zhaoxin Xie</a>, 
<a href="/search/physics?searchtype=author&query=Fan%2C+C">Cheng Fan</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+Y+I">Yi Issac Yang</a>, 
<a href="/search/physics?searchtype=author&query=Gao%2C+Y+Q">Yi Qin Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Soft Condensed Matter (cond-mat.soft); Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Theoretical studies on chemical reaction mechanisms have been crucial in
organic chemistry. Traditionally, calculating the manually constructed
molecular conformations of transition states for chemical reactions using
quantum chemical calculations is the most commonly used method. However, this
way is heavily dependent on individual experience and chemical intuition. In
our previous study, we proposed a research paradigm that uses enhanced sampling
in QM/MM molecular dynamics simulations to study chemical reactions. This
approach can directly simulate the entire process of a chemical reaction.
However, the computational speed limits the use of high-precision potential
energy functions for simulations. To address this issue, we present a scheme
for training high-precision force fields for molecular modeling using our
developed graph-neural-network-based molecular model, molecular configuration
transformer. This potential energy function allows for highly accurate
simulations at a low computational cost, leading to more precise calculations
of the mechanism of chemical reactions. We have used this approach to study a
Cope rearrangement reaction and a Carbonyl insertion reaction catalyzed by
Manganese. This "AI+Physics" based simulation approach is expected to become a
new trend in the theoretical study of organic chemical reaction mechanisms.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00523" title="Abstract">arXiv:2401.00523</a> (cross-list from eess.IV) [<a href="/pdf/2401.00523" title="Download PDF">pdf</a>, <a href="/format/2401.00523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressing Deep Image Super-resolution Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Y">Yuxuan Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Nawala%2C+J">Jakub Nawala</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Bull%2C+D">David Bull</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep learning techniques have been applied in the context of image
super-resolution (SR), achieving remarkable advances in terms of reconstruction
performance. Existing techniques typically employ highly complex model
structures which result in large model sizes and slow inference speeds. This
often leads to high energy consumption and restricts their adoption for
practical applications. To address this issue, this work employs a three-stage
workflow for compressing deep SR models which significantly reduces their
memory requirement. Restoration performance has been maintained through
teacher-student knowledge distillation using a newly designed distillation
loss. We have applied this approach to two popular image super-resolution
networks, SwinIR and EDSR, to demonstrate its effectiveness. The resulting
compact models, SwinIRmini and EDSRmini, attain an 89% and 96% reduction in
both model size and floating-point operations (FLOPs) respectively, compared to
their original versions. They also retain competitive super-resolution
performance compared to their original models and other commonly used SR
approaches. The source code and pre-trained models for these two lightweight SR
approaches are released at https://pikapi22.github.io/CDISM/.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00543" title="Abstract">arXiv:2401.00543</a> (cross-list from math.CO) [<a href="/pdf/2401.00543" title="Download PDF">pdf</a>, <a href="/ps/2401.00543" title="Download PostScript">ps</a>, <a href="/format/2401.00543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A binomial random multigraph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pelekis%2C+C">Christos Pelekis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages. Comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Probability (math.PR)

</div>
<p class="mathjax">Fix a positive integer $n$, a real number $p\in (0,1]$, and a (perhaps
random) hypergraph $\mathcal{H}$ on $[n]$. We introduce and investigate the
following random multigraph model, which we denote $\mathbb{G}(n,p\, ;
\,\mathcal{H})$: begin with an empty graph on $n$ vertices, which are labelled
by the set $[n]$. For every $H\in \mathcal{H}$ choose, independently from
previous choices, a doubleton from $H$, say $D = \{i,j\} \subset H$, uniformly
at random and then introduce an edge between the vertices $i$ and $j$ in the
graph with probability $p$, where each edge is introduced independently of all
other edges.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00587" title="Abstract">arXiv:2401.00587</a> (cross-list from eess.IV) [<a href="/pdf/2401.00587" title="Download PDF">pdf</a>, <a href="/format/2401.00587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain Tumor Segmentation Based on Deep Learning, Attention Mechanisms,  and Energy-Based Uncertainty Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schwehr%2C+Z">Zachary Schwehr</a>, 
<a href="/search/eess?searchtype=author&query=Achanta%2C+S">Sriman Achanta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, code available at <a href="https://github.com/WeToTheMoon/BrainTumorSegmentation">this https URL</a>, submitted to Computers in Biology and Medicine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Brain tumors are one of the deadliest forms of cancer with a mortality rate
of over 80%. A quick and accurate diagnosis is crucial to increase the chance
of survival. However, in medical analysis, the manual annotation and
segmentation of a brain tumor can be a complicated task. Multiple MRI
modalities are typically analyzed as they provide unique information regarding
the tumor regions. Although these MRI modalities are helpful for segmenting
gliomas, they tend to increase overfitting and computation. This paper proposes
a region of interest detection algorithm that is implemented during data
preprocessing to locate salient features and remove extraneous MRI data. This
decreases the input size, allowing for more aggressive data augmentations and
deeper neural networks. Following the preprocessing of the MRI modalities, a
fully convolutional autoencoder with soft attention segments the different
brain MRIs. When these deep learning algorithms are implemented in practice,
analysts and physicians cannot differentiate between accurate and inaccurate
predictions. Subsequently, test time augmentations and an energy-based model
were used for voxel-based uncertainty predictions. Experimentation was
conducted on the BraTS benchmarks and achieved state-of-the-art segmentation
performance. Additionally, qualitative results were used to assess the
segmentation models and uncertainty predictions.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00592" title="Abstract">arXiv:2401.00592</a> (cross-list from physics.soc-ph) [<a href="/pdf/2401.00592" title="Download PDF">pdf</a>, <a href="/format/2401.00592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Majority voting is not good for heaven or hell, with mirrored  performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Afonkin%2C+V">Vadim Afonkin</a>, 
<a href="/search/physics?searchtype=author&query=Chebotarev%2C+P">Pavel Chebotarev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures. Submitted to a Springer journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC)

</div>
<p class="mathjax">Within the ViSE (Voting in Stochastic Environment) model, we study the
effectiveness of majority voting in various environments. By the pit of losses
paradox, majority decisions in apparently hostile environments systematically
reduce the capital of society. In such cases, the basic action of ``rejecting
all proposals without voting'' outperforms simple majority. We reveal another
pit of losses appearing in favorable environments. Here, the simple action of
``accepting all proposals without voting'' is superior to simple majority,
which thus causes a loss compared to total acceptance. We show that the second
pit of losses is a mirror image of the pit of losses in hostile environments
and explain this phenomenon. Technically, we consider a voting society
consisting of individual agents whose strategy is supporting all proposals that
increase their capital and a group whose members vote for the increase of the
total group capital. According to the main result, the expected capital gain of
each agent in the environment whose proposal generator $\xi$ has mean $\mu&gt;0$
exceeds by $\mu$ their expected capital gain with generator $-\xi$. This result
extends to the shift-based families of generators with symmetric distributions.
The difference by $\mu$ causes symmetry relative to the basic action that
rejects/accepts all proposals in unfavorable/favorable environments.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00594" title="Abstract">arXiv:2401.00594</a> (cross-list from eess.SP) [<a href="/pdf/2401.00594" title="Download PDF">pdf</a>, <a href="/ps/2401.00594" title="Download PostScript">ps</a>, <a href="/format/2401.00594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Design of Multi-group Multicast Beamforming via Reconfigurable  Intelligent Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ebrahimi%2C+M">Mohammad Ebrahimi</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+M">Min Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, in the Asilomar Conference on Signals, Systems, and Computers 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This paper considers a multi-group multicasting scenario facilitated by a
reconfigurable intelligent surface (RIS). We propose a fast and scalable
algorithm for the joint design of the base station (BS) multicast beamforming
and the RIS passive beamforming to minimize the transmit power subject to the
quality-of-service (QoS) constraints. By exploring the structure of the joint
optimization problem, we show that this QoS problem can be broken into a BS
multicast QoS subproblem and an RIS max-min-fair (MMF) multicast subproblem,
which are solved alternatingly. In our proposed algorithm, we utilize the
optimal multicast beamforming structure to obtain the BS beamformers
efficiently. Furthermore, we reformulate the challenging RIS multicast
subproblem and employ a first-order projected subgradient algorithm (PSA) to
solve it, which yields closed-form updates. Simulation results show the
efficacy of our proposed algorithm in performance and computational cost
compared to other alternative methods.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00599" title="Abstract">arXiv:2401.00599</a> (cross-list from physics.chem-ph) [<a href="/pdf/2401.00599" title="Download PDF">pdf</a>, <a href="/format/2401.00599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sub-sampling of NMR Correlation and Exchange Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Beckmann%2C+J+B+B">Julian B. B. Beckmann</a>, 
<a href="/search/physics?searchtype=author&query=Mantle%2C+M+D">Mick D. Mantle</a>, 
<a href="/search/physics?searchtype=author&query=Sederman%2C+A+J">Andrew J. Sederman</a>, 
<a href="/search/physics?searchtype=author&query=Gladden%2C+L+F">Lynn F. Gladden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sub-sampling is applied to simulated $T_1$-$D$ NMR signals and its influence
on inversion performance is evaluated. For this different levels of
sub-sampling were employed ranging from the fully sampled signal down to only
less than two percent of the original data points. This was combined with
multiple sample schemes including fully random sampling, truncation and a
combination of both. To compare the performance of different inversion
algorithms, the so-generated sub-sampled signals were inverted using Tikhonov
regularization, modified total generalized variation (MTGV) regularization,
deep learning and a combination of deep learning and Tikhonov regularization.
Further, the influence of the chosen cost function on the relative inversion
performance was investigated. Overall, it could be shown that for a vast
majority of instances, deep learning clearly outperforms regularization based
inversion methods, if the signal is fully or close to fully sampled. However,
in the case of significantly sub-sampled signals regularization yields better
inversion performance than its deep learning counterpart with MTGV clearly
prevailing over Tikhonov. Additionally, fully random sampling could be
identified as the best overall sampling scheme independent of the inversion
method. Finally, it could also be shown that the choice of cost function does
vastly influence the relative rankings of the tested inversion algorithms
highlighting the importance of choosing the cost function accordingly to
experimental intentions.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00611" title="Abstract">arXiv:2401.00611</a> (cross-list from stat.ML) [<a href="/pdf/2401.00611" title="Download PDF">pdf</a>, <a href="/format/2401.00611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Compact Representation for Bayesian Neural Networks By Removing  Permutation Symmetry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xiao%2C+T+Z">Tim Z. Xiao</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+W">Weiyang Liu</a>, 
<a href="/search/stat?searchtype=author&query=Bamler%2C+R">Robert Bamler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Workshop on Unifying Representations in Neural Models; 4 pages + appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Bayesian neural networks (BNNs) are a principled approach to modeling
predictive uncertainties in deep learning, which are important in
safety-critical applications. Since exact Bayesian inference over the weights
in a BNN is intractable, various approximate inference methods exist, among
which sampling methods such as Hamiltonian Monte Carlo (HMC) are often
considered the gold standard. While HMC provides high-quality samples, it lacks
interpretable summary statistics because its sample mean and variance is
meaningless in neural networks due to permutation symmetry. In this paper, we
first show that the role of permutations can be meaningfully quantified by a
number of transpositions metric. We then show that the recently proposed
rebasin method allows us to summarize HMC samples into a compact representation
that provides a meaningful explicit uncertainty estimate for each weight in a
neural network, thus unifying sampling methods with variational inference. We
show that this compact representation allows us to compare trained BNNs
directly in weight space across sampling methods and variational inference, and
to efficiently prune neural networks trained without explicit Bayesian
frameworks by exploiting uncertainty estimates from HMC.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00657" title="Abstract">arXiv:2401.00657</a> (cross-list from math.OC) [<a href="/pdf/2401.00657" title="Download PDF">pdf</a>, <a href="/format/2401.00657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing ADMM and Over-Relaxed ADMM Parameters for Linear Quadratic  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Song%2C+J">Jintao Song</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+W">Wenqi Lu</a>, 
<a href="/search/math?searchtype=author&query=Lei%2C+Y">Yunwen Lei</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+Y">Yuchao Tang</a>, 
<a href="/search/math?searchtype=author&query=Pan%2C+Z">Zhenkuan Pan</a>, 
<a href="/search/math?searchtype=author&query=Duan%2C+J">Jinming Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Vision and Pattern Recognition (cs.CV); Spectral Theory (math.SP)

</div>
<p class="mathjax">The Alternating Direction Method of Multipliers (ADMM) has gained significant
attention across a broad spectrum of machine learning applications.
Incorporating the over-relaxation technique shows potential for enhancing the
convergence rate of ADMM. However, determining optimal algorithmic parameters,
including both the associated penalty and relaxation parameters, often relies
on empirical approaches tailored to specific problem domains and contextual
scenarios. Incorrect parameter selection can significantly hinder ADMM's
convergence rate. To address this challenge, in this paper we first propose a
general approach to optimize the value of penalty parameter, followed by a
novel closed-form formula to compute the optimal relaxation parameter in the
context of linear quadratic problems (LQPs). We then experimentally validate
our parameter selection methods through random instantiations and diverse
imaging applications, encompassing diffeomorphic image registration, image
deblurring, and MRI reconstruction.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00664" title="Abstract">arXiv:2401.00664</a> (cross-list from math.OC) [<a href="/pdf/2401.00664" title="Download PDF">pdf</a>, <a href="/ps/2401.00664" title="Download PostScript">ps</a>, <a href="/format/2401.00664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Sample Complexity Bounds for (Regularized) Sample Average  Approximation in Several Heavy-Tailed, Non-Lipschitzian, and High-Dimensional  Cases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+H">Hongcheng Liu</a>, 
<a href="/search/math?searchtype=author&query=Tong%2C+J">Jindong Tong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Probability (math.PR); Statistics Theory (math.ST)

</div>
<p class="mathjax">We study the sample complexity of sample average approximation (SAA) and its
simple variations, referred to as the regularized SAA (RSAA), in solving convex
and strongly convex stochastic programming (SP) problems under
heavy-tailed-ness, non-Lipschitz-ness, and/or high dimensionality. The presence
of such irregularities underscores critical vacua in the literature. In
response, this paper presents three sets of results: First, we show that the
(R)SAA is effective even if the objective function is not necessarily Lipschitz
and the underlying distribution admits some bounded central moments only at
(near-)optimal solutions. Second, when the SP's objective function is the sum
of a smooth term and a Lipschitz term, we prove that the (R)SAA's sample
complexity is completely independent from any complexity measures (e.g., the
covering number) of the feasible region. Third, we explicate the (R)SAA's
sample complexities with regard to the dependence on dimensionality $d$: When
some $p$th ($p\geq 2$) central moment of the underlying distribution is
bounded, we show that the required sample size grows at a rate no worse than
$\mathcal O\left(p d^{2/p}\right)$ under any one of the three structural
assumptions: (i) strong convexity w.r.t. the $q$-norm ($q\geq 1$); (ii) the
combination of restricted strong convexity and sparsity; and (iii) a
dimension-insensitive $q$-norm of an optimal solution. In both cases of (i) and
(iii), it is further required that $p\leq q/(q-1)$. As a direct implication,
the (R)SAA's complexity becomes (poly-)logarithmic in $d$, whenever $p\geq
c\cdot \ln d$ is admissible for some constant $c&gt;0$. These new results deviate
from the SAA's typical sample complexities that grow polynomially with $d$.
Part of our proof is based on the average-replace-one (RO) stability, which
appears to be novel for the (R)SAA's analyses.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00682" title="Abstract">arXiv:2401.00682</a> (cross-list from eess.SP) [<a href="/pdf/2401.00682" title="Download PDF">pdf</a>, <a href="/format/2401.00682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Smooth Trajectory Estimator for LMB Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Van+Nguyen%2C+H">Hoa Van Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+T+T+D">Tran Thien Dat Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Shim%2C+C">Changbeom Shim</a>, 
<a href="/search/eess?searchtype=author&query=Anuar%2C+M">Marzhar Anuar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures. Presented at The 12th IEEE International Conference on Control, Automation and Information Sciences (ICCAIS 2023), Nov 2023, Hanoi, Vietnam
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper proposes a smooth-trajectory estimator for the labelled
multi-Bernoulli (LMB) filter by exploiting the special structure of the
generalised labelled multi-Bernoulli (GLMB) filter. We devise a simple and
intuitive approach to store the best association map when approximating the
GLMB random finite set (RFS) to the LMB RFS. In particular, we construct a
smooth-trajectory estimator (i.e., an estimator over the entire trajectories of
labelled estimates) for the LMB filter based on the history of the best
association map and all of the measurements up to the current time.
Experimental results under two challenging scenarios demonstrate significant
tracking accuracy improvements with negligible additional computational time
compared to the conventional LMB filter. The source code is publicly available
at https://tinyurl.com/ste-lmb, aimed at promoting advancements in MOT
algorithms.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00684" title="Abstract">arXiv:2401.00684</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2401.00684" title="Download PDF">pdf</a>, <a href="/ps/2401.00684" title="Download PostScript">ps</a>, <a href="/format/2401.00684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Temporal Filter to Extract Doped Conducting Polymer Information  Features from an Electronic Nose
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Ammar%2C+W+H">Wiem Haj Ammar</a>, 
<a href="/search/cond-mat?searchtype=author&query=Boujnah%2C+A">Aicha Boujnah</a>, 
<a href="/search/cond-mat?searchtype=author&query=Baron%2C+A">Antoine Baron</a>, 
<a href="/search/cond-mat?searchtype=author&query=Boubaker%2C+A">Aimen Boubaker</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kalboussi%2C+A">Adel Kalboussi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lmimouni%2C+K">Kamal Lmimouni</a>, 
<a href="/search/cond-mat?searchtype=author&query=Pecqueur%2C+S">Sebastien Pecqueur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Identifying relevant machine-learning features for multi-sensing platforms is
both an applicative limitation to recognize environments and a necessity to
interpret the physical relevance of transducers' complementarity in their
information processing. Particularly for long acquisitions, feature extraction
must be fully automatized without human intervention and resilient to
perturbations without increasing significantly the computational cost of a
classifier. In this study, we investigate on the relative resistance and
current modulation of a 24-dimensional conductimetric electronic nose, which
uses the exponential moving average as a floating reference in a low-cost
information descriptor for environment recognition. In particular, we
identified that depending on the structure of a linear classifier, the 'modema'
descriptor is optimized for different material sensing elements' contributions
to classify information patterns. The low-pass filtering optimization leads to
opposite behaviors between unsupervised and supervised learning: the latter one
favors longer integration of the reference, allowing to recognize five
different classes over 90%, while the first one prefers using the latest events
as its reference to clusterize patterns by environment nature. Its electronic
implementation shall greatly diminish the computational requirements of
conductimetric electronic noses for on-board environment recognition without
human supervision.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00691" title="Abstract">arXiv:2401.00691</a> (cross-list from stat.ML) [<a href="/pdf/2401.00691" title="Download PDF">pdf</a>, <a href="/format/2401.00691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Gradient Descent for Additive Nonparametric Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/stat?searchtype=author&query=Klusowski%2C+J+M">Jason M. Klusowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces an iterative algorithm designed to train additive
models with favorable memory storage and computational requirements. The
algorithm can be viewed as the functional counterpart of stochastic gradient
descent, applied to the coefficients of a truncated basis expansion of the
component functions. We show that the resulting estimator satisfies an oracle
inequality that allows for model mispecification. In the well-specified
setting, by choosing the learning rate carefully across three distinct stages
of training, we prove that its risk is minimax optimal in terms of the
dependence on the dimensionality of the data and the size of the training
sample.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00692" title="Abstract">arXiv:2401.00692</a> (cross-list from eess.IV) [<a href="/pdf/2401.00692" title="Download PDF">pdf</a>, <a href="/format/2401.00692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised learning for skin cancer diagnosis with limited training  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Haggerty%2C+H">Hamish Haggerty</a>, 
<a href="/search/eess?searchtype=author&query=Chandra%2C+R">Rohitash Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cancer diagnosis is a well-studied problem in machine learning since early
detection of cancer is often the determining factor in prognosis. Supervised
deep learning achieves excellent results in cancer image classification,
usually through transfer learning. However, these models require large amounts
of labelled data and for several types of cancer, large labelled datasets do
not exist. In this paper, we demonstrate that a model pre-trained using a
self-supervised learning algorithm known as Barlow Twins can outperform the
conventional supervised transfer learning pipeline. We juxtapose two base
models: i) pretrained in a supervised fashion on ImageNet; ii) pretrained in a
self-supervised fashion on ImageNet. Both are subsequently fine tuned on a
small labelled skin lesion dataset and evaluated on a large test set. We
achieve a mean test accuracy of 70\% for self-supervised transfer in comparison
to 66\% for supervised transfer. Interestingly, boosting performance further is
possible by self-supervised pretraining a second time (on unlabelled skin
lesion images) before subsequent fine tuning. This hints at an alternative path
to collecting more labelled data in settings where this is challenging - namely
just collecting more unlabelled images. Our framework is applicable to cancer
image classification models in the low-labelled data regime.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00728" title="Abstract">arXiv:2401.00728</a> (cross-list from eess.IV) [<a href="/pdf/2401.00728" title="Download PDF">pdf</a>, <a href="/format/2401.00728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiFusionNet: Multilayer Multimodal Fusion of Deep Neural Networks for  Chest X-Ray Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Agarwal%2C+S">Saurabh Agarwal</a>, 
<a href="/search/eess?searchtype=author&query=Arya%2C+K+V">K. V. Arya</a>, 
<a href="/search/eess?searchtype=author&query=Meena%2C+Y+K">Yogesh Kumar Meena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Chest X-ray imaging is a critical diagnostic tool for identifying pulmonary
diseases. However, manual interpretation of these images is time-consuming and
error-prone. Automated systems utilizing convolutional neural networks (CNNs)
have shown promise in improving the accuracy and efficiency of chest X-ray
image classification. While previous work has mainly focused on using feature
maps from the final convolution layer, there is a need to explore the benefits
of leveraging additional layers for improved disease classification. Extracting
robust features from limited medical image datasets remains a critical
challenge. In this paper, we propose a novel deep learning-based multilayer
multimodal fusion model that emphasizes extracting features from different
layers and fusing them. Our disease detection model considers the
discriminatory information captured by each layer. Furthermore, we propose the
fusion of different-sized feature maps (FDSFM) module to effectively merge
feature maps from diverse layers. The proposed model achieves a significantly
higher accuracy of 97.21% and 99.60% for both three-class and two-class
classifications, respectively. The proposed multilayer multimodal fusion model,
along with the FDSFM module, holds promise for accurate disease classification
and can also be extended to other disease classifications in chest X-ray
images.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00733" title="Abstract">arXiv:2401.00733</a> (cross-list from math.CO) [<a href="/pdf/2401.00733" title="Download PDF">pdf</a>, <a href="/ps/2401.00733" title="Download PostScript">ps</a>, <a href="/format/2401.00733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-optimal constructions of constant weight codes and constant  composition codes asymptotically attaining the Johnson bound: the odd  distances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+M">Miao Liu</a>, 
<a href="/search/math?searchtype=author&query=Shangguan%2C+C">Chong Shangguan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, happy new year, yuan dan kuai le
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Constant weight codes (CWCs) and constant composition codes (CCCs) are two
important classes of codes that have been studied extensively in both
combinatorics and coding theory for nearly sixty years. In this paper we show
that for {\it all} fixed odd distances, there exist near-optimal CWCs and CCCs
asymptotically achieving the classic Johnson-type upper bounds.
<br />Let $A_q(n,w,d)$ denote the maximum size of $q$-ary CWCs of length $n$ with
constant weight $w$ and minimum distance $d$. One of our main results shows
that for {\it all} fixed $q,w$ and odd $d$, one has
$\lim_{n\rightarrow\infty}\frac{A_q(n,d,w)}{\binom{n}{t}}=\frac{(q-1)^t}{\binom{w}{t}}$,
where $t=\frac{2w-d+1}{2}$. This implies the existence of near-optimal
generalized Steiner systems originally introduced by Etzion, and can be viewed
as a counterpart of a celebrated result of R\"odl on the existence of
near-optimal Steiner systems. Note that prior to our work, very little is known
about $A_q(n,w,d)$ for $q\ge 3$. A similar result is proved for the maximum
size of CCCs.
<br />We provide different proofs for our two main results, based on two
strengthenings of the well-known Frankl-R\"odl-Pippenger theorem on the
existence of near-optimal matchings in hypergraphs: the first proof follows by
Kahn's linear programming variation of the above theorem, and the second
follows by the recent independent work of Delcour-Postle, and
Glock-Joos-Kim-K\"uhn-Lichev on the existence of near-optimal matchings
avoiding certain forbidden configurations.
<br />We also present several intriguing open questions for future research.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00740" title="Abstract">arXiv:2401.00740</a> (cross-list from eess.IV) [<a href="/pdf/2401.00740" title="Download PDF">pdf</a>, <a href="/format/2401.00740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Subspace Isolation: Many-to-Many Transformer for Light Field  Image Super-resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hu%2C+Z+Z">Zeke Zexi Hu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiaoming Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chung%2C+V+Y+Y">Vera Yuk Ying Chung</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+Y">Yiran Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The effective extraction of spatial-angular features plays a crucial role in
light field image super-resolution (LFSR) tasks, and the introduction of
convolution and Transformers leads to significant improvement in this area.
Nevertheless, due to the large 4D data volume of light field images, many
existing methods opted to decompose the data into a number of lower-dimensional
subspaces and perform Transformers in each sub-space individually. As a side
effect, these methods inadvertently restrict the self-attention mechanisms to a
One-to-One scheme accessing only a limited subset of LF data, explicitly
preventing comprehensive optimization on all spatial and angular cues. In this
paper, we identify this limitation as subspace isolation and introduce a novel
Many-to-Many Transformer (M2MT) to address it. M2MT aggregates angular
information in the spatial subspace before performing the self-attention
mechanism. It enables complete access to all information across all
sub-aperture images (SAIs) in a light field image. Consequently, M2MT is
enabled to comprehensively capture long-range correlation dependencies. With
M2MT as the pivotal component, we develop a simple yet effective M2MT network
for LFSR. Our experimental results demonstrate that M2MT achieves
state-of-the-art performance across various public datasets. We further conduct
in-depth analysis using local attribution maps (LAM) to obtain visual
interpretability, and the results validate that M2MT is empowered with a truly
non-local context in both spatial and angular subspaces to mitigate subspace
isolation and acquire effective spatial-angular representation.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00744" title="Abstract">arXiv:2401.00744</a> (cross-list from physics.comp-ph) [<a href="/pdf/2401.00744" title="Download PDF">pdf</a>, <a href="/format/2401.00744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonizing Covariance and Expressiveness for Deep Hamiltonian  Regression in Crystalline Material Research: a Hybrid Cascaded Regression  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yin%2C+S">Shi Yin</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+X">Xudong Zhu</a>, 
<a href="/search/physics?searchtype=author&query=Gao%2C+T">Tianyu Gao</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+H">Haochong Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Wu%2C+F">Feng Wu</a>, 
<a href="/search/physics?searchtype=author&query=He%2C+L">Lixin He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning for Hamiltonian regression of quantum systems in material
research necessitates satisfying the covariance laws, among which achieving
SO(3)-equivariance without sacrificing the expressiveness of networks remains
an elusive challenge due to the restriction to non-linear mappings on
guaranteeing theoretical equivariance. To alleviate the
covariance-expressiveness dilemma, we propose a hybrid framework with two
cascaded regression stages. The first stage, with a theoretically-guaranteed
covariant neural network modeling symmetry properties of 3D atom systems,
yields theoretically covariant features and baseline Hamiltonian predictions,
assisting the second stage in learning covariance. Meanwhile, the second stage,
powered by a non-linear 3D graph Transformer network we propose for structural
modeling of 3D atomic systems, refines the first stage's output as a
fine-grained prediction of Hamiltonians with better expressiveness capability.
The combination of a theoretically covariant yet inevitably less expressive
model with a highly expressive non-linear network enables precise,
generalizable predictions while maintaining robust covariance under coordinate
transformations. Our method achieves state-of-the-art performance in
Hamiltonian prediction for electronic structure calculations, confirmed through
experiments on five crystalline material databases.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00746" title="Abstract">arXiv:2401.00746</a> (cross-list from q-bio.NC) [<a href="/pdf/2401.00746" title="Download PDF">pdf</a>, <a href="/format/2401.00746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn to integrate parts for whole through correlated neural variability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhu%2C+Z">Zhichao Zhu</a>, 
<a href="/search/q-bio?searchtype=author&query=Qi%2C+Y">Yang Qi</a>, 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+W">Wenlian Lu</a>, 
<a href="/search/q-bio?searchtype=author&query=Feng%2C+J">Jianfeng Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Neural and Evolutionary Computing (cs.NE); Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">Sensory perception originates from the responses of sensory neurons, which
react to a collection of sensory signals linked to various physical attributes
of a singular perceptual object. Unraveling how the brain extracts perceptual
information from these neuronal responses is a pivotal challenge in both
computational neuroscience and machine learning. Here we introduce a
statistical mechanical theory, where perceptual information is first encoded in
the correlated variability of sensory neurons and then reformatted into the
firing rates of downstream neurons. Applying this theory, we illustrate the
encoding of motion direction using neural covariance and demonstrate
high-fidelity direction recovery by spiking neural networks. Networks trained
under this theory also show enhanced performance in classifying natural images,
achieving higher accuracy and faster inference speed. Our results challenge the
traditional view of neural covariance as a secondary factor in neural coding,
highlighting its potential influence on brain function.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00775" title="Abstract">arXiv:2401.00775</a> (cross-list from stat.AP) [<a href="/pdf/2401.00775" title="Download PDF">pdf</a>, <a href="/format/2401.00775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent Advances in Text Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ke%2C+Z+T">Zheng Tracy Ke</a>, 
<a href="/search/stat?searchtype=author&query=Ji%2C+P">Pengsheng Ji</a>, 
<a href="/search/stat?searchtype=author&query=Jin%2C+J">Jiashun Jin</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+W">Wanshan Li</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Annual Review of Statistics and Its Application 2024 11:1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Text analysis is an interesting research area in data science and has various
applications, such as in artificial intelligence, biomedical research, and
engineering. We review popular methods for text analysis, ranging from topic
modeling to the recent neural language models. In particular, we review
Topic-SCORE, a statistical approach to topic modeling, and discuss how to use
it to analyze MADStat - a dataset on statistical publications that we collected
and cleaned.
<br />The application of Topic-SCORE and other methods on MADStat leads to
interesting findings. For example, $11$ representative topics in statistics are
identified. For each journal, the evolution of topic weights over time can be
visualized, and these results are used to analyze the trends in statistical
research. In particular, we propose a new statistical model for ranking the
citation impacts of $11$ topics, and we also build a cross-topic citation graph
to illustrate how research results on different topics spread to one another.
<br />The results on MADStat provide a data-driven picture of the statistical
research in $1975$--$2015$, from a text analysis perspective.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00787" title="Abstract">arXiv:2401.00787</a> (cross-list from quant-ph) [<a href="/pdf/2401.00787" title="Download PDF">pdf</a>, <a href="/format/2401.00787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum multiple gray scale images encryption scheme in the bit plane  representation model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Levaillant%2C+C+I">Claire I. Levaillant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures, 2 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Quantum Algebra (math.QA)

</div>
<p class="mathjax">After introducing a bit-plane quantum representation for a multi-image, we
present a novel way to encrypt/decrypt multiple images using a quantum
computer. Our encryption scheme is based on a two-stage scrambling of the
images and of the bit planes on one hand and of the pixel positions on the
other hand, each time using quantum baker maps. The resulting quantum
multi-image is then diffused with controlled CNOT gates using a sine
chaotification of a two-dimensional H\'enon map as well as Chebyshev
polynomials. The decryption is processed by operating all the inverse quantum
gates in the reverse order.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00801" title="Abstract">arXiv:2401.00801</a> (cross-list from math.CO) [<a href="/pdf/2401.00801" title="Download PDF">pdf</a>, <a href="/ps/2401.00801" title="Download PostScript">ps</a>, <a href="/format/2401.00801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved bounds for the bracketing number of orthants or revisiting an  algorithm of Thi&#xe9;mard to compute bounds for the star discrepancy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gnewuch%2C+M">Michael Gnewuch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG); Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We improve the best known upper bound for the bracketing number of
$d$-dimensional axis-parallel boxes anchored in $0$ (or, put differently, of
lower left orthants intersected with the $d$-dimensional unit cube $[0,1]^d$).
More precisely, we provide a better upper bound for the cardinality of an
algorithmic bracketing cover construction due to Eric Thi\'emard, which forms
the core of his algorithm to approximate the star discrepancy of arbitrary
point sets from [E. Thi\'emard, An algorithm to compute bounds for the star
discrepancy, J.~Complexity 17 (2001), 850 -- 880].
<br />Moreover, the new upper bound for the bracketing number of anchored
axis-parallel boxes yields an improved upper bound for the bracketing number of
arbitrary axis-parallel boxes in $[0,1]^d$.
<br />In our upper bounds all constants are fully explicit.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00813" title="Abstract">arXiv:2401.00813</a> (cross-list from eess.AS) [<a href="/pdf/2401.00813" title="Download PDF">pdf</a>, <a href="/format/2401.00813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultraspherical/Gegenbauer polynomials to unify 2D/3D Ambisonic  directivity designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zotter%2C+F">Franz Zotter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">This report on axisymmetric ultraspherical/Gegenbauer polynomials and their
use in Ambisonic directivity design in 2D and 3D presents an alternative
mathematical formalism to what can be read in, e.g., my and Matthias Frank's
book on Ambisonics or J\'er\^ome Daniel's thesis, Gary Elko's differential
array book chapters, or Boaz Rafaely's spherical microphone array book.
<br />Ultraspherical/Gegenbauer polynomials are highly valuable when designing
axisymmetric beams and understanding spherical t designs that this report will
shed some light on what circular, spherical, and ultraspherical axisymmetric
polynomials are. While mathematically interesting by themselves already, they
can be useful in spherical beamforming as described in the literature on
spherical and differential microphone arrays.
<br />In this report, these ultraspherical/Gegenbauer polynomials will be used to
uniformly derive for arbitrary dimensions D the various directivity designs or
Ambisonic order weightings known from literature: max-DI/basic, max-rE ,
supercardioid, cardioid/inphase. Is there a way to relate higher-order
cardioids and supercardioids? How could one define directivity patterns with an
on-axis flatness constraint?
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00815" title="Abstract">arXiv:2401.00815</a> (cross-list from math.OC) [<a href="/pdf/2401.00815" title="Download PDF">pdf</a>, <a href="/format/2401.00815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsafe Probabilities and Risk Contours for Stochastic Processes using  Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miller%2C+J">Jared Miller</a>, 
<a href="/search/math?searchtype=author&query=Tacchi%2C+M">Matteo Tacchi</a>, 
<a href="/search/math?searchtype=author&query=Henrion%2C+D">Didier Henrion</a>, 
<a href="/search/math?searchtype=author&query=Sznaier%2C+M">Mario Sznaier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper proposes an algorithm to calculate the maximal probability of
unsafety with respect to trajectories of a stochastic process and a hazard set.
The unsafe probability estimation problem is cast as a primal-dual pair of
infinite-dimensional linear programs in occupation measures and continuous
functions. This convex relaxation is nonconservative (to the true probability
of unsafety) under compactness and regularity conditions in dynamics. The
continuous-function linear program is linked to existing probability-certifying
barrier certificates of safety. Risk contours for initial conditions of the
stochastic process may be generated by suitably modifying the objective of the
continuous-function program, forming an interpretable and visual representation
of stochastic safety for test initial conditions. All infinite-dimensional
linear programs are truncated to finite dimension by the Moment-Sum-of-Squares
hierarchy of semidefinite programs. Unsafe-probability estimation and risk
contours are generated for example stochastic processes.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00827" title="Abstract">arXiv:2401.00827</a> (cross-list from math.CO) [<a href="/pdf/2401.00827" title="Download PDF">pdf</a>, <a href="/ps/2401.00827" title="Download PostScript">ps</a>, <a href="/format/2401.00827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multipartite analogue of Dilworth&#x27;s Theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fox%2C+J">Jacob Fox</a>, 
<a href="/search/math?searchtype=author&query=Pham%2C+H+T">Huy Tuan Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We prove that every partially ordered set on $n$ elements contains $k$
subsets $A_{1},A_{2},\dots,A_{k}$ such that either each of these subsets has
size $\Omega(n/k^{5})$ and, for every $i&lt;j$, every element in $A_{i}$ is less
than or equal to every element in $A_{j}$, or each of these subsets has size
$\Omega(n/(k^{2}\log n))$ and, for every $i \not = j$, every element in $A_{i}$
is incomparable with every element in $A_{j}$ for $i\ne j$. This answers a
question of the first author from 2006. As a corollary, we prove for each
positive integer $h$ there is $C_h$ such that for any $h$ partial orders
$&lt;_{1},&lt;_{2},\dots,&lt;_{h}$ on a set of $n$ elements, there exists $k$ subsets
$A_{1},A_{2},\dots,A_{k}$ each of size at least $n/(k\log n)^{C_{h}}$ such that
for each partial order $&lt;_{\ell}$, either
$a_{1}&lt;_{\ell}a_{2}&lt;_{\ell}\dots&lt;_{\ell}a_{k}$ for any tuple of elements
$(a_1,a_2,\dots,a_k) \in A_1\times A_2\times \dots \times A_k$, or
$a_{1}&gt;_{\ell}a_{2}&gt;_{\ell}\dots&gt;_{\ell}a_{k}$ for any $(a_1,a_2,\dots,a_k) \in
A_1\times A_2\times \dots \times A_k$, or $a_i$ is incomparable with $a_j$ for
any $i\ne j$, $a_i\in A_i$ and $a_j\in A_j$. This improves on a 2009 result of
Pach and the first author motivated by problems in discrete geometry.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00844" title="Abstract">arXiv:2401.00844</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2401.00844" title="Download PDF">pdf</a>, <a href="/format/2401.00844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The semi-analytic theory and computation of finite-depth standing water  waves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Abassi%2C+A">Ahmad Abassi</a>, 
<a href="/search/physics?searchtype=author&query=Wilkening%2C+J">Jon Wilkening</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We propose a semi-analytic Stokes expansion ansatz for finite-depth standing
water waves and devise a recursive algorithm to solve the system of
differential equations governing the expansion coefficients. We implement the
algorithm on a supercomputer using arbitrary-precision arithmetic. The Stokes
expansion introduces hyperbolic trigonometric terms that require exponentiation
of power series. We handle this efficiently using Bell polynomials. Under mild
assumptions on the fluid depth, we prove that there are no exact resonances,
though small divisors may occur. Sudden changes in growth rate in the expansion
coefficients are found to correspond to imperfect bifurcations observed when
families of standing waves are computed using a shooting method. A direct
connection between small divisors in the recursive algorithm and imperfect
bifurcations in the solution curves is observed, where the small divisor
excites higher-frequency parasitic standing waves that oscillate on top of the
main wave. A 109th order Pad\'e approximation maintains 25--30 digits of
accuracy on both sides of the first imperfect bifurcation encountered for the
unit-depth problem. This suggests that even if the Stokes expansion is
divergent, there may be a closely related convergent sequence of rational
approximations.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue,  2 Jan 24</h3>
<dl>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.05690" title="Abstract">arXiv:2007.05690</a> (replaced) [<a href="/pdf/2007.05690" title="Download PDF">pdf</a>, <a href="/format/2007.05690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Linear Speedup Analysis of Federated Averaging and Nesterov  FedAvg
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zhaonan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kaixiang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaojian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiayu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyuan Zhou</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Artificial Intelligence Research 78 (2023) 1143-1200
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.13272" title="Abstract">arXiv:2102.13272</a> (replaced) [<a href="/pdf/2102.13272" title="Download PDF">pdf</a>, <a href="/ps/2102.13272" title="Download PostScript">ps</a>, <a href="/format/2102.13272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Large Kernel Convolutions with Nested Winograd  Transformation.pdf
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jingbo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xizi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tsui%2C+C">Chi-Ying Tsui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published ref to <a href="https://ieeexplore.ieee.org/document/10321932">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.02543" title="Abstract">arXiv:2103.02543</a> (replaced) [<a href="/pdf/2103.02543" title="Download PDF">pdf</a>, <a href="/format/2103.02543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the geometric and Riemannian structure of the spaces of group  equivariant non-expansive operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cascarano%2C+P">Pasquale Cascarano</a>, 
<a href="/search/math?searchtype=author&query=Frosini%2C+P">Patrizio Frosini</a>, 
<a href="/search/math?searchtype=author&query=Quercioli%2C+N">Nicola Quercioli</a>, 
<a href="/search/math?searchtype=author&query=Saki%2C+A">Amir Saki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 1 figure. The introduction has been extended and a section on the group's action on the space of GENEOs has been added. Some minor fixes are made. The text has been simplified and made clearer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Differential Geometry (math.DG)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.11469" title="Abstract">arXiv:2106.11469</a> (replaced) [<a href="/pdf/2106.11469" title="Download PDF">pdf</a>, <a href="/format/2106.11469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time XFEL Data Analysis at SLAC and NERSC: a Trial Run of Nascent  Exascale Experimental Data Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blaschke%2C+J+P">Johannes P. Blaschke</a> (1), 
<a href="/search/cs?searchtype=author&query=Brewster%2C+A+S">Aaron S. Brewster</a> (2), 
<a href="/search/cs?searchtype=author&query=Paley%2C+D+W">Daniel W. Paley</a> (2), 
<a href="/search/cs?searchtype=author&query=Mendez%2C+D">Derek Mendez</a> (2), 
<a href="/search/cs?searchtype=author&query=Bhowmick%2C+A">Asmit Bhowmick</a> (2), 
<a href="/search/cs?searchtype=author&query=Sauter%2C+N+K">Nicholas K. Sauter</a> (2), 
<a href="/search/cs?searchtype=author&query=Kr%C3%B6ger%2C+W">Wilko Kr&#xf6;ger</a> (3), 
<a href="/search/cs?searchtype=author&query=Shankar%2C+M">Murali Shankar</a> (3), 
<a href="/search/cs?searchtype=author&query=Enders%2C+B">Bjoern Enders</a> (1), 
<a href="/search/cs?searchtype=author&query=Bard%2C+D">Deborah Bard</a> (1) ((1) National Energy Research Scientific Computing Center, Lawrence Berkeley National Laboratory, USA, (2) Molecular Biophysics and Integrated Bioimaging Division, Lawrence Berkeley National Laboratory, USA, (3) SLAC National Accelerator Laboratory, USA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.14174" title="Abstract">arXiv:2109.14174</a> (replaced) [<a href="/pdf/2109.14174" title="Download PDF">pdf</a>, <a href="/format/2109.14174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Camera Human Motion Transfer by Time Series Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yaping Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanghan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+E+Y">Edmund Y. Lam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.05530" title="Abstract">arXiv:2111.05530</a> (replaced) [<a href="/pdf/2111.05530" title="Download PDF">pdf</a>, <a href="/format/2111.05530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearly Optimal Linear Convergence of Stochastic Primal-Dual Methods for  Linear Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lu%2C+H">Haihao Lu</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+J">Jinwen Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08364" title="Abstract">arXiv:2112.08364</a> (replaced) [<a href="/pdf/2112.08364" title="Download PDF">pdf</a>, <a href="/ps/2112.08364" title="Download PostScript">ps</a>, <a href="/format/2112.08364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Valuation for Vertical Federated Learning: A Model-free and  Privacy-preserving Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Leye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xiao Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.07794" title="Abstract">arXiv:2201.07794</a> (replaced) [<a href="/pdf/2201.07794" title="Download PDF">pdf</a>, <a href="/format/2201.07794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Non-Expert&#x27;s Introduction to Data Ethics for Mathematicians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Porter%2C+M+A">Mason A. Porter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version (reorganized, expanded, and updated; with many new references). This is a book chapter. It is associated with my data-ethics lecture at the 2021 AMS Short Course on Mathematical and Computational Methods for Complex Social Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Overview (math.HO)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Physics and Society (physics.soc-ph); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.00772" title="Abstract">arXiv:2202.00772</a> (replaced) [<a href="/pdf/2202.00772" title="Download PDF">pdf</a>, <a href="/format/2202.00772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PiP-X: Online feedback motion planning/replanning in dynamic  environments using invariant funnels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaffar%2C+M+K+M">Mohamed Khalid M Jaffar</a>, 
<a href="/search/cs?searchtype=author&query=Otte%2C+M">Michael Otte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An abridged version of this paper appeared in the conference proceedings of the International Workshop on the Algorithmic Foundations of Robotics (WAFR) 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The International Journal of Robotics Research (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.06424" title="Abstract">arXiv:2203.06424</a> (replaced) [<a href="/e-print/2203.06424" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VariabilityTrack:Multi-Object Tracking with Variable Speed Object  Movement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+R">Run Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">JinLin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qiao Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> find some mistake in this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.07436" title="Abstract">arXiv:2203.07436</a> (replaced) [<a href="/pdf/2203.07436" title="Download PDF">pdf</a>, <a href="/format/2203.07436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuperAnimal pretrained pose estimation models for behavioral analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Shaokai Ye</a>, 
<a href="/search/cs?searchtype=author&query=Filippova%2C+A">Anastasiia Filippova</a>, 
<a href="/search/cs?searchtype=author&query=Lauer%2C+J">Jessy Lauer</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+S">Steffen Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Vidal%2C+M">Maxime Vidal</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+T">Tian Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Mathis%2C+A">Alexander Mathis</a>, 
<a href="/search/cs?searchtype=author&query=Mathis%2C+M+W">Mackenzie Weygandt Mathis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Models and demos available at <a href="http://modelzoo.deeplabcut.org">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.14277" title="Abstract">arXiv:2203.14277</a> (replaced) [<a href="/pdf/2203.14277" title="Download PDF">pdf</a>, <a href="/ps/2203.14277" title="Download PostScript">ps</a>, <a href="/format/2203.14277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UAST: Unicode Aware Sanskrit Transliteration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalwadi%2C+A">Aneri Dalwadi</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+D">Dhruvil Dave</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages. Source code and implementation are available on GitHub at <a href="https://github.com/dhruvildave/uast">this https URL</a> and <a href="https://github.com/aneri0x4f/uast-cli">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.05696" title="Abstract">arXiv:2204.05696</a> (replaced) [<a href="/pdf/2204.05696" title="Download PDF">pdf</a>, <a href="/ps/2204.05696" title="Download PostScript">ps</a>, <a href="/format/2204.05696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positive definite functions on a regular domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Buhmann%2C+M">Martin Buhmann</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Y">Yuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Classical Analysis and ODEs (math.CA)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00362" title="Abstract">arXiv:2205.00362</a> (replaced) [<a href="/pdf/2205.00362" title="Download PDF">pdf</a>, <a href="/ps/2205.00362" title="Download PostScript">ps</a>, <a href="/format/2205.00362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple and General Duality Proof for Wasserstein Distributionally  Robust Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+L">Luhao Zhang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+J">Jincheng Yang</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+R">Rui Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00605" title="Abstract">arXiv:2205.00605</a> (replaced) [<a href="/pdf/2205.00605" title="Download PDF">pdf</a>, <a href="/format/2205.00605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cluster-based Regression using Variational Inference and Applications in  Financial Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Nagpal%2C+U">Udai Nagpal</a>, 
<a href="/search/q-fin?searchtype=author&query=Nagpal%2C+K">Krishan Nagpal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added comparison to regression without clusters and clearer description of theoretical contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.04151" title="Abstract">arXiv:2205.04151</a> (replaced) [<a href="/pdf/2205.04151" title="Download PDF">pdf</a>, <a href="/format/2205.04151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning effective dynamics from data-driven stochastic systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Feng%2C+L">Lingyu Feng</a>, 
<a href="/search/stat?searchtype=author&query=Gao%2C+T">Ting Gao</a>, 
<a href="/search/stat?searchtype=author&query=Dai%2C+M">Min Dai</a>, 
<a href="/search/stat?searchtype=author&query=Duan%2C+J">Jinqiao Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10981" title="Abstract">arXiv:2206.10981</a> (replaced) [<a href="/pdf/2206.10981" title="Download PDF">pdf</a>, <a href="/format/2206.10981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Sampling-based Particle Filter for Visual-inertial Gimbal in  the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xueyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Herrera%2C+A">Ariel Herrera</a>, 
<a href="/search/cs?searchtype=author&query=Lema%2C+H">Henry Lema</a>, 
<a href="/search/cs?searchtype=author&query=Valencia%2C+E">Esteban Valencia</a>, 
<a href="/search/cs?searchtype=author&query=Vandewalle%2C+P">Patrick Vandewalle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> content in 6 pages, 9 figures, 2 pseudo codes, one table, accepted by ICRA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Image and Video Processing (eess.IV); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12987" title="Abstract">arXiv:2206.12987</a> (replaced) [<a href="/pdf/2206.12987" title="Download PDF">pdf</a>, <a href="/format/2206.12987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlowX: Towards Explainable Graph Neural Networks via Message Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+S">Shurui Gui</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lao%2C+Q">Qicheng Lao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04173" title="Abstract">arXiv:2207.04173</a> (replaced) [<a href="/pdf/2207.04173" title="Download PDF">pdf</a>, <a href="/format/2207.04173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Approximation with Decision-Dependent Distributions:  Asymptotic Normality and Optimality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cutler%2C+J">Joshua Cutler</a>, 
<a href="/search/math?searchtype=author&query=D%C3%ADaz%2C+M">Mateo D&#xed;az</a>, 
<a href="/search/math?searchtype=author&query=Drusvyatskiy%2C+D">Dmitriy Drusvyatskiy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 1 figure. v2: revised asymptotic optimality results and reworked exposition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10226" title="Abstract">arXiv:2207.10226</a> (replaced) [<a href="/pdf/2207.10226" title="Download PDF">pdf</a>, <a href="/format/2207.10226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Privacy-Preserving Vertical Federated Learning by Efficient  Communication with ADMM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chulin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Nourian%2C+A">Arash Nourian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10308" title="Abstract">arXiv:2207.10308</a> (replaced) [<a href="/pdf/2207.10308" title="Download PDF">pdf</a>, <a href="/format/2207.10308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniFed: All-In-One Federated Learning Platform to Unify Open-Source  Frameworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+T">Tianneng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chulin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kangping Hu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Haoyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaojun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Vu-Le%2C+T">The-Anh Vu-Le</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nourian%2C+A">Arash Nourian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/AI-secure/FLBenchmark-toolkit">this https URL</a> Website: <a href="https://unifedbenchmark.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14653" title="Abstract">arXiv:2207.14653</a> (replaced) [<a href="/pdf/2207.14653" title="Download PDF">pdf</a>, <a href="/format/2207.14653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble forecasts in reproducing kernel Hilbert space family
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Duf%C3%A9e%2C+B">Benjamin Duf&#xe9;e</a>, 
<a href="/search/math-ph?searchtype=author&query=Hug%2C+B">B&#xe9;renger Hug</a>, 
<a href="/search/math-ph?searchtype=author&query=M%C3%A9min%2C+E">Etienne M&#xe9;min</a>, 
<a href="/search/math-ph?searchtype=author&query=Tissot%2C+G">Gilles Tissot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Computational Physics (physics.comp-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00946" title="Abstract">arXiv:2208.00946</a> (replaced) [<a href="/pdf/2208.00946" title="Download PDF">pdf</a>, <a href="/format/2208.00946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-aware Memory Network for Fast Video Salient Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Haoran Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peipei Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guodao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongdong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Ronghua Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofei He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09419" title="Abstract">arXiv:2208.09419</a> (replaced) [<a href="/pdf/2208.09419" title="Download PDF">pdf</a>, <a href="/format/2208.09419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Line Coverage with Multiple Robots: Algorithms and Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Saurav Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Akella%2C+S">Srinivas Akella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper will appear in the IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09709" title="Abstract">arXiv:2208.09709</a> (replaced) [<a href="/pdf/2208.09709" title="Download PDF">pdf</a>, <a href="/format/2208.09709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BSpell: A CNN-Blended BERT Based Bangla Spell Checker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+C+R">Chowdhury Rafeed Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+H">MD. Hasibur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Zakir%2C+S">Samiha Zakir</a>, 
<a href="/search/cs?searchtype=author&query=Rafsan%2C+M">Mohammad Rafsan</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+M+E">Mohammed Eunus Ali</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Association for Computational Linguistics, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09894" title="Abstract">arXiv:2208.09894</a> (replaced) [<a href="/pdf/2208.09894" title="Download PDF">pdf</a>, <a href="/ps/2208.09894" title="Download PostScript">ps</a>, <a href="/format/2208.09894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byzantines can also Learn from History: Fall of Centered Clipping in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ozfatura%2C+K">Kerem Ozfatura</a>, 
<a href="/search/cs?searchtype=author&query=Ozfatura%2C+E">Emre Ozfatura</a>, 
<a href="/search/cs?searchtype=author&query=Kupcu%2C+A">Alptekin Kupcu</a>, 
<a href="/search/cs?searchtype=author&query=Gunduz%2C+D">Deniz Gunduz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Information Forensics and Security 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02614" title="Abstract">arXiv:2209.02614</a> (replaced) [<a href="/pdf/2209.02614" title="Download PDF">pdf</a>, <a href="/format/2209.02614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variable binding and substitution for (nameless) dummies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirschowitz%2C+A">Andr&#xe9; Hirschowitz</a>, 
<a href="/search/cs?searchtype=author&query=Hirschowitz%2C+T">Tom Hirschowitz</a>, 
<a href="/search/cs?searchtype=author&query=Lafont%2C+A">Ambroise Lafont</a>, 
<a href="/search/cs?searchtype=author&query=Maggesi%2C+M">Marco Maggesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Expanded version of the FoSSaCS 2022 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03255" title="Abstract">arXiv:2209.03255</a> (replaced) [<a href="/pdf/2209.03255" title="Download PDF">pdf</a>, <a href="/format/2209.03255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goldfish: No More Attacks on Ethereum?!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Amato%2C+F">Francesco D&#x27;Amato</a>, 
<a href="/search/cs?searchtype=author&query=Neu%2C+J">Joachim Neu</a>, 
<a href="/search/cs?searchtype=author&query=Tas%2C+E+N">Ertem Nusret Tas</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+D">David Tse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Financial Cryptography and Data Security 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04030" title="Abstract">arXiv:2209.04030</a> (replaced) [<a href="/pdf/2209.04030" title="Download PDF">pdf</a>, <a href="/format/2209.04030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling the Connections between Privacy and Certified Robustness in  Federated Learning Against Poisoning Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chulin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yunhui Long</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Nourian%2C+A">Arash Nourian</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM CCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00392" title="Abstract">arXiv:2210.00392</a> (replaced) [<a href="/pdf/2210.00392" title="Download PDF">pdf</a>, <a href="/ps/2210.00392" title="Download PostScript">ps</a>, <a href="/format/2210.00392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physical Computing: A Category Theoretic Perspective on Physical  Computation and System Compositionality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dehghani%2C+N">Nima Dehghani</a>, 
<a href="/search/quant-ph?searchtype=author&query=Caterina%2C+G">Gianluca Caterina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computational Physics (physics.comp-ph); Other Quantitative Biology (q-bio.OT)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06971" title="Abstract">arXiv:2210.06971</a> (replaced) [<a href="/pdf/2210.06971" title="Download PDF">pdf</a>, <a href="/format/2210.06971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shot-frugal and Robust quantum kernel classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shastry%2C+A">Abhay Shastry</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jayakumar%2C+A">Abhijith Jayakumar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Patel%2C+A">Apoorva Patel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bhattacharyya%2C+C">Chiranjib Bhattacharyya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 8 figs, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08966" title="Abstract">arXiv:2210.08966</a> (replaced) [<a href="/pdf/2210.08966" title="Download PDF">pdf</a>, <a href="/format/2210.08966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable authentic research education framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samsonau%2C+S+V">Sergey V Samsonau</a>, 
<a href="/search/cs?searchtype=author&query=Kurbonova%2C+A">Aziza Kurbonova</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lashen%2C+H">Hazem Lashen</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiamu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Merchant%2C+T">Theresa Merchant</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruoxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mehnaz%2C+L">Laiba Mehnaz</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zecheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+I">Ishita Patil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09929" title="Abstract">arXiv:2210.09929</a> (replaced) [<a href="/pdf/2210.09929" title="Download PDF">pdf</a>, <a href="/format/2210.09929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dockhorn%2C+T">Tim Dockhorn</a>, 
<a href="/search/stat?searchtype=author&query=Cao%2C+T">Tianshi Cao</a>, 
<a href="/search/stat?searchtype=author&query=Vahdat%2C+A">Arash Vahdat</a>, 
<a href="/search/stat?searchtype=author&query=Kreis%2C+K">Karsten Kreis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at TMLR (<a href="https://openreview.net/forum?id=ZPpQk7FJXF">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14416" title="Abstract">arXiv:2210.14416</a> (replaced) [<a href="/pdf/2210.14416" title="Download PDF">pdf</a>, <a href="/format/2210.14416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Residual Back Projection With Untrained Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shu%2C+Z">Ziyu Shu</a>, 
<a href="/search/eess?searchtype=author&query=Entezari%2C+A">Alireza Entezari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01229" title="Abstract">arXiv:2211.01229</a> (replaced) [<a href="/pdf/2211.01229" title="Download PDF">pdf</a>, <a href="/format/2211.01229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast convergent PML method for scattering with periodic surfaces: the  exceptional case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+R">Ruming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04153" title="Abstract">arXiv:2211.04153</a> (replaced) [<a href="/pdf/2211.04153" title="Download PDF">pdf</a>, <a href="/ps/2211.04153" title="Download PostScript">ps</a>, <a href="/format/2211.04153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solution to a problem of Katona on counting cliques of weighted graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Borg%2C+P">Peter Borg</a>, 
<a href="/search/math?searchtype=author&query=Feghali%2C+C">Carl Feghali</a>, 
<a href="/search/math?searchtype=author&query=Pellerin%2C+R">R&#xe9;mi Pellerin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, minor corrections made
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Discrete Applied Mathematics 345 (2024), 147-155
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08508" title="Abstract">arXiv:2211.08508</a> (replaced) [<a href="/pdf/2211.08508" title="Download PDF">pdf</a>, <a href="/format/2211.08508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing and Utilizing the Interplay between Quantum Technologies  and Non-Terrestrial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Al-Hraishawi%2C+H">Hayder Al-Hraishawi</a>, 
<a href="/search/eess?searchtype=author&query=Rehman%2C+J+u">Junaid ur Rehman</a>, 
<a href="/search/eess?searchtype=author&query=Razavi%2C+M">Mohsen Razavi</a>, 
<a href="/search/eess?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10867" title="Abstract">arXiv:2211.10867</a> (replaced) [<a href="/pdf/2211.10867" title="Download PDF">pdf</a>, <a href="/format/2211.10867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Paradigm of Content Constraints in GAN-based Unpaired  Image-to-Image Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiuding Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaoyao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+D">Dong Miao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Linjie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yu Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02653" title="Abstract">arXiv:2212.02653</a> (replaced) [<a href="/pdf/2212.02653" title="Download PDF">pdf</a>, <a href="/ps/2212.02653" title="Download PostScript">ps</a>, <a href="/format/2212.02653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite model theory for pseudovarieties and universal algebra:  preservation, definability and complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ham%2C+L">Lucy Ham</a>, 
<a href="/search/math?searchtype=author&query=Jackson%2C+M">Marcel Jackson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Computational Complexity (cs.CC); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08559" title="Abstract">arXiv:2212.08559</a> (replaced) [<a href="/pdf/2212.08559" title="Download PDF">pdf</a>, <a href="/format/2212.08559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grothendieck inequalities characterize converses to the polynomial  method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bri%C3%ABt%2C+J">Jop Bri&#xeb;t</a>, 
<a href="/search/quant-ph?searchtype=author&query=Guti%C3%A9rrez%2C+F+E">Francisco Escudero Guti&#xe9;rrez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gribling%2C+S">Sander Gribling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version adds to the previous one part of the results of an earlier work by the first two authors (<a href="/abs/2204.12303">arXiv:2204.12303</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10772" title="Abstract">arXiv:2212.10772</a> (replaced) [<a href="/pdf/2212.10772" title="Download PDF">pdf</a>, <a href="/format/2212.10772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Light Image and Video Enhancement: A Comprehensive Survey and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yiling Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jinqian Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Changjie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+G">Gaurav Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 10 tables, and 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12802" title="Abstract">arXiv:2212.12802</a> (replaced) [<a href="/pdf/2212.12802" title="Download PDF">pdf</a>, <a href="/format/2212.12802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Distributions of Huge Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldreich%2C+O">Oded Goldreich</a>, 
<a href="/search/cs?searchtype=author&query=Ron%2C+D">Dana Ron</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TheoretiCS, Volume 2 (2023), Article 12, 1-53
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14354" title="Abstract">arXiv:2212.14354</a> (replaced) [<a href="/pdf/2212.14354" title="Download PDF">pdf</a>, <a href="/ps/2212.14354" title="Download PostScript">ps</a>, <a href="/format/2212.14354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fault Location Method Based on Electromagnetic Transient Convolution  Considering Frequency-Dependent Parameters and Lossy Ground
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Guanbo Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhuang%2C+C">Chijie Zhuang</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+J">Jun Deng</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+Z">Zhicheng Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03749" title="Abstract">arXiv:2301.03749</a> (replaced) [<a href="/pdf/2301.03749" title="Download PDF">pdf</a>, <a href="/format/2301.03749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markovian Sliced Wasserstein Distances: Beyond Independent Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+K">Khai Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Ren%2C+T">Tongzheng Ren</a>, 
<a href="/search/stat?searchtype=author&query=Ho%2C+N">Nhat Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023, 29 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05985" title="Abstract">arXiv:2301.05985</a> (replaced) [<a href="/pdf/2301.05985" title="Download PDF">pdf</a>, <a href="/format/2301.05985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct numerical simulation of electrokinetic transport phenomena in  fluids: variational multi-scale stabilization and octree-based mesh  refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kim%2C+S">Sungu Kim</a>, 
<a href="/search/math?searchtype=author&query=Saurabh%2C+K">Kumar Saurabh</a>, 
<a href="/search/math?searchtype=author&query=Khanwale%2C+M+A">Makrand A. Khanwale</a>, 
<a href="/search/math?searchtype=author&query=Mani%2C+A">Ali Mani</a>, 
<a href="/search/math?searchtype=author&query=Anand%2C+R+K">Robbyn K. Anand</a>, 
<a href="/search/math?searchtype=author&query=Ganapathysubramanian%2C+B">Baskar Ganapathysubramanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Journal of Computational Physics, 34 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07390" title="Abstract">arXiv:2301.07390</a> (replaced) [<a href="/pdf/2301.07390" title="Download PDF">pdf</a>, <a href="/format/2301.07390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relativistic Digital Twin: Bringing the IoT to the Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sciullo%2C+L">Luca Sciullo</a>, 
<a href="/search/cs?searchtype=author&query=De+Marchi%2C+A">Alberto De Marchi</a>, 
<a href="/search/cs?searchtype=author&query=Trotta%2C+A">Angelo Trotta</a>, 
<a href="/search/cs?searchtype=author&query=Montori%2C+F">Federico Montori</a>, 
<a href="/search/cs?searchtype=author&query=Bononi%2C+L">Luciano Bononi</a>, 
<a href="/search/cs?searchtype=author&query=Di+Felice%2C+M">Marco Di Felice</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures, 4 tables, 6 listings
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Future Generation Computer Systems 153, 521-536 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12526" title="Abstract">arXiv:2301.12526</a> (replaced) [<a href="/pdf/2301.12526" title="Download PDF">pdf</a>, <a href="/format/2301.12526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outer Bounds on the CEO Problem with Privacy Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yachongka%2C+V">Vamoua Yachongka</a>, 
<a href="/search/cs?searchtype=author&query=Yagi%2C+H">Hideki Yagi</a>, 
<a href="/search/cs?searchtype=author&query=Ochiai%2C+H">Hideki Ochiai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00293" title="Abstract">arXiv:2302.00293</a> (replaced) [<a href="/pdf/2302.00293" title="Download PDF">pdf</a>, <a href="/format/2302.00293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Methods, Challenges and Perspectives in Causality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gendron%2C+G">Ga&#xeb;l Gendron</a>, 
<a href="/search/cs?searchtype=author&query=Witbrock%2C+M">Michael Witbrock</a>, 
<a href="/search/cs?searchtype=author&query=Dobbie%2C+G">Gillian Dobbie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 37 pages for the main paper and 3 pages for the supplement, 8 figures, submitted to ACM Computing Surveys
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02434" title="Abstract">arXiv:2302.02434</a> (replaced) [<a href="/pdf/2302.02434" title="Download PDF">pdf</a>, <a href="/ps/2302.02434" title="Download PostScript">ps</a>, <a href="/format/2302.02434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete tensor product BGG sequences: splines and finite elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bonizzoni%2C+F">Francesca Bonizzoni</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+K">Kaibo Hu</a>, 
<a href="/search/math?searchtype=author&query=Kanschat%2C+G">Guido Kanschat</a>, 
<a href="/search/math?searchtype=author&query=Sap%2C+D">Duygu Sap</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05765" title="Abstract">arXiv:2302.05765</a> (replaced) [<a href="/pdf/2302.05765" title="Download PDF">pdf</a>, <a href="/format/2302.05765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Online Collaborative Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasteris%2C+S">Stephen Pasteris</a>, 
<a href="/search/cs?searchtype=author&query=Vitale%2C+F">Fabio Vitale</a>, 
<a href="/search/cs?searchtype=author&query=Herbster%2C+M">Mark Herbster</a>, 
<a href="/search/cs?searchtype=author&query=Gentile%2C+C">Claudio Gentile</a>, 
<a href="/search/cs?searchtype=author&query=Panisson%2C+A">Andre&#x27; Panisson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06905" title="Abstract">arXiv:2302.06905</a> (replaced) [<a href="/pdf/2302.06905" title="Download PDF">pdf</a>, <a href="/format/2302.06905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative minimization algorithm on a mixture family
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayashi%2C+M">Masahito Hayashi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13359" title="Abstract">arXiv:2302.13359</a> (replaced) [<a href="/pdf/2302.13359" title="Download PDF">pdf</a>, <a href="/format/2302.13359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the anti-aliasing properties of entropy filtering for discontinuous  spectral element approximations of under-resolved turbulent flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dzanic%2C+T">Tarik Dzanic</a>, 
<a href="/search/math?searchtype=author&query=Trojak%2C+W">Will Trojak</a>, 
<a href="/search/math?searchtype=author&query=Witherden%2C+F+D">Freddie D. Witherden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14418" title="Abstract">arXiv:2302.14418</a> (replaced) [<a href="/pdf/2302.14418" title="Download PDF">pdf</a>, <a href="/format/2302.14418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCR-CG: Point Cloud Registration via Deep Explicit Color and Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junle Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaolin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenhui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Ji Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to ECCV2022; code at <a href="https://github.com/Gardlin/PCR-CG">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14420" title="Abstract">arXiv:2302.14420</a> (replaced) [<a href="/pdf/2302.14420" title="Download PDF">pdf</a>, <a href="/ps/2302.14420" title="Download PostScript">ps</a>, <a href="/format/2302.14420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation-of-Distribution Algorithms for Multi-Valued Decision  Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jedidia%2C+F+B">Firas Ben Jedidia</a>, 
<a href="/search/cs?searchtype=author&query=Doerr%2C+B">Benjamin Doerr</a>, 
<a href="/search/cs?searchtype=author&query=Krejca%2C+M+S">Martin S. Krejca</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14770" title="Abstract">arXiv:2302.14770</a> (replaced) [<a href="/pdf/2302.14770" title="Download PDF">pdf</a>, <a href="/format/2302.14770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Completeness of Atomic Structure Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Nigam%2C+J">Jigyasa Nigam</a>, 
<a href="/search/physics?searchtype=author&query=Pozdnyakov%2C+S+N">Sergey N. Pozdnyakov</a>, 
<a href="/search/physics?searchtype=author&query=Huguenin-Dumittan%2C+K+K">Kevin K. Huguenin-Dumittan</a>, 
<a href="/search/physics?searchtype=author&query=Ceriotti%2C+M">Michele Ceriotti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03849" title="Abstract">arXiv:2303.03849</a> (replaced) [<a href="/pdf/2303.03849" title="Download PDF">pdf</a>, <a href="/format/2303.03849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TS-SEP: Joint Diarization and Separation Conditioned on Estimated  Speaker Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Boeddeker%2C+C">Christoph Boeddeker</a>, 
<a href="/search/eess?searchtype=author&query=Subramanian%2C+A+S">Aswin Shanmugam Subramanian</a>, 
<a href="/search/eess?searchtype=author&query=Wichern%2C+G">Gordon Wichern</a>, 
<a href="/search/eess?searchtype=author&query=Haeb-Umbach%2C+R">Reinhold Haeb-Umbach</a>, 
<a href="/search/eess?searchtype=author&query=Roux%2C+J+L">Jonathan Le Roux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE/ACM TASLP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05807" title="Abstract">arXiv:2303.05807</a> (replaced) [<a href="/pdf/2303.05807" title="Download PDF">pdf</a>, <a href="/format/2303.05807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aleth-NeRF: Low-light Condition View Synthesis with Concealing Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Ziteng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+L">Lin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xianzheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+T">Tatsuya Harada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> website page: <a href="https://cuiziteng.github.io/Aleth_NeRF_web/">this https URL</a>, refer to new version: <a href="/abs/2312.09093">arXiv:2312.09093</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09541" title="Abstract">arXiv:2303.09541</a> (replaced) [<a href="/pdf/2303.09541" title="Download PDF">pdf</a>, <a href="/format/2303.09541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-HPC: Synthetic Data Generation for Human Mesh Recovery in  Challenging Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+Z">Zhenzhen Weng</a>, 
<a href="/search/cs?searchtype=author&query=Bravo-S%C3%A1nchez%2C+L">Laura Bravo-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Yeung-Levy%2C+S">Serena Yeung-Levy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10600" title="Abstract">arXiv:2303.10600</a> (replaced) [<a href="/pdf/2303.10600" title="Download PDF">pdf</a>, <a href="/format/2303.10600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced Lagrange multiplier approach for non-matching coupling of  mixed-dimensional domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Heltai%2C+L">Luca Heltai</a>, 
<a href="/search/math?searchtype=author&query=Zunino%2C+P">Paolo Zunino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 11 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14702" title="Abstract">arXiv:2303.14702</a> (replaced) [<a href="/pdf/2303.14702" title="Download PDF">pdf</a>, <a href="/format/2303.14702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lot of Talk and a Badge: An Exploratory Analysis of Personal  Achievements in GitHub
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calefato%2C+F">Fabio Calefato</a>, 
<a href="/search/cs?searchtype=author&query=Quaranta%2C+L">Luigi Quaranta</a>, 
<a href="/search/cs?searchtype=author&query=Lanubile%2C+F">Filippo Lanubile</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16212" title="Abstract">arXiv:2303.16212</a> (replaced) [<a href="/pdf/2303.16212" title="Download PDF">pdf</a>, <a href="/format/2303.16212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-objective Complex Network Pruning Framework Based on  Divide-and-conquer and Global Performance Impairment Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+R">Ronghua Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Songling Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yinan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weitong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songhua Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02478" title="Abstract">arXiv:2304.02478</a> (replaced) [<a href="/pdf/2304.02478" title="Download PDF">pdf</a>, <a href="/ps/2304.02478" title="Download PostScript">ps</a>, <a href="/format/2304.02478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring AI-Generated Text in Student Writing: How Does AI Help?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woo%2C+D+J">David James Woo</a> (1), 
<a href="/search/cs?searchtype=author&query=Susanto%2C+H">Hengky Susanto</a> (2), 
<a href="/search/cs?searchtype=author&query=Yeung%2C+C+H">Chi Ho Yeung</a> (2), 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kai Guo</a> (3),  (4)
<a href="/search/cs?searchtype=author&query=Fung%2C+A+K+Y">April Ka Yeng Fung</a> ((1) Precious Blood Secondary School, Hong Kong, (2) Department of Science and Environmental Studies, The Education University of Hong Kong, Hong Kong, (3) Faculty of Education, The University of Hong Kong, Hong Kong, and (4) Hoi Ping Chamber of Commerce Secondary School, Hong Kong)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 11 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03365" title="Abstract">arXiv:2304.03365</a> (replaced) [<a href="/pdf/2304.03365" title="Download PDF">pdf</a>, <a href="/format/2304.03365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision-Focused Model-based Reinforcement Learning for Reward Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Abhishek Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Parbhoo%2C+S">Sonali Parbhoo</a>, 
<a href="/search/cs?searchtype=author&query=Gottesman%2C+O">Omer Gottesman</a>, 
<a href="/search/cs?searchtype=author&query=Doshi-Velez%2C+F">Finale Doshi-Velez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03765" title="Abstract">arXiv:2304.03765</a> (replaced) [<a href="/pdf/2304.03765" title="Download PDF">pdf</a>, <a href="/format/2304.03765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markov Decision Process Design: A Framework for Integrating Strategic  and Operational Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brown%2C+S">Seth Brown</a>, 
<a href="/search/math?searchtype=author&query=Sinha%2C+S">Saumya Sinha</a>, 
<a href="/search/math?searchtype=author&query=Schaefer%2C+A+J">Andrew J Schaefer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05673" title="Abstract">arXiv:2304.05673</a> (replaced) [<a href="/pdf/2304.05673" title="Download PDF">pdf</a>, <a href="/format/2304.05673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precise localization of corneal reflections in eye images using deep  learning trained on synthetic data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Byrne%2C+S+A">Sean Anthony Byrne</a>, 
<a href="/search/cs?searchtype=author&query=Nystr%C3%B6m%2C+M">Marcus Nystr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Maquiling%2C+V">Virmarie Maquiling</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+E">Enkelejda Kasneci</a>, 
<a href="/search/cs?searchtype=author&query=Niehorster%2C+D+C">Diederick C. Niehorster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Behavioural Research Methods
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05744" title="Abstract">arXiv:2304.05744</a> (replaced) [<a href="/pdf/2304.05744" title="Download PDF">pdf</a>, <a href="/ps/2304.05744" title="Download PostScript">ps</a>, <a href="/format/2304.05744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence analysis of Laguerre approximations for analytic functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Haiyong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Math. Comp., to appear
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Classical Analysis and ODEs (math.CA)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07597" title="Abstract">arXiv:2304.07597</a> (replaced) [<a href="/pdf/2304.07597" title="Download PDF">pdf</a>, <a href="/format/2304.07597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Instance Segmentation Dataset of Yeast Cells in Microstructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reich%2C+C">Christoph Reich</a>, 
<a href="/search/cs?searchtype=author&query=Prangemeier%2C+T">Tim Prangemeier</a>, 
<a href="/search/cs?searchtype=author&query=Fran%C3%A7ani%2C+A+O">Andr&#xe9; O. Fran&#xe7;ani</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE EMBC 2023, Christoph Reich and Tim Prangemeier - both authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08842" title="Abstract">arXiv:2304.08842</a> (replaced) [<a href="/pdf/2304.08842" title="Download PDF">pdf</a>, <a href="/format/2304.08842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UDTIRI: An Online Open-Source Intelligent Road Inspection Benchmark  Suite
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Sicen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahang Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dacheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Denghuang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shuai Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xingyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Database webpage: <a href="https://www.udtiri.com/">this https URL</a>, Kaggle webpage: <a href="https://www.kaggle.com/datasets/jiahangli617/udtiri">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13586" title="Abstract">arXiv:2304.13586</a> (replaced) [<a href="/pdf/2304.13586" title="Download PDF">pdf</a>, <a href="/format/2304.13586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Based Sliced Wasserstein Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+K">Khai Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Ho%2C+N">Nhat Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023, 30 pages, 8 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13710" title="Abstract">arXiv:2304.13710</a> (replaced) [<a href="/pdf/2304.13710" title="Download PDF">pdf</a>, <a href="/format/2304.13710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hopfield model with planted patterns: a teacher-student self-supervised  learning model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Alemanno%2C+F">Francesco Alemanno</a>, 
<a href="/search/cond-mat?searchtype=author&query=Camanzi%2C+L">Luca Camanzi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Manzan%2C+G">Gianluca Manzan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tantari%2C+D">Daniele Tantari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 5 figures, typo in the free energy corrected
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Mathematics and Computation, 2023, 458, 128253
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Machine Learning (cs.LG); Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14870" title="Abstract">arXiv:2304.14870</a> (replaced) [<a href="/pdf/2304.14870" title="Download PDF">pdf</a>, <a href="/format/2304.14870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using a Deep Learning Model to Simulate Human Stock Trader&#x27;s Methods of  Chart Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Kang%2C+S">Sungwoo Kang</a>, 
<a href="/search/q-fin?searchtype=author&query=Kim%2C+J">Jong-Kook Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05928" title="Abstract">arXiv:2305.05928</a> (replaced) [<a href="/pdf/2305.05928" title="Download PDF">pdf</a>, <a href="/ps/2305.05928" title="Download PostScript">ps</a>, <a href="/format/2305.05928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in  Wikipedia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ando%2C+K">Kenichiro Ando</a>, 
<a href="/search/cs?searchtype=author&query=Sekine%2C+S">Satoshi Sekine</a>, 
<a href="/search/cs?searchtype=author&query=Komachi%2C+M">Mamoru Komachi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 Main Track Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07459" title="Abstract">arXiv:2305.07459</a> (replaced) [<a href="/pdf/2305.07459" title="Download PDF">pdf</a>, <a href="/format/2305.07459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse wave-number-dependent source problems for the Helmholtz equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+H">Hongxia Guo</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+G">Guanghui Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08298" title="Abstract">arXiv:2305.08298</a> (replaced) [<a href="/pdf/2305.08298" title="Download PDF">pdf</a>, <a href="/format/2305.08298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbol tuning improves in-context learning in language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jerry Wei</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Le Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lampinen%2C+A">Andrew Lampinen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Da Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+Y">Yi Tay</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yifeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Denny Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+Q+V">Quoc V. Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09126" title="Abstract">arXiv:2305.09126</a> (replaced) [<a href="/pdf/2305.09126" title="Download PDF">pdf</a>, <a href="/format/2305.09126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning for Causal Effect Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Song Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+R">Ronald Moore</a>, 
<a href="/search/cs?searchtype=author&query=Kamaleswaran%2C+R">Rishikesan Kamaleswaran</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yao Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version, titled "Transfer causal learning: Causal effect estimation with knowledge transfer", has been presented in ICML 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH), 2023; see the arXiv version in v2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11946" title="Abstract">arXiv:2305.11946</a> (replaced) [<a href="/pdf/2305.11946" title="Download PDF">pdf</a>, <a href="/format/2305.11946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image2SSM: Reimagining Statistical Shape Models from Images with Radial  Basis Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Elhabian%2C+S+Y">Shireen Y. Elhabian</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Medical Image Computing and Computer Assisted Intervention. MICCAI
  2023 Conference, pp. 508_517, Springer Nature Switzerland
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14669" title="Abstract">arXiv:2305.14669</a> (replaced) [<a href="/pdf/2305.14669" title="Download PDF">pdf</a>, <a href="/format/2305.14669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NegVSR: Augmenting Negatives for Generalized Noise Modeling in  Real-World Video Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yexing Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhijing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+X">Xiaoyu Xian</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yukai Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024, a effective data augmentation framework for real-world video super-resolution, see our demo at: <a href="https://negvsr.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15573" title="Abstract">arXiv:2305.15573</a> (replaced) [<a href="/pdf/2305.15573" title="Download PDF">pdf</a>, <a href="/format/2305.15573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-global Exponential Stability for Dual Quaternion Based Rigid-Body  Tracking Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zinage%2C+V">Vrushabh Zinage</a>, 
<a href="/search/eess?searchtype=author&query=Ram%2C+S+P+A">S P Arjun Ram</a>, 
<a href="/search/eess?searchtype=author&query=Akella%2C+M+R">Maruthi R. Akella</a>, 
<a href="/search/eess?searchtype=author&query=Bakolas%2C+E">Efstathios Bakolas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16283" title="Abstract">arXiv:2305.16283</a> (replaced) [<a href="/pdf/2305.16283" title="Download PDF">pdf</a>, <a href="/format/2305.16283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graph  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangyao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96rnek%2C+E+P">Evin P&#x131;nar &#xd6;rnek</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shun-Cheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+Y">Yan Di</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera-ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16943" title="Abstract">arXiv:2305.16943</a> (replaced) [<a href="/pdf/2305.16943" title="Download PDF">pdf</a>, <a href="/format/2305.16943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionNAG: Predictor-guided Neural Architecture Generation with  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+S">Sohyun An</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hayeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+J">Jaehyeong Jo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seanie Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Sung Ju Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17282" title="Abstract">arXiv:2305.17282</a> (replaced) [<a href="/pdf/2305.17282" title="Download PDF">pdf</a>, <a href="/ps/2305.17282" title="Download PostScript">ps</a>, <a href="/format/2305.17282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal consistency of the $k$-NN rule in metric spaces and Nagata  dimension. II
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumari%2C+S">Sushma Kumari</a>, 
<a href="/search/cs?searchtype=author&query=Pestov%2C+V+G">Vladimir G. Pestov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Latex 2e, 26 pages. A major revision as requested by the anonymous ESAIM:PS reviewer, resulting in a considerable number of improvements. The main changes: a counter-example (Example 4.6) was discovered to the original version of technical Lemma 3.4 in v2 and a corrected version of the result (now Lemma 4.7) formulated; a new introductory Section 1 was written
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17939" title="Abstract">arXiv:2305.17939</a> (replaced) [<a href="/pdf/2305.17939" title="Download PDF">pdf</a>, <a href="/format/2305.17939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier Analysis on Robustness of Graph Convolutional Neural Networks  for Skeleton-based Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+N">Nariki Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Kera%2C+H">Hiroshi Kera</a>, 
<a href="/search/cs?searchtype=author&query=Kawamoto%2C+K">Kazuhiko Kawamoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18601" title="Abstract">arXiv:2305.18601</a> (replaced) [<a href="/pdf/2305.18601" title="Download PDF">pdf</a>, <a href="/format/2305.18601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BRICS: Bi-level feature Representation of Image CollectionS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dingdong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi-Amiri%2C+A">Ali Mahdavi-Amiri</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19533" title="Abstract">arXiv:2305.19533</a> (replaced) [<a href="/pdf/2305.19533" title="Download PDF">pdf</a>, <a href="/format/2305.19533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightening-Transformer: A Dynamically-operated Optically-interconnected  Photonic Transformer Accelerator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiaqi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zixuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhekai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Rongxing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chenghao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R+T">Ray T. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+D+Z">David Z. Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper in HPCA 2024. Recieved the Reproducibility Badges at IEEE. Our implementation is available at <a href="https://github.com/zhuhanqing/Lightening-Transformer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Hardware Architecture (cs.AR); Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00354" title="Abstract">arXiv:2306.00354</a> (replaced) [<a href="/pdf/2306.00354" title="Download PDF">pdf</a>, <a href="/format/2306.00354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Negative Transfer in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Go%2C+H">Hyojun Go</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">JinYoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yunsung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seunghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Shinhyeok Oh</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+H">Hyeongdon Moon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seungtaek Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips 2023. Project page: <a href="https://gohyojun15.github.io/ANT_diffusion/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00613" title="Abstract">arXiv:2306.00613</a> (replaced) [<a href="/pdf/2306.00613" title="Download PDF">pdf</a>, <a href="/ps/2306.00613" title="Download PostScript">ps</a>, <a href="/format/2306.00613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms Transcending the SAT-Symmetry Interface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anders%2C+M">Markus Anders</a>, 
<a href="/search/cs?searchtype=author&query=Schweitzer%2C+P">Pascal Schweitzer</a>, 
<a href="/search/cs?searchtype=author&query=Soos%2C+M">Mate Soos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> appeared at SAT 2023; second version corrects some minor inaccuracies
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01796" title="Abstract">arXiv:2306.01796</a> (replaced) [<a href="/pdf/2306.01796" title="Download PDF">pdf</a>, <a href="/format/2306.01796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of Extragradient SVRG for Variational Inequalities: Error  Bounds and Increasing Iterate Averaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nan%2C+T">Tianlong Nan</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/math?searchtype=author&query=Kroer%2C+C">Christian Kroer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05836" title="Abstract">arXiv:2306.05836</a> (replaced) [<a href="/pdf/2306.05836" title="Download PDF">pdf</a>, <a href="/format/2306.05836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Infer Causation from Correlation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhijing Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiarui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Z">Zhiheng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Poff%2C+S">Spencer Poff</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Mihalcea%2C+R">Rada Mihalcea</a>, 
<a href="/search/cs?searchtype=author&query=Diab%2C+M">Mona Diab</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2.0: added 5 fine-tuned model performance; de-duplicated data; and provided more fine-grained error analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07520" title="Abstract">arXiv:2306.07520</a> (replaced) [<a href="/pdf/2306.07520" title="Download PDF">pdf</a>, <a href="/format/2306.07520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruct-ReID: A Multi-purpose Person Re-identification Task with  Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+W">Weizhen He</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yiheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qingsong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+D">Donglian Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yunfeng Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08144" title="Abstract">arXiv:2306.08144</a> (replaced) [<a href="/pdf/2306.08144" title="Download PDF">pdf</a>, <a href="/format/2306.08144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correct-by-Construction Design of Contextual Robotic Missions Using  Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mallozzi%2C+P">Piergiuseppe Mallozzi</a>, 
<a href="/search/cs?searchtype=author&query=Nuzzo%2C+P">Pierluigi Nuzzo</a>, 
<a href="/search/cs?searchtype=author&query=Piterman%2C+N">Nir Piterman</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+G">Gerardo Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Pelliccione%2C+P">Patrizio Pelliccione</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11250" title="Abstract">arXiv:2306.11250</a> (replaced) [<a href="/pdf/2306.11250" title="Download PDF">pdf</a>, <a href="/format/2306.11250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InRank: Incremental Low-Rank Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiawei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beidi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fer%2C+F">Florian Sch&#xe4;fer</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12345" title="Abstract">arXiv:2306.12345</a> (replaced) [<a href="/pdf/2306.12345" title="Download PDF">pdf</a>, <a href="/format/2306.12345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Noise on the Emergence of Continuous Norms and its  Evolutionary Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anagnou%2C+S">Stavros Anagnou</a>, 
<a href="/search/cs?searchtype=author&query=Polani%2C+D">Daniel Polani</a>, 
<a href="/search/cs?searchtype=author&query=Salge%2C+C">Christoph Salge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the Proceedings of the Artificial Life Conference 2023 (ALIFE 2023), MIT Press
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13319" title="Abstract">arXiv:2306.13319</a> (replaced) [<a href="/pdf/2306.13319" title="Download PDF">pdf</a>, <a href="/format/2306.13319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A SAT Solver and Computer Algebra Attack on the Minimum Kochen-Specker  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Z">Zhengyu Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bright%2C+C">Curtis Bright</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ganesh%2C+V">Vijay Ganesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13746" title="Abstract">arXiv:2306.13746</a> (replaced) [<a href="/pdf/2306.13746" title="Download PDF">pdf</a>, <a href="/format/2306.13746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting inference after prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Motwani%2C+K">Keshav Motwani</a>, 
<a href="/search/stat?searchtype=author&query=Witten%2C+D">Daniela Witten</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13941" title="Abstract">arXiv:2306.13941</a> (replaced) [<a href="/pdf/2306.13941" title="Download PDF">pdf</a>, <a href="/format/2306.13941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grassroots Social Networking: Where Members Own and Control their  Personal Information and Social Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+E">Ehud Shapiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computers and Society (cs.CY); Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14281" title="Abstract">arXiv:2306.14281</a> (replaced) [<a href="/pdf/2306.14281" title="Download PDF">pdf</a>, <a href="/format/2306.14281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Security in UAVs and FANETs: Issues, Threats, Analysis of  Attacks, and Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ceviz%2C+O">Ozlem Ceviz</a>, 
<a href="/search/cs?searchtype=author&query=Sadioglu%2C+P">Pinar Sadioglu</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Sevil Sen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14872" title="Abstract">arXiv:2306.14872</a> (replaced) [<a href="/pdf/2306.14872" title="Download PDF">pdf</a>, <a href="/format/2306.14872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-Aware Approaches for Balancing Performance and Theoretical  Guarantees in Linear Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuwei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Bayati%2C+M">Mohsen Bayati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15546" title="Abstract">arXiv:2306.15546</a> (replaced) [<a href="/pdf/2306.15546" title="Download PDF">pdf</a>, <a href="/format/2306.15546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Foundation Model Meets Federated Learning: Motivations, Challenges,  and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+W">Weiming Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+L">Lingjuan Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16846" title="Abstract">arXiv:2306.16846</a> (replaced) [<a href="/pdf/2306.16846" title="Download PDF">pdf</a>, <a href="/format/2306.16846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight texture transfer based on texture feature preset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">ShiQi Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07607" title="Abstract">arXiv:2307.07607</a> (replaced) [<a href="/pdf/2307.07607" title="Download PDF">pdf</a>, <a href="/format/2307.07607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SubT-MRS Dataset: Pushing SLAM Towards All-weather Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shibo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuanjun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+D">Damanpreet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Rushan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haoxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sarawata%2C+M">Mansi Sarawata</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuheng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Whittaker%2C+W">Warren Whittaker</a>, 
<a href="/search/cs?searchtype=author&query=Higgins%2C+I">Ian Higgins</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yi Du</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shaoshu Su</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Can Xu</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+J">John Keller</a>, 
<a href="/search/cs?searchtype=author&query=Karhade%2C+J">Jay Karhade</a>, 
<a href="/search/cs?searchtype=author&query=Nogueira%2C+L">Lucas Nogueira</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Sourojit Saha</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenshan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08566" title="Abstract">arXiv:2307.08566</a> (replaced) [<a href="/pdf/2307.08566" title="Download PDF">pdf</a>, <a href="/format/2307.08566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposing imaginary time Feynman diagrams using separable basis  functions: Anderson impurity model strong coupling expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Kaye%2C+J">Jason Kaye</a>, 
<a href="/search/cond-mat?searchtype=author&query=Strand%2C+H+U+R">Hugo U. R. Strand</a>, 
<a href="/search/cond-mat?searchtype=author&query=Gole%C5%BE%2C+D">Denis Gole&#x17e;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Strongly Correlated Electrons (cond-mat.str-el)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08990" title="Abstract">arXiv:2307.08990</a> (replaced) [<a href="/pdf/2307.08990" title="Download PDF">pdf</a>, <a href="/format/2307.08990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study on Noisy Label Learning for Program Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanzhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Anran Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In IEEE/ACM 46th International Conference on Software Engineering (ICSE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11349" title="Abstract">arXiv:2307.11349</a> (replaced) [<a href="/pdf/2307.11349" title="Download PDF">pdf</a>, <a href="/format/2307.11349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EV-Planner: Energy-Efficient Robot Navigation via Event-Based  Physics-Guided Neuromorphic Planner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Sourav Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=Manna%2C+R+K">Rohan Kumar Manna</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11380" title="Abstract">arXiv:2307.11380</a> (replaced) [<a href="/pdf/2307.11380" title="Download PDF">pdf</a>, <a href="/format/2307.11380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect  ChatGPT-Generated Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lingyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Feng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12083" title="Abstract">arXiv:2307.12083</a> (replaced) [<a href="/pdf/2307.12083" title="Download PDF">pdf</a>, <a href="/format/2307.12083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Control of Flow over Rotating Cylinder by Multiple Jets using  Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Dobakhti%2C+K">Kamyar Dobakhti</a>, 
<a href="/search/physics?searchtype=author&query=Ghazanfarian%2C+J">Jafar Ghazanfarian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1st Edit: Parts of the introduction, simulation environment, and the network and reinforcement learning framework have been revised. --- 2nd Edit: Added real-world scenario, possible design of rotating cylinder, sensors limited to the body of the cylinder, Re = 200, compared the results and runtime of a shallow network with a higher number of neurons vs deeper network but lower number of neurons
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12235" title="Abstract">arXiv:2307.12235</a> (replaced) [<a href="/pdf/2307.12235" title="Download PDF">pdf</a>, <a href="/format/2307.12235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Time-Invariant Distributed Formation Tracking for Second-Order  Multi-Agent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fabris%2C+M">Marco Fabris</a>, 
<a href="/search/eess?searchtype=author&query=Fattore%2C+G">Giulio Fattore</a>, 
<a href="/search/eess?searchtype=author&query=Cenedese%2C+A">Angelo Cenedese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 3 figures, submitted to the European Journal of Control on December 31st, 2023 (version 2)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13535" title="Abstract">arXiv:2307.13535</a> (replaced) [<a href="/pdf/2307.13535" title="Download PDF">pdf</a>, <a href="/format/2307.13535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do algorithms and barriers for sparse principal component analysis  extend to other structured settings?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+G">Guanyi Wang</a>, 
<a href="/search/stat?searchtype=author&query=Lou%2C+M">Mengqi Lou</a>, 
<a href="/search/stat?searchtype=author&query=Pananjady%2C+A">Ashwin Pananjady</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01719" title="Abstract">arXiv:2308.01719</a> (replaced) [<a href="/pdf/2308.01719" title="Download PDF">pdf</a>, <a href="/format/2308.01719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Data Conversion Bottleneck in Analog Computing Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meech%2C+J+T">James T. Meech</a>, 
<a href="/search/cs?searchtype=author&query=Tsoutsouras%2C+V">Vasileios Tsoutsouras</a>, 
<a href="/search/cs?searchtype=author&query=Stanley-Marbell%2C+P">Phillip Stanley-Marbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the First Workshop on Machine Learning with New Compute Paradigms at NeurIPS 2023 (MLNPCP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03138" title="Abstract">arXiv:2308.03138</a> (replaced) [<a href="/pdf/2308.03138" title="Download PDF">pdf</a>, <a href="/ps/2308.03138" title="Download PostScript">ps</a>, <a href="/format/2308.03138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A randomised lattice rule algorithm with pre-determined generating  vector and random number of points for Korobov spaces with $0 &lt; &#x3b1;\le  1/2$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nuyens%2C+D">Dirk Nuyens</a>, 
<a href="/search/math?searchtype=author&query=Wilkes%2C+L">Laurence Wilkes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03407" title="Abstract">arXiv:2308.03407</a> (replaced) [<a href="/pdf/2308.03407" title="Download PDF">pdf</a>, <a href="/format/2308.03407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially Varying Nanophotonic Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kaixuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Froech%2C+J">Johannes Froech</a>, 
<a href="/search/cs?searchtype=author&query=Chakravarthula%2C+P">Praneeth Chakravarthula</a>, 
<a href="/search/cs?searchtype=author&query=Whitehead%2C+J">James Whitehead</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+E">Ethan Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Arka Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Heide%2C+F">Felix Heide</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04102" title="Abstract">arXiv:2308.04102</a> (replaced) [<a href="/pdf/2308.04102" title="Download PDF">pdf</a>, <a href="/format/2308.04102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Evolution of Deep Neural Network Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jason Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shahrzad%2C+H">Hormoz Shahrzad</a>, 
<a href="/search/cs?searchtype=author&query=Miikkulainen%2C+R">Risto Miikkulainen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06382" title="Abstract">arXiv:2308.06382</a> (replaced) [<a href="/pdf/2308.06382" title="Download PDF">pdf</a>, <a href="/format/2308.06382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phoneme Hallucinator: One-shot Voice Conversion via Set Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Siyuan Shan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Amartya Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Oliva%2C+J+B">Junier B. Oliva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 Demo, Codes: <a href="https://phonemehallucinator.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06412" title="Abstract">arXiv:2308.06412</a> (replaced) [<a href="/pdf/2308.06412" title="Download PDF">pdf</a>, <a href="/format/2308.06412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Self-Training for Open-Vocabulary Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shiyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Schulter%2C+S">Samuel Schulter</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Long Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhixing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=G%2C+V+K+B">Vijay Kumar B.G</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+Y">Yumin Suh</a>, 
<a href="/search/cs?searchtype=author&query=Chandraker%2C+M">Manmohan Chandraker</a>, 
<a href="/search/cs?searchtype=author&query=Metaxas%2C+D+N">Dimitris N. Metaxas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures. Code: <a href="https://github.com/xiaofeng94/SAS-Det">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07017" title="Abstract">arXiv:2308.07017</a> (replaced) [<a href="/e-print/2308.07017" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Bi-Projector for Unsupervised Domain Adaption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lin-Chieh Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+H">Hung-Hsu Tsai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Professor asks to withdraw this paper on arxiv. This paper will upload again if the paper is published in the journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07931" title="Abstract">arXiv:2308.07931</a> (replaced) [<a href="/pdf/2308.07931" title="Download PDF">pdf</a>, <a href="/format/2308.07931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">William Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Ge Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+A">Alan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+J">Jansen Wong</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L+P">Leslie Pack Kaelbling</a>, 
<a href="/search/cs?searchtype=author&query=Isola%2C+P">Phillip Isola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website at <a href="https://f3rm.csail.mit.edu">this https URL</a>, Accepted at the 7th Annual Conference on Robot Learning (CoRL), 2023 in Atlanta, US
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08316" title="Abstract">arXiv:2308.08316</a> (replaced) [<a href="/pdf/2308.08316" title="Download PDF">pdf</a>, <a href="/format/2308.08316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Stream Diffusion Net for Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Binhui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Anbo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhiyong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08434" title="Abstract">arXiv:2308.08434</a> (replaced) [<a href="/pdf/2308.08434" title="Download PDF">pdf</a>, <a href="/format/2308.08434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bi-Step Grounding Paradigm for Large Language Models in Recommendation  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+K">Keqin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jizhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yancheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08939" title="Abstract">arXiv:2308.08939</a> (replaced) [<a href="/pdf/2308.08939" title="Download PDF">pdf</a>, <a href="/format/2308.08939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reflections on Designing and Running Visualization Design and  Programming Activities in Courses with Many Students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knudsen%2C+S">S&#xf8;ren Knudsen</a>, 
<a href="/search/cs?searchtype=author&query=Bennetsen%2C+M+B">Mathilde Bech Bennetsen</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B8j%2C+T+K">Terese Kimmie H&#xf8;j</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C">Camilla Jensen</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%B8rgensen%2C+R+L+N">Rebecca Louise N&#xf8;rskov J&#xf8;rgensen</a>, 
<a href="/search/cs?searchtype=author&query=Loft%2C+C+S">Christian S&#xf8;e Loft</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Copyright 2023 IEEE. This is the author's version of the article that has been published in the proceedings of IEEE Visualization conference. The final version of this record is available at: <a href="https://doi.org/10.1109/EduVis60792.2023.00015">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09091" title="Abstract">arXiv:2308.09091</a> (replaced) [<a href="/pdf/2308.09091" title="Download PDF">pdf</a>, <a href="/format/2308.09091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edit Temporal-Consistent Videos with Image Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Anbo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+A+B">Antoni B. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhen Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10273" title="Abstract">arXiv:2308.10273</a> (replaced) [<a href="/pdf/2308.10273" title="Download PDF">pdf</a>, <a href="/format/2308.10273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing  Continuous Conditional Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zuheng Xu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12210" title="Abstract">arXiv:2308.12210</a> (replaced) [<a href="/pdf/2308.12210" title="Download PDF">pdf</a>, <a href="/format/2308.12210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ULDP-FL: Federated Learning with Across Silo User-Level Differential  Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kato%2C+F">Fumiyuki Kato</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Li Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Takagi%2C+S">Shun Takagi</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yoshikawa%2C+M">Masatoshi Yoshikawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14279" title="Abstract">arXiv:2308.14279</a> (replaced) [<a href="/pdf/2308.14279" title="Download PDF">pdf</a>, <a href="/ps/2308.14279" title="Download PostScript">ps</a>, <a href="/format/2308.14279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling unknown large networks restricted by low sampling rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+B">Bo Jiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages,11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14550" title="Abstract">arXiv:2308.14550</a> (replaced) [<a href="/pdf/2308.14550" title="Download PDF">pdf</a>, <a href="/format/2308.14550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReMAV: Reward Modeling of Autonomous Vehicles for Finding Likely Failure  Events
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharif%2C+A">Aizaz Sharif</a>, 
<a href="/search/cs?searchtype=author&query=Marijan%2C+D">Dusica Marijan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15821" title="Abstract">arXiv:2308.15821</a> (replaced) [<a href="/pdf/2308.15821" title="Download PDF">pdf</a>, <a href="/format/2308.15821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Two Stage Decoupling With Adaptive Personalization Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hangyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yuxiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhenping Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00993" title="Abstract">arXiv:2309.00993</a> (replaced) [<a href="/e-print/2309.00993" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Boosted Machine Learning Framework for the Improvement of Phase and  Crystal Structure Prediction of High Entropy Alloys Using Thermodynamic and  Configurational Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dey%2C+D">Debsundar Dey</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Suchandan Das</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+A">Anik Pal</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+S">Santanu Dey</a>, 
<a href="/search/cs?searchtype=author&query=Raul%2C+C+K">Chandan Kumar Raul</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+A">Arghya Chatterjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We want to modify this paper and extend some parts of it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01030" title="Abstract">arXiv:2309.01030</a> (replaced) [<a href="/pdf/2309.01030" title="Download PDF">pdf</a>, <a href="/format/2309.01030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Adaptive Mahalanobis Distance Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lianke Qin</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+A">Aravind Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02332" title="Abstract">arXiv:2309.02332</a> (replaced) [<a href="/pdf/2309.02332" title="Download PDF">pdf</a>, <a href="/format/2309.02332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Processing by Neuron Populations in the Central Nervous  System: Mathematical Structure of Data and Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Nilsson%2C+M+N+P">Martin N. P. Nilsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03537" title="Abstract">arXiv:2309.03537</a> (replaced) [<a href="/pdf/2309.03537" title="Download PDF">pdf</a>, <a href="/format/2309.03537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Adaptive Graph Framelets with Generalized Vanishing Moments for  Graph Signal Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zheng%2C+R">Ruigang Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zhuang%2C+X">Xiaosheng Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03842" title="Abstract">arXiv:2309.03842</a> (replaced) [<a href="/pdf/2309.03842" title="Download PDF">pdf</a>, <a href="/format/2309.03842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early warning indicators via latent stochastic dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Feng%2C+L">Lingyu Feng</a>, 
<a href="/search/stat?searchtype=author&query=Gao%2C+T">Ting Gao</a>, 
<a href="/search/stat?searchtype=author&query=Xiao%2C+W">Wang Xiao</a>, 
<a href="/search/stat?searchtype=author&query=Duan%2C+J">Jinqiao Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04901" title="Abstract">arXiv:2309.04901</a> (replaced) [<a href="/pdf/2309.04901" title="Download PDF">pdf</a>, <a href="/format/2309.04901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Bit-Aided Modulo Sampling for DOA Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+J">Jiang Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Qu%2C+F">Fengzhong Qu</a>, 
<a href="/search/eess?searchtype=author&query=Soh%2C+D+W">De Wen Soh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08883" title="Abstract">arXiv:2309.08883</a> (replaced) [<a href="/pdf/2309.08883" title="Download PDF">pdf</a>, <a href="/format/2309.08883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Satisfiability Modulo Counting for Symbolic and Statistical AI  Integration With Provable Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinzhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yexiang Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Complexity (cs.CC); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11766" title="Abstract">arXiv:2309.11766</a> (replaced) [<a href="/pdf/2309.11766" title="Download PDF">pdf</a>, <a href="/format/2309.11766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dictionary Attack on IMU-based Gait Authentication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Rajesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Isik%2C+C">Can Isik</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+C+K">Chilukuri K. Mohan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures, accepted at AISec23 colocated with ACM CCS, November 30, 2023, Copenhagen, Denmark
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14181" title="Abstract">arXiv:2309.14181</a> (replaced) [<a href="/pdf/2309.14181" title="Download PDF">pdf</a>, <a href="/format/2309.14181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Erli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Liang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Annan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenxiu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 11 tables, with updated results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14618" title="Abstract">arXiv:2309.14618</a> (replaced) [<a href="/pdf/2309.14618" title="Download PDF">pdf</a>, <a href="/format/2309.14618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication games, sequential equilibrium, and mediators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geffner%2C+I">Ivan Geffner</a>, 
<a href="/search/cs?searchtype=author&query=Halpern%2C+J+Y">Joseph Y. Halpern</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15031" title="Abstract">arXiv:2309.15031</a> (replaced) [<a href="/pdf/2309.15031" title="Download PDF">pdf</a>, <a href="/ps/2309.15031" title="Download PostScript">ps</a>, <a href="/format/2309.15031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nuclear Morphometry using a Deep Learning-based Algorithm has Prognostic  Relevance for Canine Cutaneous Mast Cell Tumors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haghofer%2C+A">Andreas Haghofer</a>, 
<a href="/search/cs?searchtype=author&query=Parlak%2C+E">Eda Parlak</a>, 
<a href="/search/cs?searchtype=author&query=Bartel%2C+A">Alexander Bartel</a>, 
<a href="/search/cs?searchtype=author&query=Donovan%2C+T+A">Taryn A. Donovan</a>, 
<a href="/search/cs?searchtype=author&query=Assenmacher%2C+C">Charles-Antoine Assenmacher</a>, 
<a href="/search/cs?searchtype=author&query=Bolfa%2C+P">Pompei Bolfa</a>, 
<a href="/search/cs?searchtype=author&query=Dark%2C+M+J">Michael J. Dark</a>, 
<a href="/search/cs?searchtype=author&query=Fuchs-Baumgartinger%2C+A">Andrea Fuchs-Baumgartinger</a>, 
<a href="/search/cs?searchtype=author&query=Klang%2C+A">Andrea Klang</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%A4ger%2C+K">Kathrin J&#xe4;ger</a>, 
<a href="/search/cs?searchtype=author&query=Klopfleisch%2C+R">Robert Klopfleisch</a>, 
<a href="/search/cs?searchtype=author&query=Merz%2C+S">Sophie Merz</a>, 
<a href="/search/cs?searchtype=author&query=Richter%2C+B">Barbara Richter</a>, 
<a href="/search/cs?searchtype=author&query=Schulman%2C+F+Y">F. Yvonne Schulman</a>, 
<a href="/search/cs?searchtype=author&query=Ganz%2C+J">Jonathan Ganz</a>, 
<a href="/search/cs?searchtype=author&query=Scharinger%2C+J">Josef Scharinger</a>, 
<a href="/search/cs?searchtype=author&query=Aubreville%2C+M">Marc Aubreville</a>, 
<a href="/search/cs?searchtype=author&query=Winkler%2C+S+M">Stephan M. Winkler</a>, 
<a href="/search/cs?searchtype=author&query=Kiupel%2C+M">Matti Kiupel</a>, 
<a href="/search/cs?searchtype=author&query=Bertram%2C+C+A">Christof A. Bertram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15366" title="Abstract">arXiv:2309.15366</a> (replaced) [<a href="/pdf/2309.15366" title="Download PDF">pdf</a>, <a href="/format/2309.15366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density Estimation via Measure Transport: Outlook for Applications in  the Biological Sciences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Lopez-Marrero%2C+V">Vanessa Lopez-Marrero</a>, 
<a href="/search/q-bio?searchtype=author&query=Johnstone%2C+P+R">Patrick R. Johnstone</a>, 
<a href="/search/q-bio?searchtype=author&query=Park%2C+G">Gilchan Park</a>, 
<a href="/search/q-bio?searchtype=author&query=Luo%2C+X">Xihaier Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 18 figures; Results from additional computational experiments incorporated in Section 5.2.2; Added Section 6 and Appendices A &amp; B; sha256: ff3a394c0a933a8d7d936f4ca6045bba81b2f47a84208375910b28667b176082
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Biological Physics (physics.bio-ph)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02128" title="Abstract">arXiv:2310.02128</a> (replaced) [<a href="/pdf/2310.02128" title="Download PDF">pdf</a>, <a href="/format/2310.02128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Code Graph -- an information model to facilitate software  comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borowski%2C+K">Krzysztof Borowski</a>, 
<a href="/search/cs?searchtype=author&query=Bali%C5%9B%2C+B">Bartosz Bali&#x15b;</a>, 
<a href="/search/cs?searchtype=author&query=Orzechowski%2C+T">Tomasz Orzechowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03940" title="Abstract">arXiv:2310.03940</a> (replaced) [<a href="/pdf/2310.03940" title="Download PDF">pdf</a>, <a href="/format/2310.03940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hard View Selection for Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+F">Fabio Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Rapant%2C+I">Ivo Rapant</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05450" title="Abstract">arXiv:2310.05450</a> (replaced) [<a href="/pdf/2310.05450" title="Download PDF">pdf</a>, <a href="/format/2310.05450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empower Nested Boolean Logic via Self-Supervised Curriculum Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongqiu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Linfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06594" title="Abstract">arXiv:2310.06594</a> (replaced) [<a href="/pdf/2310.06594" title="Download PDF">pdf</a>, <a href="/format/2310.06594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Evaluation and Refinement of Vision-Language Instruction Tuning  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+N">Ning Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Renqiu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Min Cao</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07220" title="Abstract">arXiv:2310.07220</a> (replaced) [<a href="/pdf/2310.07220" title="Download PDF">pdf</a>, <a href="/format/2310.07220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically  for Model-Based RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ruijie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanchao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruonan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wongkamjan%2C+W">Wichayaporn Wongkamjan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09130" title="Abstract">arXiv:2310.09130</a> (replaced) [<a href="/pdf/2310.09130" title="Download PDF">pdf</a>, <a href="/format/2310.09130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Split-and-Denoise: Protect large language model inference with local  differential privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mai%2C+P">Peihua Mai</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Ran Yan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Youjia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yan Pang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09877" title="Abstract">arXiv:2310.09877</a> (replaced) [<a href="/pdf/2310.09877" title="Download PDF">pdf</a>, <a href="/format/2310.09877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical inference using machine learning and classical techniques  based on accumulated local effects (ALE)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Okoli%2C+C">Chitu Okoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1. Normalization formula for ALE statistics has been updated to prevent inflated NALED for cases with very minor differences with only a few ALE y values. These are now normalized to zero. 2. NALER is now scaled from -50% to +50% with 0% representing the median. Its interpretation is now more intuitive. 3. A subsection has been added with detailed instructions of how to interpret NALED and NALER
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10483" title="Abstract">arXiv:2310.10483</a> (replaced) [<a href="/pdf/2310.10483" title="Download PDF">pdf</a>, <a href="/format/2310.10483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passive Inference Attacks on Split Learning via Adversarial  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaochen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xinjian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuncheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yangfan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiaokui Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ooi%2C+B+C">Beng Chin Ooi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10835" title="Abstract">arXiv:2310.10835</a> (replaced) [<a href="/pdf/2310.10835" title="Download PDF">pdf</a>, <a href="/format/2310.10835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Probabilistic Imaging using Score-Based Generative Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yu Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zihui Wu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yifan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+B+T">Berthy T. Feng</a>, 
<a href="/search/eess?searchtype=author&query=Bouman%2C+K+L">Katherine L. Bouman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11097" title="Abstract">arXiv:2310.11097</a> (replaced) [<a href="/pdf/2310.11097" title="Download PDF">pdf</a>, <a href="/format/2310.11097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimenting AI Technologies for Disinformation Combat: the IDMO  Project
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canale%2C+L">Lorenzo Canale</a>, 
<a href="/search/cs?searchtype=author&query=Messina%2C+A">Alberto Messina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12732" title="Abstract">arXiv:2310.12732</a> (replaced) [<a href="/pdf/2310.12732" title="Download PDF">pdf</a>, <a href="/ps/2310.12732" title="Download PostScript">ps</a>, <a href="/format/2310.12732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming the compression limit of the individualsequence (zero order  empirical entropy) using the Set Shaping Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koch%2C+A">Aida Koch</a>, 
<a href="/search/cs?searchtype=author&query=Petit%2C+A">Alix Petit</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+C">Christian Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Vdberg%2C+A">Adrain Vdberg</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+L">Logan Lewis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12781" title="Abstract">arXiv:2310.12781</a> (replaced) [<a href="/pdf/2310.12781" title="Download PDF">pdf</a>, <a href="/format/2310.12781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Density Estimations from Privacy-Protected Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xiong%2C+Y">Yifei Xiong</a>, 
<a href="/search/stat?searchtype=author&query=Ju%2C+N+P">Nianqiao P. Ju</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+S">Sanguo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16542" title="Abstract">arXiv:2310.16542</a> (replaced) [<a href="/pdf/2310.16542" title="Download PDF">pdf</a>, <a href="/format/2310.16542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParisLuco3D: A high-quality target dataset for domain generalization of  LiDAR perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+J">Jules Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Soum-Fontez%2C+L">Louis Soum-Fontez</a>, 
<a href="/search/cs?searchtype=author&query=Deschaud%2C+J">Jean-Emmanuel Deschaud</a>, 
<a href="/search/cs?searchtype=author&query=Goulette%2C+F">Francois Goulette</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20199" title="Abstract">arXiv:2310.20199</a> (replaced) [<a href="/pdf/2310.20199" title="Download PDF">pdf</a>, <a href="/format/2310.20199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In Search of Lost Online Test-time Adaptation: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yadan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoxiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zi Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00912" title="Abstract">arXiv:2311.00912</a> (replaced) [<a href="/pdf/2311.00912" title="Download PDF">pdf</a>, <a href="/ps/2311.00912" title="Download PostScript">ps</a>, <a href="/format/2311.00912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whitney-type estimates for convex functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Prymak%2C+A">Andriy Prymak</a>, 
<a href="/search/math?searchtype=author&query=Singh%2C+J">Jaskaran Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Referee's comments incorporated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Classical Analysis and ODEs (math.CA)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01004" title="Abstract">arXiv:2311.01004</a> (replaced) [<a href="/pdf/2311.01004" title="Download PDF">pdf</a>, <a href="/format/2311.01004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning  for Medical Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benlu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Weijie Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yizhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xuechen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01752" title="Abstract">arXiv:2311.01752</a> (replaced) [<a href="/pdf/2311.01752" title="Download PDF">pdf</a>, <a href="/ps/2311.01752" title="Download PostScript">ps</a>, <a href="/format/2311.01752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Overhead Beam Alignment for Mobile Millimeter Channel Based on  Continuous-Time Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+H">Huang-Chou Lin</a>, 
<a href="/search/eess?searchtype=author&query=Kuang-Hao">Kuang-Hao</a> (Stanley)Liu
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the proceedings of IEEE WCNC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02663" title="Abstract">arXiv:2311.02663</a> (replaced) [<a href="/pdf/2311.02663" title="Download PDF">pdf</a>, <a href="/ps/2311.02663" title="Download PostScript">ps</a>, <a href="/format/2311.02663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards finite element exterior calculus on manifolds: commuting  projections, geometric variational crimes, and approximation errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Licht%2C+M+W">Martin W. Licht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contribution to ENUMATH Proceedings 2023. 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03198" title="Abstract">arXiv:2311.03198</a> (replaced) [<a href="/pdf/2311.03198" title="Download PDF">pdf</a>, <a href="/format/2311.03198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for  Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zijie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Guangming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junyi Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Robotics and Automation Letters (RAL) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03356" title="Abstract">arXiv:2311.03356</a> (replaced) [<a href="/pdf/2311.03356" title="Download PDF">pdf</a>, <a href="/format/2311.03356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLaMM: Pixel Grounding Large Multimodal Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+H">Hanoona Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Maaz%2C+M">Muhammad Maaz</a>, 
<a href="/search/cs?searchtype=author&query=Mullappilly%2C+S+S">Sahal Shaji Mullappilly</a>, 
<a href="/search/cs?searchtype=author&query=Shaker%2C+A">Abdelrahman Shaker</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Cholakkal%2C+H">Hisham Cholakkal</a>, 
<a href="/search/cs?searchtype=author&query=Anwer%2C+R+M">Rao M. Anwer</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Erix Xing</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad S. Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report of GLaMM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03380" title="Abstract">arXiv:2311.03380</a> (replaced) [<a href="/pdf/2311.03380" title="Download PDF">pdf</a>, <a href="/ps/2311.03380" title="Download PostScript">ps</a>, <a href="/format/2311.03380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An attempt to generate new bridge types from latent space of variational  autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04014" title="Abstract">arXiv:2311.04014</a> (replaced) [<a href="/pdf/2311.04014" title="Download PDF">pdf</a>, <a href="/format/2311.04014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Method to Improve the Performance of Reinforcement Learning Based on  the Y Operator for a Class of Stochastic Differential Equation-Based  Child-Mother Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Cheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04412" title="Abstract">arXiv:2311.04412</a> (replaced) [<a href="/pdf/2311.04412" title="Download PDF">pdf</a>, <a href="/ps/2311.04412" title="Download PostScript">ps</a>, <a href="/format/2311.04412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Conditional Reasoning in Answer Set Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakama%2C+C">Chiaki Sakama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages. Shorter version: in Proceedings of the 21st International Workshop on Non-Monotonic Reasoning (NMR-2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Theory and Practice of Logic Programming, vol.24(1), January 2024,
  pp. 157-192
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06542" title="Abstract">arXiv:2311.06542</a> (replaced) [<a href="/pdf/2311.06542" title="Download PDF">pdf</a>, <a href="/ps/2311.06542" title="Download PostScript">ps</a>, <a href="/format/2311.06542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation Of Colors using Bidirectional Long Short Term Memory Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">A. Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06661" title="Abstract">arXiv:2311.06661</a> (replaced) [<a href="/pdf/2311.06661" title="Download PDF">pdf</a>, <a href="/format/2311.06661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electromagnetic Signal and Information Theory -- Electromagnetically  Consistent Communication Models for the Transmission and Processing of  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/cs?searchtype=author&query=Migliore%2C+M+D">Marco Donald Migliore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10116" title="Abstract">arXiv:2311.10116</a> (replaced) [<a href="/pdf/2311.10116" title="Download PDF">pdf</a>, <a href="/format/2311.10116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wildfire Smoke Detection with Cross Contrast Patch Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Akram%2C+A">Adeel Akram</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Z">Zhilin Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qixing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13091" title="Abstract">arXiv:2311.13091</a> (replaced) [<a href="/pdf/2311.13091" title="Download PDF">pdf</a>, <a href="/format/2311.13091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Unlearnable Example: Enhancing the Robustness of Unlearnable  Examples via Stable Error-Minimizing Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15218" title="Abstract">arXiv:2311.15218</a> (replaced) [<a href="/pdf/2311.15218" title="Download PDF">pdf</a>, <a href="/format/2311.15218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and  Qualitative Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bathini%2C+S+A">Sai Akash Bathini</a>, 
<a href="/search/cs?searchtype=author&query=Cihan%2C+D">Dagli Cihan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15487" title="Abstract">arXiv:2311.15487</a> (replaced) [<a href="/pdf/2311.15487" title="Download PDF">pdf</a>, <a href="/ps/2311.15487" title="Download PostScript">ps</a>, <a href="/format/2311.15487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global $\mathcal{L}^2$ minimization at uniform exponential rate via  geometrically adapted gradient descent in Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Thomas Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AMS Latex, 15 pages. Section 2.4 on the trapping of orbits in the standard gradient descent flow added. Title changed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Mathematical Physics (math-ph); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15654" title="Abstract">arXiv:2311.15654</a> (replaced) [<a href="/pdf/2311.15654" title="Download PDF">pdf</a>, <a href="/format/2311.15654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event Detection in Time Series: Universal Deep Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Azib%2C+M">Menouar Azib</a>, 
<a href="/search/stat?searchtype=author&query=Renard%2C+B">Benjamin Renard</a>, 
<a href="/search/stat?searchtype=author&query=Garnier%2C+P">Philippe Garnier</a>, 
<a href="/search/stat?searchtype=author&query=G%C3%A9not%2C+V">Vincent G&#xe9;not</a>, 
<a href="/search/stat?searchtype=author&query=Andr%C3%A9%2C+N">Nicolas Andr&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted to ICML 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16754" title="Abstract">arXiv:2311.16754</a> (replaced) [<a href="/pdf/2311.16754" title="Download PDF">pdf</a>, <a href="/format/2311.16754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Full-scene Domain Generalization in Multi-agent Collaborative  Bird&#x27;s Eye View Segmentation for Connected and Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Senkang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhengru Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuguang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Kwong%2C+S">Sam Kwong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00209" title="Abstract">arXiv:2312.00209</a> (replaced) [<a href="/pdf/2312.00209" title="Download PDF">pdf</a>, <a href="/format/2312.00209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Interplay Between Stepsize Tuning and Progressive Sharpening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roulet%2C+V">Vincent Roulet</a>, 
<a href="/search/cs?searchtype=author&query=Agarwala%2C+A">Atish Agarwala</a>, 
<a href="/search/cs?searchtype=author&query=Pedregosa%2C+F">Fabian Pedregosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the NeurIPS 2023 OPT Wokshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00798" title="Abstract">arXiv:2312.00798</a> (replaced) [<a href="/pdf/2312.00798" title="Download PDF">pdf</a>, <a href="/format/2312.00798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Turing Test: Are AI Chatbots Behaviorally Similar to Humans?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+Q">Qiaozhu Mei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yutong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Walter Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Jackson%2C+M+O">Matthew O. Jackson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01324" title="Abstract">arXiv:2312.01324</a> (replaced) [<a href="/pdf/2312.01324" title="Download PDF">pdf</a>, <a href="/format/2312.01324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MABViT -- Modified Attention Block Enhances Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+M">Mahesh Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Ramkumar%2C+A">Aswinkumar Ramkumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Deployable AI Workshop, AAAI Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02641" title="Abstract">arXiv:2312.02641</a> (replaced) [<a href="/pdf/2312.02641" title="Download PDF">pdf</a>, <a href="/format/2312.02641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inertial Line-Of-Sight Stabilization Using a 3-DOF Spherical Parallel  Manipulator with Coaxial Input Shafts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+A">Alexandre Le</a>, 
<a href="/search/cs?searchtype=author&query=Rance%2C+G">Guillaume Rance</a>, 
<a href="/search/cs?searchtype=author&query=Rouillier%2C+F">Fabrice Rouillier</a>, 
<a href="/search/cs?searchtype=author&query=Chablat%2C+D">Damien Chablat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> OPTRO Conference 2024 (11th International Symposium on Optronics in Defense &amp; Security, 2024), 11 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04501" title="Abstract">arXiv:2312.04501</a> (replaced) [<a href="/pdf/2312.04501" title="Download PDF">pdf</a>, <a href="/format/2312.04501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Metanetworks for Processing Diverse Neural Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+D">Derek Lim</a>, 
<a href="/search/cs?searchtype=author&query=Maron%2C+H">Haggai Maron</a>, 
<a href="/search/cs?searchtype=author&query=Law%2C+M+T">Marc T. Law</a>, 
<a href="/search/cs?searchtype=author&query=Lorraine%2C+J">Jonathan Lorraine</a>, 
<a href="/search/cs?searchtype=author&query=Lucas%2C+J">James Lucas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages. v2 updated experimental results and details
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05241" title="Abstract">arXiv:2312.05241</a> (replaced) [<a href="/pdf/2312.05241" title="Download PDF">pdf</a>, <a href="/ps/2312.05241" title="Download PostScript">ps</a>, <a href="/format/2312.05241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contra generative AI detection in higher education assessments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ardito%2C+C+G">Cesare G. Ardito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: added references, fixed typos. 20 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05506" title="Abstract">arXiv:2312.05506</a> (replaced) [<a href="/pdf/2312.05506" title="Download PDF">pdf</a>, <a href="/format/2312.05506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trade-off of Security, Latency, and Throughput of the Nakamoto Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shu-Jie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dongning Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05634" title="Abstract">arXiv:2312.05634</a> (replaced) [<a href="/pdf/2312.05634" title="Download PDF">pdf</a>, <a href="/format/2312.05634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PGS: Pose-Guided Supervision for Mitigating Clothes-Changing in Person  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trinh%2C+Q">Quoc-Huy Trinh</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+N">Nhat-Tan Bui</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D">Dinh-Hieu Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Thi%2C+P+V">Phuoc-Thao Vo Thi</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hai-Dang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+D">Debesh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Minh-Triet Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06907" title="Abstract">arXiv:2312.06907</a> (replaced) [<a href="/pdf/2312.06907" title="Download PDF">pdf</a>, <a href="/format/2312.06907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> w2v-SELD: A Sound Event Localization and Detection Framework for  Self-Supervised Spatial Audio Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Santos%2C+O+L+d">Orlem Lima dos Santos</a>, 
<a href="/search/eess?searchtype=author&query=Rosero%2C+K">Karen Rosero</a>, 
<a href="/search/eess?searchtype=author&query=de+Alencar+Lotufo%2C+R">Roberto de Alencar Lotufo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07010" title="Abstract">arXiv:2312.07010</a> (replaced) [<a href="/pdf/2312.07010" title="Download PDF">pdf</a>, <a href="/ps/2312.07010" title="Download PostScript">ps</a>, <a href="/format/2312.07010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized lattice Boltzmann method based maximum principle and energy  stability preserving finite-difference scheme for the Allen-Cahn equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Ying Chen</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+X">Xi Liu</a>, 
<a href="/search/math?searchtype=author&query=Chai%2C+Z">Zhenhua Chai</a>, 
<a href="/search/math?searchtype=author&query=Shi%2C+B">Baochang Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07586" title="Abstract">arXiv:2312.07586</a> (replaced) [<a href="/pdf/2312.07586" title="Download PDF">pdf</a>, <a href="/format/2312.07586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characteristic Guidance: Non-linear Correction for Diffusion Model at  Large Guidance Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Candi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yuan Lan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07883" title="Abstract">arXiv:2312.07883</a> (replaced) [<a href="/pdf/2312.07883" title="Download PDF">pdf</a>, <a href="/format/2312.07883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multispreads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krotov%2C+D+S">Denis S. Krotov</a>, 
<a href="/search/cs?searchtype=author&query=Mogilnykh%2C+I+Y">Ivan Yu. Mogilnykh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08299" title="Abstract">arXiv:2312.08299</a> (replaced) [<a href="/pdf/2312.08299" title="Download PDF">pdf</a>, <a href="/format/2312.08299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conceptualizing Suicidal Behavior: Utilizing Explanations of Predicted  Outcomes to Analyze Longitudinal Social Media Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V+M">Van Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nur%2C+N">Nasheen Nur</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+W">William Stern</a>, 
<a href="/search/cs?searchtype=author&query=Mercer%2C+T">Thomas Mercer</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+C">Chiradeep Sen</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+S">Siddhartha Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Tumbiolo%2C+V">Victor Tumbiolo</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+S+J">Seng Jhing Goh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at ICMLA 2023, Special Session: Machine Learning in Health, 8 pages, 6 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08793" title="Abstract">arXiv:2312.08793</a> (replaced) [<a href="/pdf/2312.08793" title="Download PDF">pdf</a>, <a href="/format/2312.08793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forbidden Facts: An Investigation of Competing Objectives in Llama-2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T+T">Tony T. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miles Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hariharan%2C+K">Kaivalya Hariharan</a>, 
<a href="/search/cs?searchtype=author&query=Shavit%2C+N">Nir Shavit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the ATTRIB and SoLaR workshops at NeurIPS 2023; (v3: clarified experimental details)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09086" title="Abstract">arXiv:2312.09086</a> (replaced) [<a href="/pdf/2312.09086" title="Download PDF">pdf</a>, <a href="/format/2312.09086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COMBHelper: A Neural Approach to Reduce Search Space for Graph  Combinatorial Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Medya%2C+S">Sourav Medya</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09168" title="Abstract">arXiv:2312.09168</a> (replaced) [<a href="/pdf/2312.09168" title="Download PDF">pdf</a>, <a href="/format/2312.09168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionLight: Light Probes for Free by Painting a Chrome Ball
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phongthawee%2C+P">Pakkapon Phongthawee</a>, 
<a href="/search/cs?searchtype=author&query=Chinchuthakun%2C+W">Worameth Chinchuthakun</a>, 
<a href="/search/cs?searchtype=author&query=Sinsunthithet%2C+N">Nontaphat Sinsunthithet</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+A">Amit Raj</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Khungurn%2C+P">Pramook Khungurn</a>, 
<a href="/search/cs?searchtype=author&query=Suwajanakorn%2C+S">Supasorn Suwajanakorn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For more info and code, please visit our website <a href="https://diffusionlight.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09916" title="Abstract">arXiv:2312.09916</a> (replaced) [<a href="/pdf/2312.09916" title="Download PDF">pdf</a>, <a href="/format/2312.09916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two trees are better than one
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dumitrescu%2C+A">Adrian Dumitrescu</a>, 
<a href="/search/cs?searchtype=author&query=Pach%2C+J">J&#xe1;nos Pach</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B3th%2C+G">G&#xe9;za T&#xf3;th</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 figures, 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10324" title="Abstract">arXiv:2312.10324</a> (replaced) [<a href="/pdf/2312.10324" title="Download PDF">pdf</a>, <a href="/format/2312.10324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning with Instance-Dependent Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jieming Bian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10402" title="Abstract">arXiv:2312.10402</a> (replaced) [<a href="/pdf/2312.10402" title="Download PDF">pdf</a>, <a href="/format/2312.10402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Annotation-free Automatic Music Transcription with Scalable Synthetic  Data and Adversarial Domain Confusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sato%2C+G">Gakusei Sato</a>, 
<a href="/search/cs?searchtype=author&query=Akama%2C+T">Taketo Akama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10472" title="Abstract">arXiv:2312.10472</a> (replaced) [<a href="/pdf/2312.10472" title="Download PDF">pdf</a>, <a href="/format/2312.10472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Generalization in Policy Networks: A Case Study with the  Double-Integrator System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruining Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Haoran Han</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+M">Maolong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qisong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jian Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10661" title="Abstract">arXiv:2312.10661</a> (replaced) [<a href="/pdf/2312.10661" title="Download PDF">pdf</a>, <a href="/format/2312.10661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wikiformer: Pre-training with Structured Information of Wikipedia for  Ad-hoc Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Weihang Su</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaolong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Shengluan Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10841" title="Abstract">arXiv:2312.10841</a> (replaced) [<a href="/pdf/2312.10841" title="Download PDF">pdf</a>, <a href="/format/2312.10841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Boosting Adaptive Learning under Concept Drift for Multistream  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+E">En Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guangquan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11245" title="Abstract">arXiv:2312.11245</a> (replaced) [<a href="/pdf/2312.11245" title="Download PDF">pdf</a>, <a href="/format/2312.11245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WiSegRT: Dataset for Site-Specific Indoor Radio Propagation Modeling  with 3D Segmentation and Differentiable Ray-Tracing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haijian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R+Q">Rose Qingyang Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE ICNC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11451" title="Abstract">arXiv:2312.11451</a> (replaced) [<a href="/pdf/2312.11451" title="Download PDF">pdf</a>, <a href="/format/2312.11451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Assisted 3D Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanmin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qiankun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report, unpublished, 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11753" title="Abstract">arXiv:2312.11753</a> (replaced) [<a href="/pdf/2312.11753" title="Download PDF">pdf</a>, <a href="/ps/2312.11753" title="Download PostScript">ps</a>, <a href="/format/2312.11753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poker Hand History File Format Specification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12999" title="Abstract">arXiv:2312.12999</a> (replaced) [<a href="/pdf/2312.12999" title="Download PDF">pdf</a>, <a href="/format/2312.12999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Mindset: An MBTI Exploration of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaxi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+L">Liuzhenghao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jing Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rongsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">YongHong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13108" title="Abstract">arXiv:2312.13108</a> (replaced) [<a href="/pdf/2312.13108" title="Download PDF">pdf</a>, <a href="/format/2312.13108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASSISTGUI: Task-Oriented Desktop Graphical User Interface Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Difei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+L">Lei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Zechen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+M">Mingyu Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peiran Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+D">Dongxing Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qinchen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiangwu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hengxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luowei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://showlab.github.io/assistgui/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13110" title="Abstract">arXiv:2312.13110</a> (replaced) [<a href="/pdf/2312.13110" title="Download PDF">pdf</a>, <a href="/ps/2312.13110" title="Download PostScript">ps</a>, <a href="/format/2312.13110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training of Molecular GNNs as Conditional Boltzmann Generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koge%2C+D">Daiki Koge</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+N">Naoaki Ono</a>, 
<a href="/search/cs?searchtype=author&query=Kanaya%2C+S">Shigehiko Kanaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages. Short paper submitted to AAAI workshop (AI2ASE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13163" title="Abstract">arXiv:2312.13163</a> (replaced) [<a href="/pdf/2312.13163" title="Download PDF">pdf</a>, <a href="/ps/2312.13163" title="Download PostScript">ps</a>, <a href="/format/2312.13163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse sampling recovery by greedy algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Temlyakov%2C+V">V. Temlyakov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2307.04161">arXiv:2307.04161</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13401" title="Abstract">arXiv:2312.13401</a> (replaced) [<a href="/pdf/2312.13401" title="Download PDF">pdf</a>, <a href="/format/2312.13401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time is Encoded in the Weights of Finetuned Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nylund%2C+K">Kai Nylund</a>, 
<a href="/search/cs?searchtype=author&query=Gururangan%2C+S">Suchin Gururangan</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added references to Jaidka et al. (2018) and Loureiro et al. (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13461" title="Abstract">arXiv:2312.13461</a> (replaced) [<a href="/pdf/2312.13461" title="Download PDF">pdf</a>, <a href="/format/2312.13461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Communication in Federated Learning Using Floating-Point Lossy  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilkins%2C+G">Grant Wilkins</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+S">Sheng Di</a>, 
<a href="/search/cs?searchtype=author&query=Calhoun%2C+J+C">Jon C. Calhoun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kibaek Kim</a>, 
<a href="/search/cs?searchtype=author&query=Underwood%2C+R">Robert Underwood</a>, 
<a href="/search/cs?searchtype=author&query=Mortier%2C+R">Richard Mortier</a>, 
<a href="/search/cs?searchtype=author&query=Cappello%2C+F">Franck Cappello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13584" title="Abstract">arXiv:2312.13584</a> (replaced) [<a href="/pdf/2312.13584" title="Download PDF">pdf</a>, <a href="/format/2312.13584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wave Physics-informed Matrix Factorizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tetali%2C+H+V">Harsha Vardhan Tetali</a>, 
<a href="/search/cs?searchtype=author&query=Harley%2C+J+B">Joel B. Harley</a>, 
<a href="/search/cs?searchtype=author&query=Haeffele%2C+B+D">Benjamin D. Haeffele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2107.09144">arXiv:2107.09144</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14335" title="Abstract">arXiv:2312.14335</a> (replaced) [<a href="/pdf/2312.14335" title="Download PDF">pdf</a>, <a href="/ps/2312.14335" title="Download PostScript">ps</a>, <a href="/format/2312.14335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-aware Decoding Reduces Hallucination in Query-focused  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhichao Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14557" title="Abstract">arXiv:2312.14557</a> (replaced) [<a href="/pdf/2312.14557" title="Download PDF">pdf</a>, <a href="/format/2312.14557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aurora:Activating Chinese chat capability for Mixtral-8x7B sparse  Mixture-of-Experts through Instruction-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rongsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ruizhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yaofei Duan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+K">Kunyan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Han Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaxi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+P+C">Patrick Cheong-Iao Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yapeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tao Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15112" title="Abstract">arXiv:2312.15112</a> (replaced) [<a href="/pdf/2312.15112" title="Download PDF">pdf</a>, <a href="/format/2312.15112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chengming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haolun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15405" title="Abstract">arXiv:2312.15405</a> (replaced) [<a href="/pdf/2312.15405" title="Download PDF">pdf</a>, <a href="/format/2312.15405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Computation Pushdown for Cloud OLAP Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiangyao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Serafini%2C+M">Marco Serafini</a>, 
<a href="/search/cs?searchtype=author&query=Aboulnaga%2C+A">Ashraf Aboulnaga</a>, 
<a href="/search/cs?searchtype=author&query=Stonebraker%2C+M">Michael Stonebraker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15479" title="Abstract">arXiv:2312.15479</a> (replaced) [<a href="/pdf/2312.15479" title="Download PDF">pdf</a>, <a href="/ps/2312.15479" title="Download PostScript">ps</a>, <a href="/format/2312.15479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted Proportional Allocations of Indivisible Goods and Chores:  Insights via Matchings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=V.%2C+V+P+H">Vishwa Prakash H.V.</a>, 
<a href="/search/cs?searchtype=author&query=Nimbhorkar%2C+P">Prajakta Nimbhorkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15826" title="Abstract">arXiv:2312.15826</a> (replaced) [<a href="/pdf/2312.15826" title="Download PDF">pdf</a>, <a href="/format/2312.15826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Item Promotion on Visually-Aware Recommender Systems by  Guided Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lijian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Guanhua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15987" title="Abstract">arXiv:2312.15987</a> (replaced) [<a href="/pdf/2312.15987" title="Download PDF">pdf</a>, <a href="/ps/2312.15987" title="Download PostScript">ps</a>, <a href="/format/2312.15987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Full-Stack End-to-End Sub-THz Simulations at 140 GHz using NYUSIM  Channel Model in ns-3
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poddar%2C+H">Hitesh Poddar</a>, 
<a href="/search/cs?searchtype=author&query=Chowdary%2C+A">Akhileswar Chowdary</a>, 
<a href="/search/cs?searchtype=author&query=Rappaport%2C+T+S">Theodore S. Rappaport</a>, 
<a href="/search/cs?searchtype=author&query=Chafii%2C+M">Marwa Chafii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16127" title="Abstract">arXiv:2312.16127</a> (replaced) [<a href="/pdf/2312.16127" title="Download PDF">pdf</a>, <a href="/format/2312.16127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model Situational Awareness Based Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liman Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Hanyang Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages including appendix. Website will be released soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16256" title="Abstract">arXiv:2312.16256</a> (replaced) [<a href="/pdf/2312.16256" title="Download PDF">pdf</a>, <a href="/format/2312.16256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DL3DV-10K: A Large-Scale Scene Dataset for Deep Learning-based 3D Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+L">Lu Ling</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Yichen Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhi Tu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wentian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+C">Cheng Xin</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+K">Kun Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lantao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zixun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yawen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuanmao Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xingpeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ashok%2C+R">Rohan Ashok</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Aniruddha Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangrui Kong</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+G">Gang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Benes%2C+B">Bedrich Benes</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Aniket Bera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16430" title="Abstract">arXiv:2312.16430</a> (replaced) [<a href="/pdf/2312.16430" title="Download PDF">pdf</a>, <a href="/format/2312.16430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preference as Reward, Maximum Preference Optimization with Importance  Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zaifan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chao Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16471" title="Abstract">arXiv:2312.16471</a> (replaced) [<a href="/pdf/2312.16471" title="Download PDF">pdf</a>, <a href="/ps/2312.16471" title="Download PostScript">ps</a>, <a href="/format/2312.16471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Super Resolution for video Enhancement Using GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Maity%2C+A">Ankush Maity</a>, 
<a href="/search/eess?searchtype=author&query=Pious%2C+R">Roshan Pious</a>, 
<a href="/search/eess?searchtype=author&query=Lenka%2C+S+K">Sourabh Kumar Lenka</a>, 
<a href="/search/eess?searchtype=author&query=Choudhary%2C+V">Vishal Choudhary</a>, 
<a href="/search/eess?searchtype=author&query=Lokhande%2C+P+S">Prof. Sharayu Lokhande</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16477" title="Abstract">arXiv:2312.16477</a> (replaced) [<a href="/pdf/2312.16477" title="Download PDF">pdf</a>, <a href="/format/2312.16477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group Multi-View Transformer for 3D Shape Analysis with Spatial Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lixiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qingzhe Cui</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Richang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuanyan Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13pages, 8 figuers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16580" title="Abstract">arXiv:2312.16580</a> (replaced) [<a href="/pdf/2312.16580" title="Download PDF">pdf</a>, <a href="/format/2312.16580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLCounter: Text-aware Visual Representation for Zero-Shot Object  Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Seunggu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+W">WonJun Moon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+E">Euiyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jae-Pil Heo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024. Code is available at <a href="https://github.com/Seunggu0305/VLCounter">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16763" title="Abstract">arXiv:2312.16763</a> (replaced) [<a href="/pdf/2312.16763" title="Download PDF">pdf</a>, <a href="/format/2312.16763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification in Machine Learning for Joint Speaker  Diarization and Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=McKnight%2C+S+W">Simon W. McKnight</a>, 
<a href="/search/eess?searchtype=author&query=Hogg%2C+A+O+T">Aidan O. T. Hogg</a>, 
<a href="/search/eess?searchtype=author&query=Neo%2C+V+W">Vincent W. Neo</a>, 
<a href="/search/eess?searchtype=author&query=Naylor%2C+P+A">Patrick A. Naylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16767" title="Abstract">arXiv:2312.16767</a> (replaced) [<a href="/pdf/2312.16767" title="Download PDF">pdf</a>, <a href="/format/2312.16767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Anytime Multi-Agent Path Finding Using Bandit-Based Large  Neighborhood Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Thomy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Taoan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dilkina%2C+B">Bistra Dilkina</a>, 
<a href="/search/cs?searchtype=author&query=Koenig%2C+S">Sven Koenig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16813" title="Abstract">arXiv:2312.16813</a> (replaced) [<a href="/pdf/2312.16813" title="Download PDF">pdf</a>, <a href="/format/2312.16813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring Correlated Sources: AoI-based Scheduling is Nearly Optimal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramakanth%2C+R+V">R Vallabh Ramakanth</a>, 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+V">Vishrant Tripathi</a>, 
<a href="/search/cs?searchtype=author&query=Modiano%2C+E">Eytan Modiano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE INFOCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16886" title="Abstract">arXiv:2312.16886</a> (replaced) [<a href="/pdf/2312.16886" title="Download PDF">pdf</a>, <a href="/format/2312.16886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobileVLM : A Fast, Strong and Open Vision Language Assistant for Mobile  Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Limeng Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xinyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaolin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17046" title="Abstract">arXiv:2312.17046</a> (replaced) [<a href="/pdf/2312.17046" title="Download PDF">pdf</a>, <a href="/format/2312.17046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing and Modeling Inconsistent, Impossible, and Incoherent  Shapes and Scenes with 2D Non-Conservative Vector Fields mapped on  2-Complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akleman%2C+E">Ergun Akleman</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gonen%2C+O">Ozgur Gonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17077" title="Abstract">arXiv:2312.17077</a> (replaced) [<a href="/pdf/2312.17077" title="Download PDF">pdf</a>, <a href="/ps/2312.17077" title="Download PostScript">ps</a>, <a href="/format/2312.17077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projected Langevin Monte Carlo algorithms in non-convex and super-linear  setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pang%2C+C">Chenxu Pang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xiaojie Wang</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+Y">Yue Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17122" title="Abstract">arXiv:2312.17122</a> (replaced) [<a href="/pdf/2312.17122" title="Download PDF">pdf</a>, <a href="/format/2312.17122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model for Causal Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haitao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+L">Lin Ge</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuhe Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Rui Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17163" title="Abstract">arXiv:2312.17163</a> (replaced) [<a href="/pdf/2312.17163" title="Download PDF">pdf</a>, <a href="/format/2312.17163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FENet: Focusing Enhanced Network for Lane Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liman Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Hanyang Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages including appendix. The website will be released soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17194" title="Abstract">arXiv:2312.17194</a> (replaced) [<a href="/pdf/2312.17194" title="Download PDF">pdf</a>, <a href="/format/2312.17194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient Constrained Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ding%2C+D">Dongsheng Ding</a>, 
<a href="/search/math?searchtype=author&query=Huan%2C+Z">Zhengyan Huan</a>, 
<a href="/search/math?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 25 figures; HTML converted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17205" title="Abstract">arXiv:2312.17205</a> (replaced) [<a href="/pdf/2312.17205" title="Download PDF">pdf</a>, <a href="/format/2312.17205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EFHQ: Multi-purpose ExtremePose-Face-HQ dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dao%2C+T+T">Trung Tuan Dao</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+D+H">Duc Hong Vu</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Cuong Pham</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://bomcon123456.github.io/efhq/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17660" title="Abstract">arXiv:2312.17660</a> (replaced) [<a href="/pdf/2312.17660" title="Download PDF">pdf</a>, <a href="/format/2312.17660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normalization of Lithuanian Text Using Regular Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasparaitis%2C+P">Pijus Kasparaitis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item306">Cross-lists</a></li>
<li><a href="#item361">Replacements</a></li>
</ul>
<small>[ total of 583 entries:  <b>1-583</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2401">2401</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
