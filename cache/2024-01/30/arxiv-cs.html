<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri 26 Jan 24  to  Mon 29 Jan 24, announced Tue, 30 Jan 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item589">Cross-lists</a></li>
<li><a href="#item661">Replacements</a></li>
</ul>
<small>[ total of 1052 entries:  <b>1-1052</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue, 30 Jan 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15079" title="Abstract">arXiv:2401.15079</a> [<a href="/pdf/2401.15079" title="Download PDF">pdf</a>, <a href="/format/2401.15079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P not equal to NP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delgado%2C+D+C">Daniel Cardona Delgado</a> (Universidad Nacional de Colombia)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">This article finds the answer to the question: for any problem from which a
non-deterministic algorithm can be derived which verifies whether an answer is
correct or not in polynomial time (complexity class NP), is it possible to
create an algorithm that finds the right answer to the problem in polynomial
time (complexity class P)? For this purpose, this article shows a decision
problem and analyzes it to demonstrate that this problem does not belong to the
complexity class P, but it belongs to the class NP; doing so it will be proved
that it exists at least one problem that belongs to class NP but not to class
P, which means that this article will prove that not all NP problems are P.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15081" title="Abstract">arXiv:2401.15081</a> [<a href="/pdf/2401.15081" title="Download PDF">pdf</a>, <a href="/format/2401.15081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can generative AI and ChatGPT outperform humans on cognitive-demanding  problem-solving tasks in science?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Nyaaba%2C+M">Matthew Nyaaba</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenchao Ma</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Science &amp; Education, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This study aimed to examine an assumption that generative artificial
intelligence (GAI) tools can overcome the cognitive intensity that humans
suffer when solving problems. We compared the performance of ChatGPT and GPT-4
on 2019 NAEP science assessments with students by cognitive demands of the
items. Fifty-four tasks were coded by experts using a two-dimensional cognitive
load framework, including task cognitive complexity and dimensionality. ChatGPT
and GPT-4 responses were scored using the scoring keys of NAEP. The analysis of
the available data was based on the average student ability scores for students
who answered each item correctly and the percentage of students who responded
to individual items. Results showed that both ChatGPT and GPT-4 consistently
outperformed most students who answered the NAEP science assessments. As the
cognitive demand for NAEP tasks increases, statistically higher average student
ability scores are required to correctly address the questions. This pattern
was observed for students in grades 4, 8, and 12, respectively. However,
ChatGPT and GPT-4 were not statistically sensitive to the increase in cognitive
demands of the tasks, except for Grade 4. As the first study focusing on
comparing GAI and K-12 students in problem-solving in science, this finding
implies the need for changes to educational objectives to prepare students with
competence to work with GAI tools in the future. Education ought to emphasize
the cultivation of advanced cognitive skills rather than depending solely on
tasks that demand cognitive intensity. This approach would foster critical
thinking, analytical skills, and the application of knowledge in novel
contexts. Findings also suggest the need for innovative assessment practices by
moving away from cognitive intensity tasks toward creativity and analytical
skills to avoid the negative effects of GAI on testing more efficiently.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15088" title="Abstract">arXiv:2401.15088</a> [<a href="/pdf/2401.15088" title="Download PDF">pdf</a>, <a href="/ps/2401.15088" title="Download PostScript">ps</a>, <a href="/format/2401.15088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design &amp; Implementation of Automatic Machine Condition Monitoring and  Maintenance System in Limited Resource Situations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ripon%2C+A+H+M">Abu Hanif Md. Ripon</a>, 
<a href="/search/eess?searchtype=author&query=Ullah%2C+M+A">Muhammad Ahsan Ullah</a>, 
<a href="/search/eess?searchtype=author&query=Paul%2C+A+K">Arindam Kumar Paul</a>, 
<a href="/search/eess?searchtype=author&query=Morshed%2C+M+M">Md. Mortaza Morshed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Peer Review, Journal: Heliyon, Section: Engineering, Page: 26
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the era of the fourth industrial revolution, it is essential to automate
fault detection and diagnosis of machineries so that a warning system can be
developed that will help to take an appropriate action before any catastrophic
damage. Some machines health monitoring systems are used globally but they are
expensive and need trained personnel to operate and analyse. Predictive
maintenance and occupational health and safety culture are not available due to
inadequate infrastructure, lack of skilled manpower, financial crisis, and
others in developing countries. Starting from developing a cost-effective DAS
for collecting fault data in this study, the effect of limited data and
resources has been investigated while automating the process. To solve this
problem, A feature engineering and data reduction method has been developed
combining the concepts from wavelets, differential calculus, and signal
processing. Finally, for automating the whole process, all the necessary
theoretical and practical considerations to develop a predictive model have
been proposed. The DAS successfully collected the required data from the
machine that is 89% accurate compared to the professional manual monitoring
system. SVM and NN were proposed for the prediction purpose because of their
high predicting accuracy greater than 95% during training and 100% during
testing the new samples. In this study, the combination of the simple algorithm
with a rule-based system instead of a data-intensive system turned out to be
hybridization by validating with collected data. The outcome of this research
can be instantly applied to small and medium-sized industries for finding other
issues and developing accordingly. As one of the foundational studies in
automatic FDD, the findings and procedure of this study can lead others to
extend, generalize, or add other dimensions to FDD automation.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15089" title="Abstract">arXiv:2401.15089</a> [<a href="/pdf/2401.15089" title="Download PDF">pdf</a>, <a href="/format/2401.15089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Material Property Prediction using Generically Complete  Isometry Invariants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balasingham%2C+J">Jonathan Balasingham</a>, 
<a href="/search/cs?searchtype=author&query=Zamaraev%2C+V">Viktor Zamaraev</a>, 
<a href="/search/cs?searchtype=author&query=Kurlin%2C+V">Vitaliy Kurlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Geometry (cs.CG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Material or crystal property prediction using machine learning has grown
popular in recent years as it provides a computationally efficient replacement
to classical simulation methods. A crucial first step for any of these
algorithms is the representation used for a periodic crystal. While similar
objects like molecules and proteins have a finite number of atoms and their
representation can be built based upon a finite point cloud interpretation,
periodic crystals are unbounded in size, making their representation more
challenging. In the present work, we adapt the Pointwise Distance Distribution
(PDD), a continuous and generically complete isometry invariant for periodic
point sets, as a representation for our learning algorithm. While the PDD is
effective in distinguishing periodic point sets up to isometry, there is no
consideration for the composition of the underlying material. We develop a
transformer model with a modified self-attention mechanism that can utilize the
PDD and incorporate compositional information via a spatial encoding method.
This model is tested on the crystals of the Materials Project and Jarvis-DFT
databases and shown to produce accuracy on par with state-of-the-art methods
while being several times faster in both training and prediction time.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15098" title="Abstract">arXiv:2401.15098</a> [<a href="/pdf/2401.15098" title="Download PDF">pdf</a>, <a href="/format/2401.15098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hi-Core: Hierarchical Knowledge Transfer for Continual Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chaofan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianrui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Continual reinforcement learning (CRL) empowers RL agents with the ability to
learn from a sequence of tasks, preserving previous knowledge and leveraging it
to facilitate future learning. However, existing methods often focus on
transferring low-level knowledge across similar tasks, which neglects the
hierarchical structure of human cognitive control, resulting in insufficient
knowledge transfer across diverse tasks. To enhance high-level knowledge
transfer, we propose a novel framework named Hi-Core (Hierarchical knowledge
transfer for Continual reinforcement learning), which is structured in two
layers: 1) the high-level policy formulation which utilizes the powerful
reasoning ability of the Large Language Model (LLM) to set goals and 2) the
low-level policy learning through RL which is oriented by high-level goals.
Moreover, the knowledge base (policy library) is constructed to store policies
that can be retrieved for hierarchical knowledge transfer. Experiments
conducted in MiniGrid have demonstrated the effectiveness of Hi-Core in
handling diverse CRL tasks, outperforming popular baselines.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15103" title="Abstract">arXiv:2401.15103</a> [<a href="/pdf/2401.15103" title="Download PDF">pdf</a>, <a href="/format/2401.15103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PruneSymNet: A Symbolic Neural Network and Pruning Algorithm for  Symbolic Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lina Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+M">Meilan Hao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Symbolic regression aims to derive interpretable symbolic expressions from
data in order to better understand and interpret data. %which plays an
important role in knowledge discovery and interpretable machine learning.
<br />In this study, a symbolic network called PruneSymNet is proposed for symbolic
regression. This is a novel neural network whose activation function consists
of common elementary functions and operators. The whole network is
differentiable and can be trained by gradient descent method. Each subnetwork
in the network corresponds to an expression, and our goal is to extract such
subnetworks to get the desired symbolic expression.
<br />Therefore, a greedy pruning algorithm is proposed to prune the network into a
subnetwork while ensuring the accuracy of data fitting. The proposed greedy
pruning algorithm preserves the edge with the least loss in each pruning, but
greedy algorithm often can not get the optimal solution. In order to alleviate
this problem, we combine beam search during pruning to obtain multiple
candidate expressions each time, and finally select the expression with the
smallest loss as the final result. It was tested on the public data set and
compared with the current popular algorithms. The results showed that the
proposed algorithm had better accuracy.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15106" title="Abstract">arXiv:2401.15106</a> [<a href="/pdf/2401.15106" title="Download PDF">pdf</a>, <a href="/ps/2401.15106" title="Download PostScript">ps</a>, <a href="/format/2401.15106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision Theoretic Foundations for Experiments Evaluating Human  Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hullman%2C+J">Jessica Hullman</a>, 
<a href="/search/cs?searchtype=author&query=Kale%2C+A">Alex Kale</a>, 
<a href="/search/cs?searchtype=author&query=Hartline%2C+J">Jason Hartline</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Decision-making with information displays is a key focus of research in areas
like explainable AI, human-AI teaming, and data visualization. However, what
constitutes a decision problem, and what is required for an experiment to be
capable of concluding that human decisions are flawed in some way, remain open
to speculation. We present a widely applicable definition of a decision problem
synthesized from statistical decision theory and information economics. We
argue that to attribute loss in human performance to forms of bias, an
experiment must provide participants with the information that a rational agent
would need to identify the normative decision. We evaluate the extent to which
recent evaluations of decision-making from the literature on AI-assisted
decisions achieve this criteria. We find that only 6 (17\%) of 35 studies that
claim to identify biased behavior present participants with sufficient
information to characterize their behavior as deviating from good
decision-making. We motivate the value of studying well-defined decision
problems by describing a characterization of performance losses they allow us
to conceive. In contrast, the ambiguities of a poorly communicated decision
problem preclude normative interpretation. We conclude with recommendations for
practice.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15108" title="Abstract">arXiv:2401.15108</a> [<a href="/pdf/2401.15108" title="Download PDF">pdf</a>, <a href="/format/2401.15108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-agent Deep Reinforcement Learning for Dynamic Pricing by  Fast-charging Electric Vehicle Hubs in ccompetition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D">Diwas Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+T+K">Tapas K. Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); General Economics (econ.GN); Systems and Control (eess.SY)

</div>
<p class="mathjax">Fast-charging hubs for electric vehicles will soon become part of the newly
built infrastructure for transportation electrification across the world. These
hubs are expected to host many DC fast-charging stations and will admit EVs
only for charging. Like the gasoline refueling stations, fast-charging hubs in
a neighborhood will dynamically vary their prices to compete for the same pool
of EV owners. These hubs will interact with the electric power network by
making purchase commitments for a significant part of their power needs in the
day-ahead (DA) electricity market and meeting the difference from the real-time
(RT) market. Hubs may have supplemental battery storage systems (BSS), which
they will use for arbitrage. In this paper, we develop a two-step data-driven
dynamic pricing methodology for hubs in price competition. We first obtain the
DA commitment by solving a stochastic DA commitment model. Thereafter we obtain
the hub pricing strategies by modeling the game as a competitive Markov
decision process (CMDP) and solving it using a multi-agent deep reinforcement
learning (MADRL) approach. We develop a numerical case study for a pricing game
between two charging hubs. We solve the case study with our methodology by
using combinations of two different DRL algorithms, DQN and SAC, and two
different neural networks (NN) architectures, a feed-forward (FF) neural
network, and a multi-head attention (MHA) neural network. We construct a
measure of collusion (index) using the hub profits. A value of zero for this
index indicates no collusion (perfect competition) and a value of one indicates
full collusion (monopolistic behavior). Our results show that the collusion
index varies approximately between 0.14 and 0.45 depending on the combinations
of the algorithms and the architectures chosen by the hubs.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15109" title="Abstract">arXiv:2401.15109</a> [<a href="/pdf/2401.15109" title="Download PDF">pdf</a>, <a href="/ps/2401.15109" title="Download PostScript">ps</a>, <a href="/format/2401.15109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Collective Superintelligence: Amplifying Group IQ using  Conversational Swarms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenberg%2C+L">Louis Rosenberg</a>, 
<a href="/search/cs?searchtype=author&query=Willcox%2C+G">Gregg Willcox</a>, 
<a href="/search/cs?searchtype=author&query=Schumann%2C+H">Hans Schumann</a>, 
<a href="/search/cs?searchtype=author&query=Mani%2C+G">Ganesh Mani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Swarm Intelligence (SI) is a natural phenomenon that enables biological
groups to amplify their combined intellect by forming real-time systems.
Artificial Swarm Intelligence (or Swarm AI) is a technology that enables
networked human groups to amplify their combined intelligence by forming
similar systems. In the past, swarm-based methods were constrained to narrowly
defined tasks like probabilistic forecasting and multiple-choice decision
making. A new technology called Conversational Swarm Intelligence (CSI) was
developed in 2023 that amplifies the decision-making accuracy of networked
human groups through natural conversational deliberations. The current study
evaluated the ability of real-time groups using a CSI platform to take a common
IQ test known as Raven's Advanced Progressive Matrices (RAPM). First, a
baseline group of participants took the Raven's IQ test by traditional survey.
This group averaged 45.6% correct. Then, groups of approximately 35 individuals
answered IQ test questions together using a CSI platform called Thinkscape.
These groups averaged 80.5% correct. This places the CSI groups in the 97th
percentile of IQ test-takers and corresponds to an effective IQ increase of 28
points (p&lt;0.001). This is an encouraging result and suggests that CSI is a
powerful method for enabling conversational collective intelligence in large,
networked groups. In addition, because CSI is scalable across groups of
potentially any size, this technology may provide a viable pathway to building
a Collective Superintelligence.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15113" title="Abstract">arXiv:2401.15113</a> [<a href="/pdf/2401.15113" title="Download PDF">pdf</a>, <a href="/format/2401.15113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Global Glacier Mapping with Deep Learning and Open Earth  Observation Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maslov%2C+K+A">Konstantin A. Maslov</a>, 
<a href="/search/cs?searchtype=author&query=Persello%2C+C">Claudio Persello</a>, 
<a href="/search/cs?searchtype=author&query=Schellenberger%2C+T">Thomas Schellenberger</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+A">Alfred Stein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate global glacier mapping is critical for understanding climate change
impacts. It is challenged by glacier diversity, difficult-to-classify debris
and big data processing. Here we propose Glacier-VisionTransformer-U-Net
(GlaViTU), a convolutional-transformer deep learning model, and five strategies
for multitemporal global-scale glacier mapping using open satellite imagery.
Assessing the spatial, temporal and cross-sensor generalisation shows that our
best strategy achieves intersection over union &gt;0.85 on previously unobserved
images in most cases, which drops to &gt;0.75 for debris-rich areas such as
High-Mountain Asia and increases to &gt;0.90 for regions dominated by clean ice.
Additionally, adding synthetic aperture radar data, namely, backscatter and
interferometric coherence, increases the accuracy in all regions where
available. The calibrated confidence for glacier extents is reported making the
predictions more reliable and interpretable. We also release a benchmark
dataset that covers 9% of glaciers worldwide. Our results support efforts
towards automated multitemporal and global glacier mapping.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15116" title="Abstract">arXiv:2401.15116</a> [<a href="/pdf/2401.15116" title="Download PDF">pdf</a>, <a href="/format/2401.15116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Online Crowdsourcing with Complex Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meir%2C+R">Reshef Meir</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Viet-An Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+J">Jagdish Ramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Weinsberg%2C+U">Udi Weinsberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> full version of a paper accepted to AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Crowdsourcing platforms use various truth discovery algorithms to aggregate
annotations from multiple labelers. In an online setting, however, the main
challenge is to decide whether to ask for more annotations for each item to
efficiently trade off cost (i.e., the number of annotations) for quality of the
aggregated annotations. In this paper, we propose a novel approach for general
complex annotation (such as bounding boxes and taxonomy paths), that works in
an online crowdsourcing setting. We prove that the expected average similarity
of a labeler is linear in their accuracy \emph{conditional on the reported
label}. This enables us to infer reported label accuracy in a broad range of
scenarios. We conduct extensive evaluations on real-world crowdsourcing data
from Meta and show the effectiveness of our proposed online algorithms in
improving the cost-quality trade-off.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15118" title="Abstract">arXiv:2401.15118</a> [<a href="/pdf/2401.15118" title="Download PDF">pdf</a>, <a href="/ps/2401.15118" title="Download PostScript">ps</a>, <a href="/format/2401.15118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoDecoder: Empowering Multimodal Map Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+F">Feng Qi</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+M">Mian Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zixian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents GeoDecoder, a dedicated multimodal model designed for
processing geospatial information in maps. Built on the BeitGPT architecture,
GeoDecoder incorporates specialized expert modules for image and text
processing. On the image side, GeoDecoder utilizes GaoDe Amap as the underlying
base map, which inherently encompasses essential details about road and
building shapes, relative positions, and other attributes. Through the
utilization of rendering techniques, the model seamlessly integrates external
data and features such as symbol markers, drive trajectories, heatmaps, and
user-defined markers, eliminating the need for extra feature engineering. The
text module of GeoDecoder accepts various context texts and question prompts,
generating text outputs in the style of GPT. Furthermore, the GPT-based model
allows for the training and execution of multiple tasks within the same model
in an end-to-end manner. To enhance map cognition and enable GeoDecoder to
acquire knowledge about the distribution of geographic entities in Beijing, we
devised eight fundamental geospatial tasks and conducted pretraining of the
model using large-scale text-image samples. Subsequently, rapid fine-tuning was
performed on three downstream tasks, resulting in significant performance
improvements. The GeoDecoder model demonstrates a comprehensive understanding
of map elements and their associated operations, enabling efficient and
high-quality application of diverse geospatial tasks in different business
scenarios.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15119" title="Abstract">arXiv:2401.15119</a> [<a href="/pdf/2401.15119" title="Download PDF">pdf</a>, <a href="/format/2401.15119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting Time Series Transformer Models and Sensitivity Analysis of  Population Age Groups to COVID-19 Infections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+K">Md Khairul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Valentine%2C+T">Tyler Valentine</a>, 
<a href="/search/cs?searchtype=author&query=Sue%2C+T+J">Timothy Joowon Sue</a>, 
<a href="/search/cs?searchtype=author&query=Karmacharya%2C+A">Ayush Karmacharya</a>, 
<a href="/search/cs?searchtype=author&query=Benham%2C+L+N">Luke Neil Benham</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kingsley Kim</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+J">Judy Fox</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">Interpreting deep learning time series models is crucial in understanding the
model's behavior and learning patterns from raw data for real-time
decision-making. However, the complexity inherent in transformer-based time
series models poses challenges in explaining the impact of individual features
on predictions. In this study, we leverage recent local interpretation methods
to interpret state-of-the-art time series models. To use real-world datasets,
we collected three years of daily case data for 3,142 US counties. Firstly, we
compare six transformer-based models and choose the best prediction model for
COVID-19 infection. Using 13 input features from the last two weeks, we can
predict the cases for the next two weeks. Secondly, we present an innovative
way to evaluate the prediction sensitivity to 8 population age groups over
highly dynamic multivariate infection data. Thirdly, we compare our proposed
perturbation-based interpretation method with related work, including a total
of eight local interpretation methods. Finally, we apply our framework to
traffic and electricity datasets, demonstrating that our approach is generic
and can be applied to other time-series domains.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15120" title="Abstract">arXiv:2401.15120</a> [<a href="/pdf/2401.15120" title="Download PDF">pdf</a>, <a href="/format/2401.15120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-driven self-supervised visual learning: Harnessing the  environment as a data source
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lizhen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+Z">James Z. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonseuk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wyble%2C+B">Brad Wyble</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Visual learning often occurs in a specific context, where an agent acquires
skills through exploration and tracking of its location in a consistent
environment. The historical spatial context of the agent provides a similarity
signal for self-supervised contrastive learning. We present a unique approach,
termed Environmental Spatial Similarity (ESS), that complements existing
contrastive learning methods. Using images from simulated, photorealistic
environments as an experimental setting, we demonstrate that ESS outperforms
traditional instance discrimination approaches. Moreover, sampling additional
data from the same environment substantially improves accuracy and provides new
augmentations. ESS allows remarkable proficiency in room classification and
spatial prediction tasks, especially in unfamiliar environments. This learning
paradigm has the potential to enable rapid visual learning in agents operating
in new environments with unique visual characteristics. Potentially
transformative applications span from robotics to space exploration. Our proof
of concept demonstrates improved efficiency over methods that rely on
extensive, disconnected datasets.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15121" title="Abstract">arXiv:2401.15121</a> [<a href="/pdf/2401.15121" title="Download PDF">pdf</a>, <a href="/ps/2401.15121" title="Download PostScript">ps</a>, <a href="/format/2401.15121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive Power of ReLU and Step Networks under Floating-Point  Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Yeachan Park</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+G">Geonho Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonyeol Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sejun Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The study of the expressive power of neural networks has investigated the
fundamental limits of neural networks. Most existing results assume real-valued
inputs and parameters as well as exact operations during the evaluation of
neural networks. However, neural networks are typically executed on computers
that can only represent a tiny subset of the reals and apply inexact
operations. In this work, we analyze the expressive power of neural networks
under a more realistic setup: when we use floating-point numbers and
operations. Our first set of results assumes floating-point operations where
the significand of a float is represented by finite bits but its exponent can
take any integer value. Under this setup, we show that neural networks using a
binary threshold unit or ReLU can memorize any finite input/output pairs and
can approximate any continuous function within a small error. We also show
similar results on memorization and universal approximation when floating-point
operations use finite bits for both significand and exponent; these results are
applicable to many popular floating-point formats such as those defined in the
IEEE 754 standard (e.g., 32-bit single-precision format) and bfloat16.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15122" title="Abstract">arXiv:2401.15122</a> [<a href="/pdf/2401.15122" title="Download PDF">pdf</a>, <a href="/format/2401.15122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Grained Symmetric Differential Equation Model for Learning  Protein-Ligand Binding Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weitao Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuoxinran Li</a>, 
<a href="/search/cs?searchtype=author&query=Bhethanabotla%2C+V">Vignesh Bhethanabotla</a>, 
<a href="/search/cs?searchtype=author&query=Rampal%2C+N">Nakul Rampal</a>, 
<a href="/search/cs?searchtype=author&query=Yaghi%2C+O">Omar Yaghi</a>, 
<a href="/search/cs?searchtype=author&query=Borgs%2C+C">Christian Borgs</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chayes%2C+J">Jennifer Chayes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)

</div>
<p class="mathjax">In drug discovery, molecular dynamics (MD) simulation for protein-ligand
binding provides a powerful tool for predicting binding affinities, estimating
transport properties, and exploring pocket sites. There has been a long history
of improving the efficiency of MD simulations through better numerical methods
and, more recently, by augmenting them with machine learning (ML) methods. Yet,
challenges remain, such as accurate modeling of extended-timescale simulations.
To address this issue, we propose NeuralMD, the first ML surrogate that can
facilitate numerical MD and provide accurate simulations of protein-ligand
binding dynamics. We propose a principled approach that incorporates a novel
physics-informed multi-grained group symmetric framework. Specifically, we
propose (1) a BindingNet model that satisfies group symmetry using vector
frames and captures the multi-level protein-ligand interactions, and (2) an
augmented neural differential equation solver that learns the trajectory under
Newtonian mechanics. For the experiment, we design ten single-trajectory and
three multi-trajectory binding simulation tasks. We show the efficiency and
effectiveness of NeuralMD, with a 2000$\times$ speedup over standard numerical
MD simulation and outperforming all other ML approaches by up to 80\% under the
stability metric. We further qualitatively show that NeuralMD reaches more
stable binding predictions compared to other machine learning methods.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15123" title="Abstract">arXiv:2401.15123</a> [<a href="/pdf/2401.15123" title="Download PDF">pdf</a>, <a href="/format/2401.15123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model Guided Knowledge Distillation for Time Series  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shibo He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shizhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+W">Wenchao Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Self-supervised methods have gained prominence in time series anomaly
detection due to the scarcity of available annotations. Nevertheless, they
typically demand extensive training data to acquire a generalizable
representation map, which conflicts with scenarios of a few available samples,
thereby limiting their performance. To overcome the limitation, we propose
\textbf{AnomalyLLM}, a knowledge distillation-based time series anomaly
detection approach where the student network is trained to mimic the features
of the large language model (LLM)-based teacher network that is pretrained on
large-scale datasets. During the testing phase, anomalies are detected when the
discrepancy between the features of the teacher and student networks is large.
To circumvent the student network from learning the teacher network's feature
of anomalous samples, we devise two key strategies. 1) Prototypical signals are
incorporated into the student network to consolidate the normal feature
extraction. 2) We use synthetic anomalies to enlarge the representation gap
between the two networks. AnomalyLLM demonstrates state-of-the-art performance
on 15 datasets, improving accuracy by at least 14.5\% in the UCR dataset.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15124" title="Abstract">arXiv:2401.15124</a> [<a href="/pdf/2401.15124" title="Download PDF">pdf</a>, <a href="/ps/2401.15124" title="Download PostScript">ps</a>, <a href="/format/2401.15124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensor-Based Data Acquisition via Ubiquitous Device to Detect Muscle  Strength Training Activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wianto%2C+E">E. Wianto</a>, 
<a href="/search/cs?searchtype=author&query=Toba%2C+H">H. Toba</a>, 
<a href="/search/cs?searchtype=author&query=Malinda%2C+M">M. Malinda</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chien-Hsu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, AHFE International Conference on Human Factors in Design, Engineering, and Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Maintaining a high quality of life through physical activities (PA) to
prevent health decline is crucial. However, the relationship between
individuals health status, PA preferences, and motion factors is complex. PA
discussions consistently show a positive correlation with healthy aging
experiences, but no explicit relation to specific types of musculoskeletal
exercises. Taking advantage of the increasingly widespread existence of
smartphones, especially in Indonesia, this research utilizes embedded sensors
for Human Activity Recognition (HAR). Based on 25 participants data, performing
nine types of selected motion, this study has successfully identified important
sensor attributes that play important roles in the right and left hands for
muscle strength motions as the basis for developing machine learning models
with the LSTM algorithm.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15127" title="Abstract">arXiv:2401.15127</a> [<a href="/pdf/2401.15127" title="Download PDF">pdf</a>, <a href="/format/2401.15127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of LLM Chatbots for OSINT-based Cyberthreat Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shafee%2C+S">Samaneh Shafee</a>, 
<a href="/search/cs?searchtype=author&query=Bessani%2C+A">Alysson Bessani</a>, 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+P+M">Pedro M. Ferreira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge sharing about emerging threats is crucial in the rapidly advancing
field of cybersecurity and forms the foundation of Cyber Threat Intelligence.
In this context, Large Language Models are becoming increasingly significant in
the field of cybersecurity, presenting a wide range of opportunities. This
study explores the capability of chatbots such as ChatGPT, GPT4all,
Dolly,Stanford Alpaca, Alpaca-LoRA, and Falcon to identify
cybersecurity-related text within Open Source Intelligence. We assess the
capabilities of existing chatbot models for Natural Language Processing tasks.
We consider binary classification and Named Entity Recognition as tasks. This
study analyzes well-established data collected from Twitter, derived from
previous research efforts. Regarding cybersecurity binary classification,
Chatbot GPT-4 as a commercial model achieved an acceptable F1-score of 0.94,
and the open-source GPT4all model achieved an F1-score of 0.90. However,
concerning cybersecurity entity recognition, chatbot models have limitations
and are less effective. This study demonstrates the capability of these
chatbots only for specific tasks, such as cybersecurity binary classification,
while highlighting the need for further refinement in other tasks, such as
Named Entity Recognition tasks.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15129" title="Abstract">arXiv:2401.15129</a> [<a href="/pdf/2401.15129" title="Download PDF">pdf</a>, <a href="/format/2401.15129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instantaneous Power Theory Revisited with Classical Mechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Milano%2C+F">Federico Milano</a>, 
<a href="/search/eess?searchtype=author&query=Tzounas%2C+G">Georgios Tzounas</a>, 
<a href="/search/eess?searchtype=author&query=Dassios%2C+I">Ioannis Dassios</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Differential Geometry (math.DG)

</div>
<p class="mathjax">The paper revisits the concepts of instantaneous active and reactive powers
and provides a novel definition for basic circuit elements based on quantities
utilized in classical mechanics, such as absolute and relative velocity,
momentum density, angular momentum and apparent forces. The discussion
leverages from recent publications by the authors that interpret the voltage
and current as velocities in generalized Lagrangian coordinates. The main
result of the paper is a general and compact expression for the instantaneous
active and reactive power of inductances, capacitances and resistances as a
multivector proportional to the generalized kinetic energy and the geometric
frequency multivector. Several numerical examples considering stationary and
transient sinusoidal and non-sinusoidal conditions are discussed in the case
study.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15132" title="Abstract">arXiv:2401.15132</a> [<a href="/pdf/2401.15132" title="Download PDF">pdf</a>, <a href="/format/2401.15132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Emergence of Symmetrical Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Z">Ziyuan Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yao Su</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hangxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE VR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial intelligence (AI) has revolutionized human cognitive abilities and
facilitated the development of new AI entities capable of interacting with
humans in both physical and virtual environments. Despite the existence of
virtual reality, mixed reality, and augmented reality for several years,
integrating these technical fields remains a formidable challenge due to their
disparate application directions. The advent of AI agents, capable of
autonomous perception and action, further compounds this issue by exposing the
limitations of traditional human-centered research approaches. It is imperative
to establish a comprehensive framework that accommodates the dual perceptual
centers of humans and AI agents in both physical and virtual worlds. In this
paper, we introduce the symmetrical reality framework, which offers a unified
representation encompassing various forms of physical-virtual amalgamations.
This framework enables researchers to better comprehend how AI agents can
collaborate with humans and how distinct technical pathways of physical-virtual
integration can be consolidated from a broader perspective. We then delve into
the coexistence of humans and AI, demonstrating a prototype system that
exemplifies the operation of symmetrical reality systems for specific tasks,
such as pouring water. Subsequently, we propose an instance of an AI-driven
active assistance service that illustrates the potential applications of
symmetrical reality. This paper aims to offer beneficial perspectives and
guidance for researchers and practitioners in different fields, thus
contributing to the ongoing research about human-AI coexistence in both
physical and virtual environments.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15138" title="Abstract">arXiv:2401.15138</a> [<a href="/pdf/2401.15138" title="Download PDF">pdf</a>, <a href="/ps/2401.15138" title="Download PostScript">ps</a>, <a href="/format/2401.15138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chaotic Encryption for 10-Gb Ethernet Optical Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Resa%2C+A">Adri&#xe1;n P&#xe9;rez-Resa</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Bosque%2C+M">Miguel Garcia-Bosque</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Azqueta%2C+C">Carlos S&#xe1;nchez-Azqueta</a>, 
<a href="/search/cs?searchtype=author&query=Celma%2C+S">Santiago Celma</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Circuits and Systems I: Regular Papers, vol.
  66, no. 2, pp. 859-868, Feb. 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, a new physical layer encryption method for optical 10-Gb
Ethernet links is proposed. Necessary modifications to introduce encryption in
Ethernet 10GBase-R standard have been considered. This security enhancement has
consisted of a symmetric streaming encryption of the 64b/66b data flow at
physical coding sublayer level thanks to two keystream generators based on a
chaotic algorithm. The overall system has been implemented and tested in a
field programmable gate array. Ethernet traffic has been encrypted,
transmitted, and decrypted over a multimode optical link. Experimental results
are analyzed concluding that it is possible to cipher traffic at this level and
hide the complete Ethernet traffic pattern from any passive eavesdropper. In
addition, no overhead is introduced during encryption, getting no losses in the
total throughput.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15159" title="Abstract">arXiv:2401.15159</a> [<a href="/pdf/2401.15159" title="Download PDF">pdf</a>, <a href="/format/2401.15159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RABBIT: A Robot-Assisted Bed Bathing System with Multimodal Perception  and Integrated Compliance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madan%2C+R">Rishabh Madan</a>, 
<a href="/search/cs?searchtype=author&query=Valdez%2C+S">Skyler Valdez</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">David Kim</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Sujie Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Luoyan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Virtue%2C+D">Diego Virtue</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+T">Tapomayukh Bhattacharjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 19th Annual ACM/IEEE International Conference on Human Robot Interaction (HRI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces RABBIT, a novel robot-assisted bed bathing system
designed to address the growing need for assistive technologies in personal
hygiene tasks. It combines multimodal perception and dual (software and
hardware) compliance to perform safe and comfortable physical human-robot
interaction. Using RGB and thermal imaging to segment dry, soapy, and wet skin
regions accurately, RABBIT can effectively execute washing, rinsing, and drying
tasks in line with expert caregiving practices. Our system includes
custom-designed motion primitives inspired by human caregiving techniques, and
a novel compliant end-effector called Scrubby, optimized for gentle and
effective interactions. We conducted a user study with 12 participants,
including one participant with severe mobility limitations, demonstrating the
system's effectiveness and perceived comfort. Supplementary material and videos
can be found on our website https://emprise.cs.cornell.edu/rabbit.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15164" title="Abstract">arXiv:2401.15164</a> [<a href="/pdf/2401.15164" title="Download PDF">pdf</a>, <a href="/format/2401.15164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMuSE: Adaptive Multimodal Analysis for Speaker Emotion Recognition in  Group Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devulapally%2C+N+K">Naresh Kumar Devulapally</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+S">Sidharth Anand</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+S+D">Sreyasee Das Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Junsong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yu-Ping Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Analyzing individual emotions during group conversation is crucial in
developing intelligent agents capable of natural human-machine interaction.
While reliable emotion recognition techniques depend on different modalities
(text, audio, video), the inherent heterogeneity between these modalities and
the dynamic cross-modal interactions influenced by an individual's unique
behavioral patterns make the task of emotion recognition very challenging. This
difficulty is compounded in group settings, where the emotion and its temporal
evolution are not only influenced by the individual but also by external
contexts like audience reaction and context of the ongoing conversation. To
meet this challenge, we propose a Multimodal Attention Network that captures
cross-modal interactions at various levels of spatial abstraction by jointly
learning its interactive bunch of mode-specific Peripheral and Central
networks. The proposed MAN injects cross-modal attention via its Peripheral
key-value pairs within each layer of a mode-specific Central query network. The
resulting cross-attended mode-specific descriptors are then combined using an
Adaptive Fusion technique that enables the model to integrate the
discriminative and complementary mode-specific data patterns within an
instance-specific multimodal descriptor. Given a dialogue represented by a
sequence of utterances, the proposed AMuSE model condenses both spatial and
temporal features into two dense descriptors: speaker-level and
utterance-level. This helps not only in delivering better classification
performance (3-5% improvement in Weighted-F1 and 5-7% improvement in Accuracy)
in large-scale public datasets but also helps the users in understanding the
reasoning behind each emotion prediction made by the model via its Multimodal
Explainability Visualization module.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15166" title="Abstract">arXiv:2401.15166</a> [<a href="/pdf/2401.15166" title="Download PDF">pdf</a>, <a href="/format/2401.15166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Design of Multi-Dimensional Spatially-Coupled Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C4%B0rima%C4%9Fz%C4%B1%2C+C">Canberk &#x130;rima&#x11f;z&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Tanr%C4%B1kulu%2C+A">Ata Tanr&#x131;kulu</a>, 
<a href="/search/cs?searchtype=author&query=Hareedy%2C+A">Ahmed Hareedy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages (double column), 5 figures, the short version has been submitted to the IEEE International Symposium on Information Theory (ISIT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Because of their excellent asymptotic and finite-length performance,
spatially-coupled (SC) codes are a class of low-density parity-check codes that
is gaining increasing attention. Multi-dimensional (MD) SC codes are
constructed by connecting copies of an SC code via relocations in order to
mitigate various sources of non-uniformity and improve performance in many data
storage and data transmission systems. As the number of degrees of freedom in
the MD-SC code design increases, appropriately exploiting them becomes more
difficult because of the complexity growth of the design process. In this
paper, we propose a probabilistic framework for the MD-SC code design, which is
based on the gradient-descent (GD) algorithm, to design better MD codes and
address this challenge. In particular, we express the expected number of short
cycles, which we seek to minimize, in the graph representation of the code in
terms of entries of a probability-distribution matrix that characterizes the
MD-SC code design. We then find a locally-optimal probability distribution,
which serves as the starting point of a finite-length algorithmic optimizer
that produces the final MD-SC code. We offer the theoretical analysis as well
as the algorithms, and we present experimental results demonstrating that our
MD codes, conveniently called GD-MD codes, have notably lower short cycle
numbers compared with the available state-of-the-art. Moreover, our algorithms
converge on solutions in few iterations, which confirms the complexity
reduction as a result of limiting the search space via the locally-optimal
GD-MD distributions.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15169" title="Abstract">arXiv:2401.15169</a> [<a href="/pdf/2401.15169" title="Download PDF">pdf</a>, <a href="/format/2401.15169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Cloth Elasticity Parameters From Homogenized Yarn-Level  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+X">Joy Xiaoji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G+W">Gene Wei-Chin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Bode%2C+L">Lukas Bode</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hsiao-yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Stuyck%2C+T">Tuur Stuyck</a>, 
<a href="/search/cs?searchtype=author&query=Larionov%2C+E">Egor Larionov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Virtual garment simulation has become increasingly important with
applications in garment design and virtual try-on. However, reproducing
garments faithfully remains a cumbersome process. We propose an end-to-end
method for estimating parameters of shell material models corresponding to real
fabrics with minimal priors. Our method determines yarn model properties from
information directly obtained from real fabrics, unlike methods that require
expensive specialized capture systems. We use an extended homogenization method
to match yarn-level and shell-level hyperelastic energies with respect to a
range of surface deformations represented by the first and second fundamental
forms, including bending along the diagonal to warp and weft directions. We
optimize the parameters of a shell deformation model involving uncoupled
bending and membrane energies. This allows the simulated model to exhibit
nonlinearity and anisotropy seen in real cloth. Finally, we validate our
results with quantitative and visual comparisons against real world fabrics
through stretch tests and drape experiments. Our homogenized shell models not
only capture the characteristics of underlying yarn patterns, but also exhibit
distinct behaviors for different yarn materials.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15170" title="Abstract">arXiv:2401.15170</a> [<a href="/pdf/2401.15170" title="Download PDF">pdf</a>, <a href="/ps/2401.15170" title="Download PostScript">ps</a>, <a href="/format/2401.15170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Qualitative Coding with LLMs: Chain-of-Thought Reasoning  Matches Human Performance in Some Hermeneutic Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunivin%2C+Z+O">Zackary Okun Dunivin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Qualitative coding, or content analysis, extracts meaning from text to
discern quantitative patterns across a corpus of texts. Recently, advances in
the interpretive abilities of large language models (LLMs) offer potential for
automating the coding process (applying category labels to texts), thereby
enabling human researchers to concentrate on more creative research aspects,
while delegating these interpretive tasks to AI. Our case study comprises a set
of socio-historical codes on dense, paragraph-long passages representative of a
humanistic study. We show that GPT-4 is capable of human-equivalent
interpretations, whereas GPT-3.5 is not. Compared to our human-derived gold
standard, GPT-4 delivers excellent intercoder reliability (Cohen's $\kappa \geq
0.79$) for 3 of 9 codes, and substantial reliability ($\kappa \geq 0.6$) for 8
of 9 codes. In contrast, GPT-3.5 greatly underperforms for all codes
($mean(\kappa) = 0.34$; $max(\kappa) = 0.55$). Importantly, we find that coding
fidelity improves considerably when the LLM is prompted to give rationale
justifying its coding decisions (chain-of-thought reasoning). We present these
and other findings along with a set of best practices for adapting traditional
codebooks for LLMs. Our results indicate that for certain codebooks,
state-of-the-art LLMs are already adept at large-scale content analysis.
Furthermore, they suggest the next generation of models will likely render AI
coding a viable option for a majority of codebooks.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15174" title="Abstract">arXiv:2401.15174</a> [<a href="/pdf/2401.15174" title="Download PDF">pdf</a>, <a href="/format/2401.15174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Multi-Modal Human-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hasler%2C+S">Stephan Hasler</a>, 
<a href="/search/cs?searchtype=author&query=Tanneberg%2C+D">Daniel Tanneberg</a>, 
<a href="/search/cs?searchtype=author&query=Ocker%2C+F">Felix Ocker</a>, 
<a href="/search/cs?searchtype=author&query=Joublin%2C+F">Frank Joublin</a>, 
<a href="/search/cs?searchtype=author&query=Ceravola%2C+A">Antonello Ceravola</a>, 
<a href="/search/cs?searchtype=author&query=Deigmoeller%2C+J">Joerg Deigmoeller</a>, 
<a href="/search/cs?searchtype=author&query=Gienger%2C+M">Michael Gienger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This paper presents an innovative large language model (LLM)-based robotic
system for enhancing multi-modal human-robot interaction (HRI). Traditional HRI
systems relied on complex designs for intent estimation, reasoning, and
behavior generation, which were resource-intensive. In contrast, our system
empowers researchers and practitioners to regulate robot behavior through three
key aspects: providing high-level linguistic guidance, creating "atomics" for
actions and expressions the robot can use, and offering a set of examples.
Implemented on a physical robot, it demonstrates proficiency in adapting to
multi-modal inputs and determining the appropriate manner of action to assist
humans with its arms, following researchers' defined guidelines.
Simultaneously, it coordinates the robot's lid, neck, and ear movements with
speech output to produce dynamic, multi-modal expressions. This showcases the
system's potential to revolutionize HRI by shifting from conventional, manual
state-and-flow design methods to an intuitive, guidance-based, and
example-driven approach.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15175" title="Abstract">arXiv:2401.15175</a> [<a href="/pdf/2401.15175" title="Download PDF">pdf</a>, <a href="/format/2401.15175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kitchen Food Waste Image Segmentation and Classification for Compost  Nutrients Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+R">Raiyan Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M">Mohsena Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yueyang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Huayi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+G">George Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanghui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The escalating global concern over extensive food wastage necessitates
innovative solutions to foster a net-zero lifestyle and reduce emissions. The
LILA home composter presents a convenient means of recycling kitchen scraps and
daily food waste into nutrient-rich, high-quality compost. To capture the
nutritional information of the produced compost, we have created and annotated
a large high-resolution image dataset of kitchen food waste with segmentation
masks of 19 nutrition-rich categories. Leveraging this dataset, we benchmarked
four state-of-the-art semantic segmentation models on food waste segmentation,
contributing to the assessment of compost quality of Nitrogen, Phosphorus, or
Potassium. The experiments demonstrate promising results of using segmentation
models to discern food waste produced in our daily lives. Based on the
experiments, SegFormer, utilizing MIT-B5 backbone, yields the best performance
with a mean Intersection over Union (mIoU) of 67.09. Class-based results are
also provided to facilitate further analysis of different food waste classes.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15182" title="Abstract">arXiv:2401.15182</a> [<a href="/pdf/2401.15182" title="Download PDF">pdf</a>, <a href="/format/2401.15182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> App Planner: Utilizing Generative AI for Design Thinking in K-12 Mobile  App Development Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">David Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+P">Prerna Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+R">Randi Williams</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+D">Daeun Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">App Planner is an interactive Creativity Support Tool for K-12 students,
designed to assist in the human-centered problem-solving and design thinking
process. By utilizing generative AI chatbot features, App Planner helps
students articulate the problem and solution in structured and diverse ways
through guided conversations via a chat-based interface. This interface
collaborates with students as a partner rather than a mentor. It assists them
in brainstorming and formulating new ideas for applications, provides feedback
on those ideas, and stimulates creative thinking. We mediate these
conversations to follow a design thinking framework that enhances and
encourages students to adopt human-centered problem-solving and critical
thinking perspectives. Here we report usability tests with high-school students
who appreciated App Planner for aiding the app design process and providing new
viewpoints on human aspects especially the potential negative impact of their
creation.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15186" title="Abstract">arXiv:2401.15186</a> [<a href="/pdf/2401.15186" title="Download PDF">pdf</a>, <a href="/ps/2401.15186" title="Download PostScript">ps</a>, <a href="/format/2401.15186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic Approach to Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barto%2C+L">Libor Barto</a>, 
<a href="/search/cs?searchtype=author&query=Butti%2C+S">Silvia Butti</a>, 
<a href="/search/cs?searchtype=author&query=Kazda%2C+A">Alexandr Kazda</a>, 
<a href="/search/cs?searchtype=author&query=Viola%2C+C">Caterina Viola</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BDivn%C3%BD%2C+S">Stanislav &#x17d;ivn&#xfd;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Following the success of the so-called algebraic approach to the study of
decision constraint satisfaction problems (CSPs), exact optimization of valued
CSPs, and most recently promise CSPs, we propose an algebraic framework for
valued promise CSPs.
<br />To every valued promise CSP we associate an algebraic object, its so-called
valued minion. Our main result shows that the existence of a homomorphism
between the associated valued minions implies a polynomial-time reduction
between the original CSPs. We also show that this general reduction theorem
includes important inapproximability results, for instance, the
inapproximability of almost solvable systems of linear equations beyond the
random assignment threshold.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15188" title="Abstract">arXiv:2401.15188</a> [<a href="/pdf/2401.15188" title="Download PDF">pdf</a>, <a href="/format/2401.15188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAREForMe: Contextual Multi-Armed Bandit Recommendation Framework for  Mental Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Nourzad%2C+N">Narjes Nourzad</a>, 
<a href="/search/cs?searchtype=author&query=Semple%2C+R+J">Randye J. Semple</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yixue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Emily Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamachari%2C+B">Bhaskar Krishnamachari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MOBILESoft 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The COVID-19 pandemic has intensified the urgency for effective and
accessible mental health interventions in people's daily lives. Mobile Health
(mHealth) solutions, such as AI Chatbots and Mindfulness Apps, have gained
traction as they expand beyond traditional clinical settings to support daily
life. However, the effectiveness of current mHealth solutions is impeded by the
lack of context-awareness, personalization, and modularity to foster their
reusability. This paper introduces CAREForMe, a contextual multi-armed bandit
(CMAB) recommendation framework for mental health. Designed with
context-awareness, personalization, and modularity at its core, CAREForMe
harnesses mobile sensing and integrates online learning algorithms with user
clustering capability to deliver timely, personalized recommendations. With its
modular design, CAREForMe serves as both a customizable recommendation
framework to guide future research, and a collaborative platform to facilitate
interdisciplinary contributions in mHealth research. We showcase CAREForMe's
versatility through its implementation across various platforms (e.g., Discord,
Telegram) and its customization to diverse recommendation features.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15189" title="Abstract">arXiv:2401.15189</a> [<a href="/pdf/2401.15189" title="Download PDF">pdf</a>, <a href="/format/2401.15189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SBFT Tool Competition 2024 -- Python Test Case Generation Track
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erni%2C+N">Nicolas Erni</a>, 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+A+M+A">Al-Ameen Mohammed Ali Mohammed</a>, 
<a href="/search/cs?searchtype=author&query=Birchler%2C+C">Christian Birchler</a>, 
<a href="/search/cs?searchtype=author&query=Derakhshanfar%2C+P">Pouria Derakhshanfar</a>, 
<a href="/search/cs?searchtype=author&query=Lukasczyk%2C+S">Stephan Lukasczyk</a>, 
<a href="/search/cs?searchtype=author&query=Panichella%2C+S">Sebastiano Panichella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, to appear in the Proceedings of the 17th International Workshop on Search-Based and Fuzz Testing (SBFT@ICSE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Test case generation (TCG) for Python poses distinctive challenges due to the
language's dynamic nature and the absence of strict type information. Previous
research has successfully explored automated unit TCG for Python, with
solutions outperforming random test generation methods. Nevertheless,
fundamental issues persist, hindering the practical adoption of existing test
case generators. To address these challenges, we report on the organization,
challenges, and results of the first edition of the Python Testing Competition.
Four tools, namely UTBotPython, Klara, Hypothesis Ghostwriter, and Pynguin were
executed on a benchmark set consisting of 35 Python source files sampled from 7
open-source Python projects for a time budget of 400 seconds. We considered one
configuration of each tool for each test subject and evaluated the tools'
effectiveness in terms of code and mutation coverage. This paper describes our
methodology, the analysis of the results together with the competing tools, and
the challenges faced while running the competition experiments.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15193" title="Abstract">arXiv:2401.15193</a> [<a href="/pdf/2401.15193" title="Download PDF">pdf</a>, <a href="/ps/2401.15193" title="Download PostScript">ps</a>, <a href="/format/2401.15193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of Sensing Attacks on Autonomous Vehicle Technologies and  Impact on Traffic Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zihao Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Sixu Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+S">Siyang Xie</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yunlong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">While perception systems in Connected and Autonomous Vehicles (CAVs), which
encompass both communication technologies and advanced sensors, promise to
significantly reduce human driving errors, they also expose CAVs to various
cyberattacks. These include both communication and sensing attacks, which
potentially jeopardize not only individual vehicles but also overall traffic
safety and efficiency. While much research has focused on communication
attacks, sensing attacks, which are equally critical, have garnered less
attention. To address this gap, this study offers a comprehensive review of
potential sensing attacks and their impact on target vehicles, focusing on
commonly deployed sensors in CAVs such as cameras, LiDAR, Radar, ultrasonic
sensors, and GPS. Based on this review, we discuss the feasibility of
integrating hardware-in-the-loop experiments with microscopic traffic
simulations. We also design baseline scenarios to analyze the macro-level
impact of sensing attacks on traffic flow. This study aims to bridge the
research gap between individual vehicle sensing attacks and broader macroscopic
impacts, thereby laying the foundation for future systemic understanding and
mitigation.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15194" title="Abstract">arXiv:2401.15194</a> [<a href="/pdf/2401.15194" title="Download PDF">pdf</a>, <a href="/ps/2401.15194" title="Download PostScript">ps</a>, <a href="/format/2401.15194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodality in Group Communication Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lange%2C+R">Robin Lange</a>, 
<a href="/search/cs?searchtype=author&query=Welles%2C+B+F">Brooke Foucault Welles</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">Gyanendra Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Radke%2C+R+J">Richard J. Radke</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+J+O">Javier O. Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+C">Christoph Riedl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Team interactions are often multisensory, requiring members to pick up on
verbal, visual, spatial and body language cues. Multimodal research, research
that captures multiple modes of communication such as audio and visual signals,
is therefore integral to understanding these multisensory group communication
processes. This type of research has gained traction in biomedical engineering
and neuroscience, but it is unclear the extent to which communication and
management researchers conduct multimodal research. Our study finds that
despite its' utility, multimodal research is underutilized in the communication
and management literature's. This paper then covers introductory guidelines for
creating new multimodal research including considerations for sensors, data
integration and ethical considerations.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15195" title="Abstract">arXiv:2401.15195</a> [<a href="/pdf/2401.15195" title="Download PDF">pdf</a>, <a href="/ps/2401.15195" title="Download PostScript">ps</a>, <a href="/format/2401.15195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounded-degree Low Rank Parity Check Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franch%2C+E">Ermes Franch</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunlei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Low rank parity check (LRPC) codes are the rank-metric analogue of low
density parity check codes. In this paper we investigate a sub-family of LRPC
codes, which have a parity check matrix defined over a subspace
$V_{\alpha,d}=\langle 1,\alpha, \ldots,
\alpha^{d-1}\rangle_{\mathbb{F}_q}\subsetneq \mathbb{F}_{q^m}$, where
$\mathbb{F}_{q^m}$ is the finite field of $q^m$ elements and $d$ is
significantly smaller than $m $. These codes are named bounded-degree LRPC
(BD-LRPC) codes and are the same as the standard LRPC codes of density $2$ when
the degree $d=2$, while BD-LRPC codes of degree $d&gt;2$ constitute a proper
subset of LRPC codes of density $d$. Exploiting the particular structure of
their parity check matrix, we show that the BD-LRPC codes of degree $d$ can
uniquely correct errors of rank weight $r$ when $n-k \geq r + u$ for certain $u
\geq 1$, in contrast to the condition $n-k\geq dr$ required for the standard
LRPC codes, where $d\geq n/(n-k)$. This underscores the superior decoding
capability of the proposed BD-LRPC codes. As the code length $n$ approaches
infinity, when $n/m\rightarrow 0$, it is shown that $u$ can be chosen as a
certain constant, which indicates that the BD-LRPC codes with a code rate of
$R$ can be, with a high probability, uniquely decodable with the decoding
radius $\rho=r/n$ approaching the Singleton bound $1-R$ for $n \to \infty$; and
when $b= n/m$ is a constant, the BD-LRPC codes can have unique decoding radius
$\rho = 1-R-\epsilon $ for a small $\epsilon$, which can easily lead to
$\rho&gt;(1-R)/2$ with properly chosen parameters.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15196" title="Abstract">arXiv:2401.15196</a> [<a href="/pdf/2401.15196" title="Download PDF">pdf</a>, <a href="/format/2401.15196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized Q-Learning with Linear Function Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+J">Jiachen Xi</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+A">Alfredo Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Momcilovic%2C+P">Petar Momcilovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Several successful reinforcement learning algorithms make use of
regularization to promote multi-modal policies that exhibit enhanced
exploration and robustness. With functional approximation, the convergence
properties of some of these algorithms (e.g. soft Q-learning) are not well
understood. In this paper, we consider a single-loop algorithm for minimizing
the projected Bellman error with finite time convergence guarantees in the case
of linear function approximation. The algorithm operates on two scales: a
slower scale for updating the target network of the state-action values, and a
faster scale for approximating the Bellman backups in the subspace of the span
of basis vectors. We show that, under certain assumptions, the proposed
algorithm converges to a stationary point in the presence of Markovian noise.
In addition, we provide a performance guarantee for the policies derived from
the proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15199" title="Abstract">arXiv:2401.15199</a> [<a href="/pdf/2401.15199" title="Download PDF">pdf</a>, <a href="/format/2401.15199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCANIA Component X Dataset: A Real-World Multivariate Time Series  Dataset for Predictive Maintenance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kharazian%2C+Z">Zahra Kharazian</a>, 
<a href="/search/cs?searchtype=author&query=Lindgren%2C+T">Tony Lindgren</a>, 
<a href="/search/cs?searchtype=author&query=Magn%C3%BAsson%2C+S">Sindri Magn&#xfa;sson</a>, 
<a href="/search/cs?searchtype=author&query=Steinert%2C+O">Olof Steinert</a>, 
<a href="/search/cs?searchtype=author&query=Reyna%2C+O+A">Oskar Andersson Reyna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a description of a real-world, multivariate time series
dataset collected from an anonymized engine component (called Component X) of a
fleet of trucks from SCANIA, Sweden. This dataset includes diverse variables
capturing detailed operational data, repair records, and specifications of
trucks while maintaining confidentiality by anonymization. It is well-suited
for a range of machine learning applications, such as classification,
regression, survival analysis, and anomaly detection, particularly when applied
to predictive maintenance scenarios. The large population size and variety of
features in the format of histograms and numerical counters, along with the
inclusion of temporal information, make this real-world dataset unique in the
field. The objective of releasing this dataset is to give a broad range of
researchers the possibility of working with real-world data from an
internationally well-known company and introduce a standard benchmark to the
predictive maintenance field, fostering reproducible research.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15201" title="Abstract">arXiv:2401.15201</a> [<a href="/pdf/2401.15201" title="Download PDF">pdf</a>, <a href="/format/2401.15201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatically Detecting Confusion and Conflict During Collaborative  Learning Using Linguistic, Prosodic, and Facial Cues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yingbo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yukyeong Song</a>, 
<a href="/search/cs?searchtype=author&query=Celepkolu%2C+M">Mehmet Celepkolu</a>, 
<a href="/search/cs?searchtype=author&query=Boyer%2C+K+E">Kristy Elizabeth Boyer</a>, 
<a href="/search/cs?searchtype=author&query=Wiebe%2C+E">Eric Wiebe</a>, 
<a href="/search/cs?searchtype=author&query=Lynch%2C+C+F">Collin F. Lynch</a>, 
<a href="/search/cs?searchtype=author&query=Israel%2C+M">Maya Israel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 7 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">During collaborative learning, confusion and conflict emerge naturally.
However, persistent confusion or conflict have the potential to generate
frustration and significantly impede learners' performance. Early automatic
detection of confusion and conflict would allow us to support early
interventions which can in turn improve students' experience with and outcomes
from collaborative learning. Despite the extensive studies modeling confusion
during solo learning, there is a need for further work in collaborative
learning. This paper presents a multimodal machine-learning framework that
automatically detects confusion and conflict during collaborative learning. We
used data from 38 elementary school learners who collaborated on a series of
programming tasks in classrooms. We trained deep multimodal learning models to
detect confusion and conflict using features that were automatically extracted
from learners' collaborative dialogues, including (1) language-derived features
including TF-IDF, lexical semantics, and sentiment, (2) audio-derived features
including acoustic-prosodic features, and (3) video-derived features including
eye gaze, head pose, and facial expressions. Our results show that multimodal
models that combine semantics, pitch, and facial expressions detected confusion
and conflict with the highest accuracy, outperforming all unimodal models. We
also found that prosodic cues are more predictive of conflict, and facial cues
are more predictive of confusion. This study contributes to the automated
modeling of collaborative learning processes and the development of real-time
adaptive support to enhance learners' collaborative learning experience in
classroom contexts.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15202" title="Abstract">arXiv:2401.15202</a> [<a href="/pdf/2401.15202" title="Download PDF">pdf</a>, <a href="/ps/2401.15202" title="Download PostScript">ps</a>, <a href="/format/2401.15202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cross Entropy Interpretation of R{&#xe9;}nyi Entropy for  $&#x3b1;$-leakage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ni Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zarrabian%2C+M+A">Mohammad Amin Zarrabian</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+P">Parastoo Sadeghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages; 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper proposes an $\alpha$-leakage measure for $\alpha\in[0,\infty)$ by
a cross entropy interpretation of R{\'{e}}nyi entropy. While R\'{e}nyi entropy
was originally defined as an $f$-mean for $f(t) = \exp((1-\alpha)t)$, we reveal
that it is also a $\tilde{f}$-mean cross entropy measure for $\tilde{f}(t) =
\exp(\frac{1-\alpha}{\alpha}t)$. Minimizing this R\'{e}nyi cross-entropy gives
R\'{e}nyi entropy, by which the prior and posterior uncertainty measures are
defined corresponding to the adversary's knowledge gain on sensitive attribute
before and after data release, respectively. The $\alpha$-leakage is proposed
as the difference between $\tilde{f}$-mean prior and posterior uncertainty
measures, which is exactly the Arimoto mutual information. This not only
extends the existing $\alpha$-leakage from $\alpha \in [1,\infty)$ to the
overall R{\'{e}}nyi order range $\alpha \in [0,\infty)$ in a well-founded way
with $\alpha=0$ referring to nonstochastic leakage, but also reveals that the
existing maximal leakage is a $\tilde{f}$-mean of an elementary
$\alpha$-leakage for all $\alpha \in [0,\infty)$, which generalizes the
existing pointwise maximal leakage.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15203" title="Abstract">arXiv:2401.15203</a> [<a href="/pdf/2401.15203" title="Download PDF">pdf</a>, <a href="/format/2401.15203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedGT: Federated Node Classification with Scalable Graph Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zaixi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qingyong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Weibo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 24 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graphs are widely used to model relational data. As graphs are getting larger
and larger in real-world scenarios, there is a trend to store and compute
subgraphs in multiple local systems. For example, recently proposed
\emph{subgraph federated learning} methods train Graph Neural Networks (GNNs)
distributively on local subgraphs and aggregate GNN parameters with a central
server. However, existing methods have the following limitations: (1) The links
between local subgraphs are missing in subgraph federated learning. This could
severely damage the performance of GNNs that follow message-passing paradigms
to update node/edge features. (2) Most existing methods overlook the subgraph
heterogeneity issue, brought by subgraphs being from different parts of the
whole graph. To address the aforementioned challenges, we propose a scalable
\textbf{Fed}erated \textbf{G}raph \textbf{T}ransformer (\textbf{FedGT}) in the
paper. Firstly, we design a hybrid attention scheme to reduce the complexity of
the Graph Transformer to linear while ensuring a global receptive field with
theoretical bounds. Specifically, each node attends to the sampled local
neighbors and a set of curated global nodes to learn both local and global
information and be robust to missing links. The global nodes are dynamically
updated during training with an online clustering algorithm to capture the data
distribution of the corresponding local subgraph. Secondly, FedGT computes
clients' similarity based on the aligned global nodes with optimal transport.
The similarity is then used to perform weighted averaging for personalized
aggregation, which well addresses the data heterogeneity problem. Moreover,
local differential privacy is applied to further protect the privacy of
clients. Finally, extensive experimental results on 6 datasets and 2 subgraph
settings demonstrate the superiority of FedGT.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15204" title="Abstract">arXiv:2401.15204</a> [<a href="/pdf/2401.15204" title="Download PDF">pdf</a>, <a href="/format/2401.15204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LYT-Net: Lightweight YUV Transformer-based Network for Low-Light Image  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brateanu%2C+A">A. Brateanu</a>, 
<a href="/search/cs?searchtype=author&query=Balmez%2C+R">R. Balmez</a>, 
<a href="/search/cs?searchtype=author&query=Avram%2C+A">A. Avram</a>, 
<a href="/search/cs?searchtype=author&query=Orhei%2C+C+C">C. C. Orhei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, submitted to ICIP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In recent years, deep learning-based solutions have proven successful in the
domains of image enhancement. This paper introduces LYT-Net, or Lightweight YUV
Transformer-based Network, as a novel approach for low-light image enhancement.
The proposed architecture, distinct from conventional Retinex-based models,
leverages the YUV color space's natural separation of luminance (Y) and
chrominance (U and V) to simplify the intricate task of disentangling light and
color information in images. By utilizing the strengths of transformers, known
for their capability to capture long-range dependencies, LYT-Net ensures a
comprehensive contextual understanding of the image while maintaining reduced
model complexity. By employing a novel hybrid loss function, our proposed
method achieves state-of-the-art results on low-light image enhancement
datasets, all while being considerably more compact than its counterparts. The
source code and pre-trained models are available at
https://github.com/albrateanu/LYT-Net
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15206" title="Abstract">arXiv:2401.15206</a> [<a href="/pdf/2401.15206" title="Download PDF">pdf</a>, <a href="/ps/2401.15206" title="Download PostScript">ps</a>, <a href="/format/2401.15206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backscatter Measurements and Models for RF Sensing Applications in  Cluttered Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chizhik%2C+D">Dmitry Chizhik</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+J">Jinfeng Du</a>, 
<a href="/search/eess?searchtype=author&query=Sapis%2C+J">Jakub Sapis</a>, 
<a href="/search/eess?searchtype=author&query=Valenzuela%2C+R+A">Reinaldo A. Valenzuela</a>, 
<a href="/search/eess?searchtype=author&query=Adhikari%2C+A">Abhishek Adhikari</a>, 
<a href="/search/eess?searchtype=author&query=Zussman%2C+G">Gil Zussman</a>, 
<a href="/search/eess?searchtype=author&query=Almendra%2C+M+A">Manuel A. Almendra</a>, 
<a href="/search/eess?searchtype=author&query=Rodriguez%2C+M">Mauricio Rodriguez</a>, 
<a href="/search/eess?searchtype=author&query=Feick%2C+R">Rodolfo Feick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A statistical backscatter channel model for indoor clutter is developed for
indoor RF sensing applications based on measurements. A narrowband 28 GHz
sounder used a quazi-monostatic radar arrangement with an omnidirectional
transmit antenna illuminating an indoor scene and a spinning horn receive
antenna less than 1 m away collecting backscattered power as a function of
azimuth. Median average backscatter power was found to vary over a 12 dB range,
with average power generally decreasing with increasing room size. A
deterministic model of average backscattered power dependent on distance to
nearest wall and wall reflection coefficient reproduces observations with 4.0
dB RMS error. Distribution of power variation in azimuth around this average is
reproduced within 1 dB by a random azimuth spectrum with a lognormal amplitude
distribution and uniformly random phase. The model is extended to provide power
distribution over both azimuth and delay (conveying range to scatterer) by
combining azimuthal distribution with published results on power delay profiles
in reverberant environments. The statistical model does not require a detailed
room layout description, aiming to reproduce backscatter clutter statistics, as
opposed to a deterministic response.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15207" title="Abstract">arXiv:2401.15207</a> [<a href="/pdf/2401.15207" title="Download PDF">pdf</a>, <a href="/format/2401.15207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongkang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiqun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Daling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtze%2C+H">Hinrich Sch&#xfc;tze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Full-parameter fine-tuning has become the go-to choice for adapting language
models (LMs) to downstream tasks due to its excellent performance. As LMs grow
in size, fine-tuning the full parameters of LMs requires a prohibitively large
amount of GPU memory. Existing approaches utilize zeroth-order optimizer to
conserve GPU memory, which can potentially compromise the performance of LMs as
non-zero order optimizers tend to converge more readily on most downstream
tasks. In this paper, we propose a novel optimizer-independent end-to-end
hierarchical fine-tuning strategy, HiFT, which only updates a subset of
parameters at each training step. HiFT can significantly reduce the amount of
gradients and optimizer state parameters residing in GPU memory at the same
time, thereby reducing GPU memory usage. Our results demonstrate that: (1) HiFT
achieves comparable performance to parameter-efficient fine-tuning and standard
full parameter fine-tuning. (2) HiFT supports various optimizers including
AdamW, AdaGrad, SGD, etc. (3) HiFT can save more than 60\% GPU memory compared
with standard full-parameter fine-tuning for 7B model. (4) HiFT enables
full-parameter fine-tuning of a 7B model on single 48G A6000 with a precision
of 32 using the AdamW optimizer, without using any memory saving techniques.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15210" title="Abstract">arXiv:2401.15210</a> [<a href="/pdf/2401.15210" title="Download PDF">pdf</a>, <a href="/ps/2401.15210" title="Download PostScript">ps</a>, <a href="/format/2401.15210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Roq: Robust Query Optimization Based on a Risk-aware Learned Cost Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamali%2C+A">Amin Kamali</a>, 
<a href="/search/cs?searchtype=author&query=Kantere%2C+V">Verena Kantere</a>, 
<a href="/search/cs?searchtype=author&query=Zuzarte%2C+C">Calisto Zuzarte</a>, 
<a href="/search/cs?searchtype=author&query=Corvinelli%2C+V">Vincent Corvinelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, submitted to SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Query optimizers in relational database management systems (RDBMSs) search
for execution plans expected to be optimal for a given queries. They use
parameter estimates, often inaccurate, and make assumptions that may not hold
in practice. Consequently, they may select execution plans that are suboptimal
at runtime, when these estimates and assumptions are not valid, which may
result in poor query performance. Therefore, query optimizers do not
sufficiently support robust query optimization. Recent years have seen a surge
of interest in using machine learning (ML) to improve efficiency of data
systems and reduce their maintenance overheads, with promising results obtained
in the area of query optimization in particular. In this paper, inspired by
these advancements, and based on several years of experience of IBM Db2 in this
journey, we propose Robust Optimization of Queries, (Roq), a holistic framework
that enables robust query optimization based on a risk-aware learning approach.
Roq includes a novel formalization of the notion of robustness in the context
of query optimization and a principled approach for its quantification and
measurement based on approximate probabilistic ML. It also includes novel
strategies and algorithms for query plan evaluation and selection. Roq also
includes a novel learned cost model that is designed to predict query execution
cost and the associated risks and performs query optimization accordingly. We
demonstrate experimentally that Roq provides significant improvements to robust
query optimization compared to the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15212" title="Abstract">arXiv:2401.15212</a> [<a href="/pdf/2401.15212" title="Download PDF">pdf</a>, <a href="/format/2401.15212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speed-based Filtration and DBSCAN of Event-based Camera Data with  Neuromorphic Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizzo%2C+C+P">Charles P. Rizzo</a>, 
<a href="/search/cs?searchtype=author&query=Schuman%2C+C+D">Catherine D. Schuman</a>, 
<a href="/search/cs?searchtype=author&query=Plank%2C+J+S">James S. Plank</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, Submitted to Neuro Inspired Computational Elements Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Spiking neural networks are powerful computational elements that pair well
with event-based cameras (EBCs). In this work, we present two spiking neural
network architectures that process events from EBCs: one that isolates and
filters out events based on their speeds, and another that clusters events
based on the DBSCAN algorithm.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15213" title="Abstract">arXiv:2401.15213</a> [<a href="/pdf/2401.15213" title="Download PDF">pdf</a>, <a href="/format/2401.15213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On inertial iterated Tikhonov methods for solving ill-posed problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rabelo%2C+J+C">Joel C. Rabelo</a>, 
<a href="/search/math?searchtype=author&query=Leit%C3%A3o%2C+A">Antonio Leit&#xe3;o</a>, 
<a href="/search/math?searchtype=author&query=Madureira%2C+A+L">Alexandre L. Madureira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures. Accepted for publication at Inverse Problems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this manuscript we propose and analyze an implicit two-point type method
(or inertial method) for obtaining stable approximate solutions to linear
ill-posed operator equations. The method is based on the iterated Tikhonov (iT)
scheme. We establish convergence for exact data, and stability and
semi-convergence for noisy data. Regarding numerical experiments we consider:
i) a 2D Inverse Potential Problem, ii) an Image Deblurring Problem; the
computational efficiency of the method is compared with standard
implementations of the iT method.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15219" title="Abstract">arXiv:2401.15219</a> [<a href="/pdf/2401.15219" title="Download PDF">pdf</a>, <a href="/format/2401.15219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Deep Learning of Point Clouds for Inverse Control of 3D Shape  Morphing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+D">Dhirodaatto Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Suo%2C+J">Jiaqi Suo</a>, 
<a href="/search/cs?searchtype=author&query=Chortos%2C+A">Alex Chortos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Shape-morphing devices, a crucial branch in soft robotics, hold significant
application value in areas like human-machine interfaces, biomimetic robotics,
and tools for interacting with biological systems. To achieve three-dimensional
(3D) programmable shape morphing (PSM), the deployment of array-based actuators
is essential. However, a critical knowledge gap impeding the development of 3D
PSM is the challenge of controlling the complex systems formed by these soft
actuator arrays. This study introduces a novel approach, for the first time,
representing the configuration of shape morphing devices using point cloud data
and employing deep learning to map these configurations to control inputs. We
propose Shape Morphing Net (SMNet), a method that realizes the regression from
point cloud data to high-dimensional continuous vectors. Applied to previous 2D
PSM actuator arrays, SMNet significantly enhances control precision from 82.23%
to 97.68%. Further, we extend its application to 3D PSM devices with three
different actuator mechanisms, demonstrating the universal applicability of
SMNet to the control of 3D shape morphing technologies. In our demonstrations,
we confirm the efficacy of inverse control, where 3D PSM devices successfully
replicate target shapes. These shapes are obtained either through 3D scanning
of physical objects or via 3D modeling software. The results show that within
the deformable range of 3D PSM devices, accurate reproduction of the desired
shapes is achievable. The findings of this research represent a substantial
advancement in soft robotics, particularly for applications demanding intricate
3D shape transformations, and establish a foundational framework for future
developments in the field.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15221" title="Abstract">arXiv:2401.15221</a> [<a href="/pdf/2401.15221" title="Download PDF">pdf</a>, <a href="/format/2401.15221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing and Testing a Mobile Application for Collecting WhatsApp Chat  Data While Preserving Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schaffner%2C+B">Brennan Schaffner</a>, 
<a href="/search/cs?searchtype=author&query=Brohn%2C+A">Archie Brohn</a>, 
<a href="/search/cs?searchtype=author&query=Chee%2C+J">Jason Chee</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+K+J">K.J. Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chetty%2C+M">Marshini Chetty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">It is common practice for researchers to join public WhatsApp chats and
scrape their contents for analysis. However, research shows collecting data
this way contradicts user expectations and preferences, even if the data is
effectively public. To overcome these issues, we outline design considerations
for collecting WhatsApp chat data with improved user privacy by heightening
user control and oversight of data collection and taking care to minimize the
data researchers collect and process off a user's device. We refer to these
design principles as User-Centered Data Sharing (UCDS). To evaluate our UCDS
principles, we implemented a mobile application representing one possible
instance of these improved data collection techniques and evaluated the
viability of using the app to collect WhatsApp chat data. Second, we surveyed
WhatsApp users to gather user perceptions on common existing WhatsApp data
collection methods as well as UCDS methods. Our results show that we were able
to glean similar informative insights into WhatsApp chats using UCDS principles
in our prototype app to common, less privacy-preserving methods. Our survey
showed that methods following the UCDS principles are preferred by users
because they offered users more control over the data collection process.
Future user studies could further expand upon UCDS principles to overcome
complications of researcher-to-group communication in research on WhatsApp
chats and evaluate these principles in other data sharing contexts.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15222" title="Abstract">arXiv:2401.15222</a> [<a href="/pdf/2401.15222" title="Download PDF">pdf</a>, <a href="/format/2401.15222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning for the Prediction of Entity Modifiers in Clinical  Text: Application to Opioid Use Disorder Case Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almudaifer%2C+A+I">Abdullateef I. Almudaifer</a>, 
<a href="/search/cs?searchtype=author&query=O%60Leary%2C+T">Tobias O`Leary</a>, 
<a href="/search/cs?searchtype=author&query=Covington%2C+W">Whitney Covington</a>, 
<a href="/search/cs?searchtype=author&query=Hairston%2C+J">JaMor Hairston</a>, 
<a href="/search/cs?searchtype=author&query=Deitch%2C+Z">Zachary Deitch</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Ankit Anand</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+C+M">Caleb M. Carroll</a>, 
<a href="/search/cs?searchtype=author&query=Crisan%2C+E">Estera Crisan</a>, 
<a href="/search/cs?searchtype=author&query=Bradford%2C+W">William Bradford</a>, 
<a href="/search/cs?searchtype=author&query=Walter%2C+L">Lauren Walter</a>, 
<a href="/search/cs?searchtype=author&query=Ellen%2C+E">Eaton Ellen</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+S+S">Sue S. Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Osborne%2C+J+D">John D. Osborne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures, 6 tables. To be submitted to the Journal of Biomedical Semantics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Background: The semantics of entities extracted from a clinical text can be
dramatically altered by modifiers, including entity negation, uncertainty,
conditionality, severity, and subject. Existing models for determining
modifiers of clinical entities involve regular expression or features weights
that are trained independently for each modifier.
<br />Methods: We develop and evaluate a multi-task transformer architecture design
where modifiers are learned and predicted jointly using the publicly available
SemEval 2015 Task 14 corpus and a new Opioid Use Disorder (OUD) data set that
contains modifiers shared with SemEval as well as novel modifiers specific for
OUD. We evaluate the effectiveness of our multi-task learning approach versus
previously published systems and assess the feasibility of transfer learning
for clinical entity modifiers when only a portion of clinical modifiers are
shared.
<br />Results: Our approach achieved state-of-the-art results on the ShARe corpus
from SemEval 2015 Task 14, showing an increase of 1.1% on weighted accuracy,
1.7% on unweighted accuracy, and 10% on micro F1 scores.
<br />Conclusions: We show that learned weights from our shared model can be
effectively transferred to a new partially matched data set, validating the use
of transfer learning for clinical text modifiers
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15223" title="Abstract">arXiv:2401.15223</a> [<a href="/pdf/2401.15223" title="Download PDF">pdf</a>, <a href="/format/2401.15223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biological Valuation Map of Flanders: A Sentinel-2 Imagery Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingshi Li</a>, 
<a href="/search/cs?searchtype=author&query=Grujicic%2C+D">Dusan Grujicic</a>, 
<a href="/search/cs?searchtype=author&query=De+Saeger%2C+S">Steven De Saeger</a>, 
<a href="/search/cs?searchtype=author&query=Heremans%2C+S">Stien Heremans</a>, 
<a href="/search/cs?searchtype=author&query=Somers%2C+B">Ben Somers</a>, 
<a href="/search/cs?searchtype=author&query=Blaschko%2C+M+B">Matthew B. Blaschko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, machine learning has become crucial in remote sensing
analysis, particularly in the domain of Land-use/Land-cover (LULC). The synergy
of machine learning and satellite imagery analysis has demonstrated significant
productivity in this field, as evidenced by several studies. A notable
challenge within this area is the semantic segmentation mapping of land usage
over extensive territories, where the accessibility of accurate land-use data
and the reliability of ground truth land-use labels pose significant
difficulties. For example, providing a detailed and accurate pixel-wise labeled
dataset of the Flanders region, a first-level administrative division of
Belgium, can be particularly insightful. Yet there is a notable lack of
regulated, formalized datasets and workflows for such studies in many regions
globally. This paper introduces a comprehensive approach to addressing these
gaps. We present a densely labeled ground truth map of Flanders paired with
Sentinel-2 satellite imagery. Our methodology includes a formalized dataset
division and sampling method, utilizing the topographic map layout
'Kaartbladversnijdingen,' and a detailed semantic segmentation model training
pipeline. Preliminary benchmarking results are also provided to demonstrate the
efficacy of our approach.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15229" title="Abstract">arXiv:2401.15229</a> [<a href="/pdf/2401.15229" title="Download PDF">pdf</a>, <a href="/format/2401.15229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving AI Risk Management: A Maturity Model based on the NIST AI Risk  Management Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dotan%2C+R">Ravit Dotan</a>, 
<a href="/search/cs?searchtype=author&query=Blili-Hamelin%2C+B">Borhane Blili-Hamelin</a>, 
<a href="/search/cs?searchtype=author&query=Madhavan%2C+R">Ravi Madhavan</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+J">Jeanna Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Scarpino%2C+J">Joshua Scarpino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Researchers, government bodies, and organizations have been repeatedly
calling for a shift in the responsible AI community from general principles to
tangible and operationalizable practices in mitigating the potential
sociotechnical harms of AI. Frameworks like the NIST AI RMF embody an emerging
consensus on recommended practices in operationalizing sociotechnical harm
mitigation. However, private sector organizations currently lag far behind this
emerging consensus. Implementation is sporadic and selective at best. At worst,
it is ineffective and can risk serving as a misleading veneer of trustworthy
processes, providing an appearance of legitimacy to substantively harmful
practices. In this paper, we provide a foundation for a framework for
evaluating where organizations sit relative to the emerging consensus on
sociotechnical harm mitigation best practices: a flexible maturity model based
on the NIST AI RMF.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15232" title="Abstract">arXiv:2401.15232</a> [<a href="/pdf/2401.15232" title="Download PDF">pdf</a>, <a href="/format/2401.15232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Beginning Programmers and Code LLMs (Mis)read Each Other
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+S">Sydney Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Babe%2C+H+M">Hannah McLean Babe</a>, 
<a href="/search/cs?searchtype=author&query=Zi%2C+Y">Yangtian Zi</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C+J">Carolyn Jane Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+M+Q">Molly Q Feldman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conditionally Accepted to CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Generative AI models, specifically large language models (LLMs), have made
strides towards the long-standing goal of text-to-code generation. This
progress has invited numerous studies of user interaction. However, less is
known about the struggles and strategies of non-experts, for whom each step of
the text-to-code problem presents challenges: describing their intent in
natural language, evaluating the correctness of generated code, and editing
prompts when the generated code is incorrect. This paper presents a large-scale
controlled study of how 120 beginning coders across three academic institutions
approach writing and editing prompts. A novel experimental design allows us to
target specific steps in the text-to-code process and reveals that beginners
struggle with writing and editing prompts, even for problems at their skill
level and when correctness is automatically determined. Our mixed-methods
evaluation provides insight into student processes and perceptions with key
implications for non-expert Code LLM use within and outside of education.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15234" title="Abstract">arXiv:2401.15234</a> [<a href="/pdf/2401.15234" title="Download PDF">pdf</a>, <a href="/format/2401.15234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moving beyond Deletions: Program Simplification via Diverse Program  Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zezhong Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chengnian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S+H">Shin Hwei Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">To reduce the complexity of software, Developers manually simplify program
(known as developer-induced program simplification in this paper) to reduce its
code size yet preserving its functionality but manual simplification is
time-consuming and error-prone. To reduce manual effort, rule-based approaches
(e.g., refactoring) and deletion-based approaches (e.g., delta debugging) can
be potentially applied to automate developer-induced program simplification.
However, as there is little study on how developers simplify programs in
Open-source Software (OSS) projects, it is unclear whether these approaches can
be effectively used for developer-induced program simplification. Hence, we
present the first study of developer-induced program simplification in OSS
projects, focusing on the types of program transformations used, the
motivations behind simplifications, and the set of program transformations
covered by existing refactoring types. Our study of 382 pull requests from 296
projects reveals that there exist gaps in applying existing approaches for
automating developer-induced program simplification. and outlines the criteria
for designing automatic program simplification techniques. Inspired by our
study and to reduce the manual effort in developer-induced program
simplification, we propose SimpT5, a tool that can automatically produce
simplified programs (semantically-equivalent programs with reduced source lines
of code). SimpT5 is trained based on our collected dataset of 92,485 simplified
programs with two heuristics: (1) simplified line localization that encodes
lines changed in simplified programs, and (2)checkers that measure the quality
of generated programs. Our evaluation shows that SimpT5 are more effective than
prior approaches in automating developer-induced program simplification.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15236" title="Abstract">arXiv:2401.15236</a> [<a href="/pdf/2401.15236" title="Download PDF">pdf</a>, <a href="/format/2401.15236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Deep Learning for Efficient Visual Pose Estimation aboard  Ultra-low-power Nano-drones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Motetti%2C+B+A">Beatrice Alessandra Motetti</a>, 
<a href="/search/cs?searchtype=author&query=Crupi%2C+L">Luca Crupi</a>, 
<a href="/search/cs?searchtype=author&query=Elshaigi%2C+M+O+M+E">Mustafa Omer Mohammed Elamin Elshaigi</a>, 
<a href="/search/cs?searchtype=author&query=Risso%2C+M">Matteo Risso</a>, 
<a href="/search/cs?searchtype=author&query=Pagliari%2C+D+J">Daniele Jahier Pagliari</a>, 
<a href="/search/cs?searchtype=author&query=Palossi%2C+D">Daniele Palossi</a>, 
<a href="/search/cs?searchtype=author&query=Burrello%2C+A">Alessio Burrello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the 2024 Design, Automation and Test in Europe (DATE) conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sub-10cm diameter nano-drones are gaining momentum thanks to their
applicability in scenarios prevented to bigger flying drones, such as in narrow
environments and close to humans. However, their tiny form factor also brings
their major drawback: ultra-constrained memory and processors for the onboard
execution of their perception pipelines. Therefore, lightweight deep
learning-based approaches are becoming increasingly popular, stressing how
computational efficiency and energy-saving are paramount as they can make the
difference between a fully working closed-loop system and a failing one. In
this work, to maximize the exploitation of the ultra-limited resources aboard
nano-drones, we present a novel adaptive deep learning-based mechanism for the
efficient execution of a vision-based human pose estimation task. We leverage
two State-of-the-Art (SoA) convolutional neural networks (CNNs) with different
regression performance vs. computational costs trade-offs. By combining these
CNNs with three novel adaptation strategies based on the output's temporal
consistency and on auxiliary tasks to swap the CNN being executed proactively,
we present six different systems. On a real-world dataset and the actual
nano-drone hardware, our best-performing system, compared to executing only the
bigger and most accurate SoA model, shows 28% latency reduction while keeping
the same mean absolute error (MAE), 3% MAE reduction while being iso-latency,
and the absolute peak performance, i.e., 6% better than SoA model.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15238" title="Abstract">arXiv:2401.15238</a> [<a href="/pdf/2401.15238" title="Download PDF">pdf</a>, <a href="/format/2401.15238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning with Tabular Data: A Self-supervised Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vyas%2C+T+K">Tirth Kiranbhai Vyas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We have described a novel approach for training tabular data using the
TabTransformer model with self-supervised learning. Traditional machine
learning models for tabular data, such as GBDT are being widely used though our
paper examines the effectiveness of the TabTransformer which is a Transformer
based model optimised specifically for tabular data. The TabTransformer
captures intricate relationships and dependencies among features in tabular
data by leveraging the self-attention mechanism of Transformers. We have used a
self-supervised learning approach in this study, where the TabTransformer
learns from unlabelled data by creating surrogate supervised tasks, eliminating
the need for the labelled data. The aim is to find the most effective
TabTransformer model representation of categorical and numerical features. To
address the challenges faced during the construction of various input settings
into the Transformers. Furthermore, a comparative analysis is also been
conducted to examine performance of the TabTransformer model against baseline
models such as MLP and supervised TabTransformer.
<br />The research has presented with a novel approach by creating various variants
of TabTransformer model namely, Binned-TT, Vanilla-MLP-TT, MLP- based-TT which
has helped to increase the effective capturing of the underlying relationship
between various features of the tabular dataset by constructing optimal inputs.
And further we have employed a self-supervised learning approach in the form of
a masking-based unsupervised setting for tabular data. The findings shed light
on the best way to represent categorical and numerical features, emphasizing
the TabTransormer performance when compared to established machine learning
models and other self-supervised learning methods.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15239" title="Abstract">arXiv:2401.15239</a> [<a href="/pdf/2401.15239" title="Download PDF">pdf</a>, <a href="/format/2401.15239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEA-Defender: A Robust Watermark against Model Extraction Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+P">Peizhuo Lv</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hualong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiachen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Ruigang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shenchen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in IEEE Symposium on Security and Privacy 2024 (IEEE S&amp;P 2024), MAY 20-23, 2024, SAN FRANCISCO, CA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, numerous highly-valuable Deep Neural Networks (DNNs) have been
trained using deep learning algorithms. To protect the Intellectual Property
(IP) of the original owners over such DNN models, backdoor-based watermarks
have been extensively studied. However, most of such watermarks fail upon model
extraction attack, which utilizes input samples to query the target model and
obtains the corresponding outputs, thus training a substitute model using such
input-output pairs. In this paper, we propose a novel watermark to protect IP
of DNN models against model extraction, named MEA-Defender. In particular, we
obtain the watermark by combining two samples from two source classes in the
input domain and design a watermark loss function that makes the output domain
of the watermark within that of the main task samples. Since both the input
domain and the output domain of our watermark are indispensable parts of those
of the main task samples, the watermark will be extracted into the stolen model
along with the main task during model extraction. We conduct extensive
experiments on four model extraction attacks, using five datasets and six
models trained based on supervised learning and self-supervised learning
algorithms. The experimental results demonstrate that MEA-Defender is highly
robust against different model extraction attacks, and various watermark
removal/detection approaches.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15240" title="Abstract">arXiv:2401.15240</a> [<a href="/pdf/2401.15240" title="Download PDF">pdf</a>, <a href="/ps/2401.15240" title="Download PostScript">ps</a>, <a href="/format/2401.15240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Policy Optimization for Correlated Equilibrium in  General-Sum Markov Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haipeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chen-Yu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weiqiang Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AISTATS 2024 Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC)

</div>
<p class="mathjax">We study policy optimization algorithms for computing correlated equilibria
in multi-player general-sum Markov Games. Previous results achieve
$O(T^{-1/2})$ convergence rate to a correlated equilibrium and an accelerated
$O(T^{-3/4})$ convergence rate to the weaker notion of coarse correlated
equilibrium. In this paper, we improve both results significantly by providing
an uncoupled policy optimization algorithm that attains a near-optimal
$\tilde{O}(T^{-1})$ convergence rate for computing a correlated equilibrium.
Our algorithm is constructed by combining two main elements (i) smooth value
updates and (ii) the optimistic-follow-the-regularized-leader algorithm with
the log barrier regularizer.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15241" title="Abstract">arXiv:2401.15241</a> [<a href="/pdf/2401.15241" title="Download PDF">pdf</a>, <a href="/format/2401.15241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlearning Reveals the Influential Training Data of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isonuma%2C+M">Masaru Isonuma</a>, 
<a href="/search/cs?searchtype=author&query=Titov%2C+I">Ivan Titov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In order to enhance the performance of language models while mitigating the
risks of generating harmful content, it is crucial to identify which training
dataset affects the model's outputs. Ideally, we can measure the influence of
each dataset by removing it from training; however, it is prohibitively
expensive to retrain a model multiple times. This paper presents UnTrac, which
estimates the influence of a training dataset by unlearning it from the trained
model. UnTrac is extremely simple; each training dataset is unlearned by
gradient ascent, and we evaluate how much the model's predictions change after
unlearning. We empirically examine if our methods can assess the influence of
pretraining datasets on generating toxic, biased, and untruthful content.
Experimental results demonstrate that our method estimates their influence much
more accurately than existing methods while requiring neither excessive memory
space nor multiple model checkpoints.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15245" title="Abstract">arXiv:2401.15245</a> [<a href="/pdf/2401.15245" title="Download PDF">pdf</a>, <a href="/format/2401.15245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenPluSSS: A Genetic Algorithm Based Plugin for Measured Subsurface  Scattering Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1r%C4%B1m%2C+B">Bar&#x131;&#x15f; Y&#x131;ld&#x131;r&#x131;m</a>, 
<a href="/search/cs?searchtype=author&query=Kurt%2C+M">Murat Kurt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This paper presents a plugin that adds a representation of homogeneous and
heterogeneous, optically thick, translucent materials on the Blender 3D
modeling tool. The working principle of this plugin is based on a combination
of Genetic Algorithm (GA) and Singular Value Decomposition (SVD)-based
subsurface scattering method (GenSSS). The proposed plugin has been implemented
using Mitsuba renderer, which is an open source rendering software. The
proposed plugin has been validated on measured subsurface scattering data. It's
shown that the proposed plugin visualizes homogeneous and heterogeneous
subsurface scattering effects, accurately, compactly and computationally
efficiently.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15246" title="Abstract">arXiv:2401.15246</a> [<a href="/pdf/2401.15246" title="Download PDF">pdf</a>, <a href="/format/2401.15246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Differentially Private Ad Prediction Models with Semi-Sensitive  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chua%2C+L">Lynn Chua</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qiliang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ghazi%2C+B">Badih Ghazi</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+C">Charlie Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+P">Pritish Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Krichene%2C+W">Walid Krichene</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Ravi Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Manurangsi%2C+P">Pasin Manurangsi</a>, 
<a href="/search/cs?searchtype=author&query=Narra%2C+K+G">Krishna Giri Narra</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Amer Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Varadarajan%2C+A">Avinash Varadarajan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chiyuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Motivated by problems arising in digital advertising, we introduce the task
of training differentially private (DP) machine learning models with
semi-sensitive features. In this setting, a subset of the features is known to
the attacker (and thus need not be protected) while the remaining features as
well as the label are unknown to the attacker and should be protected by the DP
guarantee. This task interpolates between training the model with full DP
(where the label and all features should be protected) or with label DP (where
all the features are considered known, and only the label should be protected).
We present a new algorithm for training DP models with semi-sensitive features.
Through an empirical evaluation on real ads datasets, we demonstrate that our
algorithm surpasses in utility the baselines of (i) DP stochastic gradient
descent (DP-SGD) run on all features (known and unknown), and (ii) a label DP
algorithm run only on the known features (while discarding the unknown ones).
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15248" title="Abstract">arXiv:2401.15248</a> [<a href="/pdf/2401.15248" title="Download PDF">pdf</a>, <a href="/format/2401.15248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Representations via Adversarial Training in Pre-Training: A  Theoretical Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yue Xing</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaofeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qifan Song</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Belinda Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Guang Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AISTATS2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Pre-training is known to generate universal representations for downstream
tasks in large-scale deep learning such as large language models. Existing
literature, e.g., \cite{kim2020adversarial}, empirically observe that the
downstream tasks can inherit the adversarial robustness of the pre-trained
model. We provide theoretical justifications for this robustness inheritance
phenomenon. Our theoretical results reveal that feature purification plays an
important role in connecting the adversarial robustness of the pre-trained
model and the downstream tasks in two-layer neural networks. Specifically, we
show that (i) with adversarial training, each hidden node tends to pick only
one (or a few) feature; (ii) without adversarial training, the hidden nodes can
be vulnerable to attacks. This observation is valid for both supervised
pre-training and contrastive learning. With purified nodes, it turns out that
clean training is enough to achieve adversarial robustness in downstream tasks.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15258" title="Abstract">arXiv:2401.15258</a> [<a href="/pdf/2401.15258" title="Download PDF">pdf</a>, <a href="/ps/2401.15258" title="Download PostScript">ps</a>, <a href="/format/2401.15258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundations of Substructural Dependent Type Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aberl%C3%A9%2C+C+B">C.B. Aberl&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL); Category Theory (math.CT)

</div>
<p class="mathjax">This paper presents preliminary work on a general system for integrating
dependent types into substructural type systems such as linear logic and linear
type theory. Prior work on this front has generally managed to deliver type
systems possessing either syntax or semantics inclusive of certain practical
applications, but has struggled to combine these all in one and the same
system. Toward resolving this difficulty, I propose a novel categorical
interpretation of substructural dependent types, analogous to the use of
monoidal categories as models of linear and ordered logic, that encompasses a
wide class of mathematical and computational examples. On this basis, I develop
a general framework for substructural dependent type theories, and proceed to
prove some essential metatheoretic properties thereof. As an application of
this framework, I show how it can be used to construct a type theory that
satisfactorily addresses the problem of effectively representing cut
admissibility for linear sequent calculus in a logical framework.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15261" title="Abstract">arXiv:2401.15261</a> [<a href="/pdf/2401.15261" title="Download PDF">pdf</a>, <a href="/format/2401.15261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vanishing-Point-Guided Video Semantic Segmentation of Driving Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Diandian Guo</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tongyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sakaridis%2C+C">Christos Sakaridis</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The estimation of implicit cross-frame correspondences and the high
computational cost have long been major challenges in video semantic
segmentation (VSS) for driving scenes. Prior works utilize keyframes, feature
propagation, or cross-frame attention to address these issues. By contrast, we
are the first to harness vanishing point (VP) priors for more effective
segmentation. Intuitively, objects near VPs (i.e., away from the vehicle) are
less discernible. Moreover, they tend to move radially away from the VP over
time in the usual case of a forward-facing camera, a straight road, and linear
forward motion of the vehicle. Our novel, efficient network for VSS, named
VPSeg, incorporates two modules that utilize exactly this pair of static and
dynamic VP priors: sparse-to-dense feature mining (DenseVP) and VP-guided
motion fusion (MotionVP). MotionVP employs VP-guided motion estimation to
establish explicit correspondences across frames and help attend to the most
relevant features from neighboring frames, while DenseVP enhances weak dynamic
features in distant regions around VPs. These modules operate within a
context-detail framework, which separates contextual features from
high-resolution local features at different input resolutions to reduce
computational costs. Contextual and local features are integrated through
contextualized motion attention (CMA) for the final prediction. Extensive
experiments on two popular driving segmentation benchmarks, Cityscapes and
ACDC, demonstrate that VPSeg outperforms previous SOTA methods, with only
modest computational overhead.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15265" title="Abstract">arXiv:2401.15265</a> [<a href="/pdf/2401.15265" title="Download PDF">pdf</a>, <a href="/ps/2401.15265" title="Download PostScript">ps</a>, <a href="/format/2401.15265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A method for constructing quaternary Hermitian self-dual codes and an  application to quantum codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harada%2C+M">Masaaki Harada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">We introduce quaternary modified four $\mu$-circulant codes as a modification
of four circulant codes. We give basic properties of quaternary modified four
$\mu$-circulant Hermitian self-dual codes. We also construct quaternary
modified four $\mu$-circulant Hermitian self-dual codes having large minimum
weights. Two quaternary Hermitian self-dual $[56,28,16]$ codes are constructed
for the first time. These codes improve the previously known lower bound on the
largest minimum weight among all quaternary (linear) $[56,28]$ codes. In
addition, these codes imply the existence of a quantum $[[56,0,16]]$ code.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15266" title="Abstract">arXiv:2401.15266</a> [<a href="/pdf/2401.15266" title="Download PDF">pdf</a>, <a href="/ps/2401.15266" title="Download PostScript">ps</a>, <a href="/format/2401.15266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-based instance segmentation models for the automation of masonry  crack detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zehao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lovell%2C+L">Lucy Lovell</a>, 
<a href="/search/cs?searchtype=author&query=Faramarzi%2C+A">Asaad Faramarzi</a>, 
<a href="/search/cs?searchtype=author&query=Ninic%2C+J">Jelena Ninic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automating visual inspection for capturing defects based on civil structures
appearance is crucial due to its currently labour-intensive and time-consuming
nature. An important aspect of automated inspection is image acquisition, which
is rapid and cost-effective considering the pervasive developments in both
software and hardware computing in recent years. Previous studies largely
focused on concrete and asphalt, with less attention to masonry cracks. The
latter also lacks publicly available datasets. In this paper, we first present
a corresponding data set for instance segmentation with 1,300 annotated images
(640 pixels x 640 pixels), named as MCrack1300, covering bricks, broken bricks,
and cracks. We then test several leading algorithms for benchmarking, including
the latest large-scale model, the prompt-based Segment Anything Model (SAM). We
fine-tune the encoder using Low-Rank Adaptation (LoRA) and proposed two novel
methods for automation of SAM execution. The first method involves abandoning
the prompt encoder and connecting the SAM encoder to other decoders, while the
second method introduces a learnable self-generating prompter. In order to
ensure the seamless integration of the two proposed methods with SAM encoder
section, we redesign the feature extractor. Both proposed methods exceed
state-of-the-art performance, surpassing the best benchmark by approximately 3%
for all classes and around 6% for cracks specifically. Based on successful
detection, we propose a method based on a monocular camera and the Hough Line
Transform to automatically transform images into orthographic projection maps.
By incorporating known real sizes of brick units, we accurately estimate crack
dimensions, with the results differing by less than 10% from those obtained by
laser scanning. Overall, we address important research gaps in automated
masonry crack detection and size estimation.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15268" title="Abstract">arXiv:2401.15268</a> [<a href="/pdf/2401.15268" title="Download PDF">pdf</a>, <a href="/format/2401.15268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Stable Preferences for Stakeholder-aligned Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheraz%2C+H">Haleema Sheraz</a>, 
<a href="/search/cs?searchtype=author&query=Kremer%2C+S+C">Stefan C. Kremer</a>, 
<a href="/search/cs?searchtype=author&query=Skorburg%2C+J+A">Joshua August Skorburg</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+G">Graham Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Sinnott-Armstrong%2C+W">Walter Sinnott-Armstrong</a>, 
<a href="/search/cs?searchtype=author&query=Boerstler%2C+K">Kyle Boerstler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure, 1 table, 2 appendices, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In response to the pressing challenge of kidney allocation, characterized by
growing demands for organs, this research sets out to develop a data-driven
solution to this problem, which also incorporates stakeholder values. The
primary objective of this study is to create a method for learning both
individual and group-level preferences pertaining to kidney allocations.
Drawing upon data from the 'Pairwise Kidney Patient Online Survey.' Leveraging
two distinct datasets and evaluating across three levels - Individual, Group
and Stability - we employ machine learning classifiers assessed through several
metrics. The Individual level model predicts individual participant
preferences, the Group level model aggregates preferences across participants,
and the Stability level model, an extension of the Group level, evaluates the
stability of these preferences over time. By incorporating stakeholder
preferences into the kidney allocation process, we aspire to advance the
ethical dimensions of organ transplantation, contributing to more transparent
and equitable practices while promoting the integration of moral values into
algorithmic decision-making.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15269" title="Abstract">arXiv:2401.15269</a> [<a href="/pdf/2401.15269" title="Download PDF">pdf</a>, <a href="/format/2401.15269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Medical Reasoning through Retrieval and Self-Reflection with  Retrieval-Augmented Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+M">Minbyul Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+J">Jiwoong Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+M">Mujeen Sung</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jaewoo Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Recent proprietary large language models (LLMs), such as GPT-4, have achieved
a milestone in tackling diverse challenges in the biomedical domain, ranging
from multiple-choice questions to long-form generations. To address challenges
that still cannot be handled with the encoded knowledge of LLMs, various
retrieval-augmented generation (RAG) methods have been developed by searching
documents from the knowledge corpus and appending them unconditionally or
selectively to the input of LLMs for generation. However, when applying
existing methods to different domain-specific problems, poor generalization
becomes apparent, leading to fetching incorrect documents or making inaccurate
judgments. In this paper, we introduce Self-BioRAG, a framework reliable for
biomedical text that specializes in generating explanations, retrieving
domain-specific documents, and self-reflecting generated responses. We utilize
84k filtered biomedical instruction sets to train Self-BioRAG that can assess
its generated explanations with customized reflective tokens. Our work proves
that domain-specific components, such as a retriever, domain-related document
corpus, and instruction sets are necessary for adhering to domain-related
instructions. Using three major medical question-answering benchmark datasets,
experimental results of Self-BioRAG demonstrate significant performance gains
by achieving a 7.2% absolute improvement on average over the state-of-the-art
open-foundation model with a parameter size of 7B or less. Overall, we analyze
that Self-BioRAG finds the clues in the question, retrieves relevant documents
if needed, and understands how to answer with information from retrieved
documents and encoded knowledge as a medical expert does. We release our data
and code for training our framework components and model weights (7B and 13B)
to enhance capabilities in biomedical and clinical domains.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15270" title="Abstract">arXiv:2401.15270</a> [<a href="/pdf/2401.15270" title="Download PDF">pdf</a>, <a href="/format/2401.15270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimFair: Physics-Guided Fairness-Aware Learning with Simulation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yiqun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhili Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaowei Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhe Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+A">Aolin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Fairness-awareness has emerged as an essential building block for the
responsible use of artificial intelligence in real applications. In many cases,
inequity in performance is due to the change in distribution over different
regions. While techniques have been developed to improve the transferability of
fairness, a solution to the problem is not always feasible with no samples from
the new regions, which is a bottleneck for pure data-driven attempts.
Fortunately, physics-based mechanistic models have been studied for many
problems with major social impacts. We propose SimFair, a physics-guided
fairness-aware learning framework, which bridges the data limitation by
integrating physical-rule-based simulation and inverse modeling into the
training design. Using temperature prediction as an example, we demonstrate the
effectiveness of the proposed SimFair in fairness preservation.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15273" title="Abstract">arXiv:2401.15273</a> [<a href="/pdf/2401.15273" title="Download PDF">pdf</a>, <a href="/format/2401.15273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Han Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+A">Aritra Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+J">James Anderson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">Federated reinforcement learning (FRL) has emerged as a promising paradigm
for reducing the sample complexity of reinforcement learning tasks by
exploiting information from different agents. However, when each agent
interacts with a potentially different environment, little to nothing is known
theoretically about the non-asymptotic performance of FRL algorithms. The lack
of such results can be attributed to various technical challenges and their
intricate interplay: Markovian sampling, linear function approximation,
multiple local updates to save communication, heterogeneity in the reward
functions and transition kernels of the agents' MDPs, and continuous
state-action spaces. Moreover, in the on-policy setting, the behavior policies
vary with time, further complicating the analysis. In response, we introduce
FedSARSA, a novel federated on-policy reinforcement learning scheme, equipped
with linear function approximation, to address these challenges and provide a
comprehensive finite-time error analysis. Notably, we establish that FedSARSA
converges to a policy that is near-optimal for all agents, with the extent of
near-optimality proportional to the level of heterogeneity. Furthermore, we
prove that FedSARSA leverages agent collaboration to enable linear speedups as
the number of agents increases, which holds for both fixed and adaptive
step-size configurations.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15275" title="Abstract">arXiv:2401.15275</a> [<a href="/pdf/2401.15275" title="Download PDF">pdf</a>, <a href="/format/2401.15275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Transformer Architecture for Continual Learning of Multimodal  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuliang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Rostami%2C+M">Mohammad Rostami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformer neural networks are increasingly replacing prior architectures in
a wide range of applications in different data modalities. The increasing size
and computational demands of fine-tuning large pre-trained transformer neural
networks pose significant challenges for the widespread adoption of these
models for applications that demand on-edge computing. To tackle this
challenge, continual learning (CL) emerges as a solution by facilitating the
transfer of knowledge across tasks that arrive sequentially for an autonomously
learning agent. However, current CL methods mainly focus on learning tasks that
are exclusively vision-based or language-based. We propose a transformer-based
CL framework focusing on learning tasks that involve both vision and language,
known as Vision-and-Language (VaL) tasks. Due to the success of transformers in
other modalities, our architecture has the potential to be used in multimodal
learning settings. In our framework, we benefit from introducing extra
parameters to a base transformer to specialize the network for each task. As a
result, we enable dynamic model expansion to learn several tasks in a sequence.
We also use knowledge distillation to benefit from relevant past experiences to
learn the current task more efficiently. Our proposed method, Task Attentive
Multimodal Continual Learning (TAM-CL), allows for the exchange of information
between tasks while mitigating the problem of catastrophic forgetting. Notably,
our approach is scalable, incurring minimal memory and time overhead. TAM-CL
achieves state-of-the-art (SOTA) performance on challenging multimodal tasks
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15278" title="Abstract">arXiv:2401.15278</a> [<a href="/pdf/2401.15278" title="Download PDF">pdf</a>, <a href="/format/2401.15278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Data-Driven Adaptive Control for Unknown Linear Time-Varying  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shenyu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+K">Kaiwen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Eising%2C+J">Jaap Eising</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report for the conference paper in 62nd IEEE CDC
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> S. Liu, K. Chen and J. Eising, "Online Data-Driven Adaptive
  Control for Unknown Linear Time-Varying Systems," 2023 62nd IEEE Conference
  on Decision and Control (CDC), Singapore, Singapore, 2023, pp. 8775-8780
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a novel online data-driven adaptive control for unknown
linear time-varying systems. Initialized with an empirical feedback gain, the
algorithm periodically updates this gain based on the data collected over a
short time window before each update. Meanwhile, the stability of the
closed-loop system is analyzed in detail, which shows that under some mild
assumptions, the proposed online data-driven adaptive control scheme can
guarantee practical global exponential stability. Finally, the proposed
algorithm is demonstrated by numerical simulations and its performance is
compared with other control algorithms for unknown linear time-varying systems.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15279" title="Abstract">arXiv:2401.15279</a> [<a href="/pdf/2401.15279" title="Download PDF">pdf</a>, <a href="/format/2401.15279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FabHacks: Transform Everyday Objects into Functional Fixtures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yuxuan Mei</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+B">Benjamin Jones</a>, 
<a href="/search/cs?searchtype=author&query=Cascaval%2C+D">Dan Cascaval</a>, 
<a href="/search/cs?searchtype=author&query=Mankoff%2C+J">Jennifer Mankoff</a>, 
<a href="/search/cs?searchtype=author&query=Vouga%2C+E">Etienne Vouga</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+A">Adriana Schulz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Storage, organizing, and decorating are an important part of home design.
While one can buy commercial items for many of these tasks, this can be costly,
and re-use is more sustainable. An alternative is a "home hack", a functional
assembly that can be constructed from existing household items. However, coming
up with such hacks requires combining objects to make a physically valid
design, which might be difficult to test if they are large, require nailing or
screwing something to the wall, or the designer has mobility limitations. In
this work, we present a design and visualization system for creating workable
functional assemblies, FabHacks, which is based on a solver-aided
domain-specific language (S-DSL) FabHaL. By analyzing existing home hacks
shared online, we create a design abstraction for connecting household items
using predefined types of connections. We provide a UI for FabHaL that can be
used to design assemblies that fulfill a given specification. Our system
leverages a physics-based solver that takes an assembly design and finds its
expected physical configuration. Our validation includes a user study showing
that users can create assemblies successfully using our UI and explore a range
of designs.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15280" title="Abstract">arXiv:2401.15280</a> [<a href="/pdf/2401.15280" title="Download PDF">pdf</a>, <a href="/ps/2401.15280" title="Download PostScript">ps</a>, <a href="/format/2401.15280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytical Framework for Effective Degrees of Freedom in Near-Field  XL-MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+W">Wenhui Yi</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 11 figures. This paper has been submitted to IEEE journal for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we develop an effective degrees of freedom (EDoF) performance
analysis framework specifically tailored for near-field XL-MIMO systems. We
explore five representative distinct XL-MIMO hardware designs, including
uniform planar array (UPA)-based with point antennas, two-dimensional (2D)
continuous aperture (CAP) plane-based, UPA-based with patch antennas, uniform
linear array (ULA)-based, and one-dimensional (1D) CAP line segment-based
XL-MIMO systems. Our analysis encompasses two near-field channel models: the
scalar and dyadic Green's function-based channel models. More importantly, when
applying the scalar Green's function-based channel, we derive EDoF expressions
in the closed-form, characterizing the impacts of the physical size of the
transceiver, the transmitting distance, and the carrier frequency. In our
numerical results, we evaluate and compare the EDoF performance across all
examined XL-MIMO designs, confirming the accuracy of our proposed closed-form
expressions. Furthermore, we observe that with an increasing number of
antennas, the EDoF performance for both UPA-based and ULA-based systems
approaches that of 2D CAP plane and 1D CAP line segment-based systems,
respectively. Moreover, we unveil that the EDoF performance for near-field
XL-MIMO systems is predominantly determined by the array aperture size rather
than the sheer number of antennas.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15282" title="Abstract">arXiv:2401.15282</a> [<a href="/pdf/2401.15282" title="Download PDF">pdf</a>, <a href="/format/2401.15282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GEM: Boost Simple Network for Glass Surface Segmentation via Segment  Anything Model and Data Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jing Hao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Moyun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+K+F">Kuo Feng Hung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting glass regions is a challenging task due to the ambiguity of their
transparency and reflection properties. These transparent glasses share the
visual appearance of both transmitted arbitrary background scenes and reflected
objects, thus having no fixed patterns.Recent visual foundation models, which
are trained on vast amounts of data, have manifested stunning performance in
terms of image perception and image generation. To segment glass surfaces with
higher accuracy, we make full use of two visual foundation models: Segment
Anything (SAM) and Stable Diffusion.Specifically, we devise a simple glass
surface segmentor named GEM, which only consists of a SAM backbone, a simple
feature pyramid, a discerning query selection module, and a mask decoder. The
discerning query selection can adaptively identify glass surface features,
assigning them as initialized queries in the mask decoder. We also propose a
Synthetic but photorealistic large-scale Glass Surface Detection dataset dubbed
S-GSD via diffusion model with four different scales, which contain 1x, 5x,
10x, and 20x of the original real data size. This dataset is a feasible source
for transfer learning. The scale of synthetic data has positive impacts on
transfer learning, while the improvement will gradually saturate as the amount
of data increases. Extensive experiments demonstrate that GEM achieves a new
state-of-the-art on the GSD-S validation set (IoU +2.1%). Codes and datasets
are available at: https://github.com/isbrycee/GEM-Glass-Segmentor.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15284" title="Abstract">arXiv:2401.15284</a> [<a href="/pdf/2401.15284" title="Download PDF">pdf</a>, <a href="/ps/2401.15284" title="Download PostScript">ps</a>, <a href="/format/2401.15284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building ethical guidelines for generative AI in scientific research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhicheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative artificial intelligence tools like large language models are
rapidly transforming academic research and real world applications. However,
discussions on ethical guidelines for generative AI in science remain
fragmented, underscoring the urgent need for consensus based standards. This
paper offers an initial framework by developing analyses and mitigation
strategies across five key themes: understanding model limitations regarding
truthfulness and bias; respecting privacy, confidentiality, and copyright;
avoiding plagiarism and policy violations when incorporating model output;
ensuring applications provide overall benefit; and using AI transparently and
reproducibly. Common scenarios are outlined to demonstrate potential ethical
violations. We argue that global consensus coupled with professional training
and reasonable enforcement are critical to promoting the benefits of AI while
safeguarding research integrity.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15285" title="Abstract">arXiv:2401.15285</a> [<a href="/pdf/2401.15285" title="Download PDF">pdf</a>, <a href="/ps/2401.15285" title="Download PostScript">ps</a>, <a href="/format/2401.15285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ransomware threat mitigation through network traffic analysis and  machine learning techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrban%2C+A">Ali Mehrban</a>, 
<a href="/search/cs?searchtype=author&query=Geransayeh%2C+S+K">Shirin Karimi Geransayeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, there has been a noticeable increase in cyberattacks using
ransomware. Attackers use this malicious software to break into networks and
harm computer systems. This has caused significant and lasting damage to
various organizations, including government, private companies, and regular
users. These attacks often lead to the loss or exposure of sensitive
information, disruptions in normal operations, and persistent vulnerabilities.
This paper focuses on a method for recognizing and identifying ransomware in
computer networks. The approach relies on using machine learning algorithms and
analyzing the patterns of network traffic. By collecting and studying this
traffic, and then applying machine learning models, we can accurately identify
and detect ransomware. The results of implementing this method show that
machine learning algorithms can effectively pinpoint ransomware based on
network traffic, achieving high levels of precision and accuracy.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15287" title="Abstract">arXiv:2401.15287</a> [<a href="/pdf/2401.15287" title="Download PDF">pdf</a>, <a href="/format/2401.15287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of Tao General Difference in Discrete Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Linmi Tao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Donglai Tao</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+W">Wu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Feilong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jingmao Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is the application part of the paper "Tao General Differential and Difference: Theory and Application". The theory part of the paper is renamed as "A Theory of General Difference in Continuous and Discrete Domain", which is Arxived in <a href="/abs/2305.08098">arXiv:2305.08098v2</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Discrete Mathematics (cs.DM); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Numerical difference computation is one of the cores and indispensable in the
modern digital era. Tao general difference (TGD) is a novel theory and approach
to difference computation for discrete sequences and arrays in multidimensional
space. Built on the solid theoretical foundation of the general difference in a
finite interval, the TGD operators demonstrate exceptional signal processing
capabilities in real-world applications. A novel smoothness property of a
sequence is defined on the first- and second TGD. This property is used to
denoise one-dimensional signals, where the noise is the non-smooth points in
the sequence. Meanwhile, the center of the gradient in a finite interval can be
accurately location via TGD calculation. This solves a traditional challenge in
computer vision, which is the precise localization of image edges with noise
robustness. Furthermore, the power of TGD operators extends to spatio-temporal
edge detection in three-dimensional arrays, enabling the identification of
kinetic edges in video data. These diverse applications highlight the
properties of TGD in discrete domain and the significant promise of TGD for the
computation across signal processing, image analysis, and video analytic.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15288" title="Abstract">arXiv:2401.15288</a> [<a href="/pdf/2401.15288" title="Download PDF">pdf</a>, <a href="/ps/2401.15288" title="Download PostScript">ps</a>, <a href="/format/2401.15288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAC: Leveraging Spatio-Temporal Data Associations For Efficient  Cross-Camera Streaming and Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vakhniuk%2C+V">Volodymyr Vakhniuk</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Ayush Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Ragini Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">We propose an efficient cross-cameras surveillance system called,STAC, that
leverages spatio-temporal associations between multiple cameras to provide
real-time analytics and inference under constrained network environments. STAC
is built using the proposed omni-scale feature learning people reidentification
(reid) algorithm that allows accurate detection, tracking and re-identification
of people across cameras using the spatio-temporal characteristics of video
frames. We integrate STAC with frame filtering and state-of-the-art compression
for streaming technique (that is, ffmpeg libx264 codec) to remove redundant
information from cross-camera frames. This helps in optimizing the cost of
video transmission as well as compute/processing, while maintaining high
accuracy for real-time query inference. The introduction of AICity Challenge
2023 Data [1] by NVIDIA has allowed exploration of systems utilizing
multi-camera people tracking algorithms. We evaluate the performance of STAC
using this dataset to measure the accuracy metrics and inference rate for reid.
Additionally, we quantify the reduction in video streams achieved through frame
filtering and compression using FFmpeg compared to the raw camera streams. For
completeness, we make available our repository to reproduce the results,
available at https://github.com/VolodymyrVakhniuk/CS444_Final_Project.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15289" title="Abstract">arXiv:2401.15289</a> [<a href="/pdf/2401.15289" title="Download PDF">pdf</a>, <a href="/format/2401.15289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where&#x27;s the &quot;up&quot;?! A Comprehensive (bottom-up) Study on the Security of  Arm Cortex-M Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zheyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+S">Sandro Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+L">Le Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiqiang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hongxing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziming Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Arm Cortex-M processors are the most widely used 32-bit microcontrollers
among embedded and Internetof-Things devices. Despite the widespread usage,
there has been little effort in summarizing their hardware security features,
characterizing the limitations and vulnerabilities of their hardware and
software stack, and systematizing the research on securing these systems. The
goals and contributions of this paper are multi-fold. First, we analyze the
hardware security limitations and issues of Cortex-M systems. Second, we
conducted a deep study of the software stack designed for Cortex-M and revealed
its limitations, which is accompanied by an empirical analysis of 1,797
real-world firmware from seven hardware vendors. Third, we categorize the
reported bugs in Cortex-M software systems. Finally, we systematize the efforts
that aim at securing Cortex-M systems and evaluate them in terms of the
protections they offer, run-time performance, required hardware features, etc.
Based on the insights, we develop a set of recommendations for the research
community and MCU software developers.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15290" title="Abstract">arXiv:2401.15290</a> [<a href="/pdf/2401.15290" title="Download PDF">pdf</a>, <a href="/format/2401.15290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking with MIMIC-IV, an irregular, spare clinical time series  dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bui%2C+H">Hung Bui</a>, 
<a href="/search/cs?searchtype=author&query=Warrier%2C+H">Harikrishna Warrier</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+Y">Yogesh Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Electronic health record (EHR) is more and more popular, and it comes with
applying machine learning solutions to resolve various problems in the domain.
This growing research area also raises the need for EHRs accessibility. Medical
Information Mart for Intensive Care (MIMIC) dataset is a popular, public, and
free EHR dataset in a raw format that has been used in numerous studies.
However, despite of its popularity, it is lacking benchmarking work, especially
with recent state of the art works in the field of deep learning with
time-series tabular data. The aim of this work is to fill this lack by
providing a benchmark for latest version of MIMIC dataset, MIMIC-IV. We also
give a detailed literature survey about studies that has been already done for
MIIMIC-III.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15291" title="Abstract">arXiv:2401.15291</a> [<a href="/pdf/2401.15291" title="Download PDF">pdf</a>, <a href="/ps/2401.15291" title="Download PostScript">ps</a>, <a href="/format/2401.15291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Construction of Robust Gray Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fathollahi%2C+D">Dorsa Fathollahi</a>, 
<a href="/search/cs?searchtype=author&query=Wootters%2C+M">Mary Wootters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">A robust Gray code, formally introduced by (Lolck and Pagh, SODA 2024), is a
Gray code that additionally has the property that, given a noisy version of the
encoding of an integer $j$, it is possible to reconstruct $\hat{j}$ so that $|j
- \hat{j}|$ is small with high probability. That work presented a
transformation that transforms a binary code $C$ of rate $R$ to a robust Gray
code with rate $\Omega(R)$, where the constant in the $\Omega(\cdot)$ can be at
most $1/4$. We improve upon their construction by presenting a transformation
from a (linear) binary code $C$ to a robust Gray code with similar robustness
guarantees, but with rate that can approach $R/2$.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15292" title="Abstract">arXiv:2401.15292</a> [<a href="/pdf/2401.15292" title="Download PDF">pdf</a>, <a href="/format/2401.15292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Block sparse regularization under arbitrary linear transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Furuhashi%2C+T">Takanobu Furuhashi</a>, 
<a href="/search/cs?searchtype=author&query=Hontani%2C+H">Hidekata Hontani</a>, 
<a href="/search/cs?searchtype=author&query=Yokota%2C+T">Tatsuya Yokota</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We propose a convex signal reconstruction method for block sparsity under
arbitrary linear transform with unknown block structure. The proposed method is
a generalization of the existing method LOP-$\ell_2$/$\ell_1$ and can
reconstruct signals with block sparsity under non-invertible transforms, unlike
LOP-$\ell_2$/$\ell_1$. Our work broadens the scope of block sparse
regularization, enabling more versatile and powerful applications across
various signal processing domains. We derive an iterative algorithm for solving
proposed method and provide conditions for its convergence to the optimal
solution. Numerical experiments demonstrate the effectiveness of the proposed
method.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15293" title="Abstract">arXiv:2401.15293</a> [<a href="/pdf/2401.15293" title="Download PDF">pdf</a>, <a href="/format/2401.15293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkipViT: Speeding Up Vision Transformers with a Token-Level Skip  Connection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ataiefard%2C+F">Foozhan Ataiefard</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+W">Walid Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Hajimolahoseini%2C+H">Habib Hajimolahoseini</a>, 
<a href="/search/cs?searchtype=author&query=Asani%2C+S">Saina Asani</a>, 
<a href="/search/cs?searchtype=author&query=Javadi%2C+F">Farnoosh Javadi</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+M">Mohammad Hassanpour</a>, 
<a href="/search/cs?searchtype=author&query=Awad%2C+O+M">Omar Mohamed Awad</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+A">Austin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kangling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision transformers are known to be more computationally and data-intensive
than CNN models. These transformer models such as ViT, require all the input
image tokens to learn the relationship among them. However, many of these
tokens are not informative and may contain irrelevant information such as
unrelated background or unimportant scenery. These tokens are overlooked by the
multi-head self-attention (MHSA), resulting in many redundant and unnecessary
computations in MHSA and the feed-forward network (FFN). In this work, we
propose a method to optimize the amount of unnecessary interactions between
unimportant tokens by separating and sending them through a different low-cost
computational path. Our method does not add any parameters to the ViT model and
aims to find the best trade-off between training throughput and achieving a 0%
loss in the Top-1 accuracy of the final model. Our experimental results on
training ViT-small from scratch show that SkipViT is capable of effectively
dropping 55% of the tokens while gaining more than 13% training throughput and
maintaining classification accuracy at the level of the baseline model on
Huawei Ascend910A.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15294" title="Abstract">arXiv:2401.15294</a> [<a href="/pdf/2401.15294" title="Download PDF">pdf</a>, <a href="/ps/2401.15294" title="Download PostScript">ps</a>, <a href="/format/2401.15294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integral Operator Approaches for Scattered Data Fitting on Spheres
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+S">Shao-Bo Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper focuses on scattered data fitting problems on spheres. We study
the approximation performance of a class of weighted spectral filter
algorithms, including Tikhonov regularization, Landaweber iteration, spectral
cut-off, and iterated Tikhonov, in fitting noisy data with possibly unbounded
random noise. For the analysis, we develop an integral operator approach that
can be regarded as an extension of the widely used sampling inequality approach
and norming set method in the community of scattered data fitting. After
providing an equivalence between the operator differences and quadrature rules,
we succeed in deriving optimal Sobolev-type error estimates of weighted
spectral filter algorithms. Our derived error estimates do not suffer from the
saturation phenomenon for Tikhonov regularization in the literature,
native-space-barrier for existing error analysis and adapts to different
embedding spaces. We also propose a divide-and-conquer scheme to equip weighted
spectral filter algorithms to reduce their computational burden and present the
optimal approximation error bounds.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15295" title="Abstract">arXiv:2401.15295</a> [<a href="/pdf/2401.15295" title="Download PDF">pdf</a>, <a href="/format/2401.15295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Trigger Backdoor Attacks: More Triggers, More Threats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yige Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xingjun Ma</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiabo He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hanxun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Backdoor attacks have emerged as a primary threat to (pre-)training and
deployment of deep neural networks (DNNs). While backdoor attacks have been
extensively studied in a body of works, most of them were focused on
single-trigger attacks that poison a dataset using a single type of trigger.
Arguably, real-world backdoor attacks can be much more complex, e.g., the
existence of multiple adversaries for the same dataset if it is of high value.
In this work, we investigate the practical threat of backdoor attacks under the
setting of \textbf{multi-trigger attacks} where multiple adversaries leverage
different types of triggers to poison the same dataset. By proposing and
investigating three types of multi-trigger attacks, including parallel,
sequential, and hybrid attacks, we provide a set of important understandings of
the coexisting, overwriting, and cross-activating effects between different
triggers on the same dataset. Moreover, we show that single-trigger attacks
tend to cause overly optimistic views of the security of current defense
techniques, as all examined defense methods struggle to defend against
multi-trigger attacks. Finally, we create a multi-trigger backdoor poisoning
dataset to help future evaluation of backdoor attacks and defenses. Although
our work is purely empirical, we hope it can help steer backdoor research
toward more realistic settings.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15296" title="Abstract">arXiv:2401.15296</a> [<a href="/pdf/2401.15296" title="Download PDF">pdf</a>, <a href="/format/2401.15296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on 3D Skeleton Based Person Re-Identification: Approaches,  Designs, Challenges, and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+H">Haocong Rao</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+C">Chunyan Miao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A up-to-date resource (papers, codes, data, etc.) of this survey is provided at <a href="https://github.com/Kali-Hac/3D-skeleton-based-person-re-ID-survey">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Person re-identification via 3D skeletons is an important emerging research
area that triggers great interest in the pattern recognition community. With
distinctive advantages for many application scenarios, a great diversity of 3D
skeleton based person re-identification (SRID) methods have been proposed in
recent years, effectively addressing prominent problems in skeleton modeling
and feature learning. Despite recent advances, to the best of our knowledge,
little effort has been made to comprehensively summarize these studies and
their challenges. In this paper, we attempt to fill this gap by providing a
systematic survey on current SRID approaches, model designs, challenges, and
future directions. Specifically, we first formulate the SRID problem, and
propose a taxonomy of SRID research with a summary of benchmark datasets,
commonly-used model architectures, and an analytical review of different
methods' characteristics. Then, we elaborate on the design principles of SRID
models from multiple aspects to offer key insights for model improvement.
Finally, we identify critical challenges confronting current studies and
discuss several promising directions for future research of SRID.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15298" title="Abstract">arXiv:2401.15298</a> [<a href="/pdf/2401.15298" title="Download PDF">pdf</a>, <a href="/format/2401.15298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Together We Go Further: LLMs and IDE Static Analysis for Extract Method  Refactoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pomian%2C+D">Dorin Pomian</a>, 
<a href="/search/cs?searchtype=author&query=Bellur%2C+A">Abhiram Bellur</a>, 
<a href="/search/cs?searchtype=author&query=Dilhara%2C+M">Malinda Dilhara</a>, 
<a href="/search/cs?searchtype=author&query=Kurbatova%2C+Z">Zarina Kurbatova</a>, 
<a href="/search/cs?searchtype=author&query=Bogomolov%2C+E">Egor Bogomolov</a>, 
<a href="/search/cs?searchtype=author&query=Bryksin%2C+T">Timofey Bryksin</a>, 
<a href="/search/cs?searchtype=author&query=Dig%2C+D">Danny Dig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Excessively long methods that encapsulate multiple responsibilities within a
single method are challenging to comprehend, debug, reuse, and maintain. The
solution to this problem, a hallmark refactoring called Extract Method,
consists of two phases: (i) choosing the statements to extract and (ii)
applying the mechanics to perform this refactoring. While the application part
has been a staple feature of all modern IDEs, they leave it up to developers to
choose the statements to extract. Choosing which statements are profitable to
extract has been the subject of many research tools that employ hard-coded
rules to optimize software quality metrics. Despite steady improvements, these
tools often fail to generate refactorings that align with developers'
preferences and acceptance criteria. In this paper, we introduce EM-Assist, a
tool that augments the refactoring capabilities of IDEs with the power of LLMs
to perform Extract Method refactoring. We empirically evaluated EM-Assist on a
diverse, publicly available corpus that other researchers used in the past. The
results show that EM-Assist outperforms previous state-of-the-art tools: at 1%
tolerance, EM-Assist suggests the correct refactoring among its top-5
suggestions 60.6% of the time, compared to 54.2% reported by existing ML
models, and 52.2% reported by existing static analysis tools. When we
replicated 2,849 actual Extract Method instances from open-source projects,
EM-Assist's recall rate was 42.1% compared to 6.5% for its peers. Furthermore,
we conducted warehouse surveys with 20 industrial developers and suggested
refactorings on their recent commits. 81.3% of the respondents agreed with the
recommendations provided by EM-Assist. This shows the usefulness of our
approach and ushers us into a new era of refactoring when LLMs.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15299" title="Abstract">arXiv:2401.15299</a> [<a href="/pdf/2401.15299" title="Download PDF">pdf</a>, <a href="/format/2401.15299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SupplyGraph: A Benchmark Dataset for Supply Chain Planning using Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wasi%2C+A+T">Azmine Toushik Wasi</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">MD Shafikul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Akib%2C+A+R">Adipto Raihan Akib</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures; Accepted to 4th workshop on Graphs and more Complex structures for Learning and Reasoning, colocated with AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY); Applications (stat.AP)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have gained traction across different domains
such as transportation, bio-informatics, language processing, and computer
vision. However, there is a noticeable absence of research on applying GNNs to
supply chain networks. Supply chain networks are inherently graph-like in
structure, making them prime candidates for applying GNN methodologies. This
opens up a world of possibilities for optimizing, predicting, and solving even
the most complex supply chain problems. A major setback in this approach lies
in the absence of real-world benchmark datasets to facilitate the research and
resolution of supply chain problems using GNNs. To address the issue, we
present a real-world benchmark dataset for temporal tasks, obtained from one of
the leading FMCG companies in Bangladesh, focusing on supply chain planning for
production purposes. The dataset includes temporal data as node features to
enable sales predictions, production planning, and the identification of
factory issues. By utilizing this dataset, researchers can employ GNNs to
address numerous supply chain problems, thereby advancing the field of supply
chain analytics and planning. Source: https://github.com/CIOL-SUST/SupplyGraph
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15304" title="Abstract">arXiv:2401.15304</a> [<a href="/pdf/2401.15304" title="Download PDF">pdf</a>, <a href="/format/2401.15304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Least Mean Squares Graph Neural Networks and Online Graph  Signal Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Changran Peng</a>, 
<a href="/search/cs?searchtype=author&query=Kuruoglu%2C+E+E">Ercan Engin Kuruoglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The online prediction of multivariate signals, existing simultaneously in
space and time, from noisy partial observations is a fundamental task in
numerous applications. We propose an efficient Neural Network architecture for
the online estimation of time-varying graph signals named the Adaptive Least
Mean Squares Graph Neural Networks (LMS-GNN). LMS-GNN aims to capture the time
variation and bridge the cross-space-time interactions under the condition that
signals are corrupted by noise and missing values. The LMS-GNN is a combination
of adaptive graph filters and Graph Neural Networks (GNN). At each time step,
the forward propagation of LMS-GNN is similar to adaptive graph filters where
the output is based on the error between the observation and the prediction
similar to GNN. The filter coefficients are updated via backpropagation as in
GNN. Experimenting on real-world temperature data reveals that our LMS-GNN
achieves more accurate online predictions compared to graph-based methods like
adaptive graph filters and graph convolutional neural networks.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15308" title="Abstract">arXiv:2401.15308</a> [<a href="/pdf/2401.15308" title="Download PDF">pdf</a>, <a href="/ps/2401.15308" title="Download PostScript">ps</a>, <a href="/format/2401.15308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of Locally Repairable Array Codes with Optimal Repair  Bandwidth under the Rack-Aware Storage Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yumeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Han Cai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaohu Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we discuss codes for distributed storage systems with
hierarchical repair properties. Specifically, we devote attention to the repair
problem of the rack-aware storage model with locality, aiming to enhance the
system's ability to repair a small number of erasures within each rack by
locality and efficiently handling a rack erasure with a small repair bandwidth.
By employing the regenerating coding technique, we construct a family of array
codes with $(r,u-r+1)$-locality, where the $u$ nodes of each repair set are
systematically organized into a rack. When the number of failures is less than
$u - r + 1$, these failures can be repaired without counting the system
bandwidth. In cases where the number of failures exceeds the locality, the
failed nodes within a single rack can be recovered with optimal cross-rack
bandwidth.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15312" title="Abstract">arXiv:2401.15312</a> [<a href="/pdf/2401.15312" title="Download PDF">pdf</a>, <a href="/format/2401.15312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How We Refute Claims: Automatic Fact-Checking through Flaw  Identification and Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kao%2C+W">Wei-Yu Kao</a>, 
<a href="/search/cs?searchtype=author&query=Yen%2C+A">An-Zi Yen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automated fact-checking is a crucial task in the governance of internet
content. Although various studies utilize advanced models to tackle this issue,
a significant gap persists in addressing complex real-world rumors and
deceptive claims. To address this challenge, this paper explores the novel task
of flaw-oriented fact-checking, including aspect generation and flaw
identification. We also introduce RefuteClaim, a new framework designed
specifically for this task. Given the absence of an existing dataset, we
present FlawCheck, a dataset created by extracting and transforming insights
from expert reviews into relevant aspects and identified flaws. The
experimental results underscore the efficacy of RefuteClaim, particularly in
classifying and elucidating false claims.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15313" title="Abstract">arXiv:2401.15313</a> [<a href="/pdf/2401.15313" title="Download PDF">pdf</a>, <a href="/format/2401.15313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot Relative Pose Estimation in SE(2) with Observability  Analysis: A Comparison of Extended Kalman Filtering and Robust Pose Graph  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+K">Kihoon Shin</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+H">Hyunjae Sim</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Seungwon Nam</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yonghee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jae Hu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K+K">Kwang-Ki K. Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we consider multi-robot localization problems with focus on
cooperative localization and observability analysis of relative pose
estimation. For cooperative localization, there is extra information available
to each robot via communication network and message passing. If odometry data
of a target robot can be transmitted to the ego-robot then the observability of
their relative pose estimation can be achieved by range-only or bearing-only
measurements provided both of their linear velocities are non-zero. If odometry
data of a target robot is not directly transmitted but estimated by the
ego-robot then there must be both range and bearing measurements to guarantee
the observability of relative pose estimation. For ROS/Gazebo simulations, we
consider four different sensing and communication structures in which extended
Kalman filtering (EKF) and pose graph optimization (PGO) estimation with
different robust loss functions (filtering and smoothing with different batch
sizes of sliding window) are compared in terms of estimation accuracy. For
hardware experiments, two Turtlebot3 equipped with UWB modules are used for
real-world inter-robot relative pose estimation, in which both EKF and PGO are
applied and compared.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15315" title="Abstract">arXiv:2401.15315</a> [<a href="/pdf/2401.15315" title="Download PDF">pdf</a>, <a href="/format/2401.15315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Online Belief Prediction for Efficient POMDP Planning in  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+C">Chen Lv</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wei Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Effective decision-making in autonomous driving relies on accurate inference
of other traffic agents' future behaviors. To achieve this, we propose an
online learning-based behavior prediction model and an efficient planner for
Partially Observable Markov Decision Processes (POMDPs). We develop a
learning-based prediction model, enhanced with a recurrent neural memory
network, to dynamically update latent belief states and infer the intentions of
other agents. The model can also integrate the ego vehicle's intentions to
reflect closed-loop interactions among agents, and it learns from both offline
data and online interactions. For planning, we employ an option-based
Monte-Carlo Tree Search (MCTS) planner, which reduces computational complexity
by searching over action sequences. Inside the MCTS planner, we use predicted
long-term multi-modal trajectories to approximate future updates, which
eliminates iterative belief updating and improves the running efficiency. Our
approach also incorporates deep Q-learning (DQN) as a search prior, which
significantly improves the performance of the MCTS planner. Experimental
results from simulated environments validate the effectiveness of our proposed
method. The online belief update model can significantly enhance the accuracy
and temporal consistency of predictions, leading to improved decision-making
performance. Employing DQN as a search prior in the MCTS planner considerably
boosts its performance and outperforms an imitation learning-based prior.
Additionally, we show that the option-based MCTS substantially outperforms the
vanilla method in terms of performance and efficiency.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15316" title="Abstract">arXiv:2401.15316</a> [<a href="/pdf/2401.15316" title="Download PDF">pdf</a>, <a href="/format/2401.15316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UNSEE: Unsupervised Non-contrastive Sentence Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87a%C4%9Fatan%2C+%C3%96+V">&#xd6;mer Veysel &#xc7;a&#x11f;atan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Main Proceedings of EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present UNSEE: Unsupervised Non-Contrastive Sentence Embeddings, a novel
approach that outperforms SimCSE in the Massive Text Embedding benchmark. Our
exploration begins by addressing the challenge of representation collapse, a
phenomenon observed when contrastive objectives in SimCSE are replaced with
non-contrastive objectives. To counter this issue, we propose a straightforward
solution known as the target network, effectively mitigating representation
collapse. The introduction of the target network allows us to leverage
non-contrastive objectives, maintaining training stability while achieving
performance improvements comparable to contrastive objectives. Our method has
achieved peak performance in non-contrastive sentence embeddings through
meticulous fine-tuning and optimization. This comprehensive effort has yielded
superior sentence representation models, showcasing the effectiveness of our
approach.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15317" title="Abstract">arXiv:2401.15317</a> [<a href="/pdf/2401.15317" title="Download PDF">pdf</a>, <a href="/ps/2401.15317" title="Download PostScript">ps</a>, <a href="/format/2401.15317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Floorplanning of VLSI by Mixed-Variable Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Huabin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhanyang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">By formulating the floorplanning of VLSI as a mixed-variable optimization
problem, this paper proposes to solve it by memetic algorithms, where the
discrete orientation variables are addressed by the distribution evolutionary
algorithm based on a population of probability model (DEA-PPM), and the
continuous coordination variables are optimized by the conjugate sub-gradient
algorithm (CSA). Accordingly, the fixed-outline floorplanning algorithm based
on CSA and DEA-PPM (FFA-CD) and the floorplanning algorithm with golden section
strategy (FA-GSS) are proposed for the floorplanning problems with and without
fixed-outline constraint. %FF-CD is committed to optimizing wirelength targets
within a fixed profile. FA-GSS uses the Golden Section strategy to optimize
both wirelength and area targets. The CSA is used to solve the proposed
non-smooth optimization model, and the DEA-PPM is used to explore the module
rotation scheme to enhance the flexibility of the algorithm. Numerical
experiments on GSRC test circuits show that the proposed algorithms are
superior to some celebrated B*-tree based floorplanning algorithms, and are
expected to be applied to large-scale floorplanning problems due to their low
time complexity.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15318" title="Abstract">arXiv:2401.15318</a> [<a href="/pdf/2401.15318" title="Download PDF">pdf</a>, <a href="/format/2401.15318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Splashing: Dynamic Fluid Synthesis with Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yintong Shang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Ying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+Z">Zeshun Zong</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+T">Tianjia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongzhi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chenfanfu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We demonstrate the feasibility of integrating physics-based animations of
solids and fluids with 3D Gaussian Splatting (3DGS) to create novel effects in
virtual scenes reconstructed using 3DGS. Leveraging the coherence of the
Gaussian splatting and position-based dynamics (PBD) in the underlying
representation, we manage rendering, view synthesis, and the dynamics of solids
and fluids in a cohesive manner. Similar to Gaussian shader, we enhance each
Gaussian kernel with an added normal, aligning the kernel's orientation with
the surface normal to refine the PBD simulation. This approach effectively
eliminates spiky noises that arise from rotational deformation in solids. It
also allows us to integrate physically based rendering to augment the dynamic
surface reflections on fluids. Consequently, our framework is capable of
realistically reproducing surface highlights on dynamic fluids and facilitating
interactions between scene objects and fluids from new views. For more
information, please visit our project page at
\url{https://amysteriouscat.github.io/GaussianSplashing/}.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15319" title="Abstract">arXiv:2401.15319</a> [<a href="/pdf/2401.15319" title="Download PDF">pdf</a>, <a href="/format/2401.15319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You Only Look Bottom-Up for Monocular 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+K">Kaixin Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Dingkang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongcheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dikubab%2C+W">Wondimu Dikubab</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jianwei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular 3D Object Detection is an essential task for autonomous driving.
Meanwhile, accurate 3D object detection from pure images is very challenging
due to the loss of depth information. Most existing image-based methods infer
objects' location in 3D space based on their 2D sizes on the image plane, which
usually ignores the intrinsic position clues from images, leading to
unsatisfactory performances. Motivated by the fact that humans could leverage
the bottom-up positional clues to locate objects in 3D space from a single
image, in this paper, we explore the position modeling from the image feature
column and propose a new method named You Only Look Bottum-Up (YOLOBU).
Specifically, our YOLOBU leverages Column-based Cross Attention to determine
how much a pixel contributes to pixels above it. Next, the Row-based Reverse
Cumulative Sum (RRCS) is introduced to build the connections of pixels in the
bottom-up direction. Our YOLOBU fully explores the position clues for monocular
3D detection via building the relationship of pixels from the bottom-up way.
Extensive experiments on the KITTI dataset demonstrate the effectiveness and
superiority of our method.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15321" title="Abstract">arXiv:2401.15321</a> [<a href="/pdf/2401.15321" title="Download PDF">pdf</a>, <a href="/ps/2401.15321" title="Download PostScript">ps</a>, <a href="/format/2401.15321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localization of Dummy Data Injection Attacks in Power Systems  Considering Incomplete Topological Information: A Spatio-Temporal Graph  Wavelet Convolutional Neural Network Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qu%2C+Z">Zhaoyang Qu</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+Y">Yunchang Dong</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+S">Siqi Song</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Min Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qiming Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Bo%2C+X">Xiaoyong Bo</a>, 
<a href="/search/eess?searchtype=author&query=Zang%2C+J">Jiye Zang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Q">Qi Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Applied Energy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The emergence of novel the dummy data injection attack (DDIA) poses a severe
threat to the secure and stable operation of power systems. These attacks are
particularly perilous due to the minimal Euclidean spatial separation between
the injected malicious data and legitimate data, rendering their precise
detection challenging using conventional distance-based methods. Furthermore,
existing research predominantly focuses on various machine learning techniques,
often analyzing the temporal data sequences post-attack or relying solely on
Euclidean spatial characteristics. Unfortunately, this approach tends to
overlook the inherent topological correlations within the non-Euclidean spatial
attributes of power grid data, consequently leading to diminished accuracy in
attack localization. To address this issue, this study takes a comprehensive
approach. Initially, it examines the underlying principles of these new DDIAs
on power systems. Here, an intricate mathematical model of the DDIA is
designed, accounting for incomplete topological knowledge and alternating
current (AC) state estimation from an attacker's perspective. Subsequently, by
integrating a priori knowledge of grid topology and considering the temporal
correlations within measurement data and the topology-dependent attributes of
the power grid, this study introduces temporal and spatial attention matrices.
These matrices adaptively capture the spatio-temporal correlations within the
attacks. Leveraging gated stacked causal convolution and graph wavelet sparse
convolution, the study jointly extracts spatio-temporal DDIA features. Finally,
the research proposes a DDIA localization method based on spatio-temporal graph
neural networks. The accuracy and effectiveness of the DDIA model are
rigorously demonstrated through comprehensive analytical cases.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15323" title="Abstract">arXiv:2401.15323</a> [<a href="/pdf/2401.15323" title="Download PDF">pdf</a>, <a href="/format/2401.15323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Music Auto-Tagging with Robust Music Representation Learned via Domain  Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joung%2C+H">Haesun Joung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyogu Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Music auto-tagging is crucial for enhancing music discovery and
recommendation. Existing models in Music Information Retrieval (MIR) struggle
with real-world noise such as environmental and speech sounds in multimedia
content. This study proposes a method inspired by speech-related tasks to
enhance music auto-tagging performance in noisy settings. The approach
integrates Domain Adversarial Training (DAT) into the music domain, enabling
robust music representations that withstand noise. Unlike previous research,
this approach involves an additional pretraining phase for the domain
classifier, to avoid performance degradation in the subsequent phase. Adding
various synthesized noisy music data improves the model's generalization across
different noise levels. The proposed architecture demonstrates enhanced
performance in music auto-tagging by effectively utilizing unlabeled noisy
music data. Additional experiments with supplementary unlabeled data further
improves the model's performance, underscoring its robust generalization
capabilities and broad applicability.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15328" title="Abstract">arXiv:2401.15328</a> [<a href="/pdf/2401.15328" title="Download PDF">pdf</a>, <a href="/format/2401.15328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equipping Language Models with Tool Use Capability for Tabular Data  Analysis in Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theuma%2C+A">Adrian Theuma</a>, 
<a href="/search/cs?searchtype=author&query=Shareghi%2C+E">Ehsan Shareghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL2024; code, model and dataset are available at &amp;lt;a href="https://raven-lm.github.io"&amp;gt;<a href="https://raven-lm.github.io">this https URL</a>&amp;lt;/a&amp;gt;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have exhibited an array of reasoning
capabilities but face challenges like error propagation and hallucination,
particularly in specialised areas like finance, where data is heterogeneous,
and precision is paramount. We explore the potential of language model
augmentation with external tools to mitigate these limitations and offload
certain reasoning steps to external tools that are more suited for the task,
instead of solely depending on the LLM's inherent abilities. More concretely,
using financial domain question-answering datasets, we apply supervised
fine-tuning on a LLaMA-2 13B Chat model to act both as a 'task router' and
'task solver'. The 'task router' dynamically directs a question to either be
answered internally by the LLM or externally via the right tool from the tool
set. Our tool-equipped SFT model, Raven, demonstrates an improvement of 35.2%
and 5.06% over the base model and SFT-only baselines, respectively, and is
highly competitive with strong GPT-3.5 results. To the best of our knowledge,
our work is the first that investigates tool augmentation of language models
for the finance domain.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15330" title="Abstract">arXiv:2401.15330</a> [<a href="/pdf/2401.15330" title="Download PDF">pdf</a>, <a href="/format/2401.15330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Sparse Survival Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+R">Rui Xin</a>, 
<a href="/search/cs?searchtype=author&query=Seltzer%2C+M">Margo Seltzer</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AISTATS2024 preprint. arXiv admin note: text overlap with <a href="/abs/2211.14980">arXiv:2211.14980</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Interpretability is crucial for doctors, hospitals, pharmaceutical companies
and biotechnology corporations to analyze and make decisions for high stakes
problems that involve human health. Tree-based methods have been widely adopted
for \textit{survival analysis} due to their appealing interpretablility and
their ability to capture complex relationships. However, most existing methods
to produce survival trees rely on heuristic (or greedy) algorithms, which risk
producing sub-optimal models. We present a dynamic-programming-with-bounds
approach that finds provably-optimal sparse survival tree models, frequently in
only a few seconds.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15332" title="Abstract">arXiv:2401.15332</a> [<a href="/pdf/2401.15332" title="Download PDF">pdf</a>, <a href="/format/2401.15332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient yet Accurate End-to-End SC Accelerator Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meng Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yixuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tengyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+R">Renjie Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Ru Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runsheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Providing end-to-end stochastic computing (SC) neural network acceleration
for state-of-the-art (SOTA) models has become an increasingly challenging task,
requiring the pursuit of accuracy while maintaining efficiency. It also
necessitates flexible support for different types and sizes of operations in
models by end-to-end SC circuits. In this paper, we summarize our recent
research on end-to-end SC neural network acceleration. We introduce an accurate
end-to-end SC accelerator based on a deterministic coding and sorting network.
In addition, we propose an SC-friendly model that combines low-precision data
paths with high-precision residuals. We introduce approximate computing
techniques to optimize SC nonlinear adders and provide some new SC designs for
arithmetic operations required by SOTA models. Overall, our approach allows for
further significant improvements in circuit efficiency, flexibility, and
compatibility through circuit design and model co-optimization. The results
demonstrate that the proposed end-to-end SC architecture achieves accurate and
efficient neural network acceleration while flexibly accommodating model
requirements, showcasing the potential of SC in neural network acceleration.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15335" title="Abstract">arXiv:2401.15335</a> [<a href="/pdf/2401.15335" title="Download PDF">pdf</a>, <a href="/format/2401.15335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L-AutoDA: Leveraging Large Language Models for Automated Decision-based  Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Ping Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qingchuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingfu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review of IJCNN 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the rapidly evolving field of machine learning, adversarial attacks
present a significant challenge to model robustness and security.
Decision-based attacks, which only require feedback on the decision of a model
rather than detailed probabilities or scores, are particularly insidious and
difficult to defend against. This work introduces L-AutoDA (Large Language
Model-based Automated Decision-based Adversarial Attacks), a novel approach
leveraging the generative capabilities of Large Language Models (LLMs) to
automate the design of these attacks. By iteratively interacting with LLMs in
an evolutionary framework, L-AutoDA automatically designs competitive attack
algorithms efficiently without much human effort. We demonstrate the efficacy
of L-AutoDA on CIFAR-10 dataset, showing significant improvements over baseline
methods in both success rate and computational efficiency. Our findings
underscore the potential of language models as tools for adversarial attack
generation and highlight new avenues for the development of robust AI systems.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15337" title="Abstract">arXiv:2401.15337</a> [<a href="/pdf/2401.15337" title="Download PDF">pdf</a>, <a href="/format/2401.15337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning with Information Fusion and Model Interpretation for  Health Monitoring of Fetus based on Long-term Prenatal Electronic Fetal Heart  Rate Monitoring Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zenghui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xintong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruichen Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jingying Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Shenda Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Long-term fetal heart rate (FHR) monitoring during the antepartum period,
increasingly popularized by electronic FHR monitoring, represents a growing
approach in FHR monitoring. This kind of continuous monitoring, in contrast to
the short-term one, collects an extended period of fetal heart data. This
offers a more comprehensive understanding of fetus's conditions. However, the
interpretation of long-term antenatal fetal heart monitoring is still in its
early stages, lacking corresponding clinical standards. Furthermore, the
substantial amount of data generated by continuous monitoring imposes a
significant burden on clinical work when analyzed manually. To address above
challenges, this study develops an automatic analysis system named LARA
(Long-term Antepartum Risk Analysis system) for continuous FHR monitoring,
combining deep learning and information fusion methods. LARA's core is a
well-established convolutional neural network (CNN) model. It processes
long-term FHR data as input and generates a Risk Distribution Map (RDM) and
Risk Index (RI) as the analysis results. We evaluate LARA on inner test
dataset, the performance metrics are as follows: AUC 0.872, accuracy 0.816,
specificity 0.811, sensitivity 0.806, precision 0.271, and F1 score 0.415. In
our study, we observe that long-term FHR monitoring data with higher RI is more
likely to result in adverse outcomes (p=0.0021). In conclusion, this study
introduces LARA, the first automated analysis system for long-term FHR
monitoring, initiating the further explorations into its clinical value in the
future.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15343" title="Abstract">arXiv:2401.15343</a> [<a href="/pdf/2401.15343" title="Download PDF">pdf</a>, <a href="/format/2401.15343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Quality and Efficiency in Adaptive Live Streaming with JND-Aware  Low latency Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menon%2C+V+V">Vignesh V Menon</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingwen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+P+T">Prajit T Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Afzal%2C+S">Samira Afzal</a>, 
<a href="/search/cs?searchtype=author&query=Schoeffmann%2C+K">Klaus Schoeffmann</a>, 
<a href="/search/cs?searchtype=author&query=Callet%2C+P+L">Patrick Le Callet</a>, 
<a href="/search/cs?searchtype=author&query=Timmerer%2C+C">Christian Timmerer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 Mile High Video (MHV)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">In HTTP adaptive live streaming applications, video segments are encoded at a
fixed set of bitrate-resolution pairs known as bitrate ladder. Live encoders
use the fastest available encoding configuration, referred to as preset, to
ensure the minimum possible latency in video encoding. However, an optimized
preset and optimized number of CPU threads for each encoding instance may
result in (i) increased quality and (ii) efficient CPU utilization while
encoding. For low latency live encoders, the encoding speed is expected to be
more than or equal to the video framerate. To this light, this paper introduces
a Just Noticeable Difference (JND)-Aware Low latency Encoding Scheme (JALE),
which uses random forest-based models to jointly determine the optimized
encoder preset and thread count for each representation, based on video
complexity features, the target encoding speed, the total number of available
CPU threads, and the target encoder. Experimental results show that, on
average, JALE yield a quality improvement of 1.32 dB PSNR and 5.38 VMAF points
with the same bitrate, compared to the fastest preset encoding of the HTTP Live
Streaming (HLS) bitrate ladder using x265 HEVC open-source encoder with eight
CPU threads used for each representation. These enhancements are achieved while
maintaining the desired encoding speed. Furthermore, on average, JALE results
in an overall storage reduction of 72.70 %, a reduction in the total number of
CPU threads used by 63.83 %, and a 37.87 % reduction in the overall encoding
time, considering a JND of six VMAF points.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15344" title="Abstract">arXiv:2401.15344</a> [<a href="/pdf/2401.15344" title="Download PDF">pdf</a>, <a href="/format/2401.15344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRS Aided Millimeter-Wave Sensing and Communication: Beam Scanning, Beam  Splitting, and Performance Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Renwang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+X">Xiaodan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+M">Meixia Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE TWC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Integrated sensing and communication (ISAC) has attracted growing interests
for enabling the future 6G wireless networks, due to its capability of sharing
spectrum and hardware resources between communication and sensing systems.
However, existing works on ISAC usually need to modify the communication
protocol to cater for the new sensing performance requirement, which may be
difficult to implement in practice. In this paper, we study a new intelligent
reflecting surface (IRS) aided millimeter-wave (mmWave) ISAC system by
exploiting the distinct beam scanning operation in mmWave communications to
achieve efficient sensing at the same time. First, we propose a two-phase ISAC
protocol aided by a semi-passive IRS, consisting of beam scanning and data
transmission. Specifically, in the beam scanning phase, the IRS finds the
optimal beam for reflecting signals from the base station to a communication
user via its passive elements. Meanwhile, the IRS directly estimates the angle
of a nearby target based on echo signals from the target using its equipped
active sensing element. Then, in the data transmission phase, the sensing
accuracy is further improved by leveraging the data signals via possible IRS
beam splitting. Next, we derive the achievable rate of the communication user
as well as the Cram\'er-Rao bound and the approximate mean square error of the
target angle estimation Finally, extensive simulation results are provided to
verify our analysis as well as the effectiveness of the proposed scheme.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15346" title="Abstract">arXiv:2401.15346</a> [<a href="/pdf/2401.15346" title="Download PDF">pdf</a>, <a href="/format/2401.15346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-efficient Adaptive Video Streaming with Latency-Aware Dynamic  Resolution Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menon%2C+V+V">Vignesh V Menon</a>, 
<a href="/search/cs?searchtype=author&query=Premkumar%2C+A">Amritha Premkumar</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+P+T">Prajit T Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Wieckowski%2C+A">Adam Wieckowski</a>, 
<a href="/search/cs?searchtype=author&query=Bross%2C+B">Benjamin Bross</a>, 
<a href="/search/cs?searchtype=author&query=Timmerer%2C+C">Christian Timmerer</a>, 
<a href="/search/cs?searchtype=author&query=Marpe%2C+D">Detlev Marpe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 Mile High Video (MHV)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Traditional per-title encoding schemes aim to optimize encoding resolutions
to deliver the highest perceptual quality for each representation. However,
keeping the encoding time within an acceptable threshold for a smooth user
experience is important to reduce the carbon footprint and energy consumption
on encoding servers in video streaming applications. Toward this realization,
we introduce an encoding latency-a ware dynamic resolution encoding scheme
(LADRE) for adaptive video streaming applications. LADRE determines the
encoding resolution for each target bitrate by utilizing a random forest-based
prediction model for every video segment based on spatiotemporal features and
the acceptable target latency. Experimental results show that LADRE achieves an
overall average quality improvement of 0.58 dB PSNR and 0.43 dB XPSNR while
maintaining the same bitrate, compared to the HTTP Live Streaming (HLS) bitrate
ladder encoding of 200 s segments using the VVenC encoder, when the encoding
latency for each representation is set to remain below the 200 s threshold.
This is accompanied by an 84.17 % reduction in overall encoding energy
consumption.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15347" title="Abstract">arXiv:2401.15347</a> [<a href="/pdf/2401.15347" title="Download PDF">pdf</a>, <a href="/format/2401.15347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Compression Algorithms for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seungcheol Park</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaehyeon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sojin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+U">U Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">How can we compress language models without sacrificing accuracy? The number
of compression algorithms for language models is rapidly growing to benefit
from remarkable advances of recent language models without side effects due to
the gigantic size of language models, such as increased carbon emissions and
expensive maintenance fees. While numerous compression algorithms have shown
remarkable progress in compressing language models, it ironically becomes
challenging to capture emerging trends and identify the fundamental concepts
underlying them due to the excessive number of algorithms. In this paper, we
survey and summarize diverse compression algorithms including pruning,
quantization, knowledge distillation, low-rank approximation, parameter
sharing, and efficient architecture design. We not only summarize the overall
trend of diverse compression algorithms but also select representative
algorithms and provide in-depth analyses of them. We discuss the value of each
category of compression algorithms, and the desired properties of low-cost
compression algorithms which have a significant impact due to the emergence of
large language models. Finally, we introduce promising future research topics
based on our survey results.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15348" title="Abstract">arXiv:2401.15348</a> [<a href="/pdf/2401.15348" title="Download PDF">pdf</a>, <a href="/format/2401.15348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AniDress: Animatable Loose-Dressed Avatar from Sparse Views Using  Garment Rigging Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beijia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yuefan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+Q">Qing Shuai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaowei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Youyi Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Recent communities have seen significant progress in building photo-realistic
animatable avatars from sparse multi-view videos. However, current workflows
struggle to render realistic garment dynamics for loose-fitting characters as
they predominantly rely on naked body models for human modeling while leaving
the garment part un-modeled. This is mainly due to that the deformations
yielded by loose garments are highly non-rigid, and capturing such deformations
often requires dense views as supervision. In this paper, we introduce
AniDress, a novel method for generating animatable human avatars in loose
clothes using very sparse multi-view videos (4-8 in our setting). To allow the
capturing and appearance learning of loose garments in such a situation, we
employ a virtual bone-based garment rigging model obtained from physics-based
simulation data. Such a model allows us to capture and render complex garment
dynamics through a set of low-dimensional bone transformations. Technically, we
develop a novel method for estimating temporal coherent garment dynamics from a
sparse multi-view video. To build a realistic rendering for unseen garment
status using coarse estimations, a pose-driven deformable neural radiance field
conditioned on both body and garment motions is introduced, providing explicit
control of both parts. At test time, the new garment poses can be captured from
unseen situations, derived from a physics-based or neural network-based
simulator to drive unseen garment dynamics. To evaluate our approach, we create
a multi-view dataset that captures loose-dressed performers with diverse
motions. Experiments show that our method is able to render natural garment
dynamics that deviate highly from the body and generalize well to both unseen
views and poses, surpassing the performance of existing methods. The code and
data will be publicly available.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15351" title="Abstract">arXiv:2401.15351</a> [<a href="/pdf/2401.15351" title="Download PDF">pdf</a>, <a href="/format/2401.15351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Neural Topic Models: Methods, Applications, and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaobao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Artifcial Intelligence Review. See <a href="https://doi.org/10.1007/s10462-023-10661-7">this https URL</a> and a paper list at <a href="https://github.com/BobXWu/Paper-Neural-Topic-Models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Topic models have been prevalent for decades to discover latent topics and
infer topic proportions of documents in an unsupervised fashion. They have been
widely used in various applications like text analysis and context
recommendation. Recently, the rise of neural networks has facilitated the
emergence of a new research field -- Neural Topic Models (NTMs). Different from
conventional topic models, NTMs directly optimize parameters without requiring
model-specific derivations. This endows NTMs with better scalability and
flexibility, resulting in significant research attention and plentiful new
methods and applications. In this paper, we present a comprehensive survey on
neural topic models concerning methods, applications, and challenges.
Specifically, we systematically organize current NTM methods according to their
network structures and introduce the NTMs for various scenarios like short
texts and cross-lingual documents. We also discuss a wide range of popular
applications built on NTMs. Finally, we highlight the challenges confronted by
NTMs to inspire future research.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15352" title="Abstract">arXiv:2401.15352</a> [<a href="/pdf/2401.15352" title="Download PDF">pdf</a>, <a href="/ps/2401.15352" title="Download PostScript">ps</a>, <a href="/format/2401.15352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized query composition and product distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Swagato Sanyal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to STACS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Let R_eps denote randomized query complexity for error probability eps, and
R:=R_{1/3}. In this work we investigate whether a perfect composition theorem
R(f o g^n)=Omega(R(f).R(g)) holds for a relation f in {0,1}^n * S and a total
inner function g:{0,1}^m \to {0, 1}.
<br />Let D^(prod) denote the maximum distributional query complexity with respect
to any product (over variables) distribution. In this work we show the
composition theorem R(f o g^n)=Omega(R(f).D^{prod}(g)) up to logarithmic
factors. In light of the minimax theorem which states that R(g) is the maximum
distributional complexity of g over any distribution, our result makes progress
towards answering the composition question. We prove our result by means of a
complexity measure R^(prod)_(eps) that we define for total Boolean functions.
We show it to be equivalent (up to logarithmic factors) to the sabotage
complexity measure RS() defined by Ben-David and Kothari (ICALP 2019): RS(g) =
Theta(R^(prod)_(1/3)(g)) (up to log factors).
<br />We ask if our bound RS(g) = Omega(D^(prod)(g)) (up to log factors) is tight.
We answer this question in the negative, by showing that for the NAND tree
function, sabotage complexity is polynomially larger than D^(prod). Our proof
yields an alternative and different derivation of the tight lower bound on the
bounded error randomized query complexity of the NAND tree function (originally
proved by Santha in 1985), which may be of independent interest. Our result
gives an explicit polynomial separation between R and D^(prod) which, to our
knowledge, was not known prior to our work.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15355" title="Abstract">arXiv:2401.15355</a> [<a href="/pdf/2401.15355" title="Download PDF">pdf</a>, <a href="/ps/2401.15355" title="Download PostScript">ps</a>, <a href="/format/2401.15355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved bounds on the interactive capacity via error pattern analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+M">Mudit Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+M">Manuj Mukherjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Any interactive protocol between a pair of parties can be reliably simulated
in the presence of noise with a multiplicative overhead on the number of rounds
(Schulman 1996). The reciprocal of the best (least) overhead is called the
interactive capacity of the noisy channel.
<br />In this work, we present lower bounds on the interactive capacity of the
binary erasure channel. Our lower bound improves the best known bound due to
Ben-Yishai et al. 2021 by roughly a factor of 1.75. The improvement is due to a
tighter analysis of the correctness of the simulation protocol using error
pattern analysis. More precisely, instead of using the well-known technique of
bounding the least number of erasures needed to make the simulation fail, we
identify and bound the probability of specific erasure patterns causing
simulation failure.
<br />We remark that error pattern analysis can be useful in solving other problems
involving stochastic noise, such as bounding the interactive capacity of
different channels.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15356" title="Abstract">arXiv:2401.15356</a> [<a href="/pdf/2401.15356" title="Download PDF">pdf</a>, <a href="/format/2401.15356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Statistical Framework for Measuring AI Reliance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Ziyang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hartline%2C+J">Jason Hartline</a>, 
<a href="/search/cs?searchtype=author&query=Hullman%2C+J">Jessica Hullman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Humans frequently make decisions with the aid of artificially intelligent
(AI) systems. A common pattern is for the AI to recommend an action to the
human who retains control over the final decision. Researchers have identified
ensuring that a human has appropriate reliance on an AI as a critical component
of achieving complementary performance. We argue that the current definition of
appropriate reliance used in such research lacks formal statistical grounding
and can lead to contradictions. We propose a formal definition of reliance,
based on statistical decision theory, which separates the concepts of reliance
as the probability the decision-maker follows the AI's prediction from
challenges a human may face in differentiating the signals and forming accurate
beliefs about the situation. Our definition gives rise to a framework that can
be used to guide the design and interpretation of studies on human-AI
complementarity and reliance. Using recent AI-advised decision making studies
from literature, we demonstrate how our framework can be used to separate the
loss due to mis-reliance from the loss due to not accurately differentiating
the signals. We evaluate these losses by comparing to a baseline and a
benchmark for complementary performance defined by the expected payoff achieved
by a rational agent facing the same decision task as the behavioral agents.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15360" title="Abstract">arXiv:2401.15360</a> [<a href="/pdf/2401.15360" title="Download PDF">pdf</a>, <a href="/format/2401.15360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Importance-Aware Data Augmentation for Document-Level Neural Machine  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+G">George Foster</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Lizhen Qu</a>, 
<a href="/search/cs?searchtype=author&query=Haffari%2C+G">Gholamreza Haffari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, 7 tables, accepted by EACL2024 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Document-level neural machine translation (DocNMT) aims to generate
translations that are both coherent and cohesive, in contrast to its
sentence-level counterpart. However, due to its longer input length and limited
availability of training data, DocNMT often faces the challenge of data
sparsity. To overcome this issue, we propose a novel Importance-Aware Data
Augmentation (IADA) algorithm for DocNMT that augments the training data based
on token importance information estimated by the norm of hidden states and
training gradients. We conduct comprehensive experiments on three widely-used
DocNMT benchmarks. Our empirical results show that our proposed IADA
outperforms strong DocNMT baselines as well as several data augmentation
approaches, with statistical significance on both sentence-level and
document-level BLEU.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15362" title="Abstract">arXiv:2401.15362</a> [<a href="/pdf/2401.15362" title="Download PDF">pdf</a>, <a href="/format/2401.15362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based Clipped Contrastive Quantization Learning for  Unsupervised Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Ayush Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+S+R">Shiv Ram Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+K">Satish Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wei-Ta Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised image retrieval aims to learn the important visual
characteristics without any given level to retrieve the similar images for a
given query image. The Convolutional Neural Network (CNN)-based approaches have
been extensively exploited with self-supervised contrastive learning for image
hashing. However, the existing approaches suffer due to lack of effective
utilization of global features by CNNs and biased-ness created by false
negative pairs in the contrastive learning. In this paper, we propose a
TransClippedCLR model by encoding the global context of an image using
Transformer having local context through patch based processing, by generating
the hash codes through product quantization and by avoiding the potential false
negative pairs through clipped contrastive learning. The proposed model is
tested with superior performance for unsupervised image retrieval on benchmark
datasets, including CIFAR10, NUS-Wide and Flickr25K, as compared to the recent
state-of-the-art deep models. The results using the proposed clipped
contrastive learning are greatly improved on all datasets as compared to same
backbone network with vanilla contrastive learning.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15363" title="Abstract">arXiv:2401.15363</a> [<a href="/pdf/2401.15363" title="Download PDF">pdf</a>, <a href="/format/2401.15363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair and Efficient Ridesharing: A Dynamic Programming-based Relocation  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makhdomi%2C+A+A">Aqsa Ashraf Makhdomi</a>, 
<a href="/search/cs?searchtype=author&query=Gillani%2C+I+A">Iqra Altaf Gillani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Recommending routes by their probability of having a rider has long been the
goal of conventional route recommendation systems. While this maximizes the
platform-specific criteria of efficiency, it results in sub-optimal outcomes
with the disparity among the income of drivers who work for similar time
frames. Pioneer studies on fairness in ridesharing platforms have focused on
algorithms that match drivers and riders. However, these studies do not
consider the time schedules of different riders sharing a ride in the
ridesharing mode. To overcome this shortcoming, we present the first route
recommendation system for ridesharing networks that explicitly considers
fairness as an evaluation criterion. In particular, we design a routing
mechanism that reduces the inequality among drivers and provides them with
routes that have a similar probability of finding riders over a period of time.
However, while optimizing fairness the efficiency of the platform should not be
affected as both of these goals are important for the long-term sustainability
of the system. In order to jointly optimize fairness and efficiency we consider
repositioning drivers with low income to the areas that have a higher
probability of finding riders in future. While applying driver repositioning,
we design a future-aware policy and allocate the areas to the drivers
considering the destination of requests in the corresponding area. Extensive
simulations on real-world datasets of Washington DC and New York demonstrate
superior performance by our proposed system in comparison to the existing
baselines.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15365" title="Abstract">arXiv:2401.15365</a> [<a href="/pdf/2401.15365" title="Download PDF">pdf</a>, <a href="/format/2401.15365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An open dataset for oracle bone script recognition and decipherment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaile Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Jinpeng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haisu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zhebin Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Oracle Bone Script (OBS), one of the earliest known forms of ancient Chinese
writing, holds invaluable insights into the humanities and geography of the
Shang Dynasty, dating back 3,000 years. The immense historical and cultural
significance of these writings cannot be overstated. However, the passage of
time has obscured much of their meaning, presenting a significant challenge in
deciphering these ancient texts. With the advent of Artificial Intelligence
(AI), employing AI to assist in interpreting OBS has become a feasible option.
Yet, progress in this area has been hindered by a lack of high-quality
datasets. To address this issue, this paper details the creation of the
HUST-OBS dataset. This dataset encompasses 77,064 images of 1,588 individual
deciphered scripts and 62,989 images of 9,411 undeciphered characters, with a
total of 140,053 images, compiled from diverse sources. Additionally, all
images and labels have been reviewed and corrected by experts in oracle bone
studies. The hope is that this dataset could inspire and assist future research
in deciphering those unknown OBS.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15366" title="Abstract">arXiv:2401.15366</a> [<a href="/pdf/2401.15366" title="Download PDF">pdf</a>, <a href="/format/2401.15366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Face to Cartoon Incremental Super-Resolution using Knowledge  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devkatte%2C+T">Trinetra Devkatte</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+S+R">Shiv Ram Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+K">Satish Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Hadid%2C+A">Abdenour Hadid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Facial super-resolution/hallucination is an important area of research that
seeks to enhance low-resolution facial images for a variety of applications.
While Generative Adversarial Networks (GANs) have shown promise in this area,
their ability to adapt to new, unseen data remains a challenge. This paper
addresses this problem by proposing an incremental super-resolution using GANs
with knowledge distillation (ISR-KD) for face to cartoon. Previous research in
this area has not investigated incremental learning, which is critical for
real-world applications where new data is continually being generated. The
proposed ISR-KD aims to develop a novel unified framework for facial
super-resolution that can handle different settings, including different types
of faces such as cartoon face and various levels of detail. To achieve this, a
GAN-based super-resolution network was pre-trained on the CelebA dataset and
then incrementally trained on the iCartoonFace dataset, using knowledge
distillation to retain performance on the CelebA test set while improving the
performance on iCartoonFace test set. Our experiments demonstrate the
effectiveness of knowledge distillation in incrementally adding capability to
the model for cartoon face super-resolution while retaining the learned
knowledge for facial hallucination tasks in GANs.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15368" title="Abstract">arXiv:2401.15368</a> [<a href="/pdf/2401.15368" title="Download PDF">pdf</a>, <a href="/ps/2401.15368" title="Download PostScript">ps</a>, <a href="/format/2401.15368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Capacity of the Weighted Read Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yerushalmi%2C+O">Omer Yerushalmi</a>, 
<a href="/search/cs?searchtype=author&query=Etzion%2C+T">Tuvi Etzion</a>, 
<a href="/search/cs?searchtype=author&query=Yaakobi%2C+E">Eitan Yaakobi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">One of the primary sequencing methods gaining prominence in DNA storage is
nanopore sequencing, attributed to various factors. In this work, we consider a
simplified model of the sequencer, characterized as a channel. This channel
takes a sequence and processes it using a sliding window of length $\ell$,
shifting the window by $\delta$ characters each time. The output of this
channel, which we refer to as the read vector, is a vector containing the sums
of the entries in each of the windows. The capacity of the channel is defined
as the maximal information rate of the channel. Previous works have already
revealed capacity values for certain parameters $\ell$ and $\delta$. In this
work, we show that when $\delta &lt; \ell &lt; 2\delta$, the capacity value is given
by $\frac{1}{\delta}\log_2 \frac{1}{2}(\ell+1+ \sqrt{(\ell+1)^2 - 4(\ell -
\delta)(\ell-\delta +1)})$. Additionally, we construct an upper bound when
$2\delta &lt; \ell$. Finally, we extend the model to the two-dimensional case and
present several results on its capacity.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15369" title="Abstract">arXiv:2401.15369</a> [<a href="/pdf/2401.15369" title="Download PDF">pdf</a>, <a href="/format/2401.15369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Cross-Domain Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhaohao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Weike Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Z">Zhong Ming</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Cross-domain sequential recommendation is an important development direction
of recommender systems. It combines the characteristics of sequential
recommender systems and cross-domain recommender systems, which can capture the
dynamic preferences of users and alleviate the problem of cold-start users.
However, in recent years, people pay more and more attention to their privacy.
They do not want other people to know what they just bought, what videos they
just watched, and where they just came from. How to protect the users' privacy
has become an urgent problem to be solved. In this paper, we propose a novel
privacy-preserving cross-domain sequential recommender system (PriCDSR), which
can provide users with recommendation services while preserving their privacy
at the same time. Specifically, we define a new differential privacy on the
data, taking into account both the ID information and the order information.
Then, we design a random mechanism that satisfies this differential privacy and
provide its theoretical proof. Our PriCDSR is a non-invasive method that can
adopt any cross-domain sequential recommender system as a base model without
any modification to it. To the best of our knowledge, our PriCDSR is the first
work to investigate privacy issues in cross-domain sequential recommender
systems. We conduct experiments on three domains, and the results demonstrate
that our PriCDSR, despite introducing noise, still outperforms recommender
systems that only use data from a single domain.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15371" title="Abstract">arXiv:2401.15371</a> [<a href="/pdf/2401.15371" title="Download PDF">pdf</a>, <a href="/format/2401.15371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LegalDuet: Learning Effective Representations for Legal Judgment  Prediction through a Dual-View Legal Clue Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liner Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Ge Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuang-hua Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Most existing Legal Judgment Prediction (LJP) models focus on discovering the
legal triggers in the criminal fact description. However, in real-world
scenarios, a professional judge not only needs to assimilate the law case
experience that thrives on past sentenced legal judgments but also depends on
the professional legal grounded reasoning that learned from professional legal
knowledge. In this paper, we propose a LegalDuet model, which pretrains
language models to learn a tailored embedding space for making legal judgments.
It proposes a dual-view legal clue reasoning mechanism, which derives from two
reasoning chains of judges: 1) Law Case Reasoning, which makes legal judgments
according to the judgment experiences learned from analogy/confusing legal
cases; 2) Legal Ground Reasoning, which lies in matching the legal clues
between criminal cases and legal decisions. Our experiments show that LegalDuet
achieves state-of-the-art performance on the CAIL2018 dataset and outperforms
baselines with about 4% improvements on average. Our dual-view reasoning based
pretraining can capture critical legal clues to learn a tailored embedding
space to distinguish criminal cases. It reduces LegalDuet's uncertainty during
prediction and brings pretraining advances to the confusing/low frequent
charges. All codes are available at https://github.com/NEUIR/LegalDuet.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15377" title="Abstract">arXiv:2401.15377</a> [<a href="/pdf/2401.15377" title="Download PDF">pdf</a>, <a href="/ps/2401.15377" title="Download PostScript">ps</a>, <a href="/format/2401.15377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validation of artificial neural networks to model the acoustic behaviour  of induction motors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jimenez-Romero%2C+F+J">F.J. Jimenez-Romero</a>, 
<a href="/search/cs?searchtype=author&query=Guijo-Rubio%2C+D">D. Guijo-Rubio</a>, 
<a href="/search/cs?searchtype=author&query=Lara-Raya%2C+F+R">F.R. Lara-Raya</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz-Gonzalez%2C+A">A. Ruiz-Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Hervas-Martinez%2C+C">C. Hervas-Martinez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In the last decade, the sound quality of electric induction motors is a hot
topic in the research field. Specially, due to its high number of applications,
the population is exposed to physical and psychological discomfort caused by
the noise emission. Therefore, it is necessary to minimise its psychological
impact on the population. In this way, the main goal of this work is to
evaluate the use of multitask artificial neural networks as a modelling
technique for simultaneously predicting psychoacoustic parameters of induction
motors. Several inputs are used, such as, the electrical magnitudes of the
motor power signal and the number of poles, instead of separating the noise of
the electric motor from the environmental noise. Two different kind of
artificial neural networks are proposed to evaluate the acoustic quality of
induction motors, by using the equivalent sound pressure, the loudness, the
roughness and the sharpness as outputs. Concretely, two different topologies
have been considered: simple models and more complex models. The former are
more interpretable, while the later lead to higher accuracy at the cost of
hiding the cause-effect relationship. Focusing on the simple interpretable
models, product unit neural networks achieved the best results: for MSE and for
SEP. The main benefit of this product unit model is its simplicity, since only
10 inputs variables are used, outlining the effective transfer mechanism of
multitask artificial neural networks to extract common features of multiple
tasks. Finally, a deep analysis of the acoustic quality of induction motors in
done using the best product unit neural networks.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15378" title="Abstract">arXiv:2401.15378</a> [<a href="/pdf/2401.15378" title="Download PDF">pdf</a>, <a href="/ps/2401.15378" title="Download PostScript">ps</a>, <a href="/format/2401.15378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A RAG-based Question Answering System Proposal for Understanding Islam:  MufassirQAS LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alan%2C+A+Y">Ahmet Yusuf Alan</a>, 
<a href="/search/cs?searchtype=author&query=Karaarslan%2C+E">Enis Karaarslan</a>, 
<a href="/search/cs?searchtype=author&query=Aydin%2C+O">Omer Aydin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">There exist challenges in learning and understanding religions as the
presence of complexity and depth of religious doctrines and teachings. Chatbots
as question-answering systems can help in solving these challenges. LLM
chatbots use NLP techniques to establish connections between topics and
accurately respond to complex questions. These capabilities make it perfect to
be used in enlightenment on religion as a question answering chatbot. However,
LLMs also have a tendency to generate false information, known as
hallucination. The responses of the chatbots can include content that insults
personal religious beliefs, interfaith conflicts, and controversial or
sensitive topics. It needs to avoid such cases without promoting hate speech or
offending certain groups of people or their beliefs. This study uses a vector
database-based Retrieval Augmented Generation (RAG) approach to enhance the
accuracy and transparency of LLMs. Our question-answering system is called as
"MufassirQAS". We created a vector database with several open-access books that
include Turkish context. These are Turkish translations, and interpretations on
Islam. We worked on creating system prompts with care, ensuring they provide
instructions that prevent harmful, offensive, or disrespectful responses. We
also tested the MufassirQAS and ChatGPT with sensitive questions. We got better
performance with our system. Study and enhancements are still in progress.
Results and future works are given.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15380" title="Abstract">arXiv:2401.15380</a> [<a href="/pdf/2401.15380" title="Download PDF">pdf</a>, <a href="/format/2401.15380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-RadVLAD: Fast and Robust Radar Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadd%2C+M">Matthew Gadd</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+P">Paul Newman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at 2024 IEEE Radar Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Radar place recognition often involves encoding a live scan as a vector and
matching this vector to a database in order to recognise that the vehicle is in
a location that it has visited before. Radar is inherently robust to lighting
or weather conditions, but place recognition with this sensor is still affected
by: (1) viewpoint variation, i.e. translation and rotation, (2) sensor
artefacts or "noises". For 360-degree scanning radar, rotation is readily dealt
with by in some way aggregating across azimuths. Also, we argue in this work
that it is more critical to deal with the richness of representation and sensor
noises than it is to deal with translational invariance - particularly in urban
driving where vehicles predominantly follow the same lane when repeating a
route. In our method, for computational efficiency, we use only the polar
representation. For partial translation invariance and robustness to signal
noise, we use only a one-dimensional Fourier Transform along radial returns. We
also achieve rotational invariance and a very discriminative descriptor space
by building a vector of locally aggregated descriptors. Our method is more
comprehensively tested than all prior radar place recognition work - over an
exhaustive combination of all 870 pairs of trajectories from 30 Oxford Radar
RobotCar Dataset sequences (each approximately 10 km). Code and detailed
results are provided at github.com/mttgdd/open-radvlad, as an open
implementation and benchmark for future work in this area. We achieve a median
of 91.52% in Recall@1, outstripping the 69.55% for the only other open
implementation, RaPlace, and at a fraction of its computational cost (relying
on fewer integral transforms e.g. Radon, Fourier, and inverse Fourier).
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15381" title="Abstract">arXiv:2401.15381</a> [<a href="/pdf/2401.15381" title="Download PDF">pdf</a>, <a href="/ps/2401.15381" title="Download PostScript">ps</a>, <a href="/format/2401.15381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Golay Complementary Sequences of Arbitrary Length and Asymptotic  Existence of Hadamard Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Cheng Du</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yi Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this work, we construct $4$-phase Golay complementary sequence (GCS) set
of cardinality $2^{3+\lceil \log_2 r \rceil}$ with arbitrary sequence length
$n$, where the $10^{13}$-base expansion of $n$ has $r$ nonzero digits.
Specifically, the GCS octets (eight sequences) cover all the lengths no greater
than $10^{13}$. Besides, based on the representation theory of signed symmetric
group, we construct Hadamard matrices from some special GCS to improve their
asymptotic existence: there exist Hadamard matrices of order $2^t m$ for any
odd number $m$, where $t = 6\lfloor \frac{1}{40}\log_{2}m\rfloor + 10$.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15384" title="Abstract">arXiv:2401.15384</a> [<a href="/pdf/2401.15384" title="Download PDF">pdf</a>, <a href="/format/2401.15384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Half-positional $&#x3c9;$-regular languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casares%2C+A">Antonio Casares</a>, 
<a href="/search/cs?searchtype=author&query=Ohlmann%2C+P">Pierre Ohlmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Computer Science and Game Theory (cs.GT); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In the context of two-player games over graphs, a language $L$ is called
half-positional if, in all games using $L$ as winning objective, the
protagonist can play optimally using positional strategies, that is, strategies
that do not depend on the history of the play. In this work, we describe the
class of parity automata recognising half-positional languages, providing a
complete characterisation of half-positionality for $\omega$-regular languages.
As corollaries, we establish decidability of half-positionality in polynomial
time, finite-to-infinite and 1-to-2-players lifts, and show the closure under
union of prefix-independent half-positional objectives, answering a conjecture
by Kopczy\'nski.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15385" title="Abstract">arXiv:2401.15385</a> [<a href="/pdf/2401.15385" title="Download PDF">pdf</a>, <a href="/format/2401.15385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Event Extraction from Speech with Contextual Clues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jingqi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tongtong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guitao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Guilin Qi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Fang Li</a>, 
<a href="/search/cs?searchtype=author&query=Haffari%2C+G">Gholamreza Haffari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">While text-based event extraction has been an active research area and has
seen successful application in many domains, extracting semantic events from
speech directly is an under-explored problem. In this paper, we introduce the
Speech Event Extraction (SpeechEE) task and construct three synthetic training
sets and one human-spoken test set. Compared to event extraction from text,
SpeechEE poses greater challenges mainly due to complex speech signals that are
continuous and have no word boundaries. Additionally, unlike perceptible sound
events, semantic events are more subtle and require a deeper understanding. To
tackle these challenges, we introduce a sequence-to-structure generation
paradigm that can produce events from speech signals in an end-to-end manner,
together with a conditioned generation method that utilizes speech recognition
transcripts as the contextual clue. We further propose to represent events with
a flat format to make outputs more natural language-like. Our experimental
results show that our method brings significant improvements on all datasets,
achieving a maximum F1 gain of 10.7%. The code and datasets are released on
https://github.com/jodie-kang/SpeechEE.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15390" title="Abstract">arXiv:2401.15390</a> [<a href="/pdf/2401.15390" title="Download PDF">pdf</a>, <a href="/ps/2401.15390" title="Download PostScript">ps</a>, <a href="/format/2401.15390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A microservice architecture for real-time IoT data processing: A  reusable Web of things approach for smart ports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+G">Guadalupe Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Boubeta-Puig%2C+J">Juan Boubeta-Puig</a>, 
<a href="/search/cs?searchtype=author&query=Criado%2C+J">Javier Criado</a>, 
<a href="/search/cs?searchtype=author&query=Corral-Plaza%2C+D">David Corral-Plaza</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-de-Prado%2C+A">Alfonso Garcia-de-Prado</a>, 
<a href="/search/cs?searchtype=author&query=Medina-Bulo%2C+I">Inmaculada Medina-Bulo</a>, 
<a href="/search/cs?searchtype=author&query=Iribarne%2C+L">Luis Iribarne</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> G.Ortiz,J.Boubeta-Puig,J.Criado,D.Corral-Plaza,A.Garcia de
  Prado,I.Medina-Bulo,L.Iribarne.A microservice architecture for real-time IoT
  data processing:A reusable Web of things approach for smart
  port.Comput.Stand.Interfaces 81:103604(2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Major advances in telecommunications and the Internet of Things have given
rise to numerous smart city scenarios in which smart services are provided.
What was once a dream for the future has now become reality. However, the need
to provide these smart services quickly, efficiently, in an interoperable
manner and in real time is a cutting-edge technological challenge. Although
some software architectures offer solutions in this area, these are often
limited in terms of reusability and maintenance by independent modules,
involving the need for system downtime when maintaining or evolving, as well as
by a lack of standards in terms of the interoperability of their interface. In
this paper, we propose a fully reusable microservice architecture, standardized
through the use of the Web of things paradigm, and with high efficiency in
real-time data processing, supported by complex event processing techniques. To
illustrate the proposal, we present a fully reusable implementation of the
microservices necessary for the deployment of the architecture in the field of
air quality monitoring and alerting in smart ports. The performance evaluation
of this architecture shows excellent results.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15391" title="Abstract">arXiv:2401.15391</a> [<a href="/pdf/2401.15391" title="Download PDF">pdf</a>, <a href="/format/2401.15391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop  Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yixuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Link: <a href="https://github.com/yixuantt/MultiHop-RAG/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Retrieval-augmented generation (RAG) augments large language models (LLM) by
retrieving relevant knowledge, showing promising potential in mitigating LLM
hallucinations and enhancing response quality, thereby facilitating the great
adoption of LLMs in practice. However, we find that existing RAG systems are
inadequate in answering multi-hop queries, which require retrieving and
reasoning over multiple pieces of supporting evidence. Furthermore, to our
knowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.
In this paper, we develop a novel dataset, MultiHop-RAG, which consists of a
knowledge base, a large collection of multi-hop queries, their ground-truth
answers, and the associated supporting evidence. We detail the procedure of
building the dataset, utilizing an English news article dataset as the
underlying RAG knowledge base. We demonstrate the benchmarking utility of
MultiHop-RAG in two experiments. The first experiment compares different
embedding models for retrieving evidence for multi-hop queries. In the second
experiment, we examine the capabilities of various state-of-the-art LLMs,
including GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop
queries given the evidence. Both experiments reveal that existing RAG methods
perform unsatisfactorily in retrieving and answering multi-hop queries. We hope
MultiHop-RAG will be a valuable resource for the community in developing
effective RAG systems, thereby facilitating greater adoption of LLMs in
practice. The MultiHop-RAG and implemented RAG system is publicly available at
https://github.com/yixuantt/MultiHop-RAG/.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15393" title="Abstract">arXiv:2401.15393</a> [<a href="/pdf/2401.15393" title="Download PDF">pdf</a>, <a href="/ps/2401.15393" title="Download PostScript">ps</a>, <a href="/format/2401.15393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantics of Multiword Expressions in Transformer-Based Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mileti%C4%87%2C+F">Filip Mileti&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Walde%2C+S+S+i">Sabine Schulte im Walde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TACL 2024. This is a pre-MIT Press publication version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multiword expressions (MWEs) are composed of multiple words and exhibit
variable degrees of compositionality. As such, their meanings are notoriously
difficult to model, and it is unclear to what extent this issue affects
transformer architectures. Addressing this gap, we provide the first in-depth
survey of MWE processing with transformer models. We overall find that they
capture MWE semantics inconsistently, as shown by reliance on surface patterns
and memorized information. MWE meaning is also strongly localized,
predominantly in early layers of the architecture. Representations benefit from
specific linguistic properties, such as lower semantic idiosyncrasy and
ambiguity of target expressions. Our findings overall question the ability of
transformer models to robustly capture fine-grained semantics. Furthermore, we
highlight the need for more directly comparable evaluation setups.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15399" title="Abstract">arXiv:2401.15399</a> [<a href="/pdf/2401.15399" title="Download PDF">pdf</a>, <a href="/format/2401.15399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Self-assembly for Modular USVs with Diverse Docking Mechanism  Layouts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lianxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Huihuan Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Self-assembly enables multi-robot systems to merge diverse capabilities and
accomplish tasks beyond the reach of individual robots. Incorporating varied
docking mechanisms layouts (DMLs) can enhance robot versatility or reduce
costs. However, assembling multiple heterogeneous robots with diverse DMLs is
still a research gap. This paper addresses this problem by introducing CuBoat,
an omnidirectional unmanned surface vehicle (USV). CuBoat can be equipped with
or without docking systems on its four sides to emulate heterogeneous robots.
We implement a multi-robot system based on multiple CuBoats. To enhance
maneuverability, a linear active disturbance rejection control (LADRC) scheme
is proposed. Additionally, we present a generalized parallel self-assembly
planning algorithm for efficient assembly among CuBoats with different DMLs.
Validation is conducted through simulation within 2 scenarios across 4 distinct
maps, demonstrating the performance of the self-assembly planning algorithm.
Moreover, trajectory tracking tests confirm the effectiveness of the LADRC
controller. Self-assembly experiments on 5 maps with different target
structures affirm the algorithm's feasibility and generality. This study
advances robotic self-assembly, enabling multi-robot systems to collaboratively
tackle complex tasks beyond the capabilities of individual robots.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15400" title="Abstract">arXiv:2401.15400</a> [<a href="/pdf/2401.15400" title="Download PDF">pdf</a>, <a href="/format/2401.15400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indexing Portuguese NLP Resources with PT-Pump-Up
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almeida%2C+R">R&#xfa;ben Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Campos%2C+R">Ricardo Campos</a>, 
<a href="/search/cs?searchtype=author&query=Jorge%2C+A">Al&#xed;pio Jorge</a>, 
<a href="/search/cs?searchtype=author&query=Nunes%2C+S">S&#xe9;rgio Nunes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Demo Track, 3 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PROPOR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">The recent advances in natural language processing (NLP) are linked to
training processes that require vast amounts of corpora. Access to this data is
commonly not a trivial process due to resource dispersion and the need to
maintain these infrastructures online and up-to-date. New developments in NLP
are often compromised due to the scarcity of data or lack of a shared
repository that works as an entry point to the community. This is especially
true in low and mid-resource languages, such as Portuguese, which lack data and
proper resource management infrastructures. In this work, we propose
PT-Pump-Up, a set of tools that aim to reduce resource dispersion and improve
the accessibility to Portuguese NLP resources. Our proposal is divided into
four software components: a) a web platform to list the available resources; b)
a client-side Python package to simplify the loading of Portuguese NLP
resources; c) an administrative Python package to manage the platform and d) a
public GitHub repository to foster future collaboration and contributions. All
four components are accessible using: https://linktr.ee/pt_pump_up
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15407" title="Abstract">arXiv:2401.15407</a> [<a href="/pdf/2401.15407" title="Download PDF">pdf</a>, <a href="/format/2401.15407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Well-posedness and Euler-Maruyama approximation for stochastic  fractional neutral integro-differential equations with weakly singular kernel  and generalized Gronwall inequality with a multi weakly singularity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Asadzade%2C+J+A">Javad A. Asadzade</a>, 
<a href="/search/math?searchtype=author&query=Mahmudov%2C+N+I">Nazim I. Mahmudov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Classical Analysis and ODEs (math.CA)

</div>
<p class="mathjax">This manuscript examines the problem of nonlinear stochastic fractional
neutral integro-differential equations with weakly singular kernels. Our focus
is on obtaining precise estimates to cover all possible cases of Abel-type
singular kernels. Initially, we establish the existence, uniqueness, and
continuous dependence on the initial value of the true solution, assuming a
local Lipschitz condition and linear growth condition. Additionally, we develop
the Euler-Maruyama method for the numerical solution of the equation and prove
its strong convergence under the same conditions as the well-posedness.
Moreover, we determine the accurate convergence rate of this method under
global Lipschitz conditions and linear growth conditions. And also we have
proven generalized Gronwall inequality with a multi-weakly singularity.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15414" title="Abstract">arXiv:2401.15414</a> [<a href="/pdf/2401.15414" title="Download PDF">pdf</a>, <a href="/format/2401.15414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Implicit Physical Face Model Driven by Expression and Style
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lingchen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zoss%2C+G">Gaspard Zoss</a>, 
<a href="/search/cs?searchtype=author&query=Chandran%2C+P">Prashanth Chandran</a>, 
<a href="/search/cs?searchtype=author&query=Gotardo%2C+P">Paulo Gotardo</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+M">Markus Gross</a>, 
<a href="/search/cs?searchtype=author&query=Solenthaler%2C+B">Barbara Solenthaler</a>, 
<a href="/search/cs?searchtype=author&query=Sifakis%2C+E">Eftychios Sifakis</a>, 
<a href="/search/cs?searchtype=author&query=Bradley%2C+D">Derek Bradley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SIGGRAPH ASIA 2023. Project page: <a href="https://studios.disneyresearch.com/2023/11/29/an-implicit-physical-face-model-driven-by-expression-and-style/">this https URL</a> Video: <a href="https://www.youtube.com/watch?v=-qM_XUv-JhA">this https URL</a>&amp;t
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">3D facial animation is often produced by manipulating facial deformation
models (or rigs), that are traditionally parameterized by expression controls.
A key component that is usually overlooked is expression 'style', as in, how a
particular expression is performed. Although it is common to define a semantic
basis of expressions that characters can perform, most characters perform each
expression in their own style. To date, style is usually entangled with the
expression, and it is not possible to transfer the style of one character to
another when considering facial animation. We present a new face model, based
on a data-driven implicit neural physics model, that can be driven by both
expression and style separately. At the core, we present a framework for
learning implicit physics-based actuations for multiple subjects
simultaneously, trained on a few arbitrary performance capture sequences from a
small set of identities. Once trained, our method allows generalized
physics-based facial animation for any of the trained identities, extending to
unseen performances. Furthermore, it grants control over the animation style,
enabling style transfer from one character to another or blending styles of
different characters. Lastly, as a physics-based model, it is capable of
synthesizing physical effects, such as collision handling, setting our method
apart from conventional approaches.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15417" title="Abstract">arXiv:2401.15417</a> [<a href="/pdf/2401.15417" title="Download PDF">pdf</a>, <a href="/format/2401.15417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault Diagnosis on Induction Motor using Machine Learning and Signal  Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samiullah%2C+M">Muhammad Samiullah</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+H">Hasan Ali</a>, 
<a href="/search/cs?searchtype=author&query=Zahoor%2C+S">Shehryar Zahoor</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+A">Anas Ali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 17 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The detection and identification of induction motor faults using machine
learning and signal processing is a valuable approach to avoiding plant
disturbances and shutdowns in the context of Industry 4.0. In this work, we
present a study on the detection and identification of induction motor faults
using machine learning and signal processing with MATLAB Simulink. We developed
a model of a three-phase induction motor in MATLAB Simulink to generate healthy
and faulty motor data. The data collected included stator currents, rotor
currents, input power, slip, rotor speed, and efficiency. We generated four
faults in the induction motor: open circuit fault, short circuit fault,
overload, and broken rotor bars. We collected a total of 150,000 data points
with a 60-40% ratio of healthy to faulty motor data. We applied Fast Fourier
Transform (FFT) to detect and identify healthy and unhealthy conditions and
added a distinctive feature in our data. The generated dataset was trained
different machine learning models. On comparing the accuracy of the models on
the test set, we concluded that the Decision Tree algorithm performed the best
with an accuracy of about 92%. Our study contributes to the literature by
providing a valuable approach to fault detection and classification with
machine learning models for industrial applications.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15422" title="Abstract">arXiv:2401.15422</a> [<a href="/pdf/2401.15422" title="Download PDF">pdf</a>, <a href="/ps/2401.15422" title="Download PostScript">ps</a>, <a href="/format/2401.15422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Data Augmentation in Large Model Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chenlu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages; <a href="https://github.com/MLGroup-JLU/LLM-data-aug-survey">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Large models, encompassing large language and diffusion models, have shown
exceptional promise in approximating human-level intelligence, garnering
significant interest from both academic and industrial spheres. However, the
training of these large models necessitates vast quantities of high-quality
data, and with continuous updates to these models, the existing reservoir of
high-quality data may soon be depleted. This challenge has catalyzed a surge in
research focused on data augmentation methods. Leveraging large models, these
data augmentation techniques have outperformed traditional approaches. This
paper offers an exhaustive review of large model-driven data augmentation
methods, adopting a comprehensive perspective. We begin by establishing a
classification of relevant studies into three main categories: image
augmentation, text augmentation, and paired data augmentation. Following this,
we delve into various data post-processing techniques pertinent to large
model-based data augmentation. Our discussion then expands to encompass the
array of applications for these data augmentation methods within natural
language processing, computer vision, and audio signal processing. We proceed
to evaluate the successes and limitations of large model-based data
augmentation across different scenarios. Concluding our review, we highlight
prospective challenges and avenues for future exploration in the field of data
augmentation. Our objective is to furnish researchers with critical insights,
ultimately contributing to the advancement of more sophisticated large models.
We consistently maintain the related open-source materials at:
https://github.com/MLGroup-JLU/LLM-data-aug-survey.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15436" title="Abstract">arXiv:2401.15436</a> [<a href="/pdf/2401.15436" title="Download PDF">pdf</a>, <a href="/format/2401.15436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A simple and complete discrete exterior calculus on general polygonal  meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ptackova%2C+L">Lenka Ptackova</a>, 
<a href="/search/math?searchtype=author&query=Velho%2C+L">Luiz Velho</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Aided Geometric Design 88 (2021) 102002
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">Discrete exterior calculus (DEC) offers a coordinate-free discretization of
exterior calculus especially suited for computations on curved spaces. In this
work, we present an extended version of DEC on surface meshes formed by general
polygons that bypasses the need for combinatorial subdivision and does not
involve any dual mesh. At its core, our approach introduces a new polygonal
wedge product that is compatible with the discrete exterior derivative in the
sense that it satisfies the Leibniz product rule. Based on the discrete wedge
product, we then derive a novel primal-to-primal Hodge star operator. Combining
these three `basic operators' we then define new discrete versions of the
contraction operator and Lie derivative, codifferential and Laplace operator.
We discuss the numerical convergence of each one of these proposed operators
and compare them to existing DEC methods. Finally, we show simple applications
of our operators on Helmholtz-Hodge decomposition, Laplacian surface fairing,
and Lie advection of functions and vector fields on meshes formed by general
polygons.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15439" title="Abstract">arXiv:2401.15439</a> [<a href="/pdf/2401.15439" title="Download PDF">pdf</a>, <a href="/format/2401.15439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training and Diagnosing Knowledge Base Completion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kocijan%2C+V">Vid Kocijan</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+M+E">Myeongjun Erik Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AIJ, reference to follow. arXiv admin note: substantial text overlap with <a href="/abs/2108.13073">arXiv:2108.13073</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this work, we introduce and analyze an approach to knowledge transfer from
one collection of facts to another without the need for entity or relation
matching. The method works for both canonicalized knowledge bases and
uncanonicalized or open knowledge bases, i.e., knowledge bases where more than
one copy of a real-world entity or relation may exist. The main contribution is
a method that can make use of large-scale pre-training on facts, which were
collected from unstructured text, to improve predictions on structured data
from a specific domain. The introduced method is most impactful on small
datasets such as ReVerb20k, where a 6% absolute increase of mean reciprocal
rank and 65% relative decrease of mean rank over the previously best method was
achieved, despite not relying on large pre-trained models like Bert. To
understand the obtained pre-trained models better, we then introduce a novel
dataset for the analysis of pre-trained models for Open Knowledge Base
Completion, called Doge (Diagnostics of Open knowledge Graph Embeddings). It
consists of 6 subsets and is designed to measure multiple properties of a
pre-trained model: robustness against synonyms, ability to perform deductive
reasoning, presence of gender stereotypes, consistency with reverse relations,
and coverage of different areas of general knowledge. Using the introduced
dataset, we show that the existing OKBC models lack consistency in the presence
of synonyms and inverse relations and are unable to perform deductive
reasoning. Moreover, their predictions often align with gender stereotypes,
which persist even when presented with counterevidence. We additionally
investigate the role of pre-trained word embeddings and demonstrate that
avoiding biased word embeddings is not a sufficient measure to prevent biased
behavior of OKBC models.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15441" title="Abstract">arXiv:2401.15441</a> [<a href="/pdf/2401.15441" title="Download PDF">pdf</a>, <a href="/ps/2401.15441" title="Download PostScript">ps</a>, <a href="/format/2401.15441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An overview of IoT architectures, technologies, and existing open-source  projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dom%C3%ADnguez-Bola%C3%B1o%2C+T">Tom&#xe1;s Dom&#xed;nguez-Bola&#xf1;o</a>, 
<a href="/search/eess?searchtype=author&query=Campos%2C+O">Omar Campos</a>, 
<a href="/search/eess?searchtype=author&query=Barral%2C+V">Valent&#xed;n Barral</a>, 
<a href="/search/eess?searchtype=author&query=Escudero%2C+C+J">Carlos J. Escudero</a>, 
<a href="/search/eess?searchtype=author&query=Garc%C3%ADa-Naya%2C+J+A">Jos&#xe9; A. Garc&#xed;a-Naya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures, Published in Internet of Things
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Internet of Things, vol. 20, Nov. 2022,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Today's needs for monitoring and control of different devices in
organizations require an Internet of Things (IoT) platform that can integrate
heterogeneous elements provided by multiple vendors and using different
protocols, data formats and communication technologies. This article provides a
comprehensive review of all the architectures, technologies, protocols and data
formats most commonly used by existing IoT platforms. On this basis, a
comparative analysis of the most widely used open source IoT platforms is
presented. This exhaustive comparison is based on multiple characteristics that
will be essential to select the platform that best suits the needs of each
organization.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15443" title="Abstract">arXiv:2401.15443</a> [<a href="/pdf/2401.15443" title="Download PDF">pdf</a>, <a href="/format/2401.15443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffuserLite: Towards Real-time Diffusion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zibin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yifu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+F">Fei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Diffusion planning has been recognized as an effective decision-making
paradigm in various domains. The high-quality conditional generation capability
of long-horizon trajectories makes it a promising research direction. However,
existing diffusion planning methods suffer from low decision-making frequencies
because of the expensive iterative sampling cost. To address this issue, we
introduce DiffuserLite, a fast and lightweight diffusion planning framework.
DiffuserLite employs a planning refinement process (PRP) to generate
coarse-to-fine-grained trajectories, which significantly reduces the modeling
of redundant information and leads to notable increases in decision-making
frequency. Our experimental results demonstrate that DiffuserLite incurs only
$0.88\%$ of the runtime cost compared to previous frameworks, achieves an
average decision-making frequency of $122$Hz, and reaches state-of-the-art
performance on D4RL benchmarks. In addition, our clean DiffuserLite framework
can serve as a flexible plugin to enhance decision frequency in other diffusion
planning algorithms, providing a structural design reference for future works.
More details and visualizations are available at [project
website](https://diffuserlite.github.io/).
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15444" title="Abstract">arXiv:2401.15444</a> [<a href="/pdf/2401.15444" title="Download PDF">pdf</a>, <a href="/format/2401.15444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Causal Classification: A Comprehensive Study on Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Job%2C+S">Simi Job</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaohui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Taotao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yong%2C+J">Jianming Yong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The exploration of Graph Neural Networks (GNNs) for processing
graph-structured data has expanded, particularly their potential for causal
analysis due to their universal approximation capabilities. Anticipated to
significantly enhance common graph-based tasks such as classification and
prediction, the development of a causally enhanced GNN framework is yet to be
thoroughly investigated. Addressing this shortfall, our study delves into nine
benchmark graph classification models, testing their strength and versatility
across seven datasets spanning three varied domains to discern the impact of
causality on the predictive prowess of GNNs. This research offers a detailed
assessment of these models, shedding light on their efficiency, and flexibility
in different data environments, and highlighting areas needing advancement. Our
findings are instrumental in furthering the understanding and practical
application of GNNs in diverse datacentric fields
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15447" title="Abstract">arXiv:2401.15447</a> [<a href="/pdf/2401.15447" title="Download PDF">pdf</a>, <a href="/format/2401.15447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Treatment Effect Estimation Using Gradient Interpolation and  Kernel Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagalapatti%2C+L">Lokesh Nagalapatti</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+A">Akshay Iyer</a>, 
<a href="/search/cs?searchtype=author&query=De%2C+A">Abir De</a>, 
<a href="/search/cs?searchtype=author&query=Sarawagi%2C+S">Sunita Sarawagi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We address the Individualized continuous treatment effect (ICTE) estimation
problem where we predict the effect of any continuous-valued treatment on an
individual using observational data. The main challenge in this estimation task
is the potential confounding of treatment assignment with an individual's
covariates in the training data, whereas during inference ICTE requires
prediction on independently sampled treatments. In contrast to prior work that
relied on regularizers or unstable GAN training, we advocate the direct
approach of augmenting training individuals with independently sampled
treatments and inferred counterfactual outcomes. We infer counterfactual
outcomes using a two-pronged strategy: a Gradient Interpolation for
close-to-observed treatments, and a Gaussian Process based Kernel Smoothing
which allows us to downweigh high variance inferences. We evaluate our method
on five benchmarks and show that our method outperforms six state-of-the-art
methods on the counterfactual estimation error. We analyze the superior
performance of our method by showing that (1) our inferred counterfactual
responses are more accurate, and (2) adding them to the training data reduces
the distributional distance between the confounded training distribution and
test distribution where treatment is independent of covariates. Our proposed
method is model-agnostic and we show that it improves ICTE accuracy of several
existing models.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15448" title="Abstract">arXiv:2401.15448</a> [<a href="/pdf/2401.15448" title="Download PDF">pdf</a>, <a href="/format/2401.15448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Review of Available Datasets in Additive Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mileo%2C+A">Alessandra Mileo</a>, 
<a href="/search/cs?searchtype=author&query=Smeaton%2C+A+F">Alan F. Smeaton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In-situ monitoring incorporating data from visual and other sensor
technologies, allows the collection of extensive datasets during the Additive
Manufacturing (AM) process. These datasets have potential for determining the
quality of the manufactured output and the detection of defects through the use
of Machine Learning during the manufacturing process. Open and annotated
datasets derived from AM processes are necessary for the machine learning
community to address this opportunity, which creates difficulties in the
application of computer vision-related machine learning in AM. This systematic
review investigates the availability of open image-based datasets originating
from AM processes that align with a number of pre-defined selection criteria.
The review identifies existing gaps among the current image-based datasets in
the domain of AM, and points to the need for greater availability of open
datasets in order to allow quality assessment and defect detection during
additive manufacturing, to develop.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15449" title="Abstract">arXiv:2401.15449</a> [<a href="/pdf/2401.15449" title="Download PDF">pdf</a>, <a href="/format/2401.15449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Trust Your Feelings: Leveraging Self-awareness in LLMs for  Hallucination Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhuoyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We evaluate the ability of Large Language Models (LLMs) to discern and
express their internal knowledge state, a key factor in countering factual
hallucination and ensuring reliable application of LLMs. We observe a robust
self-awareness of internal knowledge state in LLMs, evidenced by over 85%
accuracy in knowledge probing. However, LLMs often fail to express their
internal knowledge during generation, leading to factual hallucinations. We
develop an automated hallucination annotation tool, Dreamcatcher, which merges
knowledge probing and consistency checking methods to rank factual preference
data. Using knowledge preference as reward, We propose a Reinforcement Learning
from Knowledge Feedback (RLKF) training framework, leveraging reinforcement
learning to enhance the factuality and honesty of LLMs. Our experiments across
multiple models show that RLKF training effectively enhances the ability of
models to utilize their internal knowledge state, boosting performance in a
variety of knowledge-based and honesty-related tasks.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15453" title="Abstract">arXiv:2401.15453</a> [<a href="/pdf/2401.15453" title="Download PDF">pdf</a>, <a href="/format/2401.15453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Inference Accelerator for Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katti%2C+P">Prabodh Katti</a>, 
<a href="/search/cs?searchtype=author&query=Nimbekar%2C+A">Anagha Nimbekar</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Acharyya%2C+A">Amit Acharyya</a>, 
<a href="/search/cs?searchtype=author&query=Al-Hashimi%2C+B+M">Bashir M. Al-Hashimi</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+B">Bipin Rajendran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted and Accepted in ISCAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Bayesian neural networks offer better estimates of model uncertainty compared
to frequentist networks. However, inference involving Bayesian models requires
multiple instantiations or sampling of the network parameters, requiring
significant computational resources. Compared to traditional deep learning
networks, spiking neural networks (SNNs) have the potential to reduce
computational area and power, thanks to their event-driven and spike-based
computational framework. Most works in literature either address frequentist
SNN models or non-spiking Bayesian neural networks. In this work, we
demonstrate an optimization framework for developing and implementing efficient
Bayesian SNNs in hardware by additionally restricting network weights to be
binary-valued to further decrease power and area consumption. We demonstrate
accuracies comparable to Bayesian binary networks with full-precision Bernoulli
parameters, while requiring up to $25\times$ less spikes than equivalent binary
SNN implementations. We show the feasibility of the design by mapping it onto
Zynq-7000, a lightweight SoC, and achieve a $6.5 \times$ improvement in
GOPS/DSP while utilizing up to 30 times less power compared to the
state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15455" title="Abstract">arXiv:2401.15455</a> [<a href="/pdf/2401.15455" title="Download PDF">pdf</a>, <a href="/format/2401.15455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Foggy Object Detecting Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banavathu%2C+R">Rahul Banavathu</a>, 
<a href="/search/cs?searchtype=author&query=Sree%2C+M+V">Modem Veda Sree</a>, 
<a href="/search/cs?searchtype=author&query=Sri%2C+B+K">Bollina Kavya Sri</a>, 
<a href="/search/cs?searchtype=author&query=De%2C+S">Suddhasil De</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Object detection in reduced visibility has become a prominent research area.
The existing techniques are not accurate enough in recognizing objects under
such circumstances. This paper introduces a new foggy object detection method
through a two-staged architecture of region identification from input images
and detecting objects in such regions. The paper confirms notable improvements
of the proposed method's accuracy and detection time over existing techniques.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15458" title="Abstract">arXiv:2401.15458</a> [<a href="/pdf/2401.15458" title="Download PDF">pdf</a>, <a href="/ps/2401.15458" title="Download PostScript">ps</a>, <a href="/format/2401.15458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Method for Vehicle Logo Recognition Based on Swin Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Doudou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jianli Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Intelligent Transportation Systems (ITS) utilize sensors, cameras, and big
data analysis to monitor real-time traffic conditions, aiming to improve
traffic efficiency and safety. Accurate vehicle recognition is crucial in this
process, and Vehicle Logo Recognition (VLR) stands as a key method. VLR enables
effective management and monitoring by distinguishing vehicles on the road.
Convolutional Neural Networks (CNNs) have made impressive strides in VLR
research. However, achieving higher performance demands significant time and
computational resources for training. Recently, the rise of Transformer models
has brought new opportunities to VLR. Swin Transformer, with its efficient
computation and global feature modeling capabilities, outperforms CNNs under
challenging conditions. In this paper, we implement real-time VLR using Swin
Transformer and fine-tune it for optimal performance. Extensive experiments
conducted on three public vehicle logo datasets (HFUT-VL1, XMU, CTGU-VLD)
demonstrate impressive top accuracy results of 99.28%, 100%, and 99.17%,
respectively. Additionally, the use of a transfer learning strategy enables our
method to be on par with state-of-the-art VLR methods. These findings affirm
the superiority of our approach over existing methods. Future research can
explore and optimize the application of the Swin Transformer in other vehicle
vision recognition tasks to drive advancements in ITS.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15459" title="Abstract">arXiv:2401.15459</a> [<a href="/pdf/2401.15459" title="Download PDF">pdf</a>, <a href="/format/2401.15459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model as Synthesizer: Fusing Diverse Inputs for Better  Automatic Vulnerability Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kisub Kim</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">DongGyun Han</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the ICSE 2024 Research Track with a different title "Out of Sight, Out of Mind: Better Automatic Vulnerability Repair by Broadening Input Ranges and Sources"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The advances of deep learning (DL) have paved the way for automatic software
vulnerability repair approaches, which effectively learn the mapping from the
vulnerable code to the fixed code. Nevertheless, existing DL-based
vulnerability repair methods face notable limitations: 1) they struggle to
handle lengthy vulnerable code, 2) they treat code as natural language texts,
neglecting its inherent structure, and 3) they do not tap into the valuable
expert knowledge present in the expert system. To address this, we propose
VulMaster, a Transformer-based neural network model that excels at generating
vulnerability repairs by comprehensively understanding the entire vulnerable
code, irrespective of its length. This model also integrates diverse
information, encompassing vulnerable code structures and expert knowledge from
the CWE system. We evaluated VulMaster on a real-world C/C++ vulnerability
repair dataset comprising 1,754 projects with 5,800 vulnerable functions. The
experimental results demonstrated that VulMaster exhibits substantial
improvements compared to the learning-based state-of-the-art vulnerability
repair approach. Specifically, VulMaster improves the EM, BLEU, and CodeBLEU
scores from 10.2\% to 20.0\%, 21.3\% to 29.3\%, and 32.5\% to 40.9\%,
respectively.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15463" title="Abstract">arXiv:2401.15463</a> [<a href="/pdf/2401.15463" title="Download PDF">pdf</a>, <a href="/format/2401.15463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DataFrame QA: A Universal LLM Framework on DataFrame Question Answering  Without Data Exposure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junyi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guiling Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces DataFrame question answering (QA), a novel task that
utilizes large language models (LLMs) to generate Pandas queries for
information retrieval and data analysis on dataframes, emphasizing safe and
non-revealing data handling. Our method, which solely relies on dataframe
column names, not only ensures data privacy but also significantly reduces the
context window in the prompt, streamlining information processing and
addressing major challenges in LLM-based data analysis. We propose DataFrame QA
as a comprehensive framework that includes safe Pandas query generation and
code execution. Various LLMs, notably GPT-4, are evaluated using the pass@1
metric on the renowned WikiSQL and our newly developed 'UCI-DataFrameQA',
tailored for complex data analysis queries. Our findings indicate that GPT-4
achieves pass@1 rates of 86% on WikiSQL and 97% on UCI-DataFrameQA,
underscoring its capability in securely retrieving and aggregating dataframe
values and conducting sophisticated data analyses. This approach, deployable in
a zero-shot manner without prior training or adjustments, proves to be highly
adaptable and secure for diverse applications.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15468" title="Abstract">arXiv:2401.15468</a> [<a href="/pdf/2401.15468" title="Download PDF">pdf</a>, <a href="/ps/2401.15468" title="Download PostScript">ps</a>, <a href="/format/2401.15468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model for Vulnerability Detection: Emerging Results and  Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Ting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the New Ideas and Emerging Results Track at ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Previous learning-based vulnerability detection methods relied on either
medium-sized pre-trained models or smaller neural networks from scratch. Recent
advancements in Large Pre-Trained Language Models (LLMs) have showcased
remarkable few-shot learning capabilities in various tasks. However, the
effectiveness of LLMs in detecting software vulnerabilities is largely
unexplored. This paper aims to bridge this gap by exploring how LLMs perform
with various prompts, particularly focusing on two state-of-the-art LLMs:
GPT-3.5 and GPT-4. Our experimental results showed that GPT-3.5 achieves
competitive performance with the prior state-of-the-art vulnerability detection
approach and GPT-4 consistently outperformed the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15469" title="Abstract">arXiv:2401.15469</a> [<a href="/pdf/2401.15469" title="Download PDF">pdf</a>, <a href="/format/2401.15469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wind speed super-resolution and validation: from ERA5 to CERRA via  diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merizzi%2C+F">Fabio Merizzi</a>, 
<a href="/search/cs?searchtype=author&query=Asperti%2C+A">Andrea Asperti</a>, 
<a href="/search/cs?searchtype=author&query=Colamonaco%2C+S">Stefano Colamonaco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">The Copernicus Regional Reanalysis for Europe, CERRA, is a high-resolution
regional reanalysis dataset for the European domain. In recent years it has
shown significant utility across various climate-related tasks, ranging from
forecasting and climate change research to renewable energy prediction,
resource management, air quality risk assessment, and the forecasting of rare
events, among others. Unfortunately, the availability of CERRA is lagging two
years behind the current date, due to constraints in acquiring the requisite
external data and the intensive computational demands inherent in its
generation. As a solution, this paper introduces a novel method using diffusion
models to approximate CERRA downscaling in a data-driven manner, without
additional informations. By leveraging the lower resolution ERA5 dataset, which
provides boundary conditions for CERRA, we approach this as a super-resolution
task. Focusing on wind speed around Italy, our model, trained on existing CERRA
data, shows promising results, closely mirroring original CERRA data.
Validation with in-situ observations further confirms the model's accuracy in
approximating ground measurements.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15470" title="Abstract">arXiv:2401.15470</a> [<a href="/pdf/2401.15470" title="Download PDF">pdf</a>, <a href="/format/2401.15470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust globally divergence-free weak Galerkin methods for stationary  incompressible convective Brinkman-Forchheimer equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+X+J">X.J. Wang</a>, 
<a href="/search/math?searchtype=author&query=Xie%2C+X+P">X.P. Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper develops a class of robust weak Galerkin methods for the
stationary incompressible convective Brinkman-Forchheimer equations. The
methods adopt piecewise polynomials of degrees $m\ (m\geq1)$ and $m-1$
respectively for the approximations of velocity and pressure variables inside
the elements and piecewise polynomials of degrees $k \ ( k=m-1,m)$ and $m$
respectively for their numerical traces on the interfaces of elements, and are
shown to yield globally divergence-free velocity approximation. Existence and
uniqueness results for the discrete schemes, as well as optimal a priori error
estimates, are established. A convergent linearized iterative algorithm is also
presented. Numerical experiments are provided to verify the performance of the
proposed methods
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15471" title="Abstract">arXiv:2401.15471</a> [<a href="/pdf/2401.15471" title="Download PDF">pdf</a>, <a href="/format/2401.15471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConvoSense: Overcoming Monotonous Commonsense Inferences for  Conversational AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Finch%2C+S+E">Sarah E. Finch</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+D">Jinho D. Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to TACL 2024; final author's version of paper; pre-MIT Press publication version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Mastering commonsense understanding and reasoning is a pivotal skill
essential for conducting engaging conversations. While there have been several
attempts to create datasets that facilitate commonsense inferences in dialogue
contexts, existing datasets tend to lack in-depth details, restate information
already present in the conversation, and often fail to capture the multifaceted
nature of commonsense reasoning. In response to these limitations, we compile a
new synthetic dataset for commonsense reasoning in dialogue contexts using GPT,
ConvoSense, that boasts greater contextual novelty, offers a higher volume of
inferences per example, and substantially enriches the detail conveyed by the
inferences. Our dataset contains over 500,000 inferences across 12,000
dialogues with 10 popular inference types, which empowers the training of
generative commonsense models for dialogue that are superior in producing
plausible inferences with high novelty when compared to models trained on the
previous datasets. To the best of our knowledge, ConvoSense is the first of its
kind to provide such a multitude of novel inferences at such a large scale.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15472" title="Abstract">arXiv:2401.15472</a> [<a href="/pdf/2401.15472" title="Download PDF">pdf</a>, <a href="/ps/2401.15472" title="Download PostScript">ps</a>, <a href="/format/2401.15472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal evolution in synthetic handwriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carmona-Duarte%2C+C">Cristina Carmona-Duarte</a>, 
<a href="/search/cs?searchtype=author&query=Ferrer%2C+M+A">Miguel A. Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Parziale%2C+A">Antonio Parziale</a>, 
<a href="/search/cs?searchtype=author&query=Marcelli%2C+A">Angelo Marcelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Pattern Recognition
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Carmona-Duarte, C., Ferrer, M.A., Parziale, A., Marcelli, A.;
  Temporal evolution in synthetic handwriting; Pattern Recognition 68, p.p 233
  - 244 (2017)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">New methods for generating synthetic handwriting images for biometric
applications have recently been developed. The temporal evolution of
handwriting from childhood to adulthood is usually left unexplored in these
works. This paper proposes a novel methodology for including temporal evolution
in a handwriting synthesizer by means of simplifying the text trajectory plan
and handwriting dynamics. This is achieved through a tailored version of the
kinematic theory of rapid human movements and the neuromotor inspired
handwriting synthesizer. The realism of the proposed method has been evaluated
by comparing the temporal evolution of real and synthetic samples both
quantitatively and subjectively. The quantitative test is based on a visual
perception algorithm that compares the letter variability and the number of
strokes in the real and synthetic handwriting produced at different ages. In
the subjective test, 30 people are asked to evaluate the perceived realism of
the evolution of the synthetic handwriting.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15473" title="Abstract">arXiv:2401.15473</a> [<a href="/pdf/2401.15473" title="Download PDF">pdf</a>, <a href="/ps/2401.15473" title="Download PostScript">ps</a>, <a href="/format/2401.15473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iDeLog: Iterative Dual Spatial and Kinematic Extraction of  Sigma-Lognormal Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrer%2C+M+A">Miguel A. Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Diaz%2C+M">Moises Diaz</a>, 
<a href="/search/cs?searchtype=author&query=Carmona-Duarte%2C+C">Cristina Carmona-Duarte</a>, 
<a href="/search/cs?searchtype=author&query=Plamondon%2C+R">Rejean Plamondon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Version published by Transactions on Pattern Analysis and Machine Intelligence
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Pattern Analysis and Machine Intelligence,
  42(1); p.p. 114-125, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Kinematic Theory of rapid movements and its associated Sigma-Lognormal
model have been extensively used in a large variety of applications. While the
physical and biological meaning of the model have been widely tested and
validated for rapid movements, some shortcomings have been detected when it is
used with continuous long and complex movements. To alleviate such drawbacks,
and inspired by the motor equivalence theory and a conceivable visual feedback,
this paper proposes a novel framework to extract the Sigma-Lognormal
parameters, namely iDeLog. Specifically, iDeLog consists of two steps. The
first one, influenced by the motor equivalence model, separately derives an
initial action plan defined by a set of virtual points and angles from the
trajectory and a sequence of lognormals from the velocity. In the second step,
based on a hypothetical visual feedback compatible with an open-loop motor
control, the virtual target points of the action plan are iteratively moved to
improve the matching between the observed and reconstructed trajectory and
velocity. During experiments conducted with handwritten signatures, iDeLog
obtained promising results as compared to the previous development of the
Sigma-Lognormal.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15475" title="Abstract">arXiv:2401.15475</a> [<a href="/pdf/2401.15475" title="Download PDF">pdf</a>, <a href="/format/2401.15475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epidemic Population Games And Perturbed Best Response Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Park%2C+S">Shinkyu Park</a>, 
<a href="/search/eess?searchtype=author&query=Certorio%2C+J">Jair Certorio</a>, 
<a href="/search/eess?searchtype=author&query=Martins%2C+N+C">Nuno C. Martins</a>, 
<a href="/search/eess?searchtype=author&query=La%2C+R+J">Richard J. La</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper proposes an approach to mitigate epidemic spread in a population
of strategic agents by encouraging safer behaviors through carefully designed
rewards. These rewards, which vary according to the state of the epidemic, are
ascribed by a dynamic payoff mechanism we seek to design. We use a modified
SIRS model to track how the epidemic progresses in response to the population's
agents strategic choices. By employing perturbed best response evolutionary
dynamics to model the population's strategic behavior, we extend previous
related work so as to allow for noise in the agents' perceptions of the rewards
and intrinsic costs of the available strategies. Central to our approach is the
use of system-theoretic methods and passivity concepts to obtain a Lyapunov
function, ensuring the global asymptotic stability of an endemic equilibrium
with minimized infection prevalence, under budget constraints. We use the
Lyapunov function to construct anytime upper bounds for the size of the
population's infectious fraction. For a class of one-parameter perturbed best
response models, we propose a method to learn the model's parameter from data.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15476" title="Abstract">arXiv:2401.15476</a> [<a href="/pdf/2401.15476" title="Download PDF">pdf</a>, <a href="/format/2401.15476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Burst or Not to Burst: Generating and Quantifying Improbable Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sasse%2C+K">Kuleen Sasse</a>, 
<a href="/search/cs?searchtype=author&query=Barham%2C+S">Samuel Barham</a>, 
<a href="/search/cs?searchtype=author&query=Kayi%2C+E+S">Efsun Sarioglu Kayi</a>, 
<a href="/search/cs?searchtype=author&query=Staley%2C+E+W">Edward W. Staley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Originally published at the Generation, Evaluation &amp; Metrics (GEM) Workshop at EMNLP 2023. We are awaiting the release of the proceedings which we will reference here
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While large language models (LLMs) are extremely capable at text generation,
their outputs are still distinguishable from human-authored text. We explore
this separation across many metrics over text, many sampling techniques, many
types of text data, and across two popular LLMs, LLaMA and Vicuna. Along the
way, we introduce a new metric, recoverability, to highlight differences
between human and machine text; and we propose a new sampling technique, burst
sampling, designed to close this gap. We find that LLaMA and Vicuna have
distinct distributions under many of the metrics, and that this influences our
results: Recoverability separates real from fake text better than any other
metric when using LLaMA. When using Vicuna, burst sampling produces text which
is distributionally closer to real text compared to other sampling techniques.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15479" title="Abstract">arXiv:2401.15479</a> [<a href="/pdf/2401.15479" title="Download PDF">pdf</a>, <a href="/format/2401.15479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Post-API Dilemma Search Engine Results Pages Present a  Biased View of Social Media Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poudel%2C+A">Amrit Poudel</a>, 
<a href="/search/cs?searchtype=author&query=Weninger%2C+T">Tim Weninger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Recent decisions to discontinue access to social media APIs are having
detrimental effects on Internet research and the field of computational social
science as a whole. This lack of access to data has been dubbed the Post-API
era of Internet research. Fortunately, popular search engines have the means to
crawl, capture, and surface social media data on their Search Engine Results
Pages (SERP) if provided the proper search query, and may provide a solution to
this dilemma. In the present work we ask: does SERP provide a complete and
unbiased sample of social media data? Is SERP a viable alternative to direct
API-access? To answer these questions, we perform a comparative analysis
between (Google) SERP results and nonsampled data from Reddit and Twitter/X. We
find that SERP results are highly biased in favor of popular posts; against
political, pornographic, and vulgar posts; are more positive in their
sentiment; and have large topical gaps. Overall, we conclude that SERP is not a
viable alternative to social media API access.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15480" title="Abstract">arXiv:2401.15480</a> [<a href="/pdf/2401.15480" title="Download PDF">pdf</a>, <a href="/format/2401.15480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Interpretable Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Custode%2C+L+L">Leonardo Lucio Custode</a>, 
<a href="/search/cs?searchtype=author&query=Iacca%2C+G">Giovanni Iacca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, submitted to IJCAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Reinforcement Learning (RL) bears the promise of being an enabling technology
for many applications. However, since most of the literature in the field is
currently focused on opaque models, the use of RL in high-stakes scenarios,
where interpretability is crucial, is still limited. Recently, some approaches
to interpretable RL, e.g., based on Decision Trees, have been proposed, but one
of the main limitations of these techniques is their training cost. To overcome
this limitation, we propose a new population-based method, called Social
Interpretable RL (SIRL), inspired by social learning principles, to improve
learning efficiency. Our method mimics a social learning process, where each
agent in a group learns to solve a given task based both on its own individual
experience as well as the experience acquired together with its peers. Our
approach is divided into two phases. In the \emph{collaborative phase}, all the
agents in the population interact with a shared instance of the environment,
where each agent observes the state and independently proposes an action. Then,
voting is performed to choose the action that will actually be performed in the
environment. In the \emph{individual phase}, each agent refines its individual
performance by interacting with its own instance of the environment. This
mechanism makes the agents experience a larger number of episodes while
simultaneously reducing the computational cost of the process. Our results on
six well-known benchmarks show that SIRL reaches state-of-the-art performance
w.r.t. the alternative interpretable methods from the literature.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15481" title="Abstract">arXiv:2401.15481</a> [<a href="/pdf/2401.15481" title="Download PDF">pdf</a>, <a href="/format/2401.15481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BugsInPy: A Database of Existing Bugs in Python Programs to Enable  Controlled Testing and Debugging Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Widyasari%2C+R">Ratnadira Widyasari</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+S+Q">Sheng Qin Sim</a>, 
<a href="/search/cs?searchtype=author&query=Lok%2C+C">Camellia Lok</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Haodi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+J">Jack Phan</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+Q">Qijin Tay</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Constance Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wee%2C+F">Fiona Wee</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J+E">Jodie Ethelda Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yieh%2C+Y">Yuheng Yieh</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+B">Brian Goh</a>, 
<a href="/search/cs?searchtype=author&query=Thung%2C+F">Ferdian Thung</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H+J">Hong Jin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Thong Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Ouh%2C+E+L">Eng Lieh Ouh</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 28th ACM Joint Meeting on European Software
  Engineering Conference and Symposium on the Foundations of Software
  Engineering (2020) 1556-1560
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The 2019 edition of Stack Overflow developer survey highlights that, for the
first time, Python outperformed Java in terms of popularity. The gap between
Python and Java further widened in the 2020 edition of the survey.
Unfortunately, despite the rapid increase in Python's popularity, there are not
many testing and debugging tools that are designed for Python. This is in stark
contrast with the abundance of testing and debugging tools for Java. Thus,
there is a need to push research on tools that can help Python developers. One
factor that contributed to the rapid growth of Java testing and debugging tools
is the availability of benchmarks. A popular benchmark is the Defects4J
benchmark; its initial version contained 357 real bugs from 5 real-world Java
programs. Each bug comes with a test suite that can expose the bug. Defects4J
has been used by hundreds of testing and debugging studies and has helped to
push the frontier of research in these directions. In this project, inspired by
Defects4J, we create another benchmark database and tool that contain 493 real
bugs from 17 real-world Python programs. We hope our benchmark can help
catalyze future work on testing and debugging tools that work on Python
programs.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15482" title="Abstract">arXiv:2401.15482</a> [<a href="/pdf/2401.15482" title="Download PDF">pdf</a>, <a href="/format/2401.15482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Solution Operator Learning for Mean-Field Games via  Sampling-Invariant Parametrizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Han Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+R">Rongjie Lai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC)

</div>
<p class="mathjax">Recent advances in deep learning has witnessed many innovative frameworks
that solve high dimensional mean-field games (MFG) accurately and efficiently.
These methods, however, are restricted to solving single-instance MFG and
demands extensive computational time per instance, limiting practicality. To
overcome this, we develop a novel framework to learn the MFG solution operator.
Our model takes a MFG instances as input and output their solutions with one
forward pass. To ensure the proposed parametrization is well-suited for
operator learning, we introduce and prove the notion of sampling invariance for
our model, establishing its convergence to a continuous operator in the
sampling limit. Our method features two key advantages. First, it is
discretization-free, making it particularly suitable for learning operators of
high-dimensional MFGs. Secondly, it can be trained without the need for access
to supervised labels, significantly reducing the computational overhead
associated with creating training datasets in existing operator learning
methods. We test our framework on synthetic and realistic datasets with varying
complexity and dimensionality to substantiate its robustness.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15484" title="Abstract">arXiv:2401.15484</a> [<a href="/pdf/2401.15484" title="Download PDF">pdf</a>, <a href="/format/2401.15484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R$\times$R: Rapid eXploration for Reinforcement Learning via  Sampling-based Reset Distributions and Imitation Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandate%2C+G">Gagan Khandate</a>, 
<a href="/search/cs?searchtype=author&query=Saidi%2C+T+L">Tristan L. Saidi</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+S">Siqi Shang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+E+T">Eric T. Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dennis%2C+S">Seth Dennis</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+J">Johnson Adams</a>, 
<a href="/search/cs?searchtype=author&query=Ciocarlie%2C+M">Matei Ciocarlie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures, submitted to Autonomous Robots, RSS 2023 Special Issue. arXiv admin note: substantial text overlap with <a href="/abs/2303.03486">arXiv:2303.03486</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a method for enabling Reinforcement Learning of motor control
policies for complex skills such as dexterous manipulation. We posit that a key
difficulty for training such policies is the difficulty of exploring the
problem state space, as the accessible and useful regions of this space form a
complex structure along manifolds of the original high-dimensional state space.
This work presents a method to enable and support exploration with
Sampling-based Planning. We use a generally applicable non-holonomic
Rapidly-exploring Random Trees algorithm and present multiple methods to use
the resulting structure to bootstrap model-free Reinforcement Learning. Our
method is effective at learning various challenging dexterous motor control
skills of higher difficulty than previously shown. In particular, we achieve
dexterous in-hand manipulation of complex objects while simultaneously securing
the object without the use of passive support surfaces. These policies also
transfer effectively to real robots. A number of example videos can also be
found on the project website: https://sbrl.cs.columbia.edu
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15486" title="Abstract">arXiv:2401.15486</a> [<a href="/pdf/2401.15486" title="Download PDF">pdf</a>, <a href="/ps/2401.15486" title="Download PostScript">ps</a>, <a href="/format/2401.15486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pulse-Width Modulation Technique With Harmonic Injection in the  Modulating Wave and Discontinuous Frequency Modulation for the Carrier Wave  for Multilevel Inverters: An Application to the Reduction of Acoustic Noise  in Induction Motors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ruiz-Gonzalez%2C+A">Antonio Ruiz-Gonzalez</a>, 
<a href="/search/eess?searchtype=author&query=Heredia-Larrubia%2C+J">Juan-Ramon Heredia-Larrubia</a>, 
<a href="/search/eess?searchtype=author&query=Meco-Gutierrez%2C+M+J">Mario J. Meco-Gutierrez</a>, 
<a href="/search/eess?searchtype=author&query=Perez-Hidalgo%2C+F">Francisco-M. Perez-Hidalgo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, vol. 11, pp. 40579-40590, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">An implementation of a harmonic injection pulse width modulation
frequency-modulated triangular carrier (HIPWM-FMTC) control strategy applied to
a multilevel power inverter feeding an asynchronous motor is presented. The aim
was to justify the reduction in acoustic noise emitted by the machine compared
with other strategies in the technical literature. In addition, we checked how
the THD at the inverter output was reduced compared to the other control
techniques used as a reference. The proposed strategy is based on frequency
modulation of the triangular carrier. The main advantage of the proposed method
is that only one control parameter is required for modifying the electrical
spectrum. Therefore, the mechanical natural frequencies and spatial harmonics
of the machine can be avoided, and acoustic noise can be reduced. The
effectiveness of the technique was demonstrated after laboratory validation by
comparing the acoustic results for a 1 kW motor. The results obtained from the
laboratory tests are presented and compared with those of other acoustic
measurements using different PWM strategies.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15487" title="Abstract">arXiv:2401.15487</a> [<a href="/pdf/2401.15487" title="Download PDF">pdf</a>, <a href="/ps/2401.15487" title="Download PostScript">ps</a>, <a href="/format/2401.15487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence: Arguments for Catastrophic Risk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bales%2C+A">Adam Bales</a>, 
<a href="/search/cs?searchtype=author&query=D%27Alessandro%2C+W">William D&#x27;Alessandro</a>, 
<a href="/search/cs?searchtype=author&query=Kirk-Giannini%2C+C+D">Cameron Domenico Kirk-Giannini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent progress in artificial intelligence (AI) has drawn attention to the
technology's transformative potential, including what some see as its prospects
for causing large-scale harm. We review two influential arguments purporting to
show how AI could pose catastrophic risks. The first argument -- the Problem of
Power-Seeking -- claims that, under certain assumptions, advanced AI systems
are likely to engage in dangerous power-seeking behavior in pursuit of their
goals. We review reasons for thinking that AI systems might seek power, that
they might obtain it, that this could lead to catastrophe, and that we might
build and deploy such systems anyway. The second argument claims that the
development of human-level AI will unlock rapid further progress, culminating
in AI systems far more capable than any human -- this is the Singularity
Hypothesis. Power-seeking behavior on the part of such systems might be
particularly dangerous. We discuss a variety of objections to both arguments
and conclude by assessing the state of the debate.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15489" title="Abstract">arXiv:2401.15489</a> [<a href="/pdf/2401.15489" title="Download PDF">pdf</a>, <a href="/format/2401.15489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Privileged Multimodal Information for Expression Recognition  using Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aslam%2C+M+H">Muhammad Haseeb Aslam</a>, 
<a href="/search/cs?searchtype=author&query=Zeeshan%2C+M+O">Muhammad Osama Zeeshan</a>, 
<a href="/search/cs?searchtype=author&query=Belharbi%2C+S">Soufiane Belharbi</a>, 
<a href="/search/cs?searchtype=author&query=Pedersoli%2C+M">Marco Pedersoli</a>, 
<a href="/search/cs?searchtype=author&query=Koerich%2C+A">Alessandro Koerich</a>, 
<a href="/search/cs?searchtype=author&query=Bacon%2C+S">Simon Bacon</a>, 
<a href="/search/cs?searchtype=author&query=Granger%2C+E">Eric Granger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multimodal affect recognition models have reached remarkable performance in
the lab environment due to their ability to model complementary and redundant
semantic information. However, these models struggle in the wild, mainly
because of the unavailability or quality of modalities used for training. In
practice, only a subset of the training-time modalities may be available at
test time. Learning with privileged information (PI) enables deep learning
models (DL) to exploit data from additional modalities only available during
training. State-of-the-art knowledge distillation (KD) methods have been
proposed to distill multiple teacher models (each trained on a modality) to a
common student model. These privileged KD methods typically utilize
point-to-point matching and have no explicit mechanism to capture the
structural information in the teacher representation space formed by
introducing the privileged modality. We argue that encoding this same structure
in the student space may lead to enhanced student performance. This paper
introduces a new structural KD mechanism based on optimal transport (OT), where
entropy-regularized OT distills the structural dark knowledge. Privileged KD
with OT (PKDOT) method captures the local structures in the multimodal teacher
representation by calculating a cosine similarity matrix and selects the top-k
anchors to allow for sparse OT solutions, resulting in a more stable
distillation process. Experiments were performed on two different problems:
pain estimation on the Biovid dataset (ordinal classification) and
arousal-valance prediction on the Affwild2 dataset (regression). Results show
that the proposed method can outperform state-of-the-art privileged KD methods
on these problems. The diversity of different modalities and fusion
architectures indicates that the proposed PKDOT method is modality and
model-agnostic.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15492" title="Abstract">arXiv:2401.15492</a> [<a href="/pdf/2401.15492" title="Download PDF">pdf</a>, <a href="/format/2401.15492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cholesky-like Preconditioner for Hodge Laplacians via Heavy Collapsible  Subcomplex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Savostianov%2C+A">Anton Savostianov</a>, 
<a href="/search/math?searchtype=author&query=Tudisco%2C+F">Francesco Tudisco</a>, 
<a href="/search/math?searchtype=author&query=Guglielmi%2C+N">Nicola Guglielmi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Techniques based on $k$-th order Hodge Laplacian operators $L_k$ are widely
used to describe the topology as well as the governing dynamics of high-order
systems modeled as simplicial complexes. In all of them, it is required to
solve a number of least square problems with $L_k$ as coefficient matrix, for
example in order to compute some portions of the spectrum or integrate the
dynamical system. In this work, we introduce the notion of optimal collapsible
subcomplex and we present a fast combinatorial algorithm for the computation of
a sparse Cholesky-like preconditioner for $L_k$ that exploits the topological
structure of the simplicial complex. The performance of the preconditioner is
tested for conjugate gradient method for least square problems (CGLS) on a
variety of simplicial complexes with different dimensions and edge densities.
We show that, for sparse simplicial complexes, the new preconditioner reduces
significantly the condition number of $L_k$ and performs better than the
standard incomplete Cholesky factorization.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15495" title="Abstract">arXiv:2401.15495</a> [<a href="/pdf/2401.15495" title="Download PDF">pdf</a>, <a href="/ps/2401.15495" title="Download PostScript">ps</a>, <a href="/format/2401.15495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nobody Expects a Differential Equation: Minimum Energy-Per-Bit for the  Gaussian Relay Channel with Rank-1 Linear Relaying
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosut%2C+O">Oliver Kosut</a>, 
<a href="/search/cs?searchtype=author&query=Effros%2C+M">Michelle Effros</a>, 
<a href="/search/cs?searchtype=author&query=Langberg%2C+M">Michael Langberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE International Symposium on Information Theory, 2024. 13 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Motivated by the design of low-complexity low-power coding solutions for the
Gaussian relay channel, this work presents an upper bound on the minimum
energy-per-bit achievable on the Gaussian relay channel using rank-1 linear
relaying. Our study addresses high-dimensional relay codes and presents bounds
that outperform prior known bounds using 2-dimensional schemes. A novelty of
our analysis ties the optimization problem at hand to the solution of a certain
differential equation which, in turn, leads to a low energy-per-bit achievable
scheme.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15496" title="Abstract">arXiv:2401.15496</a> [<a href="/pdf/2401.15496" title="Download PDF">pdf</a>, <a href="/format/2401.15496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Baichuan2-Sum: Instruction Finetune Baichuan2-7B Model for Dialogue  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jianfei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yancan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+Y">Yimin Ou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hanyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yiyong Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) like Llama, Baichuan and Bloom models show
remarkable ability with instruction fine-tuning in many natural language tasks.
Nevertheless, for the dialogue summarization task, which aims to generate
summaries for different roles in dialogue, most of the state-of-the-art methods
conduct on small models (e.g Bart and Bert). Existing methods try to add task
specified optimization on small models like adding global-local centrality
score to models. In this paper, we propose an instruction fine-tuning model:
Baichuan2-Sum, for role-oriented diaglouge summarization. By setting different
instructions for different roles, the model can learn from the dialogue
interactions and output the expected summaries. Furthermore, we applied NEFTune
technique to add suitable noise during training to improve the results. The
experiments demonstrate that the proposed model achieves the new
state-of-the-art results on two public dialogue summarization datasets: CSDS
and SAMSUM. We release our model and related codes to facilitate future studies
on dialogue summarization task.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15497" title="Abstract">arXiv:2401.15497</a> [<a href="/pdf/2401.15497" title="Download PDF">pdf</a>, <a href="/format/2401.15497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foregrounding Artist Opinions: A Survey Study on Transparency,  Ownership, and Fairness in AI Generative Art
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lovato%2C+J">Juniper Lovato</a>, 
<a href="/search/cs?searchtype=author&query=Zimmerman%2C+J">Julia Zimmerman</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+I">Isabelle Smith</a>, 
<a href="/search/cs?searchtype=author&query=Dodds%2C+P">Peter Dodds</a>, 
<a href="/search/cs?searchtype=author&query=Karson%2C+J">Jennifer Karson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Generative Artificial Intelligence (AI) tools are used to create art-like
outputs and aid in the creative process. While these tools have potential
benefits for artists, they also have the potential to harm the art workforce
and infringe upon artistic and intellectual property rights. Without explicit
consent from artists, Generative AI creators scrape artists' digital work to
train Generative AI models and produce art-like model outputs at scale. These
outputs are now being used to compete with human artists in the marketplace as
well as being used by some artists in their generative processes to create art.
We surveyed 459 artists to investigate the tension between artists' opinions on
Generative AI art's potential utility and harm. This study surveys artists'
opinions on the utility and threat of Generative AI art models, fair practices
in the disclosure of artistic works in AI art training models, ownership and
rights of AI art derivatives, and fair compensation. We find that artists, by
and large, think that model creators should be required to disclose in detail
what art and images they use to train their AI models. We also find that
artists' opinions vary by professional status and practice, demographics,
whether they have purchased art, and familiarity with and use of Generative AI.
We hope the results of this work will further more meaningful collaboration and
alignment between the art community and Generative AI researchers and
developers.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15498" title="Abstract">arXiv:2401.15498</a> [<a href="/pdf/2401.15498" title="Download PDF">pdf</a>, <a href="/format/2401.15498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do We Need Language-Specific Fact-Checking Models? The Case of Chinese
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Caiqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhijiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Vlachos%2C+A">Andreas Vlachos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper investigates the potential benefits of language-specific
fact-checking models, focusing on the case of Chinese. We demonstrate the
limitations of methods such as translating Chinese claims and evidence into
English or directly using multilingual large language models (e.g. GPT4),
highlighting the need for language-specific systems. We further develop a
state-of-the-art Chinese fact-checking system that, in contrast to previous
approaches which treat evidence selection as a pairwise sentence classification
task, considers the context of sentences. We also create an adversarial dataset
to identify biases in our model, and while they are present as in English
language datasets and models, they are often specific to the Chinese culture.
Our study emphasizes the importance of language-specific fact-checking models
to effectively combat misinformation.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15499" title="Abstract">arXiv:2401.15499</a> [<a href="/pdf/2401.15499" title="Download PDF">pdf</a>, <a href="/format/2401.15499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Properties of cosine based bias scores for word embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+S">Sarah Schr&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+A">Alexander Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Hinder%2C+F">Fabian Hinder</a>, 
<a href="/search/cs?searchtype=author&query=Hammer%2C+B">Barbara Hammer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Plenty of works have brought social biases in language models to attention
and proposed methods to detect such biases. As a result, the literature
contains a great deal of different bias tests and scores, each introduced with
the premise to uncover yet more biases that other scores fail to detect. What
severely lacks in the literature, however, are comparative studies that analyse
such bias scores and help researchers to understand the benefits or limitations
of the existing methods. In this work, we aim to close this gap for cosine
based bias scores. By building on a geometric definition of bias, we propose
requirements for bias scores to be considered meaningful for quantifying
biases. Furthermore, we formally analyze cosine based scores from the
literature with regard to these requirements. We underline these findings with
experiments to show that the bias scores' limitations have an impact in the
application case.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15500" title="Abstract">arXiv:2401.15500</a> [<a href="/pdf/2401.15500" title="Download PDF">pdf</a>, <a href="/ps/2401.15500" title="Download PostScript">ps</a>, <a href="/format/2401.15500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Estimation of the False Positive Rate of the Bayes Binary  Classifier via Soft Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+M">Minoh Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Cardone%2C+M">Martina Cardone</a>, 
<a href="/search/cs?searchtype=author&query=Dytso%2C+A">Alex Dytso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">Classification is a fundamental task in many applications on which
data-driven methods have shown outstanding performances. However, it is
challenging to determine whether such methods have achieved the optimal
performance. This is mainly because the best achievable performance is
typically unknown and hence, effectively estimating it is of prime importance.
In this paper, we consider binary classification problems and we propose an
estimator for the false positive rate (FPR) of the Bayes classifier, that is,
the optimal classifier with respect to accuracy, from a given dataset. Our
method utilizes soft labels, or real-valued labels, which are gaining
significant traction thanks to their properties. We thoroughly examine various
theoretical properties of our estimator, including its consistency,
unbiasedness, rate of convergence, and variance. To enhance the versatility of
our estimator beyond soft labels, we also consider noisy labels, which
encompass binary labels. For noisy labels, we develop effective FPR estimators
by leveraging a denoising technique and the Nadaraya-Watson estimator. Due to
the symmetry of the problem, our results can be readily applied to estimate the
false negative rate of the Bayes classifier.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15501" title="Abstract">arXiv:2401.15501</a> [<a href="/pdf/2401.15501" title="Download PDF">pdf</a>, <a href="/format/2401.15501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FloodLense: A Framework for ChatGPT-based Real-time Flood Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumbam%2C+P+R">Pranath Reddy Kumbam</a>, 
<a href="/search/cs?searchtype=author&query=Vejre%2C+K+M">Kshitij Maruti Vejre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study addresses the vital issue of real-time flood detection and
management. It innovatively combines advanced deep learning models with Large
language models (LLM), enhancing flood monitoring and response capabilities.
This approach addresses the limitations of current methods by offering a more
accurate, versatile, user-friendly and accessible solution. The integration of
UNet, RDN, and ViT models with natural language processing significantly
improves flood area detection in diverse environments, including using aerial
and satellite imagery. The experimental evaluation demonstrates the models'
efficacy in accurately identifying and mapping flood zones, showcasing the
project's potential in transforming environmental monitoring and disaster
management fields.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15503" title="Abstract">arXiv:2401.15503</a> [<a href="/pdf/2401.15503" title="Download PDF">pdf</a>, <a href="/format/2401.15503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dawn of the Dead(line Misses): Impact of Job Dismiss on the Deadline  Miss Rate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian-Jia Chen</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnzel%2C+M">Mario G&#xfc;nzel</a>, 
<a href="/search/cs?searchtype=author&query=Bella%2C+P">Peter Bella</a>, 
<a href="/search/cs?searchtype=author&query=von+der+Br%C3%BCggen%2C+G">Georg von der Br&#xfc;ggen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kuan-Hsun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
<p class="mathjax">Occasional deadline misses are acceptable for soft real-time systems.
Quantifying probabilistic and deterministic characteristics of deadline misses
is therefore essential to ensure that deadline misses indeed happen only
occasionally. This is supported by recent research activities on probabilistic
worst-case execution time, worst-case deadline failure probability, the maximum
number of deadline misses, upper bounds on the deadline miss probability, and
the deadline miss rate. This paper focuses on the deadline miss rate of a
periodic soft real-time task in the long run. Our model assumes that this soft
real-time task has an arbitrary relative deadline and that a job can still be
executed after a deadline-miss until a dismiss point. This model generalizes
the existing models that either dismiss a job immediately after its deadline
miss or never dismiss a job. We provide mathematical notation on the
convergence of the deadline miss rate in the long run and essential properties
to calculate the deadline miss rate. Specifically, we use a Markov chain to
model the execution behavior of a periodic soft real-time task. We present the
required ergodicity property to ensure that the deadline miss rate in the long
run is described by a stationary distribution.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15507" title="Abstract">arXiv:2401.15507</a> [<a href="/pdf/2401.15507" title="Download PDF">pdf</a>, <a href="/format/2401.15507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;May I Speak?&quot;: Multi-modal Attention Guidance in Social VR Group  Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Geonsun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D+Y">Dae Yeol Lee</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+G">Guan-Ming Su</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this paper, we present a novel multi-modal attention guidance method
designed to address the challenges of turn-taking dynamics in meetings and
enhance group conversations within virtual reality (VR) environments.
Recognizing the difficulties posed by a confined field of view and the absence
of detailed gesture tracking in VR, our proposed method aims to mitigate the
challenges of noticing new speakers attempting to join the conversation. This
approach tailors attention guidance, providing a nuanced experience for highly
engaged participants while offering subtler cues for those less engaged,
thereby enriching the overall meeting dynamics. Through group interview
studies, we gathered insights to guide our design, resulting in a prototype
that employs "light" as a diegetic guidance mechanism, complemented by spatial
audio. The combination creates an intuitive and immersive meeting environment,
effectively directing users' attention to new speakers. An evaluation study,
comparing our method to state-of-the-art attention guidance approaches,
demonstrated significantly faster response times (p &lt; 0.001), heightened
perceived conversation satisfaction (p &lt; 0.001), and preference (p &lt; 0.001) for
our method. Our findings contribute to the understanding of design implications
for VR social attention guidance, opening avenues for future research and
development.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15508" title="Abstract">arXiv:2401.15508</a> [<a href="/pdf/2401.15508" title="Download PDF">pdf</a>, <a href="/format/2401.15508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proto-MPC: An Encoder-Prototype-Decoder Approach for Quadrotor Control  in Challenging Winds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuliang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Hovakimyan%2C+N">Naira Hovakimyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Quadrotors are increasingly used in the evolving field of aerial robotics for
their agility and mechanical simplicity. However, inherent uncertainties, such
as aerodynamic effects coupled with quadrotors' operation in dynamically
changing environments, pose significant challenges for traditional, nominal
model-based control designs. We propose a multi-task meta-learning method
called Encoder-Prototype-Decoder (EPD), which has the advantage of effectively
balancing shared and distinctive representations across diverse training tasks.
Subsequently, we integrate the EPD model into a model predictive control
problem (Proto-MPC) to enhance the quadrotor's ability to adapt and operate
across a spectrum of dynamically changing tasks with an efficient online
implementation. We validate the proposed method in simulations, which
demonstrates Proto-MPC's robust performance in trajectory tracking of a
quadrotor being subject to static and spatially varying side winds.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15509" title="Abstract">arXiv:2401.15509</a> [<a href="/pdf/2401.15509" title="Download PDF">pdf</a>, <a href="/format/2401.15509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style-News: Incorporating Stylized News Generation and Adversarial  Verification for Neural Fake News Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei-Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yu-Chieh Chang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wen-Chih Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024 Main Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">With the improvements in generative models, the issues of producing
hallucinations in various domains (e.g., law, writing) have been brought to
people's attention due to concerns about misinformation. In this paper, we
focus on neural fake news, which refers to content generated by neural networks
aiming to mimic the style of real news to deceive people. To prevent harmful
disinformation spreading fallaciously from malicious social media (e.g.,
content farms), we propose a novel verification framework, Style-News, using
publisher metadata to imply a publisher's template with the corresponding text
types, political stance, and credibility. Based on threat modeling aspects, a
style-aware neural news generator is introduced as an adversary for generating
news content conditioning for a specific publisher, and style and source
discriminators are trained to defend against this attack by identifying which
publisher the style corresponds with, and discriminating whether the source of
the given news is human-written or machine-generated. To evaluate the quality
of the generated content, we integrate various dimensional metrics (language
fluency, content preservation, and style adherence) and demonstrate that
Style-News significantly outperforms the previous approaches by a margin of
0.35 for fluency, 15.24 for content, and 0.38 for style at most. Moreover, our
discriminative model outperforms state-of-the-art baselines in terms of
publisher prediction (up to 4.64%) and neural fake news detection (+6.94%
$\sim$ 31.72%).
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15510" title="Abstract">arXiv:2401.15510</a> [<a href="/pdf/2401.15510" title="Download PDF">pdf</a>, <a href="/format/2401.15510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocuBits: VR Document Decomposition for Procedural Task Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Geonsun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Healey%2C+J">Jennifer Healey</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Reading monolithic instructional documents in VR is often challenging,
especially when tasks are collaborative. Here we present DocuBits, a novel
method for transforming monolithic documents into small, interactive
instructional elements. Our approach allows users to:(i) create instructional
elements (ii) position them within VR and (iii) use them to monitor and share
progress in a multi-user VR learning environment. We describe our design
methodology as well as two user studies evaluating how both individual users
and pairs of users interact with DocuBits compared to monolithic documents
while performing a chemistry lab task. Our analysis shows that, for both
studies, DocuBits had substantially higher usability, while decreasing
perceived workload (p &lt; 0.001$. Our collaborative study showed that
participants perceived higher social presence, collaborator awareness as well
as immersion and presence (p &lt; 0.001). We discuss our insights for using
text-based instructions to support enhanced collaboration in VR environments.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15511" title="Abstract">arXiv:2401.15511</a> [<a href="/pdf/2401.15511" title="Download PDF">pdf</a>, <a href="/ps/2401.15511" title="Download PostScript">ps</a>, <a href="/format/2401.15511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Resilient Interval Observer Synthesis for Nonlinear  Discrete-Time Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khajenejad%2C+M">Mohammad Khajenejad</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+S">Scott Brown</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+S">Sonia Martinez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted as a journal submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper introduces a novel recursive distributed estimation algorithm
aimed at synthesizing input and state interval observers for nonlinear
bounded-error discrete-time multi-agent systems. The considered systems have
sensors and actuators that are susceptible to unknown or adversarial inputs. To
solve this problem, we first identify conditions that allow agents to obtain
nonlinear bounded-error equations characterizing the input. Then, we propose a
distributed interval-valued observer that is guaranteed to contain the
disturbance and system states. To do this, we first detail a gain design
procedure that uses global problem data to minimize an upper bound on the
$\ell_1$ norm of the observer error. We then propose a gain design approach
that does not require global information, using only values that are local to
each agent. The second method improves on the computational tractability of the
first, at the expense of some added conservatism. Further, we discuss some
possible ways of extending the results to a broader class of systems. We
conclude by demonstrating our observer on two examples. The first is a unicycle
system, for which we apply the first gain design method. The second is a
145-bus power system, which showcases the benefits of the second method, due to
the first approach being intractable for systems with high dimensional state
spaces.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15517" title="Abstract">arXiv:2401.15517</a> [<a href="/pdf/2401.15517" title="Download PDF">pdf</a>, <a href="/ps/2401.15517" title="Download PostScript">ps</a>, <a href="/format/2401.15517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signal Recovery From Product of Two Vandermonde Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapetanovic%2C+D">Dzevdan Kapetanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this work, we present some new results for compressed sensing and phase
retrieval. For compressed sensing, it is shown that if the unknown
$n$-dimensional vector can be expressed as a linear combination of $s$ unknown
Vandermonde vectors (with Fourier vectors as a special case) and the
measurement matrix is a Vandermonde matrix, exact recovery of the vector with
$2s$ measurements and $O(\mathrm{poly}(s))$ complexity is possible when $n \geq
2s$. From these results, a measurement matrix is constructed from which it is
possible to recover $s$-sparse $n$-dimensional vectors for $n \geq 2s$ with as
few as $2s$ measurements and with a recovery algorithm of $O(\mathrm{poly}(s))$
complexity. In the second part of the work, these results are extended to the
challenging problem of phase retrieval. The most significant discovery in this
direction is that if the unknown $n$-dimensional vector is composed of $s$
frequencies with at least one being non-harmonic, $n \geq 4s - 1$ and we take
at least $8s-3$ Fourier measurements, there are, remarkably, only two possible
vectors producing the observed measurement values and they are easily
obtainable from each other. The two vectors can be found by an algorithm with
only $O(\mathrm{poly}(s))$ complexity. An immediate application of the new
result is construction of a measurement matrix from which it is possible to
recover all $s$-sparse $n$-dimensional signals (up to a global phase) from
$O(s)$ magnitude-only measurements and $O(\mathrm{poly}(s))$ recovery
complexity when $n \geq 4s - 1$.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15520" title="Abstract">arXiv:2401.15520</a> [<a href="/pdf/2401.15520" title="Download PDF">pdf</a>, <a href="/ps/2401.15520" title="Download PostScript">ps</a>, <a href="/format/2401.15520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oracle-Efficient Hybrid Online Learning with Unknown Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Changlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sima%2C+J">Jin Sima</a>, 
<a href="/search/cs?searchtype=author&query=Szpankowski%2C+W">Wojciech Szpankowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the problem of oracle-efficient hybrid online learning when the
features are generated by an unknown i.i.d. process and the labels are
generated adversarially. Assuming access to an (offline) ERM oracle, we show
that there exists a computationally efficient online predictor that achieves a
regret upper bounded by $\tilde{O}(T^{\frac{3}{4}})$ for a finite-VC class, and
upper bounded by $\tilde{O}(T^{\frac{p+1}{p+2}})$ for a class with $\alpha$
fat-shattering dimension $\alpha^{-p}$. This provides the first known
oracle-efficient sublinear regret bounds for hybrid online learning with an
unknown feature generation process. In particular, it confirms a conjecture of
Lazaric and Munos (JCSS 2012). We then extend our result to the scenario of
shifting distributions with $K$ changes, yielding a regret of order
$\tilde{O}(T^{\frac{4}{5}}K^{\frac{1}{5}})$. Finally, we establish a regret of
$\tilde{O}((K^{\frac{2}{3}}(\log|\mathcal{H}|)^{\frac{1}{3}}+K)\cdot
T^{\frac{4}{5}})$ for the contextual $K$-armed bandits with a finite policy set
$\mathcal{H}$, i.i.d. generated contexts from an unknown distribution, and
adversarially generated costs.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15522" title="Abstract">arXiv:2401.15522</a> [<a href="/pdf/2401.15522" title="Download PDF">pdf</a>, <a href="/format/2401.15522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New time domain decomposition methods for parabolic optimal control  problems II: Neumann-Neumann algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gander%2C+M+J">Martin Jakob Gander</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+L">Liu-Di Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We present new Neumann-Neumann algorithms based on a time domain
decomposition applied to unconstrained parabolic optimal control problems.
After a spatial semi-discretization, the Lagrange multiplier approach provides
a coupled forward-backward optimality system, which can be solved using a time
domain decomposition. Due to the forward-backward structure of the optimality
system, nine variants can be found for the Neumann-Neumann algorithms. We
analyze their convergence behavior and determine the optimal relaxation
parameter for each algorithm. Our analysis reveals that the most natural
algorithms are actually only good smoothers, and there are better choices which
lead to efficient solvers. We illustrate our analysis with numerical
experiments.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15523" title="Abstract">arXiv:2401.15523</a> [<a href="/pdf/2401.15523" title="Download PDF">pdf</a>, <a href="/format/2401.15523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance-Based Biped Control using a Consumer Depth Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yoonsang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+T">Taesoo Kwon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Eurographics 2017
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Graphics Forum (Eurographics 2017), Volume 36 Issue 2,
  387-395, May 2017
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">We present a technique for controlling physically simulated characters using
user inputs from an off-the-shelf depth camera. Our controller takes a
real-time stream of user poses as input, and simulates a stream of target poses
of a biped based on it. The simulated biped mimics the user's actions while
moving forward at a modest speed and maintaining balance. The controller is
parameterized over a set of modulated reference motions that aims to cover the
range of possible user actions. For real-time simulation, the best set of
control parameters for the current input pose is chosen from the parameterized
sets of pre-computed control parameters via a regression method. By applying
the chosen parameters at each moment, the simulated biped can imitate a range
of user actions while walking in various interactive scenarios.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15525" title="Abstract">arXiv:2401.15525</a> [<a href="/pdf/2401.15525" title="Download PDF">pdf</a>, <a href="/format/2401.15525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Interval Energy-Reserve Co-Optimization with SoC-Dependent Bids  from Battery Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Cong Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Siying Li</a>, 
<a href="/search/eess?searchtype=author&query=Tong%2C+L">Lang Tong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We consider the problem of co-optimized energy-reserve market clearing with
state-of-charge (SoC) dependent bids from battery storage participants. While
SoC-dependent bidding accurately captures storage's degradation and opportunity
costs, such bids result in a non-convex optimization in the market clearing
process. More challenging is the regulation reserve capacity clearing, where
the SoC-dependent cost is uncertain as it depends on the unknown regulation
trajectories ex-post of the market clearing. Addressing the nonconvexity and
uncertainty in a multi-interval co-optimized real-time energy-reserve market,
we introduce a simple restriction on the SoC-dependent bids along with a robust
optimization formulation, transforming the non-convex market clearing under
uncertainty into a standard convex piece-wise linear program and making it
possible for large-scale storage integration. Under reasonable assumptions, we
show that SoC-dependent bids yield higher profit for storage participants than
that from SoC-independent bids. Numerical simulations demonstrate a 28%-150%
profit increase of the proposed SoC-dependent bids compared with the
SoC-independent counterpart.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15526" title="Abstract">arXiv:2401.15526</a> [<a href="/pdf/2401.15526" title="Download PDF">pdf</a>, <a href="/format/2401.15526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Transferability of a Foundation Model for Fundus Images:  Application to Hypertensive Retinopathy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva-Rodriguez%2C+J">Julio Silva-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Chelbi%2C+J">Jihed Chelbi</a>, 
<a href="/search/cs?searchtype=author&query=Kabir%2C+W">Waziha Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Chakor%2C+H">Hadi Chakor</a>, 
<a href="/search/cs?searchtype=author&query=Dolz%2C+J">Jose Dolz</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+I+B">Ismail Ben Ayed</a>, 
<a href="/search/cs?searchtype=author&query=Kobbi%2C+R">Riadh Kobbi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CGI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Using deep learning models pre-trained on Imagenet is the traditional
solution for medical image classification to deal with data scarcity.
Nevertheless, relevant literature supports that this strategy may offer limited
gains due to the high dissimilarity between domains. Currently, the paradigm of
adapting domain-specialized foundation models is proving to be a promising
alternative. However, how to perform such knowledge transfer, and the benefits
and limitations it presents, are under study. The CGI-HRDC challenge for
Hypertensive Retinopathy diagnosis on fundus images introduces an appealing
opportunity to evaluate the transferability of a recently released
vision-language foundation model of the retina, FLAIR. In this work, we explore
the potential of using FLAIR features as starting point for fundus image
classification, and we compare its performance with regard to Imagenet
initialization on two popular transfer learning methods: Linear Probing (LP)
and Fine-Tuning (FP). Our empirical observations suggest that, in any case, the
use of the traditional strategy provides performance gains. In contrast, direct
transferability from FLAIR model allows gains of 2.5%. When fine-tuning the
whole network, the performance gap increases up to 4%. In this case, we show
that avoiding feature deterioration via LP initialization of the classifier
allows the best re-use of the rich pre-trained features. Although direct
transferability using LP still offers limited performance, we believe that
foundation models such as FLAIR will drive the evolution of deep-learning-based
fundus image analysis.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15529" title="Abstract">arXiv:2401.15529</a> [<a href="/pdf/2401.15529" title="Download PDF">pdf</a>, <a href="/format/2401.15529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Thorough Study of State Leakage Mitigation in Quantum Computing with  One-Time Pad
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chuanqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sikora%2C+J">Jamie Sikora</a>, 
<a href="/search/cs?searchtype=author&query=Szefer%2C+J">Jakub Szefer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures. In Proceedings of the IEEE International Symposium on Hardware Oriented Security and Trust (HOST) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">The ability for users to access quantum computers through the cloud has
increased rapidly in recent years. Despite still being Noisy Intermediate-Scale
Quantum (NISQ) machines, modern quantum computers are now being actively
employed for research and by numerous startups. Quantum algorithms typically
produce probabilistic results, necessitating repeated execution to produce the
desired outcomes. In order for the execution to begin from the specified ground
state each time and for the results of the prior execution not to interfere
with the results of the subsequent execution, the reset mechanism must be
performed between each iteration to effectively reset the qubits. However, due
to noise and errors in quantum computers and specifically these reset
mechanisms, a noisy reset operation may lead to systematic errors in the
overall computation, as well as potential security and privacy vulnerabilities
of information leakage. To counter this issue, we thoroughly examine the state
leakage problem in quantum computing, and then propose a solution by employing
the classical and quantum one-time pads before the reset mechanism to prevent
the state leakage, which works by randomly applying simple gates for each
execution of the circuit. In addition, this work explores conditions under
which the classical one-time pad, which uses fewer resources, is sufficient to
protect state leakage. Finally, we study the role of various errors in state
leakage, by evaluating the degrees of leakage under different error levels of
gate, measurement, and sampling errors. Our findings offer new perspectives on
the design of reset mechanisms and secure quantum computing systems.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15530" title="Abstract">arXiv:2401.15530</a> [<a href="/pdf/2401.15530" title="Download PDF">pdf</a>, <a href="/ps/2401.15530" title="Download PostScript">ps</a>, <a href="/format/2401.15530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Information-Theoretic Analysis of In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H+J">Hong Jun Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Q">Qi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Van+Roy%2C+B">Benjamin Van Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Previous theoretical results pertaining to meta-learning on sequences build
on contrived assumptions and are somewhat convoluted. We introduce new
information-theoretic tools that lead to an elegant and very general
decomposition of error into three components: irreducible error, meta-learning
error, and intra-task error. These tools unify analyses across many
meta-learning challenges. To illustrate, we apply them to establish new results
about in-context learning with transformers. Our theoretical results
characterizes how error decays in both the number of training sequences and
sequence lengths. Our results are very general; for example, they avoid
contrived mixing time assumptions made by all prior results that establish
decay of error with sequence length.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15532" title="Abstract">arXiv:2401.15532</a> [<a href="/pdf/2401.15532" title="Download PDF">pdf</a>, <a href="/format/2401.15532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byte Pair Encoding Is All You Need For Automatic Bengali Speech  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samin%2C+A+M">Ahnaf Mozib Samin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under-review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Byte pair encoding (BPE) emerges as an effective tokenization method for
tackling the out-of-vocabulary (OOV) challenge in various natural language and
speech processing tasks. Recent research highlights the dependency of BPE
subword tokenization's efficacy on the morphological nature of the language,
particularly in languages rich in inflectional morphology, where fewer BPE
merges suffice for generating highly productive tokens. Motivated by this, our
study empirically identifies the optimal number of BPE tokens for Bengali, a
language known for its morphological complexity, thus enhancing
out-of-distribution automatic speech recognition (ASR) performance.
Experimental evaluation reveals that an excessively high number of BPE tokens
can lead to overfitting, while approximately 500-1000 tokens result in superior
OOV performance. Furthermore, we conduct a comparative analysis of BPE with
character-based and unigram-based tokenization methods. By introducing BPE
tokenization to Bengali ASR, we achieve a substantial reduction in the word
error rate (WER) from 66.44% in our character-based baseline system to 63.80%
on the LB-ASRTD eval set and from 46.34% to 42.80% on the SHRUTI eval set, both
of which include out-of-distribution data.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15534" title="Abstract">arXiv:2401.15534</a> [<a href="/pdf/2401.15534" title="Download PDF">pdf</a>, <a href="/ps/2401.15534" title="Download PostScript">ps</a>, <a href="/format/2401.15534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRYSTALS-Kyber With Lattice Quantizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuiyin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sakzad%2C+A">Amin Sakzad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages,6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Module Learning with Errors (M-LWE) based key reconciliation mechanisms (KRM)
can be viewed as quantizing an M-LWE sample according to a lattice codebook.
This paper describes a generic M-LWE-based KRM framework, valid for any
dimensional lattices and any modulus $q$ without a dither. Our main result is
an explicit upper bound on the decryption failure rate (DFR) of M-LWE-based
KRM. This bound allows us to construct optimal lattice quantizers to reduce the
DFR and communication cost simultaneously. Moreover, we present a KRM scheme
using the same security parameters $(q,k,\eta_1,\eta_2)$ as in Kyber. Compared
with Kyber, the communication cost is reduced by up to $36.47\%$ and the DFR is
reduced by a factor of up to $2^{99}$. The security arguments remain the same
as Kyber.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15535" title="Abstract">arXiv:2401.15535</a> [<a href="/pdf/2401.15535" title="Download PDF">pdf</a>, <a href="/format/2401.15535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Stereotypes in Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">A stereotype is a generalized perception of a specific group of humans. It is
often potentially encoded in human language, which is more common in texts on
social issues. Previous works simply define a sentence as stereotypical and
anti-stereotypical. However, the stereotype of a sentence may require
fine-grained quantification. In this paper, to fill this gap, we quantify
stereotypes in language by annotating a dataset. We use the pre-trained
language models (PLMs) to learn this dataset to predict stereotypes of
sentences. Then, we discuss stereotypes about common social issues such as hate
speech, sexism, sentiments, and disadvantaged and advantaged groups. We
demonstrate the connections and differences between stereotypes and common
social issues, and all four studies validate the general findings of the
current studies. In addition, our work suggests that fine-grained stereotype
scores are a highly relevant and competitive dimension for research on social
issues.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15541" title="Abstract">arXiv:2401.15541</a> [<a href="/pdf/2401.15541" title="Download PDF">pdf</a>, <a href="/format/2401.15541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stitching Satellites to the Edge: Pervasive and Efficient Federated LEO  Satellite Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elmahallawy%2C+M">Mohamed Elmahallawy</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tie Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the ambitious realm of space AI, the integration of federated learning
(FL) with low Earth orbit (LEO) satellite constellations holds immense promise.
However, many challenges persist in terms of feasibility, learning efficiency,
and convergence. These hurdles stem from the bottleneck in communication,
characterized by sporadic and irregular connectivity between LEO satellites and
ground stations, coupled with the limited computation capability of satellite
edge computing (SEC). This paper proposes a novel FL-SEC framework that
empowers LEO satellites to execute large-scale machine learning (ML) tasks
onboard efficiently. Its key components include i) personalized learning via
divide-and-conquer, which identifies and eliminates redundant satellite images
and converts complex multi-class classification problems to simple binary
classification, enabling rapid and energy-efficient training of lightweight ML
models suitable for IoT/edge devices on satellites; ii) orbital model
retraining, which generates an aggregated "orbital model" per orbit and
retrains it before sending to the ground station, significantly reducing the
required communication rounds. We conducted experiments using Jetson Nano, an
edge device closely mimicking the limited compute on LEO satellites, and a real
satellite dataset. The results underscore the effectiveness of our approach,
highlighting SEC's ability to run lightweight ML models on real and
high-resolution satellite imagery. Our approach dramatically reduces FL
convergence time by nearly 30 times, and satellite energy consumption down to
as low as 1.38 watts, all while maintaining an exceptional accuracy of up to
96%.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15543" title="Abstract">arXiv:2401.15543</a> [<a href="/pdf/2401.15543" title="Download PDF">pdf</a>, <a href="/ps/2401.15543" title="Download PostScript">ps</a>, <a href="/format/2401.15543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly Detection of Particle Orbit in Accelerator using LSTM Deep  Learning Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bhong%2C+R">Radhika Bhong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yimin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+B">Brian Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Carpenter%2C+A">Adam Carpenter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Accelerator Physics (physics.acc-ph)

</div>
<p class="mathjax">A stable, reliable, and controllable orbit lock system is crucial to an
electron (or ion) accelerator because the beam orbit and beam energy
instability strongly affect the quality of the beam delivered to experimental
halls. Currently, when the orbit lock system fails operators must manually
intervene. This paper develops a Machine Learning based fault detection
methodology to identify orbit lock anomalies and notify accelerator operations
staff of the off-normal behavior. Our method is unsupervised, so it does not
require labeled data. It uses Long-Short Memory Networks (LSTM) Auto Encoder to
capture normal patterns and predict future values of monitoring sensors in the
orbit lock system. Anomalies are detected when the prediction error exceeds a
threshold. We conducted experiments using monitoring data from Jefferson Lab's
Continuous Electron Beam Accelerator Facility (CEBAF). The results are
promising: the percentage of real anomalies identified by our solution is
68.6%-89.3% using monitoring data of a single component in the orbit lock
control system. The accuracy can be as high as 82%.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15544" title="Abstract">arXiv:2401.15544</a> [<a href="/pdf/2401.15544" title="Download PDF">pdf</a>, <a href="/ps/2401.15544" title="Download PostScript">ps</a>, <a href="/format/2401.15544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analog and Multi-modal Manufacturing Datasets Acquired on the Future  Factories Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harik%2C+R">Ramy Harik</a>, 
<a href="/search/cs?searchtype=author&query=Kalach%2C+F+E">Fadi El Kalach</a>, 
<a href="/search/cs?searchtype=author&query=Samaha%2C+J">Jad Samaha</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+D">Devon Clark</a>, 
<a href="/search/cs?searchtype=author&query=Sander%2C+D">Drew Sander</a>, 
<a href="/search/cs?searchtype=author&query=Samaha%2C+P">Philip Samaha</a>, 
<a href="/search/cs?searchtype=author&query=Burns%2C+L">Liam Burns</a>, 
<a href="/search/cs?searchtype=author&query=Yousif%2C+I">Ibrahim Yousif</a>, 
<a href="/search/cs?searchtype=author&query=Gadow%2C+V">Victor Gadow</a>, 
<a href="/search/cs?searchtype=author&query=Tarekegne%2C+T">Theodros Tarekegne</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+N">Nitol Saha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, datasets for Future Factories
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Two industry-grade datasets are presented in this paper that were collected
at the Future Factories Lab at the University of South Carolina on December
11th and 12th of 2023. These datasets are generated by a manufacturing assembly
line that utilizes industrial standards with respect to actuators, control
mechanisms, and transducers. The two datasets were both generated
simultaneously by operating the assembly line for 30 consecutive hours (with
minor filtering) and collecting data from sensors equipped throughout the
system. During operation, defects were also introduced into the assembly
operation by manually removing parts needed for the final assembly. The
datasets generated include a time series analog dataset and the other is a time
series multi-modal dataset which includes images of the system alongside the
analog data. These datasets were generated with the objective of providing
tools to further the research towards enhancing intelligence in manufacturing.
Real manufacturing datasets can be scarce let alone datasets with anomalies or
defects. As such these datasets hope to address this gap and provide
researchers with a foundation to build and train Artificial Intelligence models
applicable for the manufacturing industry. Finally, these datasets are the
first iteration of published data from the future Factories lab and can be
further adjusted to fit more researchers needs moving forward.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15545" title="Abstract">arXiv:2401.15545</a> [<a href="/pdf/2401.15545" title="Download PDF">pdf</a>, <a href="/format/2401.15545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPM: Automated Generation of Diverse Programming Problems for  Benchmarking Code Generation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Simin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaoning Feng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaohong Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted to The ACM International Conference on the Foundations of Software Engineering FSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Programming Languages (cs.PL)

</div>
<p class="mathjax">In recent times, a plethora of Large Code Generation Models (LCGMs) have been
proposed, showcasing significant potential in assisting developers with complex
programming tasks. Benchmarking LCGMs necessitates the creation of a set of
diverse programming problems, and each problem comprises the prompt (including
the task description), canonical solution, and test inputs. The existing
methods for constructing such a problem set can be categorized into two main
types: manual methods and perturbation-based methods. However, manual methods
demand high effort and lack scalability, while also risking data integrity due
to LCGMs' potentially contaminated data collection, and perturbation-based
approaches mainly generate semantically homogeneous problems with the same
canonical solutions and introduce typos that can be easily auto-corrected by
IDE, making them ineffective and unrealistic. In this work, we propose the idea
of programming problem merging (PPM) and provide two implementation of this
idea, we utilize our tool on two widely-used datasets and compare it against
nine baseline methods using eight code generation models. The results
demonstrate the effectiveness of our tool in generating more challenging,
diverse, and natural programming problems, comparing to the baselines.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15550" title="Abstract">arXiv:2401.15550</a> [<a href="/pdf/2401.15550" title="Download PDF">pdf</a>, <a href="/format/2401.15550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Maximal Matching in Clique Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minming Li</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+P">Peter Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xianbin Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared at ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We consider the problem of computing a maximal matching with a distributed
algorithm in the presence of batch-dynamic changes to the graph topology. We
assume that a graph of $n$ nodes is vertex-partitioned among $k$ players that
communicate via message passing. Our goal is to provide an efficient algorithm
that quickly updates the matching even if an adversary determines batches of
$\ell$ edge insertions or deletions.
<br />Assuming a link bandwidth of $O(\beta\log n)$ bits per round, for a parameter
$\beta \ge 1$, we first show a lower bound of $\Omega( \frac{\ell\,\log
k}{\beta\,k^2\log n})$ rounds for recomputing a matching assuming an oblivious
adversary who is unaware of the initial (random) vertex partition as well as
the current state of the players, and a stronger lower bound of
$\Omega(\frac{\ell}{\beta\,k\log n})$ rounds against an adaptive adversary, who
may choose any balanced (but not necessarily random) vertex partition initially
and who knows the current state of the players.
<br />We also present a randomized algorithm that has an initialization time of $O(
\lceil\frac{n}{\beta\,k}\rceil\log n )$ rounds, while achieving an update time
that that is independent of $n$: In more detail, the update time is $O( \lceil
\frac{\ell}{\beta\,k} \rceil \log(\beta\,k))$ against an oblivious adversary,
who must fix all updates in advance. If we consider the stronger adaptive
adversary, the update time becomes $O( \lceil
\frac{\ell}{\sqrt{\beta\,k}}\rceil \log(\beta\,k))$ rounds.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15554" title="Abstract">arXiv:2401.15554</a> [<a href="/pdf/2401.15554" title="Download PDF">pdf</a>, <a href="/ps/2401.15554" title="Download PostScript">ps</a>, <a href="/format/2401.15554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pericoronary adipose tissue feature analysis in CT calcium score images  with comparison to coronary CTA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yingnan Song</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Juhwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Justin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hoori%2C+A">Ammar Hoori</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zimin%2C+V">Vladislav Zimin</a>, 
<a href="/search/cs?searchtype=author&query=Makhlouf%2C+M">Mohamed Makhlouf</a>, 
<a href="/search/cs?searchtype=author&query=Al-Kindi%2C+S">Sadeer Al-Kindi</a>, 
<a href="/search/cs?searchtype=author&query=Rajagopalan%2C+S">Sanjay Rajagopalan</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+C">Chun-Ho Yun</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+C">Chung-Lieh Hung</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+D+L">David L. Wilson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages,10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We investigated the feasibility and advantages of using non-contrast CT
calcium score (CTCS) images to assess pericoronary adipose tissue (PCAT) and
its association with major adverse cardiovascular events (MACE). PCAT features
from coronary CTA (CCTA) have been shown to be associated with cardiovascular
risk but are potentially confounded by iodine. If PCAT in CTCS images can be
similarly analyzed, it would avoid this issue and enable its inclusion in
formal risk assessment from readily available, low-cost CTCS images. To
identify coronaries in CTCS images that have subtle visual evidence of vessels,
we registered CTCS with paired CCTA images having coronary labels. We developed
a novel axial-disk method giving regions for analyzing PCAT features in three
main coronary arteries. We analyzed novel hand-crafted and radiomic features
using univariate and multivariate logistic regression prediction of MACE and
compared results against those from CCTA. Registration accuracy was sufficient
to enable the identification of PCAT regions in CTCS images. Motion or beam
hardening artifacts were often present in high-contrast CCTA but not CTCS. Mean
HU and volume were increased in both CTCS and CCTA for MACE group. There were
significant positive correlations between some CTCS and CCTA features,
suggesting that similar characteristics were obtained. Using
hand-crafted/radiomics from CTCS and CCTA, AUCs were 0.82/0.79 and 0.83/0.77
respectively, while Agatston gave AUC=0.73. Preliminarily, PCAT features can be
assessed from three main coronary arteries in non-contrast CTCS images with
performance characteristics that are at the very least comparable to CCTA.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15555" title="Abstract">arXiv:2401.15555</a> [<a href="/pdf/2401.15555" title="Download PDF">pdf</a>, <a href="/format/2401.15555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augment before You Try: Knowledge-Enhanced Table Question Answering via  Table Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yujian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiabao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R">Ryan Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungchul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Handong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+R">Ritwik Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shiyu Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Table question answering is a popular task that assesses a model's ability to
understand and interact with structured data. However, the given table often
does not contain sufficient information for answering the question,
necessitating the integration of external knowledge. Existing methods either
convert both the table and external knowledge into text, which neglects the
structured nature of the table; or they embed queries for external sources in
the interaction with the table, which complicates the process. In this paper,
we propose a simple yet effective method to integrate external information in a
given table. Our method first constructs an augmenting table containing the
missing information and then generates a SQL query over the two tables to
answer the question. Experiments show that our method outperforms strong
baselines on three table QA benchmarks. Our code is publicly available at
https://github.com/UCSB-NLP-Chang/Augment_tableQA.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15557" title="Abstract">arXiv:2401.15557</a> [<a href="/pdf/2401.15557" title="Download PDF">pdf</a>, <a href="/format/2401.15557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vectorized implementation of primal hybrid FEM in MATLAB
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mallesham%2C+H+N">Harish Nagula Mallesham</a>, 
<a href="/search/math?searchtype=author&query=Porwal%2C+K">Kamana Porwal</a>, 
<a href="/search/math?searchtype=author&query=Valdman%2C+J">Jan Valdman</a>, 
<a href="/search/math?searchtype=author&query=Acharya%2C+S+K">Sanjib Kumar Acharya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present efficient MATLAB implementations of the lowest-order primal hybrid
finite element method (FEM) for linear second-order elliptic and parabolic
problems with mixed boundary conditions in two spatial dimensions. We employ
the Crank-Nicolson finite difference scheme for the complete discrete setup of
the parabolic problem. All the codes presented are fully vectorized using
matrix-wise array operations. Numerical experiments are conducted to show the
performance of the software.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15558" title="Abstract">arXiv:2401.15558</a> [<a href="/pdf/2401.15558" title="Download PDF">pdf</a>, <a href="/format/2401.15558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> numaPTE: Managing Page-Tables and TLBs on NUMA Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Q">Qingxuan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Tee%2C+H">Hao-Wei Tee</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+K+T+N">Kyle Timothy Ng Chu</a>, 
<a href="/search/cs?searchtype=author&query=Sanaee%2C+A">Alireza Sanaee</a>, 
<a href="/search/cs?searchtype=author&query=Jevdjic%2C+D">Djordje Jevdjic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
<p class="mathjax">Memory management operations that modify page-tables, typically performed
during memory allocation/deallocation, are infamous for their poor performance
in highly threaded applications, largely due to process-wide TLB shootdowns
that the OS must issue due to the lack of hardware support for TLB coherence.
We study these operations in NUMA settings, where we observe up to 40x overhead
for basic operations such as munmap or mprotect. The overhead further increases
if page-table replication is used, where complete coherent copies of the
page-tables are maintained across all NUMA nodes. While eager system-wide
replication is extremely effective at localizing page-table reads during
address translation, we find that it creates additional penalties upon any
page-table changes due to the need to maintain all replicas coherent.
<br />In this paper, we propose a novel page-table management mechanism, called
numaPTE, to enable transparent, on-demand, and partial page-table replication
across NUMA nodes in order to perform address translation locally, while
avoiding the overheads and scalability issues of system-wide full page-table
replication. We then show that numaPTE's precise knowledge of page-table
sharers can be leveraged to significantly reduce the number of TLB shootdowns
issued upon any memory-management operation. As a result, numaPTE not only
avoids replication-related slowdowns, but also provides significant speedup
over the baseline on memory allocation/deallocation and access control
operations. We implement numaPTEin Linux on x86_64, evaluate it on 4- and
8-socket systems, and show that numaPTE achieves the full benefits of eager
page-table replication on a wide range of applications, while also achieving a
12% and 36% runtime improvement on Webserver and Memcached respectively due to
a significant reduction in TLB shootdowns.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15559" title="Abstract">arXiv:2401.15559</a> [<a href="/pdf/2401.15559" title="Download PDF">pdf</a>, <a href="/format/2401.15559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IntentTuner: An Interactive Framework for Integrating Human Intents in  Fine-tuning Text-to-Image Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xingchen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Ziyao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yilin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wei Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Fine-tuning facilitates the adaptation of text-to-image generative models to
novel concepts (e.g., styles and portraits), empowering users to forge
creatively customized content. Recent efforts on fine-tuning focus on reducing
training data and lightening computation overload but neglect alignment with
user intentions, particularly in manual curation of multi-modal training data
and intent-oriented evaluation. Informed by a formative study with fine-tuning
practitioners for comprehending user intentions, we propose IntentTuner, an
interactive framework that intelligently incorporates human intentions
throughout each phase of the fine-tuning workflow. IntentTuner enables users to
articulate training intentions with imagery exemplars and textual descriptions,
automatically converting them into effective data augmentation strategies.
Furthermore, IntentTuner introduces novel metrics to measure user intent
alignment, allowing intent-aware monitoring and evaluation of model training.
Application exemplars and user studies demonstrate that IntentTuner streamlines
fine-tuning, reducing cognitive effort and yielding superior models compared to
the common baseline tool.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15560" title="Abstract">arXiv:2401.15560</a> [<a href="/pdf/2401.15560" title="Download PDF">pdf</a>, <a href="/ps/2401.15560" title="Download PostScript">ps</a>, <a href="/format/2401.15560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis of Letter Dynamics in the English Alphabet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+N">Neil Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Diana Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The frequency with which the letters of the English alphabet appear in
writings has been applied to the field of cryptography, the development of
keyboard mechanics, and the study of linguistics. We expanded on the
statistical analysis of the English alphabet by examining the average frequency
which each letter appears in different categories of writings. We evaluated
news articles, novels, plays, scientific publications and calculated the
frequency of each letter of the alphabet, the information density of each
letter, and the overall letter distribution. Furthermore, we developed a metric
known as distance, d that can be used to algorithmically recognize different
categories of writings. The results of our study can be applied to information
transmission, large data curation, and linguistics.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15561" title="Abstract">arXiv:2401.15561</a> [<a href="/pdf/2401.15561" title="Download PDF">pdf</a>, <a href="/format/2401.15561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parameter Privacy-Preserving Strategy for Mixed-Autonomy Platoon  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jingyuan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+K">Kaidi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">It has been demonstrated that leading cruise control (LCC) can improve the
operation of mixed-autonomy platoons by allowing connected and automated
vehicles (CAVs) to make longitudinal control decisions based on the information
provided by surrounding vehicles. However, LCC generally requires surrounding
human-driven vehicles (HDVs) to share their real-time states, which can be used
by adversaries to infer drivers' car-following behavior, potentially leading to
financial losses or safety concerns. This paper aims to address such privacy
concerns and protect the behavioral characteristics of HDVs by devising a
parameter privacy-preserving approach for mixed-autonomy platoon control.
First, we integrate a parameter privacy filter into LCC to protect sensitive
car-following parameters. The privacy filter allows each vehicle to generate
seemingly realistic pseudo states by distorting the true parameters to pseudo
parameters, which can protect drivers' privacy in behavioral parameters without
significantly influencing the control performance. Second, to enhance the
practicality and reliability of the privacy filter within LCC, we first extend
the current approach to accommodate continuous parameter spaces through a
neural network estimator. Subsequently, we introduce an individual-level
parameter privacy preservation constraint, focusing on the privacy level of
each individual parameter pair, further enhancing the approach's reliability.
Third, analysis of head-to-tail string stability reveals the potential impact
of privacy filters in degrading mixed traffic flow performance. Simulation
shows that this approach can effectively trade off privacy and control
performance in LCC. We further demonstrate the benefit of such an approach in
networked systems, i.e., by applying the privacy filter to a proceeding
vehicle, one can also achieve a certain level of privacy for the following
vehicle.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15563" title="Abstract">arXiv:2401.15563</a> [<a href="/pdf/2401.15563" title="Download PDF">pdf</a>, <a href="/format/2401.15563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrepGen: A B-rep Generative Diffusion Model with Structured Latent  Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lambourne%2C+J+G">Joseph G. Lambourne</a>, 
<a href="/search/cs?searchtype=author&query=Jayaraman%2C+P+K">Pradeep Kumar Jayaraman</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Willis%2C+K+D+D">Karl D.D. Willis</a>, 
<a href="/search/cs?searchtype=author&query=Furukawa%2C+Y">Yasutaka Furukawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents BrepGen, a diffusion-based generative approach that
directly outputs a Boundary representation (B-rep) Computer-Aided Design (CAD)
model. BrepGen represents a B-rep model as a novel structured latent geometry
in a hierarchical tree. With the root node representing a whole CAD solid, each
element of a B-rep model (i.e., a face, an edge, or a vertex) progressively
turns into a child-node from top to bottom. B-rep geometry information goes
into the nodes as the global bounding box of each primitive along with a latent
code describing the local geometric shape. The B-rep topology information is
implicitly represented by node duplication. When two faces share an edge, the
edge curve will appear twice in the tree, and a T-junction vertex with three
incident edges appears six times in the tree with identical node features.
Starting from the root and progressing to the leaf, BrepGen employs
Transformer-based diffusion models to sequentially denoise node features while
duplicated nodes are detected and merged, recovering the B-Rep topology
information. Extensive experiments show that BrepGen sets a new milestone in
CAD B-rep generation, surpassing existing methods on various benchmarks.
Results on our newly collected furniture dataset further showcase its
exceptional capability in generating complicated geometry. While previous
methods were limited to generating simple prismatic shapes, BrepGen
incorporates free-form and doubly-curved surfaces for the first time.
Additional applications of BrepGen include CAD autocomplete and design
interpolation. The code, pretrained models, and dataset will be released.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15564" title="Abstract">arXiv:2401.15564</a> [<a href="/pdf/2401.15564" title="Download PDF">pdf</a>, <a href="/ps/2401.15564" title="Download PostScript">ps</a>, <a href="/format/2401.15564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of UAV flight state recognition and trajectory prediction system  based on trajectory feature construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+X">Xingyu Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Z">Zhuoyong Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the impact of artificial intelligence on the traditional UAV industry,
autonomous UAV flight has become a current hot research field. Based on the
demand for research on critical technologies for autonomous flying UAVs, this
paper addresses the field of flight state recognition and trajectory prediction
of UAVs. This paper proposes a method to improve the accuracy of UAV trajectory
prediction based on UAV flight state recognition and verifies it using two
prediction models. Firstly, UAV flight data acquisition and data preprocessing
are carried out; secondly, UAV flight trajectory features are extracted based
on data fusion and a UAV flight state recognition model based on PCA-DAGSVM
model is established; finally, two UAV flight trajectory prediction models are
established and the trajectory prediction errors of the two prediction models
are compared and analyzed after flight state recognition. The results show
that: 1) the UAV flight state recognition model based on PCA-DAGSVM has good
recognition effect. 2) compared with the traditional UAV trajectory prediction
model, the prediction model based on flight state recognition can effectively
reduce the prediction error.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15568" title="Abstract">arXiv:2401.15568</a> [<a href="/pdf/2401.15568" title="Download PDF">pdf</a>, <a href="/format/2401.15568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intriguing Equivalence Structures of the Embedding Space of Vision  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salman%2C+S">Shaeke Salman</a>, 
<a href="/search/cs?searchtype=author&query=Shams%2C+M+M+B">Md Montasir Bin Shams</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiuwen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pre-trained large foundation models play a central role in the recent surge
of artificial intelligence, resulting in fine-tuned models with remarkable
abilities when measured on benchmark datasets, standard exams, and
applications. Due to their inherent complexity, these models are not well
understood. While small adversarial inputs to such models are well known, the
structures of the representation space are not well characterized despite their
fundamental importance. In this paper, using the vision transformers as an
example due to the continuous nature of their input space, we show via analyses
and systematic experiments that the representation space consists of large
piecewise linear subspaces where there exist very different inputs sharing the
same representations, and at the same time, local normal spaces where there are
visually indistinguishable inputs having very different representations. The
empirical results are further verified using the local directional estimations
of the Lipschitz constants of the underlying models. Consequently, the
resulting representations change the results of downstream models, and such
models are subject to overgeneralization and with limited semantically
meaningful generalization capability.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15569" title="Abstract">arXiv:2401.15569</a> [<a href="/pdf/2401.15569" title="Download PDF">pdf</a>, <a href="/ps/2401.15569" title="Download PostScript">ps</a>, <a href="/format/2401.15569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Tuning and Inference for Large Language Models on Textual  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haizhou Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siliang Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Rich textual and topological information of textual graphs need to be modeled
in real-world applications such as webpages, e-commerce, and academic articles.
Practitioners have been long following the path of adopting a shallow text
encoder and a subsequent graph neural network (GNN) to solve this problem. In
light of recent advancements in large language models (LLMs), it is apparent
that integrating LLMs for enhanced textual encoding can substantially improve
the performance of textual graphs. Nevertheless, the efficiency of these
methods poses a significant challenge. In this paper, we propose ENGINE, a
parameter- and memory-efficient fine-tuning method for textual graphs with an
LLM encoder. The key insight is to combine the LLMs and GNNs through a tunable
side structure, which significantly reduces the training complexity without
impairing the joint model's capacity. Extensive experiments on textual graphs
demonstrate our method's effectiveness by achieving the best model performance,
meanwhile having the lowest training cost compared to previous methods.
Moreover, we introduce two variants with caching and dynamic early exit to
further enhance training and inference speed. Specifically, caching accelerates
ENGINE's training by 12x, and dynamic early exit achieves up to 5x faster
inference with a negligible performance drop (at maximum 1.17% relevant drop
across 7 datasets).
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15573" title="Abstract">arXiv:2401.15573</a> [<a href="/pdf/2401.15573" title="Download PDF">pdf</a>, <a href="/format/2401.15573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel PML-type Technique for Acoustic Scattering Problems based on A  Real Coordinate Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+J">Jiangxing Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+L">Lilian Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Bo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">It is known that any {\em real coordinate transformation} (RCT) to compress
waves in an unbounded domain into a bounded domain results in infinite
oscillations that cannot be resolved by any grid-based method. In this paper,
we intend to show that it is viable if the outgoing waves are compressed along
the radial direction and the resulting oscillatory pattern is extracted
explicitly. We therefore construct a perfectly matched layer (PML)-type
technique for domain reduction of wave scattering problems using RCT, termed as
real compressed layer (RCL). Different from all existing approaches, the RCL
technique has two features: (i) the RCL-equation only involves real-valued
coefficients, which is more desirable for computation and analysis; and (ii)
the layer is not ``artificial'' in the sense that the computed field in the
layer can recover the outgoing wave of the original scattering problem in the
unbounded domain. Here we demonstrate the essential idea and performance of the
RCL for the two-dimensional Helmholtz problem with a bounded scatterer, but
this technique can be extended to three dimensions in a similar setting.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15578" title="Abstract">arXiv:2401.15578</a> [<a href="/pdf/2401.15578" title="Download PDF">pdf</a>, <a href="/format/2401.15578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARCNet: An Asymmetric Residual Wavelet Column Correction Network for  Infrared Image Destriping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuai Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hanlin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+N">Naveed Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shiqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuowen Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Infrared image destriping seeks to restore high-quality content from degraded
images. Recent works mainly address this task by leveraging prior knowledge to
separate stripe noise from the degraded image. However, constructing a robust
decoupling model for that purpose remains challenging, especially when
significant similarities exist between the stripe noise and vertical background
structure. Addressing that, we introduce Asymmetric Residual wavelet Column
correction Network (ARCNet) for image destriping, aiming to consistently
preserve spatially precise high-resolution representations. Our neural model
leverages a novel downsampler, residual haar discrete wavelet transform
(RHDWT), stripe directional prior knowledge and data-driven learning to induce
a model with enriched feature representation of stripe noise and background. In
our technique, the inverse wavelet transform is replaced by transposed
convolution for feature upsampling, which can suppress noise crosstalk and
encourage the network to focus on robust image reconstruction. After each
sampling, a proposed column non-uniformity correction module (CNCM) is
leveraged by our method to enhance column uniformity, spatial correlation, and
global self-dependence between each layer component. CNCM can establish
structural characteristics of stripe noise and utilize contextual information
at long-range dependencies to distinguish stripes with varying intensities and
distributions. Extensive experiments on synthetic data, real data, and infrared
small target detection tasks show that the proposed method outperforms
state-of-the-art single-image destriping methods both visually and
quantitatively by a considerable margin. Our code will be made publicly
available at \url{https://github.com/xdFai}.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15579" title="Abstract">arXiv:2401.15579</a> [<a href="/pdf/2401.15579" title="Download PDF">pdf</a>, <a href="/format/2401.15579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MunTTS: A Text-to-Speech System for Mundari
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gumma%2C+V">Varun Gumma</a>, 
<a href="/search/cs?searchtype=author&query=Hada%2C+R">Rishav Hada</a>, 
<a href="/search/cs?searchtype=author&query=Yadavalli%2C+A">Aditya Yadavalli</a>, 
<a href="/search/cs?searchtype=author&query=Gogoi%2C+P">Pamir Gogoi</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+I">Ishani Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Seshadri%2C+V">Vivek Seshadri</a>, 
<a href="/search/cs?searchtype=author&query=Bali%2C+K">Kalika Bali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ComputEL-7
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We present MunTTS, an end-to-end text-to-speech (TTS) system specifically for
Mundari, a low-resource Indian language of the Austo-Asiatic family. Our work
addresses the gap in linguistic technology for underrepresented languages by
collecting and processing data to build a speech synthesis system. We begin our
study by gathering a substantial dataset of Mundari text and speech and train
end-to-end speech models. We also delve into the methods used for training our
models, ensuring they are efficient and effective despite the data constraints.
We evaluate our system with native speakers and objective metrics,
demonstrating its potential as a tool for preserving and promoting the Mundari
language in the digital age.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15582" title="Abstract">arXiv:2401.15582</a> [<a href="/pdf/2401.15582" title="Download PDF">pdf</a>, <a href="/format/2401.15582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A two-grid Adaptive Finite Element Method for the Dirichlet Boundary  Control Problem Governed by Stokes Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gudi%2C+T">Thirupathi Gudi</a>, 
<a href="/search/math?searchtype=author&query=Sau%2C+R+C">Ramesh Chandra Sau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this article, we derive \textit{a posteriori} error estimates for the
Dirichlet boundary control problem governed by Stokes equation. An energy-based
method has been deployed to solve the Dirichlet boundary control problem. We
employ an inf-sup stable finite element discretization scheme by using
$\mathbf{P}_1$ elements(in the fine mesh) for the velocity and control variable
and $P_0$ elements(in the coarse mesh) for the pressure variable. We derive an
\textit{a posteriori} error estimator for the state, adjoint state, and control
error. The control error estimator generalizes the standard residual type
estimator of the unconstrained Dirichlet boundary control problems, by
additional terms at the contact boundary addressing the non-linearity. We prove
the reliability and efficiency of the estimator. Theoretical results are
illustrated by some numerical experiments.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15583" title="Abstract">arXiv:2401.15583</a> [<a href="/pdf/2401.15583" title="Download PDF">pdf</a>, <a href="/format/2401.15583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCTransNet: Spatial-channel Cross Transformer Network for Infrared Small  Target Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuai Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hanlin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=AKhtar%2C+N">Naveed AKhtar</a>, 
<a href="/search/cs?searchtype=author&query=Mian%2C+A">Ajmal Mian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Infrared small target detection (IRSTD) has recently benefitted greatly from
U-shaped neural models. However, largely overlooking effective global
information modeling, existing techniques struggle when the target has high
similarities with the background. We present a Spatial-channel Cross
Transformer Network (SCTransNet) that leverages spatial-channel cross
transformer blocks (SCTBs) on top of long-range skip connections to address the
aforementioned challenge. In the proposed SCTBs, the outputs of all encoders
are interacted with cross transformer to generate mixed features, which are
redistributed to all decoders to effectively reinforce semantic differences
between the target and clutter at full scales. Specifically, SCTB contains the
following two key elements: (a) spatial-embedded single-head channel-cross
attention (SSCA) for exchanging local spatial features and full-level global
channel information to eliminate ambiguity among the encoders and facilitate
high-level semantic associations of the images, and (b) a complementary
feed-forward network (CFN) for enhancing the feature discriminability via a
multi-scale strategy and cross-spatial-channel information interaction to
promote beneficial information transfer. Our SCTransNet effectively encodes the
semantic differences between targets and backgrounds to boost its internal
representation for detecting small infrared targets accurately. Extensive
experiments on three public datasets, NUDT-SIRST, NUAA-SIRST, and IRSTD-1k,
demonstrate that the proposed SCTransNet outperforms existing IRSTD methods.
Our code will be made public at https://github.com/xdFai.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15584" title="Abstract">arXiv:2401.15584</a> [<a href="/pdf/2401.15584" title="Download PDF">pdf</a>, <a href="/format/2401.15584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGNN: Decoupled Graph Neural Networks with Structural Consistency  between Attribute and Graph Embedding Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinlu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jipeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanfeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junbin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaofan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yachao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Baocai Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks (GNNs) demonstrate a robust capability for
representation learning on graphs with complex structures, showcasing superior
performance in various applications. The majority of existing GNNs employ a
graph convolution operation by using both attribute and structure information
through coupled learning. In essence, GNNs, from an optimization perspective,
seek to learn a consensus and compromise embedding representation that balances
attribute and graph information, selectively exploring and retaining valid
information. To obtain a more comprehensive embedding representation of nodes,
a novel GNNs framework, dubbed Decoupled Graph Neural Networks (DGNN), is
introduced. DGNN explores distinctive embedding representations from the
attribute and graph spaces by decoupled terms. Considering that semantic graph,
constructed from attribute feature space, consists of different node connection
information and provides enhancement for the topological graph, both
topological and semantic graphs are combined for the embedding representation
learning. Further, structural consistency among attribute embedding and graph
embeddings is promoted to effectively remove redundant information and
establish soft connection. This involves promoting factor sharing for adjacency
reconstruction matrices, facilitating the exploration of a consensus and
high-level correlation. Finally, a more powerful and complete representation is
achieved through the concatenation of these embeddings. Experimental results
conducted on several graph benchmark datasets verify its superiority in node
classification task.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15585" title="Abstract">arXiv:2401.15585</a> [<a href="/pdf/2401.15585" title="Download PDF">pdf</a>, <a href="/format/2401.15585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Gender Bias in Large Language Models via Chain-of-Thought  Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+M">Masahiro Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Bollegala%2C+D">Danushka Bollegala</a>, 
<a href="/search/cs?searchtype=author&query=Okazaki%2C+N">Naoaki Okazaki</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Timothy Baldwin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">There exist both scalable tasks, like reading comprehension and
fact-checking, where model performance improves with model size, and unscalable
tasks, like arithmetic reasoning and symbolic reasoning, where model
performance does not necessarily improve with model size. Large language models
(LLMs) equipped with Chain-of-Thought (CoT) prompting are able to make accurate
incremental predictions even on unscalable tasks. Unfortunately, despite their
exceptional reasoning abilities, LLMs tend to internalize and reproduce
discriminatory societal biases. Whether CoT can provide discriminatory or
egalitarian rationalizations for the implicit information in unscalable tasks
remains an open question.
<br />In this study, we examine the impact of LLMs' step-by-step predictions on
gender bias in unscalable tasks. For this purpose, we construct a benchmark for
an unscalable task where the LLM is given a list of words comprising feminine,
masculine, and gendered occupational words, and is required to count the number
of feminine and masculine words. In our CoT prompts, we require the LLM to
explicitly indicate whether each word in the word list is a feminine or
masculine before making the final predictions. With counting and handling the
meaning of words, this benchmark has characteristics of both arithmetic
reasoning and symbolic reasoning. Experimental results in English show that
without step-by-step prediction, most LLMs make socially biased predictions,
despite the task being as simple as counting words. Interestingly, CoT
prompting reduces this unconscious social bias in LLMs and encourages fair
predictions.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15587" title="Abstract">arXiv:2401.15587</a> [<a href="/pdf/2401.15587" title="Download PDF">pdf</a>, <a href="/ps/2401.15587" title="Download PostScript">ps</a>, <a href="/format/2401.15587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperedge Interaction-aware Hypergraph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+X">Xiaobing Pei</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Rongping Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haoran Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiqi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Hypergraphs provide an effective modeling approach for modeling high-order
relationships in many real-world datasets. To capture such complex
relationships, several hypergraph neural networks have been proposed for
learning hypergraph structure, which propagate information from nodes to
hyperedges and then from hyperedges back to nodes. However, most existing
methods focus on information propagation between hyperedges and nodes,
neglecting the interactions among hyperedges themselves. In this paper, we
propose HeIHNN, a hyperedge interaction-aware hypergraph neural network, which
captures the interactions among hyperedges during the convolution process and
introduce a novel mechanism to enhance information flow between hyperedges and
nodes. Specifically, HeIHNN integrates the interactions between hyperedges into
the hypergraph convolution by constructing a three-stage information
propagation process. After propagating information from nodes to hyperedges, we
introduce a hyperedge-level convolution to update the hyperedge embeddings.
Finally, the embeddings that capture rich information from the interaction
among hyperedges will be utilized to update the node embeddings. Additionally,
we introduce a hyperedge outlier removal mechanism in the information
propagation stages between nodes and hyperedges, which dynamically adjusts the
hypergraph structure using the learned embeddings, effectively removing
outliers. Extensive experiments conducted on real-world datasets show the
competitive performance of HeIHNN compared with state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15589" title="Abstract">arXiv:2401.15589</a> [<a href="/pdf/2401.15589" title="Download PDF">pdf</a>, <a href="/format/2401.15589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpineBot: Class Feedback Reimagined Using a Conversational LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanwar%2C+H">Henansh Tanwar</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastva%2C+K">Kunal Shrivastva</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rahul Singh</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Dhruv Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Conventional class feedback systems often fall short, relying on static,
unengaging surveys offering little incentive for student participation. To
address this, we present OpineBot, a novel system employing large language
models (LLMs) to conduct personalized, conversational class feedback via
chatbot interface. We assessed OpineBot's effectiveness in a user study with 20
students from an Indian university's Operating-Systems class, utilizing surveys
and interviews to analyze their experiences. Findings revealed a resounding
preference for OpineBot compared to conventional methods, highlighting its
ability to engage students, produce deeper feedback, offering a dynamic survey
experience. This research represents a work in progress, providing early
results, marking a significant step towards revolutionizing class feedback
through LLM-based technology, promoting student engagement, and leading to
richer data for instructors. This ongoing research presents preliminary
findings and marks a notable advancement in transforming classroom feedback
using LLM-based technology to enhance student engagement and generate
comprehensive data for educators.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15595" title="Abstract">arXiv:2401.15595</a> [<a href="/pdf/2401.15595" title="Download PDF">pdf</a>, <a href="/format/2401.15595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comuniqa : Exploring Large Language Models for improving speaking skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mhasakar%2C+M">Manas Mhasakar</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shikhar Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Mehra%2C+A">Apurv Mehra</a>, 
<a href="/search/cs?searchtype=author&query=Venaik%2C+U">Utkarsh Venaik</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+U">Ujjwal Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Dhruv Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+K">Kashish Mittal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 15 figures, 4 tables, under review for ACM CHI LBW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This research paper explores the potential of Large Language Models (LLMs) to
enhance speaking skills. We first present a novel LLM-based system, Comuniqa,
for this task. We then take a humancentric approach to evaluate this system,
comparing it with human experts. We also investigate the possibility of
combining feedback from both LLM and human experts to enhance overall learning
outcomes. We use purposive and random sampling for recruiting participants,
categorizing them into three groups: those who use LLM-enabled apps for
improving speaking skills, those guided by human experts for the same task and
those who utilize both the LLM-enabled apps as well as the human experts. Using
surveys, interviews, and actual study sessions, we provide a detailed
perspective on the effectiveness of different learning modalities. Our
preliminary findings suggest that while LLM-based systems have commendable
accuracy, they lack human-level cognitive capabilities, both in terms of
accuracy and empathy.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15600" title="Abstract">arXiv:2401.15600</a> [<a href="/pdf/2401.15600" title="Download PDF">pdf</a>, <a href="/format/2401.15600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mechatronic System for the Visualisation and Analysis of Orchestral  Conducting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coates%2C+C">Courtney Coates</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures, accepted by ACRA2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Australasian Conference on Robotics and Automation (ACRA 2023).
  Sydney, Australia, 2023: 1-10
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper quantitatively analysed orchestral conducting patterns, and
detected variations as a result of extraneous body movement during conducting,
in the first experiment of its kind. A novel live conducting system featuring
data capture, processing, and analysis was developed. Reliable data of an
expert conductor's movements was collected, processed, and used to calculate
average trajectories for different conducting techniques with various
extraneous body movements; variations between extraneous body movement
techniques and controlled technique were definitively determined in a novel
quantitative analysis. A portable and affordable mechatronic system was created
to capture and process live baton tip data, and was found to be accurate
through calibration against a reliable reference. Experimental conducting field
data was captured through the mechatronic system, and analysed against
previously calculated average trajectories; the extraneous movement used during
the field data capture was successfully identified by the system.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15603" title="Abstract">arXiv:2401.15603</a> [<a href="/pdf/2401.15603" title="Download PDF">pdf</a>, <a href="/format/2401.15603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Expressive Power of Spectral Graph Neural Networks with  Eigenvalue Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Kangkang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yanhua Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zixuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zirui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+M">Meiyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Mengran Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In recent years, spectral graph neural networks, characterized by polynomial
filters, have garnered increasing attention and have achieved remarkable
performance in tasks such as node classification. These models typically assume
that eigenvalues for the normalized Laplacian matrix are distinct from each
other, thus expecting a polynomial filter to have a high fitting ability.
However, this paper empirically observes that normalized Laplacian matrices
frequently possess repeated eigenvalues. Moreover, we theoretically establish
that the number of distinguishable eigenvalues plays a pivotal role in
determining the expressive power of spectral graph neural networks. In light of
this observation, we propose an eigenvalue correction strategy that can free
polynomial filters from the constraints of repeated eigenvalue inputs.
Concretely, the proposed eigenvalue correction strategy enhances the uniform
distribution of eigenvalues, thus mitigating repeated eigenvalues, and
improving the fitting capacity and expressive power of polynomial filters.
Extensive experimental results on both synthetic and real-world datasets
demonstrate the superiority of our method.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15604" title="Abstract">arXiv:2401.15604</a> [<a href="/pdf/2401.15604" title="Download PDF">pdf</a>, <a href="/ps/2401.15604" title="Download PostScript">ps</a>, <a href="/format/2401.15604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network-Based Score Estimation in Diffusion Models: Optimization  and Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yinbin Han</a>, 
<a href="/search/cs?searchtype=author&query=Razaviyayn%2C+M">Meisam Razaviyayn</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Diffusion models have emerged as a powerful tool rivaling GANs in generating
high-quality samples with improved fidelity, flexibility, and robustness. A key
component of these models is to learn the score function through score
matching. Despite empirical success on various tasks, it remains unclear
whether gradient-based algorithms can learn the score function with a provable
accuracy. As a first step toward answering this question, this paper
establishes a mathematical framework for analyzing score estimation using
neural networks trained by gradient descent. Our analysis covers both the
optimization and the generalization aspects of the learning procedure. In
particular, we propose a parametric form to formulate the denoising
score-matching problem as a regression with noisy labels. Compared to the
standard supervised learning setup, the score-matching problem introduces
distinct challenges, including unbounded input, vector-valued output, and an
additional time variable, preventing existing techniques from being applied
directly. In this paper, we show that with a properly designed neural network
architecture, the score function can be accurately approximated by a
reproducing kernel Hilbert space induced by neural tangent kernels.
Furthermore, by applying an early-stopping rule for gradient descent and
leveraging certain coupling arguments between neural network training and
kernel regression, we establish the first generalization error (sample
complexity) bounds for learning the score function despite the presence of
noise in the observations. Our analysis is grounded in a novel parametric form
of the neural network and an innovative connection between score matching and
regression analysis, facilitating the application of advanced statistical and
optimization techniques.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15605" title="Abstract">arXiv:2401.15605</a> [<a href="/pdf/2401.15605" title="Download PDF">pdf</a>, <a href="/format/2401.15605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI as a Medical Ally: Evaluating ChatGPT&#x27;s Usage and Impact in Indian  Healthcare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raina%2C+A">Aryaman Raina</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+P">Prateek Mishra</a>, 
<a href="/search/cs?searchtype=author&query=goyal%2C+H">Harshit goyal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Dhruv Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This study investigates the integration and impact of Large Language Models
(LLMs), like ChatGPT, in India's healthcare sector. Our research employs a dual
approach, engaging both general users and medical professionals through surveys
and interviews respectively. Our findings reveal that healthcare professionals
value ChatGPT in medical education and preliminary clinical settings, but
exercise caution due to concerns about reliability, privacy, and the need for
cross-verification with medical references. General users show a preference for
AI interactions in healthcare, but concerns regarding accuracy and trust
persist. The study underscores the need for these technologies to complement,
not replace, human medical expertise, highlighting the importance of developing
LLMs in collaboration with healthcare providers. This paper enhances the
understanding of LLMs in healthcare, detailing current usage, user trust, and
improvement areas. Our insights inform future research and development,
underscoring the need for ethically compliant, user-focused LLM advancements
that address healthcare-specific challenges.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15607" title="Abstract">arXiv:2401.15607</a> [<a href="/pdf/2401.15607" title="Download PDF">pdf</a>, <a href="/format/2401.15607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey of Distributed Algorithms for Resource Allocation over  Multi-Agent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Doostmohammadian%2C+M">Mohammadreza Doostmohammadian</a>, 
<a href="/search/eess?searchtype=author&query=Aghasi%2C+A">Alireza Aghasi</a>, 
<a href="/search/eess?searchtype=author&query=Pirani%2C+M">Mohammad Pirani</a>, 
<a href="/search/eess?searchtype=author&query=Nekouei%2C+E">Ehsan Nekouei</a>, 
<a href="/search/eess?searchtype=author&query=Zarrabi%2C+H">Houman Zarrabi</a>, 
<a href="/search/eess?searchtype=author&query=Keypour%2C+R">Reza Keypour</a>, 
<a href="/search/eess?searchtype=author&query=Rikos%2C+A+I">Apostolos I. Rikos</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to annual reviews in control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
<p class="mathjax">Resource allocation and scheduling in multi-agent systems present challenges
due to complex interactions and decentralization. This survey paper provides a
comprehensive analysis of distributed algorithms for addressing the distributed
resource allocation (DRA) problem over multi-agent systems. It covers a
significant area of research at the intersection of optimization, multi-agent
systems, and distributed consensus-based computing. The paper begins by
presenting a mathematical formulation of the DRA problem, establishing a solid
foundation for further exploration. Real-world applications of DRA in various
domains are examined to underscore the importance of efficient resource
allocation, and relevant distributed optimization formulations are presented.
The survey then delves into existing solutions for DRA, encompassing linear,
nonlinear, primal-based, and dual-formulation-based approaches. Furthermore,
this paper evaluates the features and properties of DRA algorithms, addressing
key aspects such as feasibility, convergence rate, and network reliability. The
analysis of mathematical foundations, diverse applications, existing solutions,
and algorithmic properties contributes to a broader comprehension of the
challenges and potential solutions for this domain.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15608" title="Abstract">arXiv:2401.15608</a> [<a href="/pdf/2401.15608" title="Download PDF">pdf</a>, <a href="/ps/2401.15608" title="Download PostScript">ps</a>, <a href="/format/2401.15608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis for a class of stochastic fractional nonlinear Schr&#xf6;dinger  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yanjie Zhang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+A">Ao Zhang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+P">Pengde Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/math?searchtype=author&query=Duan%2C+J">Jinqiao Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We investigate the global existence of a solution for the stochastic
fractional nonlinear Schr\"odinger equation with radially symmetric initial
data in a suitable energy space $H^{\alpha}$. Using a variational principle, we
demonstrate that the stochastic fractional nonlinear Schr\"odinger equation in
the Stratonovich sense forms an infinite-dimensional stochastic Hamiltonian
system, with its phase flow preserving symplecticity. We develop a
structure-preserving algorithm for the stochastic fractional nonlinear
Schr\"odinger equation from the perspective of symplectic geometry. It is
established that the stochastic midpoint scheme satisfies the corresponding
symplectic law in the discrete sense. Furthermore, since the midpoint scheme is
implicit, we also develop a more effective mass-preserving splitting scheme.
Consequently, the convergence order of the splitting scheme is shown to be $1$.
Two numerical examples are conducted to validate the efficiency of the theory.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15610" title="Abstract">arXiv:2401.15610</a> [<a href="/pdf/2401.15610" title="Download PDF">pdf</a>, <a href="/format/2401.15610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prevalidated ridge regression is a highly-efficient drop-in replacement  for logistic regression for high-dimensional data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dempster%2C+A">Angus Dempster</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+G+I">Geoffrey I. Webb</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+D+F">Daniel F. Schmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Logistic regression is a ubiquitous method for probabilistic classification.
However, the effectiveness of logistic regression depends upon careful and
relatively computationally expensive tuning, especially for the regularisation
hyperparameter, and especially in the context of high-dimensional data. We
present a prevalidated ridge regression model that closely matches logistic
regression in terms of classification error and log-loss, particularly for
high-dimensional data, while being significantly more computationally efficient
and having effectively no hyperparameters beyond regularisation. We scale the
coefficients of the model so as to minimise log-loss for a set of prevalidated
predictions derived from the estimated leave-one-out cross-validation error.
This exploits quantities already computed in the course of fitting the ridge
regression model in order to find the scaling parameter with nominal additional
computational expense.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15615" title="Abstract">arXiv:2401.15615</a> [<a href="/pdf/2401.15615" title="Download PDF">pdf</a>, <a href="/ps/2401.15615" title="Download PostScript">ps</a>, <a href="/format/2401.15615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Noise and Efficiency Issues in Graph-Based Machine Learning  Models From the Perspective of Adversarial Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Given that no existing graph construction method can generate a perfect graph
for a given dataset, graph-based algorithms are invariably affected by the
plethora of redundant and erroneous edges present within the constructed
graphs. In this paper, we propose treating these noisy edges as adversarial
attack and use a spectral adversarial robustness evaluation method to diminish
the impact of noisy edges on the performance of graph algorithms. Our method
identifies those points that are less vulnerable to noisy edges and leverages
only these robust points to perform graph-based algorithms. Our experiments
with spectral clustering, one of the most representative and widely utilized
graph algorithms, reveal that our methodology not only substantially elevates
the precision of the algorithm but also greatly accelerates its computational
efficiency by leveraging only a select number of robust data points.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15616" title="Abstract">arXiv:2401.15616</a> [<a href="/pdf/2401.15616" title="Download PDF">pdf</a>, <a href="/format/2401.15616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Person 3D Pose Estimation from Multi-View Uncalibrated Depth  Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu-Jhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Khirodkar%2C+R">Rawal Khirodkar</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinhyung Park</a>, 
<a href="/search/cs?searchtype=author&query=Kitani%2C+K">Kris Kitani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages including appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We tackle the task of multi-view, multi-person 3D human pose estimation from
a limited number of uncalibrated depth cameras. Recently, many approaches have
been proposed for 3D human pose estimation from multi-view RGB cameras.
However, these works (1) assume the number of RGB camera views is large enough
for 3D reconstruction, (2) the cameras are calibrated, and (3) rely on ground
truth 3D poses for training their regression model. In this work, we propose to
leverage sparse, uncalibrated depth cameras providing RGBD video streams for 3D
human pose estimation. We present a simple pipeline for Multi-View Depth Human
Pose Estimation (MVD-HPE) for jointly predicting the camera poses and 3D human
poses without training a deep 3D human pose regression model. This framework
utilizes 3D Re-ID appearance features from RGBD images to formulate more
accurate correspondences (for deriving camera positions) compared to using
RGB-only features. We further propose (1) depth-guided camera-pose estimation
by leveraging 3D rigid transformations as guidance and (2) depth-constrained 3D
human pose estimation by utilizing depth-projected 3D points as an alternative
objective for optimization. In order to evaluate our proposed pipeline, we
collect three video sets of RGBD videos recorded from multiple sparse-view
depth cameras and ground truth 3D poses are manually annotated. Experiments
show that our proposed method outperforms the current 3D human pose
regression-free pipelines in terms of both camera pose estimation and 3D human
pose estimation.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15617" title="Abstract">arXiv:2401.15617</a> [<a href="/pdf/2401.15617" title="Download PDF">pdf</a>, <a href="/format/2401.15617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-based graph generative methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Can Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lingyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xuemin Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Being the most cutting-edge generative methods, diffusion methods have shown
great advances in wide generation tasks. Among them, graph generation attracts
significant research attention for its broad application in real life. In our
survey, we systematically and comprehensively review on diffusion-based graph
generative methods. We first make a review on three mainstream paradigms of
diffusion methods, which are denoising diffusion probabilistic models,
score-based genrative models, and stochastic differential equations. Then we
further categorize and introduce the latest applications of diffusion models on
graphs. In the end, we point out some limitations of current studies and future
directions of future explorations. The summary of existing methods metioned in
this survey is in
https://github.com/zhejiangzhuque/Diffusion-based-Graph-Generative-Methods.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15620" title="Abstract">arXiv:2401.15620</a> [<a href="/pdf/2401.15620" title="Download PDF">pdf</a>, <a href="/format/2401.15620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Strategies for Coping with Incomplete DVL Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+N">Nadav Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+I">Itzik Klein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">Autonomous underwater vehicles are specialized platforms engineered for deep
underwater operations. Critical to their functionality is autonomous
navigation, typically relying on an inertial navigation system and a Doppler
velocity log. In real-world scenarios, incomplete Doppler velocity log
measurements occur, resulting in positioning errors and mission aborts. To cope
with such situations, a model and learning approaches were derived. This paper
presents a comparative analysis of two cutting-edge deep learning
methodologies, namely LiBeamsNet and MissBeamNet, alongside a model-based
average estimator. These approaches are evaluated for their efficacy in
regressing missing Doppler velocity log beams when two beams are unavailable.
In our study, we used data recorded by a DVL mounted on an autonomous
underwater vehicle operated in the Mediterranean Sea. We found that both deep
learning architectures outperformed model-based approaches by over 16% in
velocity prediction accuracy.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15621" title="Abstract">arXiv:2401.15621</a> [<a href="/pdf/2401.15621" title="Download PDF">pdf</a>, <a href="/format/2401.15621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SNAP: Semantic Stories for Next Activity Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oved%2C+A">Alon Oved</a>, 
<a href="/search/cs?searchtype=author&query=Shlomov%2C+S">Segev Shlomov</a>, 
<a href="/search/cs?searchtype=author&query=Zeltyn%2C+S">Sergey Zeltyn</a>, 
<a href="/search/cs?searchtype=author&query=Mashkif%2C+N">Nir Mashkif</a>, 
<a href="/search/cs?searchtype=author&query=Yaeli%2C+A">Avi Yaeli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Predicting the next activity in an ongoing process is one of the most common
classification tasks in the business process management (BPM) domain. It allows
businesses to optimize resource allocation, enhance operational efficiency, and
aids in risk mitigation and strategic decision-making. This provides a
competitive edge in the rapidly evolving confluence of BPM and AI. Existing
state-of-the-art AI models for business process prediction do not fully
capitalize on available semantic information within process event logs. As
current advanced AI-BPM systems provide semantically-richer textual data, the
need for novel adequate models grows. To address this gap, we propose the novel
SNAP method that leverages language foundation models by constructing semantic
contextual stories from the process historical event logs and using them for
the next activity prediction. We compared the SNAP algorithm with nine
state-of-the-art models on six benchmark datasets and show that SNAP
significantly outperforms them, especially for datasets with high levels of
semantic content.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15625" title="Abstract">arXiv:2401.15625</a> [<a href="/pdf/2401.15625" title="Download PDF">pdf</a>, <a href="/format/2401.15625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI-enabled Blockchain Networks: Fundamentals, Applications,  and Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C+T">Cong T. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinqiu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shiwen Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative Artificial Intelligence (GAI) has recently emerged as a promising
solution to address critical challenges of blockchain technology, including
scalability, security, privacy, and interoperability. In this paper, we first
introduce GAI techniques, outline their applications, and discuss existing
solutions for integrating GAI into blockchains. Then, we discuss emerging
solutions that demonstrate the effectiveness of GAI in addressing various
challenges of blockchain, such as detecting unknown blockchain attacks and
smart contract vulnerabilities, designing key secret sharing schemes, and
enhancing privacy. Moreover, we present a case study to demonstrate that GAI,
specifically the generative diffusion model, can be employed to optimize
blockchain network performance metrics. Experimental results clearly show that,
compared to a baseline traditional AI approach, the proposed generative
diffusion model approach can converge faster, achieve higher rewards, and
significantly improve the throughput and latency of the blockchain network.
Additionally, we highlight future research directions for GAI in blockchain
applications, including personalized GAI-enabled blockchains, GAI-blockchain
synergy, and privacy and security considerations within blockchain ecosystems.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15626" title="Abstract">arXiv:2401.15626</a> [<a href="/pdf/2401.15626" title="Download PDF">pdf</a>, <a href="/format/2401.15626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TA&amp;AT: Enhancing Task-Oriented Dialog with Turn-Level Auxiliary Tasks  and Action-Tree Based Scheduled Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Longxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiuxing Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Task-oriented dialog systems have witnessed substantial progress due to
conversational pre-training techniques. Yet, two significant challenges
persist. First, most systems primarily utilize the latest turn's state label
for the generator. This practice overlooks the comprehensive value of state
labels in boosting the model's understanding for future generations. Second, an
overreliance on generated policy often leads to error accumulation, resulting
in suboptimal responses when adhering to incorrect actions. To combat these
challenges, we propose turn-level multi-task objectives for the encoder. With
the guidance of essential information from labeled intermediate states, we
establish a more robust representation for both understanding and generation.
For the decoder, we introduce an action tree-based scheduled sampling
technique. Specifically, we model the hierarchical policy as trees and utilize
the similarity between trees to sample negative policy based on scheduled
sampling, hoping the model to generate invariant responses under perturbations.
This method simulates potential pitfalls by sampling similar negative policy,
bridging the gap between task-oriented dialog training and inference. Among
methods without continual pre-training, our approach achieved state-of-the-art
(SOTA) performance on the MultiWOZ dataset series and was also competitive with
pre-trained SOTA methods.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15628" title="Abstract">arXiv:2401.15628</a> [<a href="/pdf/2401.15628" title="Download PDF">pdf</a>, <a href="/format/2401.15628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WetSpongeCake: a Surface Appearance Model Considering Porosity and  Saturation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+G">Gaole Pan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yuang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Beibei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Wet powdered materials, such as wet ground or moist walls, are common in the
real world. Despite their particle size being larger than the wavelength, they
remain invisible from a macro view. Reproducing these appearances accurately is
crucial for various applications. Existing methods use different approaches,
such as Monte Carlo path tracing on implicit shapes, which is accurate but
computationally expensive. Another approach involves modeling powdered
materials with a medium using the radiative transfer equation, but these
methods are computationally intensive and lack intuitive parameters. Some works
represent porosity with cylinder-shaped holes on surfaces, but they have
limitations. In this paper, we propose a practical BSDF model called
WetSpongeCake for wet powdered materials. This model includes controllable
physical parameters to faithfully reproduce real-world appearances while
remaining computationally efficient. We reformulate Monte Carlo light transport
on implicit shapes into a medium, utilizing an equivalent phase function for
light transport within ellipsoid-shaped particles and a modified RTE for
porosity and saturation effects. Our novel WetSpongeCake BSDF integrates this
medium into the SpongeCake framework, allowing representation of various wet
powdered material appearances, including both reflection and transmission. We
showcase our model with examples, such as wet paper, sand saturated with
different liquids, and sculptures made of multiple particles.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15635" title="Abstract">arXiv:2401.15635</a> [<a href="/pdf/2401.15635" title="Download PDF">pdf</a>, <a href="/format/2401.15635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecDCL: Dual Contrastive Learning for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yangliao Geng</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+W">Wenwen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhongang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WWW 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of TheWebConf 2024 (WWW '24), May 13--17, 2024,
  Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Self-supervised recommendation (SSR) has achieved great success in mining the
potential interacted behaviors for collaborative filtering in recent years. As
a major branch, Contrastive Learning (CL) based SSR conquers data sparsity in
Web platforms by contrasting the embedding between raw data and augmented data.
However, existing CL-based SSR methods mostly focus on contrasting in a
batch-wise way, failing to exploit potential regularity in the feature-wise
dimension, leading to redundant solutions during the representation learning
process of users (items) from Websites. Furthermore, the joint benefits of
utilizing both Batch-wise CL (BCL) and Feature-wise CL (FCL) for
recommendations remain underexplored. To address these issues, we investigate
the relationship of objectives between BCL and FCL. Our study suggests a
cooperative benefit of employing both methods, as evidenced from theoretical
and experimental perspectives. Based on these insights, we propose a dual CL
method for recommendation, referred to as RecDCL. RecDCL first eliminates
redundant solutions on user-item positive pairs in a feature-wise manner. It
then optimizes the uniform distributions within users and items using a
polynomial kernel from an FCL perspective. Finally, it generates contrastive
embedding on output vectors in a batch-wise objective. We conduct experiments
on four widely-used benchmarks and an industrial dataset. The results
consistently demonstrate that the proposed RecDCL outperforms the
state-of-the-art GNNs-based and SSL-based models (with up to a 5.65\%
improvement in terms of Recall@20), thereby confirming the effectiveness of the
joint-wise objective. All source codes used in this paper are publicly
available at \url{https://github.com/THUDM/RecDCL}}.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15636" title="Abstract">arXiv:2401.15636</a> [<a href="/pdf/2401.15636" title="Download PDF">pdf</a>, <a href="/format/2401.15636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+F">Feihong He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Leilei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+L">Lingyu Si</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fanzhang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The rapid development of generative diffusion models has significantly
advanced the field of style transfer. However, most current style transfer
methods based on diffusion models typically involve a slow iterative
optimization process, e.g., model fine-tuning and textual inversion of style
concept. In this paper, we introduce FreeStyle, an innovative style transfer
method built upon a pre-trained large diffusion model, requiring no further
optimization. Besides, our method enables style transfer only through a text
description of the desired style, eliminating the necessity of style images.
Specifically, we propose a dual-stream encoder and single-stream decoder
architecture, replacing the conventional U-Net in diffusion models. In the
dual-stream encoder, two distinct branches take the content image and style
text prompt as inputs, achieving content and style decoupling. In the decoder,
we further modulate features from the dual streams based on a given content
image and the corresponding style text prompt for precise style transfer. Our
experimental results demonstrate high-quality synthesis and fidelity of our
method across various content images and style text prompts. The code and more
results are available at our project
website:https://freestylefreelunch.github.io/.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15638" title="Abstract">arXiv:2401.15638</a> [<a href="/pdf/2401.15638" title="Download PDF">pdf</a>, <a href="/format/2401.15638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cyto R-CNN and CytoNuke Dataset: Towards reliable whole-cell  segmentation in bright-field histological images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raufeisen%2C+J">Johannes Raufeisen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+K">Kunpeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6rst%2C+F">Fabian H&#xf6;rst</a>, 
<a href="/search/cs?searchtype=author&query=Braunschweig%2C+T">Till Braunschweig</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianning Li</a>, 
<a href="/search/cs?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6hrig%2C+R">Rainer R&#xf6;hrig</a>, 
<a href="/search/cs?searchtype=author&query=Egger%2C+J">Jan Egger</a>, 
<a href="/search/cs?searchtype=author&query=Leibe%2C+B">Bastian Leibe</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6lzle%2C+F">Frank H&#xf6;lzle</a>, 
<a href="/search/cs?searchtype=author&query=Hermans%2C+A">Alexander Hermans</a>, 
<a href="/search/cs?searchtype=author&query=Puladi%2C+B">Behrus Puladi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Background: Cell segmentation in bright-field histological slides is a
crucial topic in medical image analysis. Having access to accurate segmentation
allows researchers to examine the relationship between cellular morphology and
clinical observations. Unfortunately, most segmentation methods known today are
limited to nuclei and cannot segmentate the cytoplasm.
<br />Material &amp; Methods: We present a new network architecture Cyto R-CNN that is
able to accurately segment whole cells (with both the nucleus and the
cytoplasm) in bright-field images. We also present a new dataset CytoNuke,
consisting of multiple thousand manual annotations of head and neck squamous
cell carcinoma cells. Utilizing this dataset, we compared the performance of
Cyto R-CNN to other popular cell segmentation algorithms, including QuPath's
built-in algorithm, StarDist and Cellpose. To evaluate segmentation
performance, we calculated AP50, AP75 and measured 17 morphological and
staining-related features for all detected cells. We compared these
measurements to the gold standard of manual segmentation using the
Kolmogorov-Smirnov test.
<br />Results: Cyto R-CNN achieved an AP50 of 58.65\% and an AP75 of 11.56\% in
whole-cell segmentation, outperforming all other methods (QuPath
$19.46/0.91\%$; StarDist $45.33/2.32\%$; Cellpose $31.85/5.61\%$). Cell
features derived from Cyto R-CNN showed the best agreement to the gold standard
($\bar{D} = 0.15$) outperforming QuPath ($\bar{D} = 0.22$), StarDist ($\bar{D}
= 0.25$) and Cellpose ($\bar{D} = 0.23$).
<br />Conclusion: Our newly proposed Cyto R-CNN architecture outperforms current
algorithms in whole-cell segmentation while providing more reliable cell
measurements than any other model. This could improve digital pathology
workflows, potentially leading to improved diagnosis. Moreover, our published
dataset can be used to develop further models in the future.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15639" title="Abstract">arXiv:2401.15639</a> [<a href="/pdf/2401.15639" title="Download PDF">pdf</a>, <a href="/format/2401.15639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TOP: Towards Open &amp; Predictable Heterogeneous SoCs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valente%2C+L">Luca Valente</a>, 
<a href="/search/cs?searchtype=author&query=Restuccia%2C+F">Francesco Restuccia</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+D">Davide Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Kastner%2C+R">Ryan Kastner</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Ensuring predictability in modern real-time Systems-on-Chip (SoCs) is an
increasingly critical concern for many application domains such as automotive,
robotics, and industrial automation. An effective approach involves the
modeling and development of hardware components, such as interconnects and
shared memory resources, to evaluate or enforce their deterministic behavior.
Unfortunately, these IPs are often closed-source, and these studies are limited
to the single modules that must later be integrated with third-party IPs in
more complex SoCs, hindering the precision and scope of modeling and
compromising the overall predictability. With the coming-of-age of open-source
instruction set architectures (RISC-V) and hardware, major opportunities for
changing this status quo are emerging. This study introduces an innovative
methodology for modeling and analyzing State-of-the-Art (SoA) open-source SoCs
for low-power cyber-physical systems. Our approach models and analyzes the
entire set of open-source IPs within these SoCs and then provides a
comprehensive analysis of the entire architecture. We validate this methodology
on a sample heterogenous low-power RISC-V architecture through RTL simulation
and FPGA implementation, minimizing pessimism in bounding the service time of
transactions crossing the architecture between 28% and 1%, which is
considerably lower when compared to similar SoA works.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15641" title="Abstract">arXiv:2401.15641</a> [<a href="/pdf/2401.15641" title="Download PDF">pdf</a>, <a href="/format/2401.15641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRE: A Peer Review Based Large Language Model Evaluator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhumin Chu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Y">Yiteng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haitao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The impressive performance of large language models (LLMs) has attracted
considerable attention from the academic and industrial communities. Besides
how to construct and train LLMs, how to effectively evaluate and compare the
capacity of LLMs has also been well recognized as an important yet difficult
problem. Existing paradigms rely on either human annotators or model-based
evaluators to evaluate the performance of LLMs on different tasks. However,
these paradigms often suffer from high cost, low generalizability, and
inherited biases in practice, which make them incapable of supporting the
sustainable development of LLMs in long term. In order to address these issues,
inspired by the peer review systems widely used in academic publication
process, we propose a novel framework that can automatically evaluate LLMs
through a peer-review process. Specifically, for the evaluation of a specific
task, we first construct a small qualification exam to select "reviewers" from
a couple of powerful LLMs. Then, to actually evaluate the "submissions" written
by different candidate LLMs, i.e., the evaluatees, we use the reviewer LLMs to
rate or compare the submissions. The final ranking of evaluatee LLMs is
generated based on the results provided by all reviewers. We conducted
extensive experiments on text summarization tasks with eleven LLMs including
GPT-4. The results demonstrate the existence of biasness when evaluating using
a single LLM. Also, our PRE model outperforms all the baselines, illustrating
the effectiveness of the peer review mechanism.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15646" title="Abstract">arXiv:2401.15646</a> [<a href="/pdf/2401.15646" title="Download PDF">pdf</a>, <a href="/format/2401.15646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Data Augmentation for Robust Visual Question Answering with  Effective Curriculum Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yuhang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Being widely used in learning unbiased visual question answering (VQA)
models, Data Augmentation (DA) helps mitigate language biases by generating
extra training samples beyond the original samples. While today's DA methods
can generate robust samples, the augmented training set, significantly larger
than the original dataset, often exhibits redundancy in terms of difficulty or
content repetition, leading to inefficient model training and even compromising
the model performance. To this end, we design an Effective Curriculum Learning
strategy ECL to enhance DA-based VQA methods. Intuitively, ECL trains VQA
models on relatively ``easy'' samples first, and then gradually changes to
``harder'' samples, and less-valuable samples are dynamically removed. Compared
to training on the entire augmented dataset, our ECL strategy can further
enhance VQA models' performance with fewer training samples. Extensive
ablations have demonstrated the effectiveness of ECL on various methods.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15647" title="Abstract">arXiv:2401.15647</a> [<a href="/pdf/2401.15647" title="Download PDF">pdf</a>, <a href="/format/2401.15647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UP-CrackNet: Unsupervised Pixel-Wise Road Crack Detection via  Adversarial Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+N">Nachuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lihua Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Over the past decade, automated methods have been developed to detect cracks
more efficiently, accurately, and objectively, with the ultimate goal of
replacing conventional manual visual inspection techniques. Among these
methods, semantic segmentation algorithms have demonstrated promising results
in pixel-wise crack detection tasks. However, training such data-driven
algorithms requires a large amount of human-annotated datasets with pixel-level
annotations, which is a highly labor-intensive and time-consuming process.
Moreover, supervised learning-based methods often struggle with poor
generalization ability in unseen datasets. Therefore, we propose an
unsupervised pixel-wise road crack detection network, known as UP-CrackNet. Our
approach first generates multi-scale square masks and randomly selects them to
corrupt undamaged road images by removing certain regions. Subsequently, a
generative adversarial network is trained to restore the corrupted regions by
leveraging the semantic context learned from surrounding uncorrupted regions.
During the testing phase, an error map is generated by calculating the
difference between the input and restored images, which allows for pixel-wise
crack detection. Our comprehensive experimental results demonstrate that
UP-CrackNet outperforms other general-purpose unsupervised anomaly detection
algorithms, and exhibits comparable performance and superior generalizability
when compared with state-of-the-art supervised crack segmentation algorithms.
Our source code is publicly available at mias.group/UP-CrackNet.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15648" title="Abstract">arXiv:2401.15648</a> [<a href="/pdf/2401.15648" title="Download PDF">pdf</a>, <a href="/format/2401.15648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A computational approach to identify the material parameters of the  relaxed micromorphic model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sarhil%2C+M">Mohammad Sarhil</a>, 
<a href="/search/math?searchtype=author&query=Scheunemann%2C+L">Lisa Scheunemann</a>, 
<a href="/search/math?searchtype=author&query=Lewintan%2C+P">Peter Lewintan</a>, 
<a href="/search/math?searchtype=author&query=Schr%C3%B6der%2C+J">J&#xf6;rg Schr&#xf6;der</a>, 
<a href="/search/math?searchtype=author&query=Neff%2C+P">Patrizio Neff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We determine the material parameters in the relaxed micromorphic generalized
continuum model for a given periodic microstructure in this work. This is
achieved through a least squares fitting of the total energy of the relaxed
micromorphic homogeneous continuum to the total energy of the fully-resolved
heterogeneous microstructure, governed by classical linear elasticity. The
relaxed micromorphic model is a generalized continuum that utilizes the $\Curl$
of a micro-distortion field instead of its full gradient as in the classical
micromorphic theory, leading to several advantages and differences. The most
crucial advantage is that it operates between two well-defined scales. These
scales are determined by linear elasticity with microscopic and macroscopic
elasticity tensors, which respectively bound the stiffness of the relaxed
micromorphic continuum from above and below. While the macroscopic elasticity
tensor is established a priori through standard periodic first-order
homogenization, the microscopic elasticity tensor remains to be determined.
Additionally, the characteristic length parameter, associated with curvature
measurement, controls the transition between the micro- and macro-scales. Both
the microscopic elasticity tensor and the characteristic length parameter are
here determined using a computational approach based on the least squares
fitting of energies. This process involves the consideration of an adequate
number of quadratic deformation modes and different specimen sizes. We conduct
a comparative analysis between the least square fitting results of the relaxed
micromorphic model, the fitting of a skew-symmetric micro-distortion field
(Cosserat-micropolar model), and the fitting of the classical micromorphic
model with two different formulations for the curvature...
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15649" title="Abstract">arXiv:2401.15649</a> [<a href="/pdf/2401.15649" title="Download PDF">pdf</a>, <a href="/format/2401.15649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CPDM: Content-Preserving Diffusion Model for Underwater Image  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaowen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan-Gen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Underwater image enhancement (UIE) is challenging since image degradation in
aquatic environments is complicated and changing over time. Existing mainstream
methods rely on either physical-model or data-driven, suffering from
performance bottlenecks due to changes in imaging conditions or training
instability. In this article, we make the first attempt to adapt the diffusion
model to the UIE task and propose a Content-Preserving Diffusion Model (CPDM)
to address the above challenges. CPDM first leverages a diffusion model as its
fundamental model for stable training and then designs a content-preserving
framework to deal with changes in imaging conditions. Specifically, we
construct a conditional input module by adopting both the raw image and the
difference between the raw and noisy images as the input, which can enhance the
model's adaptability by considering the changes involving the raw images in
underwater environments. To preserve the essential content of the raw images,
we construct a content compensation module for content-aware training by
extracting low-level features from the raw images. Extensive experimental
results validate the effectiveness of our CPDM, surpassing the state-of-the-art
methods in terms of both subjective and objective metrics.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15652" title="Abstract">arXiv:2401.15652</a> [<a href="/pdf/2401.15652" title="Download PDF">pdf</a>, <a href="/format/2401.15652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-Multiple Image Outpainting in One-Step via Positional Query  and A Diffusion-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jinfa Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image outpainting aims to generate the content of an input sub-image beyond
its original boundaries. It is an important task in content generation yet
remains an open problem for generative models. This paper pushes the technical
frontier of image outpainting in two directions that have not been resolved in
literature: 1) outpainting with arbitrary and continuous multiples (without
restriction), and 2) outpainting in a single step (even for large expansion
multiples). Moreover, we develop a method that does not depend on a pre-trained
backbone network, which is in contrast commonly required by the previous SOTA
outpainting methods. The arbitrary multiple outpainting is achieved by
utilizing randomly cropped views from the same image during training to capture
arbitrary relative positional information. Specifically, by feeding one view
and positional embeddings as queries, we can reconstruct another view. At
inference, we generate images with arbitrary expansion multiples by inputting
an anchor image and its corresponding positional embeddings. The one-step
outpainting ability here is particularly noteworthy in contrast to previous
methods that need to be performed for $N$ times to obtain a final multiple
which is $N$ times of its basic and fixed multiple. We evaluate the proposed
approach (called PQDiff as we adopt a diffusion-based generator as our
embodiment, under our proposed \textbf{P}ositional \textbf{Q}uery scheme) on
public benchmarks, demonstrating its superior performance over state-of-the-art
approaches. Specifically, PQDiff achieves state-of-the-art FID scores on the
Scenery (\textbf{21.512}), Building Facades (\textbf{25.310}), and WikiArts
(\textbf{36.212}) datasets. Furthermore, under the 2.25x, 5x and 11.7x
outpainting settings, PQDiff only takes \textbf{40.6\%}, \textbf{20.3\%} and
\textbf{10.2\%} of the time of the benchmark state-of-the-art (SOTA) method.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15656" title="Abstract">arXiv:2401.15656</a> [<a href="/pdf/2401.15656" title="Download PDF">pdf</a>, <a href="/format/2401.15656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLsM: Generative Linguistic Steganography with Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruiqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingxiao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Linguistic Steganography (LS) tasks aim to generate steganographic texts
(stego) based on secret information. Only authorized recipients can perceive
the existence of secret information in the texts and accurately extract it,
thereby preserving privacy. However, the controllability of the stego generated
by existing schemes is poor, and the generated stego is difficult to contain
specific discourse characteristics such as style, genre, and theme. As a
result, the stego are often easily detectable, compromising covert
communication. To address these problems, this paper proposes a novel scheme
named LLsM, a generative LS based on a Large Language Model (LLM). We
fine-tuned the LLM LLaMA2 with a large-scale constructed dataset encompassing
rich discourse characteristics, which enables the fine-tuned LLM to generate
texts with specific discourse in a controllable manner. Then the discourse
characteristics are used as guiding information and inputted into the
fine-tuned LLM in the form of Prompt together with secret information. The
candidate pool, derived from sampling and truncation, undergoes range encoding
to ensure the stego imitate natural text distribution. Experiments demonstrate
that LLsM performs superior to prevalent baselines regarding text quality,
statistical analysis, discourse matching, and anti-steganalysis. In particular,
LLsM's MAUVE surpasses that of some baselines by 70%-80%, and its
anti-steganalysis performance is 30%-40% higher. Notably, we also present the
long stego generated by LLsM, showing its potential superiority in long LS
tasks.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15657" title="Abstract">arXiv:2401.15657</a> [<a href="/pdf/2401.15657" title="Download PDF">pdf</a>, <a href="/format/2401.15657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Free Generalized Zero-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bowen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Long Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning models have the ability to extract rich knowledge from
large-scale datasets. However, the sharing of data has become increasingly
challenging due to concerns regarding data copyright and privacy. Consequently,
this hampers the effective transfer of knowledge from existing data to novel
downstream tasks and concepts. Zero-shot learning (ZSL) approaches aim to
recognize new classes by transferring semantic knowledge learned from base
classes. However, traditional generative ZSL methods often require access to
real images from base classes and rely on manually annotated attributes, which
presents challenges in terms of data restrictions and model scalability. To
this end, this paper tackles a challenging and practical problem dubbed as
data-free zero-shot learning (DFZSL), where only the CLIP-based base classes
data pre-trained classifier is available for zero-shot classification.
Specifically, we propose a generic framework for DFZSL, which consists of three
main components. Firstly, to recover the virtual features of the base data, we
model the CLIP features of base class images as samples from a von Mises-Fisher
(vMF) distribution based on the pre-trained classifier. Secondly, we leverage
the text features of CLIP as low-cost semantic information and propose a
feature-language prompt tuning (FLPT) method to further align the virtual image
features and textual features. Thirdly, we train a conditional generative model
using the well-aligned virtual image features and corresponding semantic text
features, enabling the generation of new classes features and achieve better
zero-shot generalization. Our framework has been evaluated on five commonly
used benchmarks for generalized ZSL, as well as 11 benchmarks for the
base-to-new ZSL. The results demonstrate the superiority and effectiveness of
our approach. Our code is available in https://github.com/ylong4/DFZSL
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15661" title="Abstract">arXiv:2401.15661</a> [<a href="/pdf/2401.15661" title="Download PDF">pdf</a>, <a href="/format/2401.15661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Complexity to Simplicity: Brain-Inspired Modularization of PINN  Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Markidis%2C+S">Stefano Markidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the 24th International Conference on Computational Science (ICCS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for
solving partial differential equations (PDEs) in various scientific and
engineering domains. However, traditional PINN architectures typically rely on
fully connected multilayer perceptrons (MLPs), lacking the sparsity and
modularity inherent in many traditional numerical solvers. This study
investigates a novel approach by merging established PINN methodologies with
brain-inspired neural network techniques to address this architectural
limitation. We leverage Brain-Inspired Modular Training (BIMT), leveraging
concepts such as locality, sparsity, and modularity inspired by the
organization of the brain. Through BIMT, we demonstrate the evolution of PINN
architectures from fully connected structures to highly sparse and modular
forms, resulting in reduced computational complexity and memory requirements.
We showcase the efficacy of this approach by solving differential equations
with varying spectral components, revealing insights into the spectral bias
phenomenon and its impact on neural network architecture. Moreover, we derive
basic PINN building blocks through BIMT training on simple problems akin to
convolutional and attention modules in deep neural networks, enabling the
construction of modular PINN architectures. Our experiments show that these
modular architectures offer improved accuracy compared to traditional fully
connected MLP PINNs, showcasing their potential for enhancing PINN performance
while reducing computational overhead. Overall, this study contributes to
advancing the understanding and development of efficient and effective neural
network architectures for solving PDEs, bridging the gap between PINNs and
traditional numerical methods.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15662" title="Abstract">arXiv:2401.15662</a> [<a href="/pdf/2401.15662" title="Download PDF">pdf</a>, <a href="/ps/2401.15662" title="Download PostScript">ps</a>, <a href="/format/2401.15662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transit Functions and Clustering Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Changat%2C+M">Manoj Changat</a>, 
<a href="/search/cs?searchtype=author&query=Shanavas%2C+A+V">Ameera Vaheeda Shanavas</a>, 
<a href="/search/cs?searchtype=author&query=Stadler%2C+P+F">Peter F. Stadler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figues, submitting to the journal Applicapable Analysis and Discrete Mathematics (AADM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Transit functions serve not only as abstractions of betweenness and convexity
but are also closely connected with clustering systems. Here, we investigate
the canonical transit functions of binary clustering systems inspired by
pyramids, i.e., interval hypergraphs. We provide alternative characterizations
of weak hierarchies, and describe union-closed binary clustering systems as a
subclass of pyramids and weakly pyramidal clustering systems as an interesting
generalization.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15664" title="Abstract">arXiv:2401.15664</a> [<a href="/pdf/2401.15664" title="Download PDF">pdf</a>, <a href="/format/2401.15664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Human-like Locomotion Based on Biological Actuation and Rewards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minkwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yoonsang Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH 2023 Posters
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIGGRAPH '23: ACM SIGGRAPH 2023 Posters, July 2023, Article No.:
  5, Pages 1-2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">We propose a method of learning a policy for human-like locomotion via deep
reinforcement learning based on a human anatomical model, muscle actuation, and
biologically inspired rewards, without any inherent control rules or reference
motions. Our main ideas involve providing a dense reward using metabolic energy
consumption at every step during the initial stages of learning and then
transitioning to a sparse reward as learning progresses, and adjusting the
initial posture of the human model to facilitate the exploration of locomotion.
Additionally, we compared and analyzed differences in learning outcomes across
various settings other than the proposed method.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15666" title="Abstract">arXiv:2401.15666</a> [<a href="/pdf/2401.15666" title="Download PDF">pdf</a>, <a href="/format/2401.15666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error-Correcting Codes for Combinatorial DNA Composite
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabary%2C+O">Omer Sabary</a>, 
<a href="/search/cs?searchtype=author&query=Preuss%2C+I">Inbal Preuss</a>, 
<a href="/search/cs?searchtype=author&query=Gabrys%2C+R">Ryan Gabrys</a>, 
<a href="/search/cs?searchtype=author&query=Yakhini%2C+Z">Zohar Yakhini</a>, 
<a href="/search/cs?searchtype=author&query=Anavy%2C+L">Leon Anavy</a>, 
<a href="/search/cs?searchtype=author&query=Yaakobi%2C+E">Eitan Yaakobi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Data storage in DNA is developing as a possible solution for archival digital
data. Recently, to further increase the potential capacity of DNA-based data
storage systems, the combinatorial composite DNA synthesis method was
suggested. This approach extends the DNA alphabet by harnessing short DNA
fragment reagents, known as shortmers. The shortmers are building blocks of the
alphabet symbols, consisting of a fixed number of shortmers. Thus, when
information is read, it is possible that one of the shortmers that forms part
of the composition of a symbol is missing and therefore the symbol cannot be
determined. In this paper, we model this type of error as a type of asymmetric
error and propose code constructions that can correct such errors in this
setup. We also provide a lower bound on the redundancy of such error-correcting
codes and give an explicit encoder and decoder pair for our construction. Our
suggested error model is also supported by an analysis of data from actual
experiments that produced DNA according to the combinatorial scheme. Lastly, we
also provide a statistical evaluation of the probability of observing such
error events, as a function of read depth.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15668" title="Abstract">arXiv:2401.15668</a> [<a href="/pdf/2401.15668" title="Download PDF">pdf</a>, <a href="/format/2401.15668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lips Are Lying: Spotting the Temporal Inconsistency between Audio and  Visual in Lip-Syncing DeepFakes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+T">Tianyi She</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Run Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+D">Dongyu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Ziyou Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, DeepFake technology has achieved unprecedented success in
high-quality video synthesis, whereas these methods also pose potential and
severe security threats to humanity. DeepFake can be bifurcated into
entertainment applications like face swapping and illicit uses such as
lip-syncing fraud. However, lip-forgery videos, which neither change identity
nor have discernible visual artifacts, present a formidable challenge to
existing DeepFake detection methods. Our preliminary experiments have shown
that the effectiveness of the existing methods often drastically decreases or
even fails when tackling lip-syncing videos.
<br />In this paper, for the first time, we propose a novel approach dedicated to
lip-forgery identification that exploits the inconsistency between lip
movements and audio signals. We also mimic human natural cognition by capturing
subtle biological links between lips and head regions to boost accuracy. To
better illustrate the effectiveness and advances of our proposed method, we
curate a high-quality LipSync dataset by employing the SOTA lip generator. We
hope this high-quality and diverse dataset could be well served the further
research on this challenging and interesting field. Experimental results show
that our approach gives an average accuracy of more than 95.3% in spotting
lip-syncing videos, significantly outperforming the baselines. Extensive
experiments demonstrate the capability to tackle deepfakes and the robustness
in surviving diverse input transformations. Our method achieves an accuracy of
up to 90.2% in real-world scenarios (e.g., WeChat video call) and shows its
powerful capabilities in real scenario deployment. To facilitate the progress
of this research community, we release all resources at
https://github.com/AaronComo/LipFD.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15669" title="Abstract">arXiv:2401.15669</a> [<a href="/pdf/2401.15669" title="Download PDF">pdf</a>, <a href="/ps/2401.15669" title="Download PostScript">ps</a>, <a href="/format/2401.15669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Programmable biomolecule-mediated processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+J">Jian-Jun Shu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z+H">Zi Hian Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi-Wen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yong%2C+K">Kian-Yan Yong</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of the American Chemical Society, Vol. 145, No. 46, pp.
  25033-25042, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Programmable biomolecule-mediated computing is a new computing paradigm as
compared to contemporary electronic computing. It employs nucleic acids and
analogous biomolecular structures as information-storing and -processing
substrates to tackle computational problems. It is of great significance to
investigate the various issues of programmable biomolecule-mediated processors
that are capable of automatically processing, storing, and displaying
information. This Perspective provides several conceptual designs of
programmable biomolecule-mediated processors and provides some insights into
potential future research directions for programmable biomolecule-mediated
processors.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15670" title="Abstract">arXiv:2401.15670</a> [<a href="/pdf/2401.15670" title="Download PDF">pdf</a>, <a href="/format/2401.15670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YODA: Teacher-Student Progressive Learning for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianqiao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanjun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhijiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenyong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baojun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lifeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Although large language models (LLMs) have demonstrated adeptness in a range
of tasks, they still lag behind human learning efficiency. This disparity is
often linked to the inherent human capacity to learn from basic examples,
gradually generalize and handle more complex problems, and refine their skills
with continuous feedback. Inspired by this, this paper introduces YODA, a novel
teacher-student progressive learning framework that emulates the
teacher-student education process to improve the efficacy of model fine-tuning.
The framework operates on an interactive \textit{basic-generalized-harder}
loop. The teacher agent provides tailored feedback on the student's answers,
and systematically organizes the education process. This process unfolds by
teaching the student basic examples, reinforcing understanding through
generalized questions, and then enhancing learning by posing questions with
progressively enhanced complexity. With the teacher's guidance, the student
learns to iteratively refine its answer with feedback, and forms a robust and
comprehensive understanding of the posed questions. The systematic procedural
data, which reflects the progressive learning process of humans, is then
utilized for model training. Taking math reasoning as a testbed, experiments
show that training LLaMA2 with data from YODA improves SFT with significant
performance gain (+17.01\% on GSM8K and +9.98\% on MATH). In addition, we find
that training with curriculum learning further improves learning robustness.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15672" title="Abstract">arXiv:2401.15672</a> [<a href="/pdf/2401.15672" title="Download PDF">pdf</a>, <a href="/ps/2401.15672" title="Download PostScript">ps</a>, <a href="/format/2401.15672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Echo State Network for Parkinson&#x27;s Disease Prediction using  Voice Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseininian%2C+S+Z+S">Seyedeh Zahra Seyedi Hosseininian</a>, 
<a href="/search/cs?searchtype=author&query=Tajari%2C+A">Ahmadreza Tajari</a>, 
<a href="/search/cs?searchtype=author&query=Ghalehnoie%2C+M">Mohsen Ghalehnoie</a>, 
<a href="/search/cs?searchtype=author&query=Alfi%2C+A">Alireza Alfi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Parkinson's disease (PD) is a debilitating neurological disorder that
necessitates precise and early diagnosis for effective patient care. This study
aims to develop a diagnostic model capable of achieving both high accuracy and
minimizing false negatives, a critical factor in clinical practice. Given the
limited training data, a feature selection strategy utilizing ANOVA is employed
to identify the most informative features. Subsequently, various machine
learning methods, including Echo State Networks (ESN), Random Forest, k-nearest
Neighbors, Support Vector Classifier, Extreme Gradient Boosting, and Decision
Tree, are employed and thoroughly evaluated. The statistical analyses of the
results highlight ESN's exceptional performance, showcasing not only superior
accuracy but also the lowest false negative rate among all methods.
Consistently, statistical data indicates that the ESN method consistently
maintains a false negative rate of less than 8% in 83% of cases. ESN's capacity
to strike a delicate balance between diagnostic precision and minimizing
misclassifications positions it as an exemplary choice for PD diagnosis,
especially in scenarios characterized by limited data. This research marks a
significant step towards more efficient and reliable PD diagnosis, with
potential implications for enhanced patient outcomes and healthcare dynamics.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15674" title="Abstract">arXiv:2401.15674</a> [<a href="/pdf/2401.15674" title="Download PDF">pdf</a>, <a href="/format/2401.15674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Receding Horizon 3D Coverage Control with a Team of  Networked Aerial Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papaioannou%2C+S">Savvas Papaioannou</a>, 
<a href="/search/cs?searchtype=author&query=Kolios%2C+P">Panayiotis Kolios</a>, 
<a href="/search/cs?searchtype=author&query=Theocharides%2C+T">Theocharis Theocharides</a>, 
<a href="/search/cs?searchtype=author&query=Panayiotou%2C+C+G">Christos G. Panayiotou</a>, 
<a href="/search/cs?searchtype=author&query=Polycarpou%2C+M+M">Marios M. Polycarpou</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 62nd IEEE Conference on Decision and Control (CDC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work proposes a receding horizon coverage control approach which allows
multiple autonomous aerial agents to work cooperatively in order cover the
total surface area of a 3D object of interest. The cooperative coverage problem
which is posed in this work as an optimal control problem, jointly optimizes
the agents' kinematic and camera control inputs, while considering coupling
constraints amongst the team of agents which aim at minimizing the duplication
of work. To generate look-ahead coverage trajectories over a finite planning
horizon, the proposed approach integrates visibility constraints into the
proposed coverage controller in order to determine the visible part of the
object with respect to the agents' future states. In particular, we show how
non-linear and non-convex visibility determination constraints can be
transformed into logical constraints which can easily be embedded into a mixed
integer optimization program.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15675" title="Abstract">arXiv:2401.15675</a> [<a href="/pdf/2401.15675" title="Download PDF">pdf</a>, <a href="/ps/2401.15675" title="Download PostScript">ps</a>, <a href="/format/2401.15675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of a facemask in real-time using deep learning methods:  Prevention of Covid 19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+G+S">Gautam Siddharth Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Sohlot%2C+J">Jatin Sohlot</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+A">Ayesha Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+R">Ramsha Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+K">Karan Malik</a>, 
<a href="/search/cs?searchtype=author&query=Wazir%2C+S">Samar Wazir</a>, 
<a href="/search/cs?searchtype=author&query=Brownlee%2C+A+E+I">Alexander E. I. Brownlee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Research Advances in Network Technologies (Volume 2) (CRC Press Taylor and Francis), 2023 (Accepted)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A health crisis is raging all over the world with the rapid transmission of
the novel-coronavirus disease (Covid-19). Out of the guidelines issued by the
World Health Organisation (WHO) to protect us against Covid-19, wearing a
facemask is the most effective. Many countries have necessitated the wearing of
face masks, but monitoring a large number of people to ensure that they are
wearing masks in a crowded place is a challenging task in itself. The
novel-coronavirus disease (Covid-19) has already affected our day-to-day life
as well as world trade movements. By the end of April 2021, the world has
recorded 144,358,956 confirmed cases of novel-coronavirus disease (Covid-19)
including 3,066,113 deaths according to the world health organization (WHO).
These increasing numbers motivate automated techniques for the detection of a
facemask in real-time scenarios for the prevention of Covid-19. We propose a
technique using deep learning that works for single and multiple people in a
frame recorded via webcam in still or in motion. We have also experimented with
our approach in night light. The accuracy of our model is good compared to the
other approaches in the literature; ranging from 74% for multiple people in a
nightlight to 99% for a single person in daylight.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15677" title="Abstract">arXiv:2401.15677</a> [<a href="/pdf/2401.15677" title="Download PDF">pdf</a>, <a href="/ps/2401.15677" title="Download PostScript">ps</a>, <a href="/format/2401.15677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A probabilistic analysis on general probabilistic scheduling problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suruga%2C+D">Daiki Suruga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The scheduling problem is a key class of optimization problems and has
various kinds of applications both in practical and theoretical scenarios. In
the scheduling problem, probabilistic analysis is a basic tool for
investigating performance of scheduling algorithms, and therefore has been
carried out by plenty amount of prior works. However, probabilistic analysis
has several potential problems. For example, current research interest in the
scheduling problem is limited to i.i.d. scenarios, due to its simplicity for
analysis. This paper provides a new framework for probabilistic analysis in the
scheduling problem and aims to deal with such problems. As a consequence, we
obtain several theorems including a theoretical limit of the scheduling problem
which can be applied to \emph{general, non-i.i.d. probability distributions}.
Several information theoretic techniques, such as \emph{information-spectrum
method}, turned out to be useful to prove our results. Since the scheduling
problem has relations to many other research fields, our framework hopefully
yields other interesting applications in the future.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15678" title="Abstract">arXiv:2401.15678</a> [<a href="/pdf/2401.15678" title="Download PDF">pdf</a>, <a href="/format/2401.15678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Subproduct Codes with Reed-Muller-like Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siddheshwar%2C+A">Aditya Siddheshwar</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+L+P">Lakshmi Prasad Natarajan</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+P">Prasad Krishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We study a family of subcodes of the $m$-dimensional product code
$\mathscr{C}^{\otimes m}$ ('subproduct codes') that have a recursive
Plotkin-like structure, and which include Reed-Muller (RM) codes and Dual
Berman codes as special cases. We denote the codes in this family as
$\mathscr{C}^{\otimes [r,m]}$, where $0 \leq r \leq m$ is the 'order' of the
code. These codes allow a 'projection' operation that can be exploited in
iterative decoding, viz., the sum of two carefully chosen subvectors of any
codeword in $\mathscr{C}^{\otimes [r,m]}$ belongs to $\mathscr{C}^{\otimes
[r-1,m-1]}$. Recursive subproduct codes provide a wide range of rates and block
lengths compared to RM codes while possessing several of their structural
properties, such as the Plotkin-like design, the projection property, and fast
ML decoding of first-order codes. Our simulation results for first-order and
second-order codes, that are based on a belief propagation decoder and a local
graph search algorithm, show instances of subproduct codes that perform either
better than or within 0.5 dB of comparable RM codes and CRC-aided Polar codes.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15681" title="Abstract">arXiv:2401.15681</a> [<a href="/pdf/2401.15681" title="Download PDF">pdf</a>, <a href="/format/2401.15681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Word Embedding to Reading Embedding Using Large Language Model, EEG  and Eye-tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shilai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cauwenberghs%2C+G">Gert Cauwenberghs</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+T">Tzyy-Ping Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Reading comprehension, a fundamental cognitive ability essential for
knowledge acquisition, is a complex skill, with a notable number of learners
lacking proficiency in this domain. This study introduces innovative tasks for
Brain-Computer Interface (BCI), predicting the relevance of words or tokens
read by individuals to the target inference words. We use state-of-the-art
Large Language Models (LLMs) to guide a new reading embedding representation in
training. This representation, integrating EEG and eye-tracking biomarkers
through an attention-based transformer encoder, achieved a mean 5-fold
cross-validation accuracy of 68.7% across nine subjects using a balanced
sample, with the highest single-subject accuracy reaching 71.2%. This study
pioneers the integration of LLMs, EEG, and eye-tracking for predicting human
reading comprehension at the word level. We fine-tune the pre-trained
Bidirectional Encoder Representations from Transformers (BERT) model for word
embedding, devoid of information about the reading tasks. Despite this absence
of task-specific details, the model effortlessly attains an accuracy of 92.7%,
thereby validating our findings from LLMs. This work represents a preliminary
step toward developing tools to assist reading.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15683" title="Abstract">arXiv:2401.15683</a> [<a href="/pdf/2401.15683" title="Download PDF">pdf</a>, <a href="/ps/2401.15683" title="Download PostScript">ps</a>, <a href="/format/2401.15683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Small-depth Frege Proofs for PHP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%A5stad%2C+J">Johan H&#xe5;stad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version published in FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We study Frege proofs for the one-to-one graph Pigeon Hole Principle defined
on the $n\times n$ grid where $n$ is odd. We are interested in the case where
each formula in the proof is a depth $d$ formula in the basis given by $\land$,
$\lor$, and $\neg$. We prove that in this situation the proof needs to be of
size exponential in $n^{\Omega (1/d)}$. If we restrict the size of each line in
the proof to be of size $M$ then the number of lines needed is exponential in
$n/(\log M)^{O(d)}$. The main technical component of the proofs is to design a
new family of random restrictions and to prove the appropriate switching
lemmas.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15685" title="Abstract">arXiv:2401.15685</a> [<a href="/pdf/2401.15685" title="Download PDF">pdf</a>, <a href="/format/2401.15685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of Autism and ADHD: A Comparative Analysis of Drawing  Velocity Profiles and the NEPSY Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fortea-Sevilla%2C+S">S. Fortea-Sevilla</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Sosa.%2C+A">A. Garcia-Sosa.</a>, 
<a href="/search/cs?searchtype=author&query=Morales-Almeida%2C+P">P. Morales-Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Carmona-Duarte%2C+C">C. Carmona-Duarte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ISBN: 978-972-778-328-1 . 21th Conference of the International Graphonomics Society (IGS2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Fortea-Sevilla, S., Garcia-Sosa, A., Morales, P., Carmona-Duarte,
  C.,Assessment of autism and adhd: A comparative analysis of drawing velocity
  profiles and the nepsy test. 21th Conference of the International
  Graphonomics Society,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The increasing prevalence of Autism Spectrum Disorder and Attention-Deficit/
Hyperactivity Disorder among students highlights the need to improve evaluation
and diagnostic techniques, as well as effective tools to mitigate the negative
consequences associated with these disorders. With the widespread use of
touchscreen mobile devices, there is an opportunity to gather comprehensive
data beyond visual cues. These devices enable the collection and visualization
of information on velocity profiles and the time taken to complete drawing and
handwriting tasks. These data can be leveraged to develop new
neuropsychological tests based on the velocity profile that assists in
distinguishing between challenging cases of ASD and ADHD that are difficult to
differentiate in clinical practice. In this paper, we present a proof of
concept that compares and combines the results obtained from standardized tasks
in the NEPSY-II assessment with a proposed observational scale based on the
visual analysis of the velocity profile collected using digital tablets.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15687" title="Abstract">arXiv:2401.15687</a> [<a href="/pdf/2401.15687" title="Download PDF">pdf</a>, <a href="/format/2401.15687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Media2Face: Co-speech Facial Animation Generation With Multi-Modality  Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qingcheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+P">Pengyu Long</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+D">Dafei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Han Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Longwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://sites.google.com/view/media2face">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">The synthesis of 3D facial animations from speech has garnered considerable
attention. Due to the scarcity of high-quality 4D facial data and
well-annotated abundant multi-modality labels, previous methods often suffer
from limited realism and a lack of lexible conditioning. We address this
challenge through a trilogy. We first introduce Generalized Neural Parametric
Facial Asset (GNPFA), an efficient variational auto-encoder mapping facial
geometry and images to a highly generalized expression latent space, decoupling
expressions and identities. Then, we utilize GNPFA to extract high-quality
expressions and accurate head poses from a large array of videos. This presents
the M2F-D dataset, a large, diverse, and scan-level co-speech 3D facial
animation dataset with well-annotated emotional and style labels. Finally, we
propose Media2Face, a diffusion model in GNPFA latent space for co-speech
facial animation generation, accepting rich multi-modality guidances from
audio, text, and image. Extensive experiments demonstrate that our model not
only achieves high fidelity in facial animation synthesis but also broadens the
scope of expressiveness and style adaptability in 3D facial animation.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15688" title="Abstract">arXiv:2401.15688</a> [<a href="/pdf/2401.15688" title="Download PDF">pdf</a>, <a href="/format/2401.15688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide and Conquer: Language Models can Plan and Self-Correct for  Compositional Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Aoxue Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongdao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite significant advancements in text-to-image models for generating
high-quality images, these methods still struggle to ensure the controllability
of text prompts over images in the context of complex text prompts, especially
when it comes to retaining object attributes and relationships. In this paper,
we propose CompAgent, a training-free approach for compositional text-to-image
generation, with a large language model (LLM) agent as its core. The
fundamental idea underlying CompAgent is premised on a divide-and-conquer
methodology. Given a complex text prompt containing multiple concepts including
objects, attributes, and relationships, the LLM agent initially decomposes it,
which entails the extraction of individual objects, their associated
attributes, and the prediction of a coherent scene layout. These individual
objects can then be independently conquered. Subsequently, the agent performs
reasoning by analyzing the text, plans and employs the tools to compose these
isolated objects. The verification and human feedback mechanism is finally
incorporated into our agent to further correct the potential attribute errors
and refine the generated images. Guided by the LLM agent, we propose a
tuning-free multi-concept customization model and a layout-to-image generation
model as the tools for concept composition, and a local image editing method as
the tool to interact with the agent for verification. The scene layout controls
the image generation process among these tools to prevent confusion among
multiple objects. Extensive experiments demonstrate the superiority of our
approach for compositional text-to-image generation: CompAgent achieves more
than 10\% improvement on T2I-CompBench, a comprehensive benchmark for
open-world compositional T2I generation. The extension to various related tasks
also illustrates the flexibility of our CompAgent for potential applications.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15691" title="Abstract">arXiv:2401.15691</a> [<a href="/pdf/2401.15691" title="Download PDF">pdf</a>, <a href="/format/2401.15691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One for all: A novel Dual-space Co-training baseline for Large-scale  Multi-View Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+Z">Zisen Kong</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zhiqiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Dongxia Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we propose a novel multi-view clustering model, named
Dual-space Co-training Large-scale Multi-view Clustering (DSCMC). The main
objective of our approach is to enhance the clustering performance by
leveraging co-training in two distinct spaces. In the original space, we learn
a projection matrix to obtain latent consistent anchor graphs from different
views. This process involves capturing the inherent relationships and
structures between data points within each view. Concurrently, we employ a
feature transformation matrix to map samples from various views to a shared
latent space. This transformation facilitates the alignment of information from
multiple views, enabling a comprehensive understanding of the underlying data
distribution. We jointly optimize the construction of the latent consistent
anchor graph and the feature transformation to generate a discriminative anchor
graph. This anchor graph effectively captures the essential characteristics of
the multi-view data and serves as a reliable basis for subsequent clustering
analysis. Moreover, the element-wise method is proposed to avoid the impact of
diverse information between different views. Our algorithm has an approximate
linear computational complexity, which guarantees its successful application on
large-scale datasets. Through experimental validation, we demonstrate that our
method significantly reduces computational complexity while yielding superior
clustering performance compared to existing approaches.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15695" title="Abstract">arXiv:2401.15695</a> [<a href="/pdf/2401.15695" title="Download PDF">pdf</a>, <a href="/format/2401.15695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HappyRouting: Learning Emotion-Aware Route Trajectories for Scalable  In-The-Wild Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bethge%2C+D">David Bethge</a>, 
<a href="/search/cs?searchtype=author&query=Bulanda%2C+D">Daniel Bulanda</a>, 
<a href="/search/cs?searchtype=author&query=Kozlowski%2C+A">Adam Kozlowski</a>, 
<a href="/search/cs?searchtype=author&query=Kosch%2C+T">Thomas Kosch</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+A">Albrecht Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Grosse-Puppendahl%2C+T">Tobias Grosse-Puppendahl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Routes represent an integral part of triggering emotions in drivers.
Navigation systems allow users to choose a navigation strategy, such as the
fastest or shortest route. However, they do not consider the driver's emotional
well-being. We present HappyRouting, a novel navigation-based empathic car
interface guiding drivers through real-world traffic while evoking positive
emotions. We propose design considerations, derive a technical architecture,
and implement a routing optimization framework. Our contribution is a machine
learning-based generated emotion map layer, predicting emotions along routes
based on static and dynamic contextual data. We evaluated HappyRouting in a
real-world driving study (N=13), finding that happy routes increase
subjectively perceived valence by 11% (p=.007). Although happy routes take 1.25
times longer on average, participants perceived the happy route as shorter,
presenting an emotion-enhanced alternative to today's fastest routing
mechanisms. We discuss how emotion-based routing can be integrated into
navigation apps, promoting emotional well-being for mobility use.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15696" title="Abstract">arXiv:2401.15696</a> [<a href="/pdf/2401.15696" title="Download PDF">pdf</a>, <a href="/ps/2401.15696" title="Download PostScript">ps</a>, <a href="/format/2401.15696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal order FEM for dynamic poroelasticity: Error analysis for equal  order elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bause%2C+M">Markus Bause</a>, 
<a href="/search/math?searchtype=author&query=Anselmann%2C+M">Mathias Anselmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The numerical approximation of dynamic poroelasticity, modeling flow in
deformable porous media, by a family of continuous space-time finite element
methods is investigated. Equal order approximation in space without any further
stabilization is used for the displacement and pore pressure variable. Optimal
order $L^\infty(L^2)$ error estimates are proved and numerically confirmed.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15700" title="Abstract">arXiv:2401.15700</a> [<a href="/pdf/2401.15700" title="Download PDF">pdf</a>, <a href="/ps/2401.15700" title="Download PostScript">ps</a>, <a href="/format/2401.15700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-based Personalization and Trust in Digital Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanaparthi%2C+V">Vijaya Kanaparthi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Personalized services bridge the gap between a financial institution and its
customers and are built on trust. The more we trust the product, the keener we
are to disclose our personal information in order to receive a highly
personalized service that maximizes consumer value. Artificial Intelligence
(AI) can help financial institutions tailor relevant products and services to
their customers as well as improve their credit risk management, compliance,
and fraud detection capabilities by incorporating chatbots and face recognition
systems. The present study has analyzed sixteen research papers using the
PRISMA model to perform a Systematic Literature Review (SLR). It has identified
five research gaps and corresponding questions to analyze the present scenario.
One of the gaps is credit risk detection for improved personalization and
trust. Finally, an AI-based credit risk detection model has been built using
four supervised machine learning classifiers viz., Support Vector Machine,
Random Forest, Decision Tree, and Logistic Regression. Performance comparison
shows an optimal performance of the model giving accuracy of ~89%, precision of
~88%, recall of ~89%, specificity of ~89%, F1_score of ~88%, and AUC of 0.77
for the Random Forest classifier. This model is foreseen to be most suitable
for envisaging customer characteristics for which personalized credit risk
mitigation strategies are particularly effective as compared to other existing
works presented in this study.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15704" title="Abstract">arXiv:2401.15704</a> [<a href="/pdf/2401.15704" title="Download PDF">pdf</a>, <a href="/format/2401.15704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phoneme-Based Proactive Anti-Eavesdropping with Controlled Recording  Privilege
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Peng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+Z">Zhongjie Ba</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Li Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Feng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 28 figures; submitted to IEEE TDSC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The widespread smart devices raise people's concerns of being eavesdropped
on. To enhance voice privacy, recent studies exploit the nonlinearity in
microphone to jam audio recorders with inaudible ultrasound. However, existing
solutions solely rely on energetic masking. Their simple-form noise leads to
several problems, such as high energy requirements and being easily removed by
speech enhancement techniques. Besides, most of these solutions do not support
authorized recording, which restricts their usage scenarios. In this paper, we
design an efficient yet robust system that can jam microphones while preserving
authorized recording. Specifically, we propose a novel phoneme-based noise with
the idea of informational masking, which can distract both machines and humans
and is resistant to denoising techniques. Besides, we optimize the noise
transmission strategy for broader coverage and implement a hardware prototype
of our system. Experimental results show that our system can reduce the
recognition accuracy of recordings to below 50\% under all tested speech
recognition systems, which is much better than existing solutions.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15708" title="Abstract">arXiv:2401.15708</a> [<a href="/pdf/2401.15708" title="Download PDF">pdf</a>, <a href="/format/2401.15708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-Driven One-Shot Fine-tuning of Text-to-Image Diffusion with  Prototypical Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianxiang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hui Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As large-scale text-to-image generation models have made remarkable progress
in the field of text-to-image generation, many fine-tuning methods have been
proposed. However, these models often struggle with novel objects, especially
with one-shot scenarios. Our proposed method aims to address the challenges of
generalizability and fidelity in an object-driven way, using only a single
input image and the object-specific regions of interest. To improve
generalizability and mitigate overfitting, in our paradigm, a prototypical
embedding is initialized based on the object's appearance and its class, before
fine-tuning the diffusion model. And during fine-tuning, we propose a
class-characterizing regularization to preserve prior knowledge of object
classes. To further improve fidelity, we introduce object-specific loss, which
can also use to implant multiple objects. Overall, our proposed object-driven
method for implanting new objects can integrate seamlessly with existing
concepts as well as with high fidelity and generalization. Our method
outperforms several existing works. The code will be released.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15710" title="Abstract">arXiv:2401.15710</a> [<a href="/pdf/2401.15710" title="Download PDF">pdf</a>, <a href="/ps/2401.15710" title="Download PostScript">ps</a>, <a href="/format/2401.15710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformational application of Artificial Intelligence and Machine  learning in Financial Technologies and Financial services: A bibliometric  review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanaparthi%2C+V">Vijaya Kanaparthi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In this study, I employ a multifaceted comprehensive scientometric approach
to explore the intellectual underpinnings of AI and ML in financial research by
examining the publication patterns of articles, journals, authors,
institutions, and nations by leveraging quantitative techniques, that transcend
conventional systematic literature reviews, enabling the effective analysis of
vast scientometric and bibliographic data. By applying these approaches, I
identify influential works, seminal contributions, thought leaders, topical
clusters, research streams, and new research frontiers, ultimately fostering a
deeper understanding of the knowledge structure in AI and ML finance research
by considering publication records from 2010 to 2022 from several search
engines and database sources. The present study finds a marked increase in
publications from 2017 to 2022, which highlights a growing interest and
expanding research activity in the field, indicating its potential significance
and relevance in the contemporary academic landscape.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15713" title="Abstract">arXiv:2401.15713</a> [<a href="/pdf/2401.15713" title="Download PDF">pdf</a>, <a href="/format/2401.15713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning and Mixture of Experts Enables Precise Vector  Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapur%2C+R">Rohan Kapur</a>, 
<a href="/search/cs?searchtype=author&query=Hallee%2C+L">Logan Hallee</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+A">Arjun Patel</a>, 
<a href="/search/cs?searchtype=author&query=Khomtchouk%2C+B">Bohdan Khomtchouk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The advancement of transformer neural networks has significantly elevated the
capabilities of sentence similarity models, particularly in creating effective
vector representations of natural language inputs. However, these models face
notable challenges in domain-specific contexts, especially in highly
specialized scientific sub-fields. Traditional methods often struggle in this
regime, either overgeneralizing similarities within a niche or being overly
sensitive to minor differences, resulting in inaccurate text classification and
subpar vector representation. In an era where retrieval augmentation and search
are increasingly crucial, precise and concise numerical representations are
essential. In this paper, we target this issue by assembling niche datasets
using co-citations as a similarity metric, focusing on biomedical domains. We
employ two key strategies for fine-tuning state-of-the-art models: 1.
Domain-specific Fine-Tuning, which tailors pretrained models to a single
domain, and 2. Universal Applicability with Mixture of Experts (MoE), adapting
pretrained models with enforced routing for multiple domains simultaneously.
Our training approach emphasizes the use of abstracts for faster training,
incorporating Multiple Negative Rankings loss for efficient contrastive
learning. Notably, our MoE variants, equipped with $N$ experts, achieve the
efficacy of $N$ individual models, heralding a new era of versatile,
One-Size-Fits-All transformer networks for various tasks. This methodology
marks significant advancements in scientific text classification metrics and
holds promise for enhancing vector database search and compilation.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15715" title="Abstract">arXiv:2401.15715</a> [<a href="/pdf/2401.15715" title="Download PDF">pdf</a>, <a href="/ps/2401.15715" title="Download PostScript">ps</a>, <a href="/format/2401.15715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of Blockchain, AI, and ML on Financial Accounting  Efficiency and Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanaparthi%2C+V">Vijaya Kanaparthi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Continuous innovations profoundly impact the financial and commercial
domains, reshaping conventional business practices. Among the disruptive
forces, Artificial Intelligence (AI), Machine Learning (ML), and blockchain
technology stand out prominently. This study aims to evaluate the integration
of blockchain, AI, and ML within financial accounting practices. It suggests a
potential revolutionary impact on financial accounting through the adoption of
blockchain technology and ML, promising reduced accounting expenses, heightened
precision, real-time financial reporting capabilities, and expeditious auditing
processes. AI's role in automating repetitive financial accounting tasks
assists organizations in circumventing the need for additional staff, thereby
minimizing associated costs. Consequently, to bolster efficiency, businesses
are increasingly embracing blockchain technology and AI applications in their
financial accounting operations.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15717" title="Abstract">arXiv:2401.15717</a> [<a href="/pdf/2401.15717" title="Download PDF">pdf</a>, <a href="/format/2401.15717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Check News in One Click: NLP-Empowered Pro-Kremlin Propaganda Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solopova%2C+V">Veronika Solopova</a>, 
<a href="/search/cs?searchtype=author&query=Herman%2C+V">Viktoriia Herman</a>, 
<a href="/search/cs?searchtype=author&query=Benzm%C3%BCller%2C+C">Christoph Benzm&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Landgraf%2C+T">Tim Landgraf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024 System Demonstrations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Many European citizens become targets of the Kremlin propaganda campaigns,
aiming to minimise public support for Ukraine, foster a climate of mistrust and
disunity, and shape elections (Meister, 2022). To address this challenge, we
developed ''Check News in 1 Click'', the first NLP-empowered pro-Kremlin
propaganda detection application available in 7 languages, which provides the
lay user with feedback on their news, and explains manipulative linguistic
features and keywords. We conducted a user study, analysed user entries and
models' behaviour paired with questionnaire answers, and investigated the
advantages and disadvantages of the proposed interpretative solution.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15720" title="Abstract">arXiv:2401.15720</a> [<a href="/pdf/2401.15720" title="Download PDF">pdf</a>, <a href="/format/2401.15720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Snippet Reliability on Misinformation in Online Health  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashavit%2C+A">Anat Hashavit</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+T">Tamar Stern</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kraus%2C+S">Sarit Kraus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Search result snippets are crucial in modern search engines, providing users
with a quick overview of a website's content. Snippets help users determine the
relevance of a document to their information needs, and in certain scenarios
even enable them to satisfy those needs without visiting web documents. Hence,
it is crucial for snippets to reliably represent the content of their
corresponding documents. While this may be a straightforward requirement for
some queries, it can become challenging in the complex domain of healthcare,
and can lead to misinformation. This paper aims to examine snippets'
reliability in representing their corresponding documents, specifically in the
health domain. To achieve this, we conduct a series of user studies using
Google's search results, where participants are asked to infer viewpoints of
search results pertaining to queries about the effectiveness of a medical
intervention for a medical condition, based solely on their titles and
snippets. Our findings reveal that a considerable portion of Google's snippets
(28%) failed to present any viewpoint on the intervention's effectiveness, and
that 35% were interpreted by participants as having a different viewpoint
compared to their corresponding documents. To address this issue, we propose a
snippet extraction solution tailored directly to users' information needs,
i.e., extracting snippets that summarize documents' viewpoints regarding the
intervention and condition that appear in the query. User study demonstrates
that our information need-focused solution outperforms the mainstream
query-based approach. With only 19.67% of snippets generated by our solution
reported as not presenting a viewpoint and a mere 20.33% misinterpreted by
participants. These results strongly suggest that an information need-focused
approach can significantly improve the reliability of extracted snippets in
online health search.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15721" title="Abstract">arXiv:2401.15721</a> [<a href="/pdf/2401.15721" title="Download PDF">pdf</a>, <a href="/format/2401.15721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of Acquisition Functions for Medical Imaging Deep Active  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dossou%2C+B+F+P">Bonaventure F. P. Dossou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Best Poster Award at Deep Learning Indaba 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Deep Learning revolution has enabled groundbreaking achievements in
recent years. From breast cancer detection to protein folding, deep learning
algorithms have been at the core of very important advancements. However, these
modern advancements are becoming more and more data-hungry, especially on
labeled data whose availability is scarce: this is even more prevalent in the
medical context. In this work, we show how active learning could be very
effective in data scarcity situations, where obtaining labeled data (or
annotation budget is very limited). We compare several selection criteria
(BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset. We also explored the
effect of acquired pool size on the model's performance. Our results suggest
that uncertainty is useful to the Melanoma detection task, and confirms the
hypotheses of the author of the paper of interest, that \textit{bald} performs
on average better than other acquisition functions. Our extended analyses
however revealed that all acquisition functions perform badly on the positive
(cancerous) samples, suggesting exploitation of class unbalance, which could be
crucial in real-world settings. We finish by suggesting future work directions
that would be useful to improve this current work. The code of our
implementation is open-sourced at
\url{https://github.com/bonaventuredossou/ece526_course_project}
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15722" title="Abstract">arXiv:2401.15722</a> [<a href="/pdf/2401.15722" title="Download PDF">pdf</a>, <a href="/ps/2401.15722" title="Download PostScript">ps</a>, <a href="/format/2401.15722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Coverage Depth in DNA Storage: A Combinatorial Perspective on  Random Access Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gruica%2C+A">Anina Gruica</a>, 
<a href="/search/cs?searchtype=author&query=Bar-Lev%2C+D">Daniella Bar-Lev</a>, 
<a href="/search/cs?searchtype=author&query=Ravagnani%2C+A">Alberto Ravagnani</a>, 
<a href="/search/cs?searchtype=author&query=Yaakobi%2C+E">Eitan Yaakobi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">We investigate the fundamental limits of the recently proposed random access
coverage depth problem for DNA data storage. Under this paradigm, it is assumed
that the user information consists of $k$ information strands, which are
encoded into $n$ strands via some generator matrix $G$. In the sequencing
process, the strands are read uniformly at random, since each strand is
available in a large number of copies. In this context, the random access
coverage depth problem refers to the expected number of reads (i.e., sequenced
strands) until it is possible to decode a specific information strand, which is
requested by the user. The goal is to minimize the maximum expectation over all
possible requested information strands, and this value is denoted by
$T_{\max}(G)$. This paper introduces new techniques to investigate the random
access coverage depth problem, which capture its combinatorial nature. We
establish two general formulas to find $T_{max}(G)$ for arbitrary matrices. We
introduce the concept of recovery balanced codes and combine all these results
and notions to compute $T_{\max}(G)$ for MDS, simplex, and Hamming codes. We
also study the performance of modified systematic MDS matrices and our results
show that the best results for $T_{\max}(G)$ are achieved with a specific mix
of encoded strands and replication of the information strands.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15724" title="Abstract">arXiv:2401.15724</a> [<a href="/pdf/2401.15724" title="Download PDF">pdf</a>, <a href="/format/2401.15724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RE-GAINS &amp; EnCHANT: Intelligent Tool Manipulation Systems For Enhanced  Query Responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Girhepuje%2C+S">Sahil Girhepuje</a>, 
<a href="/search/cs?searchtype=author&query=Sajeev%2C+S+S">Siva Sankar Sajeev</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Purvam Jain</a>, 
<a href="/search/cs?searchtype=author&query=Sikder%2C+A">Arya Sikder</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+A+R">Adithya Rama Varma</a>, 
<a href="/search/cs?searchtype=author&query=George%2C+R">Ryan George</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+A+G">Akshay Govind Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Kurup%2C+M">Mahendra Kurup</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Ashmit Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S">Sudip Mondal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite the remarkable success of LLMs, they still suffer from tool
invocation and tool chaining due to inadequate input queries and/or tool
argument descriptions. We propose two novel frameworks, RE-GAINS and EnCHANT,
enabling LLMs to tackle tool manipulation for solving complex user queries by
making API calls. EnCHANT is an open-source solution that makes use of an LLM
format enforcer, an LLM(OpenChat 3.5) and a retriever(ToolBench's API
Retriever). RE-GAINS is based on OpenAI models and embeddings using a special
prompt based on the RAP paper. Both solutions cost less than $0.01 per query
with minimal latency, therefore showcasing the usefulness of the frameworks.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15726" title="Abstract">arXiv:2401.15726</a> [<a href="/pdf/2401.15726" title="Download PDF">pdf</a>, <a href="/format/2401.15726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach  Without Reanalysis Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Young-Jae Park</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minseok Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Doyi Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeri Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sanghoon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+B">Beomkyu Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+J">Jeongwon Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+S">Sohee Son</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H">Hae-Gon Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yeji Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted for a Spotlight presentation at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the face of escalating climate changes, typhoon intensities and their
ensuing damage have surged. Accurate trajectory prediction is crucial for
effective damage control. Traditional physics-based models, while
comprehensive, are computationally intensive and rely heavily on the expertise
of forecasters. Contemporary data-driven methods often rely on reanalysis data,
which can be considered to be the closest to the true representation of weather
conditions. However, reanalysis data is not produced in real-time and requires
time for adjustment because prediction models are calibrated with observational
data. This reanalysis data, such as ERA5, falls short in challenging real-world
situations. Optimal preparedness necessitates predictions at least 72 hours in
advance, beyond the capabilities of standard physics models. In response to
these constraints, we present an approach that harnesses real-time Unified
Model (UM) data, sidestepping the limitations of reanalysis data. Our model
provides predictions at 6-hour intervals for up to 72 hours in advance and
outperforms both state-of-the-art data-driven methods and numerical weather
prediction models. In line with our efforts to mitigate adversities inflicted
by \rthree{typhoons}, we release our preprocessed \textit{PHYSICS TRACK}
dataset, which includes ERA5 reanalysis data, typhoon best-track, and UM
forecast data.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15729" title="Abstract">arXiv:2401.15729</a> [<a href="/pdf/2401.15729" title="Download PDF">pdf</a>, <a href="/ps/2401.15729" title="Download PostScript">ps</a>, <a href="/format/2401.15729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power based adaptive compensator of output oscillations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ruderman%2C+M">Michael Ruderman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Power-based output feedback compensator for oscillatory systems is proposed.
The average input-output power of an oscillatory signal serves as an equivalent
control effort, while the unknown oscillation's amplitude and frequency are
detected at each half-period. This makes the compensator adaptive and discrete,
while the measured oscillatory output is the single available signal in use.
The proposed compensator is derived for second-order systems, while an
extension to higher-order dynamics, like e.g. in case of two-inertia systems,
is also provided. An illustrative experimental case study of the fifth-order
oscillatory system is provided.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15733" title="Abstract">arXiv:2401.15733</a> [<a href="/pdf/2401.15733" title="Download PDF">pdf</a>, <a href="/ps/2401.15733" title="Download PostScript">ps</a>, <a href="/format/2401.15733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving DNA Labeling Capacity with Minimum Labels through Extremal de  Bruijn Subgraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hofmeister%2C+C">Christoph Hofmeister</a>, 
<a href="/search/cs?searchtype=author&query=Gruica%2C+A">Anina Gruica</a>, 
<a href="/search/cs?searchtype=author&query=Hanania%2C+D">Dganit Hanania</a>, 
<a href="/search/cs?searchtype=author&query=Bitar%2C+R">Rawad Bitar</a>, 
<a href="/search/cs?searchtype=author&query=Yaakobi%2C+E">Eitan Yaakobi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">DNA labeling is a tool in molecular biology and biotechnology to visualize,
detect, and study DNA at the molecular level. In this process, a DNA molecule
is labeled by a set of specific patterns, referred to as labels, and is then
imaged. The resulting image is modeled as an $(\ell+1)$-ary sequence, where
$\ell$ is the number of labels, in which any non-zero symbol indicates the
appearance of the corresponding label in the DNA molecule. The labeling
capacity refers to the maximum information rate that can be achieved by the
labeling process for any given set of labels. The main goal of this paper is to
study the minimum number of labels of the same length required to achieve the
maximum labeling capacity of 2 for DNA sequences or $\log_2q$ for an arbitrary
alphabet of size $q$. The solution to this problem requires the study of path
unique subgraphs of the de Bruijn graph with the largest number of edges and we
provide upper and lower bounds on this value.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15739" title="Abstract">arXiv:2401.15739</a> [<a href="/pdf/2401.15739" title="Download PDF">pdf</a>, <a href="/ps/2401.15739" title="Download PostScript">ps</a>, <a href="/format/2401.15739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegmentAnyTree: A sensor and platform agnostic deep learning model for  tree segmentation using laser scanning data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wielgosz%2C+M">Maciej Wielgosz</a>, 
<a href="/search/cs?searchtype=author&query=Puliti%2C+S">Stefano Puliti</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+B">Binbin Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Astrup%2C+R">Rasmus Astrup</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This research advances individual tree crown (ITC) segmentation in lidar
data, using a deep learning model applicable to various laser scanning types:
airborne (ULS), terrestrial (TLS), and mobile (MLS). It addresses the challenge
of transferability across different data characteristics in 3D forest scene
analysis. The study evaluates the model's performance based on platform (ULS,
MLS) and data density, testing five scenarios with varying input data,
including sparse versions, to gauge adaptability and canopy layer efficacy. The
model, based on PointGroup architecture, is a 3D CNN with separate heads for
semantic and instance segmentation, validated on diverse point cloud datasets.
Results show point cloud sparsification enhances performance, aiding sparse
data handling and improving detection in dense forests. The model performs well
with &gt;50 points per sq. m densities but less so at 10 points per sq. m due to
higher omission rates. It outperforms existing methods (e.g., Point2Tree,
TLS2trees) in detection, omission, commission rates, and F1 score, setting new
benchmarks on LAUTx, Wytham Woods, and TreeLearn datasets. In conclusion, this
study shows the feasibility of a sensor-agnostic model for diverse lidar data,
surpassing sensor-specific approaches and setting new standards in tree
segmentation, particularly in complex forests. This contributes to future
ecological modeling and forest management advancements.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15741" title="Abstract">arXiv:2401.15741</a> [<a href="/pdf/2401.15741" title="Download PDF">pdf</a>, <a href="/ps/2401.15741" title="Download PostScript">ps</a>, <a href="/format/2401.15741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SERNet-Former: Semantic Segmentation by Efficient Residual Network with  Attention-Boosting Gates and Attention-Fusion Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erisen%2C+S">Serdar Erisen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Improving the efficiency of state-of-the-art methods in semantic segmentation
requires overcoming the increasing computational cost as well as issues such as
fusing semantic information from global and local contexts. Based on the recent
success and problems that convolutional neural networks (CNNs) encounter in
semantic segmentation, this research proposes an encoder-decoder architecture
with a unique efficient residual network. Attention-boosting gates (AbGs) and
attention-boosting modules (AbMs) are deployed by aiming to fuse the
feature-based semantic information with the global context of the efficient
residual network in the encoder. Respectively, the decoder network is developed
with the additional attention-fusion networks (AfNs) inspired by AbM. AfNs are
designed to improve the efficiency in the one-to-one conversion of the semantic
information by deploying additional convolution layers in the decoder part. Our
network is tested on the challenging CamVid and Cityscapes datasets, and the
proposed methods reveal significant improvements on the existing baselines,
such as ResNet-50. To the best of our knowledge, the developed network,
SERNet-Former, achieves state-of-the-art results (84.62 % mean IoU) on CamVid
dataset and challenging results (87.35 % mean IoU) on Cityscapes validation
dataset.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15742" title="Abstract">arXiv:2401.15742</a> [<a href="/pdf/2401.15742" title="Download PDF">pdf</a>, <a href="/format/2401.15742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Data-Driven MPC for Demand Response of Commercial Buildings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Par%C3%A9%2C+M">Marie-Christine Par&#xe9;</a>, 
<a href="/search/eess?searchtype=author&query=Dermardiros%2C+V">Vasken Dermardiros</a>, 
<a href="/search/eess?searchtype=author&query=Lesage-Landry%2C+A">Antoine Lesage-Landry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Model predictive control (MPC) has been shown to significantly improve the
energy efficiency of buildings while maintaining thermal comfort. Data-driven
approaches based on neural networks have been proposed to facilitate system
modelling. However, such approaches are generally nonconvex and result in
computationally intractable optimization problems. In this work, we design a
readily implementable energy management method for small commercial buildings.
We then leverage our approach to formulate a real-time demand bidding strategy.
We propose a data-driven and mixed-integer convex MPC which is solved via
derivative-free optimization given a limited computational time of 5 minutes to
respect operational constraints. We consider rooftop unit heating, ventilation,
and air conditioning systems with discrete controls to accurately model the
operation of most commercial buildings. Our approach uses an input convex
recurrent neural network to model the thermal dynamics. We apply our approach
in several demand response (DR) settings, including a demand bidding, a
time-of-use, and a critical peak rebate program. Controller performance is
evaluated on a state-of-the-art building simulation. The proposed approach
improves thermal comfort while reducing energy consumption and cost through DR
participation, when compared to other data-driven approaches or a set-point
controller.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15747" title="Abstract">arXiv:2401.15747</a> [<a href="/pdf/2401.15747" title="Download PDF">pdf</a>, <a href="/format/2401.15747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical modelling of protein misfolding in neurodegenerative diseases:  a computational study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>, 
<a href="/search/math?searchtype=author&query=Corti%2C+M">Mattia Corti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The spreading of misfolded proteins is a known hallmark in some
neurodegenerative diseases, known as proteinopathies. A significant example is
the tau protein, associated with many pathologies, such as Alzheimer's. In this
work, we discuss and compare two different models for the mathematical
modelling of protein misfolding, namely the heterodimer model and the
Fisher-Kolmogorov model, as well as their numerical discretizations. We
introduce a discontinuous Galerkin method on polygonal and polyhedral grids for
space discretization to accurately simulate the wavefronts typically observed
in the prionic spreading. Starting from the semidiscrete formulations, we use a
Crank-Nicolson scheme to advance in time. Finally, we simulate the spreading of
the misfolded tau protein in a two-dimensional brain slice in the sagittal
plane with a polygonal agglomerated grid. The simulation is performed using
both the presented models, and we compare the results and the differences
deriving from the modelling choices.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15752" title="Abstract">arXiv:2401.15752</a> [<a href="/pdf/2401.15752" title="Download PDF">pdf</a>, <a href="/format/2401.15752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communication in the Finite Blocklength Regime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikbakht%2C+H">Homa Nikbakht</a>, 
<a href="/search/cs?searchtype=author&query=Wigger%2C+M">Mich&#xe8;le Wigger</a>, 
<a href="/search/cs?searchtype=author&query=Shamai%2C+S">Shlomo Shamai</a> (Shitz), 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H.Vincent Poor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">A point-to-point integrated sensing and communication (ISAC) system is
considered where a transmitter conveys a message to a receiver over a discrete
memoryless channel (DMC) and simultaneously estimates the state of the channel
through the backscattered signals of the emitted waveform.
<br />We derive achievability and converse bounds on the rate-distortion-error
tradeoff in the finite blocklength regime, and also characterize the
second-order rate-distortion-error region for the proposed setup. Numerical
analysis shows that our proposed joint ISAC scheme significantly outperforms
traditional time-sharing based schemes where the available resources are split
between the sensing and communication tasks.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15753" title="Abstract">arXiv:2401.15753</a> [<a href="/pdf/2401.15753" title="Download PDF">pdf</a>, <a href="/format/2401.15753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An objective comparison of methods for augmented reality in laparoscopic  liver resection by preoperative-to-intraoperative image fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Sharib Ali</a>, 
<a href="/search/cs?searchtype=author&query=Espinel%2C+Y">Yamid Espinel</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yueming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peng Liu</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCttner%2C+B">Bianca G&#xfc;ttner</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xukun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lihua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dowrick%2C+T">Tom Dowrick</a>, 
<a href="/search/cs?searchtype=author&query=Clarkson%2C+M+J">Matthew J. Clarkson</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shiting Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yijun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lan Li</a>, 
<a href="/search/cs?searchtype=author&query=Pfeiffer%2C+M">Micha Pfeiffer</a>, 
<a href="/search/cs?searchtype=author&query=Farid%2C+S">Shahid Farid</a>, 
<a href="/search/cs?searchtype=author&query=Maier-Hein%2C+L">Lena Maier-Hein</a>, 
<a href="/search/cs?searchtype=author&query=Buc%2C+E">Emmanuel Buc</a>, 
<a href="/search/cs?searchtype=author&query=Bartoli%2C+A">Adrien Bartoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Augmented reality for laparoscopic liver resection is a visualisation mode
that allows a surgeon to localise tumours and vessels embedded within the liver
by projecting them on top of a laparoscopic image. Preoperative 3D models
extracted from CT or MRI data are registered to the intraoperative laparoscopic
images during this process. In terms of 3D-2D fusion, most of the algorithms
make use of anatomical landmarks to guide registration. These landmarks include
the liver's inferior ridge, the falciform ligament, and the occluding contours.
They are usually marked by hand in both the laparoscopic image and the 3D
model, which is time-consuming and may contain errors if done by a
non-experienced user. Therefore, there is a need to automate this process so
that augmented reality can be used effectively in the operating room. We
present the Preoperative-to-Intraoperative Laparoscopic Fusion Challenge
(P2ILF), held during the Medical Imaging and Computer Assisted Interventions
(MICCAI 2022) conference, which investigates the possibilities of detecting
these landmarks automatically and using them in registration. The challenge was
divided into two tasks: 1) A 2D and 3D landmark detection task and 2) a 3D-2D
registration task. The teams were provided with training data consisting of 167
laparoscopic images and 9 preoperative 3D models from 9 patients, with the
corresponding 2D and 3D landmark annotations. A total of 6 teams from 4
countries participated, whose proposed methods were evaluated on 16 images and
two preoperative 3D models from two patients. All the teams proposed deep
learning-based methods for the 2D and 3D landmark segmentation tasks and
differentiable rendering-based methods for the registration task. Based on the
experimental outcomes, we propose three key hypotheses that determine current
limitations and future directions for research in this domain.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15756" title="Abstract">arXiv:2401.15756</a> [<a href="/pdf/2401.15756" title="Download PDF">pdf</a>, <a href="/ps/2401.15756" title="Download PostScript">ps</a>, <a href="/format/2401.15756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Allocation in C-V2X: A review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tahi%2C+T+Z">Tahmid Zaman Tahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Cellular Vehicle-to-Everything (C-V2X) is a cutting-edge wireless
communication technology that enables seamless connectivity and information
exchange among vehicles, infrastructure, networks, and pedestrians. As a vital
component of Intelligent Transportation Systems (ITS), C-V2X is designed to
support a wide range of applications aimed at enhancing traffic efficiency,
improving road safety, reducing accident rates, and facilitating the
development of autonomous and connected vehicles. C-V2X technology is built
upon the Long-Term Evolution (LTE) and 5G New Radio (NR) stan- dards,
leveraging the robustness, reliability, and scalability of cellular networks.
It encompasses two distinct communication modes: (1) direct communication,
which includes Vehicle-to-Vehicle (V2V), Vehicle-to-Infrastructure (V2I), and
Vehicle-to-Pedestrian (V2P) communication, and (2) network-based communication,
which involves Vehicle-to-Network (V2N) communication. Resource allocation is a
critical challenge in the design and operation of C-V2X systems, as it is
responsible for determining the optimal distribution of communication resources
among users, ensuring efficient utilization and fair sharing. In C-V2X,
resource allocation is complicated by factors such as highly dynamic network
topologies, diverse quality of service (QoS) requirements, and spectrum
scarcity. Therefore, it is essential to explore and analyze various resource
allocation strategies and techniques that can effectively address these
challenges. This review paper provides a comprehensive overview of the recent
progress in resource allocation for C-V2X communications. As C-V2X technology
evolves, it is expected to play a crucial role in transforming the
transportation landscape, paving the way for smarter, safer, and more efficient
transportation systems.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15758" title="Abstract">arXiv:2401.15758</a> [<a href="/pdf/2401.15758" title="Download PDF">pdf</a>, <a href="/format/2401.15758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Preconditioned Solvers for Strong Constraint 4D-Var Data  Assimilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Subrahmanya%2C+A+N">Amit N. Subrahmanya</a>, 
<a href="/search/math?searchtype=author&query=Rao%2C+V">Vishwas Rao</a>, 
<a href="/search/math?searchtype=author&query=Saibaba%2C+A+K">Arvind K. Saibaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Strong Constraint 4D Variational (SC-4DVAR) is a data assimilation method
that is widely used in climate and weather applications. SC-4DVAR involves
solving a minimization problem to compute the maximum a posteriori estimate,
which we tackle using the Gauss-Newton method. The computation of the descent
direction is expensive since it involves the solution of a large-scale and
potentially ill-conditioned linear system, solved using the preconditioned
conjugate gradient (PCG) method. To address this cost, we efficiently construct
scalable preconditioners using three different randomization techniques, which
all rely on a certain low-rank structure involving the Gauss-Newton Hessian.
The proposed techniques come with theoretical (probabilistic) guarantees on the
condition number, and at the same time, are amenable to parallelization. We
also develop an adaptive approach to estimate the sketch size and to choose
between the reuse or recomputation of the preconditioner. We demonstrate the
performance and effectiveness of our methodology on two representative model
problems -- the Burgers and barotropic vorticity equation -- showing a drastic
reduction in both the number of PCG iterations and the number of Gauss-Newton
Hessian products (after including the preconditioner construction cost).
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15760" title="Abstract">arXiv:2401.15760</a> [<a href="/pdf/2401.15760" title="Download PDF">pdf</a>, <a href="/ps/2401.15760" title="Download PostScript">ps</a>, <a href="/format/2401.15760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HRI Challenges Influencing Low Usage of Robotic Systems in Disaster  Response and Rescue Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoque%2C+S">Shahinul Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Riya%2C+F+F">Farhin Farhad Riya</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jinyuan Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The breakthrough in AI and Machine Learning has brought a new revolution in
robotics, resulting in the construction of more sophisticated robotic systems.
Not only can these robotic systems benefit all domains, but also can accomplish
tasks that seemed to be unimaginable a few years ago. From swarms of autonomous
small robots working together to more very heavy and large objects, to
seemingly indestructible robots capable of going to the harshest environments,
we can see robotic systems designed for every task imaginable. Among them, a
key scenario where robotic systems can benefit is in disaster response
scenarios and rescue operations. Robotic systems are capable of successfully
conducting tasks such as removing heavy materials, utilizing multiple advanced
sensors for finding objects of interest, moving through debris and various
inhospitable environments, and not the least have flying capabilities. Even
with so much potential, we rarely see the utilization of robotic systems in
disaster response scenarios and rescue missions. Many factors could be
responsible for the low utilization of robotic systems in such scenarios. One
of the key factors involve challenges related to Human-Robot Interaction (HRI)
issues. Therefore, in this paper, we try to understand the HRI challenges
involving the utilization of robotic systems in disaster response and rescue
operations. Furthermore, we go through some of the proposed robotic systems
designed for disaster response scenarios and identify the HRI challenges of
those systems. Finally, we try to address the challenges by introducing ideas
from various proposed research works.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15762" title="Abstract">arXiv:2401.15762</a> [<a href="/pdf/2401.15762" title="Download PDF">pdf</a>, <a href="/format/2401.15762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart Driver Monitoring Robotic System to Enhance Road Safety : A  Comprehensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riya%2C+F+F">Farhin Farhad Riya</a>, 
<a href="/search/cs?searchtype=author&query=Hoque%2C+S">Shahinul Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaopeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J+S">Jinyuan Stella Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The future of transportation is being shaped by technology, and one
revolutionary step in improving road safety is the incorporation of robotic
systems into driver monitoring infrastructure. This literature review explores
the current landscape of driver monitoring systems, ranging from traditional
physiological parameter monitoring to advanced technologies such as facial
recognition to steering analysis. Exploring the challenges faced by existing
systems, the review then investigates the integration of robots as intelligent
entities within this framework. These robotic systems, equipped with artificial
intelligence and sophisticated sensors, not only monitor but actively engage
with the driver, addressing cognitive and emotional states in real-time. The
synthesis of existing research reveals a dynamic interplay between human and
machine, offering promising avenues for innovation in adaptive, personalized,
and ethically responsible human-robot interactions for driver monitoring. This
review establishes a groundwork for comprehending the intricacies and potential
avenues within this dynamic field. It encourages further investigation and
advancement at the intersection of human-robot interaction and automotive
safety, introducing a novel direction. This involves various sections detailing
technological enhancements that can be integrated to propose an innovative and
improved driver monitoring system.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15763" title="Abstract">arXiv:2401.15763</a> [<a href="/pdf/2401.15763" title="Download PDF">pdf</a>, <a href="/format/2401.15763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing an Analytical Fixed Source Solver for the 1D Multigroup $S_N$  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miao%2C+J">Jilang Miao</a>, 
<a href="/search/math?searchtype=author&query=Jin%2C+M">Miaomiao Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We extend the analytical multigroup $S_N$ method to solve 1D fixed source
problems. The fixed source solver is applied in power iteration of eigenvalue
problems.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15765" title="Abstract">arXiv:2401.15765</a> [<a href="/pdf/2401.15765" title="Download PDF">pdf</a>, <a href="/format/2401.15765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coarse Mesh Iteration Approach for Analytical 1D Multigroup $S_N$  Eigenvalue Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miao%2C+J">Jilang Miao</a>, 
<a href="/search/math?searchtype=author&query=Jin%2C+M">Miaomiao Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">This paper extends the fixed source capability of analytical 1D multigroup
$S_N$ equations to solve eigenvalue problems on coarse mesh.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15766" title="Abstract">arXiv:2401.15766</a> [<a href="/pdf/2401.15766" title="Download PDF">pdf</a>, <a href="/ps/2401.15766" title="Download PostScript">ps</a>, <a href="/format/2401.15766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EEG for fatigue monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rakhmatulin%2C+I">Ildar Rakhmatulin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Physiological fatigue, a state of reduced cognitive and physical performance
resulting from prolonged mental or physical exertion, poses significant
challenges in various domains, including healthcare, aviation, transportation,
and industrial sectors. As the understanding of fatigue's impact on human
performance grows, there is a growing interest in developing effective fatigue
monitoring techniques. Among these techniques, electroencephalography (EEG) has
emerged as a promising tool for objectively assessing physiological fatigue due
to its non-invasiveness, high temporal resolution, and sensitivity to neural
activity. This paper aims to provide a comprehensive analysis of the current
state of the use of EEG for monitoring physiological fatigue.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15767" title="Abstract">arXiv:2401.15767</a> [<a href="/pdf/2401.15767" title="Download PDF">pdf</a>, <a href="/format/2401.15767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Centralized Reinforcement Learning Framework for Adaptive Clustering  with Low Control Overhead in IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jurado-Lasso%2C+F+F">F. Fernando Jurado-Lasso</a>, 
<a href="/search/cs?searchtype=author&query=Jurado%2C+J+F">J. F. Jurado</a>, 
<a href="/search/cs?searchtype=author&query=Fafoutis%2C+X">Xenofon Fafoutis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 13 figures, 3 tables, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Wireless Sensor Networks (WSNs) play a pivotal role in enabling Internet of
Things (IoT) devices with sensing and actuation capabilities. Operating in
remote and resource-constrained environments, these IoT devices face challenges
related to energy consumption, crucial for network longevity. Clustering
protocols have emerged as an effective solution to alleviate energy burdens on
IoT devices. This paper introduces Low-Energy Adaptive Clustering Hierarchy
with Reinforcement Learning-based Controller (LEACH-RLC), a novel clustering
protocol that employs a Mixed Integer Linear Programming (MILP) for strategic
selection of cluster heads (CHs) and node-to-cluster assignments. Additionally,
it integrates a Reinforcement Learning (RL) agent to minimize control overhead
by learning optimal timings for generating new clusters. Addressing key
research questions, LEACH-RLC seeks to balance control overhead reduction
without compromising overall network performance. Through extensive
simulations, this paper investigates the frequency and opportune moments for
generating new clustering solutions. Results demonstrate the superior
performance of LEACH-RLC over conventional LEACH and LEACH-C, showcasing
enhanced network lifetime, reduced average energy consumption, and minimized
control overhead. The proposed protocol contributes to advancing the efficiency
and adaptability of WSNs, addressing critical challenges in IoT deployments.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15770" title="Abstract">arXiv:2401.15770</a> [<a href="/pdf/2401.15770" title="Download PDF">pdf</a>, <a href="/format/2401.15770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PILOT: Legal Case Outcome Prediction with Case Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Cao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Machine learning shows promise in predicting the outcome of legal cases, but
most research has concentrated on civil law cases rather than case law systems.
We identified two unique challenges in making legal case outcome predictions
with case law. First, it is crucial to identify relevant precedent cases that
serve as fundamental evidence for judges during decision-making. Second, it is
necessary to consider the evolution of legal principles over time, as early
cases may adhere to different legal contexts.
<br />In this paper, we proposed a new model named PILOT (PredictIng Legal case
OuTcome) for case outcome prediction. It comprises two modules for relevant
case retrieval and temporal pattern handling, respectively. To benchmark the
performance of existing legal case outcome prediction models, we curated a
dataset from a large-scale case law database. We demonstrate the importance of
accurately identifying precedent cases and mitigating the temporal shift when
making predictions for case law, as our method shows a significant improvement
over the prior methods that focus on civil law case outcome predictions.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15773" title="Abstract">arXiv:2401.15773</a> [<a href="/pdf/2401.15773" title="Download PDF">pdf</a>, <a href="/ps/2401.15773" title="Download PostScript">ps</a>, <a href="/format/2401.15773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of k-means time series clustering based on z-normalization  and NP-Free
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Ming-Chang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jia-Chun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Stolz%2C+V">Volker Stolz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 8 tables, 13th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the widespread use of k-means time series clustering in various
domains, there exists a gap in the literature regarding its comprehensive
evaluation with different time series normalization approaches. This paper
seeks to fill this gap by conducting a thorough performance evaluation of
k-means time series clustering on real-world open-source time series datasets.
The evaluation focuses on two distinct normalization techniques:
z-normalization and NP-Free. The former is one of the most commonly used
normalization approach for time series. The latter is a real-time time series
representation approach, which can serve as a time series normalization
approach. The primary objective of this paper is to assess the impact of these
two normalization techniques on k-means time series clustering in terms of its
clustering quality. The experiments employ the silhouette score, a
well-established metric for evaluating the quality of clusters in a dataset. By
systematically investigating the performance of k-means time series clustering
with these two normalization techniques, this paper addresses the current gap
in k-means time series clustering evaluation and contributes valuable insights
to the development of time series clustering.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15774" title="Abstract">arXiv:2401.15774</a> [<a href="/pdf/2401.15774" title="Download PDF">pdf</a>, <a href="/ps/2401.15774" title="Download PostScript">ps</a>, <a href="/format/2401.15774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Differential Privacy and Contextual Integrity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benthall%2C+S">Sebastian Benthall</a>, 
<a href="/search/cs?searchtype=author&query=Cummings%2C+R">Rachel Cummings</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Proceedings of 3rd ACM Computer Science And Law Symposium, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In this work, we propose the first framework for integrating Differential
Privacy (DP) and Contextual Integrity (CI). DP is a property of an algorithm
that injects statistical noise to obscure information about individuals
represented within a database. CI defines privacy as information flow that is
appropriate to social context. Analyzed together, these paradigms outline two
dimensions on which to analyze privacy of information flows: descriptive and
normative properties. We show that our new integrated framework provides
benefits to both CI and DP that cannot be attained when each definition is
considered in isolation: it enables contextually-guided tuning of the epsilon
parameter in DP, and it enables CI to be applied to a broader set of
information flows occurring in real-world systems, such as those involving PETs
and machine learning. We conclude with a case study based on the use of DP in
the U.S. Census Bureau.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15777" title="Abstract">arXiv:2401.15777</a> [<a href="/pdf/2401.15777" title="Download PDF">pdf</a>, <a href="/format/2401.15777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> cantnlp@LT-EDI-2024: Automatic Detection of Anti-LGBTQ+ Hate Speech in  Under-resourced Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+S+G+-">Sidney G.-J. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Durward%2C+M">Matthew Durward</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted EACL 2024 Workshop LTEDI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper describes our homophobia/transphobia in social media comments
detection system developed as part of the shared task at LT-EDI-2024. We took a
transformer-based approach to develop our multiclass classification model for
ten language conditions (English, Spanish, Gujarati, Hindi, Kannada, Malayalam,
Marathi, Tamil, Tulu, and Telugu). We introduced synthetic and organic
instances of script-switched language data during domain adaptation to mirror
the linguistic realities of social media language as seen in the labelled
training data. Our system ranked second for Gujarati and Telugu with varying
levels of performance for other language conditions. The results suggest
incorporating elements of paralinguistic behaviour such as script-switching may
improve the performance of language detection systems especially in the cases
of under-resourced languages conditions.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15780" title="Abstract">arXiv:2401.15780</a> [<a href="/pdf/2401.15780" title="Download PDF">pdf</a>, <a href="/ps/2401.15780" title="Download PostScript">ps</a>, <a href="/format/2401.15780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuned Large Language Models for Symptom Recognition from Spanish  Clinical Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaaban%2C+M+A">Mai A. Shaaban</a>, 
<a href="/search/cs?searchtype=author&query=Akkasi%2C+A">Abbas Akkasi</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Adnan Khan</a>, 
<a href="/search/cs?searchtype=author&query=Komeili%2C+M">Majid Komeili</a>, 
<a href="/search/cs?searchtype=author&query=Yaqub%2C+M">Mohammad Yaqub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The accurate recognition of symptoms in clinical reports is significantly
important in the fields of healthcare and biomedical natural language
processing. These entities serve as essential building blocks for clinical
information extraction, enabling retrieval of critical medical insights from
vast amounts of textual data. Furthermore, the ability to identify and
categorize these entities is fundamental for developing advanced clinical
decision support systems, aiding healthcare professionals in diagnosis and
treatment planning. In this study, we participated in SympTEMIST, a shared task
on the detection of symptoms, signs and findings in Spanish medical documents.
We combine a set of large language models fine-tuned with the data released by
the organizers.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15781" title="Abstract">arXiv:2401.15781</a> [<a href="/pdf/2401.15781" title="Download PDF">pdf</a>, <a href="/format/2401.15781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Discrepancy of Shortest Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chengyuan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hoppenworth%2C+G">Gary Hoppenworth</a>, 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+J">Jalaj Upadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The hereditary discrepancy of a set system is a certain quantitative measure
of the pseudorandom properties of the system. Roughly, hereditary discrepancy
measures how well one can $2$-color the elements of the system so that each set
contains approximately the same number of elements of each color. Hereditary
discrepancy has well-studied applications e.g. in communication complexity and
derandomization. More recently, the hereditary discrepancy of set systems of
shortest paths has found applications in differential privacy [Chen et al.~SODA
23].
<br />The contribution of this paper is to improve the upper and lower bounds on
the hereditary discrepancy of set systems of unique shortest paths in graphs.
In particular, we show that any system of unique shortest paths in an
undirected weighted graph has hereditary discrepancy $\widetilde{O}(n^{1/4})$,
and we construct lower bound examples demonstrating that this bound is tight up
to hidden $\text{polylog } n$ factors. Our lower bounds apply even in the
planar and bipartite settings, and they improve on a previous lower bound of
$\Omega(n^{1/6})$ obtained by applying the trace bound of Chazelle and Lvov
[SoCG'00] to a classical point-line system of Erd\H{o}s. We also show similar
bounds on (non-hereditary) discrepancy and in the setting of directed graphs.
<br />As applications, we improve the lower bound on the additive error for
differentially-private all pairs shortest distances from $\Omega(n^{1/6})$
[Chen et al.~SODA 23] to $\Omega(n^{1/4})$, and we improve the lower bound on
additive error for the differentially-private all sets range queries problem to
$\Omega(n^{1/4})$, which is tight up to hidden $\text{polylog } n$ factors
[Deng et al.~WADS 23].
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15783" title="Abstract">arXiv:2401.15783</a> [<a href="/pdf/2401.15783" title="Download PDF">pdf</a>, <a href="/format/2401.15783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARGOS: An Automaton Referencing Guided Overtake System for Head-to-Head  Autonomous Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sukhil%2C+V">Varundev Sukhil</a>, 
<a href="/search/cs?searchtype=author&query=Behl%2C+M">Madhur Behl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous overtaking at high speeds is a challenging multi-agent robotics
research problem. The high-speed and close proximity situations that arise in
multi-agent autonomous racing require designing algorithms that trade off
aggressive overtaking maneuvers and minimize the risk of collision with the
opponent. In this paper, we study a special case of multi-agent autonomous
race, called the head-to-head autonomous race, that requires two racecars with
similar performance envelopes. We present a mathematical formulation of an
overtake and position defense in this head-to-head autonomous racing scenario,
and we introduce the Automaton Referencing Guided Overtake System (ARGOS)
framework that supervises the execution of an overtake or position defense
maneuver depending on the current role of the racecar. The ARGOS framework
works by decomposing complex overtake and position-defense maneuvers into
sequential and temporal submaneuvers that are individually managed and
supervised by a network of automatons. We verify the properties of the ARGOS
framework using model-checking and demonstrate results from multiple
simulations, which show that the framework meets the desired specifications.
The ARGOS framework performs similar to what can be observed from real-world
human-driven motor sport racing.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15785" title="Abstract">arXiv:2401.15785</a> [<a href="/pdf/2401.15785" title="Download PDF">pdf</a>, <a href="/format/2401.15785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time object detection and robotic manipulation for agriculture  using a YOLO-based learning approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zezhi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+Y">Yuancheng Si</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Mingyang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Panoutsos%2C+G">George Panoutsos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">The optimisation of crop harvesting processes for commonly cultivated crops
is of great importance in the aim of agricultural industrialisation. Nowadays,
the utilisation of machine vision has enabled the automated identification of
crops, leading to the enhancement of harvesting efficiency, but challenges
still exist. This study presents a new framework that combines two separate
architectures of convolutional neural networks (CNNs) in order to
simultaneously accomplish the tasks of crop detection and harvesting (robotic
manipulation) inside a simulated environment. Crop images in the simulated
environment are subjected to random rotations, cropping, brightness, and
contrast adjustments to create augmented images for dataset generation. The you
only look once algorithmic framework is employed with traditional rectangular
bounding boxes for crop localization. The proposed method subsequently utilises
the acquired image data via a visual geometry group model in order to reveal
the grasping positions for the robotic manipulation.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15788" title="Abstract">arXiv:2401.15788</a> [<a href="/pdf/2401.15788" title="Download PDF">pdf</a>, <a href="/ps/2401.15788" title="Download PostScript">ps</a>, <a href="/format/2401.15788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 230,439 Test Failures Later: An Empirical Evaluation of Flaky Failure  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshammari%2C+A">Abdulrahman Alshammari</a>, 
<a href="/search/cs?searchtype=author&query=Ammann%2C+P">Paul Ammann</a>, 
<a href="/search/cs?searchtype=author&query=Hilton%2C+M">Michael Hilton</a>, 
<a href="/search/cs?searchtype=author&query=Bell%2C+J">Jonathan Bell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Flaky tests are tests that can non-deterministically pass or fail, even in
the absence of code changes.Despite being a source of false alarms, flaky tests
often remain in test suites once they are detected, as they also may be relied
upon to detect true failures. Hence, a key open problem in flaky test research
is: How to quickly determine if a test failed due to flakiness, or if it
detected a bug? The state-of-the-practice is for developers to re-run failing
tests: if a test fails and then passes, it is flaky by definition; if the test
persistently fails, it is likely a true failure. However, this approach can be
both ineffective and inefficient. An alternate approach that developers may
already use for triaging test failures is failure de-duplication, which matches
newly discovered test failures to previously witnessed flaky and true failures.
However, because flaky test failure symptoms might resemble those of true
failures, there is a risk of missclassifying a true test failure as a flaky
failure to be ignored. Using a dataset of 498 flaky tests from 22 open-source
Java projects, we collect a large dataset of 230,439 failure messages (both
flaky and not), allowing us to empirically investigate the efficacy of failure
de-duplication. We find that for some projects, this approach is extremely
effective (with 100\% specificity), while for other projects, the approach is
entirely ineffective. By analyzing the characteristics of these flaky and
non-flaky failures, we provide useful guidance on how developers should rely on
this approach.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15794" title="Abstract">arXiv:2401.15794</a> [<a href="/pdf/2401.15794" title="Download PDF">pdf</a>, <a href="/format/2401.15794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regulation of Algorithmic Collusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartline%2C+J+D">Jason D. Hartline</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+S">Sheng Long</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenhao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">Consider sellers in a competitive market that use algorithms to adapt their
prices from data that they collect. In such a context it is plausible that
algorithms could arrive at prices that are higher than the competitive prices
and this may benefit sellers at the expense of consumers (i.e., the buyers in
the market). This paper gives a definition of plausible algorithmic
non-collusion for pricing algorithms. The definition allows a regulator to
empirically audit algorithms by applying a statistical test to the data that
they collect. Algorithms that are good, i.e., approximately optimize prices to
market conditions, can be augmented to contain the data sufficient to pass the
audit. Algorithms that have colluded on, e.g., supra-competitive prices cannot
pass the audit. The definition allows sellers to possess useful side
information that may be correlated with supply and demand and could affect the
prices used by good algorithms. The paper provides an analysis of the
statistical complexity of such an audit, i.e., how much data is sufficient for
the test of non-collusion to be accurate.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15798" title="Abstract">arXiv:2401.15798</a> [<a href="/pdf/2401.15798" title="Download PDF">pdf</a>, <a href="/format/2401.15798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UnMASKed: Quantifying Gender Biases in Masked Language Models through  Linguistically Informed Job Market Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parra%2C+I">I&#xf1;igo Parra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024 SRW
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language models (LMs) have become pivotal in the realm of technological
advancements. While their capabilities are vast and transformative, they often
include societal biases encoded in the human-produced datasets used for their
training. This research delves into the inherent biases present in masked
language models (MLMs), with a specific focus on gender biases. This study
evaluated six prominent models: BERT, RoBERTa, DistilBERT, BERT-multilingual,
XLM-RoBERTa, and DistilBERT-multilingual. The methodology employed a novel
dataset, bifurcated into two subsets: one containing prompts that encouraged
models to generate subject pronouns in English, and the other requiring models
to return the probabilities of verbs, adverbs, and adjectives linked to the
prompts' gender pronouns. The analysis reveals stereotypical gender alignment
of all models, with multilingual variants showing comparatively reduced biases.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15803" title="Abstract">arXiv:2401.15803</a> [<a href="/pdf/2401.15803" title="Download PDF">pdf</a>, <a href="/format/2401.15803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GarchingSim: An Autonomous Driving Simulator with Photorealistic Scenes  and Minimalist Workflow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Liguo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yinglei Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yichao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sodamin%2C+M">Michael Sodamin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongshen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haichuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Systems and Control (eess.SY)

</div>
<p class="mathjax">Conducting real road testing for autonomous driving algorithms can be
expensive and sometimes impractical, particularly for small startups and
research institutes. Thus, simulation becomes an important method for
evaluating these algorithms. However, the availability of free and open-source
simulators is limited, and the installation and configuration process can be
daunting for beginners and interdisciplinary researchers. We introduce an
autonomous driving simulator with photorealistic scenes, meanwhile keeping a
user-friendly workflow. The simulator is able to communicate with external
algorithms through ROS2 or Socket.IO, making it compatible with existing
software stacks. Furthermore, we implement a highly accurate vehicle dynamics
model within the simulator to enhance the realism of the vehicle's physical
effects. The simulator is able to serve various functions, including generating
synthetic data and driving with machine learning-based algorithms. Moreover, we
prioritize simplicity in the deployment process, ensuring that beginners find
it approachable and user-friendly.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15805" title="Abstract">arXiv:2401.15805</a> [<a href="/pdf/2401.15805" title="Download PDF">pdf</a>, <a href="/ps/2401.15805" title="Download PostScript">ps</a>, <a href="/format/2401.15805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of Breast Cancer Recurrence Risk Using a Multi-Model Approach  Integrating Whole Slide Imaging and Clinicopathologic Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goyal%2C+M">Manu Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Marotti%2C+J+D">Jonathan D. Marotti</a>, 
<a href="/search/cs?searchtype=author&query=Workman%2C+A+A">Adrienne A. Workman</a>, 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+E+P">Elaine P. Kuhn</a>, 
<a href="/search/cs?searchtype=author&query=Tooker%2C+G+M">Graham M. Tooker</a>, 
<a href="/search/cs?searchtype=author&query=Ramin%2C+S+K">Seth K. Ramin</a>, 
<a href="/search/cs?searchtype=author&query=Chamberlin%2C+M+D">Mary D. Chamberlin</a>, 
<a href="/search/cs?searchtype=author&query=diFlorio-Alexander%2C+R+M">Roberta M. diFlorio-Alexander</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+S">Saeed Hassanpour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Breast cancer is the most common malignancy affecting women worldwide and is
notable for its morphologic and biologic diversity, with varying risks of
recurrence following treatment. The Oncotype DX Breast Recurrence Score test is
an important predictive and prognostic genomic assay for estrogen
receptor-positive breast cancer that guides therapeutic strategies; however,
such tests can be expensive, delay care, and are not widely available. The aim
of this study was to develop a multi-model approach integrating the analysis of
whole slide images and clinicopathologic data to predict their associated
breast cancer recurrence risks and categorize these patients into two risk
groups according to the predicted score: low and high risk. The proposed novel
methodology uses convolutional neural networks for feature extraction and
vision transformers for contextual aggregation, complemented by a logistic
regression model that analyzes clinicopathologic data for classification into
two risk categories. This method was trained and tested on 993 hematoxylin and
eosin-stained whole-slide images of breast cancers with corresponding
clinicopathological features that had prior Oncotype DX testing. The model's
performance was evaluated using an internal test set of 198 patients from
Dartmouth Health and an external test set of 418 patients from the University
of Chicago. The multi-model approach achieved an AUC of 0.92 (95 percent CI:
0.88-0.96) on the internal set and an AUC of 0.85 (95 percent CI: 0.79-0.90) on
the external cohort. These results suggest that with further validation, the
proposed methodology could provide an alternative to assist clinicians in
personalizing treatment for breast cancer patients and potentially improving
their outcomes.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15810" title="Abstract">arXiv:2401.15810</a> [<a href="/pdf/2401.15810" title="Download PDF">pdf</a>, <a href="/format/2401.15810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Green Runner: A tool for efficient deep learning component selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kannan%2C+J">Jai Kannan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">For software that relies on machine-learned functionality, model selection is
key to finding the right model for the task with desired performance
characteristics. Evaluating a model requires developers to i) select from many
models (e.g. the Hugging face model repository), ii) select evaluation metrics
and training strategy, and iii) tailor trade-offs based on the problem domain.
However, current evaluation approaches are either ad-hoc resulting in
sub-optimal model selection or brute force leading to wasted compute. In this
work, we present \toolname, a novel tool to automatically select and evaluate
models based on the application scenario provided in natural language. We
leverage the reasoning capabilities of large language models to propose a
training strategy and extract desired trade-offs from a problem description.
\toolname~features a resource-efficient experimentation engine that integrates
constraints and trade-offs based on the problem into the model selection
process. Our preliminary evaluation demonstrates that \toolname{} is both
efficient and accurate compared to ad-hoc evaluations and brute force. This
work presents an important step toward energy-efficient tools to help reduce
the environmental impact caused by the growing demand for software with
machine-learned functionality.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15814" title="Abstract">arXiv:2401.15814</a> [<a href="/pdf/2401.15814" title="Download PDF">pdf</a>, <a href="/format/2401.15814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OntoMedRec: Logically-Pretrained Model-Agnostic Ontology Encoders for  Medication Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weicong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Buntine%2C+W">Wray Buntine</a>, 
<a href="/search/cs?searchtype=author&query=Bingham%2C+G">Gordon Bingham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Most existing medication recommendation models learn representations for
medical concepts based on electronic health records (EHRs) and make
recommendations with learnt representations. However, most medications appear
in the dataset for limited times, resulting in insufficient learning of their
representations. Medical ontologies are the hierarchical classification systems
for medical terms where similar terms are in the same class on a certain level.
In this paper, we propose OntoMedRec, the logically-pretrained and
model-agnostic medical Ontology Encoders for Medication Recommendation that
addresses data sparsity problem with medical ontologies. We conduct
comprehensive experiments on benchmark datasets to evaluate the effectiveness
of OntoMedRec, and the result shows the integration of OntoMedRec improves the
performance of various models in both the entire EHR datasets and the
admissions with few-shot medications. We provide the GitHub repository for the
source code on https://anonymous.4open.science/r/OntoMedRec-D123
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15817" title="Abstract">arXiv:2401.15817</a> [<a href="/pdf/2401.15817" title="Download PDF">pdf</a>, <a href="/ps/2401.15817" title="Download PostScript">ps</a>, <a href="/format/2401.15817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transparency Attacks: How Imperceptible Image Layers Can Fool AI  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McKee%2C+F">Forrest McKee</a>, 
<a href="/search/cs?searchtype=author&query=Noever%2C+D">David Noever</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper investigates a novel algorithmic vulnerability when imperceptible
image layers confound multiple vision models into arbitrary label assignments
and captions. We explore image preprocessing methods to introduce stealth
transparency, which triggers AI misinterpretation of what the human eye
perceives. The research compiles a broad attack surface to investigate the
consequences ranging from traditional watermarking, steganography, and
background-foreground miscues. We demonstrate dataset poisoning using the
attack to mislabel a collection of grayscale landscapes and logos using either
a single attack layer or randomly selected poisoning classes. For example, a
military tank to the human eye is a mislabeled bridge to object classifiers
based on convolutional networks (YOLO, etc.) and vision transformers (ViT,
GPT-Vision, etc.). A notable attack limitation stems from its dependency on the
background (hidden) layer in grayscale as a rough match to the transparent
foreground image that the human eye perceives. This dependency limits the
practical success rate without manual tuning and exposes the hidden layers when
placed on the opposite display theme (e.g., light background, light transparent
foreground visible, works best against a light theme image viewer or browser).
The stealth transparency confounds established vision systems, including
evading facial recognition and surveillance, digital watermarking, content
filtering, dataset curating, automotive and drone autonomy, forensic evidence
tampering, and retail product misclassifying. This method stands in contrast to
traditional adversarial attacks that typically focus on modifying pixel values
in ways that are either slightly perceptible or entirely imperceptible for both
humans and machines.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15818" title="Abstract">arXiv:2401.15818</a> [<a href="/pdf/2401.15818" title="Download PDF">pdf</a>, <a href="/format/2401.15818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Middle Way to Traffic Enlightenment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nice%2C+M+W">Matthew W. Nice</a>, 
<a href="/search/cs?searchtype=author&query=Gunter%2C+G">George Gunter</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Junyi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bunting%2C+M">Matthew Bunting</a>, 
<a href="/search/cs?searchtype=author&query=Barbour%2C+W">Will Barbour</a>, 
<a href="/search/cs?searchtype=author&query=Sprinkle%2C+J">Jonathan Sprinkle</a>, 
<a href="/search/cs?searchtype=author&query=Work%2C+D">Dan Work</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear, ICCPS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces a novel approach that seeks a middle ground for traffic
control in multi-lane congestion, where prevailing traffic speeds are too fast,
and speed recommendations designed to dampen traffic waves are too slow.
Advanced controllers that modify the speed of an automated car for
wave-dampening, eco-driving, or other goals, typically are designed with
forward collision safety in mind. Our approach goes further, by considering how
dangerous it can be for a controller to drive so slowly relative to prevailing
traffic that it creates a significant issue for safety and comfort. This paper
explores open-road scenarios where large gaps between prevailing speeds and
desired speeds can exist, specifically when infrastructure-based variable speed
limit systems are not strictly followed at all times by other drivers. Our
designed, implemented, and deployed algorithm is able to follow variable speed
limits when others also follow it, avoid collisions with vehicles ahead, and
adapt to prevailing traffic when other motorists are traveling well above the
posted speeds. The key is to reject unsafe speed recommendations from
infrastructure-based traffic smoothing systems, based on real-time local
traffic conditions observed by the vehicle under control. This solution is
implemented and deployed on two control vehicles in heavy multi-lane highway
congestion. The results include analysis from system design, and field tests
that validate the system's performance using an existing Variable Speed Limit
system as the external source for speed recommendations, and the on-board
sensors of a stock Toyota Rav4 for inputs that estimate the prevailing speed of
traffic around the vehicle under control.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15820" title="Abstract">arXiv:2401.15820</a> [<a href="/pdf/2401.15820" title="Download PDF">pdf</a>, <a href="/format/2401.15820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Aware Neuron Interpretation for Scene Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Lecue%2C+F">Freddy Lecue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ru Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J+Z">Jeff Z. Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although neural models have achieved remarkable performance, they still
encounter doubts due to the intransparency. To this end, model prediction
explanation is attracting more and more attentions. However, current methods
rarely incorporate external knowledge and still suffer from three limitations:
(1) Neglecting concept completeness. Merely selecting concepts may not
sufficient for prediction. (2) Lacking concept fusion. Failure to merge
semantically-equivalent concepts. (3) Difficult in manipulating model behavior.
Lack of verification for explanation on original model. To address these
issues, we propose a novel knowledge-aware neuron interpretation framework to
explain model predictions for image scene classification. Specifically, for
concept completeness, we present core concepts of a scene based on knowledge
graph, ConceptNet, to gauge the completeness of concepts. Our method,
incorporating complete concepts, effectively provides better prediction
explanations compared to baselines. Furthermore, for concept fusion, we
introduce a knowledge graph-based method known as Concept Filtering, which
produces over 23% point gain on neuron behaviors for neuron interpretation. At
last, we propose Model Manipulation, which aims to study whether the core
concepts based on ConceptNet could be employed to manipulate model behavior.
The results show that core concepts can effectively improve the performance of
original model by over 26%.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15824" title="Abstract">arXiv:2401.15824</a> [<a href="/pdf/2401.15824" title="Download PDF">pdf</a>, <a href="/format/2401.15824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innovation-triggered Learning for Data-driven Predictive Control:  Deterministic and Stochastic Formulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zheng%2C+K">Kaikai Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+D">Dawei Shi</a>, 
<a href="/search/eess?searchtype=author&query=Hirche%2C+S">Sandra Hirche</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yang Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Data-driven control has attracted lots of attention in recent years,
especially for plants that are difficult to model based on first-principle. In
particular, a key issue in data-driven approaches is how to make efficient use
of data as the abundance of data becomes overwhelming. {To address this issue,
this work proposes an innovation-triggered learning framework and a
corresponding data-driven controller design approach with guaranteed stability.
Specifically, we consider a linear time-invariant system with unknown dynamics
subject to deterministic/stochastic disturbances, respectively. Two kinds of
data selection mechanisms are proposed by online evaluating the innovation
contained in the sampled data, wherein the innovation is quantified by its
effect of shrinking the set of potential system dynamics that are compatible
with the sampled data. Next, after introducing a stability criterion using the
set-valued estimation of system dynamics, a robust data-driven predictive
controller is designed by minimizing a worst-case cost function.} The
closed-loop stability of the data-driven predictive controller equipped with
the innovation-triggered learning protocol is proved with a high probability
framework. Finally, numerical experiments are performed to verify the validity
of the proposed approaches, and the characteristics and the selection principle
of the learning hyper-parameter are also discussed.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15828" title="Abstract">arXiv:2401.15828</a> [<a href="/pdf/2401.15828" title="Download PDF">pdf</a>, <a href="/format/2401.15828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Spectre of Surveillance and Censorship in Future Internet  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wrana%2C+M">Michael Wrana</a>, 
<a href="/search/cs?searchtype=author&query=Barradas%2C+D">Diogo Barradas</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+N">N. Asokan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Recent initiatives known as Future Internet Architectures (FIAs) seek to
redesign the Internet to improve performance, scalability, and security.
However, some governments perceive Internet access as a threat to their
political standing and engage in widespread network surveillance and
censorship. In this paper, we provide an in-depth analysis into the designs of
prominent FIAs, to help understand of how FIAs impact surveillance and
censorship abilities. Then, we survey the applicability of privacy-enhancing
technologies to FIAs. We conclude by providing guidelines for future research
into novel FIA-based privacy-enhancing technologies, and recommendations to
guide the evaluation of these technologies.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15834" title="Abstract">arXiv:2401.15834</a> [<a href="/pdf/2401.15834" title="Download PDF">pdf</a>, <a href="/format/2401.15834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few and Fewer: Learning Better from Few Examples Using Fewer Base  Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lafargue%2C+R">Raphael Lafargue</a>, 
<a href="/search/cs?searchtype=author&query=Bendou%2C+Y">Yassir Bendou</a>, 
<a href="/search/cs?searchtype=author&query=Pasdeloup%2C+B">Bastien Pasdeloup</a>, 
<a href="/search/cs?searchtype=author&query=Diguet%2C+J">Jean-Philippe Diguet</a>, 
<a href="/search/cs?searchtype=author&query=Reid%2C+I">Ian Reid</a>, 
<a href="/search/cs?searchtype=author&query=Gripon%2C+V">Vincent Gripon</a>, 
<a href="/search/cs?searchtype=author&query=Valmadre%2C+J">Jack Valmadre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9.5 pages + bibliography and supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">When training data is scarce, it is common to make use of a feature extractor
that has been pre-trained on a large base dataset, either by fine-tuning its
parameters on the ``target'' dataset or by directly adopting its representation
as features for a simple classifier. Fine-tuning is ineffective for few-shot
learning, since the target dataset contains only a handful of examples.
However, directly adopting the features without fine-tuning relies on the base
and target distributions being similar enough that these features achieve
separability and generalization. This paper investigates whether better
features for the target dataset can be obtained by training on fewer base
classes, seeking to identify a more useful base dataset for a given task.We
consider cross-domain few-shot image classification in eight different domains
from Meta-Dataset and entertain multiple real-world settings (domain-informed,
task-informed and uninformed) where progressively less detail is known about
the target task. To our knowledge, this is the first demonstration that
fine-tuning on a subset of carefully selected base classes can significantly
improve few-shot learning. Our contributions are simple and intuitive methods
that can be implemented in any few-shot solution. We also give insights into
the conditions in which these solutions are likely to provide a boost in
accuracy. We release the code to reproduce all experiments from this paper on
GitHub. https://github.com/RafLaf/Few-and-Fewer.git
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15836" title="Abstract">arXiv:2401.15836</a> [<a href="/pdf/2401.15836" title="Download PDF">pdf</a>, <a href="/format/2401.15836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refreshable Tactile Displays for Accessible Data Visualisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holloway%2C+L">Leona Holloway</a>, 
<a href="/search/cs?searchtype=author&query=Cracknell%2C+P">Peter Cracknell</a>, 
<a href="/search/cs?searchtype=author&query=Stephens%2C+K">Kate Stephens</a>, 
<a href="/search/cs?searchtype=author&query=Fanshawe%2C+M">Melissa Fanshawe</a>, 
<a href="/search/cs?searchtype=author&query=Reinders%2C+S">Samuel Reinders</a>, 
<a href="/search/cs?searchtype=author&query=Marriott%2C+K">Kim Marriott</a>, 
<a href="/search/cs?searchtype=author&query=Butler%2C+M">Matthew Butler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Poster presented at IEEE VIS 2023 (Best Poster Honorable Mentions)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Refreshable tactile displays (RTDs) are predicted to soon become a viable
option for the provision of accessible graphics for people who are blind or
have low vision (BLV). This new technology for the tactile display of braille
and graphics, usually using raised pins, makes it easier to generate and access
a large number of graphics. However, it differs from existing tactile graphics
in terms of scale, height and fidelity. Here, we share the perspectives of four
key stakeholders -- blind touch readers, vision specialist teachers, accessible
format producers and assistive technology providers -- to explore the potential
uses, advantages and needs relating to the introduction of RTDs. We also
provide advice on what role the data visualisation community can take to help
ensure that people who are BLV are best able to benefit from the introduction
of affordable RTDs.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15839" title="Abstract">arXiv:2401.15839</a> [<a href="/pdf/2401.15839" title="Download PDF">pdf</a>, <a href="/format/2401.15839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swarm: Cost-Efficient Video Content Distribution with a Peer-to-Peer  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Dehui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haozhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhichen Xue</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yajie Peng</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+X">Xiaofei Pang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+R">Rui Han</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">As ByteDance's business expands, the substantial infrastructure expenses
associated with centralized Content Delivery Network (CDN) networks have
rendered content distribution costs prohibitively high. In response, we
embarked on exploring a peer-to-peer (P2P) network as a promising solution to
alleviate the escalating costs of content distribution. However, the
decentralized nature of P2P often introduces performance challenges, given the
diversity and dispersion of peer devices. This study introduces Swarm,
ByteDance's innovative hybrid system for video streaming. Swarm seamlessly
integrates the robustness of a conventional CDN with the cost-efficiency of a
decentralized P2P network. Its primary aim is to provide users with reliable
streaming quality while minimizing traffic expenses. To achieve this, Swarm
employs a centralized control plane comprised of a tracker cluster, overseeing
a data plane with numerous edge residual resources. The tracker also takes on
the responsibility of mapping clients to servers. Addressing the performance
disparities among individual peer servers, Swarm utilizes our proprietary
multipath parallel transmission method for communication between clients and
peer servers. Operating stably for six years, Swarm now manages over a hundred
thousand peer servers, serving nearly a hundred million users daily and saving
the company hundreds of millions of RMB annually. Experimental results affirm
that, while significantly cutting costs, Swarm performs on par with traditional
CDNs.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15840" title="Abstract">arXiv:2401.15840</a> [<a href="/pdf/2401.15840" title="Download PDF">pdf</a>, <a href="/format/2401.15840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Explainability: Adding a causal chain to neural network  inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perrett%2C+A">Adam Perrett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This position paper presents a theoretical framework for enhancing
explainable artificial intelligence (xAI) through emergent communication
(EmCom), focusing on creating a causal understanding of AI model outputs. We
explore the novel integration of EmCom into AI systems, offering a paradigm
shift from conventional associative relationships between inputs and outputs to
a more nuanced, causal interpretation. The framework aims to revolutionize how
AI processes are understood, making them more transparent and interpretable.
While the initial application of this model is demonstrated on synthetic data,
the implications of this research extend beyond these simple applications. This
general approach has the potential to redefine interactions with AI across
multiple domains, fostering trust and informed decision-making in healthcare
and in various sectors where AI's decision-making processes are critical. The
paper discusses the theoretical underpinnings of this approach, its potential
broad applications, and its alignment with the growing need for responsible and
transparent AI systems in an increasingly digital world.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15841" title="Abstract">arXiv:2401.15841</a> [<a href="/pdf/2401.15841" title="Download PDF">pdf</a>, <a href="/format/2401.15841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2L3: Lifting Imperfect Generated 2D Images into Accurate 3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yizheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Rengan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zixuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianxiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rong Li</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuchi Huo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing 3D objects from a single image is an intriguing but
challenging problem. One promising solution is to utilize multi-view (MV) 3D
reconstruction to fuse generated MV images into consistent 3D objects. However,
the generated images usually suffer from inconsistent lighting, misaligned
geometry, and sparse views, leading to poor reconstruction quality. To cope
with these problems, we present a novel 3D reconstruction framework that
leverages intrinsic decomposition guidance, transient-mono prior guidance, and
view augmentation to cope with the three issues, respectively. Specifically, we
first leverage to decouple the shading information from the generated images to
reduce the impact of inconsistent lighting; then, we introduce mono prior with
view-dependent transient encoding to enhance the reconstructed normal; and
finally, we design a view augmentation fusion strategy that minimizes
pixel-level loss in generated sparse views and semantic loss in augmented
random views, resulting in view-consistent geometry and detailed textures. Our
approach, therefore, enables the integration of a pre-trained MV image
generator and a neural network-based volumetric signed distance function (SDF)
representation for a single image to 3D object reconstruction. We evaluate our
framework on various datasets and demonstrate its superior performance in both
quantitative and qualitative assessments, signifying a significant advancement
in 3D object reconstruction. Compared with the latest state-of-the-art method
Syncdreamer~\cite{liu2023syncdreamer}, we reduce the Chamfer Distance error by
about 36\% and improve PSNR by about 30\% .
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15842" title="Abstract">arXiv:2401.15842</a> [<a href="/pdf/2401.15842" title="Download PDF">pdf</a>, <a href="/ps/2401.15842" title="Download PostScript">ps</a>, <a href="/format/2401.15842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LCVO: An Efficient Pretraining-Free Framework for Visual Question  Answering Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Lumei Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lihua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiwei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages,9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, the LCVO modular method is proposed for the Visual Question
Answering (VQA) Grounding task in the vision-language multimodal domain. This
approach relies on a frozen large language model (LLM) as intermediate mediator
between the off-the-shelf VQA model and the off-the-shelf Open-Vocabulary
Object Detection (OVD) model, where the LLM transforms and conveys textual
information between the two modules based on a designed prompt. LCVO establish
an integrated plug-and-play framework without the need for any pre-training
process. This framework can be deployed for VQA Grounding tasks under low
computational resources. The modularized model within the framework allows
application with various state-of-the-art pre-trained models, exhibiting
significant potential to be advance with the times. Experimental
implementations were conducted under constrained computational and memory
resources, evaluating the proposed method's performance on benchmark datasets
including GQA, CLEVR, and VizWiz-VQA-Grounding. Comparative analyses with
baseline methods demonstrate the robust competitiveness of LCVO.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15843" title="Abstract">arXiv:2401.15843</a> [<a href="/pdf/2401.15843" title="Download PDF">pdf</a>, <a href="/format/2401.15843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APIGen: Generative API Method Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yujia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Cuiyun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Muyijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qing Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guoai Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the proceedings of the 31st IEEE International Conference on Software Analysis, Evolution, and Reengineering (SANER 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Automatic API method recommendation is an essential task of code
intelligence, which aims to suggest suitable APIs for programming queries.
Existing approaches can be categorized into two primary groups: retrieval-based
and learning-based approaches. Although these approaches have achieved
remarkable success, they still come with notable limitations. The
retrieval-based approaches rely on the text representation capabilities of
embedding models, while the learning-based approaches require extensive
task-specific labeled data for training. To mitigate the limitations, we
propose APIGen, a generative API recommendation approach through enhanced
in-context learning (ICL). APIGen involves two main components: (1) Diverse
Examples Selection. APIGen searches for similar posts to the programming
queries from the lexical, syntactical, and semantic perspectives, providing
more informative examples for ICL. (2) Guided API Recommendation. APIGen
enables large language models (LLMs) to perform reasoning before generating API
recommendations, where the reasoning involves fine-grained matching between the
task intent behind the queries and the factual knowledge of the APIs. With the
reasoning process, APIGen makes recommended APIs better meet the programming
requirement of queries and also enhances the interpretability of results. We
compare APIGen with four existing approaches on two publicly available
benchmarks. Experiments show that APIGen outperforms the best baseline CLEAR by
105.8% in method-level API recommendation and 54.3% in class-level API
recommendation in terms of SuccessRate@1. Besides, APIGen achieves an average
49.87% increase compared to the zero-shot performance of popular LLMs such as
GPT-4 in method-level API recommendation regarding the SuccessRate@3 metric.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15844" title="Abstract">arXiv:2401.15844</a> [<a href="/pdf/2401.15844" title="Download PDF">pdf</a>, <a href="/format/2401.15844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Layer Performance Evaluation of C-V2X
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sunuwar%2C+D">Dhruba Sunuwar</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+S">Seungmo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended abstract that was accepted on 01/22/2024 for publication to IEEE SoutheastCon 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As self-driving cars increasingly penetrate our daily lives,
vehicle-to-everything (V2X) communications are emerging as one of the key
enabler technologies. However, the dynamicity of vehicles (one of whose causes
is the mobility of vehicles) often complicates it even further to evaluate the
performance of a V2X system. We have been building a system-level simulator
dedicated to assessing the performance of V2X communications. We highlight that
the simulator features the incorporation of (i) intelligent transportation
system (ITS) scenarios in geographical setup and (ii) physical (PHY) and radio
resource control (RRC) cross-layer performance evaluation capability. In
particular, this abstract reports the status of our implementation of the
modulation and coding scheme (MCS).
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15846" title="Abstract">arXiv:2401.15846</a> [<a href="/pdf/2401.15846" title="Download PDF">pdf</a>, <a href="/format/2401.15846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Learning for Neural Network-based Temporal Point Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takimoto%2C+Y">Yoshiaki Takimoto</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+Y">Yusuke Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Iwata%2C+T">Tomoharu Iwata</a>, 
<a href="/search/cs?searchtype=author&query=Okawa%2C+M">Maya Okawa</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hideaki Kim</a>, 
<a href="/search/cs?searchtype=author&query=Toda%2C+H">Hiroyuki Toda</a>, 
<a href="/search/cs?searchtype=author&query=Kurashima%2C+T">Takeshi Kurashima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Human activities generate various event sequences such as taxi trip records,
bike-sharing pick-ups, crime occurrence, and infectious disease transmission.
The point process is widely used in many applications to predict such events
related to human activities. However, point processes present two problems in
predicting events related to human activities. First, recent high-performance
point process models require the input of sufficient numbers of events
collected over a long period (i.e., long sequences) for training, which are
often unavailable in realistic situations. Second, the long-term predictions
required in real-world applications are difficult. To tackle these problems, we
propose a novel meta-learning approach for periodicity-aware prediction of
future events given short sequences. The proposed method first embeds short
sequences into hidden representations (i.e., task representations) via
recurrent neural networks for creating predictions from short sequences. It
then models the intensity of the point process by monotonic neural networks
(MNNs), with the input being the task representations. We transfer the prior
knowledge learned from related tasks and can improve event prediction given
short sequences of target tasks. We design the MNNs to explicitly take temporal
periodic patterns into account, contributing to improved long-term prediction
performance. Experiments on multiple real-world datasets demonstrate that the
proposed method has higher prediction performance than existing alternatives.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15847" title="Abstract">arXiv:2401.15847</a> [<a href="/pdf/2401.15847" title="Download PDF">pdf</a>, <a href="/format/2401.15847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Muffin or Chihuahua? Challenging Large Vision-Language Models with  Multipanel VQA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yue Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jing Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaiwen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qianqi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+C">Ching-Chen Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+X">Xinze Guan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X+E">Xin Eric Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Multipanel images, commonly seen as web screenshots, posters, etc., pervade
our daily lives. These images, characterized by their composition of multiple
subfigures in distinct layouts, effectively convey information to people.
Toward building advanced multimodal AI applications, such as agents that
understand complex scenes and navigate through webpages, the skill of
multipanel visual reasoning is essential, and a comprehensive evaluation of
models in this regard is important. Therefore, our paper introduces Multipanel
Visual Question Answering (MultipanelVQA), a novel benchmark that specifically
challenges models in comprehending multipanel images. The benchmark comprises
6,600 questions and answers related to multipanel images. While these questions
are straightforward for average humans, achieving nearly perfect correctness,
they pose significant challenges to the state-of-the-art Large Vision Language
Models (LVLMs) we tested. In our study, we utilized synthetically curated
multipanel images specifically designed to isolate and evaluate the impact of
diverse factors on model performance, revealing the sensitivity of LVLMs to
various interferences in multipanel images, such as adjacent subfigures and
layout complexity. As a result, MultipanelVQA highlights the need and direction
for improving LVLMs' ability to understand complex visual-language contexts.
Code and data are released at https://sites.google.com/view/multipanelvqa/home.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15848" title="Abstract">arXiv:2401.15848</a> [<a href="/pdf/2401.15848" title="Download PDF">pdf</a>, <a href="/format/2401.15848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Voltage Control and Renewable  Accommodation Using Spatial-Temporal Graph Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jinhao Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+R">Ruichang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Lai%2C+H">Hongyang Lai</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yanru Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 15 figures. Accepted by IEEE Transactions on Sustainable Energy
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Sustainable Energy, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Renewable energy resources (RERs) have been increasingly integrated into
distribution networks (DNs) for decarbonization. However, the variable nature
of RERs introduces uncertainties to DNs, frequently resulting in voltage
fluctuations that threaten system security and hamper the further adoption of
RERs. To incentivize more RER penetration, we propose a deep reinforcement
learning (DRL)-based strategy to dynamically balance the trade-off between
voltage fluctuation control and renewable accommodation. To further extract
multi-time-scale spatial-temporal (ST) graphical information of a DN, our
strategy draws on a multi-grained attention-based spatial-temporal graph
convolution network (MG-ASTGCN), consisting of ST attention mechanism and ST
convolution to explore the node correlations in the spatial and temporal views.
The continuous decision-making process of balancing such a trade-off can be
modeled as a Markov decision process optimized by the deep deterministic policy
gradient (DDPG) algorithm with the help of the derived ST information. We
validate our strategy on the modified IEEE 33, 69, and 118-bus radial
distribution systems, with outcomes significantly outperforming the
optimization-based benchmarks. Simulations also reveal that our developed
MG-ASTGCN can to a great extent accelerate the convergence speed of DDPG and
improve its performance in stabilizing node voltage in an RER-rich DN.
Moreover, our method improves the DN's robustness in the presence of generator
failures.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15853" title="Abstract">arXiv:2401.15853</a> [<a href="/pdf/2401.15853" title="Download PDF">pdf</a>, <a href="/format/2401.15853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attentive Convolutional Deep Reinforcement Learning for Optimizing  Solar-Storage Systems in Real-Time Electricity Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jinhao Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Changlong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Industrial Informatics, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper studies the synergy of solar-battery energy storage system (BESS)
and develops a viable strategy for the BESS to unlock its economic potential by
serving as a backup to reduce solar curtailments while also participating in
the electricity market. We model the real-time bidding of the solar-battery
system as two Markov decision processes for the solar farm and the BESS,
respectively. We develop a novel deep reinforcement learning (DRL) algorithm to
solve the problem by leveraging attention mechanism (AC) and multi-grained
feature convolution to process DRL input for better bidding decisions.
Simulation results demonstrate that our AC-DRL outperforms two
optimization-based and one DRL-based benchmarks by generating 23%, 20%, and 11%
higher revenue, as well as improving curtailment responses. The excess solar
generation can effectively charge the BESS to bid in the market, significantly
reducing solar curtailments by 76% and creating synergy for the solar-battery
system to be more viable.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15854" title="Abstract">arXiv:2401.15854</a> [<a href="/pdf/2401.15854" title="Download PDF">pdf</a>, <a href="/format/2401.15854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LSTM-based Deep Neural Network With A Focus on Sentence Representation  for Sequential Sentence Classification in Medical Scientific Abstracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lam%2C+P">Phat Lam</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+L">Lam Pham</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tin Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hieu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Michael%2C+S">Seidl Michael</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+A">Alexander Schindler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The Sequential Sentence Classification task within the domain of medical
abstracts, termed as SSC, involves the categorization of sentences into
pre-defined headings based on their roles in conveying critical information in
the abstract. In the SSC task, sentences are often sequentially related to each
other. For this reason, the role of sentence embedding is crucial for capturing
both the semantic information between words in the sentence and the contextual
relationship of sentences within the abstract to provide a comprehensive
representation for better classification. In this paper, we present a
hierarchical deep learning model for the SSC task. First, we propose a
LSTM-based network with multiple feature branches to create well-presented
sentence embeddings at the sentence level. To perform the sequence of
sentences, a convolutional-recurrent neural network (C-RNN) at the abstract
level and a multi-layer perception network (MLP) at the segment level are
developed that further enhance the model performance. Additionally, an ablation
study is also conducted to evaluate the contribution of individual component in
the entire network to the model performance at different levels. Our proposed
system is very competitive to the state-of-the-art systems and further improve
F1 scores of the baseline by 1.0%, 2.8%, and 2.6% on the benchmark datasets
PudMed 200K RCT, PudMed 20K RCT and NICTA-PIBOSO, respectively.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15855" title="Abstract">arXiv:2401.15855</a> [<a href="/pdf/2401.15855" title="Download PDF">pdf</a>, <a href="/format/2401.15855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Scale MAE: A Tale of Multi-Scale Exploitation in Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Maofeng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cozma%2C+A">Andrei Cozma</a>, 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+K">Konstantinos Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Hairong Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Remote sensing images present unique challenges to image analysis due to the
extensive geographic coverage, hardware limitations, and misaligned multi-scale
images. This paper revisits the classical multi-scale representation learning
problem but under the general framework of self-supervised learning for remote
sensing image understanding. We present Cross-Scale MAE, a self-supervised
model built upon the Masked Auto-Encoder (MAE).During pre-training, Cross-Scale
MAE employs scale augmentation techniques and enforces cross-scale consistency
constraints through both contrastive and generative losses to ensure consistent
and meaningful representations well-suited for a wide range of downstream
tasks. Further, our implementation leverages the xFormers library to accelerate
network pre-training on a single GPU while maintaining the quality of learned
representations. Experimental evaluations demonstrate that Cross-Scale MAE
exhibits superior performance compared to standard MAE and other
state-of-the-art remote sensing MAE methods.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15856" title="Abstract">arXiv:2401.15856</a> [<a href="/pdf/2401.15856" title="Download PDF">pdf</a>, <a href="/format/2401.15856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look Around! Unexpected gains from training on environments in the  vicinity of the target
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bono%2C+S">Serena Bono</a>, 
<a href="/search/cs?searchtype=author&query=Madan%2C+S">Spandan Madan</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+I">Ishaan Grover</a>, 
<a href="/search/cs?searchtype=author&query=Yasueda%2C+M">Mao Yasueda</a>, 
<a href="/search/cs?searchtype=author&query=Breazeal%2C+C">Cynthia Breazeal</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+H">Hanspeter Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Kreiman%2C+G">Gabriel Kreiman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Solutions to Markov Decision Processes (MDP) are often very sensitive to
state transition probabilities. As the estimation of these probabilities is
often inaccurate in practice, it is important to understand when and how
Reinforcement Learning (RL) agents generalize when transition probabilities
change. Here we present a new methodology to evaluate such generalization of RL
agents under small shifts in the transition probabilities. Specifically, we
evaluate agents in new environments (MDPs) in the vicinity of the training MDP
created by adding quantifiable, parametric noise into the transition function
of the training MDP. We refer to this process as Noise Injection, and the
resulting environments as $\delta$-environments. This process allows us to
create controlled variations of the same environment with the level of the
noise serving as a metric of distance between environments. Conventional wisdom
suggests that training and testing on the same MDP should yield the best
results. However, we report several cases of the opposite -- when targeting a
specific environment, training the agent in an alternative noise setting can
yield superior outcomes. We showcase this phenomenon across $60$ different
variations of ATARI games, including PacMan, Pong, and Breakout.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15857" title="Abstract">arXiv:2401.15857</a> [<a href="/pdf/2401.15857" title="Download PDF">pdf</a>, <a href="/format/2401.15857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leadership Dynamics in Social Multiplex Networks with Mono and  Bi-directional Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Talebi%2C+A">Amirreza Talebi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We explored the dynamics of opinions within a multiplex network, where agents
engage in one-way or two-way communication, and the network may have a des-
ignated leader. Additionally, we demonstrated that, under specific conditions,
opinions tend to converge despite non-positive diagonal elements in transition
probability matrices or decomposable layers. Lastly, we contrasted the conver-
gence rates of opinion dynamics in networks with one-way interactions against
those with two-way interactions, revealing that one-way interactions may
facili- tate faster convergence outcomes. Additionally, we shed light on the
pivotal role of designated leaders in steering opinion convergence within the
network.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15859" title="Abstract">arXiv:2401.15859</a> [<a href="/pdf/2401.15859" title="Download PDF">pdf</a>, <a href="/format/2401.15859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Facial Forgery Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Harry Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yangyang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The dataset will be released at \url{<a href="https://github.com/xaCheng1996/DiFF">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Detecting diffusion-generated images has recently grown into an emerging
research area. Existing diffusion-based datasets predominantly focus on general
image generation. However, facial forgeries, which pose a more severe social
risk, have remained less explored thus far. To address this gap, this paper
introduces DiFF, a comprehensive dataset dedicated to face-focused
diffusion-generated images. DiFF comprises over 500,000 images that are
synthesized using thirteen distinct generation methods under four conditions.
In particular, this dataset leverages 30,000 carefully collected textual and
visual prompts, ensuring the synthesis of images with both high fidelity and
semantic consistency. We conduct extensive experiments on the DiFF dataset via
a human test and several representative forgery detection methods. The results
demonstrate that the binary detection accuracy of both human observers and
automated detectors often falls below 30%, shedding light on the challenges in
detecting diffusion-generated facial forgeries. Furthermore, we propose an edge
graph regularization approach to effectively enhance the generalization
capability of existing detectors.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15861" title="Abstract">arXiv:2401.15861</a> [<a href="/pdf/2401.15861" title="Download PDF">pdf</a>, <a href="/format/2401.15861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DrBERT: Unveiling the Potential of Masked Language Modeling Decoder in  BERT pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Wen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youzhi Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">BERT (Bidirectional Encoder Representations from Transformers) has
revolutionized the field of natural language processing through its exceptional
performance on numerous tasks. Yet, the majority of researchers have mainly
concentrated on enhancements related to the model structure, such as relative
position embedding and more efficient attention mechanisms. Others have delved
into pretraining tricks associated with Masked Language Modeling, including
whole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's
encoder model for pretraining, proving to be highly effective. We argue that
the design and research around enhanced masked language modeling decoders have
been underappreciated. In this paper, we propose several designs of enhanced
decoders and introduce DrBERT (Decoder-refined BERT), a novel method for
modeling training. Typically, a pretrained BERT model is fine-tuned for
specific Natural Language Understanding (NLU) tasks. In our approach, we
utilize the original BERT model as the encoder, making only changes to the
decoder without altering the encoder. This approach does not necessitate
extensive modifications to the model's architecture and can be seamlessly
integrated into existing fine-tuning pipelines and services, offering an
efficient and effective enhancement strategy. Compared to other methods, while
we also incur a moderate training cost for the decoder during the pretraining
process, our approach does not introduce additional training costs during the
fine-tuning phase. We test multiple enhanced decoder structures after
pretraining and evaluate their performance on the GLUE benchmark. Our results
demonstrate that DrBERT, having only undergone subtle refinements to the model
structure during pretraining, significantly enhances model performance without
escalating the inference time and serving budget.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15862" title="Abstract">arXiv:2401.15862</a> [<a href="/pdf/2401.15862" title="Download PDF">pdf</a>, <a href="/format/2401.15862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PML-based boundary integral equation method for electromagnetic  scattering problems in a layered-medium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bao%2C+G">Gang Bao</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+W">Wangtao Lu</a>, 
<a href="/search/math?searchtype=author&query=Yin%2C+T">Tao Yin</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper proposes a new boundary integral equation (BIE) methodology based
on the perfectly matched layer (PML) truncation technique for solving the
electromagnetic scattering problems in a multi-layered medium. Instead of using
the original PML stretched fields, artificial fields which are also equivalent
to the solutions in the physical region are introduced. This significantly
simplifies the study of the proposed methodology to derive the PML problem.
Then some PML transformed layer potentials and the associated boundary integral
operators (BIOs) are defined and the corresponding jump relations are shown.
Under the assumption that the fields vanish on the PML boundary, the solution
representations, as well as the related BIEs and regularization of the
hyper-singular operators, in terms of the current density functions on the
truncated interface, are derived. Numerical experiments are presented to
demonstrate the efficiency and accuracy of the method.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15863" title="Abstract">arXiv:2401.15863</a> [<a href="/pdf/2401.15863" title="Download PDF">pdf</a>, <a href="/format/2401.15863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Importance-Aware Adaptive Dataset Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guang Li</a>, 
<a href="/search/cs?searchtype=author&query=Togo%2C+R">Ren Togo</a>, 
<a href="/search/cs?searchtype=author&query=Ogawa%2C+T">Takahiro Ogawa</a>, 
<a href="/search/cs?searchtype=author&query=Haseyama%2C+M">Miki Haseyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a journal paper in Elsevier Neural Networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Herein, we propose a novel dataset distillation method for constructing small
informative datasets that preserve the information of the large original
datasets. The development of deep learning models is enabled by the
availability of large-scale datasets. Despite unprecedented success,
large-scale datasets considerably increase the storage and transmission costs,
resulting in a cumbersome model training process. Moreover, using raw data for
training raises privacy and copyright concerns. To address these issues, a new
task named dataset distillation has been introduced, aiming to synthesize a
compact dataset that retains the essential information from the large original
dataset. State-of-the-art (SOTA) dataset distillation methods have been
proposed by matching gradients or network parameters obtained during training
on real and synthetic datasets. The contribution of different network
parameters to the distillation process varies, and uniformly treating them
leads to degraded distillation performance. Based on this observation, we
propose an importance-aware adaptive dataset distillation (IADD) method that
can improve distillation performance by automatically assigning importance
weights to different network parameters during distillation, thereby
synthesizing more robust distilled datasets. IADD demonstrates superior
performance over other SOTA dataset distillation methods based on parameter
matching on multiple benchmark datasets and outperforms them in terms of
cross-architecture generalization. In addition, the analysis of self-adaptive
weights demonstrates the effectiveness of IADD. Furthermore, the effectiveness
of IADD is validated in a real-world medical application such as COVID-19
detection.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15864" title="Abstract">arXiv:2401.15864</a> [<a href="/pdf/2401.15864" title="Download PDF">pdf</a>, <a href="/format/2401.15864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Decomposition and Temporal Fusion based Inter Prediction for  Learned Video Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+X">Xihua Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Video compression performance is closely related to the accuracy of inter
prediction. It tends to be difficult to obtain accurate inter prediction for
the local video regions with inconsistent motion and occlusion. Traditional
video coding standards propose various technologies to handle motion
inconsistency and occlusion, such as recursive partitions, geometric
partitions, and long-term references. However, existing learned video
compression schemes focus on obtaining an overall minimized prediction error
averaged over all regions while ignoring the motion inconsistency and occlusion
in local regions. In this paper, we propose a spatial decomposition and
temporal fusion based inter prediction for learned video compression. To handle
motion inconsistency, we propose to decompose the video into structure and
detail (SDD) components first. Then we perform SDD-based motion estimation and
SDD-based temporal context mining for the structure and detail components to
generate short-term temporal contexts. To handle occlusion, we propose to
propagate long-term temporal contexts by recurrently accumulating the temporal
information of each historical reference feature and fuse them with short-term
temporal contexts. With the SDD-based motion model and long short-term temporal
contexts fusion, our proposed learned video codec can obtain more accurate
inter prediction. Comprehensive experimental results demonstrate that our codec
outperforms the reference software of H.266/VVC on all common test datasets for
both PSNR and MS-SSIM.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15865" title="Abstract">arXiv:2401.15865</a> [<a href="/pdf/2401.15865" title="Download PDF">pdf</a>, <a href="/format/2401.15865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Shipeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Miao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaobo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to highly constrained computing power and memory, deploying 3D
lidar-based detectors on edge devices equipped in autonomous vehicles and
robots poses a crucial challenge. Being a convenient and straightforward model
compression approach, Post-Training Quantization (PTQ) has been widely adopted
in 2D vision tasks. However, applying it directly to 3D lidar-based tasks
inevitably leads to performance degradation. As a remedy, we propose an
effective PTQ method called LiDAR-PTQ, which is particularly curated for 3D
lidar detection (both SPConv-based and SPConv-free). Our LiDAR-PTQ features
three main components, \textbf{(1)} a sparsity-based calibration method to
determine the initialization of quantization parameters, \textbf{(2)} a
Task-guided Global Positive Loss (TGPL) to reduce the disparity between the
final predictions before and after quantization, \textbf{(3)} an adaptive
rounding-to-nearest operation to minimize the layerwise reconstruction error.
Extensive experiments demonstrate that our LiDAR-PTQ can achieve
state-of-the-art quantization performance when applied to CenterPoint (both
Pillar-based and Voxel-based). To our knowledge, for the very first time in
lidar-based 3D detection tasks, the PTQ INT8 model's accuracy is almost the
same as the FP32 model while enjoying $3\times$ inference speedup. Moreover,
our LiDAR-PTQ is cost-effective being $30\times$ faster than the
quantization-aware training method. Code will be released at
\url{https://github.com/StiphyJay/LiDAR-PTQ}.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15866" title="Abstract">arXiv:2401.15866</a> [<a href="/pdf/2401.15866" title="Download PDF">pdf</a>, <a href="/format/2401.15866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Amortization: A Unified Approach to Accelerate Feature and  Data Attribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Covert%2C+I">Ian Covert</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chanwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Su-In Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T">Tatsunori Hashimoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Many tasks in explainable machine learning, such as data valuation and
feature attribution, perform expensive computation for each data point and can
be intractable for large datasets. These methods require efficient
approximations, and learning a network that directly predicts the desired
output, which is commonly known as amortization, is a promising solution.
However, training such models with exact labels is often intractable; we
therefore explore training with noisy labels and find that this is inexpensive
and surprisingly effective. Through theoretical analysis of the label noise and
experiments with various models and datasets, we show that this approach
significantly accelerates several feature attribution and data valuation
methods, often yielding an order of magnitude speedup over existing approaches.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15867" title="Abstract">arXiv:2401.15867</a> [<a href="/pdf/2401.15867" title="Download PDF">pdf</a>, <a href="/ps/2401.15867" title="Download PostScript">ps</a>, <a href="/format/2401.15867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Information Aggregation Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+H">Heyang Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This study explores a new mathematical operator, symbolized as $\cupplus$,
for information aggregation, aimed at enhancing traditional methods by directly
amalgamating probability distributions. This operator facilitates the
combination of probability densities, contributing a nuanced approach to
probabilistic analysis. We apply this operator to a personalized incentive
scenario, illustrating its potential in a practical context. The paper's
primary contribution lies in introducing this operator and elucidating its
elegant mathematical properties. This exploratory work marks a step forward in
the field of information fusion and probabilistic reasoning.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15869" title="Abstract">arXiv:2401.15869</a> [<a href="/pdf/2401.15869" title="Download PDF">pdf</a>, <a href="/format/2401.15869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Circuit Reconstruction from Power Side-Channel Attacks on  Quantum Computer Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erata%2C+F">Ferhat Erata</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chuanqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Piskac%2C+R">Ruzica Piskac</a>, 
<a href="/search/cs?searchtype=author&query=Szefer%2C+J">Jakub Szefer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IACR Transactions on Cryptographic Hardware and Embedded Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The interest in quantum computing has grown rapidly in recent years, and with
it grows the importance of securing quantum circuits. A novel type of threat to
quantum circuits that dedicated attackers could launch are power trace attacks.
To address this threat, this paper presents first formalization and
demonstration of using power traces to unlock and steal quantum circuit
secrets. With access to power traces, attackers can recover information about
the control pulses sent to quantum computers. From the control pulses, the gate
level description of the circuits, and eventually the secret algorithms can be
reverse engineered. This work demonstrates how and what information could be
recovered. This work uses algebraic reconstruction from power traces to realize
two new types of single trace attacks: per-channel and total power attacks. The
former attack relies on per-channel measurements to perform a brute-force
attack to reconstruct the quantum circuits. The latter attack performs a
single-trace attack using Mixed-Integer Linear Programming optimization.
Through the use of algebraic reconstruction, this work demonstrates that
quantum circuit secrets can be stolen with high accuracy. Evaluation on 32 real
benchmark quantum circuits shows that our technique is highly effective at
reconstructing quantum circuits. The findings not only show the veracity of the
potential attacks, but also the need to develop new means to protect quantum
circuits from power trace attacks. Throughout this work real control pulse
information from real quantum computers is used to demonstrate potential
attacks based on simulation of collection of power traces.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15870" title="Abstract">arXiv:2401.15870</a> [<a href="/pdf/2401.15870" title="Download PDF">pdf</a>, <a href="/format/2401.15870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DF* PageRank: Improved Incrementally Expanding Approaches for Updating  PageRank on Dynamic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">PageRank is a widely used centrality measure that assesses the significance
of vertices in a graph by considering their connections and the importance of
those connections. Efficiently updating PageRank on dynamic graphs is essential
for various applications due to the increasing scale of datasets. This
technical report introduces our improved Dynamic Frontier (DF) and Dynamic
Frontier with Pruning (DF-P) approaches. Given a batch update comprising edge
insertions and deletions, these approaches iteratively identify vertices likely
to change their ranks with minimal overhead. On a server featuring a 64-core
AMD EPYC-7742 processor, our approaches outperform Static and Dynamic Traversal
PageRank by 5.2x/15.2x and 1.3x/3.5x respectively - on real-world dynamic
graphs, and by 7.2x/9.6x and 4.0x/5.6x on large static graphs with random batch
updates. Furthermore, our approaches improve performance at a rate of 1.8x/1.7x
for every doubling of threads.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15872" title="Abstract">arXiv:2401.15872</a> [<a href="/pdf/2401.15872" title="Download PDF">pdf</a>, <a href="/format/2401.15872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Q-Network Based on Radial Basis Functions for Multi-Echelon  Inventory Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Liqiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Weiwei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yidong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper addresses a multi-echelon inventory management problem with a
complex network topology where deriving optimal ordering decisions is
difficult. Deep reinforcement learning (DRL) has recently shown potential in
solving such problems, while designing the neural networks in DRL remains a
challenge. In order to address this, a DRL model is developed whose Q-network
is based on radial basis functions. The approach can be more easily constructed
compared to classic DRL models based on neural networks, thus alleviating the
computational burden of hyperparameter tuning. Through a series of simulation
experiments, the superior performance of this approach is demonstrated compared
to the simple base-stock policy, producing a better policy in the multi-echelon
system and competitive performance in the serial system where the base-stock
policy is optimal. In addition, the approach outperforms current DRL
approaches.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15874" title="Abstract">arXiv:2401.15874</a> [<a href="/pdf/2401.15874" title="Download PDF">pdf</a>, <a href="/format/2401.15874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Personalized Federated Learning with Clustering-based Dynamic  Graph Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuzhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuhang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+M">Mahashweta Das</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fenglong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by PAKDD 2024 as an oral presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Most existing personalized federated learning approaches are based on
intricate designs, which often require complex implementation and tuning. In
order to address this limitation, we propose a simple yet effective
personalized federated learning framework. Specifically, during each
communication round, we group clients into multiple clusters based on their
model training status and data distribution on the server side. We then
consider each cluster center as a node equipped with model parameters and
construct a graph that connects these nodes using weighted edges. Additionally,
we update the model parameters at each node by propagating information across
the entire graph. Subsequently, we design a precise personalized model
distribution strategy to allow clients to obtain the most suitable model from
the server side. We conduct experiments on three image benchmark datasets and
create synthetic structured datasets with three types of typologies.
Experimental results demonstrate the effectiveness of the proposed work.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15875" title="Abstract">arXiv:2401.15875</a> [<a href="/pdf/2401.15875" title="Download PDF">pdf</a>, <a href="/format/2401.15875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Satellite and Weather Data for Crop Type Mapping: An Inverse  Modelling Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ravirathinam%2C+P">Praveen Ravirathinam</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+R">Rahul Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+A">Ankush Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaowei Jia</a>, 
<a href="/search/cs?searchtype=author&query=Mulla%2C+D">David Mulla</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vipin Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, SIAM International Conference on Data Mining (SDM24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate and timely crop mapping is essential for yield estimation, insurance
claims, and conservation efforts. Over the years, many successful machine
learning models for crop mapping have been developed that use just the
multi-spectral imagery from satellites to predict crop type over the area of
interest. However, these traditional methods do not account for the physical
processes that govern crop growth. At a high level, crop growth can be
envisioned as physical parameters, such as weather and soil type, acting upon
the plant leading to crop growth which can be observed via satellites. In this
paper, we propose Weather-based Spatio-Temporal segmentation network with
ATTention (WSTATT), a deep learning model that leverages this understanding of
crop growth by formulating it as an inverse model that combines weather
(Daymet) and satellite imagery (Sentinel-2) to generate accurate crop maps. We
show that our approach provides significant improvements over existing
algorithms that solely rely on spectral imagery by comparing segmentation maps
and F1 classification scores. Furthermore, effective use of attention in WSTATT
architecture enables detection of crop types earlier in the season (up to 5
months in advance), which is very useful for improving food supply projections.
We finally discuss the impact of weather by correlating our results with crop
phenology to show that WSTATT is able to capture physical properties of crop
growth.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15876" title="Abstract">arXiv:2401.15876</a> [<a href="/pdf/2401.15876" title="Download PDF">pdf</a>, <a href="/format/2401.15876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMA-ES with Learning Rate Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nomura%2C+M">Masahiro Nomura</a>, 
<a href="/search/cs?searchtype=author&query=Akimoto%2C+Y">Youhei Akimoto</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+I">Isao Ono</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review for ACM TELO
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The covariance matrix adaptation evolution strategy (CMA-ES) is one of the
most successful methods for solving continuous black-box optimization problems.
A practically useful aspect of the CMA-ES is that it can be used without
hyperparameter tuning. However, the hyperparameter settings still have a
considerable impact on performance, especially for difficult tasks, such as
solving multimodal or noisy problems. This study comprehensively explores the
impact of learning rate on the CMA-ES performance and demonstrates the
necessity of a small learning rate by considering ordinary differential
equations. Thereafter, it discusses the setting of an ideal learning rate.
Based on these discussions, we develop a novel learning rate adaptation
mechanism for the CMA-ES that maintains a constant signal-to-noise ratio.
Additionally, we investigate the behavior of the CMA-ES with the proposed
learning rate adaptation mechanism through numerical experiments, and compare
the results with those obtained for the CMA-ES with a fixed learning rate and
with population size adaptation. The results show that the CMA-ES with the
proposed learning rate adaptation works well for multimodal and/or noisy
problems without extremely expensive learning rate tuning.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15877" title="Abstract">arXiv:2401.15877</a> [<a href="/pdf/2401.15877" title="Download PDF">pdf</a>, <a href="/format/2401.15877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DPFIX: Improving Remote Novices&#x27; 3D Printing Troubleshooting through  Human-AI Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+N">Nahyun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeeeun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S+R">Sungsoo Ray Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CSCW'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The widespread consumer-grade 3D printers and learning resources online
enable novices to self-train in remote settings. While troubleshooting plays an
essential part of 3D printing, the process remains challenging for many remote
novices even with the help of well-developed online sources, such as online
troubleshooting archives and online community help. We conducted a formative
study with 76 active 3D printing users to learn how remote novices leverage
online resources in troubleshooting and their challenges. We found that remote
novices cannot fully utilize online resources. For example, the online archives
statically provide general information, making it hard to search and relate
their unique cases with existing descriptions. Online communities can
potentially ease their struggles by providing more targeted suggestions, but a
helper who can provide custom help is rather scarce, making it hard to obtain
timely assistance. We propose 3DPFIX, an interactive 3D troubleshooting system
powered by the pipeline to facilitate Human-AI Collaboration, designed to
improve novices' 3D printing experiences and thus help them easily accumulate
their domain knowledge. We built 3DPFIX that supports automated diagnosis and
solution-seeking. 3DPFIX was built upon shared dialogues about failure cases
from Q\&amp;A discourses accumulated in online communities. We leverage social
annotations (i.e., comments) to build an annotated failure image dataset for AI
classifiers and extract a solution pool. Our summative study revealed that
using 3DPFIX helped participants spend significantly less effort in diagnosing
failures and finding a more accurate solution than relying on their common
practice. We also found that 3DPFIX users learn about 3D printing
domain-specific knowledge. We discuss the implications of leveraging
community-driven data in developing future Human-AI Collaboration designs.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15878" title="Abstract">arXiv:2401.15878</a> [<a href="/pdf/2401.15878" title="Download PDF">pdf</a>, <a href="/format/2401.15878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding the MITRE Engenuity ATT&amp;CK Enterprise Evaluation: An Analysis  of EDR Performance in Real-World Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiangmin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Burleigh%2C+G">Graham Burleigh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures, to appear in AsiaCCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Endpoint detection and response (EDR) systems have emerged as a critical
component of enterprise security solutions, effectively combating endpoint
threats like APT attacks with extended lifecycles. In light of the growing
significance of endpoint detection and response (EDR) systems, many
cybersecurity providers have developed their own proprietary EDR solutions.
It's crucial for users to assess the capabilities of these detection engines to
make informed decisions about which products to choose. This is especially
urgent given the market's size, which is expected to reach around 3.7 billion
dollars by 2023 and is still expanding. MITRE is a leading organization in
cyber threat analysis. In 2018, MITRE started to conduct annual APT emulations
that cover major EDR vendors worldwide. Indicators include telemetry, detection
and blocking capability, etc. Nevertheless, the evaluation results published by
MITRE don't contain any further interpretations or suggestions.
<br />In this paper, we thoroughly analyzed MITRE evaluation results to gain
further insights into real-world EDR systems under test. Specifically, we
designed a whole-graph analysis method, which utilizes additional control flow
and data flow information to measure the performance of EDR systems. Besides,
we analyze MITRE evaluation's results over multiple years from various aspects,
including detection coverage, detection confidence, detection modifier, data
source, compatibility, etc. Through the above studies, we have compiled a
thorough summary of our findings and gained valuable insights from the
evaluation results. We believe these summaries and insights can assist
researchers, practitioners, and vendors in better understanding the strengths
and limitations of mainstream EDR products.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15879" title="Abstract">arXiv:2401.15879</a> [<a href="/pdf/2401.15879" title="Download PDF">pdf</a>, <a href="/format/2401.15879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> lil&#x27;HDoC: An Algorithm for Good Arm Identification under Small Threshold  Gap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+T">Tzu-Hsien Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yun-Da Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shou-De Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Good arm identification (GAI) is a pure-exploration bandit problem in which a
single learner outputs an arm as soon as it is identified as a good arm. A good
arm is defined as an arm with an expected reward greater than or equal to a
given threshold. This paper focuses on the GAI problem under a small threshold
gap, which refers to the distance between the expected rewards of arms and the
given threshold. We propose a new algorithm called lil'HDoC to significantly
improve the total sample complexity of the HDoC algorithm. We demonstrate that
the sample complexity of the first $\lambda$ output arm in lil'HDoC is bounded
by the original HDoC algorithm, except for one negligible term, when the
distance between the expected reward and threshold is small. Extensive
experiments confirm that our algorithm outperforms the state-of-the-art
algorithms in both synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15883" title="Abstract">arXiv:2401.15883</a> [<a href="/pdf/2401.15883" title="Download PDF">pdf</a>, <a href="/format/2401.15883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransTroj: Transferable Backdoor Attacks to Pre-trained Models via  Embedding Indistinguishability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shangwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jialing He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hangcheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 16 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pre-trained models (PTMs) are extensively utilized in various downstream
tasks. Adopting untrusted PTMs may suffer from backdoor attacks, where the
adversary can compromise the downstream models by injecting backdoors into the
PTM. However, existing backdoor attacks to PTMs can only achieve partially
task-agnostic and the embedded backdoors are easily erased during the
fine-tuning process. In this paper, we propose a novel transferable backdoor
attack, TransTroj, to simultaneously meet functionality-preserving, durable,
and task-agnostic. In particular, we first formalize transferable backdoor
attacks as the indistinguishability problem between poisoned and clean samples
in the embedding space. We decompose the embedding indistinguishability into
pre- and post-indistinguishability, representing the similarity of the poisoned
and reference embeddings before and after the attack. Then, we propose a
two-stage optimization that separately optimizes triggers and victim PTMs to
achieve embedding indistinguishability. We evaluate TransTroj on four PTMs and
six downstream tasks. Experimental results show that TransTroj significantly
outperforms SOTA task-agnostic backdoor attacks (18%$\sim$99%, 68% on average)
and exhibits superior performance under various system settings. The code is
available at https://github.com/haowang-cqu/TransTroj .
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15884" title="Abstract">arXiv:2401.15884</a> [<a href="/pdf/2401.15884" title="Download PDF">pdf</a>, <a href="/format/2401.15884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corrective Retrieval Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shi-Qi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jia-Chen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zhen-Hua Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) inevitably exhibit hallucinations since the
accuracy of generated texts cannot be secured solely by the parametric
knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a
practicable complement to LLMs, it relies heavily on the relevance of retrieved
documents, raising concerns about how the model behaves if retrieval goes
wrong. To this end, we propose the Corrective Retrieval Augmented Generation
(CRAG) to improve the robustness of generation. Specifically, a lightweight
retrieval evaluator is designed to assess the overall quality of retrieved
documents for a query, returning a confidence degree based on which different
knowledge retrieval actions can be triggered. Since retrieval from static and
limited corpora can only return sub-optimal documents, large-scale web searches
are utilized as an extension for augmenting the retrieval results. Besides, a
decompose-then-recompose algorithm is designed for retrieved documents to
selectively focus on key information and filter out irrelevant information in
them. CRAG is plug-and-play and can be seamlessly coupled with various
RAG-based approaches. Experiments on four datasets covering short- and
long-form generation tasks show that CRAG can significantly improve the
performance of RAG-based approaches.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15885" title="Abstract">arXiv:2401.15885</a> [<a href="/pdf/2401.15885" title="Download PDF">pdf</a>, <a href="/format/2401.15885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rectify the Regression Bias in Long-Tailed Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Ke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+M">Minghao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jie Shao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianxin Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Long-tailed object detection faces great challenges because of its extremely
imbalanced class distribution. Recent methods mainly focus on the
classification bias and its loss function design, while ignoring the subtle
influence of the regression branch. This paper shows that the regression bias
exists and does adversely and seriously impact the detection accuracy. While
existing methods fail to handle the regression bias, the class-specific
regression head for rare classes is hypothesized to be the main cause of it in
this paper. As a result, three kinds of viable solutions to cater for the rare
categories are proposed, including adding a class-agnostic branch, clustering
heads and merging heads. The proposed methods brings in consistent and
significant improvements over existing long-tailed detection methods,
especially in rare and common classes. The proposed method achieves
state-of-the-art performance in the large vocabulary LVIS dataset with
different backbones and architectures. It generalizes well to more difficult
evaluation metrics, relatively balanced datasets, and the mask branch. This is
the first attempt to reveal and explore rectifying of the regression bias in
long-tailed object detection.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15886" title="Abstract">arXiv:2401.15886</a> [<a href="/pdf/2401.15886" title="Download PDF">pdf</a>, <a href="/format/2401.15886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grey Level Texture Features for Segmentation of Chromogenic Dye RNAscope  From Breast Cancer Tissue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davidson%2C+A">Andrew Davidson</a> (1), 
<a href="/search/cs?searchtype=author&query=Morley-Bunker%2C+A">Arthur Morley-Bunker</a> (2), 
<a href="/search/cs?searchtype=author&query=Wiggins%2C+G">George Wiggins</a> (2), 
<a href="/search/cs?searchtype=author&query=Walker%2C+L">Logan Walker</a> (2), 
<a href="/search/cs?searchtype=author&query=Harris%2C+G">Gavin Harris</a> (3), 
<a href="/search/cs?searchtype=author&query=Mukundan%2C+R">Ramakrishnan Mukundan</a> (1), 
<a href="/search/cs?searchtype=author&query=Investigators%2C+k">kConFab Investigators</a> (4 and 5) ((1) University of Canterbury, (2) University of Otago, (3) Canterbury Health Laboratories, (4) The University of Melbourne, (5) Peter MacCallum Cancer Center)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the proceedings of MICAD2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Chromogenic RNAscope dye and haematoxylin staining of cancer tissue
facilitates diagnosis of the cancer type and subsequent treatment, and fits
well into existing pathology workflows. However, manual quantification of the
RNAscope transcripts (dots), which signify gene expression, is prohibitively
time consuming. In addition, there is a lack of verified supporting methods for
quantification and analysis. This paper investigates the usefulness of gray
level texture features for automatically segmenting and classifying the
positions of RNAscope transcripts from breast cancer tissue. Feature analysis
showed that a small set of gray level features, including Gray Level Dependence
Matrix and Neighbouring Gray Tone Difference Matrix features, were well suited
for the task. The automated method performed similarly to expert annotators at
identifying the positions of RNAscope transcripts, with an F1-score of 0.571
compared to the expert inter-rater F1-score of 0.596. These results demonstrate
the potential of gray level texture features for automated quantification of
RNAscope in the pathology workflow.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15893" title="Abstract">arXiv:2401.15893</a> [<a href="/pdf/2401.15893" title="Download PDF">pdf</a>, <a href="/format/2401.15893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arbitrary-Scale Downscaling of Tidal Current Data Using Implicit  Continuous Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongheon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+S">Seungmyong Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y">Youngmin Ro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Numerical models have long been used to understand geoscientific phenomena,
including tidal currents, crucial for renewable energy production and coastal
engineering. However, their computational cost hinders generating data of
varying resolutions. As an alternative, deep learning-based downscaling methods
have gained traction due to their faster inference speeds. But most of them are
limited to only inference fixed scale and overlook important characteristics of
target geoscientific data. In this paper, we propose a novel downscaling
framework for tidal current data, addressing its unique characteristics, which
are dissimilar to images: heterogeneity and local dependency. Moreover, our
framework can generate any arbitrary-scale output utilizing a continuous
representation model. Our proposed framework demonstrates significantly
improved flow velocity predictions by 93.21% (MSE) and 63.85% (MAE) compared to
the Baseline model while achieving a remarkable 33.2% reduction in FLOPs.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15894" title="Abstract">arXiv:2401.15894</a> [<a href="/pdf/2401.15894" title="Download PDF">pdf</a>, <a href="/format/2401.15894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Gated MLP Architecture for Learning Topological Dependencies in  Spatio-Temporal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y+Y">Yun Young Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S+W">Sun Woo Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seunghwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+J">Joohwan Ko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) and Transformer have been increasingly adopted
to learn the complex vector representations of spatio-temporal graphs,
capturing intricate spatio-temporal dependencies crucial for applications such
as traffic datasets. Although many existing methods utilize multi-head
attention mechanisms and message-passing neural networks (MPNNs) to capture
both spatial and temporal relations, these approaches encode temporal and
spatial relations independently, and reflect the graph's topological
characteristics in a limited manner. In this work, we introduce the Cycle to
Mixer (Cy2Mixer), a novel spatio-temporal GNN based on topological non-trivial
invariants of spatio-temporal graphs with gated multi-layer perceptrons (gMLP).
The Cy2Mixer is composed of three blocks based on MLPs: A message-passing block
for encapsulating spatial information, a cycle message-passing block for
enriching topological information through cyclic subgraphs, and a temporal
block for capturing temporal properties. We bolster the effectiveness of
Cy2Mixer with mathematical evidence emphasizing that our cycle message-passing
block is capable of offering differentiated information to the deep learning
model compared to the message-passing block. Furthermore, empirical evaluations
substantiate the efficacy of the Cy2Mixer, demonstrating state-of-the-art
performances across various traffic benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15896" title="Abstract">arXiv:2401.15896</a> [<a href="/pdf/2401.15896" title="Download PDF">pdf</a>, <a href="/format/2401.15896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\boldsymbol{M^2}$-Encoder: Advancing Bilingual Image-Text Understanding  by Large-scale Efficient Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qingpei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Furong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Wang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+L">Lin Ju</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision-language foundation models like CLIP have revolutionized the field of
artificial intelligence. Nevertheless, VLM models supporting multi-language,
e.g., in both Chinese and English, have lagged due to the relative scarcity of
large-scale pretraining datasets. Toward this end, we introduce a comprehensive
bilingual (Chinese-English) dataset BM-6B with over 6 billion image-text pairs,
aimed at enhancing multimodal foundation models to well understand images in
both languages. To handle such a scale of dataset, we propose a novel grouped
aggregation approach for image-text contrastive loss computation, which reduces
the communication overhead and GPU memory demands significantly, facilitating a
60% increase in training speed. We pretrain a series of bilingual image-text
foundation models with an enhanced fine-grained understanding ability on BM-6B,
the resulting models, dubbed as $M^2$-Encoders (pronounced "M-Square"), set new
benchmarks in both languages for multimodal retrieval and classification tasks.
Notably, Our largest $M^2$-Encoder-10B model has achieved top-1 accuracies of
88.5% on ImageNet and 80.7% on ImageNet-CN under a zero-shot classification
setting, surpassing previously reported SoTA methods by 2.2% and 21.1%,
respectively. The $M^2$-Encoder series represents one of the most comprehensive
bilingual image-text foundation models to date, so we are making it available
to the research community for further exploration and development.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15897" title="Abstract">arXiv:2401.15897</a> [<a href="/pdf/2401.15897" title="Download PDF">pdf</a>, <a href="/ps/2401.15897" title="Download PostScript">ps</a>, <a href="/format/2401.15897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Red-Teaming for Generative AI: Silver Bullet or Security Theater?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feffer%2C+M">Michael Feffer</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Anusha Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+Z+C">Zachary C. Lipton</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+H">Hoda Heidari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">In response to rising concerns surrounding the safety, security, and
trustworthiness of Generative AI (GenAI) models, practitioners and regulators
alike have pointed to AI red-teaming as a key component of their strategies for
identifying and mitigating these risks. However, despite AI red-teaming's
central role in policy discussions and corporate messaging, significant
questions remain about what precisely it means, what role it can play in
regulation, and how precisely it relates to conventional red-teaming practices
as originally conceived in the field of cybersecurity. In this work, we
identify recent cases of red-teaming activities in the AI industry and conduct
an extensive survey of the relevant research literature to characterize the
scope, structure, and criteria for AI red-teaming practices. Our analysis
reveals that prior methods and practices of AI red-teaming diverge along
several axes, including the purpose of the activity (which is often vague), the
artifact under evaluation, the setting in which the activity is conducted
(e.g., actors, resources, and methods), and the resulting decisions it informs
(e.g., reporting, disclosure, and mitigation). In light of our findings, we
argue that while red-teaming may be a valuable big-tent idea for characterizing
a broad set of activities and attitudes aimed at improving the behavior of
GenAI models, gestures towards red-teaming as a panacea for every possible risk
verge on security theater. To move toward a more robust toolbox of evaluations
for generative AI, we synthesize our recommendations into a question bank meant
to guide and scaffold future AI red-teaming practices.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15900" title="Abstract">arXiv:2401.15900</a> [<a href="/pdf/2401.15900" title="Download PDF">pdf</a>, <a href="/format/2401.15900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MV2MAE: Multi-View Video Masked Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+K">Ketul Shah</a>, 
<a href="/search/cs?searchtype=author&query=Crandall%2C+R">Robert Crandall</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=George%2C+M">Marian George</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mayank Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Videos captured from multiple viewpoints can help in perceiving the 3D
structure of the world and benefit computer vision tasks such as action
recognition, tracking, etc. In this paper, we present a method for
self-supervised learning from synchronized multi-view videos. We use a
cross-view reconstruction task to inject geometry information in the model. Our
approach is based on the masked autoencoder (MAE) framework. In addition to the
same-view decoder, we introduce a separate cross-view decoder which leverages
cross-attention mechanism to reconstruct a target viewpoint video using a video
from source viewpoint, to help representations robust to viewpoint changes. For
videos, static regions can be reconstructed trivially which hinders learning
meaningful representations. To tackle this, we introduce a motion-weighted
reconstruction loss which improves temporal modeling. We report
state-of-the-art results on the NTU-60, NTU-120 and ETRI datasets, as well as
in the transfer learning setting on NUCLA, PKU-MMD-II and ROCOG-v2 datasets,
demonstrating the robustness of our approach. Code will be made available.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15902" title="Abstract">arXiv:2401.15902</a> [<a href="/pdf/2401.15902" title="Download PDF">pdf</a>, <a href="/format/2401.15902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Concise but Effective Network for Image Guided Depth Completion in  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Moyun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Youping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jingming Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depth completion is a crucial task in autonomous driving, aiming to convert a
sparse depth map into a dense depth prediction. Due to its potentially rich
semantic information, RGB image is commonly fused to enhance the completion
effect. Image-guided depth completion involves three key challenges: 1) how to
effectively fuse the two modalities; 2) how to better recover depth
information; and 3) how to achieve real-time prediction for practical
autonomous driving. To solve the above problems, we propose a concise but
effective network, named CENet, to achieve high-performance depth completion
with a simple and elegant structure. Firstly, we use a fast guidance module to
fuse the two sensor features, utilizing abundant auxiliary features extracted
from the color space. Unlike other commonly used complicated guidance modules,
our approach is intuitive and low-cost. In addition, we find and analyze the
optimization inconsistency problem for observed and unobserved positions, and a
decoupled depth prediction head is proposed to alleviate the issue. The
proposed decoupled head can better output the depth of valid and invalid
positions with very few extra inference time. Based on the simple structure of
dual-encoder and single-decoder, our CENet can achieve superior balance between
accuracy and efficiency. In the KITTI depth completion benchmark, our CENet
attains competitive performance and inference speed compared with the
state-of-the-art methods. To validate the generalization of our method, we also
evaluate on indoor NYUv2 dataset, and our CENet still achieve impressive
results. The code of this work will be available at
https://github.com/lmomoy/CENet.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15903" title="Abstract">arXiv:2401.15903</a> [<a href="/pdf/2401.15903" title="Download PDF">pdf</a>, <a href="/format/2401.15903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward the Identifiability of Comparative Deep Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopez%2C+R">Romain Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Huetter%2C+J">Jan-Christian Huetter</a>, 
<a href="/search/cs?searchtype=author&query=Hajiramezanali%2C+E">Ehsan Hajiramezanali</a>, 
<a href="/search/cs?searchtype=author&query=Pritchard%2C+J">Jonathan Pritchard</a>, 
<a href="/search/cs?searchtype=author&query=Regev%2C+A">Aviv Regev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Causal Learning and Reasoning 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN); Methodology (stat.ME)

</div>
<p class="mathjax">Deep Generative Models (DGMs) are versatile tools for learning data
representations while adequately incorporating domain knowledge such as the
specification of conditional probability distributions. Recently proposed DGMs
tackle the important task of comparing data sets from different sources. One
such example is the setting of contrastive analysis that focuses on describing
patterns that are enriched in a target data set compared to a background data
set. The practical deployment of those models often assumes that DGMs naturally
infer interpretable and modular latent representations, which is known to be an
issue in practice. Consequently, existing methods often rely on ad-hoc
regularization schemes, although without any theoretical grounding. Here, we
propose a theory of identifiability for comparative DGMs by extending recent
advances in the field of non-linear independent component analysis. We show
that, while these models lack identifiability across a general class of mixing
functions, they surprisingly become identifiable when the mixing function is
piece-wise affine (e.g., parameterized by a ReLU neural network). We also
investigate the impact of model misspecification, and empirically show that
previously proposed regularization techniques for fitting comparative DGMs help
with identifiability when the number of latent variables is not known in
advance. Finally, we introduce a novel methodology for fitting comparative DGMs
that improves the treatment of multiple data sources via multi-objective
optimization and that helps adjust the hyperparameter for the regularization in
an interpretable manner, using constrained optimization. We empirically
validate our theory and new methodology using simulated data as well as a
recent data set of genetic perturbations in cells profiled via single-cell RNA
sequencing.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15906" title="Abstract">arXiv:2401.15906</a> [<a href="/pdf/2401.15906" title="Download PDF">pdf</a>, <a href="/format/2401.15906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mean Estimation with User-Level Privacy for Spatio-Temporal IoT Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rameshwar%2C+V+A">V. Arvind Rameshwar</a>, 
<a href="/search/cs?searchtype=author&query=Tandon%2C+A">Anshoo Tandon</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Prajjwal Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+N">Novoneel Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Abhay Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT); Applications (stat.AP)

</div>
<p class="mathjax">This paper considers the problem of the private release of sample means of
speed values from traffic datasets. Our key contribution is the development of
user-level differentially private algorithms that incorporate carefully chosen
parameter values to ensure low estimation errors on real-world datasets, while
ensuring privacy. We test our algorithms on ITMS (Intelligent Traffic
Management System) data from an Indian city, where the speeds of different
buses are drawn in a potentially non-i.i.d. manner from an unknown
distribution, and where the number of speed samples contributed by different
buses is potentially different. We then apply our algorithms to a synthetic
dataset, generated based on the ITMS data, having either a large number of
users or a large number of samples per user. Here, we provide recommendations
for the choices of parameters and algorithm subroutines that result in low
estimation errors, while guaranteeing user-level privacy.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15910" title="Abstract">arXiv:2401.15910</a> [<a href="/pdf/2401.15910" title="Download PDF">pdf</a>, <a href="/ps/2401.15910" title="Download PostScript">ps</a>, <a href="/format/2401.15910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correction to &quot;Private Information Retrieval Over Gaussian MAC&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elimelech%2C+O">Or Elimelech</a>, 
<a href="/search/cs?searchtype=author&query=Shmuel%2C+O">Ori Shmuel</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Asaf Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In the above article \cite{shmuel2021private}, the authors introduced a PIR
scheme for the Additive White Gaussian Noise (AWGN) Multiple Access Channel
(MAC), both with and without fading. The authors utilized the additive nature
of the channel and leveraged the linear properties and structure of lattice
codes to retrieve the desired message without the servers acquiring any
knowledge on the retrieved message's index.
<br />Theorems 3 and 4 in \cite{shmuel2021private} contain an error arising from
the incorrect usage of the modulo operator. Moreover, the proofs assume a
one-to-one mapping function, $\phi(\cdot)$, between a message
$W_j\in\mathbb{F}_p^L$ and the elements of $\cC$, mistakenly suggesting that
the user possesses all the required information in advance. However, this is
not the case. Herein, we present the corrected versions of these theorems.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15911" title="Abstract">arXiv:2401.15911</a> [<a href="/pdf/2401.15911" title="Download PDF">pdf</a>, <a href="/ps/2401.15911" title="Download PostScript">ps</a>, <a href="/format/2401.15911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-consistency Structural Causal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+H">Heyang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chaochao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">In the field of causal modeling, potential outcomes (PO) and structural
causal models (SCMs) stand as the predominant frameworks. However, these
frameworks face notable challenges in practically modeling counterfactuals,
formalized as parameters of the joint distribution of potential outcomes.
Counterfactual reasoning holds paramount importance in contemporary
decision-making processes, especially in scenarios that demand personalized
incentives based on the joint values of $(Y(0), Y(1))$. This paper begins with
an investigation of the PO and SCM frameworks for modeling counterfactuals.
Through the analysis, we identify an inherent model capacity limitation, termed
as the ``degenerative counterfactual problem'', emerging from the consistency
rule that is the cornerstone of both frameworks. To address this limitation, we
introduce a novel \textit{distribution-consistency} assumption, and in
alignment with it, we propose the Distribution-consistency Structural Causal
Models (DiscoSCMs) offering enhanced capabilities to model counterfactuals. To
concretely reveal the enhanced model capacity, we introduce a new identifiable
causal parameter, \textit{the probability of consistency}, which holds
practical significance within DiscoSCM alone, showcased with a personalized
incentive example. Furthermore, we provide a comprehensive set of theoretical
results about the ``Ladder of Causation'' within the DiscoSCM framework. We
hope it opens new avenues for future research of counterfactual modeling,
ultimately enhancing our understanding of causality and its real-world
applications.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15912" title="Abstract">arXiv:2401.15912</a> [<a href="/pdf/2401.15912" title="Download PDF">pdf</a>, <a href="/format/2401.15912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient, High-Rate Scheme for Private Information Retrieval over  the Gaussian MAC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elimelech%2C+O">Or Elimelech</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Asaf Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper addresses the challenge of the private information retrieval (PIR)
problem wherein there are $N$ replicated non-communicating databases containing
the same $M$ messages and a user who wants to retrieve one of the messages
without revealing the wanted message's index to the databases. In addition, we
assume a block-fading additive white Gaussian noise multiple access channel
(AWGN MAC) linking the user and the databases. Shmuel's contribution
\cite{shmuel2021private}, presenting a joint channel-PIR scheme utilizing the
C\&amp;F protocol, has shown the potential of a joint channel-PIR scheme over a
separated scheme. In this paper, we propose an improved joint channel-PIR
approach tailored for the PIR problem with $N$ databases over a block-fading
AWGN. Unlike the C\&amp;F protocol, our scheme offers reduced computational
complexity while improving the scaling laws governing the achievable rate. Our
achievable rate scales with the number of databases $N$ and the power $P$
similarly to the channel capacity without the privacy constraint and
outperforms the C\&amp;F-based approach. Furthermore, our analysis demonstrates
that our improved rate exhibits only a finite gap from the channel capacity of
one bit as $N$ increases.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15914" title="Abstract">arXiv:2401.15914</a> [<a href="/pdf/2401.15914" title="Download PDF">pdf</a>, <a href="/format/2401.15914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Yuhang Zang</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+H">Hanlin Goh</a>, 
<a href="/search/cs?searchtype=author&query=Susskind%2C+J">Josh Susskind</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chen Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing vision-language models exhibit strong generalization on a variety of
visual domains and tasks. However, such models mainly perform zero-shot
recognition in a closed-set manner, and thus struggle to handle open-domain
visual concepts by design. There are recent finetuning methods, such as prompt
learning, that not only study the discrimination between in-distribution (ID)
and out-of-distribution (OOD) samples, but also show some improvements in both
ID and OOD accuracies. In this paper, we first demonstrate that vision-language
models, after long enough finetuning but without proper regularization, tend to
overfit the known classes in the given dataset, with degraded performance on
unknown classes. Then we propose a novel approach OGEN to address this pitfall,
with the main focus on improving the OOD GENeralization of finetuned models.
Specifically, a class-conditional feature generator is introduced to synthesize
OOD features using just the class name of any unknown class. Such synthesized
features will provide useful knowledge about unknowns and help regularize the
decision boundary between ID and OOD data when optimized jointly. Equally
important is our adaptive self-distillation mechanism to regularize our feature
generation model during joint optimization, i.e., adaptively transferring
knowledge between model states to further prevent overfitting. Experiments
validate that our method yields convincing gains in OOD generalization
performance in different settings.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15915" title="Abstract">arXiv:2401.15915</a> [<a href="/pdf/2401.15915" title="Download PDF">pdf</a>, <a href="/ps/2401.15915" title="Download PostScript">ps</a>, <a href="/format/2401.15915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unrestricted Error-Type Codebook Generation for Error Correction Code in  DNA Storage Inspired by NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+G">Guangxiang Si</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, this paper is submitted to the 2024 IEEE International Symposium on Information Theory (ISIT 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Recently, DNA storage has surfaced as a promising alternative for data
storage, presenting notable benefits in terms of storage capacity,
cost-effectiveness in maintenance, and the capability for parallel replication.
Mathematically, the DNA storage process can be conceptualized as an insertion,
deletion, and substitution (IDS) channel. Due to the mathematical complexity
associated with the Levenshtein distance, creating a code that corrects for IDS
remains a challenging task. In this paper, we propose a bottom-up generation
approach to grow the required codebook based on the computation of Edit
Computational Graph (ECG) which differs from the algebraic constructions by
incorporating the Derivative-Free Optimization (DFO) method. Specifically, this
approach is regardless of the type of errors. Compared the results with the
work for 1-substitution-1-deletion and 2-deletion, the redundancy is reduced by
about 30-bit and 60-bit, respectively. As far as we know, our method is the
first IDS-correcting code designed using classical Natural Language Process
(NLP) techniques, marking a turning point in the field of error correction code
research. Based on the codebook generated by our method, there may be
significant breakthroughs in the complexity of encoding and decoding
algorithms.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15917" title="Abstract">arXiv:2401.15917</a> [<a href="/pdf/2401.15917" title="Download PDF">pdf</a>, <a href="/format/2401.15917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-enabled Trustworthy Federated Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yijing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhipeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jinke Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhiqiang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Federated unlearning is a promising paradigm for protecting the data
ownership of distributed clients. It allows central servers to remove
historical data effects within the machine learning model as well as address
the "right to be forgotten" issue in federated learning. However, existing
works require central servers to retain the historical model parameters from
distributed clients, such that allows the central server to utilize these
parameters for further training even, after the clients exit the training
process. To address this issue, this paper proposes a new blockchain-enabled
trustworthy federated unlearning framework. We first design a proof of
federated unlearning protocol, which utilizes the Chameleon hash function to
verify data removal and eliminate the data contributions stored in other
clients' models. Then, an adaptive contribution-based retraining mechanism is
developed to reduce the computational overhead and significantly improve the
training efficiency. Extensive experiments demonstrate that the proposed
framework can achieve a better data removal effect than the state-of-the-art
frameworks, marking a significant stride towards trustworthy federated
unlearning.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15921" title="Abstract">arXiv:2401.15921</a> [<a href="/pdf/2401.15921" title="Download PDF">pdf</a>, <a href="/format/2401.15921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Framework to Predict and Visualize Technology Acceptance: A Case  Study of Shared Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lirui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Burke%2C+M+G">Michael G. Burke</a>, 
<a href="/search/cs?searchtype=author&query=Griggs%2C+W+M">Wynita M. Griggs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The burgeoning field of Shared Autonomous Vehicles (SAVs) presents
transformative potential for the transport sector, subject to public
acceptance. Traditional acceptance models, primarily reliant on Structural
Equation Modelling (SEM), often fall short of capturing the complex, non-linear
dynamics underlying this acceptance. To address these limitations, this paper
proposes a Machine Learning (ML) approach to predict public acceptance of SAVs
and employs a chord diagram to visualize the influence of different predictors.
This approach reveals nuanced, non-linear relationships between factors at both
macro and micro levels, and identifies attitude as the primary predictor of SAV
usage intention, followed by perceived risk, perceived usefulness, trust, and
perceived ease of use. The framework also uncovers divergent perceptions of
these factors among SAV adopters and non-adopters, providing granular insights
for strategic initiatives to enhance SAV acceptance. Using SAV acceptance as a
case study, our findings contribute a novel, machine learning-based perspective
to the discourse on technology acceptance, underscoring the importance of
nuanced, data-driven approaches in understanding and fostering public
acceptance of emerging transport technologies.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15924" title="Abstract">arXiv:2401.15924</a> [<a href="/pdf/2401.15924" title="Download PDF">pdf</a>, <a href="/format/2401.15924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Aware Service Offloading for Semantic Communications in Wireless  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saadat%2C+H">Hassan Saadat</a>, 
<a href="/search/cs?searchtype=author&query=Albaseer%2C+A">Abdullatif Albaseer</a>, 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+M">Mohamed Abdallah</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+A">Amr Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Erbad%2C+A">Aiman Erbad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for IEEE ICC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Today, wireless networks are becoming responsible for serving intelligent
applications, such as extended reality and metaverse, holographic telepresence,
autonomous transportation, and collaborative robots. Although current
fifth-generation (5G) networks can provide high data rates in terms of
Gigabytes/second, they cannot cope with the high demands of the aforementioned
applications, especially in terms of the size of the high-quality live videos
and images that need to be communicated in real-time. Therefore, with the help
of artificial intelligence (AI)-based future sixth-generation (6G) networks,
the semantic communication concept can provide the services demanded by these
applications. Unlike Shannon's classical information theory, semantic
communication urges the use of the semantics (meaningful contents) of the data
in designing more efficient data communication schemes. Hence, in this paper,
we model semantic communication as an energy minimization framework in
heterogeneous wireless networks with respect to delay and quality-of-service
constraints. Then, we propose a sub-optimal solution to the NP-hard
combinatorial mixed-integer nonlinear programming problem (MINLP) by utilizing
efficient techniques such as discrete optimization variables' relaxation. In
addition, AI-based autoencoder and classifier are trained and deployed to
perform semantic extraction, reconstruction, and classification services.
Finally, we compare our proposed sub-optimal solution with different
state-of-the-art methods, and the obtained results demonstrate its superiority.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15927" title="Abstract">arXiv:2401.15927</a> [<a href="/pdf/2401.15927" title="Download PDF">pdf</a>, <a href="/format/2401.15927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jinchang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ao%2C+C">Chang Ao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haihong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangtao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhigang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Daijia Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengming Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiping Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruifeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+S">Shiwen Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the accelerating development of Large Language Models (LLMs), many LLMs
are beginning to be used in the Chinese K-12 education domain. The integration
of LLMs and education is getting closer and closer, however, there is currently
no benchmark for evaluating LLMs that focuses on the Chinese K-12 education
domain. Therefore, there is an urgent need for a comprehensive natural language
processing benchmark to accurately assess the capabilities of various LLMs in
the Chinese K-12 education domain. To address this, we introduce the E-EVAL,
the first comprehensive evaluation benchmark specifically designed for the
Chinese K-12 education field. The E-EVAL consists of 4,351 multiple-choice
questions at the primary, middle, and high school levels across a wide range of
subjects, including Chinese, English, Politics, History, Ethics, Physics,
Chemistry, Mathematics, and Geography. We conducted a comprehensive evaluation
of E-EVAL on advanced LLMs, including both English-dominant and
Chinese-dominant models. Findings show that Chinese-dominant models perform
well compared to English-dominant models, with many scoring even above the GPT
4.0. However, almost all models perform poorly in complex subjects such as
mathematics. We also found that most Chinese-dominant LLMs did not achieve
higher scores at the primary school level compared to the middle school level.
We observe that the mastery of higher-order knowledge by the model does not
necessarily imply the mastery of lower-order knowledge as well. Additionally,
the experimental results indicate that the Chain of Thought (CoT) technique is
effective only for the challenging science subjects, while Few-shot prompting
is more beneficial for liberal arts subjects. With E-EVAL, we aim to analyze
the strengths and limitations of LLMs in educational applications, and to
contribute to the progress and development of Chinese K-12 education and LLMs.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15931" title="Abstract">arXiv:2401.15931</a> [<a href="/pdf/2401.15931" title="Download PDF">pdf</a>, <a href="/format/2401.15931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmoDM: A Diffusion Model for Evolutionary Multi-objective Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xueming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Evolutionary algorithms have been successful in solving multi-objective
optimization problems (MOPs). However, as a class of population-based search
methodology, evolutionary algorithms require a large number of evaluations of
the objective functions, preventing them from being applied to a wide range of
expensive MOPs. To tackle the above challenge, this work proposes for the first
time a diffusion model that can learn to perform evolutionary multi-objective
search, called EmoDM. This is achieved by treating the reversed convergence
process of evolutionary search as the forward diffusion and learn the noise
distributions from previously solved evolutionary optimization tasks. The
pre-trained EmoDM can then generate a set of non-dominated solutions for a new
MOP by means of its reverse diffusion without further evolutionary search,
thereby significantly reducing the required function evaluations. To enhance
the scalability of EmoDM, a mutual entropy-based attention mechanism is
introduced to capture the decision variables that are most important for the
objectives. Experimental results demonstrate the competitiveness of EmoDM in
terms of both the search performance and computational efficiency compared with
state-of-the-art evolutionary algorithms in solving MOPs having up to 5000
decision variables. The pre-trained EmoDM is shown to generalize well to unseen
problems, revealing its strong potential as a general and efficient MOP solver.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15934" title="Abstract">arXiv:2401.15934</a> [<a href="/pdf/2401.15934" title="Download PDF">pdf</a>, <a href="/format/2401.15934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HICH Image/Text (HICH-IT): Comprehensive Text and Image Datasets for  Hypertensive Intracerebral Hemorrhage Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yulong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+F">Fenglin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Miao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Li Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce a new multimodal dataset in the medical field of
hypertensive intracerebral hemorrhage(HICH), called as HICH-IT, which includes
both textual information and head CT images. This dataset is designed to
enhance the accuracy of artificial intelligence in the diagnosis and treatment
of HICH. This dataset, built upon the foundation of standard text and image
data, incorporates specific annotations within the text data, extracting key
content from the text information, and categorizes the annotation content of
imaging data into four types: brain midline, hematoma, left cerebral ventricle,
and right cerebral ventricle. HICH-IT aims to be a foundational dataset for
feature learning in image segmentation tasks and named entity recognition. To
further understand the dataset, we have trained deep learning algorithms to
observe the performance. The pretrained models have been released at both
www.daip.club and github.com/Deep-AI-Application-DAIP. The dataset has been
uploaded to https://github.com/CYBUS123456/HICH-IT-Datasets.
<br />Index Terms-HICH, Deep learning, Intraparenchymal hemorrhage, named entity
recognition, novel dataset
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15935" title="Abstract">arXiv:2401.15935</a> [<a href="/pdf/2401.15935" title="Download PDF">pdf</a>, <a href="/format/2401.15935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning in Event Sequences: A Comparative Study and  Hybrid Approach of Generative Modeling and Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moskvoretskii%2C+V">Viktor Moskvoretskii</a>, 
<a href="/search/cs?searchtype=author&query=Osin%2C+D">Dmitry Osin</a>, 
<a href="/search/cs?searchtype=author&query=Shvetsov%2C+E">Egor Shvetsov</a>, 
<a href="/search/cs?searchtype=author&query=Udovichenko%2C+I">Igor Udovichenko</a>, 
<a href="/search/cs?searchtype=author&query=Zhelnin%2C+M">Maxim Zhelnin</a>, 
<a href="/search/cs?searchtype=author&query=Dukhovny%2C+A">Andrey Dukhovny</a>, 
<a href="/search/cs?searchtype=author&query=Zhimerikina%2C+A">Anna Zhimerikina</a>, 
<a href="/search/cs?searchtype=author&query=Efimov%2C+A">Albert Efimov</a>, 
<a href="/search/cs?searchtype=author&query=Burnaev%2C+E">Evgeny Burnaev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study investigates self-supervised learning techniques to obtain
representations of Event Sequences. It is a key modality in various
applications, including but not limited to banking, e-commerce, and healthcare.
<br />We perform a comprehensive study of generative and contrastive approaches in
self-supervised learning, applying them both independently. We find that there
is no single supreme method. Consequently, we explore the potential benefits of
combining these approaches. To achieve this goal, we introduce a novel method
that aligns generative and contrastive embeddings as distinct modalities,
drawing inspiration from contemporary multimodal research.
<br />Generative and contrastive approaches are often treated as mutually
exclusive, leaving a gap for their combined exploration. Our results
demonstrate that this aligned model performs at least on par with, and mostly
surpasses, existing methods and is more universal across a variety of tasks.
Furthermore, we demonstrate that self-supervised methods consistently
outperform the supervised approach on our datasets.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15938" title="Abstract">arXiv:2401.15938</a> [<a href="/pdf/2401.15938" title="Download PDF">pdf</a>, <a href="/format/2401.15938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-induced error reduction for high-speed dynamic digital fringe  projection system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+S">Sanghoon Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyo-Geon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jae-Sung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bo-Min Kang</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+B">Byung-Wook Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J+Y">Jun Young Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Hyun%2C+J">Jae-Sang Hyun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In phase-shifting profilometry (PSP), any motion during the acquisition of
fringe patterns can introduce errors because it assumes both the object and
measurement system are stationary. Therefore, we propose a method to pixel-wise
reduce the errors when the measurement system is in motion due to a motorized
linear stage. The proposed method introduces motion-induced error reduction
algorithm, which leverages the motor's encoder and pinhole model of the camera
and projector. 3D shape measurement is possible with only three fringe patterns
by applying geometric constraints of the digital fringe projection system. We
address the mismatch problem due to the motion-induced camera pixel disparities
and reduce phase-shift errors. These processes are easy to implement and
require low computational cost. Experimental results demonstrate that the
presented method effectively reduces the errors even in non-uniform motion.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15939" title="Abstract">arXiv:2401.15939</a> [<a href="/pdf/2401.15939" title="Download PDF">pdf</a>, <a href="/format/2401.15939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correcting a Single Deletion in Reads from a Nanopore Sequencer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Anisha Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Yehezkeally%2C+Y">Yonatan Yehezkeally</a>, 
<a href="/search/cs?searchtype=author&query=Wachter-Zeh%2C+A">Antonia Wachter-Zeh</a>, 
<a href="/search/cs?searchtype=author&query=Yaakobi%2C+E">Eitan Yaakobi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ISIT 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Owing to its several merits over other DNA sequencing technologies, nanopore
sequencers hold an immense potential to revolutionize the efficiency of DNA
storage systems. However, their higher error rates necessitate further research
to devise practical and efficient coding schemes that would allow accurate
retrieval of the data stored. Our work takes a step in this direction by
adopting a simplified model of the nanopore sequencer inspired by Mao \emph{et
al.}, which incorporates some of its physical aspects. This channel model can
be viewed as a sliding window of length $\ell$ that passes over the incoming
input sequence and produces the $L_1$-weight of the enclosed $\ell$ bits, while
shifting by one position at each time step. The resulting $(\ell+1)$-ary
vector, referred to as the $\ell$-\emph{read vector}, is susceptible to
deletion errors due to imperfections inherent in the sequencing process. We
establish that at least $\log n - \ell$ bits of redundancy are needed to
correct a single deletion. An error-correcting code that is optimal up to an
additive constant, is also proposed. Furthermore, we find that for $\ell \geq
2$, reconstruction from two distinct noisy $\ell$-read vectors can be
accomplished without any redundancy, and provide a suitable reconstruction
algorithm to this effect.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15940" title="Abstract">arXiv:2401.15940</a> [<a href="/pdf/2401.15940" title="Download PDF">pdf</a>, <a href="/format/2401.15940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Aware Code Generation with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhihong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chen Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) perform well on basic programming problems.
However, they encounter challenges when dealing with complex tasks involving
the use of diverse algorithmic and data structure skills, particularly
programming competition-level problems. Notably, ChatGPT exhibits proficient
performance on problems it has encountered during its pre-training phase, but
this performance deteriorates when faced with novel problems. Consequently,
enhancing the ability of LLMs to address unfamiliar problems has emerged as a
pivotal research focus. The problem-solving process of LLMs mirrors human
programmers' approach to a certain extent. When confronted with new programming
tasks, human programmers engage in task planning and code writing with the
previously acquired knowledge about algorithms and data structures. Despite
having learned such knowledge, LLMs struggle to effectively apply it when faced
with specific new problems. To address this issue, we constructed a novel
dataset, CodeF, which contains a portion of programming problems that ChatGPT
has not previously encountered. Furthermore, we developed a Knowledge Library
tailored for Python programming contest problems and introduced the concept of
Knowledge-Aware Code Generation (KareCoder). KareCoder bolsters the models'
understanding and problem-solving capabilities by integrating prompt and
knowledge from the library into the LLMs' code generation reasoning process,
especially on Pass@1 metrics. Upon testing on the CodeF and APPS datasets,
KareCoder demonstrated outstanding performance in handling novel problems
previously unencountered by LLMs. In contrast with the code directly generated
by ChatGPT, KareCoder achieved a relative improvement of 23.3% on the Pass@1
metric on the CodeF post2021-9 dataset. Additionally, it performs well compared
to other methods when dealing with problems that LLMs have previously
encountered.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15941" title="Abstract">arXiv:2401.15941</a> [<a href="/pdf/2401.15941" title="Download PDF">pdf</a>, <a href="/ps/2401.15941" title="Download PostScript">ps</a>, <a href="/format/2401.15941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High order conservative LDG-IMEX methods for the degenerate nonlinear  non-equilibrium radiation diffusion problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zheng%2C+S">Shaoqin Zheng</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+M">Min Tang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/math?searchtype=author&query=Xiong%2C+T">Tao Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we develop a class of high-order conservative methods for
simulating non-equilibrium radiation diffusion problems. Numerically, this
system poses significant challenges due to strong nonlinearity within the stiff
source terms and the degeneracy of nonlinear diffusion terms. Explicit methods
require impractically small time steps, while implicit methods, which offer
stability, come with the challenge to guarantee the convergence of nonlinear
iterative solvers. To overcome these challenges, we propose a
predictor-corrector approach and design proper implicit-explicit time
discretizations. In the predictor step, the system is reformulated into a
nonconservative form and linear diffusion terms are introduced as a
penalization to mitigate strong nonlinearities. We then employ a Picard
iteration to secure convergence in handling the nonlinear aspects. The
corrector step guarantees the conservation of total energy, which is vital for
accurately simulating the speeds of propagating sharp fronts in this system.
<br />For spatial approximations, we utilize local discontinuous Galerkin finite
element methods, coupled with positive-preserving and TVB limiters. We validate
the orders of accuracy, conservation properties, and suitability of using large
time steps for our proposed methods, through numerical experiments conducted on
one- and two-dimensional spatial problems. In both homogeneous and
heterogeneous non-equilibrium radiation diffusion problems, we attain a time
stability condition comparable to that of a fully implicit time discretization.
Such an approach is also applicable to many other reaction-diffusion systems.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15942" title="Abstract">arXiv:2401.15942</a> [<a href="/pdf/2401.15942" title="Download PDF">pdf</a>, <a href="/format/2401.15942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Multi-Center Classifier via Conditional Gaussian Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhemin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xun Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The linear classifier is widely used in various image classification tasks.
It works by optimizing the distance between a sample and its corresponding
class center. However, in real-world data, one class can contain several local
clusters, e.g., birds of different poses. To address this complexity, we
propose a novel multi-center classifier. Different from the vanilla linear
classifier, our proposal is established on the assumption that the deep
features of the training set follow a Gaussian Mixture distribution.
Specifically, we create a conditional Gaussian distribution for each class and
then sample multiple sub-centers from that distribution to extend the linear
classifier. This approach allows the model to capture intra-class local
structures more efficiently. In addition, at test time we set the mean of the
conditional Gaussian distribution as the class center of the linear classifier
and follow the vanilla linear classifier outputs, thus requiring no additional
parameters or computational overhead. Extensive experiments on image
classification show that the proposed multi-center classifier is a powerful
alternative to widely used linear classifiers. Code available at
https://github.com/ZheminZhang1/MultiCenter-Classifier.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15944" title="Abstract">arXiv:2401.15944</a> [<a href="/pdf/2401.15944" title="Download PDF">pdf</a>, <a href="/format/2401.15944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Domain Gap: A Simple Domain Matching Method for  Reference-based Image Super-Resolution in Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+J">Jeongho Min</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yejun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jaejun Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE GRSL 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Volume: 21, Year: 2023, Page: 1-5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, reference-based image super-resolution (RefSR) has shown excellent
performance in image super-resolution (SR) tasks. The main idea of RefSR is to
utilize additional information from the reference (Ref) image to recover the
high-frequency components in low-resolution (LR) images. By transferring
relevant textures through feature matching, RefSR models outperform existing
single image super-resolution (SISR) models. However, their performance
significantly declines when a domain gap between Ref and LR images exists,
which often occurs in real-world scenarios, such as satellite imaging. In this
letter, we introduce a Domain Matching (DM) module that can be seamlessly
integrated with existing RefSR models to enhance their performance in a
plug-and-play manner. To the best of our knowledge, we are the first to explore
Domain Matching-based RefSR in remote sensing image processing. Our analysis
reveals that their domain gaps often occur in different satellites, and our
model effectively addresses these challenges, whereas existing models struggle.
Our experiments demonstrate that the proposed DM module improves SR performance
both qualitatively and quantitatively for remote sensing super-resolution
tasks.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15945" title="Abstract">arXiv:2401.15945</a> [<a href="/pdf/2401.15945" title="Download PDF">pdf</a>, <a href="/ps/2401.15945" title="Download PostScript">ps</a>, <a href="/format/2401.15945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularization of linear inverse problems with irregular noise using  embedding operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xinyan Li</a>, 
<a href="/search/math?searchtype=author&query=Hubmer%2C+S">Simon Hubmer</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+S">Shuai Lu</a>, 
<a href="/search/math?searchtype=author&query=Ramlau%2C+R">Ronny Ramlau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we investigate regularization of linear inverse problems with
irregular noise. In particular, we consider the case that the noise can be
preprocessed by certain adjoint embedding operators. By introducing the
consequent preprocessed problem, we provide convergence analysis for general
regularization schemes under standard assumptions. Furthermore, for a special
case of Tikhonov regularization in Computerized Tomography, we show that our
approach leads to a novel (Fourier-based) filtered backprojection algorithm.
Numerical examples with different parameter choice rules verify the efficiency
of our proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15946" title="Abstract">arXiv:2401.15946</a> [<a href="/pdf/2401.15946" title="Download PDF">pdf</a>, <a href="/format/2401.15946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approaching Maximum Likelihood Decoding Performance via Reshuffling  ORBGRAND
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+L">Li Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenyi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Guessing random additive noise decoding (GRAND) is a recently proposed
decoding paradigm particularly suitable for codes with short length and high
rate. Among its variants, ordered reliability bits GRAND (ORBGRAND) exploits
soft information in a simple and effective fashion to schedule its queries,
thereby allowing efficient hardware implementation. Compared with maximum
likelihood (ML) decoding, however, ORBGRAND still exhibits noticeable
performance gap in terms of block error rate (BLER). In order to improve the
performance of ORBGRAND while still retaining its amenability to hardware
implementation, a new variant of ORBGRAND termed RS-ORBGRAND is proposed, whose
basic idea is to reshuffle the queries of ORBGRAND so that the expected number
of queries is minimized. Numerical simulations show that RS-ORBGRAND leads to
noticeable gains compared with ORBGRAND and its existing variants, and is only
0.1dB away from ML decoding, for BLER as low as $10^{-6}$.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15947" title="Abstract">arXiv:2401.15947</a> [<a href="/pdf/2401.15947" title="Download PDF">pdf</a>, <a href="/format/2401.15947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoE-LLaVA: Mixture of Experts for Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhenyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaxi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Peng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junwu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+M">Munan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For Large Vision-Language Models (LVLMs), scaling the model can effectively
improve performance. However, expanding model parameters significantly
increases the training and inferring costs, as all model parameters are
activated for each token in the calculation. In this work, we propose a novel
training strategy MoE-tuning for LVLMs, which can constructing a sparse model
with an outrageous number of parameter but a constant computational cost, and
effectively addresses the performance degradation typically associated with
multi-modal learning and model sparsity. Furthermore, we present the MoE-LLaVA
framework, a MoE-based sparse LVLM architecture. This framework uniquely
activates only the top-k experts through routers during deployment, keeping the
remaining experts inactive. Our extensive experiments highlight the excellent
capabilities of MoE-LLaVA in visual understanding and its potential to reduce
hallucinations in model outputs. Remarkably, with just 3 billion sparsely
activated parameters, MoE-LLaVA demonstrates performance comparable to the
LLaVA-1.5-7B on various visual understanding datasets and even surpasses the
LLaVA-1.5-13B in object hallucination benchmarks. Through MoE-LLaVA, we aim to
establish a baseline for sparse LVLMs and provide valuable insights for future
research in developing more efficient and effective multi-modal learning
systems. Code is released at \url{https://github.com/PKU-YuanGroup/MoE-LLaVA}.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15948" title="Abstract">arXiv:2401.15948</a> [<a href="/pdf/2401.15948" title="Download PDF">pdf</a>, <a href="/format/2401.15948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdvNF: Reducing Mode Collapse in Conditional Normalising Flows using  Adversarial Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanaujia%2C+V">Vikas Kanaujia</a>, 
<a href="/search/cs?searchtype=author&query=Scheurer%2C+M+S">Mathias S. Scheurer</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+V">Vipul Arora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, submitted to Scipost Physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Deep generative models complement Markov-chain-Monte-Carlo methods for
efficiently sampling from high-dimensional distributions. Among these methods,
explicit generators, such as Normalising Flows (NFs), in combination with the
Metropolis Hastings algorithm have been extensively applied to get unbiased
samples from target distributions. We systematically study central problems in
conditional NFs, such as high variance, mode collapse and data efficiency. We
propose adversarial training for NFs to ameliorate these problems. Experiments
are conducted with low-dimensional synthetic datasets and XY spin models in two
spatial dimensions.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15949" title="Abstract">arXiv:2401.15949</a> [<a href="/pdf/2401.15949" title="Download PDF">pdf</a>, <a href="/ps/2401.15949" title="Download PostScript">ps</a>, <a href="/format/2401.15949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TFDMNet: A Novel Network Structure Combines the Time Domain and  Frequency Domain Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hengyue Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhiliang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+P">Peng Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Linbo Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is the updated edition of our paper Learning Convolutional Neural Networks in the Frequency Domain (<a href="/abs/2204.06718">arXiv:2204.06718</a>). Comparing with the previous edition, we design a mixture model to get the balance between the computation complexity and memory usage
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Convolutional neural network (CNN) has achieved impressive success in
computer vision during the past few decades. The image convolution operation
helps CNNs to get good performance on image-related tasks. However, it also has
high computation complexity and hard to be parallelized. This paper proposes a
novel Element-wise Multiplication Layer (EML) to replace convolution layers,
which can be trained in the frequency domain. Theoretical analyses show that
EMLs lower the computation complexity and easier to be parallelized. Moreover,
we introduce a Weight Fixation mechanism to alleviate the problem of
over-fitting, and analyze the working behavior of Batch Normalization and
Dropout in the frequency domain. To get the balance between the computation
complexity and memory usage, we propose a new network structure, namely
Time-Frequency Domain Mixture Network (TFDMNet), which combines the advantages
of both convolution layers and EMLs. Experimental results imply that TFDMNet
achieves good performance on MNIST, CIFAR-10 and ImageNet databases with less
number of operations comparing with corresponding CNNs.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15952" title="Abstract">arXiv:2401.15952</a> [<a href="/pdf/2401.15952" title="Download PDF">pdf</a>, <a href="/format/2401.15952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Class-aware Optimal Transport Approach with Higher-Order Moment  Matching for Unsupervised Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung Le</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">He Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q+H">Quan Hung Tran</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+D">Dinh Phung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Unsupervised domain adaptation (UDA) aims to transfer knowledge from a
labeled source domain to an unlabeled target domain. In this paper, we
introduce a novel approach called class-aware optimal transport (OT), which
measures the OT distance between a distribution over the source
class-conditional distributions and a mixture of source and target data
distribution. Our class-aware OT leverages a cost function that determines the
matching extent between a given data example and a source class-conditional
distribution. By optimizing this cost function, we find the optimal matching
between target examples and source class-conditional distributions, effectively
addressing the data and label shifts that occur between the two domains. To
handle the class-aware OT efficiently, we propose an amortization solution that
employs deep neural networks to formulate the transportation probabilities and
the cost function. Additionally, we propose minimizing class-aware Higher-order
Moment Matching (HMM) to align the corresponding class regions on the source
and target domains. The class-aware HMM component offers an economical
computational approach for accurately evaluating the HMM distance between the
two distributions. Extensive experiments on benchmark datasets demonstrate that
our proposed method significantly outperforms existing state-of-the-art
baselines.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15953" title="Abstract">arXiv:2401.15953</a> [<a href="/pdf/2401.15953" title="Download PDF">pdf</a>, <a href="/format/2401.15953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Audio Modeling with CLAP and Multi-Objective Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+Y">Yifei Xin</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiulian Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Interspeech2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Most existing masked audio modeling (MAM) methods learn audio representations
by masking and reconstructing local spectrogram patches. However, the
reconstruction loss mainly accounts for the signal-level quality of the
reconstructed spectrogram and is still limited in extracting high-level audio
semantics. In this paper, we propose to enhance the semantic modeling of MAM by
distilling cross-modality knowledge from contrastive language-audio pretraining
(CLAP) representations for both masked and unmasked regions (MAM-CLAP) and
leveraging a multi-objective learning strategy with a supervised classification
branch (SupMAM), thereby providing more semantic knowledge for MAM and enabling
it to effectively learn global features from labels. Experiments show that our
methods significantly improve the performance on multiple downstream tasks.
Furthermore, by combining our MAM-CLAP with SupMAM, we can achieve new
state-of-the-art results on various audio and speech classification tasks,
exceeding previous self-supervised learning and supervised pretraining methods.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15954" title="Abstract">arXiv:2401.15954</a> [<a href="/pdf/2401.15954" title="Download PDF">pdf</a>, <a href="/format/2401.15954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A supervised learning scheme for computing Hamilton-Jacobi equation via  density coupling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cui%2C+J">Jianbo Cui</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+H">Haomin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a supervised learning scheme for the first order Hamilton-Jacobi
PDEs in high dimensions. The scheme is designed by using the geometric
structure of Wasserstein Hamiltonian flows via a density coupling strategy. It
is equivalently posed as a regression problem using the Bregman divergence,
which provides the loss function in learning while the data is generated
through the particle formulation of Wasserstein Hamiltonian flow. We prove a
posterior estimate on $L^1$ residual of the proposed scheme based on the
coupling density. Furthermore, the proposed scheme can be used to describe the
behaviors of Hamilton-Jacobi PDEs beyond the singularity formations on the
support of coupling density.Several numerical examples with different
Hamiltonians are provided to support our findings.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15956" title="Abstract">arXiv:2401.15956</a> [<a href="/pdf/2401.15956" title="Download PDF">pdf</a>, <a href="/format/2401.15956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobFuzz: Adaptive Multi-objective Optimization in Gray-box Fuzzing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tai Yue</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangdong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Kai Lu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Network and Distributed Systems Security (NDSS) Symposium 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Coverage-guided gray-box fuzzing (CGF) is an efficient software testing
technique. There are usually multiple objectives to optimize in CGF. However,
existing CGF meth- ods cannot successfully find the optimal values for multiple
objectives simultaneously. In this paper, we propose a gray-box fuzzer for
multi-objective optimization (MOO) called MobFuzz. We model the multi-objective
optimization process as a multi- player multi-armed bandit (MPMAB). First, it
adaptively selects the objective combination that contains the most appropriate
objectives for the current situation. Second, our model deals with the power
schedule, which adaptively allocates energy to the seeds under the chosen
objective combination. In MobFuzz, we propose an evolutionary algorithm called
NIC to optimize our chosen objectives simultaneously without incurring
additional performance overhead. To prove the effectiveness of MobFuzz, we
conduct experiments on 12 real-world programs and the MAGMA data set.
Experiment results show that multi-objective optimization in MobFuzz
outperforms single-objective fuzzing in the baseline fuzzers. In contrast to
them, MobFuzz can select the optimal objective combination and increase the
values of multiple objectives up to 107%, with at most a 55% reduction in the
energy consumption. Moreover, MobFuzz has up to 6% more program coverage and
finds 3x more unique bugs than the baseline fuzzers. The NIC algorithm has at
least a 2x improvement with a performance overhead of approximately 3%.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15957" title="Abstract">arXiv:2401.15957</a> [<a href="/pdf/2401.15957" title="Download PDF">pdf</a>, <a href="/format/2401.15957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Federated Unlearning via Isolated and Coded Sharding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yijing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhipeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+G">Gui Gui</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jinke Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Federated unlearning has emerged as a promising paradigm to erase the
client-level data effect without affecting the performance of collaborative
learning models. However, the federated unlearning process often introduces
extensive storage overhead and consumes substantial computational resources,
thus hindering its implementation in practice. To address this issue, this
paper proposes a scalable federated unlearning framework based on isolated
sharding and coded computing. We first divide distributed clients into multiple
isolated shards across stages to reduce the number of clients being affected.
Then, to reduce the storage overhead of the central server, we develop a coded
computing mechanism by compressing the model parameters across different
shards. In addition, we provide the theoretical analysis of time efficiency and
storage effectiveness for the isolated and coded sharding. Finally, extensive
experiments on two typical learning tasks, i.e., classification and generation,
demonstrate that our proposed framework can achieve better performance than
three state-of-the-art frameworks in terms of accuracy, retraining time,
storage overhead, and F1 scores for resisting membership inference attacks.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15960" title="Abstract">arXiv:2401.15960</a> [<a href="/pdf/2401.15960" title="Download PDF">pdf</a>, <a href="/format/2401.15960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EchoPFL: Asynchronous Personalized Federated Learning on Mobile Devices  with On-Demand Staleness Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaochen Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sicong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zimu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Bin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwen Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by Ubicomp2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The rise of mobile devices with abundant sensory data and local computing
capabilities has driven the trend of federated learning (FL) on these devices.
And personalized FL (PFL) emerges to train specific deep models for each mobile
device to address data heterogeneity and varying performance preferences.
However, mobile training times vary significantly, resulting in either delay
(when waiting for slower devices for aggregation) or accuracy decline (when
aggregation proceeds without waiting). In response, we propose a shift towards
asynchronous PFL, where the server aggregates updates as soon as they are
available. Nevertheless, existing asynchronous protocols are unfit for PFL
because they are devised for federated training of a single global model. They
suffer from slow convergence and decreased accuracy when confronted with severe
data heterogeneity prevalent in PFL. Furthermore, they often exclude slower
devices for staleness control, which notably compromises accuracy when these
devices possess critical personalized data. Therefore, we propose EchoPFL, a
coordination mechanism for asynchronous PFL. Central to EchoPFL is to include
updates from all mobile devices regardless of their latency. To cope with the
inevitable staleness from slow devices, EchoPFL revisits model broadcasting. It
intelligently converts the unscalable broadcast to on-demand broadcast,
leveraging the asymmetrical bandwidth in wireless networks and the dynamic
clustering-based PFL. Experiments show that compared to status quo approaches,
EchoPFL achieves a reduction of up to 88.2% in convergence time, an improvement
of up to 46% in accuracy, and a decrease of 37% in communication costs
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15962" title="Abstract">arXiv:2401.15962</a> [<a href="/pdf/2401.15962" title="Download PDF">pdf</a>, <a href="/ps/2401.15962" title="Download PostScript">ps</a>, <a href="/format/2401.15962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An implicit staggered algorithm for CPFEM-based analysis of aluminum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Areias%2C+P">Pedro Areias</a>, 
<a href="/search/math?searchtype=author&query=Santos%2C+C+d">Charles dos Santos</a>, 
<a href="/search/math?searchtype=author&query=Melicio%2C+R">Rui Melicio</a>, 
<a href="/search/math?searchtype=author&query=Silvestre%2C+N">Nuno Silvestre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we introduce an implicit staggered algorithm for crystal
plasticity finite element method (CPFEM) which makes use of dynamic relaxation
at the constitutive integration level. An uncoupled version of the constitutive
system consists of a multi-surface flow law complemented by an evolution law
for the hardening variables. Since a saturation law is adopted for hardening, a
sequence of nonlinear iteration followed by a linear system is feasible. To tie
the constitutive unknowns, the dynamic relaxation method is adopted. A
Green-Nagdhi plasticity model is adopted based on the Hencky strain calculated
using a [2/2] Pad\'e approximation. For the incompressible case, the
approximation error is calculated exactly. A enhanced-assumed strain (EAS)
element technology is adopted, which was found to be especially suited to
localization problems such as the ones resulting from crystal plasticity plane
slipping. Analysis of the results shows significant reduction of drift and well
defined localization without spurious modes or hourglassing.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15963" title="Abstract">arXiv:2401.15963</a> [<a href="/pdf/2401.15963" title="Download PDF">pdf</a>, <a href="/format/2401.15963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional  Correctness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhal%2C+M">Manav Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+T">Tushar Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Awasthi%2C+A">Abhijeet Awasthi</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+N">Nagarajan Natarajan</a>, 
<a href="/search/cs?searchtype=author&query=Kanade%2C+A">Aditya Kanade</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Existing evaluation benchmarks of language models of code (code LMs) focus
almost exclusively on whether the LMs can generate functionally-correct code.
In real-world software engineering, developers think beyond functional
correctness. They have requirements on "how" a functionality should be
implemented to meet overall system design objectives like efficiency, security,
and maintainability. They would also trust the code LMs more if the LMs
demonstrate robust understanding of requirements and code semantics.
<br />We propose a new benchmark NoFunEval to evaluate code LMs on non-functional
requirements and simple classification instances for both functional and
non-functional requirements. We propose a prompting method, Coding Concepts
(CoCo), as a way for a developer to communicate the domain knowledge to the
LMs. We conduct an extensive evaluation of twenty-two code LMs. Our finding is
that they generally falter when tested on our benchmark, hinting at fundamental
blindspots in their training setups. Surprisingly, even the classification
accuracy on functional-correctness instances derived from the popular HumanEval
benchmark is low, calling in question the depth of their comprehension and the
source of their success in generating functionally-correct code in the first
place. We will release our benchmark and evaluation scripts publicly at
https://aka.ms/NoFunEval.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15964" title="Abstract">arXiv:2401.15964</a> [<a href="/pdf/2401.15964" title="Download PDF">pdf</a>, <a href="/format/2401.15964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Attention Graph Neural Network for Remaining Useful Life  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhixin Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yujiang He</a>, 
<a href="/search/cs?searchtype=author&query=Sick%2C+B">Bernhard Sick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted in the International Conference Computational Science &amp; Computational Intelligence (CSCI'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Remaining useful life prediction plays a crucial role in the health
management of industrial systems. Given the increasing complexity of systems,
data-driven predictive models have attracted significant research interest.
Upon reviewing the existing literature, it appears that many studies either do
not fully integrate both spatial and temporal features or employ only a single
attention mechanism. Furthermore, there seems to be inconsistency in the choice
of data normalization methods, particularly concerning operating conditions,
which might influence predictive performance. To bridge these observations,
this study presents the Spatio-Temporal Attention Graph Neural Network. Our
model combines graph neural networks and temporal convolutional neural networks
for spatial and temporal feature extraction, respectively. The cascade of these
extractors, combined with multi-head attention mechanisms for both
spatio-temporal dimensions, aims to improve predictive precision and refine
model explainability. Comprehensive experiments were conducted on the C-MAPSS
dataset to evaluate the impact of unified versus clustering normalization. The
findings suggest that our model performs state-of-the-art results using only
the unified normalization. Additionally, when dealing with datasets with
multiple operating conditions, cluster normalization enhances the performance
of our proposed model by up to 27%.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15966" title="Abstract">arXiv:2401.15966</a> [<a href="/pdf/2401.15966" title="Download PDF">pdf</a>, <a href="/ps/2401.15966" title="Download PostScript">ps</a>, <a href="/format/2401.15966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Response Generation for Cognitive Behavioral Therapy with Large Language  Models: Comparative Study with Socratic Questioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izumi%2C+K">Kenta Izumi</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+H">Hiroki Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Shidara%2C+K">Kazuhiro Shidara</a>, 
<a href="/search/cs?searchtype=author&query=Adachi%2C+H">Hiroyoshi Adachi</a>, 
<a href="/search/cs?searchtype=author&query=Kanayama%2C+D">Daisuke Kanayama</a>, 
<a href="/search/cs?searchtype=author&query=Kudo%2C+T">Takashi Kudo</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+S">Satoshi Nakamura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IWSDS2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Dialogue systems controlled by predefined or rule-based scenarios derived
from counseling techniques, such as cognitive behavioral therapy (CBT), play an
important role in mental health apps. Despite the need for responsible
responses, it is conceivable that using the newly emerging LLMs to generate
contextually relevant utterances will enhance these apps. In this study, we
construct dialogue modules based on a CBT scenario focused on conventional
Socratic questioning using two kinds of LLMs: a Transformer-based dialogue
model further trained with a social media empathetic counseling dataset,
provided by Osaka Prefecture (OsakaED), and GPT-4, a state-of-the art LLM
created by OpenAI. By comparing systems that use LLM-generated responses with
those that do not, we investigate the impact of generated responses on
subjective evaluations such as mood change, cognitive change, and dialogue
quality (e.g., empathy). As a result, no notable improvements are observed when
using the OsakaED model. When using GPT-4, the amount of mood change, empathy,
and other dialogue qualities improve significantly. Results suggest that GPT-4
possesses a high counseling ability. However, they also indicate that even when
using a dialogue model trained with a human counseling dataset, it does not
necessarily yield better outcomes compared to scenario-based dialogues. While
presenting LLM-generated responses, including GPT-4, and having them interact
directly with users in real-life mental health care services may raise ethical
issues, it is still possible for human professionals to produce example
responses or response templates using LLMs in advance in systems that use
rules, scenarios, or example responses.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15967" title="Abstract">arXiv:2401.15967</a> [<a href="/pdf/2401.15967" title="Download PDF">pdf</a>, <a href="/format/2401.15967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INSTILLER: Towards Efficient and Realistic RTL Fuzzing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tai Yue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Danjun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yubei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Kai Lu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Computer-Aided Design of Integrated Circuits
  and Systems 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Bugs exist in hardware, such as CPU. Unlike soft- ware bugs, these hardware
bugs need to be detected before deployment. Previous fuzzing work in CPU bug
detection has several disadvantages, e.g., the length of RTL input instructions
keeps growing, and longer inputs are ineffective for fuzzing. In this paper, we
propose INSTILLER (Instruction Distiller), an RTL fuzzer based on ant colony
optimization (ACO). First, to keep the input instruction length short and
efficient in fuzzing, it distills input instructions with a variant of ACO
(VACO). Next, related work cannot simulate realistic interruptions well in
fuzzing, and INSTILLER solves the problem of inserting interruptions and
exceptions in generating the inputs. Third, to further improve the fuzzing
performance of INSTILLER, we propose hardware-based seed selection and mutation
strategies. We implement a prototype and conduct extensive experiments against
state-of-the-art fuzzing work in real-world target CPU cores. In experiments,
INSTILLER has 29.4% more coverage than DiFuzzRTL. In addition, 17.0% more
mismatches are detected by INSTILLER. With the VACO algorithm, INSTILLER
generates 79.3% shorter input instructions than DiFuzzRTL, demonstrating its
effectiveness in distilling the input instructions. In addition, the
distillation leads to a 6.7% increase in execution speed on average.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15969" title="Abstract">arXiv:2401.15969</a> [<a href="/pdf/2401.15969" title="Download PDF">pdf</a>, <a href="/format/2401.15969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Routers in Vision Mixture of Experts: An Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianlin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Blondel%2C+M">Mathieu Blondel</a>, 
<a href="/search/cs?searchtype=author&query=Riquelme%2C+C">Carlos Riquelme</a>, 
<a href="/search/cs?searchtype=author&query=Puigcerver%2C+J">Joan Puigcerver</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Mixture-of-Experts (MoE) models are a promising way to scale up model
capacity without significantly increasing computational cost. A key component
of MoEs is the router, which decides which subset of parameters (experts)
process which feature embeddings (tokens). In this paper, we present a
comprehensive study of routers in MoEs for computer vision tasks. We introduce
a unified MoE formulation that subsumes different MoEs with two parametric
routing tensors. This formulation covers both sparse MoE, which uses a binary
or hard assignment between experts and tokens, and soft MoE, which uses a soft
assignment between experts and weighted combinations of tokens. Routers for
sparse MoEs can be further grouped into two variants: Token Choice, which
matches experts to each token, and Expert Choice, which matches tokens to each
expert. We conduct head-to-head experiments with 6 different routers, including
existing routers from prior work and new ones we introduce. We show that (i)
many routers originally developed for language modeling can be adapted to
perform strongly in vision tasks, (ii) in sparse MoE, Expert Choice routers
generally outperform Token Choice routers, and (iii) soft MoEs generally
outperform sparse MoEs with a fixed compute budget. These results provide new
insights regarding the crucial role of routers in vision MoE models.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15970" title="Abstract">arXiv:2401.15970</a> [<a href="/pdf/2401.15970" title="Download PDF">pdf</a>, <a href="/format/2401.15970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HEQuant: Marrying Homomorphic Encryption and Quantization for  Communication-Efficient Private Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianshi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runsheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Secure two-party computation with homomorphic encryption (HE) protects data
privacy with a formal security guarantee but suffers from high communication
overhead. While previous works, e.g., Cheetah, Iron, etc, have proposed
efficient HE-based protocols for different neural network (NN) operations, they
still assume high precision, e.g., fixed point 37 bit, for the NN operations
and ignore NNs' native robustness against quantization error. In this paper, we
propose HEQuant, which features low-precision-quantization-aware optimization
for the HE-based protocols. We observe the benefit of a naive combination of
quantization and HE quickly saturates as bit precision goes down. Hence, to
further improve communication efficiency, we propose a series of optimizations,
including an intra-coefficient packing algorithm and a quantization-aware
tiling algorithm, to simultaneously reduce the number and precision of the
transferred data. Compared with prior-art HE-based protocols, e.g., CrypTFlow2,
Cheetah, Iron, etc, HEQuant achieves $3.5\sim 23.4\times$ communication
reduction and $3.0\sim 9.3\times$ latency reduction. Meanwhile, when compared
with prior-art network optimization frameworks, e.g., SENet, SNL, etc, HEQuant
also achieves $3.1\sim 3.6\times$ communication reduction.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15973" title="Abstract">arXiv:2401.15973</a> [<a href="/pdf/2401.15973" title="Download PDF">pdf</a>, <a href="/format/2401.15973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Weight Estimation Using Meta-Updates for Online Continual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemati%2C+H">Hamed Hemati</a>, 
<a href="/search/cs?searchtype=author&query=Borth%2C+D">Damian Borth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The loss function plays an important role in optimizing the performance of a
learning system. A crucial aspect of the loss function is the assignment of
sample weights within a mini-batch during loss computation. In the context of
continual learning (CL), most existing strategies uniformly treat samples when
calculating the loss value, thereby assigning equal weights to each sample.
While this approach can be effective in certain standard benchmarks, its
optimal effectiveness, particularly in more complex scenarios, remains
underexplored. This is particularly pertinent in training "in the wild," such
as with self-training, where labeling is automated using a reference model.
This paper introduces the Online Meta-learning for Sample Importance (OMSI)
strategy that approximates sample weights for a mini-batch in an online CL
stream using an inner- and meta-update mechanism. This is done by first
estimating sample weight parameters for each sample in the mini-batch, then,
updating the model with the adapted sample weights. We evaluate OMSI in two
distinct experimental settings. First, we show that OMSI enhances both learning
and retained accuracy in a controlled noisy-labeled data stream. Then, we test
the strategy in three standard benchmarks and compare it with other popular
replay-based strategies. This research aims to foster the ongoing exploration
in the area of self-adaptive CL.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15975" title="Abstract">arXiv:2401.15975</a> [<a href="/pdf/2401.15975" title="Download PDF">pdf</a>, <a href="/format/2401.15975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StableIdentity: Inserting Anybody into Anywhere at First Sight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qinghe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xu Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaomin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Taiqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liqian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhuge%2C+Y">Yunzhi Zhuge</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in large pretrained text-to-image models have shown
unprecedented capabilities for high-quality human-centric generation, however,
customizing face identity is still an intractable problem. Existing methods
cannot ensure stable identity preservation and flexible editability, even with
several images for each subject during training. In this work, we propose
StableIdentity, which allows identity-consistent recontextualization with just
one face image. More specifically, we employ a face encoder with an identity
prior to encode the input face, and then land the face representation into a
space with an editable prior, which is constructed from celeb names. By
incorporating identity prior and editability prior, the learned identity can be
injected anywhere with various contexts. In addition, we design a masked
two-phase diffusion loss to boost the pixel-level perception of the input face
and maintain the diversity of generation. Extensive experiments demonstrate our
method outperforms previous customization methods. In addition, the learned
identity can be flexibly combined with the off-the-shelf modules such as
ControlNet. Notably, to the best knowledge, we are the first to directly inject
the identity learned from a single image into video/3D generation without
finetuning. We believe that the proposed StableIdentity is an important step to
unify image, video, and 3D customized generation models.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15976" title="Abstract">arXiv:2401.15976</a> [<a href="/pdf/2401.15976" title="Download PDF">pdf</a>, <a href="/format/2401.15976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Period Topology and Design Optimization Approach for District  Heating Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wack%2C+Y">Yannick Wack</a>, 
<a href="/search/cs?searchtype=author&query=Sollich%2C+M">Martin Sollich</a>, 
<a href="/search/cs?searchtype=author&query=Salenbien%2C+R">Robbe Salenbien</a>, 
<a href="/search/cs?searchtype=author&query=Diriken%2C+J">Jan Diriken</a>, 
<a href="/search/cs?searchtype=author&query=Baelmans%2C+M">Martine Baelmans</a>, 
<a href="/search/cs?searchtype=author&query=Blommaert%2C+M">Maarten Blommaert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The transition to 4th generation district heating creates a growing need for
scalable, automated design tools that accurately capture the spatial and
temporal details of heating network operation. This paper presents an automated
design approach for the optimal design of district heating networks that
combines scalable density-based topology optimization with a multi-period
approach. In this way, temporal variations in demand, supply, and heat losses
can be taken into account while optimizing the network design based on a
nonlinear physics model. The transition of the automated design approach from
worst-case to multi-period shows a design progression from separate branched
networks to a single integrated meshed network topology connecting all
producers. These integrated topologies emerge without imposing such structures
a priori. They increase network connectivity, and allow for more flexible
shifting of heat loads between different producers and heat consumers,
resulting in more cost-effective use of heat. In a case study, this integrated
design resulted in an increase in waste heat share of 42.8 % and a subsequent
reduction in project cost of 17.9 %. We show how producer unavailability can be
accounted for in the automated design at the cost of a 3.1 % increase in the
cost of backup capacity. The resulting optimized network designs of this
approach connect multiple low temperature heat sources in a single integrated
network achieving high waste heat utilization and redundancy, highlighting the
applicability of the approach to next-generation district heating networks.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15977" title="Abstract">arXiv:2401.15977</a> [<a href="/pdf/2401.15977" title="Download PDF">pdf</a>, <a href="/format/2401.15977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-I2V: Consistent and Controllable Image-to-Video Generation with  Explicit Motion Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhaoyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fu-Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+W">Weikang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dasong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Manyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+K+C">Ka Chun Cheung</a>, 
<a href="/search/cs?searchtype=author&query=See%2C+S">Simon See</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hongwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Da%2C+J">Jifeng Da</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Motion-I2V, a novel framework for consistent and controllable
image-to-video generation (I2V). In contrast to previous methods that directly
learn the complicated image-to-video mapping, Motion-I2V factorizes I2V into
two stages with explicit motion modeling. For the first stage, we propose a
diffusion-based motion field predictor, which focuses on deducing the
trajectories of the reference image's pixels. For the second stage, we propose
motion-augmented temporal attention to enhance the limited 1-D temporal
attention in video latent diffusion models. This module can effectively
propagate reference image's feature to synthesized frames with the guidance of
predicted trajectories from the first stage. Compared with existing methods,
Motion-I2V can generate more consistent videos even at the presence of large
motion and viewpoint variation. By training a sparse trajectory ControlNet for
the first stage, Motion-I2V can support users to precisely control motion
trajectories and motion regions with sparse trajectory and region annotations.
This offers more controllability of the I2V process than solely relying on
textual instructions. Additionally, Motion-I2V's second stage naturally
supports zero-shot video-to-video translation. Both qualitative and
quantitative comparisons demonstrate the advantages of Motion-I2V over prior
approaches in consistent and controllable image-to-video generation.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15978" title="Abstract">arXiv:2401.15978</a> [<a href="/pdf/2401.15978" title="Download PDF">pdf</a>, <a href="/format/2401.15978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilevel Markov Chain Monte Carlo with likelihood scaling for  high-resolution data assimilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vanmechelen%2C+P">Pieter Vanmechelen</a>, 
<a href="/search/math?searchtype=author&query=Lombaert%2C+G">Geert Lombaert</a>, 
<a href="/search/math?searchtype=author&query=Samaey%2C+G">Giovanni Samaey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a multilevel Markov chain Monte Carlo (MCMC) method for the
Bayesian inference of random field parameters in PDEs using high-resolution
data. Compared to existing multilevel MCMC methods, we additionally consider
level-dependent data resolution and introduce a suitable likelihood scaling to
enable consistent cross-level comparisons. We theoretically show that this
approach attains the same convergence rates as when using level-independent
treatment of data, but at significantly reduced computational cost.
Additionally, we show that assumptions of exponential covariance and
log-normality of random fields, widely held in multilevel Monte Carlo
literature, can be extended to a wide range of covariance structures and random
fields. These results are illustrated using numerical experiments for a 2D
plane stress problem, where the Young's modulus is estimated from
discretisations of the displacement field.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15985" title="Abstract">arXiv:2401.15985</a> [<a href="/pdf/2401.15985" title="Download PDF">pdf</a>, <a href="/format/2401.15985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissecting the software-based measurement of CPU energy consumption: a  comparative analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raffin%2C+G">Guillaume Raffin</a> (DATAMOVE, UGA), 
<a href="/search/cs?searchtype=author&query=Trystram%2C+D">Denis Trystram</a> (UGA (2016-2019), DATAMOVE, UGA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Every day, we experience the effects of the global warming: extreme weather
events, major forest fires, storms, global warming, etc. The scientific
community acknowledges that this crisis is a consequence of human activities
where Information and Communications Technologies (ICT) are an increasingly
important contributor. Computer scientists need tools for measuring the
footprint of the code they produce. Running Average Power Limit (RAPL) is a
low-level interface designed by Intel that provides a measure of the energy
consumption of a CPU (and more) without the need for additional hardware. Since
2017, it is available on most computing devices, including non-Intel devices
such as AMD processors. More and more people are using RAPL for energy
measurement, mostly like a black box without deep knowledge of its behaviour.
In this paper, we propose to come back to the basic mechanisms that allow to
use RAPL measurements and present a critical analysis of their operations. For
each mechanism, we release a reference implementation in Rust that avoids the
pitfalls we detected in existing tools, improving correctness, timing accuracy
and performance. In addition to long-established methods, we explore the
suitability of the recent eBPF technology for working with RAPL. We also
provide an experimental study with multiple benchmarks and processor models in
order to evaluate the efficiency of the various mechanisms and their impact on
parallel software. Our experiments show that no mechanism provides a
significant performance advantage over the others. However, they differ
significantly in terms of ease-of-use and resiliency. We believe that this work
will help the community to develop correct, resilient and lightweight
measurement tools, based on the mechanism that suits their needs.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15987" title="Abstract">arXiv:2401.15987</a> [<a href="/pdf/2401.15987" title="Download PDF">pdf</a>, <a href="/format/2401.15987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hand-Centric Motion Refinement for 3D Hand-Object Interaction via  Hierarchical Spatial-Temporal Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yuze Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+T">Tao Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+F">Fuan Wen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hehe Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Hands are the main medium when people interact with the world. Generating
proper 3D motion for hand-object interaction is vital for applications such as
virtual reality and robotics. Although grasp tracking or object manipulation
synthesis can produce coarse hand motion, this kind of motion is inevitably
noisy and full of jitter. To address this problem, we propose a data-driven
method for coarse motion refinement. First, we design a hand-centric
representation to describe the dynamic spatial-temporal relation between hands
and objects. Compared to the object-centric representation, our hand-centric
representation is straightforward and does not require an ambiguous projection
process that converts object-based prediction into hand motion. Second, to
capture the dynamic clues of hand-object interaction, we propose a new
architecture that models the spatial and temporal structure in a hierarchical
manner. Extensive experiments demonstrate that our method outperforms previous
methods by a noticeable margin.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15989" title="Abstract">arXiv:2401.15989</a> [<a href="/pdf/2401.15989" title="Download PDF">pdf</a>, <a href="/format/2401.15989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Embedding Clustering Driven by Sample Stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhanwen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feijiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jieting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yuhua Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,5 figures,submitted to a conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep clustering methods improve the performance of clustering tasks by
jointly optimizing deep representation learning and clustering. While numerous
deep clustering algorithms have been proposed, most of them rely on
artificially constructed pseudo targets for performing clustering. This
construction process requires some prior knowledge, and it is challenging to
determine a suitable pseudo target for clustering. To address this issue, we
propose a deep embedding clustering algorithm driven by sample stability
(DECS), which eliminates the requirement of pseudo targets. Specifically, we
start by constructing the initial feature space with an autoencoder and then
learn the cluster-oriented embedding feature constrained by sample stability.
The sample stability aims to explore the deterministic relationship between
samples and all cluster centroids, pulling samples to their respective clusters
and keeping them away from other clusters with high determinacy. We analyzed
the convergence of the loss using Lipschitz continuity in theory, which
verifies the validity of the model. The experimental results on five datasets
illustrate that the proposed method achieves superior performance compared to
state-of-the-art clustering approaches.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15993" title="Abstract">arXiv:2401.15993</a> [<a href="/pdf/2401.15993" title="Download PDF">pdf</a>, <a href="/format/2401.15993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Target Speech Extraction: Enhancing Personalized Diarization  and Extraction on Complex Recordings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">He Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hangting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuehai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Target speaker extraction (TSE) aims to extract the target speaker's voice
from the input mixture. Previous studies have concentrated on high-overlapping
scenarios. However, real-world applications usually meet more complex scenarios
like variable speaker overlapping and target speaker absence. In this paper, we
introduces a framework to perform continuous TSE (C-TSE), comprising a target
speaker voice activation detection (TSVAD) and a TSE model. This framework
significantly improves TSE performance on similar speakers and enhances
personalization, which is lacking in traditional diarization methods. In
detail, unlike conventional TSVAD deployed to refine the diarization results,
the proposed Attention-target speaker voice activation detection (A-TSVAD)
directly generates timestamps of the target speaker. We also explore some
different integration methods of A-TSVAD and TSE by comparing the cascaded and
parallel methods. The framework's effectiveness is assessed using a range of
metrics, including diarization and enhancement metrics. Our experiments
demonstrate that A-TSVAD outperforms conventional methods in reducing
diarization errors. Furthermore, the integration of A-TSVAD and TSE in a
sequential cascaded manner further enhances extraction accuracy.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15994" title="Abstract">arXiv:2401.15994</a> [<a href="/pdf/2401.15994" title="Download PDF">pdf</a>, <a href="/ps/2401.15994" title="Download PostScript">ps</a>, <a href="/format/2401.15994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting and visualizing a new classification system for Colombia&#x27;s  National Administrative Department of Statistics. A visual analytics  framework case study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raimbaud%2C+P">Pierre Raimbaud</a> (UNIANDES), 
<a href="/search/cs?searchtype=author&query=Castillo%2C+J+C+E">Jaime Camilo Espitia Castillo</a> (UNIANDES), 
<a href="/search/cs?searchtype=author&query=Guerra-Gomez%2C+J">John Guerra-Gomez</a> (Northeastern University, Silicon Valley Campus)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> V Jornadas Iberoamericanas de Interacci{\'o}n Humano-Computador 2019, Benem{\'e}rita Universidad Aut{\'o}noma de Puebla, Jun 2019, Puebla (Mexico), Mexico
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In a world filled with data, it is expected for a nation to take decisions
informed by data. However, countries need to first collect and publish such
data in a way meaningful for both citizens and policy makers. A good thematic
classification could be instrumental in helping users navigate and find the
right resources on a rich data repository as the one collected by Colombia's
National Administrative Department of Statistics (DANE). The Visual Analytics
Framework is a methodology for conducting visual analysis developed by T.
Munzner et al. [T. Munzner, Visualization Analysis and Design, A K Peters
Visualization Series, 1, 2014] that could help with this task. This paper
presents a case study applying such framework conducted to help the DANE better
visualize their data repository, and present a more understandable
classification of it. It describes three main analysis tasks identified, the
proposed solutions and the collection of insights generated from them.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15996" title="Abstract">arXiv:2401.15996</a> [<a href="/pdf/2401.15996" title="Download PDF">pdf</a>, <a href="/format/2401.15996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AccessLens: Auto-detecting Inaccessibility of Everyday Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+N">Nahyun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qazi%2C+M+H">Muhammad Hasham Qazi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Joanne Liu</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+C">Changhoon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Shu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeeeun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CHI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In our increasingly diverse society, everyday physical interfaces often
present barriers, impacting individuals across various contexts. This
oversight, from small cabinet knobs to identical wall switches that can pose
different contextual challenges, highlights an imperative need for solutions.
Leveraging low-cost 3D-printed augmentations such as knob magnifiers and
tactile labels seems promising, yet the process of discovering unrecognized
barriers remains challenging because disability is context-dependent. We
introduce AccessLens, an end-to-end system designed to identify inaccessible
interfaces in daily objects, and recommend 3D-printable augmentations for
accessibility enhancement. Our approach involves training a detector using the
novel AccessDB dataset designed to automatically recognize 21 distinct
Inaccessibility Classes (e.g., bar-small and round-rotate) within 6 common
object categories (e.g., handle and knob). AccessMeta serves as a robust way to
build a comprehensive dictionary linking these accessibility classes to
open-source 3D augmentation designs. Experiments demonstrate our detector's
performance in detecting inaccessible objects.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16001" title="Abstract">arXiv:2401.16001</a> [<a href="/pdf/2401.16001" title="Download PDF">pdf</a>, <a href="/format/2401.16001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LESSON: Multi-Label Adversarial False Data Injection Attack for Deep  Learning Locational Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiwei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Buhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaofang Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenhao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TDSC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Deep learning methods can not only detect false data injection attacks (FDIA)
but also locate attacks of FDIA. Although adversarial false data injection
attacks (AFDIA) based on deep learning vulnerabilities have been studied in the
field of single-label FDIA detection, the adversarial attack and defense
against multi-label FDIA locational detection are still not involved. To bridge
this gap, this paper first explores the multi-label adversarial example attacks
against multi-label FDIA locational detectors and proposes a general
multi-label adversarial attack framework, namely muLti-labEl adverSarial falSe
data injectiON attack (LESSON). The proposed LESSON attack framework includes
three key designs, namely Perturbing State Variables, Tailored Loss Function
Design, and Change of Variables, which can help find suitable multi-label
adversarial perturbations within the physical constraints to circumvent both
Bad Data Detection (BDD) and Neural Attack Location (NAL). Four typical LESSON
attacks based on the proposed framework and two dimensions of attack objectives
are examined, and the experimental results demonstrate the effectiveness of the
proposed attack framework, posing serious and pressing security concerns in
smart grids.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16004" title="Abstract">arXiv:2401.16004</a> [<a href="/pdf/2401.16004" title="Download PDF">pdf</a>, <a href="/ps/2401.16004" title="Download PostScript">ps</a>, <a href="/format/2401.16004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model predictive control of wakes for wind farm power tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sterle%2C+A">Arnold Sterle</a>, 
<a href="/search/eess?searchtype=author&query=Hans%2C+C+A">Christian A. Hans</a>, 
<a href="/search/eess?searchtype=author&query=Raisch%2C+J">J&#xf6;rg Raisch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, a model predictive control scheme for wind farms is presented.
Our approach considers wake dynamics including their influence on local wind
conditions and allows to track a given power reference. In detail, a Gaussian
wake model is used in combination with observation points that carry wind
condition information. This allows to estimate the rotor effective wind speeds
at downstream turbines based on which we deduce their power output. Through
different approximation methods, the associated finite horizon nonlinear
optimization problem is reformulated in a mixed-integer
quadratically-constrained quadratic program fashion. By solving the
reformulated problem online, optimal yaw angles and axial induction factors are
found. Closed-loop simulations indicate good power tracking capabilities over a
wide range of power setpoints while distributing wind turbine infeed evenly
among all units. Additionally, the simulation results underline real time
capabilities of our approach.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16009" title="Abstract">arXiv:2401.16009</a> [<a href="/pdf/2401.16009" title="Download PDF">pdf</a>, <a href="/ps/2401.16009" title="Download PostScript">ps</a>, <a href="/format/2401.16009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpectroGLY: A Low-Cost IoT-Based Ecosystem for the Detection of  Glyphosate Residues in Waters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aira%2C+J">Javier Aira</a>, 
<a href="/search/cs?searchtype=author&query=Olivares%2C+T">Teresa Olivares</a>, 
<a href="/search/cs?searchtype=author&query=Delicado%2C+F+M">Francisco M. Delicado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Glyphosate contamination in waters is becoming a major health problem that
needs to be urgently addressed, as accidental spraying, drift or leakage of
this highly water-soluble herbicide can impact aquatic ecosystems. Researchers
are increasingly concerned about exposure to glyphosate and the risks its poses
to human health, since it may cause substantial damage, even in small doses.
The detection of glyphosate residues in waters is not a simple task, as it
requires complex and expensive equipment and qualified personnel. New
technological tools need to be designed and developed, based on proven, but
also cost-efficient, agile and user-friendly, analytical techniques, which can
be used in the field and in the lab, enabled by connectivity and multi-platform
software applications. This paper presents the design, development and testing
of an innovative low-cost VIS-NIR (Visible and Near-Infrared) spectrometer
(called SpectroGLY), based on IoT (Internet of Things) technologies, which
allows potential glyphosate contamination in waters to be detected. SpectroGLY
combines the functional concept of a traditional lab spectrometer with the IoT
technological concept, enabling the integration of several connectivity options
for rural and urban settings and digital visualization and monitoring platforms
(Mobile App and Dashboard Web). Thanks to its portability, it can be used in
any context and provides results in 10 minutes. Additionally, it is unnecessary
to transfer the sample to a laboratory (optimizing time, costs and the capacity
for corrective actions by the authorities). In short, this paper proposes an
innovative, low-cost, agile and highly promising solution to avoid potential
intoxications that may occur due to ingestion of water contaminated by this
herbicide.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16011" title="Abstract">arXiv:2401.16011</a> [<a href="/pdf/2401.16011" title="Download PDF">pdf</a>, <a href="/format/2401.16011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPS: Graph Contrastive Learning via Multi-scale Augmented Views from  Adversarial Pooling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yiyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhengyang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Z">Ziyue Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yifang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SCIENCE CHINA Information Sciences (SCIS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Self-supervised graph representation learning has recently shown considerable
promise in a range of fields, including bioinformatics and social networks. A
large number of graph contrastive learning approaches have shown promising
performance for representation learning on graphs, which train models by
maximizing agreement between original graphs and their augmented views (i.e.,
positive views). Unfortunately, these methods usually involve pre-defined
augmentation strategies based on the knowledge of human experts. Moreover,
these strategies may fail to generate challenging positive views to provide
sufficient supervision signals. In this paper, we present a novel approach
named Graph Pooling ContraSt (GPS) to address these issues. Motivated by the
fact that graph pooling can adaptively coarsen the graph with the removal of
redundancy, we rethink graph pooling and leverage it to automatically generate
multi-scale positive views with varying emphasis on providing challenging
positives and preserving semantics, i.e., strongly-augmented view and
weakly-augmented view. Then, we incorporate both views into a joint contrastive
learning framework with similarity learning and consistency learning, where our
pooling module is adversarially trained with respect to the encoder for
adversarial robustness. Experiments on twelve datasets on both graph
classification and transfer learning tasks verify the superiority of the
proposed method over its counterparts.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16012" title="Abstract">arXiv:2401.16012</a> [<a href="/pdf/2401.16012" title="Download PDF">pdf</a>, <a href="/format/2401.16012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Challenging Metaphors that Confuse Pretrained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yucheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Guerin%2C+F">Frank Guerin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Metaphors are considered to pose challenges for a wide spectrum of NLP tasks.
This gives rise to the area of computational metaphor processing. However, it
remains unclear what types of metaphors challenge current state-of-the-art
models. In this paper, we test various NLP models on the VUA metaphor dataset
and quantify to what extent metaphors affect models' performance on various
downstream tasks. Analysis reveals that VUA includes a large number of
metaphors that pose little difficulty to downstream tasks. We would like to
shift the attention of researchers away from these metaphors to instead focus
on challenging metaphors. To identify hard metaphors, we propose an automatic
pipeline that identifies metaphors that challenge a particular model. Our
analysis demonstrates that our detected hard metaphors contrast significantly
with VUA and reduce the accuracy of machine translation by 16\%, QA performance
by 4\%, NLI by 7\%, and metaphor identification recall by over 14\% for various
popular NLP systems.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16013" title="Abstract">arXiv:2401.16013</a> [<a href="/pdf/2401.16013" title="Download PDF">pdf</a>, <a href="/format/2401.16013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SERL: A Software Suite for Sample-Efficient Robotic Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jianlan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zheyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Charles Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y+L">You Liang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Berg%2C+J">Jacob Berg</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Archit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Schaal%2C+S">Stefan Schaal</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, significant progress has been made in the field of robotic
reinforcement learning (RL), enabling methods that handle complex image
observations, train in the real world, and incorporate auxiliary data, such as
demonstrations and prior experience. However, despite these advances, robotic
RL remains hard to use. It is acknowledged among practitioners that the
particular implementation details of these algorithms are often just as
important (if not more so) for performance as the choice of algorithm. We posit
that a significant challenge to widespread adoption of robotic RL, as well as
further development of robotic RL methods, is the comparative inaccessibility
of such methods. To address this challenge, we developed a carefully
implemented library containing a sample efficient off-policy deep RL method,
together with methods for computing rewards and resetting the environment, a
high-quality controller for a widely-adopted robot, and a number of challenging
example tasks. We provide this library as a resource for the community,
describe its design choices, and present experimental results. Perhaps
surprisingly, we find that our implementation can achieve very efficient
learning, acquiring policies for PCB board assembly, cable routing, and object
relocation between 25 to 50 minutes of training per policy on average,
improving over state-of-the-art results reported for similar tasks in the
literature. These policies achieve perfect or near-perfect success rates,
extreme robustness even under perturbations, and exhibit emergent recovery and
correction behaviors. We hope that these promising results and our high-quality
open-source implementation will provide a tool for the robotics community to
facilitate further developments in robotic RL. Our code, documentation, and
videos can be found at https://serl-robot.github.io/
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16015" title="Abstract">arXiv:2401.16015</a> [<a href="/pdf/2401.16015" title="Download PDF">pdf</a>, <a href="/ps/2401.16015" title="Download PostScript">ps</a>, <a href="/format/2401.16015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Querying Fault and Attack Trees: Property Specification on a Water  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nicoletti%2C+S+M">Stefano M. Nicoletti</a>, 
<a href="/search/cs?searchtype=author&query=Lopuha%C3%A4-Zwakenberg%2C+M">Milan Lopuha&#xe4;-Zwakenberg</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+E+M">E. Moritz Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Stoelinga%2C+M">Mari&#xeb;lle Stoelinga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We provide an overview of three different query languages whose objective is
to specify properties on the highly popular formalisms of fault trees (FTs) and
attack trees (ATs). These are BFL, a Boolean Logic for FTs, PFL, a
probabilistic extension of BFL and ATM, a logic for security metrics on ATs. We
validate the framework composed by these three logics by applying them to the
case study of a water distribution network. We extend the FT for this network -
found in the literature - and we propose to model the system under analysis
with the Fault Trees/Attack Trees (FT/ATs) formalism, combining both FTs and
ATs in a unique model. Furthermore, we propose a novel combination of the
showcased logics to account for queries that jointly consider both the FT and
the AT of the model, integrating influences of attacks on failure probabilities
of different components. Finally, we extend the domain specific language for
PFL with novel constructs to capture the interplay between metrics of attacks -
e.g., "cost", success probabilities - and failure probabilities in the system.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16024" title="Abstract">arXiv:2401.16024</a> [<a href="/pdf/2401.16024" title="Download PDF">pdf</a>, <a href="/format/2401.16024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Abduction for Visual Abstract Reasoning via Learning Rules  in Vector-symbolic Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hersche%2C+M">Michael Hersche</a>, 
<a href="/search/cs?searchtype=author&query=di+Stefano%2C+F">Francesco di Stefano</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+T">Thomas Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Sebastian%2C+A">Abu Sebastian</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+A">Abbas Rahimi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023 Workshop on MATH-AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Abstract reasoning is a cornerstone of human intelligence, and replicating it
with artificial intelligence (AI) presents an ongoing challenge. This study
focuses on efficiently solving Raven's progressive matrices (RPM), a visual
test for assessing abstract reasoning abilities, by using distributed
computation and operators provided by vector-symbolic architectures (VSA).
Instead of hard-coding the rule formulations associated with RPMs, our approach
can learn the VSA rule formulations (hence the name Learn-VRF) with just one
pass through the training data. Yet, our approach, with compact parameters,
remains transparent and interpretable. Learn-VRF yields accurate predictions on
I-RAVEN's in-distribution data, and exhibits strong out-of-distribution
capabilities concerning unseen attribute-rule pairs, significantly
outperforming pure connectionist baselines including large language models. Our
code is available at
https://github.com/IBM/learn-vector-symbolic-architectures-rule-formulations.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16025" title="Abstract">arXiv:2401.16025</a> [<a href="/pdf/2401.16025" title="Download PDF">pdf</a>, <a href="/format/2401.16025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhengpeng Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">PPO (Proximal Policy Optimization) algorithm has demonstrated excellent
performance in many fields, and it is considered as a simple version of TRPO
(Trust Region Policy Optimization) algorithm. However, the ratio clipping
operation in PPO may not always effectively enforce the trust region
constraints, this can be a potential factor affecting the stability of the
algorithm. In this paper, we propose SPO (Simple Policy Optimization)
algorithm, which introduces a novel clipping method for KL divergence between
the old and current policies. SPO can effectively enforce the trust region
constraints in almost all environments, while still maintaining the simplicity
of a first-order algorithm. Comparative experiments in Atari 2600 environments
show that SPO sometimes provides stronger performance than PPO. Code is
available at https://github.com/MyRepositories-hub/Simple-Policy-Optimization.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16027" title="Abstract">arXiv:2401.16027</a> [<a href="/pdf/2401.16027" title="Download PDF">pdf</a>, <a href="/format/2401.16027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain adaptation strategies for 3D reconstruction of the lumbar spine  using real fluoroscopy data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jecklin%2C+S">Sascha Jecklin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Youyang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gout%2C+A">Amandine Gout</a>, 
<a href="/search/cs?searchtype=author&query=Suter%2C+D">Daniel Suter</a>, 
<a href="/search/cs?searchtype=author&query=Calvet%2C+L">Lilian Calvet</a>, 
<a href="/search/cs?searchtype=author&query=Zingg%2C+L">Lukas Zingg</a>, 
<a href="/search/cs?searchtype=author&query=Straub%2C+J">Jennifer Straub</a>, 
<a href="/search/cs?searchtype=author&query=Cavalcanti%2C+N+A">Nicola Alessandro Cavalcanti</a>, 
<a href="/search/cs?searchtype=author&query=Farshad%2C+M">Mazda Farshad</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%BCrnstahl%2C+P">Philipp F&#xfc;rnstahl</a>, 
<a href="/search/cs?searchtype=author&query=Esfandiari%2C+H">Hooman Esfandiari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study tackles key obstacles in adopting surgical navigation in
orthopedic surgeries, including time, cost, radiation, and workflow integration
challenges. Recently, our work X23D showed an approach for generating 3D
anatomical models of the spine from only a few intraoperative fluoroscopic
images. This negates the need for conventional registration-based surgical
navigation by creating a direct intraoperative 3D reconstruction of the
anatomy. Despite these strides, the practical application of X23D has been
limited by a domain gap between synthetic training data and real intraoperative
images.
<br />In response, we devised a novel data collection protocol for a paired dataset
consisting of synthetic and real fluoroscopic images from the same
perspectives. Utilizing this dataset, we refined our deep learning model via
transfer learning, effectively bridging the domain gap between synthetic and
real X-ray data. A novel style transfer mechanism also allows us to convert
real X-rays to mirror the synthetic domain, enabling our in-silico-trained X23D
model to achieve high accuracy in real-world settings.
<br />Our results demonstrated that the refined model can rapidly generate accurate
3D reconstructions of the entire lumbar spine from as few as three
intraoperative fluoroscopic shots. It achieved an 84% F1 score, matching the
accuracy of our previous synthetic data-based research. Additionally, with a
computational time of only 81.1 ms, our approach provides real-time
capabilities essential for surgery integration.
<br />Through examining ideal imaging setups and view angle dependencies, we've
further confirmed our system's practicality and dependability in clinical
settings. Our research marks a significant step forward in intraoperative 3D
reconstruction, offering enhancements to surgical planning, navigation, and
robotics.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16028" title="Abstract">arXiv:2401.16028</a> [<a href="/pdf/2401.16028" title="Download PDF">pdf</a>, <a href="/format/2401.16028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A blockchain-based e-goverment service for Quantity Surveyors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alcaide%2C+%C3%81+F">&#xc1;ngel F. Alcaide</a>, 
<a href="/search/cs?searchtype=author&query=N%C3%BAnez-G%C3%B3mez%2C+C">Carlos N&#xfa;nez-G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Delicado%2C+F+M">Francisco M. Delicado</a>, 
<a href="/search/cs?searchtype=author&query=Carri%C3%B3n%2C+C">Carmen Carri&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Caminero%2C+M+B">M. Blanca Caminero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In Spain, quantity surveyors are entitled to carry out official cadastral
surveys, attestations, and certificate issuing according to a well-defined
professional code. Official Associations of Quantity Surveyors and Technical
Architects (COAAT) are responsible for endorsing the documentation related to
actions performed on buildings. An e-platform that enables immutability,
traceability, and a unique property record among all the Spanish COAATs, with
an affordable cost, is essential to streamline the involved processes.
<br />The blockchain technology and smart contracts have recently emerged as
promising solutions for e-government services due to the inherent features
provided by the technology. In this paper, we identify the design goals and
propose a blockchain-based e-government system for the electronic management of
the documentation generated, submitted, and validated by the Spanish COAATs,
namely, the COAATChain. The proposal has been deployed and evaluated on the
Binance testnet blockchain, in order to assess its affordability.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16035" title="Abstract">arXiv:2401.16035</a> [<a href="/pdf/2401.16035" title="Download PDF">pdf</a>, <a href="/ps/2401.16035" title="Download PostScript">ps</a>, <a href="/format/2401.16035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Second Order Kinematic Surface Fitting in Anatomical Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wimmer%2C+W">Wilhelm Wimmer</a>, 
<a href="/search/cs?searchtype=author&query=Delingette%2C+H">Herv&#xe9; Delingette</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Symmetry detection and morphological classification of anatomical structures
play pivotal roles in medical image analysis. The application of kinematic
surface fitting, a method for characterizing shapes through parametric
stationary velocity fields, has shown promising results in computer vision and
computer-aided design. However, existing research has predominantly focused on
first order rotational velocity fields, which may not adequately capture the
intricate curved and twisted nature of anatomical structures. To address this
limitation, we propose an innovative approach utilizing a second order velocity
field for kinematic surface fitting. This advancement accommodates higher
rotational shape complexity and improves the accuracy of symmetry detection in
anatomical structures. We introduce a robust fitting technique and validate its
performance through testing on synthetic shapes and real anatomical structures.
Our method not only enables the detection of curved rotational symmetries (core
lines) but also facilitates morphological classification by deriving intrinsic
shape parameters related to curvature and torsion. We illustrate the usefulness
of our technique by categorizing the shape of human cochleae in terms of the
intrinsic velocity field parameters. The results showcase the potential of our
method as a valuable tool for medical image analysis, contributing to the
assessment of complex anatomical shapes.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16045" title="Abstract">arXiv:2401.16045</a> [<a href="/pdf/2401.16045" title="Download PDF">pdf</a>, <a href="/format/2401.16045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Type-based Neural Link Prediction Adapter for Complex Query Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lingning Song</a>, 
<a href="/search/cs?searchtype=author&query=Zu%2C+Y">Yi Zu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shan Lu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jieyue He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Answering complex logical queries on incomplete knowledge graphs (KGs) is a
fundamental and challenging task in multi-hop reasoning. Recent work defines
this task as an end-to-end optimization problem, which significantly reduces
the training cost and enhances the generalization of the model by a pretrained
link predictors for query answering. However, most existing proposals ignore
the critical semantic knowledge inherently available in KGs, such as type
information, which could help answer complex logical queries. To this end, we
propose TypE-based Neural Link Prediction Adapter (TENLPA), a novel model that
constructs type-based entity-relation graphs to discover the latent
relationships between entities and relations by leveraging type information in
KGs. Meanwhile, in order to effectively combine type information with complex
logical queries, an adaptive learning mechanism is introduced, which is trained
by back-propagating during the complex query answering process to achieve
adaptive adjustment of neural link predictors. Experiments on 3 standard
datasets show that TENLPA model achieves state-of-the-art performance on
complex query answering with good generalization and robustness.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16051" title="Abstract">arXiv:2401.16051</a> [<a href="/pdf/2401.16051" title="Download PDF">pdf</a>, <a href="/format/2401.16051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Prototype Adaptation with Distillation for Few-shot Point Cloud  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wenzhe Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haochen Wang</a>, 
<a href="/search/cs?searchtype=author&query=CHen%2C+Y">Yunlu CHen</a>, 
<a href="/search/cs?searchtype=author&query=Sonke%2C+J">Jan-Jakob Sonke</a>, 
<a href="/search/cs?searchtype=author&query=Gavves%2C+E">Efstratios Gavves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in 3DV2024, code is available at <a href="https://github.com/jliu4ai/DPA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot point cloud segmentation seeks to generate per-point masks for
previously unseen categories, using only a minimal set of annotated point
clouds as reference. Existing prototype-based methods rely on support
prototypes to guide the segmentation of query point clouds, but they encounter
challenges when significant object variations exist between the support
prototypes and query features. In this work, we present dynamic prototype
adaptation (DPA), which explicitly learns task-specific prototypes for each
query point cloud to tackle the object variation problem. DPA achieves the
adaptation through prototype rectification, aligning vanilla prototypes from
support with the query feature distribution, and prototype-to-query attention,
extracting task-specific context from query point clouds. Furthermore, we
introduce a prototype distillation regularization term, enabling knowledge
transfer between early-stage prototypes and their deeper counterparts during
adaption. By iteratively applying these adaptations, we generate task-specific
prototypes for accurate mask predictions on query point clouds. Extensive
experiments on two popular benchmarks show that DPA surpasses state-of-the-art
methods by a significant margin, e.g., 7.43\% and 6.39\% under the 2-way 1-shot
setting on S3DIS and ScanNet, respectively. Code is available at
https://github.com/jliu4ai/DPA.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16055" title="Abstract">arXiv:2401.16055</a> [<a href="/pdf/2401.16055" title="Download PDF">pdf</a>, <a href="/format/2401.16055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stolen Subwords: Importance of Vocabularies for Machine Translation  Model Stealing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zouhar%2C+V">Vil&#xe9;m Zouhar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In learning-based functionality stealing, the attacker is trying to build a
local model based on the victim's outputs. The attacker has to make choices
regarding the local model's architecture, optimization method and, specifically
for NLP models, subword vocabulary, such as BPE. On the machine translation
task, we explore (1) whether the choice of the vocabulary plays a role in model
stealing scenarios and (2) if it is possible to extract the victim's
vocabulary. We find that the vocabulary itself does not have a large effect on
the local model's performance. Given gray-box model access, it is possible to
collect the victim's vocabulary by collecting the outputs (detokenized subwords
on the output). The results of the minimum effect of vocabulary choice are
important more broadly for black-box knowledge distillation.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16058" title="Abstract">arXiv:2401.16058</a> [<a href="/pdf/2401.16058" title="Download PDF">pdf</a>, <a href="/format/2401.16058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuromorphic Valence and Arousal Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berlincioni%2C+L">Lorenzo Berlincioni</a>, 
<a href="/search/cs?searchtype=author&query=Cultrera%2C+L">Luca Cultrera</a>, 
<a href="/search/cs?searchtype=author&query=Becattini%2C+F">Federico Becattini</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bimbo%2C+A">Alberto Del Bimbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Journal of Ambient Intelligence and Humanized Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recognizing faces and their underlying emotions is an important aspect of
biometrics. In fact, estimating emotional states from faces has been tackled
from several angles in the literature. In this paper, we follow the novel route
of using neuromorphic data to predict valence and arousal values from faces.
Due to the difficulty of gathering event-based annotated videos, we leverage an
event camera simulator to create the neuromorphic counterpart of an existing
RGB dataset. We demonstrate that not only training models on simulated data can
still yield state-of-the-art results in valence-arousal estimation, but also
that our trained models can be directly applied to real data without further
training to address the downstream task of emotion recognition. In the paper we
propose several alternative models to solve the task, both frame-based and
video-based.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16063" title="Abstract">arXiv:2401.16063</a> [<a href="/pdf/2401.16063" title="Download PDF">pdf</a>, <a href="/ps/2401.16063" title="Download PostScript">ps</a>, <a href="/format/2401.16063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shannon Capacity of Channels with Markov Insertions, Deletions and  Substitutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morozov%2C+R">Ruslan Morozov</a>, 
<a href="/search/cs?searchtype=author&query=Duman%2C+T+M">Tolga M. Duman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We consider channels with synchronization errors modeled as insertions and
deletions. A classical result for such channels is the information stability of
such channels, hence the existence of the Shannon capacity, when the
synchronization errors are memoryless. In this paper, we extend this result to
the case where the insertions and deletions have memory. Specifically, we
assume that the synchronization errors are governed by a stationary and ergodic
finite state Markov chain, and prove that mutual information capacity of such
channels exist, and it is equal to its coding capacity, showing that there
exists a coding scheme which achieves this limit.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16072" title="Abstract">arXiv:2401.16072</a> [<a href="/pdf/2401.16072" title="Download PDF">pdf</a>, <a href="/ps/2401.16072" title="Download PostScript">ps</a>, <a href="/format/2401.16072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A symmetric silicon microring resonator optical crossbar array for  accelerated inference and training in deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Rui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ohno%2C+S">Shuhei Ohno</a>, 
<a href="/search/cs?searchtype=author&query=Tanizawa%2C+K">Ken Tanizawa</a>, 
<a href="/search/cs?searchtype=author&query=Ikeda%2C+K">Kazuhiro Ikeda</a>, 
<a href="/search/cs?searchtype=author&query=Okano%2C+M">Makoto Okano</a>, 
<a href="/search/cs?searchtype=author&query=Toprasertpong%2C+K">Kasidit Toprasertpong</a>, 
<a href="/search/cs?searchtype=author&query=Takagi%2C+S">Shinichi Takagi</a>, 
<a href="/search/cs?searchtype=author&query=Takenaka%2C+M">Mitsuru Takenaka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Optics (physics.optics)

</div>
<p class="mathjax">Photonic integrated circuits are emerging as a promising platform for
accelerating matrix multiplications in deep learning, leveraging the inherent
parallel nature of light. Although various schemes have been proposed and
demonstrated to realize such photonic matrix accelerators, the in-situ training
of artificial neural networks using photonic accelerators remains challenging
due to the difficulty of direct on-chip backpropagation on a photonic chip. In
this work, we propose a silicon microring resonator (MRR) optical crossbar
array with a symmetric structure that allows for simple on-chip
backpropagation, potentially enabling the acceleration of both the inference
and training phases of deep learning. We demonstrate a 4 $\times$ 4 circuit on
a Si-on-insulator (SOI) platform and use it to perform inference tasks of a
simple neural network for classifying Iris flowers, achieving a classification
accuracy of 93.3%. Furthermore, we train the neural network using simulated
on-chip backpropagation and achieve an accuracy of 91.1% in the same inference
task after training. This work contributes to the realization of compact and
energy-efficient photonic accelerators for deep learning.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16076" title="Abstract">arXiv:2401.16076</a> [<a href="/pdf/2401.16076" title="Download PDF">pdf</a>, <a href="/format/2401.16076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Find the Cliffhanger: Multi-Modal Trailerness in Soap Operas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bretti%2C+C">Carlo Bretti</a>, 
<a href="/search/cs?searchtype=author&query=Mettes%2C+P">Pascal Mettes</a>, 
<a href="/search/cs?searchtype=author&query=Koops%2C+H+V">Hendrik Vincent Koops</a>, 
<a href="/search/cs?searchtype=author&query=Odijk%2C+D">Daan Odijk</a>, 
<a href="/search/cs?searchtype=author&query=van+Noord%2C+N">Nanne van Noord</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MMM24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Creating a trailer requires carefully picking out and piecing together brief
enticing moments out of a longer video, making it a chal- lenging and
time-consuming task. This requires selecting moments based on both visual and
dialogue information. We introduce a multi-modal method for predicting the
trailerness to assist editors in selecting trailer- worthy moments from
long-form videos. We present results on a newly introduced soap opera dataset,
demonstrating that predicting trailerness is a challenging task that benefits
from multi-modal information. Code is available at
https://github.com/carlobretti/cliffhanger
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16078" title="Abstract">arXiv:2401.16078</a> [<a href="/pdf/2401.16078" title="Download PDF">pdf</a>, <a href="/format/2401.16078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the effects of word-level linguistic annotations in  under-resourced neural machine translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Cartagena%2C+V+M">V&#xed;ctor M. S&#xe1;nchez-Cartagena</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Ortiz%2C+J+A">Juan Antonio P&#xe9;rez-Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Mart%C3%ADnez%2C+F">Felipe S&#xe1;nchez-Mart&#xed;nez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Understanding the effects of word-level linguistic annotations in
  under-resourced neural machine translation (S\'anchez-Cartagena et al.,
  COLING 2020)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper studies the effects of word-level linguistic annotations in
under-resourced neural machine translation, for which there is incomplete
evidence in the literature. The study covers eight language pairs, different
training corpus sizes, two architectures, and three types of annotation: dummy
tags (with no linguistic information at all), part-of-speech tags, and
morpho-syntactic description tags, which consist of part of speech and
morphological features. These linguistic annotations are interleaved in the
input or output streams as a single tag placed before each word. In order to
measure the performance under each scenario, we use automatic evaluation
metrics and perform automatic error classification. Our experiments show that,
in general, source-language annotations are helpful and morpho-syntactic
descriptions outperform part of speech for some language pairs. On the
contrary, when words are annotated in the target language, part-of-speech tags
systematically outperform morpho-syntactic description tags in terms of
automatic evaluation metrics, even though the use of morpho-syntactic
description tags improves the grammaticality of the output. We provide a
detailed analysis of the reasons behind this result.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16086" title="Abstract">arXiv:2401.16086</a> [<a href="/pdf/2401.16086" title="Download PDF">pdf</a>, <a href="/format/2401.16086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Fluent Synthetic Target-Language Data Improve Neural Machine  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Cartagena%2C+V+M">V&#xed;ctor M. S&#xe1;nchez-Cartagena</a>, 
<a href="/search/cs?searchtype=author&query=Espl%C3%A0-Gomis%2C+M">Miquel Espl&#xe0;-Gomis</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Ortiz%2C+J+A">Juan Antonio P&#xe9;rez-Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Mart%C3%ADnez%2C+F">Felipe S&#xe1;nchez-Mart&#xed;nez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2109.03645">arXiv:2109.03645</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Pattern Analysis and Machine Intelligence (
  Volume: 46, Issue: 2, February 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">When the amount of parallel sentences available to train a neural machine
translation is scarce, a common practice is to generate new synthetic training
samples from them. A number of approaches have been proposed to produce
synthetic parallel sentences that are similar to those in the parallel data
available. These approaches work under the assumption that non-fluent
target-side synthetic training samples can be harmful and may deteriorate
translation performance. Even so, in this paper we demonstrate that synthetic
training samples with non-fluent target sentences can improve translation
performance if they are used in a multilingual machine translation framework as
if they were sentences in another language. We conducted experiments on ten
low-resource and four high-resource translation tasks and found out that this
simple approach consistently improves translation performance as compared to
state-of-the-art methods for generating synthetic training samples similar to
those found in corpora. Furthermore, this improvement is independent of the
size of the original training corpus, the resulting systems are much more
robust against domain shift and produce less hallucinations.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16087" title="Abstract">arXiv:2401.16087</a> [<a href="/pdf/2401.16087" title="Download PDF">pdf</a>, <a href="/format/2401.16087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Resolution Image Quality Database
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Q">Qiang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Korhonen%2C+J">Jari Korhonen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">With technology for digital photography and high resolution displays rapidly
evolving and gaining popularity, there is a growing demand for blind image
quality assessment (BIQA) models for high resolution images. Unfortunately, the
publicly available large scale image quality databases used for training BIQA
models contain mostly low or general resolution images. Since image resizing
affects image quality, we assume that the accuracy of BIQA models trained on
low resolution images would not be optimal for high resolution images.
Therefore, we created a new high resolution image quality database (HRIQ),
consisting of 1120 images with resolution of 2880x2160 pixels. We conducted a
subjective study to collect the subjective quality ratings for HRIQ in a
controlled laboratory setting, resulting in accurate MOS at high resolution. To
demonstrate the importance of a high resolution image quality database for
training BIQA models to predict mean opinion scores (MOS) of high resolution
images accurately, we trained and tested several traditional and deep learning
based BIQA methods on different resolution versions of our database. The
database is publicly available in https://github.com/jarikorhonen/hriq.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16088" title="Abstract">arXiv:2401.16088</a> [<a href="/pdf/2401.16088" title="Download PDF">pdf</a>, <a href="/format/2401.16088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness in Algorithmic Recourse Through the Lens of Substantive  Equality of Opportunity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bell%2C+A">Andrew Bell</a>, 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+J">Joao Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Abrate%2C+C">Carlo Abrate</a>, 
<a href="/search/cs?searchtype=author&query=Bonchi%2C+F">Francesco Bonchi</a>, 
<a href="/search/cs?searchtype=author&query=Stoyanovich%2C+J">Julia Stoyanovich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Algorithmic recourse -- providing recommendations to those affected
negatively by the outcome of an algorithmic system on how they can take action
and change that outcome -- has gained attention as a means of giving persons
agency in their interactions with artificial intelligence (AI) systems. Recent
work has shown that even if an AI decision-making classifier is ``fair''
(according to some reasonable criteria), recourse itself may be unfair due to
differences in the initial circumstances of individuals, compounding
disparities for marginalized populations and requiring them to exert more
effort than others. There is a need to define more methods and metrics for
evaluating fairness in recourse that span a range of normative views of the
world, and specifically those that take into account time. Time is a critical
element in recourse because the longer it takes an individual to act, the more
the setting may change due to model or data drift.
<br />This paper seeks to close this research gap by proposing two notions of
fairness in recourse that are in normative alignment with substantive equality
of opportunity, and that consider time. The first considers the (often
repeated) effort individuals exert per successful recourse event, and the
second considers time per successful recourse event. Building upon an
agent-based framework for simulating recourse, this paper demonstrates how much
effort is needed to overcome disparities in initial circumstances. We then
proposes an intervention to improve the fairness of recourse by rewarding
effort, and compare it to existing strategies.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16092" title="Abstract">arXiv:2401.16092</a> [<a href="/pdf/2401.16092" title="Download PDF">pdf</a>, <a href="/format/2401.16092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and  Prompt Engineering May Not Help You
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+F">Felix Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4mmerl%2C+K">Katharina H&#xe4;mmerl</a>, 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=Libovicky%2C+J">Jindrich Libovicky</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>, 
<a href="/search/cs?searchtype=author&query=Fraser%2C+A">Alexander Fraser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Text-to-image generation models have recently achieved astonishing results in
image quality, flexibility, and text alignment and are consequently employed in
a fast-growing number of applications. Through improvements in multilingual
abilities, a larger community now has access to this kind of technology. Yet,
as we will show, multilingual models suffer similarly from (gender) biases as
monolingual models. Furthermore, the natural expectation is that these models
will provide similar results across languages, but this is not the case and
there are important differences between languages. Thus, we propose a novel
benchmark MAGBIG intending to foster research in multilingual models without
gender bias. We investigate whether multilingual T2I models magnify gender bias
with MAGBIG. To this end, we use multilingual prompts requesting portrait
images of persons of a certain occupation or trait (using adjectives). Our
results show not only that models deviate from the normative assumption that
each gender should be equally likely to be generated, but that there are also
big differences across languages. Furthermore, we investigate prompt
engineering strategies, i.e. the use of indirect, neutral formulations, as a
possible remedy for these biases. Unfortunately, they help only to a limited
extent and result in worse text-to-image alignment. Consequently, this work
calls for more research into diverse representations across languages in image
generators.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16094" title="Abstract">arXiv:2401.16094</a> [<a href="/pdf/2401.16094" title="Download PDF">pdf</a>, <a href="/format/2401.16094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated unsupervised random forest for privacy-preserving patient  stratification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pfeifer%2C+B">Bastian Pfeifer</a>, 
<a href="/search/cs?searchtype=author&query=Sirocchi%2C+C">Christel Sirocchi</a>, 
<a href="/search/cs?searchtype=author&query=Bloice%2C+M+D">Marcus D. Bloice</a>, 
<a href="/search/cs?searchtype=author&query=Kreuzthaler%2C+M">Markus Kreuzthaler</a>, 
<a href="/search/cs?searchtype=author&query=Urschler%2C+M">Martin Urschler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">In the realm of precision medicine, effective patient stratification and
disease subtyping demand innovative methodologies tailored for multi-omics
data. Clustering techniques applied to multi-omics data have become
instrumental in identifying distinct subgroups of patients, enabling a
finer-grained understanding of disease variability. This work establishes a
powerful framework for advancing precision medicine through unsupervised
random-forest-based clustering and federated computing. We introduce a novel
multi-omics clustering approach utilizing unsupervised random-forests. The
unsupervised nature of the random forest enables the determination of
cluster-specific feature importance, unraveling key molecular contributors to
distinct patient groups. Moreover, our methodology is designed for federated
execution, a crucial aspect in the medical domain where privacy concerns are
paramount. We have validated our approach on machine learning benchmark data
sets as well as on cancer data from The Cancer Genome Atlas (TCGA). Our method
is competitive with the state-of-the-art in terms of disease subtyping, but at
the same time substantially improves the cluster interpretability. Experiments
indicate that local clustering performance can be improved through federated
computing.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16095" title="Abstract">arXiv:2401.16095</a> [<a href="/pdf/2401.16095" title="Download PDF">pdf</a>, <a href="/ps/2401.16095" title="Download PostScript">ps</a>, <a href="/format/2401.16095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Separability Problem of VASS Reachability Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keskin%2C+E">Eren Keskin</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+R">Roland Meyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">We show that the regular separability problem of VASS reachability languages
is decidable and $\mathbf{F}_{\omega}$-complete. At the heart of our decision
procedure are doubly-marked graph transition sequences, a new proof object that
tracks a suitable product of the VASS we wish to separate. We give a
decomposition algorithm for DMGTS that not only achieves perfectness as known
from MGTS, but also a new property called faithfulness. Faithfulness allows us
to construct, from a regular separator for the $\mathbb{Z}$-versions of the
VASS, a regular separator for the $\mathbb{N}$-versions. Behind faithfulness is
the insight that, for separability, it is sufficient to track the counters of
one VASS modulo a large number that is determined by the decomposition.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16097" title="Abstract">arXiv:2401.16097</a> [<a href="/pdf/2401.16097" title="Download PDF">pdf</a>, <a href="/format/2401.16097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing the Limits: Concurrency Detection in Acyclic, Live, and 1-Safe  Free-Choice Nets in $O\big((P + T)^2\big)$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prinz%2C+T+M">Thomas M. Prinz</a>, 
<a href="/search/cs?searchtype=author&query=Klaus%2C+J">Julien Klaus</a>, 
<a href="/search/cs?searchtype=author&query=van+Beest%2C+N+R+T+P">Nick R.T.P. van Beest</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 14 figures, 4 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Information Retrieval (cs.IR); Software Engineering (cs.SE)

</div>
<p class="mathjax">Concurrency is an important aspect of (Petri) nets to describe and simulate
the behavior of complex systems. Knowing which places and transitions could be
executed in parallel helps to understand nets and enables analysis techniques
and the computation of other properties, such as causality, exclusivity, etc..
All techniques based on concurrency detection depend on the efficiency of this
detection methodology. Kovalyov and Esparza have developed algorithms that
compute all concurrent places in $O\big((P+T)TP^2\big)$ for live nets (where
$P$ and $T$ are the numbers of places and transitions) and in
$O\big(P(P+T)^2\big)$ for live free-choice nets. Although these algorithms have
a reasonably good computational complexity, large numbers of concurrent pairs
of nodes may still lead to long computation times. Furthermore, both algorithms
cannot be parallelized without additional effort. This paper complements the
palette of concurrency detection algorithms with the Concurrent Paths (CP)
algorithm for safe, live, free-choice nets. The algorithm allows
parallelization and has a worst-case computational complexity of
$O\big((P+T)^2\big)$ for acyclic nets and of $O\big(P^3+PT^2\big)$ for cyclic
nets. Although the computational complexity of cyclic nets has not improved,
the evaluation shows the benefits of CP, especially, if the net contains many
nodes in concurrency relation.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16102" title="Abstract">arXiv:2401.16102</a> [<a href="/pdf/2401.16102" title="Download PDF">pdf</a>, <a href="/format/2401.16102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Parallel Neural Network Architecture Model for Early Prediction  of Lithium Battery Life
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lidang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuoxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Changyan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingsong Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+G">Ge He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The early prediction of battery life (EPBL) is vital for enhancing the
efficiency and extending the lifespan of lithium batteries. Traditional models
with fixed architectures often encounter underfitting or overfitting issues due
to the diverse data distributions in different EPBL tasks. An interpretable
deep learning model of flexible parallel neural network (FPNN) is proposed,
which includes an InceptionBlock, a 3D convolutional neural network (CNN), a 2D
CNN, and a dual-stream network. The proposed model effectively extracts
electrochemical features from video-like formatted data using the 3D CNN and
achieves advanced multi-scale feature abstraction through the InceptionBlock.
The FPNN can adaptively adjust the number of InceptionBlocks to flexibly handle
tasks of varying complexity in EPBL. The test on the MIT dataset shows that the
FPNN model achieves outstanding predictive accuracy in EPBL tasks, with MAPEs
of 2.47%, 1.29%, 1.08%, and 0.88% when the input cyclic data volumes are 10,
20, 30, and 40, respectively. The interpretability of the FPNN is mainly
reflected in its flexible unit structure and parameter selection: its diverse
branching structure enables the model to capture features at different scales,
thus allowing the machine to learn informative features. The approach presented
herein provides an accurate, adaptable, and comprehensible solution for early
life prediction of lithium batteries, opening new possibilities in the field of
battery health monitoring.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16104" title="Abstract">arXiv:2401.16104</a> [<a href="/pdf/2401.16104" title="Download PDF">pdf</a>, <a href="/format/2401.16104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A 2D Sinogram-Based Approach to Defect Localization in Computed  Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuzhong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+L">Linda-Sophie Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+F">Fuxin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+A">Andreas Maier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The rise of deep learning has introduced a transformative era in the field of
image processing, particularly in the context of computed tomography. Deep
learning has made a significant contribution to the field of industrial
Computed Tomography. However, many defect detection algorithms are applied
directly to the reconstructed domain, often disregarding the raw sensor data.
This paper shifts the focus to the use of sinograms. Within this framework, we
present a comprehensive three-step deep learning algorithm, designed to
identify and analyze defects within objects without resorting to image
reconstruction. These three steps are defect segmentation, mask isolation, and
defect analysis. We use a U-Net-based architecture for defect segmentation. Our
method achieves the Intersection over Union of 92.02% on our simulated data,
with an average position error of 1.3 pixels for defect detection on a
512-pixel-wide detector.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16107" title="Abstract">arXiv:2401.16107</a> [<a href="/pdf/2401.16107" title="Download PDF">pdf</a>, <a href="/format/2401.16107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation  for Automatic Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haochun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sendong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+Z">Zewen Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+N">Nuwa Xi</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Automatic diagnosis is a significant application of AI in healthcare, where
diagnoses are generated based on the symptom description of patients. Previous
works have approached this task directly by modeling the relationship between
the normalized symptoms and all possible diseases. However, in the clinical
diagnostic process, patients are initially consulted by a general practitioner
and, if necessary, referred to specialists in specific domains for a more
comprehensive evaluation. The final diagnosis often emerges from a
collaborative consultation among medical specialist groups. Recently, large
language models have shown impressive capabilities in natural language
understanding. In this study, we adopt tuning-free LLM-based agents as medical
practitioners and propose the Agent-derived Multi-Specialist Consultation
(AMSC) framework to model the diagnosis process in the real world by adaptively
fusing probability distributions of agents over potential diseases.
Experimental results demonstrate the superiority of our approach compared with
baselines. Notably, our approach requires significantly less parameter updating
and training time, enhancing efficiency and practical utility. Furthermore, we
delve into a novel perspective on the role of implicit symptoms within the
context of automatic diagnosis.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16108" title="Abstract">arXiv:2401.16108</a> [<a href="/pdf/2401.16108" title="Download PDF">pdf</a>, <a href="/format/2401.16108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Future Impact Decomposition in Request-level Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaobei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuchang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Q">Qingpeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lantao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Han Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Guangming Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In recommender systems, reinforcement learning solutions have shown promising
results in optimizing the interaction sequence between users and the system
over the long-term performance. For practical reasons, the policy's actions are
typically designed as recommending a list of items to handle users' frequent
and continuous browsing requests more efficiently. In this list-wise
recommendation scenario, the user state is updated upon every request in the
corresponding MDP formulation. However, this request-level formulation is
essentially inconsistent with the user's item-level behavior. In this study, we
demonstrate that an item-level optimization approach can better utilize item
characteristics and optimize the policy's performance even under the
request-level MDP. We support this claim by comparing the performance of
standard request-level methods with the proposed item-level actor-critic
framework in both simulation and online experiments. Furthermore, we found that
the naive equal decomposition of future values may not effectively express the
item-wise utility in the long term. To address this issue, we propose a future
decomposition strategy based on each item's immediate reward, and further show
that we can obtain more advanced settings of weight through adversarial
learning.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16109" title="Abstract">arXiv:2401.16109</a> [<a href="/pdf/2401.16109" title="Download PDF">pdf</a>, <a href="/format/2401.16109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimalistic System Modelling: Behaviours, Interfaces, and Local  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galmiche%2C+D">Didier Galmiche</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+T">Timo Lang</a>, 
<a href="/search/cs?searchtype=author&query=Pym%2C+D">David Pym</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The infrastructure upon which the functioning of society depends is composed
of complex ecosystems of systems. Consequently, we must reason about the
properties of such ecosystems, which requires that we construct models of them.
There are very many approaches to systems modelling, typically building on
complex structural and dynamic frameworks. Our purpose here is to explore a
modelling framework based on minimal assumptions, starting from a primitive
notion of behaviour, and to show that such an approach allows the recovery of
the key ideas, including a generalized CAP theorem, required for effective
modelling of and reasoning about ecosystems of systems. We establish a logic of
behaviours and use it to express local reasoning principles for the
compositional structure of systems.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16110" title="Abstract">arXiv:2401.16110</a> [<a href="/pdf/2401.16110" title="Download PDF">pdf</a>, <a href="/format/2401.16110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Scenario Generalization for Vision-based Roadside 3D Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chuang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+L">Li Ju</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Roadside perception can greatly increase the safety of autonomous vehicles by
extending their perception ability beyond the visual range and addressing blind
spots. However, current state-of-the-art vision-based roadside detection
methods possess high accuracy on labeled scenes but have inferior performance
on new scenes. This is because roadside cameras remain stationary after
installation and can only collect data from a single scene, resulting in the
algorithm overfitting these roadside backgrounds and camera poses. To address
this issue, in this paper, we propose an innovative Scenario Generalization
Framework for Vision-based Roadside 3D Object Detection, dubbed SGV3D.
Specifically, we employ a Background-suppressed Module (BSM) to mitigate
background overfitting in vision-centric pipelines by attenuating background
features during the 2D to bird's-eye-view projection. Furthermore, by
introducing the Semi-supervised Data Generation Pipeline (SSDG) using unlabeled
images from new scenes, diverse instance foregrounds with varying camera poses
are generated, addressing the risk of overfitting specific camera poses. We
evaluate our method on two large-scale roadside benchmarks. Our method
surpasses all previous methods by a significant margin in new scenes, including
+42.57% for vehicle, +5.87% for pedestrian, and +14.89% for cyclist compared to
BEVHeight on the DAIR-V2X-I heterologous benchmark. On the larger-scale Rope3D
heterologous benchmark, we achieve notable gains of 14.48% for car and 12.41%
for large vehicle. We aspire to contribute insights on the exploration of
roadside perception techniques, emphasizing their capability for scenario
generalization. The code will be available at {\url{
https://github.com/yanglei18/SGV3D}}
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16113" title="Abstract">arXiv:2401.16113</a> [<a href="/pdf/2401.16113" title="Download PDF">pdf</a>, <a href="/ps/2401.16113" title="Download PostScript">ps</a>, <a href="/format/2401.16113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A parallel preconditioner for the all-at-once linear system from  evolutionary PDEs with Crank-Nicolson discretization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+Y">Yong-Liang Zhao</a>, 
<a href="/search/math?searchtype=author&query=Gu%2C+X">Xian-Ming Gu</a>, 
<a href="/search/math?searchtype=author&query=Oosterlee%2C+C+W">Cornelis W. Oosterlee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Crank-Nicolson (CN) method is a well-known time integrator for
evolutionary partial differential equations (PDEs) arising in many real-world
applications. Since the solution at any time depends on the solution at
previous time steps, the CN method will be inherently difficult to parallelize.
In this paper, we consider a parallel method for the solution of evolutionary
PDEs with the CN scheme. Using an all-at-once approach, we can solve for all
time steps simultaneously using a parallelizable over time preconditioner
within a standard iterative method. Due to the diagonalization of the proposed
preconditioner, we can prove that most eigenvalues of preconditioned matrices
are equal to 1 and the others lie in the set: $\left\{z\in\mathbb{C}: 1/(1 +
\alpha) &lt; |z| &lt; 1/(1 - \alpha)~{\rm and}~\Re{e}(z) &gt; 0\right\}$, where $0 &lt;
\alpha &lt; 1$ is a free parameter. Meanwhile, the efficient implementation of
this proposed preconditioner is described and a mesh-independent convergence
rate of the preconditioned GMRES method is derived under certain conditions.
Finally, we will verify our theoretical findings via numerical experiments on
financial option pricing partial differential equations.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16119" title="Abstract">arXiv:2401.16119</a> [<a href="/pdf/2401.16119" title="Download PDF">pdf</a>, <a href="/format/2401.16119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triple Disentangled Representation Learning for Multimodal Affective  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Ying Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xuefeng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Han Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Multimodal learning has exhibited a significant advantage in affective
analysis tasks owing to the comprehensive information of various modalities,
particularly the complementary information. Thus, many emerging studies focus
on disentangling the modality-invariant and modality-specific representations
from input data and then fusing them for prediction. However, our study shows
that modality-specific representations may contain information that is
irrelevant or conflicting with the tasks, which downgrades the effectiveness of
learned multimodal representations. We revisit the disentanglement issue, and
propose a novel triple disentanglement approach, TriDiRA, which disentangles
the modality-invariant, effective modality-specific and ineffective
modality-specific representations from input data. By fusing only the
modality-invariant and effective modality-specific representations, TriDiRA can
significantly alleviate the impact of irrelevant and conflicting information
across modalities during model training. Extensive experiments conducted on
four benchmark datasets demonstrate the effectiveness and generalization of our
triple disentanglement, which outperforms SOTA methods.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16122" title="Abstract">arXiv:2401.16122</a> [<a href="/pdf/2401.16122" title="Download PDF">pdf</a>, <a href="/format/2401.16122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeFlow: Decoder of Scene Flow Network in Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Heng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+R">Ruoyu Geng</a>, 
<a href="/search/cs?searchtype=author&query=Jensfelt%2C+P">Patric Jensfelt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, Code check <a href="https://github.com/KTH-RPL/deflow">this https URL</a>, accepted by ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Scene flow estimation determines a scene's 3D motion field, by predicting the
motion of points in the scene, especially for aiding tasks in autonomous
driving. Many networks with large-scale point clouds as input use voxelization
to create a pseudo-image for real-time running. However, the voxelization
process often results in the loss of point-specific features. This gives rise
to a challenge in recovering those features for scene flow tasks. Our paper
introduces DeFlow which enables a transition from voxel-based features to point
features using Gated Recurrent Unit (GRU) refinement. To further enhance scene
flow estimation performance, we formulate a novel loss function that accounts
for the data imbalance between static and dynamic points. Evaluations on the
Argoverse 2 scene flow task reveal that DeFlow achieves state-of-the-art
results on large-scale point cloud data, demonstrating that our network has
better performance and efficiency compared to others. The code is open-sourced
at https://github.com/KTH-RPL/deflow.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16123" title="Abstract">arXiv:2401.16123</a> [<a href="/pdf/2401.16123" title="Download PDF">pdf</a>, <a href="/format/2401.16123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Looking for a better fit? An Incremental Learning Multimodal Object  Referencing Framework adapting to Individual Drivers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomaa%2C+A">Amr Gomaa</a>, 
<a href="/search/cs?searchtype=author&query=Reyes%2C+G">Guillermo Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Feld%2C+M">Michael Feld</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+A">Antonio Kr&#xfc;ger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the Proceedings of the 29th International Conference on Intelligent User Interfaces (IUI'24), March 18--21, 2024, in Greenville, SC, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The rapid advancement of the automotive industry towards automated and
semi-automated vehicles has rendered traditional methods of vehicle
interaction, such as touch-based and voice command systems, inadequate for a
widening range of non-driving related tasks, such as referencing objects
outside of the vehicle. Consequently, research has shifted toward gestural
input (e.g., hand, gaze, and head pose gestures) as a more suitable mode of
interaction during driving. However, due to the dynamic nature of driving and
individual variation, there are significant differences in drivers' gestural
input performance. While, in theory, this inherent variability could be
moderated by substantial data-driven machine learning models, prevalent
methodologies lean towards constrained, single-instance trained models for
object referencing. These models show a limited capacity to continuously adapt
to the divergent behaviors of individual drivers and the variety of driving
scenarios. To address this, we propose \textit{IcRegress}, a novel
regression-based incremental learning approach that adapts to changing behavior
and the unique characteristics of drivers engaged in the dual task of driving
and referencing objects. We suggest a more personalized and adaptable solution
for multimodal gestural interfaces, employing continuous lifelong learning to
enhance driver experience, safety, and convenience. Our approach was evaluated
using an outside-the-vehicle object referencing use case, highlighting the
superiority of the incremental learning models adapted over a single trained
model across various driver traits such as handedness, driving experience, and
numerous driving conditions. Finally, to facilitate reproducibility, ease
deployment, and promote further research, we offer our approach as an
open-source framework at \url{https://github.com/amrgomaaelhady/IcRegress}.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16124" title="Abstract">arXiv:2401.16124</a> [<a href="/pdf/2401.16124" title="Download PDF">pdf</a>, <a href="/format/2401.16124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the generalization of learned constraints for ASP solving in temporal  domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+J">Javier Romero</a>, 
<a href="/search/cs?searchtype=author&query=Schaub%2C+T">Torsten Schaub</a>, 
<a href="/search/cs?searchtype=author&query=Strauch%2C+K">Klaus Strauch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The representation of a dynamic problem in ASP usually boils down to using
copies of variables and constraints, one for each time stamp, no matter whether
it is directly encoded or via an action or temporal language. The
multiplication of variables and constraints is commonly done during grounding
and the solver is completely ignorant about the temporal relationship among the
different instances. On the other hand, a key factor in the performance of
today's ASP solvers is conflict-driven constraint learning. Our question is now
whether a constraint learned for particular time steps can be generalized and
reused at other time stamps, and ultimately whether this enhances the overall
solver performance on temporal problems. Knowing full well the domain of time,
we study conditions under which learned dynamic constraints can be generalized.
We propose a simple translation of the original logic program such that, for
the translated programs, the learned constraints can be generalized to other
time points. Additionally, we identify a property of temporal problems that
allows us to generalize all learned constraints to all time steps. It turns out
that this property is satisfied by many planning problems. Finally, we
empirically evaluate the impact of adding the generalized constraints to an ASP
solver
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16130" title="Abstract">arXiv:2401.16130</a> [<a href="/pdf/2401.16130" title="Download PDF">pdf</a>, <a href="/format/2401.16130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A polytopal discrete de Rham complex on manifolds, with application to  the Maxwell equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Droniou%2C+J">J&#xe9;r&#xf4;me Droniou</a>, 
<a href="/search/math?searchtype=author&query=Hanot%2C+M">Marien Hanot</a>, 
<a href="/search/math?searchtype=author&query=Oliynyk%2C+T">Todd Oliynyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We design in this work a discrete de Rham complex on manifolds. This complex,
written in the framework of exterior calculus, is applicable on meshes on the
manifold with generic elements, and has the same cohomology as the continuous
de Rham complex. Notions of local (full and trimmed) polynomial spaces are
developed, with compatibility requirements between polynomials on mesh entities
of various dimensions. Explicit examples of polynomials spaces are presented.
The discrete de Rham complex is then used to set up a scheme for the Maxwell
equations on a 2D manifold without boundary, and we show that a natural
discrete version of the constraint linking the electric field and the electric
charge density is satisfied. Numerical examples are provided on the sphere and
the torus, based on a bespoke analytical solution and mesh design on each
manifold.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16131" title="Abstract">arXiv:2401.16131</a> [<a href="/pdf/2401.16131" title="Download PDF">pdf</a>, <a href="/format/2401.16131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CIMIL-CRC: a clinically-informed multiple instance learning framework  for patient-level colorectal cancer molecular subtypes classification from  H\&amp;E stained images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hezi%2C+H">Hadar Hezi</a>, 
<a href="/search/cs?searchtype=author&query=Gelber%2C+M">Matan Gelber</a>, 
<a href="/search/cs?searchtype=author&query=Balabanov%2C+A">Alexander Balabanov</a>, 
<a href="/search/cs?searchtype=author&query=Maruvka%2C+Y+E">Yosef E. Maruvka</a>, 
<a href="/search/cs?searchtype=author&query=Freiman%2C+M">Moti Freiman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Treatment approaches for colorectal cancer (CRC) are highly dependent on the
molecular subtype, as immunotherapy has shown efficacy in cases with
microsatellite instability (MSI) but is ineffective for the microsatellite
stable (MSS) subtype. There is promising potential in utilizing deep neural
networks (DNNs) to automate the differentiation of CRC subtypes by analyzing
Hematoxylin and Eosin (H\&amp;E) stained whole-slide images (WSIs). Due to the
extensive size of WSIs, Multiple Instance Learning (MIL) techniques are
typically explored. However, existing MIL methods focus on identifying the most
representative image patches for classification, which may result in the loss
of critical information. Additionally, these methods often overlook clinically
relevant information, like the tendency for MSI class tumors to predominantly
occur on the proximal (right side) colon. We introduce `CIMIL-CRC', a DNN
framework that: 1) solves the MSI/MSS MIL problem by efficiently combining a
pre-trained feature extraction model with principal component analysis (PCA) to
aggregate information from all patches, and 2) integrates clinical priors,
particularly the tumor location within the colon, into the model to enhance
patient-level classification accuracy. We assessed our CIMIL-CRC method using
the average area under the curve (AUC) from a 5-fold cross-validation
experimental setup for model development on the TCGA-CRC-DX cohort, contrasting
it with a baseline patch-level classification, MIL-only approach, and
Clinically-informed patch-level classification approach. Our CIMIL-CRC
outperformed all methods (AUROC: $0.92\pm0.002$ (95\% CI 0.91-0.92), vs.
$0.79\pm0.02$ (95\% CI 0.76-0.82), $0.86\pm0.01$ (95\% CI 0.85-0.88), and
$0.87\pm0.01$ (95\% CI 0.86-0.88), respectively). The improvement was
statistically significant.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16132" title="Abstract">arXiv:2401.16132</a> [<a href="/pdf/2401.16132" title="Download PDF">pdf</a>, <a href="/ps/2401.16132" title="Download PostScript">ps</a>, <a href="/format/2401.16132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges in computing matrix functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fasi%2C+M">Massimiliano Fasi</a>, 
<a href="/search/math?searchtype=author&query=Gaudreault%2C+S">St&#xe9;phane Gaudreault</a>, 
<a href="/search/math?searchtype=author&query=Lund%2C+K">Kathryn Lund</a>, 
<a href="/search/math?searchtype=author&query=Schweitzer%2C+M">Marcel Schweitzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This manuscript summarizes the outcome of the focus groups at "The f(A)bulous
workshop on matrix functions and exponential integrators", held at the Max
Planck Institute for Dynamics of Complex Technical Systems in Magdeburg,
Germany, on 25-27 September 2023. There were three focus groups in total, each
with a different theme: knowledge transfer, high-performance and energy-aware
computing, and benchmarking. We collect insights, open issues, and perspectives
from each focus group, as well as from general discussions throughout the
workshop. Our primary aim is to highlight ripe research directions and continue
to build on the momentum from a lively meeting.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16133" title="Abstract">arXiv:2401.16133</a> [<a href="/pdf/2401.16133" title="Download PDF">pdf</a>, <a href="/ps/2401.16133" title="Download PostScript">ps</a>, <a href="/format/2401.16133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BooleanOCT: Optimal Classification Trees based on multivariate Boolean  Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+J">Jiancheng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wenqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhibin Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The global optimization of classification trees has demonstrated considerable
promise, notably in enhancing accuracy, optimizing size, and thereby improving
human comprehensibility. While existing optimal classification trees
substantially enhance accuracy over greedy-based tree models like CART, they
still fall short when compared to the more complex black-box models, such as
random forests. To bridge this gap, we introduce a new mixed-integer
programming (MIP) formulation, grounded in multivariate Boolean rules, to
derive the optimal classification tree. Our methodology integrates both linear
metrics, including accuracy, balanced accuracy, and cost-sensitive cost, as
well as nonlinear metrics such as the F1-score. The approach is implemented in
an open-source Python package named BooleanOCT. We comprehensively benchmark
these methods on the 36 datasets from the UCI machine learning repository. The
proposed models demonstrate practical solvability on real-world datasets,
effectively handling sizes in the tens of thousands. Aiming to maximize
accuracy, this model achieves an average absolute improvement of 3.1\% and
1.5\% over random forests in small-scale and medium-sized datasets,
respectively. Experiments targeting various objectives, including balanced
accuracy, cost-sensitive cost, and F1-score, demonstrate the framework's wide
applicability and its superiority over contemporary state-of-the-art optimal
classification tree methods in small to medium-scale datasets.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16136" title="Abstract">arXiv:2401.16136</a> [<a href="/pdf/2401.16136" title="Download PDF">pdf</a>, <a href="/format/2401.16136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Training on Encrypted Data with TFHE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montero%2C+L">Luis Montero</a>, 
<a href="/search/cs?searchtype=author&query=Frery%2C+J">Jordan Frery</a>, 
<a href="/search/cs?searchtype=author&query=Kherfallah%2C+C">Celia Kherfallah</a>, 
<a href="/search/cs?searchtype=author&query=Bredehoft%2C+R">Roman Bredehoft</a>, 
<a href="/search/cs?searchtype=author&query=Stoian%2C+A">Andrei Stoian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present an approach to outsourcing of training neural networks while
preserving data confidentiality from malicious parties. We use fully
homomorphic encryption to build a unified training approach that works on
encrypted data and learns quantized neural network models. The data can be
horizontally or vertically split between multiple parties, enabling
collaboration on confidential data. We train logistic regression and
multi-layer perceptrons on several datasets.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16137" title="Abstract">arXiv:2401.16137</a> [<a href="/pdf/2401.16137" title="Download PDF">pdf</a>, <a href="/format/2401.16137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-PEFT: eXtremely Parameter-Efficient Fine-Tuning for Extreme  Multi-Profile Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwak%2C+N">Namju Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taesup Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Parameter-efficient fine-tuning (PEFT) techniques, such as adapter tuning,
aim to fine-tune a pre-trained language model (PLM) using a minimal number of
parameters for a specific task or profile. Although adapter tuning provides
increased parameter efficiency compared to full-model fine-tuning, it
introduces a small set of additional parameters attached to a PLM for each
profile. This can become problematic in practical applications with multiple
profiles, particularly when a significant increase in the number of profiles
linearly boosts the total number of additional parameters. To mitigate this
issue, we introduce X-PEFT, a novel PEFT method that leverages a multitude of
given adapters by fine-tuning an extremely small set of compact tensors for a
new profile, which serve as binary masks to adaptively select the given
adapters. To efficiently validate our proposed method, we implement it using a
large number of trained or untrained (random) adapters. We evaluate the
performance of X-PEFT through LaMP and GLUE tasks and demonstrate that it
either matches or surpasses the effectiveness of conventional adapter tuning,
despite reducing the memory requirements per profile by a factor of 10,000
compared to it.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16139" title="Abstract">arXiv:2401.16139</a> [<a href="/pdf/2401.16139" title="Download PDF">pdf</a>, <a href="/ps/2401.16139" title="Download PostScript">ps</a>, <a href="/format/2401.16139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving device-aware Web services and their mobile clients through an  aspect-oriented, model-driven approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+G">Guadalupe Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-de-Prado%2C+A">Alfonso Garcia-de-Prado</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information and Software Technology(2010), Vol.52, n.10,
  pp.1080-1093
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Context: Mobile devices have become an essential element in our daily lives,
even for connecting to the Internet. Consequently, Web services have become
extremely important when offering services through the Internet. However,
current Web services are very inflexible as regards their invocation from
different types of device, especially if we consider the need for them to be
adaptable when being invoked from mobile devices. Objective: In this paper, we
provide an approach for the creation of flexible Web services which can be
invoked transparently from different device types and which return subsequent
responses, as well as providing the client's adaptation as a result of the
particular device characteristics and end-user preferences in a completely
decoupled way. Method: Aspect-Oriented Programming and model-driven development
have been used to reduce both the impact of service and client code adaptation
for multiple devices as well as to facilitate the developer's task. Results: A
model-driven methodology can be followed from system models to code, providing
the Web service developer with the option of marking which services should be
adapted to mobile devices in the UML models, and obtaining the decoupled
adaptation code automatically from the models. Conclusion: We can conclude that
the approach presented in this paper provides us with the possibility of
following the development of mobile-aware Web services in an integrated
platform, benefiting from the use of aspect-oriented techniques not only for
maintaining device-related code completely decoupled from the main
functionality one, but also allowing a modularized non-intrusive adaptation of
mobile clients to the specific device characteristics as well as to final user
preferences.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16144" title="Abstract">arXiv:2401.16144</a> [<a href="/pdf/2401.16144" title="Download PDF">pdf</a>, <a href="/format/2401.16144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide and Conquer: Rethinking the Training Paradigm of Neural Radiance  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Rongkai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lebrat%2C+L">Leo Lebrat</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+R+S">Rodrigo Santa Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Avraham%2C+G">Gil Avraham</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Y">Yan Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Salvado%2C+O">Olivier Salvado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural radiance fields (NeRFs) have exhibited potential in synthesizing
high-fidelity views of 3D scenes but the standard training paradigm of NeRF
presupposes an equal importance for each image in the training set. This
assumption poses a significant challenge for rendering specific views
presenting intricate geometries, thereby resulting in suboptimal performance.
In this paper, we take a closer look at the implications of the current
training paradigm and redesign this for more superior rendering quality by
NeRFs. Dividing input views into multiple groups based on their visual
similarities and training individual models on each of these groups enables
each model to specialize on specific regions without sacrificing speed or
efficiency. Subsequently, the knowledge of these specialized models is
aggregated into a single entity via a teacher-student distillation paradigm,
enabling spatial efficiency for online render-ing. Empirically, we evaluate our
novel training framework on two publicly available datasets, namely NeRF
synthetic and Tanks&amp;Temples. Our evaluation demonstrates that our DaC training
pipeline enhances the rendering quality of a state-of-the-art baseline model
while exhibiting convergence to a superior minimum.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16152" title="Abstract">arXiv:2401.16152</a> [<a href="/pdf/2401.16152" title="Download PDF">pdf</a>, <a href="/ps/2401.16152" title="Download PostScript">ps</a>, <a href="/format/2401.16152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agile Effort Estimation: Comparing the Accuracy and Efficiency of  Planning Poker, Bucket System, and Affinity Estimation methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Po%C5%BEenel%2C+M">Marko Po&#x17e;enel</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%BCrst%2C+L">Luka F&#xfc;rst</a>, 
<a href="/search/cs?searchtype=author&query=Vavpoti%C4%8D%2C+D">Damjan Vavpoti&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Hovelja%2C+T">Toma&#x17e; Hovelja</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Software Engineering and Knowledge
  Engineering 33 11n12 (2023) 1923-1950 (World Scientific Journals)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Published studies on agile effort estimation predominantly focus on
comparisons of the accuracy of different estimation methods, while efficiency
comparisons, i.e. how much time the estimation methods consume was not in the
forefront. However, for practical use in software development, the time
required can be a very important cost factor for enterprises, especially when
the accuracy of different agile effort estimations is similar. In this study,
we thus try to advance the current standard accuracy comparison between methods
by introducing efficiency i.e. time it takes to use a method as an additional
dimension of comparison. We conduct this comparison between three agile effort
estimation methods that were not yet compared in the literature, namely
Planning Poker, Bucket System and Affinity Estimation. For the comparison, we
used eight student teams with 29 students that had to use all the effort
estimation methods during the course where they had to finish a programming
project in 3 weeks. The results indicate that after the students get used to
using the different methods the accuracy between them is not statistically
significantly different, however, the efficiency is. On average Bucket System
and Affinity Estimation methods take half as much time as Planning Poker.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16156" title="Abstract">arXiv:2401.16156</a> [<a href="/pdf/2401.16156" title="Download PDF">pdf</a>, <a href="/ps/2401.16156" title="Download PostScript">ps</a>, <a href="/format/2401.16156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fitted scheme for a Caputo initial-boundary value problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gracia%2C+J+L">J.L. Gracia</a>, 
<a href="/search/math?searchtype=author&query=O%27Riordan%2C+E">E. O&#x27;Riordan</a>, 
<a href="/search/math?searchtype=author&query=Stynes%2C+M">M. Stynes</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Sci. Comput. 76 (2018) 583-609
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we consider an initial-boundary value problem with a Caputo
time derivative of order $\alpha\in(0,1)$. The solution typically exhibits a
weak singularity near the initial time and this causes a reduction in the
orders of convergence of standard schemes. To deal with this singularity, the
solution is computed with a fitted difference scheme on a graded mesh. The
convergence of this scheme is analysed using a discrete maximum principle and
carefully chosen barrier functions. Sharp error estimates are proved, which
show an enhancement in the convergence rate compared with the standard L1
approximation on uniform meshes, and also indicate an optimal choice for the
mesh grading. This optimal mesh grading is less severe than the optimal grading
for the standard L1 scheme. Furthermore, the dependence of the error on the
final time forms part of our error estimate. Numerical experiments are
presented which corroborate our theoretical results.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16157" title="Abstract">arXiv:2401.16157</a> [<a href="/pdf/2401.16157" title="Download PDF">pdf</a>, <a href="/format/2401.16157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Aware Latent Initialization for Controllable Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenqiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Teng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zehong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, text-to-image diffusion models have demonstrated impressive ability
to generate high-quality images conditioned on the textual input. However,
these models struggle to accurately adhere to textual instructions regarding
spatial layout information. While previous research has primarily focused on
aligning cross-attention maps with layout conditions, they overlook the impact
of the initialization noise on the layout guidance. To achieve better layout
control, we propose leveraging a spatial-aware initialization noise during the
denoising process. Specifically, we find that the inverted reference image with
finite inversion steps contains valuable spatial awareness regarding the
object's position, resulting in similar layouts in the generated images. Based
on this observation, we develop an open-vocabulary framework to customize a
spatial-aware initialization noise for each layout condition. Without modifying
other modules except the initialization noise, our approach can be seamlessly
integrated as a plug-and-play module within other training-free layout guidance
frameworks. We evaluate our approach quantitatively and qualitatively on the
available Stable Diffusion model and COCO dataset. Equipped with the
spatial-aware latent initialization, our method significantly improves the
effectiveness of layout guidance while preserving high-quality content.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16158" title="Abstract">arXiv:2401.16158</a> [<a href="/pdf/2401.16158" title="Download PDF">pdf</a>, <a href="/format/2401.16158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiabo Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weizhou Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jitao Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Mobile device agent based on Multimodal Large Language Models (MLLM) is
becoming a popular application. In this paper, we introduce Mobile-Agent, an
autonomous multi-modal mobile device agent. Mobile-Agent first leverages visual
perception tools to accurately identify and locate both the visual and textual
elements within the app's front-end interface. Based on the perceived vision
context, it then autonomously plans and decomposes the complex operation task,
and navigates the mobile Apps through operations step by step. Different from
previous solutions that rely on XML files of Apps or mobile system metadata,
Mobile-Agent allows for greater adaptability across diverse mobile operating
environments in a vision-centric way, thereby eliminating the necessity for
system-specific customizations. To assess the performance of Mobile-Agent, we
introduced Mobile-Eval, a benchmark for evaluating mobile device operations.
Based on Mobile-Eval, we conducted a comprehensive evaluation of Mobile-Agent.
The experimental results indicate that Mobile-Agent achieved remarkable
accuracy and completion rates. Even with challenging instructions, such as
multi-app operations, Mobile-Agent can still complete the requirements. Code
and model will be open-sourced at https://github.com/X-PLUG/MobileAgent.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16160" title="Abstract">arXiv:2401.16160</a> [<a href="/pdf/2401.16160" title="Download PDF">pdf</a>, <a href="/format/2401.16160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaVA-MoLE: Sparse Mixture of LoRA Experts for Mitigating Data Conflicts  in Instruction Finetuning MLLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaoxiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jie%2C+Z">Zequn Jie</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Instruction finetuning on a variety of image-text instruction data is the key
to obtaining a versatile Multimodal Large Language Model (MLLM), and different
configurations of the instruction data can lead to finetuned models with
different capabilities. However, we have discovered that data conflicts are
inevitable when mixing instruction data from distinct domains, which can result
in performance drops for tasks of a specific domain. To address this issue, we
propose to apply a sparse mixture of LoRA experts for instruction finetuning
MLLMs. Within the Transformer layers, we extend the popular Low-Rank Adaption
(LoRA) method by creating a set of LoRA experts specifically for the MLP layer,
and route each token to the top-1 expert based on a routing function, allowing
adaptive choices for tokens from different domains. Since the LoRA experts are
sparsely activated, the training and inference cost are kept roughly constant
compared to the original LoRA method. By replacing the plain-LoRA finetuing of
LLaVA-1.5, our final model is named LLaVA-MoLE. Extensive experiments proved
that LLaVA-MoLE effectively mitigates the data conflict issue when mixing
multiple distinct instruction datasets with various configurations, and
achieves consistent performance gains over the strong plain-LoRA baselines.
Most importantly, on the mixed datasets, LLaVA-MoLE can even outperform the
plain-LoRA baseline trained with twice the samples.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16164" title="Abstract">arXiv:2401.16164</a> [<a href="/pdf/2401.16164" title="Download PDF">pdf</a>, <a href="/format/2401.16164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Bi-Level Optimization: Proximal Lagrangian Value function  Approach and Hessian-free Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chengming Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Shangzhi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents a new approach and algorithm for solving a class of
constrained Bi-Level Optimization (BLO) problems in which the lower-level
problem involves constraints coupling both upper-level and lower-level
variables. Such problems have recently gained significant attention due to
their broad applicability in machine learning. However, conventional
gradient-based methods unavoidably rely on computationally intensive
calculations related to the Hessian matrix. To address this challenge, we begin
by devising a smooth proximal Lagrangian value function to handle the
constrained lower-level problem. Utilizing this construct, we introduce a
single-level reformulation for constrained BLOs that transforms the original
BLO problem into an equivalent optimization problem with smooth constraints.
Enabled by this reformulation, we develop a Hessian-free gradient-based
algorithm-termed proximal Lagrangian Value function-based Hessian-free Bi-level
Algorithm (LV-HBA)-that is straightforward to implement in a single loop
manner. Consequently, LV-HBA is especially well-suited for machine learning
applications. Furthermore, we offer non-asymptotic convergence analysis for
LV-HBA, eliminating the need for traditional strong convexity assumptions for
the lower-level problem while also being capable of accommodating non-singleton
scenarios. Empirical results substantiate the algorithm's superior practical
performance.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16167" title="Abstract">arXiv:2401.16167</a> [<a href="/pdf/2401.16167" title="Download PDF">pdf</a>, <a href="/format/2401.16167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;You tell me&quot;: A Dataset of GPT-4-Based Behaviour Change Support  Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+S">Selina Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Elsweiler%2C+D">David Elsweiler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint as accepted at the 2024 ACM SIGIR Conference on Human Information Interaction and Retrieval (CHIIR '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Conversational agents are increasingly used to address emotional needs on top
of information needs. One use case of increasing interest are counselling-style
mental health and behaviour change interventions, with large language model
(LLM)-based approaches becoming more popular. Research in this context so far
has been largely system-focused, foregoing the aspect of user behaviour and the
impact this can have on LLM-generated texts. To address this issue, we share a
dataset containing text-based user interactions related to behaviour change
with two GPT-4-based conversational agents collected in a preregistered user
study. This dataset includes conversation data, user language analysis,
perception measures, and user feedback for LLM-generated turns, and can offer
valuable insights to inform the design of such systems based on real
interactions.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16170" title="Abstract">arXiv:2401.16170</a> [<a href="/pdf/2401.16170" title="Download PDF">pdf</a>, <a href="/format/2401.16170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Privacy-preserving key transmission protocol to distribute QRNG keys  using zk-SNARKs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soler%2C+D">David Soler</a> (1), 
<a href="/search/cs?searchtype=author&query=Dafonte%2C+C">Carlos Dafonte</a> (1), 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Veiga%2C+M">Manuel Fern&#xe1;ndez-Veiga</a> (2), 
<a href="/search/cs?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a> (2), 
<a href="/search/cs?searchtype=author&query=N%C3%B3voa%2C+F+J">Francisco J. N&#xf3;voa</a> (1) ((1) CITIC, Universidade da Coru&#x148;a, A Coru&#x148;a, Spain, (2) atlanTTic, Universidade de Vigo, Vigo, Spain)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 6 figures. Submitted to Computer Networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">High-entropy random numbers are an essential part of cryptography, and
Quantum Random Number Generators (QRNG) are an emergent technology that can
provide high-quality keys for cryptographic algorithms but unfortunately are
currently difficult to access. Existing Entropy-as-a-Service solutions require
users to trust the central authority distributing the key material, which is
not desirable in a high-privacy environment. In this paper, we present a novel
key transmission protocol that allows users to obtain cryptographic material
generated by a QRNG in such a way that the server is unable to identify which
user is receiving each key. This is achieved with the inclusion of Zero
Knowledge Succinct Non-interactive Arguments of Knowledge (zk-SNARK), a
cryptographic primitive that allow users to prove knowledge of some value
without needing to reveal it. The security analysis of the protocol proves that
it satisfies the properties of Anonymity, Unforgeability and Confidentiality,
as defined in this document. We also provide an implementation of the protocol
demonstrating its functionality and performance, using NFC as the transmission
channel for the QRNG key.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16173" title="Abstract">arXiv:2401.16173</a> [<a href="/pdf/2401.16173" title="Download PDF">pdf</a>, <a href="/format/2401.16173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing Close Human Interactions from Multiple Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shuai%2C+Q">Qing Shuai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhize Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haijun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Can Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaowei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transactions on Graphics 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the challenging task of reconstructing the poses of
multiple individuals engaged in close interactions, captured by multiple
calibrated cameras. The difficulty arises from the noisy or false 2D keypoint
detections due to inter-person occlusion, the heavy ambiguity in associating
keypoints to individuals due to the close interactions, and the scarcity of
training data as collecting and annotating motion data in crowded scenes is
resource-intensive. We introduce a novel system to address these challenges.
Our system integrates a learning-based pose estimation component and its
corresponding training and inference strategies. The pose estimation component
takes multi-view 2D keypoint heatmaps as input and reconstructs the pose of
each individual using a 3D conditional volumetric network. As the network
doesn't need images as input, we can leverage known camera parameters from test
scenes and a large quantity of existing motion capture data to synthesize
massive training data that mimics the real data distribution in test scenes.
Extensive experiments demonstrate that our approach significantly surpasses
previous approaches in terms of pose accuracy and is generalizable across
various camera setups and population sizes. The code is available on our
project page: https://github.com/zju3dv/CloseMoCap.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16176" title="Abstract">arXiv:2401.16176</a> [<a href="/pdf/2401.16176" title="Download PDF">pdf</a>, <a href="/format/2401.16176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Structure-Preserving Graph Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+V+T">Van Thuy Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+O">O-Joun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The transformer architecture has shown remarkable success in various domains,
such as natural language processing and computer vision. When it comes to graph
learning, transformers are required not only to capture the interactions
between pairs of nodes but also to preserve graph structures connoting the
underlying relations and proximity between them, showing the expressive power
to capture different graph structures. Accordingly, various
structure-preserving graph transformers have been proposed and widely used for
various tasks, such as graph-level tasks in bioinformatics and
chemoinformatics. However, strategies related to graph structure preservation
have not been well organized and systematized in the literature. In this paper,
we provide a comprehensive overview of structure-preserving graph transformers
and generalize these methods from the perspective of their design objective.
First, we divide strategies into four main groups: node feature modulation,
context node sampling, graph rewriting, and transformer architecture
improvements. We then further divide the strategies according to the coverage
and goals of graph structure preservation. Furthermore, we also discuss
challenges and future directions for graph transformer models to preserve the
graph structure and understand the nature of graphs.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16178" title="Abstract">arXiv:2401.16178</a> [<a href="/pdf/2401.16178" title="Download PDF">pdf</a>, <a href="/format/2401.16178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> B&#xe9;zier curves and the Takagi function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ptackova%2C+L">Lenka Ptackova</a>, 
<a href="/search/math?searchtype=author&query=Vivaldi%2C+F">Franco Vivaldi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider B\'ezier curves with complex parameter, and we determine
explicitly the affine iterated function system (IFS) corresponding to the de
Casteljau subdivision algorithm, together with the complex parametric domain
over which such an IFS has a unique global connected attractor. For a specific
family of complex parameter having vanishing imaginary part, we prove that the
Takagi fractal curve is the attractor, under suitable scaling.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16181" title="Abstract">arXiv:2401.16181</a> [<a href="/pdf/2401.16181" title="Download PDF">pdf</a>, <a href="/format/2401.16181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Decentralized Linearly Separable Computation With the Minimum  Computation Cost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Minquan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhenhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Youlong Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The distributed linearly separable computation problem finds extensive
applications across domains such as distributed gradient coding, distributed
linear transform, real-time rendering, etc. In this paper, we investigate this
problem in a fully decentralized scenario, where $\mathsf{N}$ workers
collaboratively perform the computation task without a central master. Each
worker aims to compute a linearly separable computation that can be manifested
as $\mathsf{K}_{\mathrm{c}}$ linear combinations of $\mathsf{K}$ messages,
where each message is a function of a distinct dataset. We require that each
worker successfully fulfill the task based on the transmissions from any
$\mathsf{N}_{\mathrm{r}}$ workers, such that the system can tolerate any
$\mathsf{N}-\mathsf{N}_{\mathrm{r}}$ stragglers. We focus on the scenario where
the computation cost (the number of uncoded datasets assigned to each worker)
is minimum, and aim to minimize the communication cost (the number of symbols
the fastest $\mathsf{N}_{\mathrm{r}}$ workers transmit). We propose a novel
distributed computing scheme that is optimal under the widely used cyclic data
assignment. Interestingly, we demonstrate that the side information at each
worker is ineffective in reducing the communication cost when
$\mathsf{K}_{\mathrm{c}}\leq {\mathsf{K}}\mathsf{N}_{\mathrm{r}}/{\mathsf{N}}$,
while it helps reduce the communication cost as $\mathsf{K}_{\mathrm{c}}$
increases.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16182" title="Abstract">arXiv:2401.16182</a> [<a href="/pdf/2401.16182" title="Download PDF">pdf</a>, <a href="/format/2401.16182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaMandement: Large Language Models for Summarization of French  Legislative Proposals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gesnouin%2C+J">Joseph Gesnouin</a>, 
<a href="/search/cs?searchtype=author&query=Tannier%2C+Y">Yannis Tannier</a>, 
<a href="/search/cs?searchtype=author&query=Da+Silva%2C+C+G">Christophe Gomes Da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Tapory%2C+H">Hatim Tapory</a>, 
<a href="/search/cs?searchtype=author&query=Brier%2C+C">Camille Brier</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+H">Hugo Simon</a>, 
<a href="/search/cs?searchtype=author&query=Rozenberg%2C+R">Raphael Rozenberg</a>, 
<a href="/search/cs?searchtype=author&query=Woehrel%2C+H">Hermann Woehrel</a>, 
<a href="/search/cs?searchtype=author&query=Yakaabi%2C+M+E">Mehdi El Yakaabi</a>, 
<a href="/search/cs?searchtype=author&query=Binder%2C+T">Thomas Binder</a>, 
<a href="/search/cs?searchtype=author&query=Marie%2C+G">Guillaume Marie</a>, 
<a href="/search/cs?searchtype=author&query=Caron%2C+E">Emilie Caron</a>, 
<a href="/search/cs?searchtype=author&query=Nogueira%2C+M">Mathile Nogueira</a>, 
<a href="/search/cs?searchtype=author&query=Fontas%2C+T">Thomas Fontas</a>, 
<a href="/search/cs?searchtype=author&query=Puydebois%2C+L">Laure Puydebois</a>, 
<a href="/search/cs?searchtype=author&query=Theophile%2C+M">Marie Theophile</a>, 
<a href="/search/cs?searchtype=author&query=Morandi%2C+S">Stephane Morandi</a>, 
<a href="/search/cs?searchtype=author&query=Petit%2C+M">Mael Petit</a>, 
<a href="/search/cs?searchtype=author&query=Creissac%2C+D">David Creissac</a>, 
<a href="/search/cs?searchtype=author&query=Ennouchy%2C+P">Pauline Ennouchy</a>, 
<a href="/search/cs?searchtype=author&query=Valetoux%2C+E">Elise Valetoux</a>, 
<a href="/search/cs?searchtype=author&query=Visade%2C+C">Celine Visade</a>, 
<a href="/search/cs?searchtype=author&query=Balloux%2C+S">Severine Balloux</a>, 
<a href="/search/cs?searchtype=author&query=Cortes%2C+E">Emmanuel Cortes</a>, 
<a href="/search/cs?searchtype=author&query=Devineau%2C+P">Pierre-Etienne Devineau</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+U">Ulrich Tan</a>, 
<a href="/search/cs?searchtype=author&query=Mac+Namara%2C+E">Esther Mac Namara</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Su Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This report introduces LLaMandement, a state-of-the-art Large Language Model,
fine-tuned by the French government and designed to enhance the efficiency and
efficacy of processing parliamentary sessions (including the production of
bench memoranda and documents required for interministerial meetings) by
generating neutral summaries of legislative proposals. Addressing the
administrative challenges of manually processing a growing volume of
legislative amendments, LLaMandement stands as a significant legal
technological milestone, providing a solution that exceeds the scalability of
traditional human efforts while matching the robustness of a specialized legal
drafter. We release all our fine-tuned models and training data to the
community.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16183" title="Abstract">arXiv:2401.16183</a> [<a href="/pdf/2401.16183" title="Download PDF">pdf</a>, <a href="/ps/2401.16183" title="Download PostScript">ps</a>, <a href="/format/2401.16183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Reinforcement Learning for Linear-Quadratic Control of Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Olsson%2C+J">Johan Olsson</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+R">Runyu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Tegling%2C+E">Emma Tegling</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+N">Na Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Distributed optimal control is known to be challenging and can become
intractable even for linear-quadratic regulator problems. In this work, we
study a special class of such problems where distributed state feedback
controllers can give near-optimal performance. More specifically, we consider
networked linear-quadratic controllers with decoupled costs and spatially
exponentially decaying dynamics. We aim to exploit the structure in the problem
to design a scalable reinforcement learning algorithm for learning a
distributed controller. Recent work has shown that the optimal controller can
be well approximated only using information from a $\kappa$-neighborhood of
each agent. Motivated by these results, we show that similar results hold for
the agents' individual value and Q-functions. We continue by designing an
algorithm, based on the actor-critic framework, to learn distributed
controllers only using local information. Specifically, the Q-function is
estimated by modifying the Least Squares Temporal Difference for Q-functions
method to only use local information. The algorithm then updates the policy
using gradient descent. Finally, we evaluate the algorithm through simulations
that indeed suggest near-optimal performance.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16184" title="Abstract">arXiv:2401.16184</a> [<a href="/pdf/2401.16184" title="Download PDF">pdf</a>, <a href="/format/2401.16184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Semantics of LM Latent Space: A Vocabulary-defined Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Aleti%2C+A">Aldeida Aleti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of deep learning, understanding the latent space of language
models (LMs) like transformers is crucial for refining their performance and
interpretability. However, existing analyses often fall short in providing
absolute and model-centric insights into LM semantics, and neglect essential
aspects of LM adaption. In response, we introduce a pioneering method called
vocabulary-defined semantics, which establishes a fixed reference frame within
the LM latent space, ensuring absolute semantic analysis grounded in LM
vocabulary. Our approach transcends prior relative analyses, leveraging LM
vocabulary for model-centric insights. Furthermore, we propose a novel
technique to compute logits, emphasizing differentiability and local isotropy,
and introduce a neural clustering module for semantically calibrating data
representations during LM adaptation. Through extensive experiments across
diverse text understanding datasets, our approach surpasses state-of-the-art
methods of retrieval-augmented generation and parameters-efficient finetuning,
showcasing its efficacy and broad applicability. Our findings not only shed
light on LM mechanics but also offer practical solutions for enhancing LM
performance and interpretability.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16185" title="Abstract">arXiv:2401.16185</a> [<a href="/pdf/2401.16185" title="Download PDF">pdf</a>, <a href="/format/2401.16185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing  LLMs&#x27; Vulnerability Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuqiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Daoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yue Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lyuye Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Miaolei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a technical report by Nanyang Technological University
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated significant poten- tial for
many downstream tasks, including those requiring human- level intelligence,
such as vulnerability detection. However, recent attempts to use LLMs for
vulnerability detection are still prelim- inary, as they lack an in-depth
understanding of a subject LLM's vulnerability reasoning capability - whether
it originates from the model itself or from external assistance, such as
invoking tool sup- port and retrieving vulnerability knowledge. In this paper,
we aim to decouple LLMs' vulnerability reason- ing capability from their other
capabilities, including the ability to actively seek additional information
(e.g., via function calling in SOTA models), adopt relevant vulnerability
knowledge (e.g., via vector-based matching and retrieval), and follow
instructions to out- put structured results. To this end, we propose a unified
evaluation framework named LLM4Vuln, which separates LLMs' vulnerability
reasoning from their other capabilities and evaluates how LLMs' vulnerability
reasoning could be enhanced when combined with the enhancement of other
capabilities. To demonstrate the effectiveness of LLM4Vuln, we have designed
controlled experiments using 75 ground-truth smart contract vulnerabilities,
which were extensively audited as high-risk on Code4rena from August to
November 2023, and tested them in 4,950 different scenarios across three
represen- tative LLMs (GPT-4, Mixtral, and Code Llama). Our results not only
reveal ten findings regarding the varying effects of knowledge en- hancement,
context supplementation, prompt schemes, and models but also enable us to
identify 9 zero-day vulnerabilities in two pilot bug bounty programs with over
1,000 USD being awarded.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16186" title="Abstract">arXiv:2401.16186</a> [<a href="/pdf/2401.16186" title="Download PDF">pdf</a>, <a href="/format/2401.16186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study on Usage and Perceptions of LLMs in a Software  Engineering Project
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rasnayaka%2C+S">Sanka Rasnayaka</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shariffdeen%2C+R">Ridwan Shariffdeen</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+G+N">Ganesh Neelakanta Iyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, accepted for publication at the LLM4Code workshop @ ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) represent a leap in artificial intelligence,
excelling in tasks using human language(s). Although the main focus of
general-purpose LLMs is not code generation, they have shown promising results
in the domain. However, the usefulness of LLMs in an academic software
engineering project has not been fully explored yet. In this study, we explore
the usefulness of LLMs for 214 students working in teams consisting of up to
six members. Notably, in the academic course through which this study is
conducted, students were encouraged to integrate LLMs into their development
tool-chain, in contrast to most other academic courses that explicitly prohibit
the use of LLMs.
<br />In this paper, we analyze the AI-generated code, prompts used for code
generation, and the human intervention levels to integrate the code into the
code base. We also conduct a perception study to gain insights into the
perceived usefulness, influencing factors, and future outlook of LLM from a
computer science student's perspective. Our findings suggest that LLMs can play
a crucial role in the early stages of software development, especially in
generating foundational code structures, and helping with syntax and error
debugging. These insights provide us with a framework on how to effectively
utilize LLMs as a tool to enhance the productivity of software engineering
students, and highlight the necessity of shifting the educational focus toward
preparing students for successful human-AI collaboration.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16187" title="Abstract">arXiv:2401.16187</a> [<a href="/pdf/2401.16187" title="Download PDF">pdf</a>, <a href="/ps/2401.16187" title="Download PostScript">ps</a>, <a href="/format/2401.16187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Network-based Joint Equalization and Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clausius%2C+J">Jannis Clausius</a>, 
<a href="/search/cs?searchtype=author&query=Geiselhart%2C+M">Marvin Geiselhart</a>, 
<a href="/search/cs?searchtype=author&query=Tandler%2C+D">Daniel Tandler</a>, 
<a href="/search/cs?searchtype=author&query=Brink%2C+S+t">Stephan ten Brink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ISIT 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper proposes to use graph neural networks (GNNs) for equalization,
that can also be used to perform joint equalization and decoding (JED). For
equalization, the GNN is build upon the factor graph representations of the
channel, while for JED, the factor graph is expanded by the Tanner graph of the
parity-check matrix (PCM) of the channel code, sharing the variable nodes
(VNs). A particularly advantageous property of the GNN is the robustness
against cycles in the factor graphs which is the main problem for belief
propagation (BP)-based equalization. As a result of having a fully deep
learning-based receiver, joint optimization instead of individual optimization
of the components is enabled, so-called end-to-end learning. Furthermore, we
propose a parallel flooding schedule that further reduces the latency, which
turns out to improve also the error correcting performance. The proposed
approach is analyzed and compared to state-of-the-art baselines in terms of
error correcting capability and latency. At a fixed low latency, the flooding
GNN for JED demonstrates a gain of 2.25 dB in bit error rate (BER) compared to
an iterative Bahl--Cock--Jelinek--Raviv (BCJR)-BP baseline.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16189" title="Abstract">arXiv:2401.16189</a> [<a href="/pdf/2401.16189" title="Download PDF">pdf</a>, <a href="/format/2401.16189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIMP: Future Interaction Modeling for Multi-Agent Motion Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Sungmin Woo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minjung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghyeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+S">Sungjun Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangyoun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Multi-agent motion prediction is a crucial concern in autonomous driving, yet
it remains a challenge owing to the ambiguous intentions of dynamic agents and
their intricate interactions. Existing studies have attempted to capture
interactions between road entities by using the definite data in history
timesteps, as future information is not available and involves high
uncertainty. However, without sufficient guidance for capturing future states
of interacting agents, they frequently produce unrealistic trajectory overlaps.
In this work, we propose Future Interaction modeling for Motion Prediction
(FIMP), which captures potential future interactions in an end-to-end manner.
FIMP adopts a future decoder that implicitly extracts the potential future
information in an intermediate feature-level, and identifies the interacting
entity pairs through future affinity learning and top-k filtering strategy.
Experiments show that our future interaction modeling improves the performance
remarkably, leading to superior performance on the Argoverse motion forecasting
benchmark.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16191" title="Abstract">arXiv:2401.16191</a> [<a href="/pdf/2401.16191" title="Download PDF">pdf</a>, <a href="/format/2401.16191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Tripods to Bipods: Reducing the Queue Number of Planar Graphs Costs  Just One Leg
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=F%C3%B6rster%2C+H">Henry F&#xf6;rster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">As an alternative to previously existing planar graph product structure
theorems, we prove that every planar graph $G$ is a subgraph of the strong
product of $K_2$, a path and a planar subgraph of a $4$-tree. As an
application, we show that the queue number of planar graphs is at most $38$
whereas the queue number of planar bipartite graphs is at most $25$.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16193" title="Abstract">arXiv:2401.16193</a> [<a href="/pdf/2401.16193" title="Download PDF">pdf</a>, <a href="/format/2401.16193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contributing Dimension Structure of Deep Feature for Coreset Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhijing Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Satoh%2C+S">Shin&#x27;ichi Satoh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,10 figures, to be published in AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Coreset selection seeks to choose a subset of crucial training samples for
efficient learning. It has gained traction in deep learning, particularly with
the surge in training dataset sizes. Sample selection hinges on two main
aspects: a sample's representation in enhancing performance and the role of
sample diversity in averting overfitting. Existing methods typically measure
both the representation and diversity of data based on similarity metrics, such
as L2-norm. They have capably tackled representation via distribution matching
guided by the similarities of features, gradients, or other information between
data. However, the results of effectively diverse sample selection are mired in
sub-optimality. This is because the similarity metrics usually simply aggregate
dimension similarities without acknowledging disparities among the dimensions
that significantly contribute to the final similarity. As a result, they fall
short of adequately capturing diversity. To address this, we propose a
feature-based diversity constraint, compelling the chosen subset to exhibit
maximum diversity. Our key lies in the introduction of a novel Contributing
Dimension Structure (CDS) metric. Different from similarity metrics that
measure the overall similarity of high-dimensional features, our CDS metric
considers not only the reduction of redundancy in feature dimensions, but also
the difference between dimensions that contribute significantly to the final
similarity. We reveal that existing methods tend to favor samples with similar
CDS, leading to a reduced variety of CDS types within the coreset and
subsequently hindering model performance. In response, we enhance the
performance of five classical selection methods by integrating the CDS
constraint. Our experiments on three datasets demonstrate the general
effectiveness of the proposed method in boosting existing methods.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16195" title="Abstract">arXiv:2401.16195</a> [<a href="/pdf/2401.16195" title="Download PDF">pdf</a>, <a href="/ps/2401.16195" title="Download PostScript">ps</a>, <a href="/format/2401.16195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dot-depth three, return of the J-class
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Place%2C+T">Thomas Place</a>, 
<a href="/search/cs?searchtype=author&query=Zeitoun%2C+M">Marc Zeitoun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">We look at concatenation hierarchies of classes of regular languages. Each
such hierarchy is determined by a single class, its basis: level $n$ is built
by applying the Boolean polynomial closure operator (BPol), $n$ times to the
basis. A prominent and difficult open question in automata theory is to decide
membership of a regular language in a given level. For instance, for the
historical dot-depth hierarchy, the decidability of membership is only known at
levels one and two.
<br />We give a generic algebraic characterization of the operator BPol. This
characterization implies that for any concatenation hierarchy, if $n$ is at
least two, membership at level $n$ reduces to a more complex problem, called
covering, for the previous level, $n-1$. Combined with earlier results on
covering, this implies that membership is decidable for dot-depth three and for
level two in most of the prominent hierarchies in the literature. For instance,
we obtain that the levels two in both the modulo hierarchy and the group
hierarchy have decidable membership.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16197" title="Abstract">arXiv:2401.16197</a> [<a href="/pdf/2401.16197" title="Download PDF">pdf</a>, <a href="/format/2401.16197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geospatial Disparities: A Case Study on Real Estate Prices in Paris
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Machado%2C+A+F">Agathe Fernandes Machado</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+F">Fran&#xe7;ois Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ratz%2C+P">Philipp Ratz</a>, 
<a href="/search/cs?searchtype=author&query=Gallic%2C+E">Ewen Gallic</a>, 
<a href="/search/cs?searchtype=author&query=Charpentier%2C+A">Arthur Charpentier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Driven by an increasing prevalence of trackers, ever more IoT sensors, and
the declining cost of computing power, geospatial information has come to play
a pivotal role in contemporary predictive models. While enhancing prognostic
performance, geospatial data also has the potential to perpetuate many
historical socio-economic patterns, raising concerns about a resurgence of
biases and exclusionary practices, with their disproportionate impacts on
society. Addressing this, our paper emphasizes the crucial need to identify and
rectify such biases and calibration errors in predictive models, particularly
as algorithms become more intricate and less interpretable. The increasing
granularity of geospatial information further introduces ethical concerns, as
choosing different geographical scales may exacerbate disparities akin to
redlining and exclusionary zoning. To address these issues, we propose a
toolkit for identifying and mitigating biases arising from geospatial data.
Extending classical fairness definitions, we incorporate an ordinal regression
case with spatial attributes, deviating from the binary classification focus.
This extension allows us to gauge disparities stemming from data aggregation
levels and advocates for a less interfering correction approach. Illustrating
our methodology using a Parisian real estate dataset, we showcase practical
applications and scrutinize the implications of choosing geographical
aggregation levels for fairness and calibration measures.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16198" title="Abstract">arXiv:2401.16198</a> [<a href="/pdf/2401.16198" title="Download PDF">pdf</a>, <a href="/format/2401.16198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contracting with a Learning Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guruganesh%2C+G">Guru Guruganesh</a>, 
<a href="/search/cs?searchtype=author&query=Kolumbus%2C+Y">Yoav Kolumbus</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jon Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Talgam-Cohen%2C+I">Inbal Talgam-Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Vlatakis-Gkaragkounis%2C+E">Emmanouil-Vasileios Vlatakis-Gkaragkounis</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+R">Joshua R. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Weinberg%2C+S+M">S. Matthew Weinberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">Many real-life contractual relations differ completely from the clean, static
model at the heart of principal-agent theory. Typically, they involve repeated
strategic interactions of the principal and agent, taking place under
uncertainty and over time. While appealing in theory, players seldom use
complex dynamic strategies in practice, often preferring to circumvent
complexity and approach uncertainty through learning. We initiate the study of
repeated contracts with a learning agent, focusing on agents who achieve
no-regret outcomes.
<br />Optimizing against a no-regret agent is a known open problem in general
games; we achieve an optimal solution to this problem for a canonical contract
setting, in which the agent's choice among multiple actions leads to
success/failure. The solution has a surprisingly simple structure: for some
$\alpha &gt; 0$, initially offer the agent a linear contract with scalar $\alpha$,
then switch to offering a linear contract with scalar $0$. This switch causes
the agent to ``free-fall'' through their action space and during this time
provides the principal with non-zero reward at zero cost. Despite apparent
exploitation of the agent, this dynamic contract can leave \emph{both} players
better off compared to the best static contract. Our results generalize beyond
success/failure, to arbitrary non-linear contracts which the principal rescales
dynamically.
<br />Finally, we quantify the dependence of our results on knowledge of the time
horizon, and are the first to address this consideration in the study of
strategizing against learning agents.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16199" title="Abstract">arXiv:2401.16199</a> [<a href="/pdf/2401.16199" title="Download PDF">pdf</a>, <a href="/ps/2401.16199" title="Download PostScript">ps</a>, <a href="/format/2401.16199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal quadrature errors and sampling numbers for Sobolev spaces with  logarithmic perturbation on spheres
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Geng%2C+J">Jiaxin Geng</a>, 
<a href="/search/math?searchtype=author&query=Ling%2C+Y">Yun Ling</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jiansong Li</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Heping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we study optimal quadrature errors, approximation numbers, and
sampling numbers in $L_2(\Bbb S^d)$ for Sobolev spaces ${\rm
H}^{\alpha,\beta}(\Bbb S^d)$ with logarithmic perturbation on the unit sphere
$\Bbb S^d$ in $\Bbb R^{d+1}$. First we obtain strong equivalences of the
approximation numbers for ${\rm H}^{\alpha,\beta}(\Bbb S^d)$ with $\alpha&gt;0$,
which gives a clue to Open problem 3 as posed by Krieg and Vyb\'iral in
\cite{KV}. Second, for the optimal quadrature errors for ${\rm
H}^{\alpha,\beta}(\Bbb S^d)$, we use the "fooling" function technique to get
lower bounds in the case $\alpha&gt;d/2$, and apply Hilbert space structure and
Vyb\'iral's theorem about Schur product theory to obtain lower bounds in the
case $\alpha=d/2,\,\beta&gt;1/2$ of small smoothness, which confirms the
conjecture as posed by Grabner and Stepanyukin in \cite{GS} and solves Open
problem 2 in \cite{KV}. Finally, we employ the weighted least squares operators
and the least squares quadrature rules to obtain approximation theorems and
quadrature errors for ${\rm H}^{\alpha,\beta}(\Bbb S^d)$ with $\alpha&gt;d/2$ or
$\alpha=d/2,\,\beta&gt;1/2$, which are order optimal.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16202" title="Abstract">arXiv:2401.16202</a> [<a href="/pdf/2401.16202" title="Download PDF">pdf</a>, <a href="/format/2401.16202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPIA: Field-Programmable Ising Arrays with In-Memory Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hutchinson%2C+G+H">George Higgins Hutchinson</a>, 
<a href="/search/cs?searchtype=author&query=Sifferman%2C+E">Ethan Sifferman</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+T">Tinish Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Strukov%2C+D+B">Dmitri B. Strukov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Ising Machine is a promising computing approach for solving combinatorial
optimization problems. It is naturally suited for energy-saving and compact
in-memory computing implementations with emerging memories. A na\"ive in-memory
computing implementation of a quadratic Ising Machine requires an array of
coupling weights that grows quadratically with problem size. However, the
resources in such an approach are used inefficiently due to sparsity in
practical optimization problems. We first show that this issue can be addressed
by partitioning a coupling array into smaller sub-arrays. This technique,
however, requires interconnecting subarrays; hence, we developed in-memory
computing architecture for quadratic Ising Machines inspired by island-type
field programmable gate arrays, which is the main contribution of our paper. We
adapt open-source tools to optimize problem embedding and model routing
overhead. Modeling results of benchmark problems for the developed architecture
show up to 60x area improvement and faster operation than the baseline
approach. Finally, we discuss algorithm/circuit co-design techniques for
further improvements.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16204" title="Abstract">arXiv:2401.16204</a> [<a href="/pdf/2401.16204" title="Download PDF">pdf</a>, <a href="/ps/2401.16204" title="Download PostScript">ps</a>, <a href="/format/2401.16204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing High-Degree Polynomial Gradients in Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+T">T. Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Hutchinson%2C+G+H">G. H. Hutchinson</a>, 
<a href="/search/cs?searchtype=author&query=Pedretti%2C+G">G. Pedretti</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+X">X. Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Ignowski%2C+J">J. Ignowski</a>, 
<a href="/search/cs?searchtype=author&query=Van+Vaerenbergh%2C+T">T. Van Vaerenbergh</a>, 
<a href="/search/cs?searchtype=author&query=Beausoleil%2C+R">R. Beausoleil</a>, 
<a href="/search/cs?searchtype=author&query=Strachan%2C+J+P">J.P. Strachan</a>, 
<a href="/search/cs?searchtype=author&query=Strukov%2C+D+B">D.B. Strukov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Specialized function gradient computing hardware could greatly improve the
performance of state-of-the-art optimization algorithms, e.g., based on
gradient descent or conjugate gradient methods that are at the core of control,
machine learning, and operations research applications. Prior work on such
hardware, performed in the context of the Ising Machines and related concepts,
is limited to quadratic polynomials and not scalable to commonly used
higher-order functions. Here, we propose a novel approach for massively
parallel gradient calculations of high-degree polynomials, which is conducive
to efficient mixed-signal in-memory computing circuit implementations and whose
area complexity scales linearly with the number of variables and terms in the
function and, most importantly, independent of its degree. Two flavors of such
an approach are proposed. The first is limited to binary-variable polynomials
typical in combinatorial optimization problems, while the second type is
broader at the cost of a more complex periphery. To validate the former
approach, we experimentally demonstrated solving a small-scale third-order
Boolean satisfiability problem based on integrated metal-oxide memristor
crossbar circuits, one of the most prospective in-memory computing device
technologies, with a competitive heuristics algorithm. Simulation results for
larger-scale, more practical problems show orders of magnitude improvements in
the area, and related advantages in speed and energy efficiency compared to the
state-of-the-art. We discuss how our work could enable even higher-performance
systems after co-designing algorithms to exploit massively parallel gradient
computation.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16205" title="Abstract">arXiv:2401.16205</a> [<a href="/pdf/2401.16205" title="Download PDF">pdf</a>, <a href="/format/2401.16205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CognitiveOS: Large Multimodal Model based System to Endow Any Type of  Robot with Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lykov%2C+A">Artem Lykov</a>, 
<a href="/search/cs?searchtype=author&query=Konenkov%2C+M">Mikhail Konenkov</a>, 
<a href="/search/cs?searchtype=author&query=Gbagbe%2C+K+F">Koffivi Fid&#xe8;le Gbagbe</a>, 
<a href="/search/cs?searchtype=author&query=Litvinov%2C+M">Mikhail Litvinov</a>, 
<a href="/search/cs?searchtype=author&query=Peter%2C+R">Robinroy Peter</a>, 
<a href="/search/cs?searchtype=author&query=Davletshin%2C+D">Denis Davletshin</a>, 
<a href="/search/cs?searchtype=author&query=Fedoseev%2C+A">Aleksey Fedoseev</a>, 
<a href="/search/cs?searchtype=author&query=Kobzarev%2C+O">Oleg Kobzarev</a>, 
<a href="/search/cs?searchtype=author&query=Alabbas%2C+A">Ali Alabbas</a>, 
<a href="/search/cs?searchtype=author&query=Alyounes%2C+O">Oussama Alyounes</a>, 
<a href="/search/cs?searchtype=author&query=Cabrera%2C+M+A">Miguel Altamirano Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=Tsetserukou%2C+D">Dzmitry Tsetserukou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper submitted to CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces CognitiveOS, a disruptive system based on multiple
transformer-based models, endowing robots of various types with cognitive
abilities not only for communication with humans but also for task resolution
through physical interaction with the environment. The system operates smoothly
on different robotic platforms without extra tuning. It autonomously makes
decisions for task execution by analyzing the environment and using information
from its long-term memory. The system underwent testing on various platforms,
including quadruped robots and manipulator robots, showcasing its capability to
formulate behavioral plans even for robots whose behavioral examples were
absent in the training dataset.
<br />Experimental results revealed the system's high performance in advanced task
comprehension and adaptability, emphasizing its potential for real-world
applications. The chapters of this paper describe the key components of the
system and the dataset structure. The dataset for fine-tuning step generation
model is provided at the following link: link coming soon
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16209" title="Abstract">arXiv:2401.16209</a> [<a href="/pdf/2401.16209" title="Download PDF">pdf</a>, <a href="/format/2401.16209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiMUC: Multilingual Template Filling on MUC-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gantt%2C+W">William Gantt</a>, 
<a href="/search/cs?searchtype=author&query=Behzad%2C+S">Shabnam Behzad</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+H+Y">Hannah YoungEun An</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunmo Chen</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+A+S">Aaron Steven White</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Yarmohammadi%2C+M">Mahsa Yarmohammadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce MultiMUC, the first multilingual parallel corpus for template
filling, comprising translations of the classic MUC-4 template filling
benchmark into five languages: Arabic, Chinese, Farsi, Korean, and Russian. We
obtain automatic translations from a strong multilingual machine translation
system and manually project the original English annotations into each target
language. For all languages, we also provide human translations for sentences
in the dev and test splits that contain annotated template arguments. Finally,
we present baselines on MultiMUC both with state-of-the-art template filling
models and with ChatGPT.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16212" title="Abstract">arXiv:2401.16212</a> [<a href="/pdf/2401.16212" title="Download PDF">pdf</a>, <a href="/format/2401.16212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Call GPT, Comparing Large Language Models Against Lawyers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martin%2C+L">Lauren Martin</a>, 
<a href="/search/cs?searchtype=author&query=Whitehouse%2C+N">Nick Whitehouse</a>, 
<a href="/search/cs?searchtype=author&query=Yiu%2C+S">Stephanie Yiu</a>, 
<a href="/search/cs?searchtype=author&query=Catterson%2C+L">Lizzie Catterson</a>, 
<a href="/search/cs?searchtype=author&query=Perera%2C+R">Rivindu Perera</a> (Onit AI Centre of Excellence)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper presents a groundbreaking comparison between Large Language Models
and traditional legal contract reviewers, Junior Lawyers and Legal Process
Outsourcers. We dissect whether LLMs can outperform humans in accuracy, speed,
and cost efficiency during contract review. Our empirical analysis benchmarks
LLMs against a ground truth set by Senior Lawyers, uncovering that advanced
models match or exceed human accuracy in determining legal issues. In speed,
LLMs complete reviews in mere seconds, eclipsing the hours required by their
human counterparts. Cost wise, LLMs operate at a fraction of the price,
offering a staggering 99.97 percent reduction in cost over traditional methods.
These results are not just statistics, they signal a seismic shift in legal
practice. LLMs stand poised to disrupt the legal industry, enhancing
accessibility and efficiency of legal services. Our research asserts that the
era of LLM dominance in legal contract review is upon us, challenging the
status quo and calling for a reimagined future of legal workflows.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16213" title="Abstract">arXiv:2401.16213</a> [<a href="/pdf/2401.16213" title="Download PDF">pdf</a>, <a href="/format/2401.16213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Study on Sequentiality in Universal Classification with  Empirically Observed Statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Ching-Fang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+I">I-Hsiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In hypothesis testing problems, taking samples sequentially and stopping
opportunistically to make the inference greatly enhances the reliability. The
design of the stopping and inference policy, however, critically relies on the
knowledge of the underlying distribution of each hypothesis. When the knowledge
of distributions, say, $P_0$ and $P_1$ in the binary-hypothesis case, is
replaced by empirically observed statistics from the respective distributions,
the gain of sequentiality is less understood when subject to universality
constraints. In this work, the gap is mended by a unified study on
sequentiality in the universal binary classification problem. We propose a
unified framework where the universality constraints are set on the expected
stopping time as well as the type-I error exponent. The type-I error exponent
is required to achieve a pre-set distribution-dependent constraint
$\lambda(P_0,P_1)$ for all $P_0,P_1$. The framework is employed to investigate
a semi-sequential and a fully-sequential setup, so that fair comparison can be
made with the fixed-length setup. The optimal type-II error exponents in
different setups are characterized when the function $\lambda$ satisfies mild
continuity conditions. The benefit of sequentiality is shown by comparing the
semi-sequential, the fully-sequential, and the fixed-length cases in
representative examples of $\lambda$. Conditions under which sequentiality
eradicates the trade-off between error exponents are also derived.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16215" title="Abstract">arXiv:2401.16215</a> [<a href="/pdf/2401.16215" title="Download PDF">pdf</a>, <a href="/format/2401.16215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning big logical rules by joining small rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hocquette%2C+C">C&#xe9;line Hocquette</a>, 
<a href="/search/cs?searchtype=author&query=Niskanen%2C+A">Andreas Niskanen</a>, 
<a href="/search/cs?searchtype=author&query=Morel%2C+R">Rolf Morel</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%A4rvisalo%2C+M">Matti J&#xe4;rvisalo</a>, 
<a href="/search/cs?searchtype=author&query=Cropper%2C+A">Andrew Cropper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">A major challenge in inductive logic programming is learning big rules. To
address this challenge, we introduce an approach where we join small rules to
learn big rules. We implement our approach in a constraint-driven system and
use constraint solvers to efficiently join rules. Our experiments on many
domains, including game playing and drug design, show that our approach can (i)
learn rules with more than 100 literals, and (ii) drastically outperform
existing approaches in terms of predictive accuracies.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16216" title="Abstract">arXiv:2401.16216</a> [<a href="/pdf/2401.16216" title="Download PDF">pdf</a>, <a href="/ps/2401.16216" title="Download PostScript">ps</a>, <a href="/format/2401.16216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A mechanism for discovering semantic relationships among agent  communication protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berges%2C+I">Idoia Berges</a>, 
<a href="/search/cs?searchtype=author&query=Berm%C3%BAdez%2C+J">Jes&#xfa;s Berm&#xfa;dez</a>, 
<a href="/search/cs?searchtype=author&query=Go%C3%B1i%2C+A">Alfredo Go&#xf1;i</a>, 
<a href="/search/cs?searchtype=author&query=Illarramendi%2C+A">Arantza Illarramendi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The final published version of this paper can be found in Idoia Berges, Jes\'us Berm\'udez, Alfredo Go\~ni, Arantza Illarramendi. 2011. A mechanism for discovering semantic relationships among agent communication protocols. Autonomous Agents and Multi Agent Systems 23(3): 453-485. DOI: <a href="https://doi.org/10.1007/s10458-010-9154-1.">this https URL</a> arXiv admin note: text overlap with <a href="/abs/2401.11841">arXiv:2401.11841</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Autonomous Agents and Multi Agent Systems 2011. 23(3): 453-485
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">One relevant aspect in the development of the Semantic Web framework is the
achievement of a real inter-agents communication capability at the semantic
level. Agents should be able to communicate with each other freely using
different communication protocols, constituted by communication acts. For that
scenario, we introduce in this paper an efficient mechanism presenting the
following main features: - It promotes the description of the communication
acts of protocols as classes that belong to a communication acts ontology, and
associates to those acts a social commitment semantics formalized through
predicates in the Event Calculus. - It is sustained on the idea that different
protocols can be compared semantically by looking to the set of fluents
associated to each branch of the protocols. Those sets are generated using
Semantic Web technology rules. - It discovers the following types of protocol
relationships: equivalence, specialization, restriction, prefix, suffix, infix
and complement_to_infix.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16221" title="Abstract">arXiv:2401.16221</a> [<a href="/pdf/2401.16221" title="Download PDF">pdf</a>, <a href="/format/2401.16221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundations of Work-Systems Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Proper%2C+H+A">Henderik Alex Proper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">In 2006, the course "Modeling of Organizations" is taught for the third time.
This third time will be the second time we will use the new lecture notes "Work
Systems Modelling" from the DA VINCI series. These lecture notes, however, will
be evolved further hand-in-hand with the actual process of lecturing. In the
academic year 2005/2006, a second incarnation of these lecture notes will be
created, where the aim is to deliver these lecture notes in three increments.
An important step that will be taken in this academic year is the integration
of the ICIS Work Systems Modelling lecture notes with the NICI course on
Organisational Dynamics. The first results of this integration will start to
appear in the second and third trimester.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16222" title="Abstract">arXiv:2401.16222</a> [<a href="/pdf/2401.16222" title="Download PDF">pdf</a>, <a href="/format/2401.16222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling Solar PV Adoption in Irish Dairy Farms using Agent-Based  Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faiud%2C+I">Iias Faiud</a>, 
<a href="/search/cs?searchtype=author&query=Schukat%2C+M">Michael Schukat</a>, 
<a href="/search/cs?searchtype=author&query=Mason%2C+K">Karl Mason</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The agricultural sector is facing mounting demands to enhance energy
efficiency within farm enterprises, concurrent with a steady escalation in
electricity costs. This paper focuses on modelling the adoption rate of
photovoltaic (PV) energy within the dairy sector in Ireland. An agent-based
modelling approach is introduced to estimate the adoption rate. The model
considers grid energy prices, revenue, costs, and maintenance expenses to
calculate the probability of PV adoption. The ABM outputs estimate that by year
2022, 2.45% of dairy farmers have installed PV. This is a 0.45% difference to
the actual PV adoption rate in year 2022. This validates the proposed ABM. The
paper demonstrates the increasing interest in PV systems as evidenced by the
rate of adoption, shedding light on the potential advantages of PV energy
adoption in agriculture. This study possesses the potential to forecast future
rates of PV energy adoption among dairy farmers. It establishes a groundwork
for further research on predicting and understanding the factors influencing
the adoption of renewable energy.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16224" title="Abstract">arXiv:2401.16224</a> [<a href="/pdf/2401.16224" title="Download PDF">pdf</a>, <a href="/format/2401.16224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffutoon: High-Resolution Editable Toon Shading via Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhongjie Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Weining Qian</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Toon shading is a type of non-photorealistic rendering task of animation. Its
primary purpose is to render objects with a flat and stylized appearance. As
diffusion models have ascended to the forefront of image synthesis
methodologies, this paper delves into an innovative form of toon shading based
on diffusion models, aiming to directly render photorealistic videos into anime
styles. In video stylization, extant methods encounter persistent challenges,
notably in maintaining consistency and achieving high visual quality. In this
paper, we model the toon shading problem as four subproblems: stylization,
consistency enhancement, structure guidance, and colorization. To address the
challenges in video stylization, we propose an effective toon shading approach
called \textit{Diffutoon}. Diffutoon is capable of rendering remarkably
detailed, high-resolution, and extended-duration videos in anime style. It can
also edit the content according to prompts via an additional branch. The
efficacy of Diffutoon is evaluated through quantitive metrics and human
evaluation. Notably, Diffutoon surpasses both open-source and closed-source
baseline approaches in our experiments. Our work is accompanied by the release
of both the source code and example videos on Github (Project page:
https://ecnu-cilab.github.io/DiffutoonProjectPage/).
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16227" title="Abstract">arXiv:2401.16227</a> [<a href="/pdf/2401.16227" title="Download PDF">pdf</a>, <a href="/format/2401.16227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Volumetric Saliency Guided Image Summarization for RGB-D Indoor Scene  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meena%2C+P">Preeti Meena</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+H">Himanshu Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+S">Sandeep Yadav</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Image summary, an abridged version of the original visual content, can be
used to represent the scene. Thus, tasks such as scene classification,
identification, indexing, etc., can be performed efficiently using the unique
summary. Saliency is the most commonly used technique for generating the
relevant image summary. However, the definition of saliency is subjective in
nature and depends upon the application. Existing saliency detection methods
using RGB-D data mainly focus on color, texture, and depth features.
Consequently, the generated summary contains either foreground objects or
non-stationary objects. However, applications such as scene identification
require stationary characteristics of the scene, unlike state-of-the-art
methods. This paper proposes a novel volumetric saliency-guided framework for
indoor scene classification. The results highlight the efficacy of the proposed
method.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16228" title="Abstract">arXiv:2401.16228</a> [<a href="/pdf/2401.16228" title="Download PDF">pdf</a>, <a href="/format/2401.16228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Anatomy of Real-World R Code for Static Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sihler%2C+F">Florian Sihler</a>, 
<a href="/search/cs?searchtype=author&query=Pietzschmann%2C+L">Lukas Pietzschmann</a>, 
<a href="/search/cs?searchtype=author&query=Straub%2C+R">Raphael Straub</a>, 
<a href="/search/cs?searchtype=author&query=Tichy%2C+M">Matthias Tichy</a>, 
<a href="/search/cs?searchtype=author&query=Diera%2C+A">Andor Diera</a>, 
<a href="/search/cs?searchtype=author&query=Dahou%2C+A">Abdelhalim Dahou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11+1 pages, 6 figures, 2 tables, accepted at MSR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">CONTEXT The R programming language has a huge and active community,
especially in the area of statistical computing. Its interpreted nature allows
for several interesting constructs, like the manipulation of functions at
run-time, that hinder the static analysis of R programs. At the same time,
there is a lack of existing research regarding how these features, or even the
R language as a whole are used in practice. OBJECTIVE In this paper, we conduct
a large-scale, static analysis of more than 50 million lines of real-world R
programs and packages to identify their characteristics and the features that
are actually used. Moreover, we compare the similarities and differences
between the scripts of R users and the implementations of package authors. We
provide insights for static analysis tools like the lintr package as well as
potential interpreter optimizations and uncover areas for future research.
METHOD We analyze 4230 R scripts submitted alongside publications and the
sources of 19450 CRAN packages for over 350000 R files, collecting and
summarizing quantitative information for features of interest. RESULTS We find
a high frequency of name-based indexing operations, assignments, and loops, but
a low frequency for most of R's reflective functions. Furthermore, we find
neither testing functions nor many calls to R's foreign function interface
(FFI) in the publication submissions. CONCLUSION R scripts and package sources
differ, for example, in their size, the way they include other packages, and
their usage of R's reflective capabilities. We provide features that are used
frequently and should be prioritized by static analysis tools, like operator
assignments, function calls, and certain reflective functions like load.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16230" title="Abstract">arXiv:2401.16230</a> [<a href="/pdf/2401.16230" title="Download PDF">pdf</a>, <a href="/format/2401.16230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elementary first-order model checking for sparse graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gajarsk%C3%BD%2C+J">Jakub Gajarsk&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Micha&#x142; Pilipczuk</a>, 
<a href="/search/cs?searchtype=author&query=Soko%C5%82owski%2C+M">Marek Soko&#x142;owski</a>, 
<a href="/search/cs?searchtype=author&query=Stamoulis%2C+G">Giannos Stamoulis</a>, 
<a href="/search/cs?searchtype=author&query=Toru%C5%84czyk%2C+S">Szymon Toru&#x144;czyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO); Logic (math.LO)

</div>
<p class="mathjax">It is known that for subgraph-closed graph classes the first-order model
checking problem is fixed-parameter tractable if and only if the class is
nowhere dense [Grohe, Kreutzer, Siebertz, STOC 2014]. However, the dependency
on the formula size is non-elementary, and in fact, this is unavoidable even
for the class of all trees [Frick and Grohe, LICS 2002]. On the other hand, it
is known that the dependency is elementary for classes of bounded degree [Frick
and Grohe, LICS 2002] as well as for classes of bounded pathwidth [Lampis,
ICALP 2023]. In this paper we generalise these results and almost completely
characterise subgraph-closed graph classes for which the model checking problem
is fixed-parameter tractable with an elementary dependency on the formula size.
Those are the graph classes for which there exists a number $d$ such that for
every $r$, some tree of depth $d$ and size bounded by an elementary function of
$r$ is avoided as an $({\leq} r)$-subdivision in all graphs in the class. In
particular, this implies that if the class in question excludes a fixed tree as
a topological minor, then first-order model checking for graphs in the class is
fixed-parameter tractable with an elementary dependency on the formula size.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16231" title="Abstract">arXiv:2401.16231</a> [<a href="/pdf/2401.16231" title="Download PDF">pdf</a>, <a href="/format/2401.16231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Mitigation for Thermodynamic Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aifer%2C+M">Maxwell Aifer</a>, 
<a href="/search/cs?searchtype=author&query=Melanson%2C+D">Denis Melanson</a>, 
<a href="/search/cs?searchtype=author&query=Donatella%2C+K">Kaelan Donatella</a>, 
<a href="/search/cs?searchtype=author&query=Crooks%2C+G">Gavin Crooks</a>, 
<a href="/search/cs?searchtype=author&query=Ahle%2C+T">Thomas Ahle</a>, 
<a href="/search/cs?searchtype=author&query=Coles%2C+P+J">Patrick J. Coles</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Statistical Mechanics (cond-mat.stat-mech); Quantum Physics (quant-ph)

</div>
<p class="mathjax">While physics-based computing can offer speed and energy efficiency compared
to digital computing, it also is subject to errors that must be mitigated. For
example, many error mitigation methods have been proposed for quantum
computing. However this error mitigation framework has yet to be applied to
other physics-based computing paradigms. In this work, we consider
thermodynamic computing, which has recently captured attention due to its
relevance to artificial intelligence (AI) applications, such as probabilistic
AI and generative AI. A key source of errors in this paradigm is the
imprecision of the analog hardware components. Here, we introduce a method that
reduces the overall error from a linear to a quadratic dependence (from
$\epsilon$ to $\epsilon^2$) on the imprecision $\epsilon$, for Gaussian
sampling and linear algebra applications. The method involves sampling from an
ensemble of imprecise distributions associated with various rounding events and
then merging these samples. We numerically demonstrate the scalability of this
method for dimensions greater than 1000. Finally, we implement this method on
an actual thermodynamic computer and show $20\%$ error reduction for matrix
inversion; the first thermodynamic error mitigation experiment.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16232" title="Abstract">arXiv:2401.16232</a> [<a href="/pdf/2401.16232" title="Download PDF">pdf</a>, <a href="/ps/2401.16232" title="Download PostScript">ps</a>, <a href="/format/2401.16232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Database Liveness Detection: Insights from Comparative Biometric  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+O">Oleksandr Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Zakharov%2C+D">Dmytro Zakharov</a>, 
<a href="/search/cs?searchtype=author&query=Frontoni%2C+E">Emanuele Frontoni</a>, 
<a href="/search/cs?searchtype=author&query=Maranesi%2C+A">Andrea Maranesi</a>, 
<a href="/search/cs?searchtype=author&query=Bohucharskyi%2C+S">Serhii Bohucharskyi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at SCIA 2023, Lviv, Ukraine, Nov. 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2nd International Workshop on Social
  Communication and Information Activity in Digital Humanities (SCIA 2023), in
  CEUR Workshop Proceedings, vol. 3608, 2023, pp. 250-263
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In an era where biometric security serves as a keystone of modern identity
verification systems, ensuring the authenticity of these biometric samples is
paramount. Liveness detection, the capability to differentiate between genuine
and spoofed biometric samples, stands at the forefront of this challenge. This
research presents a comprehensive evaluation of liveness detection models, with
a particular focus on their performance in cross-database scenarios, a test
paradigm notorious for its complexity and real-world relevance. Our study
commenced by meticulously assessing models on individual datasets, revealing
the nuances in their performance metrics. Delving into metrics such as the Half
Total Error Rate, False Acceptance Rate, and False Rejection Rate, we unearthed
invaluable insights into the models' strengths and weaknesses. Crucially, our
exploration of cross-database testing provided a unique perspective,
highlighting the chasm between training on one dataset and deploying on
another. Comparative analysis with extant methodologies, ranging from
convolutional networks to more intricate strategies, enriched our understanding
of the current landscape. The variance in performance, even among
state-of-the-art models, underscored the inherent challenges in this domain. In
essence, this paper serves as both a repository of findings and a clarion call
for more nuanced, data-diverse, and adaptable approaches in biometric liveness
detection. In the dynamic dance between authenticity and deception, our work
offers a blueprint for navigating the evolving rhythms of biometric security.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16233" title="Abstract">arXiv:2401.16233</a> [<a href="/pdf/2401.16233" title="Download PDF">pdf</a>, <a href="/ps/2401.16233" title="Download PostScript">ps</a>, <a href="/format/2401.16233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Proof Development in Dafny with Module-Based Induction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+S">Son Ho</a>, 
<a href="/search/cs?searchtype=author&query=Pit-Claudel%2C+C">Cl&#xe9;ment Pit-Claudel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Highly automated theorem provers like Dafny allow users to prove simple
properties with little effort, making it easy to quickly sketch proofs. The
drawback is that such provers leave users with little control about the proof
search, meaning that the small changes inherent to the iterative process of
writing a proof often lead to unpredictable variations in verification time,
and eventually hard-to-diagnose proof failures. This sometimes turns the boon
of high automation into a curse, as instead of breaking early and showing
unsolved goals to the user like in Coq, proofs tend to gradually become
unstable until their verification time explodes. At this point, the absence of
a proof context to investigate often leaves the user to a painful debugging
session. In this paper, we show how to use Dafny modules to encode Coq-like
induction principles to dramatically improve the stability and maintainability
of proofs about inductive data structures.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16234" title="Abstract">arXiv:2401.16234</a> [<a href="/pdf/2401.16234" title="Download PDF">pdf</a>, <a href="/format/2401.16234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAEDALUS: Defense Against Firmware ROP Exploits Using Stochastic  Software Diversity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Obaidat%2C+I">Islam Obaidat</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+M">Meera Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Tavakoli%2C+F">Fatemeh Tavakoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper presents DAEDALUS, a software diversity-based framework designed
to resist ROP attacks on Linux-based IoT devices. DAEDALUS generates unique,
semantically equivalent but syntactically different rewrites of IoT firmware,
disrupting large-scale replication of ROP attacks. DAEDALUS employs STOKE, a
stochastic optimizer for x86 binaries, as its core diversity engine but
introduces significant extensions to address unique IoT firmware challenges.
DAEDALUS's effectiveness is evaluated using DDoSim, a published botnet DDoS
attack simulation testbed. Results demonstrate that DAEDALUS successfully
neutralizes ROP payloads by diversifying critical basic blocks in the firmware,
preventing attackers from compromising multiple devices for DDoS attacks via
memory error vulnerabilities. The findings indicate that DAEDALUS not only
mitigates the impact of ROP attacks on individual IoT devices through
probabilistic protection but also thwarts large-scale ROP attacks across
multiple devices.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16235" title="Abstract">arXiv:2401.16235</a> [<a href="/pdf/2401.16235" title="Download PDF">pdf</a>, <a href="/ps/2401.16235" title="Download PostScript">ps</a>, <a href="/format/2401.16235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Player Pressure Map - A Novel Representation of Pressure in Soccer for  Evaluating Player Performance in Different Game Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+C">Chaoyi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+J">Jiaming Na</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yisheng Pei</a>, 
<a href="/search/cs?searchtype=author&query=De+Silva%2C+V">Varuna De Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">In soccer, contextual player performance metrics are invaluable to coaches.
For example, the ability to perform under pressure during matches distinguishes
the elite from the average. Appropriate pressure metric enables teams to assess
players' performance accurately under pressure and design targeted training
scenarios to address their weaknesses. The primary objective of this paper is
to leverage both tracking and event data and game footage to capture the
pressure experienced by the possession team in a soccer game scene. We propose
a player pressure map to represent a given game scene, which lowers the
dimension of raw data and still contains rich contextual information. Not only
does it serve as an effective tool for visualizing and evaluating the pressure
on the team and each individual, but it can also be utilized as a backbone for
accessing players' performance. Overall, our model provides coaches and
analysts with a deeper understanding of players' performance under pressure so
that they make data-oriented tactical decisions.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16236" title="Abstract">arXiv:2401.16236</a> [<a href="/pdf/2401.16236" title="Download PDF">pdf</a>, <a href="/format/2401.16236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Communication with Dynamic Feature Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Talli%2C+P">Pietro Talli</a>, 
<a href="/search/cs?searchtype=author&query=Pase%2C+F">Francesco Pase</a>, 
<a href="/search/cs?searchtype=author&query=Chiariotti%2C+F">Federico Chiariotti</a>, 
<a href="/search/cs?searchtype=author&query=Zanella%2C+A">Andrea Zanella</a>, 
<a href="/search/cs?searchtype=author&query=Zorzi%2C+M">Michele Zorzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE Transactions on Communications (under review). arXiv admin note: substantial text overlap with <a href="/abs/2301.05901">arXiv:2301.05901</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Multiagent Systems (cs.MA); Optimization and Control (math.OC)

</div>
<p class="mathjax">The remote wireless control of industrial systems is one of the major use
cases for 5G and beyond systems: in these cases, the massive amounts of sensory
information that need to be shared over the wireless medium may overload even
high-capacity connections. Consequently, solving the effective communication
problem by optimizing the transmission strategy to discard irrelevant
information can provide a significant advantage, but is often a very complex
task. In this work, we consider a prototypal system in which an observer must
communicate its sensory data to a robot controlling a task (e.g., a mobile
robot in a factory). We then model it as a remote Partially Observable Markov
Decision Process (POMDP), considering the effect of adopting semantic and
effective communication-oriented solutions on the overall system performance.
We split the communication problem by considering an ensemble Vector Quantized
Variational Autoencoder (VQ-VAE) encoding, and train a Deep Reinforcement
Learning (DRL) agent to dynamically adapt the quantization level, considering
both the current state of the environment and the memory of past messages. We
tested the proposed approach on the well-known CartPole reference control
problem, obtaining a significant performance increase over traditional
approaches.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16238" title="Abstract">arXiv:2401.16238</a> [<a href="/pdf/2401.16238" title="Download PDF">pdf</a>, <a href="/format/2401.16238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alternating Minimization for Wideband Multiuser IRS-aided MIMO Systems  under Imperfect CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Ad%C3%A1n%2C+D">Darian P&#xe9;rez-Ad&#xe1;n</a> (1), 
<a href="/search/cs?searchtype=author&query=Joham%2C+M">Michael Joham</a> (2), 
<a href="/search/cs?searchtype=author&query=Fresnedo%2C+%C3%93">&#xd3;scar Fresnedo</a> (1), 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Coma%2C+J+P">Jos&#xe9; P. Gonz&#xe1;lez-Coma</a> (3), 
<a href="/search/cs?searchtype=author&query=Castedo%2C+L">Luis Castedo</a> (1), 
<a href="/search/cs?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a> ((1) University of A Coru&#xf1;a, (2) Technical University of Munich, (3) Defense University Center at the Spanish Naval Academy)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Signal Processing, vol. 72, pp. 99-114, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This work focuses on wideband intelligent reflecting surface (IRS)-aided
multiuser MIMO systems. One of the major challenges of this scenario is the
joint design of the frequency-dependent base station (BS) precoder and user
filters, and the IRS phase-shift matrix which is frequency flat and common to
all the users. In addition, we consider that the channel state information
(CSI) is imperfect at both the transmitter and the receivers. A statistical
model for the imperfect CSI is developed and exploited for the system design. A
minimum mean square error (MMSE) approach is followed to determine the IRS
phase-shift matrix, the transmit precoders, and the receiving filters. The
broadcast (BC)- multiple access channel (MAC) duality is used to solve the
optimization problem following an alternating minimization approach. Numerical
results show that the proposed approach leads to substantial performance gains
with respect to baseline strategies that neglect the inter-user interference
and do not optimize the IRS phase-shift matrix. Further performance gains are
obtained when incorporating into the system design the statistical information
of the channel estimation errors.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16240" title="Abstract">arXiv:2401.16240</a> [<a href="/pdf/2401.16240" title="Download PDF">pdf</a>, <a href="/format/2401.16240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clinically meaningful timeline summarisation in social media for mental  health monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiayu Song</a>, 
<a href="/search/cs?searchtype=author&query=Chim%2C+J">Jenny Chim</a>, 
<a href="/search/cs?searchtype=author&query=Tsakalidis%2C+A">Adam Tsakalidis</a>, 
<a href="/search/cs?searchtype=author&query=Ive%2C+J">Julia Ive</a>, 
<a href="/search/cs?searchtype=author&query=Atzil-Slonim%2C+D">Dana Atzil-Slonim</a>, 
<a href="/search/cs?searchtype=author&query=Liakata%2C+M">Maria Liakata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce the new task of clinically meaningful summarisation of social
media user timelines, appropriate for mental health monitoring. We develop a
novel approach for unsupervised abstractive summarisation that produces a
two-layer summary consisting of both high-level information, covering aspects
useful to clinical experts, as well as accompanying time sensitive evidence
from a user's social media timeline. A key methodological novelty comes from
the timeline summarisation component based on a version of hierarchical
variational autoencoder (VAE) adapted to represent long texts and guided by
LLM-annotated key phrases. The resulting timeline summary is input into a LLM
(LLaMA-2) to produce the final summary containing both the high level
information, obtained through instruction prompting, as well as corresponding
evidence from the user's timeline. We assess the summaries generated by our
novel architecture via automatic evaluation against expert written summaries
and via human evaluation with clinical experts, showing that timeline
summarisation by TH-VAE results in logically coherent summaries rich in
clinical utility and superior to LLM-only approaches in capturing changes over
time.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16241" title="Abstract">arXiv:2401.16241</a> [<a href="/pdf/2401.16241" title="Download PDF">pdf</a>, <a href="/format/2401.16241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Estimation and Hybrid Precoding for Frequency Selective  Multiuser mmWave MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Coma%2C+J+P">J. P. Gonz&#xe1;lez-Coma</a> (1), 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-Fern%C3%A1ndez%2C+J">J. Rodr&#xed;guez-Fern&#xe1;ndez</a> (2), 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Prelcic%2C+N">N. Gonz&#xe1;lez-Prelcic</a> (2), 
<a href="/search/cs?searchtype=author&query=Castedo%2C+L">L. Castedo</a> (1), 
<a href="/search/cs?searchtype=author&query=Heath%2C+R+W">R. W. Heath</a> (3) ((1) University of A Coru&#xf1;a, (2) University of Vigo, (3) The University of Texas at Austin)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE J. Sel. Top. Signal Process., vol. 12, no. 2, pp. 353-367,
  May 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Configuring the hybrid precoders and combiners in a millimeter wave (mmWave)
multiuser (MU) multiple-input multiple-output (MIMO) system is challenging in
frequency selective channels. In this paper, we develop a system that uses
compressive estimation on the uplink to configure precoders and combiners for
the downlink (DL). In the first step, the base station (BS) simultaneously
estimates the channels from all the mobile stations (MSs) on each subcarrier.
To reduce the number of measurements required, compressed sensing techniques
are developed that exploit common support on the different subcarriers. In the
second step, exploiting reciprocity and the channel estimates, the base station
designs hybrid precoders and combiners. Two algorithms are developed for this
purpose, with different performance and complexity tradeoffs: 1) a
factorization of the purely digital solution, and 2) an iterative hybrid
design. Extensive numerical experiments evaluate the proposed solutions
comparing to state-of-the-art strategies, and illustrating design tradeoffs in
overhead, complexity, and performance.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16244" title="Abstract">arXiv:2401.16244</a> [<a href="/pdf/2401.16244" title="Download PDF">pdf</a>, <a href="/ps/2401.16244" title="Download PostScript">ps</a>, <a href="/format/2401.16244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Employing Iterative Feature Selection in Fuzzy Rule-Based Binary  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoning Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qinghua Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The feature selection in a traditional binary classification algorithm is
always used in the stage of dataset preprocessing, which makes the obtained
features not necessarily the best ones for the classification algorithm, thus
affecting the classification performance. For a traditional rule-based binary
classification algorithm, classification rules are usually deterministic, which
results in the fuzzy information contained in the rules being ignored. To do
so, this paper employs iterative feature selection in fuzzy rule-based binary
classification. The proposed algorithm combines feature selection based on
fuzzy correlation family with rule mining based on biclustering. It first
conducts biclustering on the dataset after feature selection. Then it conducts
feature selection again for the biclusters according to the feedback of
biclusters evaluation. In this way, an iterative feature selection framework is
build. During the iteration process, it stops until the obtained bicluster
meets the requirements. In addition, the rule membership function is introduced
to extract vectorized fuzzy rules from the bicluster and construct weak
classifiers. The weak classifiers with good classification performance are
selected by Adaptive Boosting and the strong classifier is constructed by
"weighted average". Finally, we perform the proposed algorithm on different
datasets and compare it with other peers. Experimental results show that it
achieves good classification performance and outperforms its peers.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16247" title="Abstract">arXiv:2401.16247</a> [<a href="/pdf/2401.16247" title="Download PDF">pdf</a>, <a href="/format/2401.16247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Red Teaming in Multimodal and Multilingual Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ropers%2C+C">Christophe Ropers</a>, 
<a href="/search/cs?searchtype=author&query=Dale%2C+D">David Dale</a>, 
<a href="/search/cs?searchtype=author&query=Hansanti%2C+P">Prangthip Hansanti</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+G+M">Gabriel Mejia Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Evtimov%2C+I">Ivan Evtimov</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C">Corinne Wong</a>, 
<a href="/search/cs?searchtype=author&query=Touret%2C+C">Christophe Touret</a>, 
<a href="/search/cs?searchtype=author&query=Pereyra%2C+K">Kristina Pereyra</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+S">Seohyun Sonia Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ferrer%2C+C+C">Cristian Canton Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Andrews%2C+P">Pierre Andrews</a>, 
<a href="/search/cs?searchtype=author&query=Costa-juss%C3%A0%2C+M+R">Marta R. Costa-juss&#xe0;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2312.05187">arXiv:2312.05187</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Assessing performance in Natural Language Processing is becoming increasingly
complex. One particular challenge is the potential for evaluation datasets to
overlap with training data, either directly or indirectly, which can lead to
skewed results and overestimation of model performance. As a consequence, human
evaluation is gaining increasing interest as a means to assess the performance
and reliability of models. One such method is the red teaming approach, which
aims to generate edge cases where a model will produce critical errors. While
this methodology is becoming standard practice for generative AI, its
application to the realm of conditional AI remains largely unexplored. This
paper presents the first study on human-based red teaming for Machine
Translation (MT), marking a significant step towards understanding and
improving the performance of translation models. We delve into both human-based
red teaming and a study on automation, reporting lessons learned and providing
recommendations for both translation models and red teaming drills. This
pioneering work opens up new avenues for research and development in the field
of MT.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16250" title="Abstract">arXiv:2401.16250</a> [<a href="/pdf/2401.16250" title="Download PDF">pdf</a>, <a href="/ps/2401.16250" title="Download PostScript">ps</a>, <a href="/format/2401.16250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Solution of ill-posed integral equations through averaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Griebel%2C+M">Michael Griebel</a>, 
<a href="/search/math?searchtype=author&query=Jahn%2C+T">Tim Jahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper discusses the error and cost aspects of ill-posed integral
equations when given discrete noisy point evaluations on a fine grid. Standard
solution methods usually employ discretization schemes that are directly
induced by the measurement points. Thus, they may scale unfavorably with the
number of evaluation points, which can result in computational inefficiency. To
address this issue, we propose an algorithm that achieves the same level of
accuracy while significantly reducing computational costs. Our approach
involves an initial averaging procedure to sparsify the underlying grid. To
keep the exposition simple, we focus only on one-dimensional ill-posed integral
equations that have sufficient smoothness. However, the approach can be
generalized to more complicated two- and three-dimensional problems with
appropriate modifications.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16251" title="Abstract">arXiv:2401.16251</a> [<a href="/pdf/2401.16251" title="Download PDF">pdf</a>, <a href="/format/2401.16251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-silo Federated Learning with Record-level Personalized  Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junxu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Li Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiaofeng Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning enhanced by differential privacy has emerged as a popular
approach to better safeguard the privacy of client-side data by protecting
clients' contributions during the training process. Existing solutions
typically assume a uniform privacy budget for all records and provide
one-size-fits-all solutions that may not be adequate to meet each record's
privacy requirement. In this paper, we explore the uncharted territory of
cross-silo FL with record-level personalized differential privacy. We devise a
novel framework named rPDP-FL, employing a two-stage hybrid sampling scheme
with both client-level sampling and non-uniform record-level sampling to
accommodate varying privacy requirements. A critical and non-trivial problem is
to select the ideal per-record sampling probability q given the personalized
privacy budget {\epsilon}. We introduce a versatile solution named
Simulation-CurveFitting, allowing us to uncover a significant insight into the
nonlinear correlation between q and {\epsilon} and derive an elegant
mathematical model to tackle the problem. Our evaluation demonstrates that our
solution can provide significant performance gains over the baselines that do
not consider personalized privacy preservation.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16258" title="Abstract">arXiv:2401.16258</a> [<a href="/pdf/2401.16258" title="Download PDF">pdf</a>, <a href="/ps/2401.16258" title="Download PostScript">ps</a>, <a href="/format/2401.16258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MosquIoT: A System Based on IoT and Machine Learning for the Monitoring  of Aedes aegypti (Diptera: Culicidae)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aira%2C+J">Javier Aira</a>, 
<a href="/search/cs?searchtype=author&query=Montes%2C+T+O">Teresa Olivares Montes</a>, 
<a href="/search/cs?searchtype=author&query=Delicado%2C+F+M">Francisco M. Delicado</a>, 
<a href="/search/cs?searchtype=author&query=Vezzani%2C+D">Dar&#xec;o Vezzani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
<p class="mathjax">Millions of people around the world are infected with mosquito-borne diseases
each year. One of the most dangerous species is Aedes aegypti, the main vector
of viruses such as dengue, yellow fever, chikungunya, and Zika, among others.
Mosquito prevention and eradication campaigns are essential to avoid major
public health consequences. In this respect, entomological surveillance is an
important tool. At present, this traditional monitoring tool is executed
manually and requires digital transformation to help authorities make better
decisions, improve their planning efforts, speed up execution, and better
manage available resources. Therefore, new technological tools based on proven
techniques need to be designed and developed. However, such tools should also
be cost-effective, autonomous, reliable, and easy to implement, and should be
enabled by connectivity and multi-platform software applications. This paper
presents the design, development, and testing of an innovative system named
MosquIoT. It is based on traditional ovitraps with embedded Internet of Things
(IoT) and Tiny Machine Learning (TinyML) technologies, which enable the
detection and quantification of Ae. aegypti eggs. This innovative and promising
solution may help dynamically understand the behavior of Ae. aegypti
populations in cities, shifting from the current reactive entomological
monitoring model to a proactive and predictive digital one.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16261" title="Abstract">arXiv:2401.16261</a> [<a href="/pdf/2401.16261" title="Download PDF">pdf</a>, <a href="/format/2401.16261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using multiple Dirac delta points to describe inhomogeneous flux density  over a cell boundary in a single-cell diffusion model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Peng%2C+Q">Qiyao Peng</a>, 
<a href="/search/math?searchtype=author&query=Hille%2C+S+C">Sander C. Hille</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">Biological cells can release compounds into their direct environment,
generally inhomogeneously over their cell membrane, after which the compounds
spread by diffusion. In mathematical modelling and simulation of a collective
of such cells, it is theoretically and numerically advantageous to replace
spatial extended cells with point sources, in particular when cell numbers are
large, but still so small that a continuum density description cannot be
justified, or when cells are moving. We show that inhomogeneous flux density
over the cell boundary may be realized in a point source approach, thus
maintaining computational efficiency, by utilizing multiple, clustered point
sources (and sinks). In this report, we limit ourselves to a sinusoidal
function as flux density in the spatial exclusion model, and we show how to
determine the amplitudes of the Dirac delta points in the point source model,
such that the deviation between the point source model and the spatial
exclusion model is small.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16263" title="Abstract">arXiv:2401.16263</a> [<a href="/pdf/2401.16263" title="Download PDF">pdf</a>, <a href="/format/2401.16263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaboration Petri Nets: Verification, Equivalence, and Discovery  (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benzin%2C+J">Janik-Vasily Benzin</a>, 
<a href="/search/cs?searchtype=author&query=Rinderle-Ma%2C+S">Stefanie Rinderle-Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Process modeling and discovery techniques aim to construct sound and valid
process models for different types of processes, i.e., process orchestrations
and collaboration processes. Orchestrations represent behavior of cases within
one process. Collaboration processes represent behavior of collaborating cases
within multiple process orchestrations that interact via collaboration concepts
such as organizations, agents, objects, and services. The heterogeneity of
collaboration concepts and types such as message exchange and resource sharing
has led to different representations and discovery techniques for collaboration
process models, but a standard model class is lacking. We propose collaboration
Petri nets (cPN) to achieve comparability between techniques, to enable
approach and property transfer, and to build a standardized collaboration
mining pipeline similar to process mining. For cPN, we require desirable
modeling power, decision power, modeling convenience, and relations to existing
model classes. We show the representation of collaboration types, structural
characterization as workflow nets, automatic verification of soundness,
bisimulation equivalence to existing model classes, and application in a
general discovery framework. As empirical evidence to discover cPN, we conduct
a comparative evaluation between three discovery techniques on a set of
existing collaboration event logs.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16265" title="Abstract">arXiv:2401.16265</a> [<a href="/pdf/2401.16265" title="Download PDF">pdf</a>, <a href="/format/2401.16265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CO2: Efficient Distributed Training with Full Communication-Computation  Overlap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weigao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shidi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuyang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 Spotlight. Yiran Zhong is the corresponding author. Code is available at: <a href="https://github.com/OpenNLPLab/CO2">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The fundamental success of large language models hinges upon the efficacious
implementation of large-scale distributed training techniques. Nevertheless,
building a vast, high-performance cluster featuring high-speed communication
interconnectivity is prohibitively costly, and accessible only to prominent
entities. In this work, we aim to lower this barrier and democratize
large-scale training with limited bandwidth clusters. We propose a new approach
called CO2 that introduces local-updating and asynchronous communication to the
distributed data-parallel training, thereby facilitating the full overlap of
COmunication with COmputation. CO2 is able to attain a high scalability even on
extensive multi-node clusters constrained by very limited communication
bandwidth. We further propose the staleness gap penalty and outer momentum
clipping techniques together with CO2 to bolster its convergence and training
stability. Besides, CO2 exhibits seamless integration with well-established
ZeRO-series optimizers which mitigate memory consumption of model states with
large model training. We also provide a mathematical proof of convergence,
accompanied by the establishment of a stringent upper bound. Furthermore, we
validate our findings through an extensive set of practical experiments
encompassing a wide range of tasks in the fields of computer vision and natural
language processing. These experiments serve to demonstrate the capabilities of
CO2 in terms of convergence, generalization, and scalability when deployed
across configurations comprising up to 128 A100 GPUs. The outcomes emphasize
the outstanding capacity of CO2 to hugely improve scalability, no matter on
clusters with 800Gbps RDMA or 80Gbps TCP/IP inter-node connections.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16268" title="Abstract">arXiv:2401.16268</a> [<a href="/pdf/2401.16268" title="Download PDF">pdf</a>, <a href="/ps/2401.16268" title="Download PostScript">ps</a>, <a href="/format/2401.16268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A.I. In All The Wrong Places
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6hlen%2C+M">Marc B&#xf6;hlen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruolin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoxu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gopaladinne%2C+S">Srikar Gopaladinne</a>, 
<a href="/search/cs?searchtype=author&query=Gorla%2C+H">Hemanth Gorla</a>, 
<a href="/search/cs?searchtype=author&query=Kandukuri%2C+D">Divya Kandukuri</a>, 
<a href="/search/cs?searchtype=author&query=Mansfield%2C+S">Sean Mansfield</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 tables, 4 images
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This text describes experiences gained across a two-year test period during
which two generations of Generative Artificial Intelligence (A.I.) systems were
incorpo-rated into an interdisciplinary, university level course on A.I. for
art and design practices. The text uses the results from the courses to reflect
on new opportuni-ties for generative systems in art and design while
considering traps and limits.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16270" title="Abstract">arXiv:2401.16270</a> [<a href="/pdf/2401.16270" title="Download PDF">pdf</a>, <a href="/format/2401.16270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capturing Knowledge Graphs and Rules with Octagon Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charpenay%2C+V">Victor Charpenay</a>, 
<a href="/search/cs?searchtype=author&query=Schockaert%2C+S">Steven Schockaert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Region based knowledge graph embeddings represent relations as geometric
regions. This has the advantage that the rules which are captured by the model
are made explicit, making it straightforward to incorporate prior knowledge and
to inspect learned models. Unfortunately, existing approaches are severely
restricted in their ability to model relational composition, and hence also
their ability to model rules, thus failing to deliver on the main promise of
region based models. With the aim of addressing these limitations, we
investigate regions which are composed of axis-aligned octagons. Such octagons
are particularly easy to work with, as intersections and compositions can be
straightforwardly computed, while they are still sufficiently expressive to
model arbitrary knowledge graphs. Among others, we also show that our octagon
embeddings can properly capture a non-trivial class of rule bases. Finally, we
show that our model achieves competitive experimental results.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16274" title="Abstract">arXiv:2401.16274</a> [<a href="/pdf/2401.16274" title="Download PDF">pdf</a>, <a href="/format/2401.16274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The HSF Conditions Database Reference Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mashinistov%2C+R">Ruslan Mashinistov</a>, 
<a href="/search/cs?searchtype=author&query=Gerlach%2C+L">Lino Gerlach</a>, 
<a href="/search/cs?searchtype=author&query=Laycock%2C+P">Paul Laycock</a>, 
<a href="/search/cs?searchtype=author&query=Formica%2C+A">Andrea Formica</a>, 
<a href="/search/cs?searchtype=author&query=Govi%2C+G">Giacomo Govi</a>, 
<a href="/search/cs?searchtype=author&query=Pinkenburg%2C+C">Chris Pinkenburg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; High Energy Physics - Experiment (hep-ex)

</div>
<p class="mathjax">Conditions data is the subset of non-event data that is necessary to process
event data. It poses a unique set of challenges, namely a heterogeneous
structure and high access rates by distributed computing. The HSF Conditions
Databases activity is a forum for cross-experiment discussions inviting as
broad a participation as possible. It grew out of the HSF Community White Paper
work to study conditions data access, where experts from ATLAS, Belle II, and
CMS converged on a common language and proposed a schema that represents best
practice. Following discussions with a broader community, including NP as well
as HEP experiments, a core set of use cases, functionality and behaviour was
defined with the aim to describe a core conditions database API. This paper
will describe the reference implementation of both the conditions database
service and the client which together encapsulate HSF best practice conditions
data handling. Django was chosen for the service implementation, which uses an
ORM instead of the direct use of SQL for all but one method. The simple
relational database schema to organise conditions data is implemented in
PostgreSQL. The task of storing conditions data payloads themselves is
outsourced to any POSIX- compliant filesystem, allowing for transparent
relocation and redundancy. Cru- cially this design provides a clear separation
between retrieving the metadata describing which conditions data are needed for
a data processing job, and retrieving the actual payloads from storage. The
service deployment using Helm on OKD will be described together with scaling
tests and operations experience from the sPHENIX experiment running more than
25k cores at BNL.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16277" title="Abstract">arXiv:2401.16277</a> [<a href="/pdf/2401.16277" title="Download PDF">pdf</a>, <a href="/format/2401.16277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SECOMP: Formally Secure Compilation of Compartmentalized C Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thibault%2C+J">J&#xe9;r&#xe9;my Thibault</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+R">Roberto Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Argo%2C+S">Sven Argo</a>, 
<a href="/search/cs?searchtype=author&query=de+Amorim%2C+A+A">Arthur Azevedo de Amorim</a>, 
<a href="/search/cs?searchtype=author&query=Georges%2C+A+L">A&#xef;na Linn Georges</a>, 
<a href="/search/cs?searchtype=author&query=Hritcu%2C+C">Catalin Hritcu</a>, 
<a href="/search/cs?searchtype=author&query=Tolmach%2C+A">Andrew Tolmach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CCS'24 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Undefined behavior in C often causes devastating security vulnerabilities.
One practical mitigation is compartmentalization, which allows developers to
structure large programs into mutually distrustful compartments with clearly
specified privileges and interactions. In this paper we introduce SECOMP, a
compiler for compartmentalized C code that comes with machine-checked proofs
guaranteeing that the scope of undefined behavior is restricted to the
compartments that encounter it and become dynamically compromised. These
guarantees are formalized as the preservation of safety properties against
adversarial contexts, a secure compilation criterion similar to full
abstraction, and this is the first time such a strong criterion is proven for a
mainstream programming language. To achieve this we extend the languages of the
CompCert verified C compiler with isolated compartments that can only interact
via procedure calls and returns, as specified by cross-compartment interfaces.
We adapt the passes and optimizations of CompCert as well as their correctness
proofs to this compartment-aware setting. We then use compiler correctness as
an ingredient in a larger secure compilation proof that involves several proof
engineering novelties, needed to scale formally secure compilation up to a C
compiler.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16279" title="Abstract">arXiv:2401.16279</a> [<a href="/pdf/2401.16279" title="Download PDF">pdf</a>, <a href="/format/2401.16279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Producer-Consumer Relationship in Modern DRAM-Based  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+M">Minesh Patel</a>, 
<a href="/search/cs?searchtype=author&query=Shahroodi%2C+T">Taha Shahroodi</a>, 
<a href="/search/cs?searchtype=author&query=Manglik%2C+A">Aditya Manglik</a>, 
<a href="/search/cs?searchtype=author&query=Ya%C4%9Fl%C4%B1k%C3%A7%C4%B1%2C+A+G">Abdullah Giray Ya&#x11f;l&#x131;k&#xe7;&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haocong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2204.10378">arXiv:2204.10378</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Generational improvements to commodity DRAM throughout half a century have
long solidified its prevalence as main memory across the computing industry.
However, overcoming today's DRAM technology scaling challenges requires new
solutions driven by both DRAM producers and consumers. In this paper, we
observe that the separation of concerns between producers and consumers
specified by industry-wide DRAM standards is becoming a liability to progress
in addressing scaling-related concerns.
<br />To understand the problem, we study four key directions for overcoming DRAM
scaling challenges using system-memory cooperation: (i) improving memory access
latencies; (ii) reducing DRAM refresh overheads; (iii) securely defending
against the RowHammer vulnerability; and (iv) addressing worsening memory
errors. We find that the single most important barrier to advancement in all
four cases is the consumer's lack of insight into DRAM reliability. Based on an
analysis of DRAM reliability testing, we recommend revising the separation of
concerns to incorporate limited information transparency between producers and
consumers. Finally, we propose adopting this revision in a two-step plan,
starting with immediate information release through crowdsourcing and
publication and culminating in widespread modifications to DRAM standards.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16280" title="Abstract">arXiv:2401.16280</a> [<a href="/pdf/2401.16280" title="Download PDF">pdf</a>, <a href="/format/2401.16280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cutup and Detect: Human Fall Detection on Cutup Untrimmed Videos Using a  Large Foundational Video Understanding Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grutschus%2C+T">Till Grutschus</a>, 
<a href="/search/cs?searchtype=author&query=Karrar%2C+O">Ola Karrar</a>, 
<a href="/search/cs?searchtype=author&query=Esenov%2C+E">Emir Esenov</a>, 
<a href="/search/cs?searchtype=author&query=Vats%2C+E">Ekta Vats</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work explores the performance of a large video understanding foundation
model on the downstream task of human fall detection on untrimmed video and
leverages a pretrained vision transformer for multi-class action detection,
with classes: "Fall", "Lying" and "Other/Activities of daily living (ADL)". A
method for temporal action localization that relies on a simple cutup of
untrimmed videos is demonstrated. The methodology includes a preprocessing
pipeline that converts datasets with timestamp action annotations into labeled
datasets of short action clips. Simple and effective clip-sampling strategies
are introduced. The effectiveness of the proposed method has been empirically
evaluated on the publicly available High-Quality Fall Simulation Dataset
(HQFSD). The experimental results validate the performance of the proposed
pipeline. The results are promising for real-time application, and the falls
are detected on video level with a state-of-the-art 0.96 F1 score on the HQFSD
dataset under the given experimental settings. The source code will be made
available on GitHub.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16282" title="Abstract">arXiv:2401.16282</a> [<a href="/pdf/2401.16282" title="Download PDF">pdf</a>, <a href="/format/2401.16282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAPLE: Micro Analysis of Pairwise Language Evolution for Few-Shot Claim  Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zubiaga%2C+A">Arkaitz Zubiaga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by EACL Findings 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Claim verification is an essential step in the automated fact-checking
pipeline which assesses the veracity of a claim against a piece of evidence. In
this work, we explore the potential of few-shot claim verification, where only
very limited data is available for supervision. We propose MAPLE (Micro
Analysis of Pairwise Language Evolution), a pioneering approach that explores
the alignment between a claim and its evidence with a small seq2seq model and a
novel semantic measure. Its innovative utilization of micro language evolution
path leverages unlabelled pairwise data to facilitate claim verification while
imposing low demand on data annotations and computing resources. MAPLE
demonstrates significant performance improvements over SOTA baselines SEED, PET
and LLaMA 2 across three fact-checking datasets: FEVER, Climate FEVER, and
SciFact. Data and code are available here: https://github.com/XiaZeng0223/MAPLE
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16284" title="Abstract">arXiv:2401.16284</a> [<a href="/pdf/2401.16284" title="Download PDF">pdf</a>, <a href="/format/2401.16284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Positional Encoding for Robust Multi-Reference-Based Object  6D Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaewoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaeguk Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+N+I">Nam Ik Cho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurately estimating the pose of an object is a crucial task in computer
vision and robotics. There are two main deep learning approaches for this:
geometric representation regression and iterative refinement. However, these
methods have some limitations that reduce their effectiveness. In this paper,
we analyze these limitations and propose new strategies to overcome them. To
tackle the issue of blurry geometric representation, we use positional encoding
with high-frequency components for the object's 3D coordinates. To address the
local minimum problem in refinement methods, we introduce a normalized image
plane-based multi-reference refinement strategy that's independent of intrinsic
matrix constraints. Lastly, we utilize adaptive instance normalization and a
simple occlusion augmentation method to help our model concentrate on the
target object. Our experiments on Linemod, Linemod-Occlusion, and YCB-Video
datasets demonstrate that our approach outperforms existing methods. We will
soon release the code.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16285" title="Abstract">arXiv:2401.16285</a> [<a href="/pdf/2401.16285" title="Download PDF">pdf</a>, <a href="/format/2401.16285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capturing Pertinent Symbolic Features for Enhanced Content-Based  Misinformation Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merenda%2C+F">Flavio Merenda</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-P%C3%A9rez%2C+J+M">Jos&#xe9; Manuel G&#xf3;mez-P&#xe9;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at K-CAP'23: The 12th Knowledge Capture Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Preventing the spread of misinformation is challenging. The detection of
misleading content presents a significant hurdle due to its extreme linguistic
and domain variability. Content-based models have managed to identify deceptive
language by learning representations from textual data such as social media
posts and web articles. However, aggregating representative samples of this
heterogeneous phenomenon and implementing effective real-world applications is
still elusive. Based on analytical work on the language of misinformation, this
paper analyzes the linguistic attributes that characterize this phenomenon and
how representative of such features some of the most popular misinformation
datasets are. We demonstrate that the appropriate use of pertinent symbolic
knowledge in combination with neural language models is helpful in detecting
misleading content. Our results achieve state-of-the-art performance in
misinformation datasets across the board, showing that our approach offers a
valid and robust alternative to multi-task transfer learning without requiring
any additional training data. Furthermore, our results show evidence that
structured knowledge can provide the extra boost required to address a complex
and unpredictable real-world problem like misinformation detection, not only in
terms of accuracy but also time efficiency and resource utilization.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16287" title="Abstract">arXiv:2401.16287</a> [<a href="/pdf/2401.16287" title="Download PDF">pdf</a>, <a href="/format/2401.16287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAPS: Geometry-Aware Problem Solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yinghui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Moshfeghi%2C+Y">Yashar Moshfeghi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Geometry problem solving presents a formidable challenge within the NLP
community. Existing approaches often rely on models designed for solving math
word problems, neglecting the unique characteristics of geometry math problems.
Additionally, the current research predominantly focuses on geometry
calculation problems, while overlooking other essential aspects like proving.
In this study, we address these limitations by proposing the Geometry-Aware
Problem Solver (GAPS) model. GAPS is specifically designed to generate solution
programs for geometry math problems of various types with the help of its
unique problem-type classifier. To achieve this, GAPS treats the solution
program as a composition of operators and operands, segregating their
generation processes. Furthermore, we introduce the geometry elements
enhancement method, which enhances the ability of GAPS to recognize geometry
elements accurately. By leveraging these improvements, GAPS showcases
remarkable performance in resolving geometry math problems. Our experiments
conducted on the UniGeo dataset demonstrate the superiority of GAPS over the
state-of-the-art model, Geoformer. Specifically, GAPS achieves an accuracy
improvement of more than 5.3% for calculation tasks and an impressive 41.1% for
proving tasks. Notably, GAPS achieves an impressive accuracy of 97.5% on
proving problems, representing a significant advancement in solving geometry
proving tasks.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16288" title="Abstract">arXiv:2401.16288</a> [<a href="/pdf/2401.16288" title="Download PDF">pdf</a>, <a href="/format/2401.16288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Upper bounds on the rate of linear $q$-ary $k$-hash codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Della+Fiore%2C+S">Stefano Della Fiore</a>, 
<a href="/search/cs?searchtype=author&query=Dalai%2C+M">Marco Dalai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">This paper presents new upper bounds on the rate of linear $k$-hash codes in
$\mathbb{F}_q^n$, $q\geq k$, that is, codes with the property that any $k$
distinct codewords are all simultaneously distinct in at least one coordinate.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16291" title="Abstract">arXiv:2401.16291</a> [<a href="/pdf/2401.16291" title="Download PDF">pdf</a>, <a href="/format/2401.16291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MachineLearnAthon: An Action-Oriented Machine Learning Didactic Concept
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tk%C3%A1%C4%8D%2C+M">Michal Tk&#xe1;&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Sieber%2C+J">Jakub Sieber</a>, 
<a href="/search/cs?searchtype=author&query=Kuhlmann%2C+L">Lara Kuhlmann</a>, 
<a href="/search/cs?searchtype=author&query=Brueggenolte%2C+M">Matthias Brueggenolte</a>, 
<a href="/search/cs?searchtype=author&query=Rinciog%2C+A">Alexandru Rinciog</a>, 
<a href="/search/cs?searchtype=author&query=Henke%2C+M">Michael Henke</a>, 
<a href="/search/cs?searchtype=author&query=Schweidtmann%2C+A+M">Artur M. Schweidtmann</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qinghe Gao</a>, 
<a href="/search/cs?searchtype=author&query=Theisen%2C+M+F">Maximilian F. Theisen</a>, 
<a href="/search/cs?searchtype=author&query=Shawi%2C+R+E">Radwa El Shawi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Machine Learning (ML) techniques are encountered nowadays across disciplines,
from social sciences, through natural sciences to engineering. The broad
application of ML and the accelerated pace of its evolution lead to an
increasing need for dedicated teaching concepts aimed at making the application
of this technology more reliable and responsible. However, teaching ML is a
daunting task. Aside from the methodological complexity of ML algorithms, both
with respect to theory and implementation, the interdisciplinary and empirical
nature of the field need to be taken into consideration. This paper introduces
the MachineLearnAthon format, an innovative didactic concept designed to be
inclusive for students of different disciplines with heterogeneous levels of
mathematics, programming and domain expertise. At the heart of the concept lie
ML challenges, which make use of industrial data sets to solve real-world
problems. These cover the entire ML pipeline, promoting data literacy and
practical skills, from data preparation, through deployment, to evaluation.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16292" title="Abstract">arXiv:2401.16292</a> [<a href="/pdf/2401.16292" title="Download PDF">pdf</a>, <a href="/format/2401.16292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pilotfish: Distributed Transaction Execution for Lazy Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kniep%2C+Q">Quentin Kniep</a>, 
<a href="/search/cs?searchtype=author&query=Kokoris-Kogias%2C+L">Lefteris Kokoris-Kogias</a>, 
<a href="/search/cs?searchtype=author&query=Sonnino%2C+A">Alberto Sonnino</a>, 
<a href="/search/cs?searchtype=author&query=Zablotchi%2C+I">Igor Zablotchi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Nuda Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Pilotfish is the first scale-out blockchain execution engine able to harness
any degree of parallelizability existing in its workload. Pilotfish allows each
validator to employ multiple machines, named ExecutionWorkers, under its
control to scale its execution layer. Given a sufficiently parallelizable and
compute-intensive load, the number of transactions that the validator can
execute increases linearly with the number of ExecutionWorkers at its disposal.
<br />In addition, Pilotfish maintains the consistency of the state, even when many
validators experience simultaneous machine failures. This is possible due to
the meticulous co-design of our crash-recovery protocol which leverages the
existing fault tolerance in the blockchain's consensus mechanism.
<br />Finally, Pilotfish can also be seen as the first distributed deterministic
execution engine that provides support for dynamic reads as transactions are
not required to provide a fully accurate read and write set. This loosening of
requirements would normally reduce the parallelizability available by blocking
write-after-write conflicts, but our novel versioned-queues scheduling
algorithm circumvents this by exploiting the lazy recovery property of
Pilotfish, which only persists consistent state and re-executes any optimistic
steps taken before the crash.
<br />In order to prove our claims we implemented the common path of Pilotfish with
support for the MoveVM and evaluated it against the parallel execution MoveVM
of Sui. Our results show that our simpler scheduling algorithms outperforms Sui
even with a single execution worker, but more importantly provides linear
scalability up to 4 ExecutionWorkers even for simple asset-transfers and to any
number of ExecutionWorkers for more computationally heavy workloads.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16293" title="Abstract">arXiv:2401.16293</a> [<a href="/pdf/2401.16293" title="Download PDF">pdf</a>, <a href="/format/2401.16293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Textual Entailment for Effective Triple Validation in Object Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Silva%2C+A">Andr&#xe9;s Garc&#xed;a-Silva</a>, 
<a href="/search/cs?searchtype=author&query=Berr%C3%ADo%2C+C">Cristian Berr&#xed;o</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-P%C3%A9rez%2C+J+M">Jos&#xe9; Manuel G&#xf3;mez-P&#xe9;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ISWC'23 - The International Semantic Web Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Digital Libraries (cs.DL)

</div>
<p class="mathjax">Knowledge base population seeks to expand knowledge graphs with facts that
are typically extracted from a text corpus. Recently, language models
pretrained on large corpora have been shown to contain factual knowledge that
can be retrieved using cloze-style strategies. Such approach enables zero-shot
recall of facts, showing competitive results in object prediction compared to
supervised baselines. However, prompt-based fact retrieval can be brittle and
heavily depend on the prompts and context used, which may produce results that
are unintended or hallucinatory.We propose to use textual entailment to
validate facts extracted from language models through cloze statements. Our
results show that triple validation based on textual entailment improves
language model predictions in different training regimes. Furthermore, we show
that entailment-based triple validation is also effective to validate candidate
facts extracted from other sources including existing knowledge graphs and text
passages where named entities are recognized.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16294" title="Abstract">arXiv:2401.16294</a> [<a href="/pdf/2401.16294" title="Download PDF">pdf</a>, <a href="/format/2401.16294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual feature-based and example-based explanation methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konstantinov%2C+A+V">Andrei V. Konstantinov</a>, 
<a href="/search/cs?searchtype=author&query=Kozlov%2C+B+V">Boris V. Kozlov</a>, 
<a href="/search/cs?searchtype=author&query=Kirpichenko%2C+S+R">Stanislav R. Kirpichenko</a>, 
<a href="/search/cs?searchtype=author&query=Utkin%2C+L+V">Lev V. Utkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">A new approach to the local and global explanation is proposed. It is based
on selecting a convex hull constructed for the finite number of points around
an explained instance. The convex hull allows us to consider a dual
representation of instances in the form of convex combinations of extreme
points of a produced polytope. Instead of perturbing new instances in the
Euclidean feature space, vectors of convex combination coefficients are
uniformly generated from the unit simplex, and they form a new dual dataset. A
dual linear surrogate model is trained on the dual dataset. The explanation
feature importance values are computed by means of simple matrix calculations.
The approach can be regarded as a modification of the well-known model LIME.
The dual representation inherently allows us to get the example-based
explanation. The neural additive model is also considered as a tool for
implementing the example-based explanation approach. Many numerical experiments
with real datasets are performed for studying the approach. The code of
proposed algorithms is available.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16296" title="Abstract">arXiv:2401.16296</a> [<a href="/pdf/2401.16296" title="Download PDF">pdf</a>, <a href="/format/2401.16296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of Establishing Hereditary Graph Properties via Vertex  Splitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Firbas%2C+A">Alexander Firbas</a>, 
<a href="/search/cs?searchtype=author&query=Sorge%2C+M">Manuel Sorge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Vertex splitting is a graph operation that replaces a vertex $v$ with two
nonadjacent new vertices and makes each neighbor of $v$ adjacent with one or
both of the introduced vertices. Vertex splitting has been used in contexts
from circuit design to statistical analysis. In this work, we explore the
computational complexity of achieving a given graph property $\Pi$ by a limited
number of vertex splits, formalized as the problem $\Pi$ Vertex Splitting
($\Pi$-VS). We focus on hereditary graph properties and contribute four groups
of results: First, we classify the classical complexity of $\Pi$-VS for graph
properties characterized by forbidden subgraphs of size at most 3. Second, we
provide a framework that allows to show NP-completeness whenever one can
construct a combination of a forbidden subgraph and prescribed vertex splits
that satisfy certain conditions. Leveraging this framework we show
NP-completeness when $\Pi$ is characterized by forbidden subgraphs that are
sufficiently well connected. In particular, we show that $F$-Free-VS is
NP-complete for each biconnected graph $F$. Third, we study infinite families
of forbidden subgraphs, obtaining NP-hardness for Bipartite-VS and Perfect-VS.
Finally, we touch upon the parameterized complexity of $\Pi$-VS with respect to
the number of allowed splits, showing para-NP-hardness for $K_3$-Free-VS and
deriving an XP-algorithm when each vertex is only allowed to be split at most
once.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16298" title="Abstract">arXiv:2401.16298</a> [<a href="/pdf/2401.16298" title="Download PDF">pdf</a>, <a href="/format/2401.16298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking the Barrier: Selective Uncertainty-based Active Learning for  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Siteng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haochang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lawlor%2C+A">Aonghus Lawlor</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Ruihai Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Active learning (AL) has found wide applications in medical image
segmentation, aiming to alleviate the annotation workload and enhance
performance. Conventional uncertainty-based AL methods, such as entropy and
Bayesian, often rely on an aggregate of all pixel-level metrics. However, in
imbalanced settings, these methods tend to neglect the significance of target
regions, eg., lesions, and tumors. Moreover, uncertainty-based selection
introduces redundancy. These factors lead to unsatisfactory performance, and in
many cases, even underperform random sampling. To solve this problem, we
introduce a novel approach called the Selective Uncertainty-based AL, avoiding
the conventional practice of summing up the metrics of all pixels. Through a
filtering process, our strategy prioritizes pixels within target areas and
those near decision boundaries. This resolves the aforementioned disregard for
target areas and redundancy. Our method showed substantial improvements across
five different uncertainty-based methods and two distinct datasets, utilizing
fewer labeled data to reach the supervised baseline and consistently achieving
the highest overall performance. Our code is available at
https://github.com/HelenMa9998/Selective\_Uncertainty\_AL.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16299" title="Abstract">arXiv:2401.16299</a> [<a href="/pdf/2401.16299" title="Download PDF">pdf</a>, <a href="/format/2401.16299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Molecular Property Prediction with Auxiliary Learning and  Task-Specific Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dey%2C+V">Vishal Dey</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xia Ning</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pretrained Graph Neural Networks have been widely adopted for various
molecular property prediction tasks. Despite their ability to encode structural
and relational features of molecules, traditional fine-tuning of such
pretrained GNNs on the target task can lead to poor generalization. To address
this, we explore the adaptation of pretrained GNNs to the target task by
jointly training them with multiple auxiliary tasks. This could enable the GNNs
to learn both general and task-specific features, which may benefit the target
task. However, a major challenge is to determine the relatedness of auxiliary
tasks with the target task. To address this, we investigate multiple strategies
to measure the relevance of auxiliary tasks and integrate such tasks by
adaptively combining task gradients or by learning task weights via bi-level
optimization. Additionally, we propose a novel gradient surgery-based approach,
Rotation of Conflicting Gradients ($\mathtt{RCGrad}$), that learns to align
conflicting auxiliary task gradients through rotation. Our experiments with
state-of-the-art pretrained GNNs demonstrate the efficacy of our proposed
methods, with improvements of up to 7.7% over fine-tuning. This suggests that
incorporating auxiliary tasks along with target task fine-tuning can be an
effective way to improve the generalizability of pretrained GNNs for molecular
property prediction.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16301" title="Abstract">arXiv:2401.16301</a> [<a href="/pdf/2401.16301" title="Download PDF">pdf</a>, <a href="/format/2401.16301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Factor Graph-Based Heterogeneous Bayesian DDF for Dynamic  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dagan%2C+O">Ofer Dagan</a>, 
<a href="/search/cs?searchtype=author&query=Cinquini%2C+T+L">Tycho L. Cinquini</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N+R">Nisar R. Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 13 figures, submitted for review at IEEE Transactions on Robotics (T-RO)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Heterogeneous Bayesian decentralized data fusion captures the set of problems
in which two robots must combine two probability density functions over
non-equal, but overlapping sets of random variables. In the context of
multi-robot dynamic systems, this enables robots to take a "divide and conquer"
approach to reason and share data over complementary tasks instead of over the
full joint state space. For example, in a target tracking application, this
allows robots to track different subsets of targets and share data on only
common targets. This paper presents a framework by which robots can each use a
local factor graph to represent relevant partitions of a complex global joint
probability distribution, thus allowing them to avoid reasoning over the
entirety of a more complex model and saving communication as well as
computation costs. From a theoretical point of view, this paper makes
contributions by casting the heterogeneous decentralized fusion problem in
terms of a factor graph, analyzing the challenges that arise due to dynamic
filtering, and then developing a new conservative filtering algorithm that
ensures statistical correctness. From a practical point of view, we show how
this framework can be used to represent different multi-robot applications and
then test it with simulations and hardware experiments to validate and
demonstrate its statistical conservativeness, applicability, and robustness to
real-world challenges.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16302" title="Abstract">arXiv:2401.16302</a> [<a href="/pdf/2401.16302" title="Download PDF">pdf</a>, <a href="/format/2401.16302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-safe Encryption: A New Method to Reduce Complexity and/or  Improve Security Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandani%2C+A+K">Amir K. Khandani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This work presents some novel techniques to enhance an encryption scheme
motivated by classical McEliece cryptosystem. Contributions include: (1) using
masking matrices to hide sensitive data, (2) allowing both legitimate parties
to incorporate randomness in the public key without sharing any additional
public information, (3) using concatenation of a repetition code for error
correction, permitting key recovery with a negligible decoding complexity, (4)
making attacks more difficult by increasing the complexity in verifying a given
key candidate has resulted in the actual key, (5) introducing memory in the
error sequence such that: (i) error vector is composed of a random number of
erroneous bits, (ii) errors can be all corrected when used in conjunction with
concatenation of a repetition code of length 3. Proposed techniques allow
generating significantly larger keys, at the same time, with a much lower
complexity, as compared to known post-quantum key generation techniques relying
on randomization.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16304" title="Abstract">arXiv:2401.16304</a> [<a href="/pdf/2401.16304" title="Download PDF">pdf</a>, <a href="/format/2401.16304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regressing Transformers for Data-efficient Visual Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leyva-Vallina%2C+M">Mar&#xed;a Leyva-Vallina</a>, 
<a href="/search/cs?searchtype=author&query=Strisciuglio%2C+N">Nicola Strisciuglio</a>, 
<a href="/search/cs?searchtype=author&query=Petkov%2C+N">Nicolai Petkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Visual place recognition is a critical task in computer vision, especially
for localization and navigation systems. Existing methods often rely on
contrastive learning: image descriptors are trained to have small distance for
similar images and larger distance for dissimilar ones in a latent space.
However, this approach struggles to ensure accurate distance-based image
similarity representation, particularly when training with binary pairwise
labels, and complex re-ranking strategies are required. This work introduces a
fresh perspective by framing place recognition as a regression problem, using
camera field-of-view overlap as similarity ground truth for learning. By
optimizing image descriptors to align directly with graded similarity labels,
this approach enhances ranking capabilities without expensive re-ranking,
offering data-efficient training and strong generalization across several
benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16305" title="Abstract">arXiv:2401.16305</a> [<a href="/pdf/2401.16305" title="Download PDF">pdf</a>, <a href="/format/2401.16305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixSup: Mixed-grained Supervision for Label-efficient LiDAR-based 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuxue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lue Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024, code is available at <a href="https://github.com/BraveGroup/PointSAM-for-MixSup">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Label-efficient LiDAR-based 3D object detection is currently dominated by
weakly/semi-supervised methods. Instead of exclusively following one of them,
we propose MixSup, a more practical paradigm simultaneously utilizing massive
cheap coarse labels and a limited number of accurate labels for Mixed-grained
Supervision. We start by observing that point clouds are usually textureless,
making it hard to learn semantics. However, point clouds are geometrically rich
and scale-invariant to the distances from sensors, making it relatively easy to
learn the geometry of objects, such as poses and shapes. Thus, MixSup leverages
massive coarse cluster-level labels to learn semantics and a few expensive
box-level labels to learn accurate poses and shapes. We redesign the label
assignment in mainstream detectors, which allows them seamlessly integrated
into MixSup, enabling practicality and universality. We validate its
effectiveness in nuScenes, Waymo Open Dataset, and KITTI, employing various
detectors. MixSup achieves up to 97.31% of fully supervised performance, using
cheap cluster annotations and only 10% box annotations. Furthermore, we propose
PointSAM based on the Segment Anything Model for automated coarse labeling,
further reducing the annotation burden. The code is available at
https://github.com/BraveGroup/PointSAM-for-MixSup.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16307" title="Abstract">arXiv:2401.16307</a> [<a href="/pdf/2401.16307" title="Download PDF">pdf</a>, <a href="/format/2401.16307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Momentary Stressor Logging and Reflective Visualizations: Implications  for Stress Management with Wearables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neupane%2C+S">Sameer Neupane</a> (University of Memphis), 
<a href="/search/cs?searchtype=author&query=Saha%2C+M">Mithun Saha</a> (University of Memphis), 
<a href="/search/cs?searchtype=author&query=Ali%2C+N">Nasir Ali</a> (University of Memphis), 
<a href="/search/cs?searchtype=author&query=Hnat%2C+T">Timothy Hnat</a> (CuesHub, PBC), 
<a href="/search/cs?searchtype=author&query=Samiei%2C+S+A">Shahin Alan Samiei</a> (University of Memphis), 
<a href="/search/cs?searchtype=author&query=Nandugudi%2C+A">Anandatirtha Nandugudi</a> (University of Memphis), 
<a href="/search/cs?searchtype=author&query=Almeida%2C+D+M">David M. Almeida</a> (The Pennsylvania State University), 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Santosh Kumar</a> (University of Memphis)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In CHI '24 Proceedings of the CHI Conference on Human Factors in Computing Systems Honolulu, HI, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Commercial wearables from Fitbit, Garmin, and Whoop have recently introduced
real-time notifications based on detecting changes in physiological responses
indicating potential stress. In this paper, we investigate how these new
capabilities can be leveraged to improve stress management. We developed a
smartwatch app, a smartphone app, and a cloud service, and conducted a 100-day
field study with 122 participants who received prompts triggered by
physiological responses several times a day. They were asked whether they were
stressed, and if so, to log the most likely stressor. Each week, participants
received new visualizations of their data to self-reflect on patterns and
trends. Participants reported better awareness of their stressors, and
self-initiating fourteen kinds of behavioral changes to reduce stress in their
daily lives. Repeated self-reports over 14 weeks showed reductions in both
stress intensity (in 26,521 momentary ratings) and stress frequency (in 1,057
weekly surveys).
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16310" title="Abstract">arXiv:2401.16310</a> [<a href="/pdf/2401.16310" title="Download PDF">pdf</a>, <a href="/format/2401.16310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security Code Review by LLMs: A Deep Dive into Responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiaxin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yujia Fu</a>, 
<a href="/search/cs?searchtype=author&query=Tahir%2C+A">Amjed Tahir</a>, 
<a href="/search/cs?searchtype=author&query=Shahin%2C+M">Mojtaba Shahin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yangxiao Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Security code review aims to combine automated tools and manual efforts to
detect security defects during development. The rapid development of Large
Language Models (LLMs) has shown promising potential in software development,
as well as opening up new possibilities in automated security code review. To
explore the challenges of applying LLMs in practical code review for security
defect detection, this study compared the detection performance of three
state-of-the-art LLMs (Gemini Pro, GPT-4, and GPT-3.5) under five prompts on
549 code files that contain security defects from real-world code reviews.
Through analyzing 82 responses generated by the best-performing LLM-prompt
combination based on 100 randomly selected code files, we extracted and
categorized quality problems present in these responses into 5 themes and 16
categories. Our results indicate that the responses produced by LLMs often
suffer from verbosity, vagueness, and incompleteness, highlighting the
necessity to enhance their conciseness, understandability, and compliance to
security defect detection. This work reveals the deficiencies of LLM-generated
responses in security code review and paves the way for future optimization of
LLMs towards this task.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16312" title="Abstract">arXiv:2401.16312</a> [<a href="/pdf/2401.16312" title="Download PDF">pdf</a>, <a href="/ps/2401.16312" title="Download PostScript">ps</a>, <a href="/format/2401.16312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Degradability of Modified Landau-Streater Type Low-Noise Quantum  Channels in High Dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lo%2C+Y">Yun-Feng Lo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yen-Chi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+M">Min-Hsiu Hsieh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">This paper delves into the degradability of quantum channels, with a specific
focus on high-dimensional extensions of qubit depolarizing channels in
low-noise regimes. We build upon the foundation of $\eta$-approximate
degradable channels, as established by Sutter et al. and Leditzky et al., to
introduce and examine the Modified Landau-Streater (MLS) channels. These
channels expand upon the qubit depolarizing and the recently proposed modified
Werner-Holevo channels by Roofeh and Karimipour, extending them to
higher-dimensional Hilbert spaces (with dimension $d=2j+1$, where $j$ are
positive half-integers). Our investigation centers on their conformity to the
$O(\varepsilon^2)$ degradability pattern, aligning with and extending Leditzky
et al.'s findings in the $d=2$ case. By replacing the SU($2$) generators with
SU($d$) in our treatment, we may explore the potential inclusion of generalized
Gell-Mann matrices in future research. Our results enhance the understanding of
super-additivity in quantum channels within the low-noise regime and lay the
groundwork for future explorations into conditions and structures that could
lead to $O(\varepsilon^2)$ degradability across a broader spectrum of quantum
channels.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16313" title="Abstract">arXiv:2401.16313</a> [<a href="/pdf/2401.16313" title="Download PDF">pdf</a>, <a href="/format/2401.16313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Translation Meta Evaluation through Translation Accuracy  Challenge Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moghe%2C+N">Nikita Moghe</a>, 
<a href="/search/cs?searchtype=author&query=Fazla%2C+A">Arnisa Fazla</a>, 
<a href="/search/cs?searchtype=author&query=Amrhein%2C+C">Chantal Amrhein</a>, 
<a href="/search/cs?searchtype=author&query=Kocmi%2C+T">Tom Kocmi</a>, 
<a href="/search/cs?searchtype=author&query=Steedman%2C+M">Mark Steedman</a>, 
<a href="/search/cs?searchtype=author&query=Birch%2C+A">Alexandra Birch</a>, 
<a href="/search/cs?searchtype=author&query=Sennrich%2C+R">Rico Sennrich</a>, 
<a href="/search/cs?searchtype=author&query=Guillou%2C+L">Liane Guillou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2210.15615">arXiv:2210.15615</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent machine translation (MT) metrics calibrate their effectiveness by
correlating with human judgement but without any insights about their behaviour
across different error types. Challenge sets are used to probe specific
dimensions of metric behaviour but there are very few such datasets and they
either focus on a limited number of phenomena or a limited number of language
pairs. We introduce ACES, a contrastive challenge set spanning 146 language
pairs, aimed at discovering whether metrics can identify 68 translation
accuracy errors. These phenomena range from simple alterations at the
word/character level to more complex errors based on discourse and real-world
knowledge. We conduct a large-scale study by benchmarking ACES on 50 metrics
submitted to the WMT 2022 and 2023 metrics shared tasks. We benchmark metric
performance, assess their incremental performance over successive campaigns,
and measure their sensitivity to a range of linguistic phenomena. We also
investigate claims that Large Language Models (LLMs) are effective as MT
evaluators by evaluating on ACES. Our results demonstrate that different metric
families struggle with different phenomena and that LLM-based methods fail to
demonstrate reliable performance. Our analyses indicate that most metrics
ignore the source sentence, tend to prefer surface-level overlap and end up
incorporating properties of base models which are not always beneficial. We
expand ACES to include error span annotations, denoted as SPAN-ACES and we use
this dataset to evaluate span-based error metrics showing these metrics also
need considerable improvement. Finally, we provide a set of recommendations for
building better MT metrics, including focusing on error labels instead of
scores, ensembling, designing strategies to explicitly focus on the source
sentence, focusing on semantic content and choosing the right base model for
representations.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16314" title="Abstract">arXiv:2401.16314</a> [<a href="/pdf/2401.16314" title="Download PDF">pdf</a>, <a href="/ps/2401.16314" title="Download PostScript">ps</a>, <a href="/format/2401.16314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creative Telescoping for Hypergeometric Double Sums
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paule%2C+P">Peter Paule</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+C">Carsten Schneider</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">We present efficient methods for calculating linear recurrences of
hypergeometric double sums and, more generally, of multiple sums. In
particular, we supplement this approach with the algorithmic theory of
contiguous relations, which guarantees the applicability of our method for many
input sums. In addition, we elaborate new techniques to optimize the underlying
key task of our method to compute rational solutions of parameterized linear
recurrences.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16316" title="Abstract">arXiv:2401.16316</a> [<a href="/pdf/2401.16316" title="Download PDF">pdf</a>, <a href="/format/2401.16316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis of a Preconditioned Steepest Descent Solver for the  Cahn-Hilliard Equation with Logarithmic Potential
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Diegel%2C+A+E">Amanda E. Diegel</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/math?searchtype=author&query=Wise%2C+S+M">Steven M. Wise</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we provide a theoretical analysis for a preconditioned
steepest descent (PSD) iterative solver that improves the computational time of
a finite difference numerical scheme for the Cahn-Hilliard equation with
Flory-Huggins energy potential. In the numerical design, a convex splitting
approach is applied to the chemical potential such that the logarithmic and the
surface diffusion terms are treated implicitly while the expansive concave term
is treated with an explicit update. The nonlinear and singular nature of the
logarithmic energy potential makes the numerical implementation very
challenging. However, the positivity-preserving property for the logarithmic
arguments, unconditional energy stability, and optimal rate error estimates
have been established in a recent work and it has been shown that successful
solvers ensure a similar positivity-preserving property at each iteration
stage. Therefore, in this work, we will show that the PSD solver ensures a
positivity-preserving property at each iteration stage. The PSD solver consists
of first computing a search direction (involved with solving a Poisson-like
equation) and then takes a one-parameter optimization step over the search
direction in which the Newton iteration becomes very powerful. A theoretical
analysis is applied to the PSD iteration solver and a geometric convergence
rate is proved for the iteration. In particular, the strict separation property
of the numerical solution, which indicates a uniform distance between the
numerical solution and the singular limit values of $\pm 1$ for the phase
variable, plays an essential role in the iteration convergence analysis. A few
numerical results are presented to demonstrate the robustness and efficiency of
the PSD solver.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16318" title="Abstract">arXiv:2401.16318</a> [<a href="/pdf/2401.16318" title="Download PDF">pdf</a>, <a href="/format/2401.16318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defining and Extracting generalizable interaction primitives from DNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+S">Siyu Lou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Benhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanshi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Faithfully summarizing the knowledge encoded by a deep neural network (DNN)
into a few symbolic primitive patterns without losing much information
represents a core challenge in explainable AI. To this end, Ren et al. (2023c)
have derived a series of theorems to prove that the inference score of a DNN
can be explained as a small set of interactions between input variables.
However, the lack of generalization power makes it still hard to consider such
interactions as faithful primitive patterns encoded by the DNN. Therefore,
given different DNNs trained for the same task, we develop a new method to
extract interactions that are shared by these DNNs. Experiments show that the
extracted interactions can better reflect common knowledge shared by different
DNNs.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16321" title="Abstract">arXiv:2401.16321</a> [<a href="/pdf/2401.16321" title="Download PDF">pdf</a>, <a href="/format/2401.16321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Control of Renewable Energy Communities subject to Network Peak  Fees with Model Predictive Control and Reinforcement Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aittahar%2C+S">Samy Aittahar</a>, 
<a href="/search/eess?searchtype=author&query=Bolland%2C+A">Adrien Bolland</a>, 
<a href="/search/eess?searchtype=author&query=Derval%2C+G">Guillaume Derval</a>, 
<a href="/search/eess?searchtype=author&query=Ernst%2C+D">Damien Ernst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages (excl. appendices and references), 14 pages of appendix. 10 figures and 10 tables. To be reviewed as a journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We propose in this paper an optimal control framework for renewable energy
communities (RECs) equipped with controllable assets. Such RECs allow its
members to exchange production surplus through an internal market. The
objective is to control their assets in order to minimise the sum of individual
electricity bills. These bills account for the electricity exchanged through
the REC and with the retailers. Typically, for large companies, another
important part of the bills are the costs related to the power peaks; in our
framework, they are determined from the energy exchanges with the retailers. We
compare rule-based control strategies with the two following control
algorithms. The first one is derived from model predictive control techniques,
and the second one is built with reinforcement learning techniques. We also
compare variants of these algorithms that neglect the peak power costs. Results
confirm that using policies accounting for the power peaks lead to a
significantly lower sum of electricity bills and thus better control strategies
at the cost of higher computation time. Furthermore, policies trained with
reinforcement learning approaches appear promising for real-time control of the
communities, where model predictive control policies may be computationally
expensive in practice. These findings encourage pursuing the efforts toward
development of scalable control algorithms, operating from a centralised
standpoint, for renewable energy communities equipped with controllable assets.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16322" title="Abstract">arXiv:2401.16322</a> [<a href="/pdf/2401.16322" title="Download PDF">pdf</a>, <a href="/format/2401.16322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-order exponential integration for seismic wave modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ravelo%2C+F+V">Fernando V. Ravelo</a>, 
<a href="/search/math?searchtype=author&query=Schreiber%2C+M">Martin Schreiber</a>, 
<a href="/search/math?searchtype=author&query=Peixoto%2C+P+S">Pedro S. Peixoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Seismic imaging is a major challenge in geophysics with broad applications.
It involves solving wave propagation equations with absorbing boundary
conditions (ABC) multiple times. This drives the need for accurate and
efficient numerical methods. This study examines a collection of exponential
integration methods, known for their good numerical properties on wave
representation, to investigate their efficacy in solving the wave equation with
ABC. The purpose of this research is to assess the performance of these
methods. We compare a recently proposed Exponential Integration based on Faber
polynomials with well-established Krylov exponential methods alongside a
high-order Runge-Kutta scheme and low-order classical methods. Through our
analysis, we found that the exponential integrator based on the Krylov subspace
exhibits the best convergence results among the high-order methods. We also
discovered that high-order methods can achieve computational efficiency similar
to lower-order methods while allowing for considerably larger time steps. Most
importantly, the possibility of undertaking large time steps could be used for
important memory savings in full waveform inversion imaging problems.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16327" title="Abstract">arXiv:2401.16327</a> [<a href="/pdf/2401.16327" title="Download PDF">pdf</a>, <a href="/format/2401.16327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PICL: Physics Informed Contrastive Learning for Partial Differential  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorsung%2C+C">Cooper Lorsung</a>, 
<a href="/search/cs?searchtype=author&query=Farimani%2C+A+B">Amir Barati Farimani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Neural operators have recently grown in popularity as Partial Differential
Equation (PDEs) surrogate models. Learning solution functionals, rather than
functions, has proven to be a powerful approach to calculate fast, accurate
solutions to complex PDEs. While much work has been done evaluating neural
operator performance on a wide variety of surrogate modeling tasks, these works
normally evaluate performance on a single equation at a time. In this work, we
develop a novel contrastive pretraining framework utilizing Generalized
Contrastive Loss that improves neural operator generalization across multiple
governing equations simultaneously. Governing equation coefficients are used to
measure ground-truth similarity between systems. A combination of
physics-informed system evolution and latent-space model output are anchored to
input data and used in our distance function. We find that physics-informed
contrastive pretraining improves both accuracy and generalization for the
Fourier Neural Operator in fixed-future task, with comparable performance on
the autoregressive rollout, and superresolution tasks for the 1D Heat,
Burgers', and linear advection equations.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16329" title="Abstract">arXiv:2401.16329</a> [<a href="/pdf/2401.16329" title="Download PDF">pdf</a>, <a href="/format/2401.16329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesis of 3D on-air signatures with the Sigma-Lognormal model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrer%2C+M+A">Miguel A. Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Diaz%2C+M">Moises Diaz</a>, 
<a href="/search/cs?searchtype=author&query=Carmona-Duarte%2C+C">Cristina Carmona-Duarte</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez%2C+J+J+Q">Jose J. Quintana Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Plamondon%2C+R">Rejean Plamondon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Version. Published on Knowledge-Based Systems
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Miguel A. Ferrer, Moises Diaz, Cristina Carmona-Duarte, Jose Juan
  Quintana, Rejean Plamondon,Synthesis of 3D on-air signatures with the
  Sigma-Lognormal model,Knowledge-Based Systems, Vol. 265,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Signature synthesis is a computation technique that generates artificial
specimens which can support decision making in automatic signature
verification. A lot of work has been dedicated to this subject, which centres
on synthesizing dynamic and static two-dimensional handwriting on canvas. This
paper proposes a framework to generate synthetic 3D on-air signatures
exploiting the lognormality principle, which mimics the complex neuromotor
control processes at play as the fingertip moves. Addressing the usual cases
involving the development of artificial individuals and duplicated samples,
this paper contributes to the synthesis of: (1) the trajectory and velocity of
entirely 3D new signatures; (2) kinematic information when only the 3D
trajectory of the signature is known, and (3) duplicate samples of 3D real
signatures. Validation was conducted by generating synthetic 3D signature
databases mimicking real ones and showing that automatic signature
verifications of genuine and skilled forgeries report performances similar to
those of real and synthetic databases. We also observed that training 3D
automatic signature verifiers with duplicates can reduce errors. We further
demonstrated that our proposal is also valid for synthesizing 3D air writing
and gestures. Finally, a perception test confirmed the human likeness of the
generated specimens. The databases generated are publicly available, only for
research purposes, at .
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16330" title="Abstract">arXiv:2401.16330</a> [<a href="/pdf/2401.16330" title="Download PDF">pdf</a>, <a href="/ps/2401.16330" title="Download PostScript">ps</a>, <a href="/format/2401.16330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital requirements engineering with an INCOSE-derived SysML meta-model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wheaton%2C+J+S">James S. Wheaton</a>, 
<a href="/search/eess?searchtype=author&query=Herber%2C+D+R">Daniel R. Herber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted manuscript; 11 pages; 5 figures; 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Traditional requirements engineering tools do not readily access the system
architecture model defined in SysML and related Profiles, often resulting in
duplication of basic system model elements that nevertheless lack the
connectivity and expressive detail possible in a SysML-defined model. Without
architecture model connectivity, requirements can suffer from imprecision and
inconsistent terminology, and thereby frustrate communication during the system
development lifecycle. Further integration of requirements engineering
activities with system architecture modeling contributes to the Authoritative
Source of Truth while facilitating deep access to system architecture model
elements for V&amp;V activities. The Model-Based Structured Requirement SysML
Profile was extended to comply with INCOSE Guide for Writing Requirements and
Needs &amp; Requirements Manual updated in 2023 while conforming to the
ISO/IEC/IEEE 29148 standard requirement statement templates. Rules,
Characteristics, and Attributes were defined according to the Guide to
facilitate definition and requirements V&amp;V. The resulting SysML Profile was
applied in two system architecture models at NASA Jet Propulsion Laboratory
allowing us to explore its applicability and value in a real-world project
environment. Initial results show that INCOSE-derived Model-Based Structured
Requirements complement the NASA Systems Engineering Handbook checklist and
guidance, but Attribute consistency can be difficult to achieve with the system
architecture modeling software in use.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16332" title="Abstract">arXiv:2401.16332</a> [<a href="/pdf/2401.16332" title="Download PDF">pdf</a>, <a href="/format/2401.16332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tradeoffs Between Alignment and Helpfulness in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolf%2C+Y">Yotam Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Wies%2C+N">Noam Wies</a>, 
<a href="/search/cs?searchtype=author&query=Shteyman%2C+D">Dorin Shteyman</a>, 
<a href="/search/cs?searchtype=author&query=Rothberg%2C+B">Binyamin Rothberg</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+Y">Yoav Levine</a>, 
<a href="/search/cs?searchtype=author&query=Shashua%2C+A">Amnon Shashua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Language model alignment has become an important component of AI safety,
allowing safe interactions between humans and language models, by enhancing
desired behaviors and inhibiting undesired ones. It is often done by tuning the
model or inserting preset aligning prompts. Recently, representation
engineering, a method which alters the model's behavior via changing its
representations post-training, was shown to be effective in aligning LLMs (Zou
et al., 2023a). Representation engineering yields gains in alignment oriented
tasks such as resistance to adversarial attacks and reduction of social biases,
but was also shown to cause a decrease in the ability of the model to perform
basic tasks. In this paper we study the tradeoff between the increase in
alignment and decrease in helpfulness of the model. We propose a theoretical
framework which provides bounds for these two quantities, and demonstrate their
relevance empirically. Interestingly, we find that while the helpfulness
generally decreases, it does so quadratically with the norm of the
representation engineering vector, while the alignment increases linearly with
it, indicating a regime in which it is efficient to use representation
engineering. We validate our findings empirically, and chart the boundaries to
the usefulness of representation engineering for alignment.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16335" title="Abstract">arXiv:2401.16335</a> [<a href="/pdf/2401.16335" title="Download PDF">pdf</a>, <a href="/format/2401.16335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Data Smoothing: Mitigating Reward Overfitting and  Overoptimization in RLHF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jiantao Jiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique that
aligns language models closely with human-centric values. The initial phase of
RLHF involves learning human values using a reward model from ranking data. It
is observed that the performance of the reward model degrades after one epoch
of training, and optimizing too much against the learned reward model
eventually hinders the true objective. This paper delves into these issues,
leveraging the theoretical insights to design improved reward learning
algorithm termed 'Iterative Data Smoothing' (IDS). The core idea is that during
each training epoch, we not only update the model with the data, but also
update the date using the model, replacing hard labels with soft labels. Our
empirical findings highlight the superior performance of this approach over the
traditional methods.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16337" title="Abstract">arXiv:2401.16337</a> [<a href="/pdf/2401.16337" title="Download PDF">pdf</a>, <a href="/format/2401.16337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum-Based Reinforcement Learning for Quadrupedal Jumping: A  Reference-free Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atanassov%2C+V">Vassil Atanassov</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jiatao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Kober%2C+J">Jens Kober</a>, 
<a href="/search/cs?searchtype=author&query=Havoutis%2C+I">Ioannis Havoutis</a>, 
<a href="/search/cs?searchtype=author&query=Della+Santina%2C+C">Cosimo Della Santina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Deep reinforcement learning (DRL) has emerged as a promising solution to
mastering explosive and versatile quadrupedal jumping skills. However, current
DRL-based frameworks usually rely on well-defined reference trajectories, which
are obtained by capturing animal motions or transferring experience from
existing controllers. This work explores the possibility of learning dynamic
jumping without imitating a reference trajectory. To this end, we incorporate a
curriculum design into DRL so as to accomplish challenging tasks progressively.
Starting from a vertical in-place jump, we then generalize the learned policy
to forward and diagonal jumps and, finally, learn to jump across obstacles.
Conditioned on the desired landing location, orientation, and obstacle
dimensions, the proposed approach contributes to a wide range of jumping
motions, including omnidirectional jumping and robust jumping, alleviating the
effort to extract references in advance. Particularly, without constraints from
the reference motion, a 90cm forward jump is achieved, exceeding previous
records for similar robots reported in the existing literature. Additionally,
continuous jumping on the soft grassy floor is accomplished, even when it is
not encountered in the training stage. A supplementary video showing our
results can be found at https://youtu.be/nRaMCrwU5X8 .
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16339" title="Abstract">arXiv:2401.16339</a> [<a href="/pdf/2401.16339" title="Download PDF">pdf</a>, <a href="/ps/2401.16339" title="Download PostScript">ps</a>, <a href="/format/2401.16339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAT-CEP-monitor: An air quality monitoring software architecture  combining complex event processing with satellite remote sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Semlali%2C+B+B">Badr-Eddine Boudriki Semlali</a>, 
<a href="/search/cs?searchtype=author&query=Amrani%2C+C+E">Chaker El Amrani</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+G">Guadalupe Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Boubeta-Puig%2C+J">Juan Boubeta-Puig</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-de-Prado%2C+A">Alfonso Garcia-de-Prado</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Comput.Electr.Eng. 93:107257 (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE); Signal Processing (eess.SP)

</div>
<p class="mathjax">Air pollution is a major problem today that causes serious damage to human
health. Urban areas are the most affected by the degradation of air quality
caused by anthropogenic gas emissions. Although there are multiple proposals
for air quality monitoring, in most cases, two limitations are imposed: the
impossibility of processing data in Near Real-Time (NRT) for remote sensing
approaches and the impossibility of reaching areas of limited accessibility or
low network coverage for ground data approaches. We propose a software
architecture that efficiently combines complex event processing with remote
sensing data from various satellite sensors to monitor air quality in NRT,
giving support to decision-makers. We illustrate the proposed solution by
calculating the air quality levels for several areas of Morocco and Spain,
extracting and processing satellite information in NRT. This study also
validates the air quality measured by ground stations and satellite sensor
data.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16340" title="Abstract">arXiv:2401.16340</a> [<a href="/pdf/2401.16340" title="Download PDF">pdf</a>, <a href="/format/2401.16340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The role of library versions in Developer-ChatGPT conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raj%2C+R">Rachna Raj</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+D+E">Diego Elias Costa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The latest breakthroughs in large language models (LLM) have empowered
software development tools, such as ChatGPT, to aid developers in complex
tasks. Developers use ChatGPT to write code, review code changes, and even
debug their programs. In these interactions, ChatGPT often recommends code
snippets that depend on external libraries. However, code from libraries
changes over time, invalidating a once-correct code snippet and making it
difficult to reuse recommended code.
<br />In this study, we analyze DevGPT, a dataset of more than 4,000
Developer-ChatGPT interactions, to understand the role of library versions in
code-related conversations. We quantify how often library version constraints
are mentioned in code-related conversations and when ChatGPT recommends the
installation of specific libraries. Our findings show that, albeit to
constantly recommend and analyze code with external dependencies, library
version constraints only appear in 9% of the conversations. In the majority of
conversations, the version constraints are prompted by users (as opposed to
being specified by ChatGPT) as a method for receiving better quality responses.
Moreover, we study how library version constraints are used in the conversation
through qualitative methods, identifying several potential problems that
warrant further research.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16341" title="Abstract">arXiv:2401.16341</a> [<a href="/pdf/2401.16341" title="Download PDF">pdf</a>, <a href="/format/2401.16341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S-HIDRA: A blockchain and SDN domain-based architecture to orchestrate  fog computing environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%BA%C3%B1ez-G%C3%B3mez%2C+c">carlos N&#xfa;&#xf1;ez-G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Carri%C3%B3n%2C+C">Carmen Carri&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Caminero%2C+B">Blanca Caminero</a>, 
<a href="/search/cs?searchtype=author&query=Delicado%2C+F+M">Francisco M. Delicado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Fog computing arises as a complement to cloud computing where computing and
storage are provided in a decentralized way rather than the centralized
approach of the cloud paradigm. In addition, blockchain provides a
decentralized and immutable ledger which can provide support for running
arbitrary logic thanks to smart contracts. These facts can lead to harness
smart contracts on blockchain as the basis for a decentralized, autonomous, and
resilient orchestrator for the resources in the fog. However, the potentially
vast amount of geographically distributed fog nodes may threaten the
feasibility of the orchestration. On the other hand, fog nodes can exhibit
highly dynamic workloads which may result in the orchestrator redistributing
the services among them. Thus, there is also a need to dynamically support the
network connections to those services independently of their location. Software
Defined Networking (SDN) can be integrated within the orchestrator to carry out
a seamless service management. To tackle both aforementioned issues, the
S-HIDRA architecture is proposed. It integrates SDN support within a
blockchain-based orchestrator of container-based services for fog environments,
in order to provide low network latency and high service availability. Also, a
domain-based architecture is outlined \marev{as potential scenario} to address
the geographic distributed nature of fog environments. Results obtained from a
proof-of-concept implementation assess the required functionality for S-HIDRA.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16342" title="Abstract">arXiv:2401.16342</a> [<a href="/pdf/2401.16342" title="Download PDF">pdf</a>, <a href="/format/2401.16342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Achievable Rates for the Shotgun Sequencing Channel with Erasures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+H">Hrishi Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+P">Prasad Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Parekh%2C+N">Nita Parekh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In the shotgun sequencing channel, the input sequence (possibly, a long DNA
sequence composed of nucleotide bases) is read into multiple fragments (called
`reads') of much shorter lengths. In the context of DNA data storage, the
capacity of this channel was identified in a recent work, assuming that the
reads themselves are noiseless substrings of the original sequence. Modern
shotgun sequencers however also output quality scores for each base read,
indicating the confidence in its identification. Bases with low quality scores
can be considered to be erased. Motivated by this, we consider the shotgun
sequencing channel with erasures, where each symbol in any read can be
independently erased with some probability $\delta$. We identify achievable
rates for this channel, using a random code construction and a decoder that
uses typicality-like arguments to merge the reads.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16347" title="Abstract">arXiv:2401.16347</a> [<a href="/pdf/2401.16347" title="Download PDF">pdf</a>, <a href="/ps/2401.16347" title="Download PostScript">ps</a>, <a href="/format/2401.16347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Coordination Across a Diverse Set of Input Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+J">Jorge S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Laguna%2C+R">Rodrigo Laguna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Cross-modal retrieval is the task of retrieving samples of a given modality
by using queries of a different one. Due to the wide range of practical
applications, the problem has been mainly focused on the vision and language
case, e.g. text to image retrieval, where models like CLIP have proven
effective in solving such tasks. The dominant approach to learning such
coordinated representations consists of projecting them onto a common space
where matching views stay close and those from non-matching pairs are pushed
away from each other. Although this cross-modal coordination has been applied
also to other pairwise combinations, extending it to an arbitrary number of
diverse modalities is a problem that has not been fully explored in the
literature. In this paper, we propose two different approaches to the problem.
The first is based on an extension of the CLIP contrastive objective to an
arbitrary number of input modalities, while the second departs from the
contrastive formulation and tackles the coordination problem by regressing the
cross-modal similarities towards a target that reflects two simple and
intuitive constraints of the cross-modal retrieval task. We run experiments on
two different datasets, over different combinations of input modalities and
show that the approach is not only simple and effective but also allows for
tackling the retrieval problem in novel ways. Besides capturing a more diverse
set of pair-wise interactions, we show that we can use the learned
representations to improve retrieval performance by combining the embeddings
from two or more such modalities.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16348" title="Abstract">arXiv:2401.16348</a> [<a href="/pdf/2401.16348" title="Download PDF">pdf</a>, <a href="/format/2401.16348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Automated Evaluation Metrics: Evaluating Topic Models On  Practical Social Science Content Analysis Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+A">Andrew Mao</a>, 
<a href="/search/cs?searchtype=author&query=Stephens%2C+D">Daniel Stephens</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+P">Pranav Goel</a>, 
<a href="/search/cs?searchtype=author&query=Walpole%2C+E">Emily Walpole</a>, 
<a href="/search/cs?searchtype=author&query=Dima%2C+A">Alden Dima</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+J">Juan Fung</a>, 
<a href="/search/cs?searchtype=author&query=Boyd-Graber%2C+J">Jordan Boyd-Graber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 tables, 6 figures, Accepted to EACL Main Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Topic models are a popular tool for understanding text collections, but their
evaluation has been a point of contention. Automated evaluation metrics such as
coherence are often used, however, their validity has been questioned for
neural topic models (NTMs) and can overlook the benefits of a model in real
world applications. To this end, we conduct the first evaluation of neural,
supervised and classical topic models in an interactive task based setting. We
combine topic models with a classifier and test their ability to help humans
conduct content analysis and document annotation. From simulated, real user and
expert pilot studies, the Contextual Neural Topic Model does the best on
cluster evaluation metrics and human evaluations; however, LDA is competitive
with two other NTMs under our simulated experiment and user study results,
contrary to what coherence scores suggest. We show that current automated
metrics do not provide a complete picture of topic modeling capabilities, but
the right choice of NTMs can be better than classical models on practical
tasks.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16349" title="Abstract">arXiv:2401.16349</a> [<a href="/pdf/2401.16349" title="Download PDF">pdf</a>, <a href="/format/2401.16349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConFit: Improving Resume-Job Matching using Data Augmentation and  Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinzhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> working progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">A reliable resume-job matching system helps a company find suitable
candidates from a pool of resumes, and helps a job seeker find relevant jobs
from a list of job posts. However, since job seekers apply only to a few jobs,
interaction records in resume-job datasets are sparse. Different from many
prior work that use complex modeling techniques, we tackle this sparsity
problem using data augmentations and a simple contrastive learning approach.
ConFit first creates an augmented resume-job dataset by paraphrasing specific
sections in a resume or a job post. Then, ConFit uses contrastive learning to
further increase training samples from $B$ pairs per batch to $O(B^2)$ per
batch. We evaluate ConFit on two real-world datasets and find it outperforms
prior methods (including BM25 and OpenAI text-ada-002) by up to 19% and 31%
absolute in nDCG@10 for ranking jobs and ranking resumes, respectively.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16350" title="Abstract">arXiv:2401.16350</a> [<a href="/pdf/2401.16350" title="Download PDF">pdf</a>, <a href="/format/2401.16350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedFair^3: Unlocking Threefold Fairness in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javaherian%2C+S">Simin Javaherian</a>, 
<a href="/search/cs?searchtype=author&query=Panta%2C+S">Sanjeev Panta</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+S">Shelby Williams</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Md Sirajul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) is an emerging paradigm in machine learning without
exposing clients' raw data. In practical scenarios with numerous clients,
encouraging fair and efficient client participation in federated learning is of
utmost importance, which is also challenging given the heterogeneity in data
distribution and device properties. Existing works have proposed different
client-selection methods that consider fairness; however, they fail to select
clients with high utilities while simultaneously achieving fair accuracy
levels. In this paper, we propose a fair client-selection approach that unlocks
threefold fairness in federated learning. In addition to having a fair
client-selection strategy, we enforce an equitable number of rounds for client
participation and ensure a fair accuracy distribution over the clients. The
experimental results demonstrate that FedFair^3, in comparison to the
state-of-the-art baselines, achieves 18.15% less accuracy variance on the IID
data and 54.78% on the non-IID data, without decreasing the global accuracy.
Furthermore, it shows 24.36% less wall-clock training time on average.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16352" title="Abstract">arXiv:2401.16352</a> [<a href="/pdf/2401.16352" title="Download PDF">pdf</a>, <a href="/format/2401.16352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Training on Purification (AToP): Advancing Both Robustness  and Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianhai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+T">Toshihisa Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qibin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The deep neural networks are known to be vulnerable to well-designed
adversarial attacks. The most successful defense technique based on adversarial
training (AT) can achieve optimal robustness against particular attacks but
cannot generalize well to unseen attacks. Another effective defense technique
based on adversarial purification (AP) can enhance generalization but cannot
achieve optimal robustness. Meanwhile, both methods share one common limitation
on the degraded standard accuracy. To mitigate these issues, we propose a novel
framework called Adversarial Training on Purification (AToP), which comprises
two components: perturbation destruction by random transforms (RT) and purifier
model fine-tuned (FT) by adversarial loss. RT is essential to avoid
overlearning to known attacks resulting in the robustness generalization to
unseen attacks and FT is essential for the improvement of robustness. To
evaluate our method in an efficient and scalable way, we conduct extensive
experiments on CIFAR-10, CIFAR-100, and ImageNette to demonstrate that our
method achieves state-of-the-art results and exhibits generalization ability
against unseen attacks.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16353" title="Abstract">arXiv:2401.16353</a> [<a href="/pdf/2401.16353" title="Download PDF">pdf</a>, <a href="/ps/2401.16353" title="Download PostScript">ps</a>, <a href="/format/2401.16353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical and Theoretical Analysis of Liquid Staking Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gogol%2C+K">Krzysztof Gogol</a>, 
<a href="/search/cs?searchtype=author&query=Kraner%2C+B">Benjamin Kraner</a>, 
<a href="/search/cs?searchtype=author&query=Schlosser%2C+M">Malte Schlosser</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+T">Tao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tessone%2C+C">Claudio Tessone</a>, 
<a href="/search/cs?searchtype=author&query=Stiller%2C+B">Burkhard Stiller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Liquid staking has become the largest category of decentralized finance
protocols in terms of total value locked. However, few studies exist on its
implementation designs or underlying risks. The liquid staking protocols allow
for earning staking rewards without the disadvantage of locking the capital at
the validators. Yet, they are seen by some as a threat to the Proof-of-Stake
blockchain security.
<br />This paper is the first work that classifies liquid staking implementations.
It analyzes the historical performance of major liquid staking tokens in
comparison to the traditional staking for the largest Proof-of-Stake
blockchains. Furthermore, the research investigates the impact of
centralization, maximum extractable value and the migration of Ethereum from
Proof-of-Work to Proof-of-Stake on the tokens' performance. Examining the
tracking error of the liquid stacking providers to the staking rewards shows
that they are persistent and cannot be explained by macro-variables of the
currency, such as the variance or return.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16355" title="Abstract">arXiv:2401.16355</a> [<a href="/pdf/2401.16355" title="Download PDF">pdf</a>, <a href="/format/2401.16355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PathMMU: A Massive Multimodal Expert-Level Benchmark for Understanding  and Reasoning in Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenglu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sunyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qizi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+X">Xiaoxiao Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Mengyue Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xinheng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 107 pages, 103 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The emergence of large multimodal models has unlocked remarkable potential in
AI, particularly in pathology. However, the lack of specialized, high-quality
benchmark impeded their development and precise evaluation. To address this, we
introduce PathMMU, the largest and highest-quality expert-validated pathology
benchmark for LMMs. It comprises 33,573 multimodal multi-choice questions and
21,599 images from various sources, and an explanation for the correct answer
accompanies each question. The construction of PathMMU capitalizes on the
robust capabilities of GPT-4V, utilizing approximately 30,000 gathered
image-caption pairs to generate Q\&amp;As. Significantly, to maximize PathMMU's
authority, we invite six pathologists to scrutinize each question under strict
standards in PathMMU's validation and test sets, while simultaneously setting
an expert-level performance benchmark for PathMMU. We conduct extensive
evaluations, including zero-shot assessments of 14 open-sourced and three
closed-sourced LMMs and their robustness to image corruption. We also fine-tune
representative LMMs to assess their adaptability to PathMMU. The empirical
findings indicate that advanced LMMs struggle with the challenging PathMMU
benchmark, with the top-performing LMM, GPT-4V, achieving only a 51.7\%
zero-shot performance, significantly lower than the 71.4\% demonstrated by
human pathologists. After fine-tuning, even open-sourced LMMs can surpass
GPT-4V with a performance of over 60\%, but still fall short of the expertise
shown by pathologists. We hope that the PathMMU will offer valuable insights
and foster the development of more specialized, next-generation LLMs for
pathology.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16359" title="Abstract">arXiv:2401.16359</a> [<a href="/pdf/2401.16359" title="Download PDF">pdf</a>, <a href="/format/2401.16359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reference Coverage Analysis of OpenAlex compared to Web of Science and  Scopus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Culbert%2C+J">Jack Culbert</a>, 
<a href="/search/cs?searchtype=author&query=Hobert%2C+A">Anne Hobert</a>, 
<a href="/search/cs?searchtype=author&query=Jahn%2C+N">Najko Jahn</a>, 
<a href="/search/cs?searchtype=author&query=Haupka%2C+N">Nick Haupka</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+M">Marion Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Donner%2C+P">Paul Donner</a>, 
<a href="/search/cs?searchtype=author&query=Mayr%2C+P">Philipp Mayr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">OpenAlex is a promising open source of scholarly metadata, and competitor to
the established proprietary sources, the Web of Science and Scopus. As OpenAlex
provides its data freely and openly, it permits researchers to perform
bibliometric studies that can be reproduced in the community without licensing
barriers. However, as OpenAlex is a rapidly evolving source and the data
contained within is expanding and also quickly changing, the question naturally
arises as to the trustworthiness of its data. In this empirical paper, we will
study the reference and metadata coverage within each database and compare them
with each other to help address this open question in bibliometrics. In our
large-scale study, we demonstrate that, when restricted to a cleaned dataset of
16,788,282 recent publications shared by all three databases, OpenAlex has
average reference numbers comparable to both Web of Science and Scopus. We also
demonstrate that the comparison of other core metadata covered by OpenAlex
shows mixed results, with OpenAlex capturing more ORCID identifiers, fewer
abstracts and a similar number of Open Access information per article when
compared to both Web of Science and Scopus.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16366" title="Abstract">arXiv:2401.16366</a> [<a href="/pdf/2401.16366" title="Download PDF">pdf</a>, <a href="/ps/2401.16366" title="Download PostScript">ps</a>, <a href="/format/2401.16366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choiceless Polynomial Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrarotti%2C+F">Flavio Ferrarotti</a>, 
<a href="/search/cs?searchtype=author&query=Schewe%2C+K">Klaus-Dieter Schewe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages. arXiv admin note: substantial text overlap with <a href="/abs/2005.04598">arXiv:2005.04598</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Abstract State Machines (ASMs) provide a model of computations on structures
rather than strings. Blass, Gurevich and Shelah showed that deterministic
PTIME-bounded ASMs define the choiceless fragment of PTIME, but cannot capture
PTIME. In this article deterministic PSPACE-bounded ASMs are introduced, and it
is proven that they cannot capture PSPACE. The key for the proof is a
characterisation by partial fixed-point formulae over the St\"ark/Nanchen logic
for deterministic ASMs and a construction of transitive structures, in which
such formulae must hold. This construction exploits that the decisive support
theorem for choiceless polynomial time holds under slightly weaker assumptions.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16367" title="Abstract">arXiv:2401.16367</a> [<a href="/pdf/2401.16367" title="Download PDF">pdf</a>, <a href="/format/2401.16367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TQCompressor: improving tensor decomposition methods in neural networks  via permutations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abronin%2C+V">V. Abronin</a>, 
<a href="/search/cs?searchtype=author&query=Naumov%2C+A">A. Naumov</a>, 
<a href="/search/cs?searchtype=author&query=Mazur%2C+D">D. Mazur</a>, 
<a href="/search/cs?searchtype=author&query=Bystrov%2C+D">D. Bystrov</a>, 
<a href="/search/cs?searchtype=author&query=Tsarova%2C+K">K. Tsarova</a>, 
<a href="/search/cs?searchtype=author&query=Melnikov%2C+A">Ar. Melnikov</a>, 
<a href="/search/cs?searchtype=author&query=Oseledets%2C+I">I. Oseledets</a>, 
<a href="/search/cs?searchtype=author&query=Dolgov%2C+S">S. Dolgov</a>, 
<a href="/search/cs?searchtype=author&query=Brasher%2C+R">R. Brasher</a>, 
<a href="/search/cs?searchtype=author&query=Perelshtein%2C+M">M. Perelshtein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">We introduce TQCompressor, a novel method for neural network model
compression with improved tensor decompositions. We explore the challenges
posed by the computational and storage demands of pre-trained language models
in NLP tasks and propose a permutation-based enhancement to Kronecker
decomposition. This enhancement makes it possible to reduce loss in model
expressivity which is usually associated with factorization. We demonstrate
this method applied to the GPT-2$_{small}$. The result of the compression is
TQCompressedGPT-2 model, featuring 81 mln. parameters compared to 124 mln. in
the GPT-2$_{small}$. We make TQCompressedGPT-2 publicly available. We further
enhance the performance of the TQCompressedGPT-2 through a training strategy
involving multi-step knowledge distillation, using only a 3.1% of the
OpenWebText. TQCompressedGPT-2 surpasses DistilGPT-2 and KnGPT-2 in comparative
evaluations, marking an advancement in the efficient and effective deployment
of models in resource-constrained environments.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16368" title="Abstract">arXiv:2401.16368</a> [<a href="/pdf/2401.16368" title="Download PDF">pdf</a>, <a href="/format/2401.16368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new numerical method for scalar eigenvalue problems in heterogeneous,  dispersive, sign-changing materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Halla%2C+M">Martin Halla</a>, 
<a href="/search/math?searchtype=author&query=Hohage%2C+T">Thorsten Hohage</a>, 
<a href="/search/math?searchtype=author&query=Oberender%2C+F">Florian Oberender</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider time-harmonic scalar transmission problems between dielectric and
dispersive materials with generalized Lorentz frequency laws. For certain
frequency ranges such equations involve a sign-change in their principle part.
Due to the resulting loss of coercivity properties, the numerical simulation of
such problems is demanding. Furthermore, the related eigenvalue problems are
nonlinear and give rise to additional challenges. We present a new finite
element method for both of these types of problems, which is based on a weakly
coercive reformulation of the PDE. The new scheme can handle
$C^{1,1}$-interfaces consisting piecewise of elementary geometries. Neglecting
quadrature errors, the method allows for a straightforward convergence
analysis. In our implementation we apply a simple, but nonstandard quadrature
rule to achieve negligible quadrature errors. We present computational
experiments in 2D and 3D for both source and eigenvalue problems which confirm
the stability and convergence of the new scheme.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16369" title="Abstract">arXiv:2401.16369</a> [<a href="/pdf/2401.16369" title="Download PDF">pdf</a>, <a href="/format/2401.16369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed-Order Meshes through rp-adaptivity for Surface Fitting to Implicit  Geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+K">Ketan Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Dobrev%2C+V+A">Veselin A. Dobrev</a>, 
<a href="/search/cs?searchtype=author&query=Knupp%2C+P">Patrick Knupp</a>, 
<a href="/search/cs?searchtype=author&query=Kolev%2C+T">Tzanio Kolev</a>, 
<a href="/search/cs?searchtype=author&query=Ledoux%2C+F">Franck Ledoux</a>, 
<a href="/search/cs?searchtype=author&query=Roche%2C+C">Claire Roche</a>, 
<a href="/search/cs?searchtype=author&query=Tomov%2C+V+Z">Vladimir Z. Tomov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Computational analysis with the finite element method requires geometrically
accurate meshes. It is well known that high-order meshes can accurately capture
curved surfaces with fewer degrees of freedom in comparison to low-order
meshes. Existing techniques for high-order mesh generation typically output
meshes with same polynomial order for all elements. However, high order
elements away from curvilinear boundaries or interfaces increase the
computational cost of the simulation without increasing geometric accuracy. In
prior work, we have presented one such approach for generating body-fitted
uniform-order meshes that takes a given mesh and morphs it to align with the
surface of interest prescribed as the zero isocontour of a level-set function.
We extend this method to generate mixed-order meshes such that curved surfaces
of the domain are discretized with high-order elements, while low-order
elements are used elsewhere. Numerical experiments demonstrate the robustness
of the approach and show that it can be used to generate mixed-order meshes
that are much more efficient than high uniform-order meshes. The proposed
approach is purely algebraic, and extends to different types of elements
(quadrilaterals/triangles/tetrahedron/hexahedra) in two- and three-dimensions.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16373" title="Abstract">arXiv:2401.16373</a> [<a href="/pdf/2401.16373" title="Download PDF">pdf</a>, <a href="/format/2401.16373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian optimization as a flexible and efficient design framework for  sustainable process systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paulson%2C+J+A">Joel A. Paulson</a>, 
<a href="/search/cs?searchtype=author&query=Tsay%2C+C">Calvin Tsay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 figure, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Bayesian optimization (BO) is a powerful technology for optimizing noisy
expensive-to-evaluate black-box functions, with a broad range of real-world
applications in science, engineering, economics, manufacturing, and beyond. In
this paper, we provide an overview of recent developments, challenges, and
opportunities in BO for design of next-generation process systems. After
describing several motivating applications, we discuss how advanced BO methods
have been developed to more efficiently tackle important problems in these
applications. We conclude the paper with a summary of challenges and
opportunities related to improving the quality of the probabilistic model, the
choice of internal optimization procedure used to select the next sample point,
and the exploitation of problem structure to improve sample efficiency.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16375" title="Abstract">arXiv:2401.16375</a> [<a href="/pdf/2401.16375" title="Download PDF">pdf</a>, <a href="/format/2401.16375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spot the Error: Non-autoregressive Graphic Layout Generation with  Wireframe Locator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jieru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Danqing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tiejun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+D">Dechen Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Yew Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Layout generation is a critical step in graphic design to achieve meaningful
compositions of elements. Most previous works view it as a sequence generation
problem by concatenating element attribute tokens (i.e., category, size,
position). So far the autoregressive approach (AR) has achieved promising
results, but is still limited in global context modeling and suffers from error
propagation since it can only attend to the previously generated tokens. Recent
non-autoregressive attempts (NAR) have shown competitive results, which
provides a wider context range and the flexibility to refine with iterative
decoding. However, current works only use simple heuristics to recognize
erroneous tokens for refinement which is inaccurate. This paper first conducts
an in-depth analysis to better understand the difference between the AR and NAR
framework. Furthermore, based on our observation that pixel space is more
sensitive in capturing spatial patterns of graphic layouts (e.g., overlap,
alignment), we propose a learning-based locator to detect erroneous tokens
which takes the wireframe image rendered from the generated layout sequence as
input. We show that it serves as a complementary modality to the element
sequence in object space and contributes greatly to the overall performance.
Experiments on two public datasets show that our approach outperforms both AR
and NAR baselines. Extensive studies further prove the effectiveness of
different modules with interesting findings. Our code will be available at
https://github.com/ffffatgoose/SpotError.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16379" title="Abstract">arXiv:2401.16379</a> [<a href="/pdf/2401.16379" title="Download PDF">pdf</a>, <a href="/format/2401.16379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponentially Fitted Finite Difference Approximation for Singularly  Perturbed Fredholm Integro-Differential Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alam%2C+M">Mehebub Alam</a>, 
<a href="/search/math?searchtype=author&query=Pandey%2C+R+K">Rajni Kant Pandey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we concentrate on solving second-order singularly perturbed
Fredholm integro-differential equations (SPFIDEs). It is well known that
solving these equations analytically is a challenging endeavor because of the
presence of boundary and interior layers within the domain. To overcome these
challenges, we develop a fitted second-order difference scheme that can capture
the layer behavior of the solution accurately and efficiently, which is again,
based on the integral identities with exponential basis functions, the
composite trapezoidal rule, and an appropriate interpolating quadrature rules
with the remainder terms in the integral form on a piecewise uniform mesh.
Hence, our numerical method acts as a superior alternative to the existing
methods in the literature. Further, using appropriate techniques in error
analysis the scheme's convergence and stability have been studied in the
discrete max norm. We have provided necessary experimental evidence that
corroborates the theoretical results with a high degree of accuracy.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16380" title="Abstract">arXiv:2401.16380</a> [<a href="/pdf/2401.16380" title="Download PDF">pdf</a>, <a href="/format/2401.16380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rephrasing the Web: A Recipe for Compute and Data-Efficient Language  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maini%2C+P">Pratyush Maini</a>, 
<a href="/search/cs?searchtype=author&query=Seto%2C+S">Skyler Seto</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">He Bai</a>, 
<a href="/search/cs?searchtype=author&query=Grangier%2C+D">David Grangier</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jaitly%2C+N">Navdeep Jaitly</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models are trained on massive scrapes of the web, which are
often unstructured, noisy, and poorly phrased. Current scaling laws show that
learning from such data requires an abundance of both compute and data, which
grows with the size of the model being trained. This is infeasible both because
of the large compute costs and duration associated with pre-training, and the
impending scarcity of high-quality data on the web. In this work, we propose
Web Rephrase Augmented Pre-training ($\textbf{WRAP}$) that uses an
off-the-shelf instruction-tuned model prompted to paraphrase documents on the
web in specific styles such as "like Wikipedia" or in "question-answer format"
to jointly pre-train LLMs on real and synthetic rephrases. First, we show that
using WRAP on the C4 dataset, which is naturally noisy, speeds up pre-training
by $\sim3x$. At the same pre-training compute budget, it improves perplexity by
more than 10% on average across different subsets of the Pile, and improves
zero-shot question answer accuracy across 13 tasks by more than 2%. Second, we
investigate the impact of the re-phrasing style on the performance of the
model, offering insights into how the composition of the training data can
impact the performance of LLMs in OOD settings. Our gains are attributed to the
fact that re-phrased synthetic data has higher utility than just real data
because it (i) incorporates style diversity that closely reflects downstream
evaluation style, and (ii) has higher 'quality' than web-scraped data.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16382" title="Abstract">arXiv:2401.16382</a> [<a href="/pdf/2401.16382" title="Download PDF">pdf</a>, <a href="/ps/2401.16382" title="Download PostScript">ps</a>, <a href="/format/2401.16382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A KDM-Based Approach for Architecture Conformance Checking in Adaptive  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn%2C+D+S">Daniel San Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Angulo%2C+G">Guisella Angulo</a>, 
<a href="/search/cs?searchtype=author&query=de+Camargo%2C+V+V">Valter Vieira de Camargo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to JSERD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Adaptive Systems (ASs) are capable to monitor their behavior and make
adjustments when quality goals are not achieved through the MAPE-K, a widely
recognized reference model that offers abstractions for designing ASs. By
making these abstractions evident in the system structure, numerous benefits
emerge, particularly in terms of enhancing the architecture's maintenance and
comprehensibility. However, it is observed that many existing ASs are not
designed in accordance with MAPE-K, causing these abstractions to remain hidden
in their architecture. To address this issue, Architectural Conformance
Checking (ACC) emerges as a valuable technique for verifying whether the
current architecture (CA) of a system adheres to the rules prescribed by the
planned architecture (PA) or a reference model, such as MAPE-K. In this paper,
we present REMEDY, a domain-specific approach that encompasses the
specification of the planned adaptive architecture based on the MAPE-K
reference model, the recovery of the current adaptive architecture, the
conformance checking process, and architecture visualizations. Furthermore, our
approach is specifically tailored for ASs, incorporating well-known rules from
the MAPE-K model. The evaluation of the REMEDY DSL involves a comparison with a
general-purpose DSL, and the results demonstrate improvements in productivity.
REMEDY facilitates the identification and correction of architectural
non-conformance issues, thereby enhancing the overall quality of adaptive
systems.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16383" title="Abstract">arXiv:2401.16383</a> [<a href="/pdf/2401.16383" title="Download PDF">pdf</a>, <a href="/ps/2401.16383" title="Download PostScript">ps</a>, <a href="/format/2401.16383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning logic programs by finding minimal unsatisfiable subprograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cropper%2C+A">Andrew Cropper</a>, 
<a href="/search/cs?searchtype=author&query=Hocquette%2C+C">C&#xe9;line Hocquette</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">The goal of inductive logic programming (ILP) is to search for a logic
program that generalises training examples and background knowledge. We
introduce an ILP approach that identifies minimal unsatisfiable subprograms
(MUSPs). We show that finding MUSPs allows us to efficiently and soundly prune
the search space. Our experiments on multiple domains, including program
synthesis and game playing, show that our approach can reduce learning times by
99%.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16386" title="Abstract">arXiv:2401.16386</a> [<a href="/pdf/2401.16386" title="Download PDF">pdf</a>, <a href="/format/2401.16386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning with Pre-Trained Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Da-Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hai-Long Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+J">Jingyi Ning</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Han-Jia Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+D">De-Chuan Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at: <a href="https://github.com/sun-hailong/LAMDA-PILOT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Nowadays, real-world applications often face streaming data, which requires
the learning system to absorb new knowledge as data evolves. Continual Learning
(CL) aims to achieve this goal and meanwhile overcome the catastrophic
forgetting of former knowledge when learning new ones. Typical CL methods build
the model from scratch to grow with incoming data. However, the advent of the
pre-trained model (PTM) era has sparked immense research interest, particularly
in leveraging PTMs' robust representational capabilities. This paper presents a
comprehensive survey of the latest advancements in PTM-based CL. We categorize
existing methodologies into three distinct groups, providing a comparative
analysis of their similarities, differences, and respective advantages and
disadvantages. Additionally, we offer an empirical study contrasting various
state-of-the-art methods to highlight concerns regarding fairness in
comparisons. The source code to reproduce these evaluations is available at:
https://github.com/sun-hailong/LAMDA-PILOT
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16387" title="Abstract">arXiv:2401.16387</a> [<a href="/pdf/2401.16387" title="Download PDF">pdf</a>, <a href="/format/2401.16387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Green Adaptation of Real-Time Web Services for Industrial CPS within a  Cloud Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Higuera%2C+T">Teresa Higuera</a>, 
<a href="/search/cs?searchtype=author&query=Risco-Mart%C3%ADn%2C+J+L">Jos&#xe9; L. Risco-Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Arroba%2C+P">Patricia Arroba</a>, 
<a href="/search/cs?searchtype=author&query=Ayala%2C+J+L">Jos&#xe9; L. Ayala</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Industrial Informatics, 13(3), 2017
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Managing energy efficiency under timing constraints is an interesting and big
challenge. This work proposes an accurate power model in data centers for
time-constrained servers in Cloud computing. This model, as opposed to previous
approaches, does not only consider the workload assigned to the processing
element, but also incorporates the need of considering the static power
consumption and, even more interestingly, its dependency with temperature. The
proposed model has been used in a multi-objective optimization environment in
which the Dynamic Voltage and Frequency Scaling (DVFS) and workload assignment
have been efficiently optimized.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16390" title="Abstract">arXiv:2401.16390</a> [<a href="/pdf/2401.16390" title="Download PDF">pdf</a>, <a href="/ps/2401.16390" title="Download PostScript">ps</a>, <a href="/format/2401.16390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Private Membership Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aytekin%2C+A">Alptug Aytekin</a>, 
<a href="/search/cs?searchtype=author&query=Nomeir%2C+M">Mohamed Nomeir</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We consider the problem of private set membership aggregation of $N$ parties
by using an entangled quantum state. In this setting, the $N$ parties, which
share an entangled state, aim to \emph{privately} know the number of times each
element (message) is repeated among the $N$ parties, with respect to a
universal set $\mathcal{K}$. This problem has applications in private
comparison, ranking, voting, etc. We propose an encoding algorithm that maps
the classical information into distinguishable quantum states, along with a
decoding algorithm that exploits the distinguishability of the mapped states.
The proposed scheme can also be used to calculate the $N$ party private
summation modulo $P$.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16391" title="Abstract">arXiv:2401.16391</a> [<a href="/pdf/2401.16391" title="Download PDF">pdf</a>, <a href="/ps/2401.16391" title="Download PostScript">ps</a>, <a href="/format/2401.16391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Framework for Problem-Based Learning in an Introductory  Circuit Analysis Course
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Martin%2C+S">Sebastian Martin</a>, 
<a href="/search/eess?searchtype=author&query=Pineda%2C+S">Salvador Pineda</a>, 
<a href="/search/eess?searchtype=author&query=Perez-Ruiz%2C+J">Juan Perez-Ruiz</a>, 
<a href="/search/eess?searchtype=author&query=Alguacil%2C+N">Natalia Alguacil</a>, 
<a href="/search/eess?searchtype=author&query=Ruiz-Gonzalez%2C+A">Antonio Ruiz-Gonzalez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages and 1 Table
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Education Conference (EDUCON) 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Introductory courses on electric circuits at under- graduate level are
usually presented in quite abstract terms, with questions and problems quite
far from practical problems. This causes the students have difficulties to
apply that theory to solve practical technical problems. On the other hand,
electric circuits are everywhere in our lives, so we have plenty of real
practical problems. Here we compile a selection of practical contexts suited
for implementing Problem Based Learning approach in an introductory course on
circuit analysis. And some examples describing the gamification process that
uses these problems to build single-player role-playing games that fulfil the
course contents and scheduling. The key point of the assessment and how it is
related to the progress in the game is also described.
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16393" title="Abstract">arXiv:2401.16393</a> [<a href="/pdf/2401.16393" title="Download PDF">pdf</a>, <a href="/format/2401.16393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amazon&#x27;s 2023 Drought: Sentinel-1 Reveals Extreme Rio Negro River  Contraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wagner%2C+F+H">Fabien H Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Favrichon%2C+S">Samuel Favrichon</a>, 
<a href="/search/cs?searchtype=author&query=Dalagnol%2C+R">Ricardo Dalagnol</a>, 
<a href="/search/cs?searchtype=author&query=Hirye%2C+M+C">Mayumi CM Hirye</a>, 
<a href="/search/cs?searchtype=author&query=Mullissa%2C+A">Adugna Mullissa</a>, 
<a href="/search/cs?searchtype=author&query=Saatchi%2C+S">Sassan Saatchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Amazon, the world's largest rainforest, faces a severe historic drought.
The Rio Negro River, one of the major Amazon River tributaries, reaches its
lowest level in a century in October 2023. Here, we used a U-net deep learning
model to map water surfaces in the Rio Negro River basin every 12 days in 2022
and 2023 using 10 m spatial resolution Sentinel-1 satellite radar images. The
accuracy of the water surface model was high with an F1-score of 0.93. The 12
days mosaic time series of water surface was generated from the Sentinel-1
prediction. The water surface mask demonstrated relatively consistent agreement
with the Global Surface Water (GSW) product from Joint Research Centre
(F1-score: 0.708) and with the Brazilian Mapbiomas Water initiative (F1-score:
0.686). The main errors of the map were omission errors in flooded woodland, in
flooded shrub and because of clouds. Rio Negro water surfaces reached their
lowest level around the 25th of November 2023 and were reduced to 68.1\%
(9,559.9 km$^2$) of the maximum water surfaces observed in the period 2022-2023
(14,036.3 km$^2$). Synthetic Aperture Radar (SAR) data, in conjunction with
deep learning techniques, can significantly improve near real-time mapping of
water surface in tropical regions.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16395" title="Abstract">arXiv:2401.16395</a> [<a href="/pdf/2401.16395" title="Download PDF">pdf</a>, <a href="/format/2401.16395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciding Subtyping for Asynchronous Multiparty Sessions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+E">Elaine Li</a>, 
<a href="/search/cs?searchtype=author&query=Stutz%2C+F">Felix Stutz</a>, 
<a href="/search/cs?searchtype=author&query=Wies%2C+T">Thomas Wies</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Multiparty session types (MSTs) are a type-based approach to verifying
communication protocols, represented as global types in the framework. We
present a precise subtyping relation for asynchronous MSTs with communicating
state machines (CSMs) as implementation model. We address two problems: when
can a local implementation safely substitute another, and when does an
arbitrary CSM implement a global type? We define safety with respect to a given
global type, in terms of subprotocol fidelity and deadlock freedom. Our
implementation model subsumes existing work which considers local types with
restricted choice. We exploit the connection between MST subtyping and
refinement to formulate concise conditions that are directly checkable on the
candidate implementations, and use them to show that both problems are
decidable in polynomial time.
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16398" title="Abstract">arXiv:2401.16398</a> [<a href="/pdf/2401.16398" title="Download PDF">pdf</a>, <a href="/format/2401.16398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Imitation Policy via Search in Demonstration Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malato%2C+F">Federco Malato</a>, 
<a href="/search/cs?searchtype=author&query=Leopold%2C+F">Florian Leopold</a>, 
<a href="/search/cs?searchtype=author&query=Melnik%2C+A">Andrew Melnik</a>, 
<a href="/search/cs?searchtype=author&query=Hautamaki%2C+V">Ville Hautamaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Behavioral cloning uses a dataset of demonstrations to learn a policy. To
overcome computationally expensive training procedures and address the policy
adaptation problem, we propose to use latent spaces of pre-trained foundation
models to index a demonstration dataset, instantly access similar relevant
experiences, and copy behavior from these situations. Actions from a selected
similar situation can be performed by the agent until representations of the
agent's current situation and the selected experience diverge in the latent
space. Thus, we formulate our control problem as a dynamic search problem over
a dataset of experts' demonstrations. We test our approach on BASALT
MineRL-dataset in the latent representation of a Video Pre-Training model. We
compare our model to state-of-the-art, Imitation Learning-based Minecraft
agents. Our approach can effectively recover meaningful demonstrations and show
human-like behavior of an agent in the Minecraft environment in a wide variety
of scenarios. Experimental results reveal that performance of our search-based
approach clearly wins in terms of accuracy and perceptual evaluation over
learning-based models.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16399" title="Abstract">arXiv:2401.16399</a> [<a href="/pdf/2401.16399" title="Download PDF">pdf</a>, <a href="/format/2401.16399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Winner Voting with Alliances: Avoiding the Spoiler Effect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pierczy%C5%84ski%2C+G">Grzegorz Pierczy&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Szufa%2C+S">Stanis&#x142;aw Szufa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">We study the setting of single-winner elections with ordinal preferences
where candidates might be members of \emph{alliances} (which may correspond to
e.g., political parties, factions, or coalitions). However, we do not assume
that candidates from the same alliance are necessarily adjacent in voters'
rankings. In such case, every classical voting rule is vulnerable to the
spoiler effect, i.e., the presence of a candidate may harm his or her alliance.
We therefore introduce a new idea of \emph{alliance-aware} voting rules which
extend the classical ones. We show that our approach is superior both to using
classical cloneproof voting rules and to running primaries within alliances
before the election.
<br />We introduce several alliance-aware voting rules and show that they satisfy
the most desirable standard properties of their classical counterparts as well
as newly introduced axioms for the model with alliances which, e.g., exclude
the possibility of the spoiler effect. Our rules have natural definitions and
are simple enough to explain to be used in practice.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16402" title="Abstract">arXiv:2401.16402</a> [<a href="/pdf/2401.16402" title="Download PDF">pdf</a>, <a href="/format/2401.16402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Visual Anomaly Detection: Challenge, Approach, and Prospect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yunkang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaonan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weiming Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Yunkang Cao, Xiaohao Xu, and Jiangning Zhang contribute equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Visual Anomaly Detection (VAD) endeavors to pinpoint deviations from the
concept of normality in visual data, widely applied across diverse domains,
e.g., industrial defect inspection, and medical lesion detection. This survey
comprehensively examines recent advancements in VAD by identifying three
primary challenges: 1) scarcity of training data, 2) diversity of visual
modalities, and 3) complexity of hierarchical anomalies. Starting with a brief
overview of the VAD background and its generic concept definitions, we
progressively categorize, emphasize, and discuss the latest VAD progress from
the perspective of sample number, data modality, and anomaly hierarchy. Through
an in-depth analysis of the VAD field, we finally summarize future developments
for VAD and conclude the key findings and contributions of this survey.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16403" title="Abstract">arXiv:2401.16403</a> [<a href="/pdf/2401.16403" title="Download PDF">pdf</a>, <a href="/format/2401.16403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViLexNorm: A Lexical Normalization Corpus for Vietnamese Social Media  Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thanh-Nhi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Thanh-Phong Le</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+K">Kiet Van Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the EACL 2024 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Lexical normalization, a fundamental task in Natural Language Processing
(NLP), involves the transformation of words into their canonical forms. This
process has been proven to benefit various downstream NLP tasks greatly. In
this work, we introduce Vietnamese Lexical Normalization (ViLexNorm), the
first-ever corpus developed for the Vietnamese lexical normalization task. The
corpus comprises over 10,000 pairs of sentences meticulously annotated by human
annotators, sourced from public comments on Vietnam's most popular social media
platforms. Various methods were used to evaluate our corpus, and the
best-performing system achieved a result of 57.74% using the Error Reduction
Rate (ERR) metric (van der Goot, 2019a) with the Leave-As-Is (LAI) baseline.
For extrinsic evaluation, employing the model trained on ViLexNorm demonstrates
the positive impact of the Vietnamese lexical normalization task on other NLP
tasks. Our corpus is publicly available exclusively for research purposes.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16405" title="Abstract">arXiv:2401.16405</a> [<a href="/pdf/2401.16405" title="Download PDF">pdf</a>, <a href="/format/2401.16405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Sparse Fine-Tuning to Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ansell%2C+A">Alan Ansell</a>, 
<a href="/search/cs?searchtype=author&query=Vuli%C4%87%2C+I">Ivan Vuli&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Sterz%2C+H">Hannah Sterz</a>, 
<a href="/search/cs?searchtype=author&query=Korhonen%2C+A">Anna Korhonen</a>, 
<a href="/search/cs?searchtype=author&query=Ponti%2C+E+M">Edoardo M. Ponti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) are difficult to fully fine-tune (e.g., with
instructions or human feedback) due to their sheer number of parameters. A
family of parameter-efficient sparse fine-tuning (SFT) methods have proven
promising in terms of performance but their memory requirements increase
proportionally to the size of the LLMs. In this work, we scale sparse
fine-tuning to state-of-the-art LLMs like LLaMA 2 7B and 13B. At any given
time, for a desired density level, we maintain an array of parameter indices
and the deltas of these parameters relative to their pretrained values. We
iterate among: (a) updating the active deltas, (b) pruning indices (based on
the change of magnitude of their deltas) and (c) regrowth of indices. For
regrowth, we explore two criteria based on either the accumulated gradients of
a few candidate parameters or their approximate momenta estimated using the
efficient SM3 optimizer. We experiment with instruction-tuning of LLMs on
standard dataset mixtures, finding that SFT is often superior to popular
parameter-efficient fine-tuning methods like LoRA (low-rank adaptation) in
terms of performance and comparable in terms of run time. We additionally show
that SFT is compatible with both quantization and efficient optimizers, to
facilitate scaling to ever-larger model sizes. We release the code for SFT at
https://github.com/AlanAnsell/peft and for the instruction-tuning experiments
at https://github.com/ducdauge/sft-llm.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16411" title="Abstract">arXiv:2401.16411</a> [<a href="/pdf/2401.16411" title="Download PDF">pdf</a>, <a href="/format/2401.16411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Discrete Empirical Interpolation Method: State Estimation from  Few Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Farazmand%2C+M">Mohammad Farazmand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Discrete empirical interpolation method (DEIM) estimates a function from its
incomplete pointwise measurements. Unfortunately, DEIM suffers large
interpolation errors when few measurements are available. Here, we introduce
Sparse DEIM (S-DEIM) for accurately estimating a function even when very few
measurements are available. To this end, S-DEIM leverages a kernel vector which
has been neglected in previous DEIM-based methods. We derive theoretical error
estimates for S-DEIM, showing its relatively small error when an optimal kernel
vector is used. When the function is generated by a continuous-time dynamical
system, we propose a data assimilation algorithm which approximates the optimal
kernel vector using observational time series. We prove that, under certain
conditions, data assimilated S-DEIM converges exponentially fast towards the
true state. We demonstrate the efficacy of our method on two numerical
examples.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16412" title="Abstract">arXiv:2401.16412</a> [<a href="/pdf/2401.16412" title="Download PDF">pdf</a>, <a href="/format/2401.16412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Manipulate under Limited Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holliday%2C+W+H">Wesley H. Holliday</a>, 
<a href="/search/cs?searchtype=author&query=Kristoffersen%2C+A">Alexander Kristoffersen</a>, 
<a href="/search/cs?searchtype=author&query=Pacuit%2C+E">Eric Pacuit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures. Code available at <a href="https://github.com/epacuit/ltm">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">By classic results in social choice theory, any reasonable preferential
voting method sometimes gives individuals an incentive to report an insincere
preference. The extent to which different voting methods are more or less
resistant to such strategic manipulation has become a key consideration for
comparing voting methods. Here we measure resistance to manipulation by whether
neural networks of varying sizes can learn to profitably manipulate a given
voting method in expectation, given different types of limited information
about how other voters will vote. We trained nearly 40,000 neural networks of
26 sizes to manipulate against 8 different voting methods, under 6 types of
limited information, in committee-sized elections with 5-21 voters and 3-6
candidates. We find that some voting methods, such as Borda, are highly
manipulable by networks with limited information, while others, such as Instant
Runoff, are not, despite being quite profitably manipulated by an ideal
manipulator with full information.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16413" title="Abstract">arXiv:2401.16413</a> [<a href="/pdf/2401.16413" title="Download PDF">pdf</a>, <a href="/ps/2401.16413" title="Download PostScript">ps</a>, <a href="/format/2401.16413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The geometric error is less than the pollution error when solving the  high-frequency Helmholtz equation with high-order FEM on curved domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chaumont-Frelet%2C+T">Th&#xe9;ophile Chaumont-Frelet</a>, 
<a href="/search/math?searchtype=author&query=Spence%2C+E+A">Euan A. Spence</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the $h$-version of the finite-element method, where accuracy is
increased by decreasing the meshwidth $h$ while keeping the polynomial degree
$p$ constant, applied to the Helmholtz equation. Although the question "how
quickly must $h$ decrease as the wavenumber $k$ increases to maintain
accuracy?" has been studied intensively since the 1990s, none of the existing
rigorous wavenumber-explicit analyses take into account the approximation of
the geometry. In this paper we prove that for nontrapping problems solved using
straight elements the geometric error is order $kh$, which is then less than
the pollution error $k(kh)^{2p}$ when $k$ is large; this fact is then
illustrated in numerical experiments. More generally, we prove that, even for
problems with strong trapping, using degree four (in 2-d) or degree five (in
3-d) polynomials and isoparametric elements ensures that the geometric error is
smaller than the pollution error for most large wavenumbers.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16414" title="Abstract">arXiv:2401.16414</a> [<a href="/pdf/2401.16414" title="Download PDF">pdf</a>, <a href="/format/2401.16414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Causal Model for Quantifying Multipartite Classical and Quantum  Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuchan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wunder%2C+G">Gerhard Wunder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We give an operational definition of information-theoretic resources within a
given multipartite classical or quantum correlation. We present our causal
model that serves as the source coding side of this correlation and introduce a
novel concept of resource rate. We argue that, beyond classical secrecy,
additional resources exist that are useful for the security of distributed
computing problems, which can be captured by the resource rate. Furthermore, we
establish a relationship between resource rate and an extension of Shannon's
logarithmic information measure, namely, total correlation. Subsequently, we
present a novel quantum secrecy monotone and investigate a quantum hybrid key
distribution system as an extension of our causal model. Finally, we discuss
some connections to optimal transport (OT) problem.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16416" title="Abstract">arXiv:2401.16416</a> [<a href="/pdf/2401.16416" title="Download PDF">pdf</a>, <a href="/format/2401.16416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Endo-4DGS: Distilling Depth Ranking for Endoscopic Monocular Scene  Reconstruction with 4D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Beilei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Long Bai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Ziqi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengya Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hongliang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the realm of robot-assisted minimally invasive surgery, dynamic scene
reconstruction can significantly enhance downstream tasks and improve surgical
outcomes. Neural Radiance Fields (NeRF)-based methods have recently risen to
prominence for their exceptional ability to reconstruct scenes. Nonetheless,
these methods are hampered by slow inference, prolonged training, and
substantial computational demands. Additionally, some rely on stereo depth
estimation, which is often infeasible due to the high costs and logistical
challenges associated with stereo cameras. Moreover, the monocular
reconstruction quality for deformable scenes is currently inadequate. To
overcome these obstacles, we present Endo-4DGS, an innovative, real-time
endoscopic dynamic reconstruction approach that utilizes 4D Gaussian Splatting
(GS) and requires no ground truth depth data. This method extends 3D GS by
incorporating a temporal component and leverages a lightweight MLP to capture
temporal Gaussian deformations. This effectively facilitates the reconstruction
of dynamic surgical scenes with variable conditions. We also integrate
Depth-Anything to generate pseudo-depth maps from monocular views, enhancing
the depth-guided reconstruction process. Our approach has been validated on two
surgical datasets, where it has proven to render in real-time, compute
efficiently, and reconstruct with remarkable accuracy. These results underline
the vast potential of Endo-4DGS to improve surgical assistance.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16417" title="Abstract">arXiv:2401.16417</a> [<a href="/pdf/2401.16417" title="Download PDF">pdf</a>, <a href="/ps/2401.16417" title="Download PostScript">ps</a>, <a href="/format/2401.16417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Coding with Mean and Variance Cost Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+A">Adeel Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+A+B">Aaron B. Wagner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We consider channel coding for discrete memoryless channels (DMCs) with a
novel cost constraint that constrains both the mean and the variance of the
cost of the codewords. We show that the maximum (asymptotically) achievable
rate under the new cost formulation is equal to the capacity-cost function; in
particular, the strong converse holds. We further characterize the optimal
second-order coding rate of these cost-constrained codes; in particular, the
optimal second-order coding rate is finite. We then show that the second-order
coding performance is strictly improved with feedback using a new variation of
timid/bold coding, significantly broadening the applicability of timid/bold
coding schemes from unconstrained compound-dispersion channels to all
cost-constrained channels. Equivalent results on the minimum average
probability of error are also given.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16419" title="Abstract">arXiv:2401.16419</a> [<a href="/pdf/2401.16419" title="Download PDF">pdf</a>, <a href="/format/2401.16419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-parametric Expert Bayesian Network Learning with Gaussian Processes  and Horseshoe Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+Y">Yidou Weng</a>, 
<a href="/search/cs?searchtype=author&query=Doshi-Velez%2C+F">Finale Doshi-Velez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, AAAI-2024 workshops
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper proposes a model learning Semi-parametric rela- tionships in an
Expert Bayesian Network (SEBN) with linear parameter and structure constraints.
We use Gaussian Pro- cesses and a Horseshoe prior to introduce minimal nonlin-
ear components. To prioritize modifying the expert graph over adding new edges,
we optimize differential Horseshoe scales. In real-world datasets with unknown
truth, we gen- erate diverse graphs to accommodate user input, addressing
identifiability issues and enhancing interpretability. Evalua- tion on
synthetic and UCI Liver Disorders datasets, using metrics like structural
Hamming Distance and test likelihood, demonstrates our models outperform
state-of-the-art semi- parametric Bayesian Network model.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16420" title="Abstract">arXiv:2401.16420</a> [<a href="/pdf/2401.16420" title="Download PDF">pdf</a>, <a href="/format/2401.16420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InternLM-XComposer2: Mastering Free-form Text-Image Composition and  Comprehension in Vision-Language Large Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Yuhang Zang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuhang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+L">Linke Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xilin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haodong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Maosong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yining Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingcheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and models are available at <a href="https://github.com/InternLM/InternLM-XComposer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We introduce InternLM-XComposer2, a cutting-edge vision-language model
excelling in free-form text-image composition and comprehension. This model
goes beyond conventional vision-language understanding, adeptly crafting
interleaved text-image content from diverse inputs like outlines, detailed
textual specifications, and reference images, enabling highly customizable
content creation. InternLM-XComposer2 proposes a Partial LoRA (PLoRA) approach
that applies additional LoRA parameters exclusively to image tokens to preserve
the integrity of pre-trained language knowledge, striking a balance between
precise vision understanding and text composition with literary talent.
Experimental results demonstrate the superiority of InternLM-XComposer2 based
on InternLM2-7B in producing high-quality long-text multi-modal content and its
exceptional vision-language understanding performance across various
benchmarks, where it not only significantly outperforms existing multimodal
models but also matches or even surpasses GPT-4V and Gemini Pro in certain
assessments. This highlights its remarkable proficiency in the realm of
multimodal understanding. The InternLM-XComposer2 model series with 7B
parameters are publicly available at
https://github.com/InternLM/InternLM-XComposer.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16421" title="Abstract">arXiv:2401.16421</a> [<a href="/pdf/2401.16421" title="Download PDF">pdf</a>, <a href="/format/2401.16421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length  Extrapolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhenyu He</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+G">Guhao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shengjie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Di He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingjing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures, 8 tables; Working in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this work, we leverage the intrinsic segmentation of language sequences
and design a new positional encoding method called Bilevel Positional Encoding
(BiPE). For each position, our BiPE blends an intra-segment encoding and an
inter-segment encoding. The intra-segment encoding identifies the locations
within a segment and helps the model capture the semantic information therein
via absolute positional encoding. The inter-segment encoding specifies the
segment index, models the relationships between segments, and aims to improve
extrapolation capabilities via relative positional encoding. Theoretical
analysis shows this disentanglement of positional information makes learning
more effective. The empirical results also show that our BiPE has superior
length extrapolation capabilities across a wide range of tasks in diverse text
modalities.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16422" title="Abstract">arXiv:2401.16422</a> [<a href="/pdf/2401.16422" title="Download PDF">pdf</a>, <a href="/format/2401.16422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategic Usage in a Multi-Learner Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shekhtman%2C+E">Eliot Shekhtman</a>, 
<a href="/search/cs?searchtype=author&query=Dean%2C+S">Sarah Dean</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Real-world systems often involve some pool of users choosing between a set of
services. With the increase in popularity of online learning algorithms, these
services can now self-optimize, leveraging data collected on users to maximize
some reward such as service quality. On the flipside, users may strategically
choose which services to use in order to pursue their own reward functions, in
the process wielding power over which services can see and use their data.
Extensive prior research has been conducted on the effects of strategic users
in single-service settings, with strategic behavior manifesting in the
manipulation of observable features to achieve a desired classification;
however, this can often be costly or unattainable for users and fails to
capture the full behavior of multi-service dynamic systems. As such, we analyze
a setting in which strategic users choose among several available services in
order to pursue positive classifications, while services seek to minimize loss
functions on their observations. We focus our analysis on realizable settings,
and show that naive retraining can still lead to oscillation even if all users
are observed at different times; however, if this retraining uses memory of
past observations, convergent behavior can be guaranteed for certain loss
function classes. We provide results obtained from synthetic and real-world
data to empirically validate our theoretical findings.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16423" title="Abstract">arXiv:2401.16423</a> [<a href="/pdf/2401.16423" title="Download PDF">pdf</a>, <a href="/format/2401.16423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synchformer: Efficient Synchronization from Sparse Cues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iashin%2C+V">Vladimir Iashin</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Rahtu%2C+E">Esa Rahtu</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the ICASSP 24 paper. Project page: <a href="https://www.robots.ox.ac.uk/~vgg/research/synchformer/">this https URL</a> Code: <a href="https://github.com/v-iashin/Synchformer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Our objective is audio-visual synchronization with a focus on 'in-the-wild'
videos, such as those on YouTube, where synchronization cues can be sparse. Our
contributions include a novel audio-visual synchronization model, and training
that decouples feature extraction from synchronization modelling through
multi-modal segment-level contrastive pre-training. This approach achieves
state-of-the-art performance in both dense and sparse settings. We also extend
synchronization model training to AudioSet a million-scale 'in-the-wild'
dataset, investigate evidence attribution techniques for interpretability, and
explore a new capability for synchronization models: audio-visual
synchronizability.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16424" title="Abstract">arXiv:2401.16424</a> [<a href="/pdf/2401.16424" title="Download PDF">pdf</a>, <a href="/format/2401.16424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer Vision for Primate Behavior Analysis in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vogg%2C+R">Richard Vogg</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCddecke%2C+T">Timo L&#xfc;ddecke</a>, 
<a href="/search/cs?searchtype=author&query=Henrich%2C+J">Jonathan Henrich</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+S">Sharmita Dey</a>, 
<a href="/search/cs?searchtype=author&query=Nuske%2C+M">Matthias Nuske</a>, 
<a href="/search/cs?searchtype=author&query=Hassler%2C+V">Valentin Hassler</a>, 
<a href="/search/cs?searchtype=author&query=Murphy%2C+D">Derek Murphy</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+J">Julia Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Ostner%2C+J">Julia Ostner</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BClke%2C+O">Oliver Sch&#xfc;lke</a>, 
<a href="/search/cs?searchtype=author&query=Kappeler%2C+P+M">Peter M. Kappeler</a>, 
<a href="/search/cs?searchtype=author&query=Fichtel%2C+C">Claudia Fichtel</a>, 
<a href="/search/cs?searchtype=author&query=Gail%2C+A">Alexander Gail</a>, 
<a href="/search/cs?searchtype=author&query=Treue%2C+S">Stefan Treue</a>, 
<a href="/search/cs?searchtype=author&query=Scherberger%2C+H">Hansj&#xf6;rg Scherberger</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%B6rg%C3%B6tter%2C+F">Florentin W&#xf6;rg&#xf6;tter</a>, 
<a href="/search/cs?searchtype=author&query=Ecker%2C+A+S">Alexander S. Ecker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Advances in computer vision as well as increasingly widespread video-based
behavioral monitoring have great potential for transforming how we study animal
cognition and behavior. However, there is still a fairly large gap between the
exciting prospects and what can actually be achieved in practice today,
especially in videos from the wild. With this perspective paper, we want to
contribute towards closing this gap, by guiding behavioral scientists in what
can be expected from current methods and steering computer vision researchers
towards problems that are relevant to advance research in animal behavior. We
start with a survey of the state-of-the-art methods for computer vision
problems that are directly relevant to the video-based study of animal
behavior, including object detection, multi-individual tracking, (inter)action
recognition and individual identification. We then review methods for
effort-efficient learning, which is one of the biggest challenges from a
practical perspective. Finally, we close with an outlook into the future of the
emerging field of computer vision for animal behavior, where we argue that the
field should move fast beyond the common frame-by-frame processing and treat
video as a first-class citizen.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue, 30 Jan 24</h3>
<dl>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15092" title="Abstract">arXiv:2401.15092</a> (cross-list from math.PR) [<a href="/pdf/2401.15092" title="Download PDF">pdf</a>, <a href="/ps/2401.15092" title="Download PostScript">ps</a>, <a href="/format/2401.15092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on the capacity of the binary perceptron
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Altschuler%2C+D+J">Dylan J. Altschuler</a>, 
<a href="/search/math?searchtype=author&query=Tikhomirov%2C+K">Konstantin Tikhomirov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Determining the capacity $\alpha_c$ of the Binary Perceptron is a
long-standing problem. Krauth and Mezard (1989) conjectured an explicit value
of $\alpha_c$, approximately equal to .833, and a rigorous lower bound matching
this prediction was recently established by Ding and Sun (2019). Regarding the
upper bound, Kim and Roche (1998) and Talagrand (1999) independently showed
that $\alpha_c$ &lt; .996, while Krauth and Mezard outlined an argument which can
be used to show that $\alpha_c$ &lt; .847. The purpose of this expository note is
to record a complete proof of the bound $\alpha_c$ &lt; .847. The proof is a
conditional first moment method combined with known results on the spherical
perceptron
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15096" title="Abstract">arXiv:2401.15096</a> (cross-list from math.AP) [<a href="/pdf/2401.15096" title="Download PDF">pdf</a>, <a href="/ps/2401.15096" title="Download PostScript">ps</a>, <a href="/format/2401.15096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jet space extensions of infinite-dimensional Hamiltonian systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Preuster%2C+T">Till Preuster</a>, 
<a href="/search/math?searchtype=author&query=Schaller%2C+M">Manuel Schaller</a>, 
<a href="/search/math?searchtype=author&query=Maschke%2C+B">Bernhard Maschke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Systems and Control (eess.SY); Mathematical Physics (math-ph)

</div>
<p class="mathjax">We analyze infinite-dimensional Hamiltonian systems corresponding to partial
differential equations on one-dimensional spatial domains formulated with
formally skew-adjoint Hamiltonian operators and nonlinear Hamiltonian density.
In various applications, the Hamiltonian density can depend on spatial
derivatives of the state such that these systems can not straightforwardly be
formulated as boundary port-Hamiltonian system using a Stokes-Dirac structure.
In this work, we show that any Hamiltonian system of the above class can be
reformulated as a Hamiltonian system on the jet space, in which the Hamiltonian
density only depends on the extended state variable itself and not on its
derivatives. Consequently, well-known geometric formulations with Stokes- Dirac
structures are applicable. Additionally, we provide a similar result for
dissipative systems. We illustrate the developed theory by means of the the
Boussinesq equation, the dynamics of an elastic rod and the Allen-Cahn
equation.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15105" title="Abstract">arXiv:2401.15105</a> (cross-list from eess.IV) [<a href="/pdf/2401.15105" title="Download PDF">pdf</a>, <a href="/format/2401.15105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Enhancement for Cloud Removal in Ultra-Resolution Remote  Sensing Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sui%2C+J">Jialu Sui</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Y">Yiyang Ma</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+W">Wenhan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiaokang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Pun%2C+M">Man-On Pun</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jiaying Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The presence of cloud layers severely compromises the quality and
effectiveness of optical remote sensing (RS) images. However, existing
deep-learning (DL)-based Cloud Removal (CR) techniques encounter difficulties
in accurately reconstructing the original visual authenticity and detailed
semantic content of the images. To tackle this challenge, this work proposes to
encompass enhancements at the data and methodology fronts. On the data side, an
ultra-resolution benchmark named CUHK Cloud Removal (CUHK-CR) of 0.5m spatial
resolution is established. This benchmark incorporates rich detailed textures
and diverse cloud coverage, serving as a robust foundation for designing and
assessing CR models. From the methodology perspective, a novel diffusion-based
framework for CR called Diffusion Enhancement (DE) is proposed to perform
progressive texture detail recovery, which mitigates the training difficulty
with improved inference accuracy. Additionally, a Weight Allocation (WA)
network is developed to dynamically adjust the weights for feature fusion,
thereby further improving performance, particularly in the context of
ultra-resolution image generation. Furthermore, a coarse-to-fine training
strategy is applied to effectively expedite training convergence while reducing
the computational complexity required to handle ultra-resolution images.
Extensive experiments on the newly established CUHK-CR and existing datasets
such as RICE confirm that the proposed DE framework outperforms existing
DL-based methods in terms of both perceptual quality and signal fidelity.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15107" title="Abstract">arXiv:2401.15107</a> (cross-list from math.OC) [<a href="/pdf/2401.15107" title="Download PDF">pdf</a>, <a href="/format/2401.15107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Potential Shaping on SE(3) via Neural ODEs on Lie Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wotte%2C+Y+P">Yannik P. Wotte</a>, 
<a href="/search/math?searchtype=author&query=Califano%2C+F">Federico Califano</a>, 
<a href="/search/math?searchtype=author&query=Stramigioli%2C+S">Stefano Stramigioli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the International Journal of Robotics Research (IJRR). 20 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">This work presents a novel approach for the optimization of dynamic systems
on finite-dimensional Lie groups. We rephrase dynamic systems as so-called
neural ordinary differential equations (neural ODEs), and formulate the
optimization problem on Lie groups. A gradient descent optimization algorithm
is presented to tackle the optimization numerically. Our algorithm is scalable,
and applicable to any finite dimensional Lie group, including matrix Lie
groups. By representing the system at the Lie algebra level, we reduce the
computational cost of the gradient computation. In an extensive example,
optimal potential energy shaping for control of a rigid body is treated. The
optimal control problem is phrased as an optimization of a neural ODE on the
Lie group SE(3), and the controller is iteratively optimized. The final
controller is validated on a state-regulation task.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15111" title="Abstract">arXiv:2401.15111</a> (cross-list from eess.IV) [<a href="/pdf/2401.15111" title="Download PDF">pdf</a>, <a href="/format/2401.15111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Fairness of Automated Chest X-ray Diagnosis by Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+M">Mingquan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tianhao Li</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zhaoyi Sun</a>, 
<a href="/search/eess?searchtype=author&query=Holste%2C+G">Gregory Holste</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+Y">Ying Ding</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Shih%2C+G">George Shih</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Purpose: Limited studies exploring concrete methods or approaches to tackle
and enhance model fairness in the radiology domain. Our proposed AI model
utilizes supervised contrastive learning to minimize bias in CXR diagnosis.
<br />Materials and Methods: In this retrospective study, we evaluated our proposed
method on two datasets: the Medical Imaging and Data Resource Center (MIDRC)
dataset with 77,887 CXR images from 27,796 patients collected as of April 20,
2023 for COVID-19 diagnosis, and the NIH Chest X-ray (NIH-CXR) dataset with
112,120 CXR images from 30,805 patients collected between 1992 and 2015. In the
NIH-CXR dataset, thoracic abnormalities include atelectasis, cardiomegaly,
effusion, infiltration, mass, nodule, pneumonia, pneumothorax, consolidation,
edema, emphysema, fibrosis, pleural thickening, or hernia. Our proposed method
utilizes supervised contrastive learning with carefully selected positive and
negative samples to generate fair image embeddings, which are fine-tuned for
subsequent tasks to reduce bias in chest X-ray (CXR) diagnosis. We evaluated
the methods using the marginal AUC difference ($\delta$ mAUC).
<br />Results: The proposed model showed a significant decrease in bias across all
subgroups when compared to the baseline models, as evidenced by a paired T-test
(p&lt;0.0001). The $\delta$ mAUC obtained by our method were 0.0116 (95\% CI,
0.0110-0.0123), 0.2102 (95% CI, 0.2087-0.2118), and 0.1000 (95\% CI,
0.0988-0.1011) for sex, race, and age on MIDRC, and 0.0090 (95\% CI,
0.0082-0.0097) for sex and 0.0512 (95% CI, 0.0512-0.0532) for age on NIH-CXR,
respectively.
<br />Conclusion: Employing supervised contrastive learning can mitigate bias in
CXR diagnosis, addressing concerns of fairness and reliability in deep
learning-based diagnostic methods.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15130" title="Abstract">arXiv:2401.15130</a> (cross-list from math.CO) [<a href="/pdf/2401.15130" title="Download PDF">pdf</a>, <a href="/ps/2401.15130" title="Download PostScript">ps</a>, <a href="/format/2401.15130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dichromatic Number and Cycle Inversions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Charbit%2C+P">Pierre Charbit</a>, 
<a href="/search/math?searchtype=author&query=Thomass%C3%A9%2C+S">St&#xe9;phan Thomass&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The results of this note were stated in the first author PhD manuscript in
2006 but never published. The writing of a proof given there was slightly
careless and the proof itself scattered across the document, the goal of this
note is to give a short and clear proof using Farkas Lemma. The first result is
a characterization of the acyclic chromatic number of a digraph in terms of
cyclic ordering. Using this theorem we prove that for any digraph, one can
sequentially reverse the orientations of the arcs of a family of directed
cycles so that the resulting digraph has acyclic chromatic number at most 2.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15139" title="Abstract">arXiv:2401.15139</a> (cross-list from q-fin.PM) [<a href="/pdf/2401.15139" title="Download PDF">pdf</a>, <a href="/format/2401.15139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FDR-Controlled Portfolio Optimization for Sparse Financial Index  Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Machkour%2C+J">Jasin Machkour</a>, 
<a href="/search/q-fin?searchtype=author&query=Palomar%2C+D+P">Daniel P. Palomar</a>, 
<a href="/search/q-fin?searchtype=author&query=Muma%2C+M">Michael Muma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">In high-dimensional data analysis, such as financial index tracking or
biomedical applications, it is crucial to select the few relevant variables
while maintaining control over the false discovery rate (FDR). In these
applications, strong dependencies often exist among the variables (e.g., stock
returns), which can undermine the FDR control property of existing methods like
the model-X knockoff method or the T-Rex selector. To address this issue, we
have expanded the T-Rex framework to accommodate overlapping groups of highly
correlated variables. This is achieved by integrating a nearest neighbors
penalization mechanism into the framework, which provably controls the FDR at
the user-defined target level. A real-world example of sparse index tracking
demonstrates the proposed method's ability to accurately track the S&amp;P 500
index over the past 20 years based on a small number of stocks. An open-source
implementation is provided within the R package TRexSelector on CRAN.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15140" title="Abstract">arXiv:2401.15140</a> (cross-list from math.DS) [<a href="/pdf/2401.15140" title="Download PDF">pdf</a>, <a href="/format/2401.15140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Link Prediction Accuracy on Real-World Networks Under Non-Uniform  Missing Edge Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=He%2C+X">Xie He</a>, 
<a href="/search/math?searchtype=author&query=Ghasemian%2C+A">Amir Ghasemian</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+E">Eun Lee</a>, 
<a href="/search/math?searchtype=author&query=Schwarze%2C+A">Alice Schwarze</a>, 
<a href="/search/math?searchtype=author&query=Clauset%2C+A">Aaron Clauset</a>, 
<a href="/search/math?searchtype=author&query=Mucha%2C+P+J">Peter J. Mucha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transaction on Network Science and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Real-world network datasets are typically obtained in ways that fail to
capture all links, and there are many different non-uniform ways in which real
data might be missing. Nevertheless, uniform missing data is a common
assumption made when no additional information is available about the
underlying ''missingness function.'' To investigate the impact of different
missingness patterns on link prediction accuracy, we employ 9 link prediction
algorithms from 4 different families to analyze 20 different missingness
functions categorized into 5 groups. By studying 250 real-world network
datasets, we illustrate that different prediction algorithms exhibit
significant differences in accuracy contingent upon both the dataset domain and
the nature of the missingness pattern. Our study thereby provides guidance for
selecting appropriate prediction algorithms when encountering diverse patterns
of missing data across various domains, emphasizing the importance of
considering the specific characteristics of the dataset for effective link
prediction.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15185" title="Abstract">arXiv:2401.15185</a> (cross-list from math.OC) [<a href="/pdf/2401.15185" title="Download PDF">pdf</a>, <a href="/format/2401.15185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Theory of Control Architecture: A quantitative framework for  layered multi-rate control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Matni%2C+N">Nikolai Matni</a>, 
<a href="/search/math?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>, 
<a href="/search/math?searchtype=author&query=Doyle%2C+J+C">John C. Doyle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Control Systems Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper focuses on the need for a rigorous theory of layered control
architectures (LCAs) for complex engineered and natural systems, such as power
systems, communication networks, autonomous robotics, bacteria, and human
sensorimotor control. All deliver extraordinary capabilities, but they lack a
coherent theory of analysis and design, partly due to the diverse domains
across which LCAs can be found. In contrast, there is a core universal set of
control concepts and theory that applies very broadly and accommodates
necessary domain-specific specializations. However, control methods are
typically used only to design algorithms in components within a larger system
designed by others, typically with minimal or no theory. This points towards a
need for natural but large extensions of robust performance from control to the
full decision and control stack. It is encouraging that the successes of extant
architectures from bacteria to the Internet are due to strikingly universal
mechanisms and design patterns. This is largely due to convergent evolution by
natural selection and not intelligent design, particularly when compared with
the sophisticated design of components. Our aim here is to describe the
universals of architecture and sketch tentative paths towards a useful design
theory.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15216" title="Abstract">arXiv:2401.15216</a> (cross-list from eess.SP) [<a href="/pdf/2401.15216" title="Download PDF">pdf</a>, <a href="/format/2401.15216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Assisted Adaptive Beamforming in UASs Network: Enhancing  Airborne Communication via Collaborative UASs for NextG IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Arya%2C+S">Sudhanshu Arya</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Ying Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper introduces a novel quantum-based method for dynamic beamforming
and re-forming in Unmanned Aircraft Systems (UASs), specifically addressing the
critical challenges posed by the unavoidable hovering characteristics of UAVs.
Hovering creates significant beam path distortions, impacting the reliability
and quality of distributed beamforming in airborne networks. To overcome these
challenges, our Quantum Search for UAS Beamforming (QSUB) employs quantum
superposition, entanglement, and amplitude amplification. It adaptively
reconfigures beams, enhancing beam quality and maintaining robust communication
links in the face of rapid UAS state changes due to hovering. Furthermore, we
propose an optimized framework, Quantum-Position-Locked Loop (Q-P-LL), that is
based on the principle of the Nelder-Mead optimization method for adaptive
search to reduce prediction error and improve resilience against
angle-of-arrival estimation errors, crucial under dynamic hovering conditions.
We also demonstrate the scalability of the system performance and computation
complexity by comparing various numbers of active UASs. Importantly, QSUB and
Q-P-LL can be applied to both classical and quantum computing architectures.
Comparative analyses with conventional Maximum Ratio Transmission (MRT) schemes
demonstrate the superior performance and scalability of our quantum approaches,
marking significant advancements in the next-generation Internet of Things
(IoT) applications requiring reliable airborne communication networks.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15235" title="Abstract">arXiv:2401.15235</a> (cross-list from eess.IV) [<a href="/pdf/2401.15235" title="Download PDF">pdf</a>, <a href="/format/2401.15235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CascadedGaze: Efficiency in Global Context Extraction for Image  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghasemabadi%2C+A">Amirhosein Ghasemabadi</a>, 
<a href="/search/eess?searchtype=author&query=Salameh%2C+M">Mohammad Salameh</a>, 
<a href="/search/eess?searchtype=author&query=Janjua%2C+M+K">Muhammad Kamran Janjua</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+C">Chunhua Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+F">Fengyu Sun</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+D">Di Niu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages. ArXiV preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Image restoration tasks traditionally rely on convolutional neural networks.
However, given the local nature of the convolutional operator, they struggle to
capture global information. The promise of attention mechanisms in Transformers
is to circumvent this problem, but it comes at the cost of intensive
computational overhead. Many recent studies in image restoration have focused
on solving the challenge of balancing performance and computational cost via
Transformer variants. In this paper, we present CascadedGaze Network (CGNet),
an encoder-decoder architecture that employs Global Context Extractor (GCE), a
novel and efficient way to capture global information for image restoration.
The GCE module leverages small kernels across convolutional layers to learn
global dependencies, without requiring self-attention. Extensive experimental
results show that our approach outperforms a range of state-of-the-art methods
on denoising benchmark datasets including both real image denoising and
synthetic image denoising, as well as on image deblurring task, while being
more computationally efficient.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15254" title="Abstract">arXiv:2401.15254</a> (cross-list from stat.ML) [<a href="/pdf/2401.15254" title="Download PDF">pdf</a>, <a href="/format/2401.15254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite Sample Confidence Regions for Linear Regression Parameters Using  Arbitrary Predictors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Guille-Escuret%2C+C">Charles Guille-Escuret</a>, 
<a href="/search/stat?searchtype=author&query=Ndiaye%2C+E">Eugene Ndiaye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">We explore a novel methodology for constructing confidence regions for
parameters of linear models, using predictions from any arbitrary predictor.
Our framework requires minimal assumptions on the noise and can be extended to
functions deviating from strict linearity up to some adjustable threshold,
thereby accommodating a comprehensive and pragmatically relevant set of
functions. The derived confidence regions can be cast as constraints within a
Mixed Integer Linear Programming framework, enabling optimisation of linear
objectives. This representation enables robust optimization and the extraction
of confidence intervals for specific parameter coordinates. Unlike previous
methods, the confidence region can be empty, which can be used for hypothesis
testing. Finally, we validate the empirical applicability of our method on
synthetic data.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15262" title="Abstract">arXiv:2401.15262</a> (cross-list from math.ST) [<a href="/pdf/2401.15262" title="Download PDF">pdf</a>, <a href="/format/2401.15262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic Behavior of Adversarial Training Estimator under  $\ell_\infty$-Perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xie%2C+Y">Yiling Xie</a>, 
<a href="/search/math?searchtype=author&query=Huo%2C+X">Xiaoming Huo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Adversarial training has been proposed to hedge against adversarial attacks
in machine learning and statistical models. This paper focuses on adversarial
training under $\ell_\infty$-perturbation, which has recently attracted much
research attention. The asymptotic behavior of the adversarial training
estimator is investigated in the generalized linear model. The results imply
that the limiting distribution of the adversarial training estimator under
$\ell_\infty$-perturbation could put a positive probability mass at $0$ when
the true parameter is $0$, providing a theoretical guarantee of the associated
sparsity-recovery ability. Alternatively, a two-step procedure is proposed --
adaptive adversarial training, which could further improve the performance of
adversarial training under $\ell_\infty$-perturbation. Specifically, the
proposed procedure could achieve asymptotic unbiasedness and variable-selection
consistency. Numerical experiments are conducted to show the sparsity-recovery
ability of adversarial training under $\ell_\infty$-perturbation and to compare
the empirical performance between classic adversarial training and adaptive
adversarial training.
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15305" title="Abstract">arXiv:2401.15305</a> (cross-list from physics.ao-ph) [<a href="/pdf/2401.15305" title="Download PDF">pdf</a>, <a href="/format/2401.15305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Practical Probabilistic Benchmark for AI Weather Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Brenowitz%2C+N+D">Noah D. Brenowitz</a>, 
<a href="/search/physics?searchtype=author&query=Cohen%2C+Y">Yair Cohen</a>, 
<a href="/search/physics?searchtype=author&query=Pathak%2C+J">Jaideep Pathak</a>, 
<a href="/search/physics?searchtype=author&query=Mahesh%2C+A">Ankur Mahesh</a>, 
<a href="/search/physics?searchtype=author&query=Bonev%2C+B">Boris Bonev</a>, 
<a href="/search/physics?searchtype=author&query=Kurth%2C+T">Thorsten Kurth</a>, 
<a href="/search/physics?searchtype=author&query=Durran%2C+D+R">Dale R. Durran</a>, 
<a href="/search/physics?searchtype=author&query=Harrington%2C+P">Peter Harrington</a>, 
<a href="/search/physics?searchtype=author&query=Pritchard%2C+M+S">Michael S. Pritchard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Since the weather is chaotic, forecasts aim to predict the distribution of
future states rather than make a single prediction. Recently, multiple data
driven weather models have emerged claiming breakthroughs in skill. However,
these have mostly been benchmarked using deterministic skill scores, and little
is known about their probabilistic skill. Unfortunately, it is hard to fairly
compare AI weather models in a probabilistic sense, since variations in choice
of ensemble initialization, definition of state, and noise injection
methodology become confounding. Moreover, even obtaining ensemble forecast
baselines is a substantial engineering challenge given the data volumes
involved. We sidestep both problems by applying a decades-old idea -- lagged
ensembles -- whereby an ensemble can be constructed from a moderately-sized
library of deterministic forecasts. This allows the first parameter-free
intercomparison of leading AI weather models' probabilistic skill against an
operational baseline. The results reveal that two leading AI weather models,
i.e. GraphCast and Pangu, are tied on the probabilistic CRPS metric even though
the former outperforms the latter in deterministic scoring. We also reveal how
multiple time-step loss functions, which many data-driven weather models have
employed, are counter-productive: they improve deterministic metrics at the
cost of increased dissipation, deteriorating probabilistic skill. This is
confirmed through ablations applied to a spherical Fourier Neural Operator
(SFNO) approach to AI weather forecasting. Separate SFNO ablations modulating
effective resolution reveal it has a useful effect on ensemble dispersion
relevant to achieving good ensemble calibration. We hope these and forthcoming
insights from lagged ensembles can help guide the development of AI weather
forecasts and have thus shared the diagnostic code.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15307" title="Abstract">arXiv:2401.15307</a> (cross-list from eess.IV) [<a href="/pdf/2401.15307" title="Download PDF">pdf</a>, <a href="/format/2401.15307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParaTransCNN: Parallelized TransCNN Encoder for Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Hongkun Sun</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+Y">Yuping Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The convolutional neural network-based methods have become more and more
popular for medical image segmentation due to their outstanding performance.
However, they struggle with capturing long-range dependencies, which are
essential for accurately modeling global contextual correlations. Thanks to the
ability to model long-range dependencies by expanding the receptive field, the
transformer-based methods have gained prominence. Inspired by this, we propose
an advanced 2D feature extraction method by combining the convolutional neural
network and Transformer architectures. More specifically, we introduce a
parallelized encoder structure, where one branch uses ResNet to extract local
information from images, while the other branch uses Transformer to extract
global information. Furthermore, we integrate pyramid structures into the
Transformer to extract global information at varying resolutions, especially in
intensive prediction tasks. To efficiently utilize the different information in
the parallelized encoder at the decoder stage, we use a channel attention
module to merge the features of the encoder and propagate them through skip
connections and bottlenecks. Intensive numerical experiments are performed on
both aortic vessel tree, cardiac, and multi-organ datasets. By comparing with
state-of-the-art medical image segmentation methods, our method is shown with
better segmentation accuracy, especially on small organs. The code is publicly
available on https://github.com/HongkunSun/ParaTransCNN.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15354" title="Abstract">arXiv:2401.15354</a> (cross-list from eess.IV) [<a href="/pdf/2401.15354" title="Download PDF">pdf</a>, <a href="/format/2401.15354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepGI: An Automated Approach for Gastrointestinal Tract Segmentation in  MRI Scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Ye Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Gong%2C+Y">Yulu Gong</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+D">Dongji Cui</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xinrui Li</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+X">Xinyu Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Gastrointestinal (GI) tract cancers pose a global health challenge, demanding
precise radiotherapy planning for optimal treatment outcomes. This paper
introduces a cutting-edge approach to automate the segmentation of GI tract
regions in magnetic resonance imaging (MRI) scans. Leveraging advanced deep
learning architectures, the proposed model integrates Inception-V4 for initial
classification, UNet++ with a VGG19 encoder for 2.5D data, and Edge UNet for
grayscale data segmentation. Meticulous data preprocessing, including
innovative 2.5D processing, is employed to enhance adaptability, robustness,
and accuracy.
<br />This work addresses the manual and time-consuming segmentation process in
current radiotherapy planning, presenting a unified model that captures
intricate anatomical details. The integration of diverse architectures, each
specializing in unique aspects of the segmentation task, signifies a novel and
comprehensive solution. This model emerges as an efficient and accurate tool
for clinicians, marking a significant advancement in the field of GI tract
image segmentation for radiotherapy planning.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15394" title="Abstract">arXiv:2401.15394</a> (cross-list from math.CO) [<a href="/pdf/2401.15394" title="Download PDF">pdf</a>, <a href="/format/2401.15394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partitioning a Planar Graph into two Triangle-Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Knauer%2C+K">Kolja Knauer</a>, 
<a href="/search/math?searchtype=author&query=Ueckerdt%2C+T">Torsten Ueckerdt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We show that the vertices of every planar graph can be partitioned into two
sets, each inducing a so-called triangle-forest, i.e., a graph with no cycles
of length more than three.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15434" title="Abstract">arXiv:2401.15434</a> (cross-list from eess.IV) [<a href="/pdf/2401.15434" title="Download PDF">pdf</a>, <a href="/ps/2401.15434" title="Download PostScript">ps</a>, <a href="/format/2401.15434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Gossip Mutual Learning (GML) for brain tumor segmentation  on multi-parametric MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jingyun Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+Y">Yading Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 1 figure, accepted to IEEE EMBS 2023. arXiv admin note: text overlap with <a href="/abs/2401.06180">arXiv:2401.06180</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) enables collaborative model training among medical
centers without sharing private data. However, traditional FL risks on server
failures and suboptimal performance on local data due to the nature of
centralized model aggregation. To address these issues, we present Gossip
Mutual Learning (GML), a decentralized framework that uses Gossip Protocol for
direct peer-to-peer communication. In addition, GML encourages each site to
optimize its local model through mutual learning to account for data variations
among different sites. For the task of tumor segmentation using 146 cases from
four clinical sites in BraTS 2021 dataset, we demonstrated GML outperformed
local models and achieved similar performance as FedAvg with only 25%
communication overhead.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15456" title="Abstract">arXiv:2401.15456</a> (cross-list from math.CO) [<a href="/pdf/2401.15456" title="Download PDF">pdf</a>, <a href="/ps/2401.15456" title="Download PostScript">ps</a>, <a href="/format/2401.15456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Product Mixing in Compact Lie Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ellis%2C+D">David Ellis</a>, 
<a href="/search/math?searchtype=author&query=Kindler%2C+G">Guy Kindler</a>, 
<a href="/search/math?searchtype=author&query=Lifshitz%2C+N">Noam Lifshitz</a>, 
<a href="/search/math?searchtype=author&query=Minzer%2C+D">Dor Minzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Group Theory (math.GR); Probability (math.PR)

</div>
<p class="mathjax">If $G$ is a group, we say a subset $S$ of $G$ is product-free if the equation
$xy=z$ has no solutions with $x,y,z \in S$. For $D \in \mathbb{N}$, a group $G$
is said to be $D$-quasirandom if the minimal dimension of a nontrivial complex
irreducible representation of $G$ is at least $D$. Gowers showed that in a
$D$-quasirandom finite group $G$, the maximal size of a product-free set is at
most $|G|/D^{1/3}$. This disproved a longstanding conjecture of Babai and S\'os
from 1985.
<br />For the special unitary group, $G=SU(n)$, Gowers observed that his argument
yields an upper bound of $n^{-1/3}$ on the measure of a measurable product-free
subset. In this paper, we improve Gowers' upper bound to $\exp(-cn^{1/3})$,
where $c&gt;0$ is an absolute constant. In fact, we establish something stronger,
namely, product-mixing for measurable subsets of $SU(n)$ with measure at least
$\exp(-cn^{1/3})$; for this product-mixing result, the $n^{1/3}$ in the
exponent is sharp.
<br />Our approach involves introducing novel hypercontractive inequalities, which
imply that the non-Abelian Fourier spectrum of the indicator function of a
small set concentrates on high-dimensional irreducible representations.
<br />Our hypercontractive inequalities are obtained via methods from
representation theory, harmonic analysis, random matrix theory and differential
geometry. We generalize our hypercontractive inequalities from $SU(n)$ to an
arbitrary $D$-quasirandom compact connected Lie group for $D$ at least an
absolute constant, thereby extending our results on product-free sets to such
groups.
<br />We also demonstrate various other applications of our inequalities to
geometry (viz., non-Abelian Brunn-Minkowski type inequalities), mixing times,
and the theory of growth in compact Lie groups.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15462" title="Abstract">arXiv:2401.15462</a> (cross-list from math.PR) [<a href="/pdf/2401.15462" title="Download PDF">pdf</a>, <a href="/ps/2401.15462" title="Download PostScript">ps</a>, <a href="/format/2401.15462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the monotonicity of discrete entropy for log-concave random vectors  on $\mathbb{Z}^d$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fradelizi%2C+M">Matthieu Fradelizi</a>, 
<a href="/search/math?searchtype=author&query=Gavalakis%2C+L">Lampros Gavalakis</a>, 
<a href="/search/math?searchtype=author&query=Rapaport%2C+M">Martin Rapaport</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We prove the following type of discrete entropy monotonicity for isotropic
log-concave sums of independent identically distributed random vectors
$X_1,\dots,X_{n+1}$ on $\mathbb{Z}^d$: $$ H(X_1+\cdots+X_{n+1}) \geq
H(X_1+\cdots+X_{n}) + \frac{d}{2}\log{\Bigl(\frac{n+1}{n}\Bigr)} +o(1), $$
where $o(1)$ vanishes as $H(X_1) \to \infty$. Moreover, for the $o(1)$-term we
obtain a rate of convergence $ O\Bigl({H(X_1)}{e^{-\frac{1}{d}H(X_1)}}\Bigr)$,
where the implied constants depend on $d$ and $n$. This generalizes to
$\mathbb{Z}^d$ the one-dimensional result of the second named author (2023). As
in dimension one, our strategy is to establish that the discrete entropy
$H(X_1+\cdots+X_{n})$ is close to the differential (continuous) entropy
$h(X_1+U_1+\cdots+X_{n}+U_{n})$, where $U_1,\dots, U_n$ are independent and
identically distributed uniform random vectors on $[0,1]^d$ and to apply the
theorem of Artstein, Ball, Barthe and Naor (2004) on the monotonicity of
differential entropy. However, in dimension $d\ge2$, more involved tools from
convex geometry are needed because a suitable position is required. We show
that for a log-concave function on $\mathbb{R}^d$ in isotropic position, its
integral, its barycenter and its covariance matrix are close to their discrete
counterparts. One of our technical tools is a discrete analogue to the upper
bound on the isotropic constant of a log-concave function, which generalises a
result of Bobkov, Marsiglietti and Melbourne (2022) and may be of independent
interest.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15478" title="Abstract">arXiv:2401.15478</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.15478" title="Download PDF">pdf</a>, <a href="/format/2401.15478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Product Manifold Representations for Learning on Biological Pathways
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=McNeela%2C+D">Daniel McNeela</a>, 
<a href="/search/q-bio?searchtype=author&query=Sala%2C+F">Frederic Sala</a>, 
<a href="/search/q-bio?searchtype=author&query=Gitter%2C+A">Anthony Gitter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Molecular Networks (q-bio.MN)

</div>
<p class="mathjax">Machine learning models that embed graphs in non-Euclidean spaces have shown
substantial benefits in a variety of contexts, but their application has not
been studied extensively in the biological domain, particularly with respect to
biological pathway graphs. Such graphs exhibit a variety of complex network
structures, presenting challenges to existing embedding approaches. Learning
high-quality embeddings for biological pathway graphs is important for
researchers looking to understand the underpinnings of disease and train
high-quality predictive models on these networks. In this work, we investigate
the effects of embedding pathway graphs in non-Euclidean mixed-curvature spaces
and compare against traditional Euclidean graph representation learning models.
We then train a supervised model using the learned node embeddings to predict
missing protein-protein interactions in pathway graphs. We find large
reductions in distortion and boosts on in-distribution edge prediction
performance as a result of using mixed-curvature embeddings and their
corresponding graph neural network models. However, we find that
mixed-curvature representations underperform existing baselines on
out-of-distribution edge prediction performance suggesting that these
representations may overfit to the training graph topology. We provide our
mixed-curvature product GCN code at
https://github.com/mcneela/Mixed-Curvature-GCN and our pathway analysis code at
https://github.com/mcneela/Mixed-Curvature-Pathways.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15502" title="Abstract">arXiv:2401.15502</a> (cross-list from stat.ML) [<a href="/pdf/2401.15502" title="Download PDF">pdf</a>, <a href="/format/2401.15502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Bayesian Tests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chakraborty%2C+A">Abhisek Chakraborty</a>, 
<a href="/search/stat?searchtype=author&query=Datta%2C+S">Saptati Datta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Differential privacy has emerged as an significant cornerstone in the realm
of scientific hypothesis testing utilizing confidential data. In reporting
scientific discoveries, Bayesian tests are widely adopted since they
effectively circumnavigate the key criticisms of P-values, namely, lack of
interpretability and inability to quantify evidence in support of the competing
hypotheses. We present a novel differentially private Bayesian hypotheses
testing framework that arise naturally under a principled data generative
mechanism, inherently maintaining the interpretability of the resulting
inferences. Furthermore, by focusing on differentially private Bayes factors
based on widely used test statistics, we circumvent the need to model the
complete data generative mechanism and ensure substantial computational
benefits. We also provide a set of sufficient conditions to establish results
on Bayes factor consistency under the proposed framework. The utility of the
devised technology is showcased via several numerical experiments.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15504" title="Abstract">arXiv:2401.15504</a> (cross-list from math.GR) [<a href="/pdf/2401.15504" title="Download PDF">pdf</a>, <a href="/ps/2401.15504" title="Download PostScript">ps</a>, <a href="/format/2401.15504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Membership problems in nilpotent groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bodart%2C+C">Corentin Bodart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures. Comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We study both the Submonoid Membership problem and the Rational Subset
Membership problem in finitely generated nilpotent groups. We give two
reductions with important applications. First, Submonoid Membership in any
nilpotent group can be reduced to Rational Subset Membership in smaller groups.
As a corollary, we prove the existence of a group with decidable Submonoid
Membership and undecidable Rational Subset Membership, confirming a conjecture
of Lohrey and Steinberg. Second, the Rational Subset Membership problem in
$H_3(\mathbb Z)$ can be reduced to the Knapsack problem in the same group, and
is therefore decidable. Combining both results, we deduce that the filiform
$3$-step nilpotent group has decidable Submonoid Membership.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15513" title="Abstract">arXiv:2401.15513</a> (cross-list from eess.IV) [<a href="/pdf/2401.15513" title="Download PDF">pdf</a>, <a href="/format/2401.15513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiTU-Net: A fine-tuned U-Net with SegFormer backbone for segmenting  pubic symphysis-fetal head
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Fangyijie Wang</a>, 
<a href="/search/eess?searchtype=author&query=Silvestre%2C+G">Guenole Silvestre</a>, 
<a href="/search/eess?searchtype=author&query=Curran%2C+K">Kathleen Curran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 5th place in the Pubic Symphysis-Fetal Head Segmentation Challenge in MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Ultrasound measurements have been examined as potential tools for predicting
the likelihood of successful vaginal delivery. The angle of progression (AoP)
is a measurable parameter that can be obtained during the initial stage of
labor. The AoP is defined as the angle between a straight line along the
longitudinal axis of the pubic symphysis (PS) and a line from the inferior edge
of the PS to the leading edge of the fetal head (FH). However, the process of
measuring AoP on ultrasound images is time consuming and prone to errors. To
address this challenge, we propose the Mix Transformer U-Net (MiTU-Net)
network, for automatic fetal head-pubic symphysis segmentation and AoP
measurement. The MiTU-Net model is based on an encoder-decoder framework,
utilizing a pre-trained efficient transformer to enhance feature
representation. Within the efficient transformer encoder, the model
significantly reduces the trainable parameters of the encoder-decoder model.
The effectiveness of the proposed method is demonstrated through experiments
conducted on a recent transperineal ultrasound dataset. Our model achieves
competitive performance, ranking 5th compared to existing approaches. The
MiTU-Net presents an efficient method for automatic segmentation and AoP
measurement, reducing errors and assisting sonographers in clinical practice.
Reproducibility: Framework implementation and models available on
https://github.<a href="/abs/com/1320494">com/1320494</a>2/MiTU-Net.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15562" title="Abstract">arXiv:2401.15562</a> (cross-list from eess.SP) [<a href="/pdf/2401.15562" title="Download PDF">pdf</a>, <a href="/format/2401.15562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Integrated Sensing and Communication with Intelligent  Metasurfaces: Trends, Challenges, and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Magbool%2C+A">Ahmed Magbool</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+V">Vaibhav Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/eess?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/eess?searchtype=author&query=Flanagan%2C+M+F">Mark F. Flanagan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The emergence of various technologies demanding both high data rates and
precise sensing performance, such as autonomous vehicles and internet of things
devices, has propelled an increasing popularity of integrated sensing and
communication (ISAC) in recent years. ISAC offers an efficient framework for
communication and sensing where both functionalities are carried out in a
shared spectrum, utilizing the same hardware, beamformer and waveform design.
At the same time, intelligent metasurfaces have been identified as an
architectural enabler for the upcoming sixth-generation (6G) of wireless
communication due to their ability to control the propagation environment in an
energy-efficient manner. Due to the potential of metasurfaces to enhance both
communication and sensing performance, numerous papers have explored the
performance gains of using metasurfaces to improve ISAC. This survey reviews
the existing literature on metasurface-assisted ISAC, detailing the associated
challenges and opportunities. To provide a comprehensive overview, we commence
by offering relevant background information on standalone metasurface-assisted
communication and metasurface-assisted sensing systems, followed by a
discussion on the fundamentals of ISAC. The core part of the paper then
summarizes the state-of-the-art studies on metasurface-assisted ISAC with
metasurfaces employed as separate entities placed between the transmitter and
receiver, also known as reconfigurable intelligent surfaces, with an emphasis
on its two levels of integration: radio-communications co-existence and
dual-function radar-communications. We also review the current works in the
area of holographic ISAC where metasurfaces are used to form part of ISAC
transmitter. Within each category, the challenges, opportunities and future
research directions are also highlighted.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15566" title="Abstract">arXiv:2401.15566</a> (cross-list from stat.ML) [<a href="/pdf/2401.15566" title="Download PDF">pdf</a>, <a href="/format/2401.15566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Cross-Concentrated Sampling for Matrix Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cai%2C+H">HanQin Cai</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+L">Longxiu Huang</a>, 
<a href="/search/stat?searchtype=author&query=Kundu%2C+C">Chandra Kundu</a>, 
<a href="/search/stat?searchtype=author&query=Su%2C+B">Bowen Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 58th Annual Conference of Information Sciences and Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Matrix completion is one of the crucial tools in modern data science
research. Recently, a novel sampling model for matrix completion coined
cross-concentrated sampling (CCS) has caught much attention. However, the
robustness of the CCS model against sparse outliers remains unclear in the
existing studies. In this paper, we aim to answer this question by exploring a
novel Robust CCS Completion problem. A highly efficient non-convex iterative
algorithm, dubbed Robust CUR Completion (RCURC), is proposed. The empirical
performance of the proposed algorithm, in terms of both efficiency and
robustness, is verified in synthetic and real datasets.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15571" title="Abstract">arXiv:2401.15571</a> (cross-list from math.CO) [<a href="/pdf/2401.15571" title="Download PDF">pdf</a>, <a href="/ps/2401.15571" title="Download PostScript">ps</a>, <a href="/format/2401.15571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New results on sparse representations in unions of orthonormal bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/math?searchtype=author&query=Ge%2C+G">Gennian Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The problem of sparse representation has significant applications in signal
processing. The spark of a dictionary plays a crucial role in the study of
sparse representation. Donoho and Elad initially explored the spark, and they
provided a general lower bound. When the dictionary is a union of several
orthonormal bases, Gribonval and Nielsen presented an improved lower bound for
spark. In this paper, we introduce a new construction of dictionary, achieving
the spark bound given by Gribonval and Nielsen. Our result extends Shen et al.'
s findings [IEEE Trans. Inform. Theory, vol. 68, pp. 4230--4243, 2022].
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15598" title="Abstract">arXiv:2401.15598</a> (cross-list from eess.SP) [<a href="/pdf/2401.15598" title="Download PDF">pdf</a>, <a href="/format/2401.15598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Distributed Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Doostmohammadian%2C+M">Mohammadreza Doostmohammadian</a>, 
<a href="/search/eess?searchtype=author&query=Aghasi%2C+A">Alireza Aghasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conditionally accepted in IEEE SPL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">Distributed allocation finds applications in many scenarios including CPU
scheduling, distributed energy resource management, and networked coverage
control. In this paper, we propose a fast convergent optimization algorithm
with a tunable rate using the signum function. The convergence rate of the
proposed algorithm can be managed by changing two parameters. We prove
convergence over uniformly-connected multi-agent networks. Therefore, the
solution converges even if the network loses connectivity at some finite time
intervals. The proposed algorithm is all-time feasible, implying that at any
termination time of the algorithm, the resource-demand feasibility holds. This
is in contrast to asymptotic feasibility in many dual formulation solutions
(e.g., ADMM) that meet resource-demand feasibility over time and
asymptotically.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15613" title="Abstract">arXiv:2401.15613</a> (cross-list from eess.IV) [<a href="/pdf/2401.15613" title="Download PDF">pdf</a>, <a href="/format/2401.15613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Arbitrary-Scale Histopathology Image Super-resolution: An  Efficient Dual-branch Framework via Implicit Self-texture Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Duan%2C+M">Minghong Duan</a>, 
<a href="/search/eess?searchtype=author&query=Qu%2C+L">Linhao Qu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Zhiwei Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Manning Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chenxi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Z">Zhijian Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to JBHI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">High-quality whole-slide scanners are expensive, complex, and time-consuming,
thus limiting the acquisition and utilization of high-resolution pathology
whole-slide images in daily clinical work. Deep learning-based single-image
super-resolution techniques are an effective way to solve this problem by
synthesizing high-resolution images from low-resolution ones. However, the
existing super-resolution models applied in pathology images can only work in
fixed integer magnifications, significantly decreasing their applicability.
Though methods based on implicit neural representation have shown promising
results in arbitrary-scale super-resolution of natural images, applying them
directly to pathology images is inadequate because they have unique
fine-grained image textures different from natural images. Thus, we propose an
Implicit Self-Texture Enhancement-based dual-branch framework (ISTE) for
arbitrary-scale super-resolution of pathology images to address this challenge.
ISTE contains a pixel learning branch and a texture learning branch, which
first learn pixel features and texture features, respectively. Then, we design
a two-stage texture enhancement strategy to fuse the features from the two
branches to obtain the super-resolution results, where the first stage is
feature-based texture enhancement, and the second stage is spatial-domain-based
texture enhancement. Extensive experiments on three public datasets show that
ISTE outperforms existing fixed-scale and arbitrary-scale algorithms at
multiple magnifications and helps to improve downstream task performance. To
the best of our knowledge, this is the first work to achieve arbitrary-scale
super-resolution in pathology images. Codes will be available.
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15623" title="Abstract">arXiv:2401.15623</a> (cross-list from stat.ML) [<a href="/pdf/2401.15623" title="Download PDF">pdf</a>, <a href="/format/2401.15623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GT-PCA: Effective and Interpretable Dimensionality Reduction with  General Transform-Invariant Principal Component Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Heinrichs%2C+F">Florian Heinrichs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Data analysis often requires methods that are invariant with respect to
specific transformations, such as rotations in case of images or shifts in case
of images and time series. While principal component analysis (PCA) is a
widely-used dimension reduction technique, it lacks robustness with respect to
these transformations. Modern alternatives, such as autoencoders, can be
invariant with respect to specific transformations but are generally not
interpretable. We introduce General Transform-Invariant Principal Component
Analysis (GT-PCA) as an effective and interpretable alternative to PCA and
autoencoders. We propose a neural network that efficiently estimates the
components and show that GT-PCA significantly outperforms alternative methods
in experiments based on synthetic and real data.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15630" title="Abstract">arXiv:2401.15630</a> (cross-list from q-bio.NC) [<a href="/pdf/2401.15630" title="Download PDF">pdf</a>, <a href="/format/2401.15630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revising clustering and small-worldness in brain networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Fardet%2C+T">Tanguy Fardet</a>, 
<a href="/search/q-bio?searchtype=author&query=Giannakakis%2C+E">Emmanouil Giannakakis</a>, 
<a href="/search/q-bio?searchtype=author&query=Paulun%2C+L">Lukas Paulun</a>, 
<a href="/search/q-bio?searchtype=author&query=Levina%2C+A">Anna Levina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Social and Information Networks (cs.SI); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">As more connectome data become available, the question of how to best analyse
the structure of biological neural networks becomes increasingly pertinent. In
brain networks, knowing that two areas are connected is often not sufficient,
as the directionality and weight of the connection affect the dynamics in
crucial ways. Still, the methods commonly used to estimate network properties,
such as clustering and small-worldness, usually disregard features encoded in
the directionality and strength of network connections. To address this issue,
we propose using fully-weighted and directed clustering measures that provide
higher sensitivity to non-random structural features. Using artificial
networks, we demonstrate the problems with methods routinely used in the field
and how fully-weighted and directed methods can alleviate them. Specifically,
we highlight their robustness to noise and their ability to address
thresholding issues, particularly in inferred networks. We further apply our
method to the connectomes of different species and uncover regularities and
correlations between neuronal structures and functions that cannot be detected
with traditional clustering metrics. Finally, we extend the notion of
small-worldness in brain networks to account for weights and directionality and
show that some connectomes can no longer be considered ``small-world''.
Overall, our study makes a case for a combined use of fully-weighted and
directed measures to deal with the variability of brain networks and suggests
the presence of complex patterns in neural connectivity that can only be
revealed using such methods.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15632" title="Abstract">arXiv:2401.15632</a> (cross-list from astro-ph.HE) [<a href="/pdf/2401.15632" title="Download PDF">pdf</a>, <a href="/format/2401.15632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Gamma-Ray Bursts: A data driven event framework for  X/Gamma-Ray analysis in space telescopes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Crupi%2C+R">Riccardo Crupi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Astrophysical Phenomena (astro-ph.HE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This thesis comprises the first three chapters dedicated to providing an
overview of Gamma Ray-Bursts (GRBs), their properties, the instrumentation used
to detect them, and Artificial Intelligence (AI) applications in the context of
GRBs, including a literature review and future prospects. Considering both the
current and the next generation of high X-ray monitors, such as Fermi-GBM and
HERMES Pathfinder (an in-orbit demonstration of six 3U nano-satellites), the
research question revolves around the detection of long and faint high-energy
transients, potentially GRBs, that might have been missed by previous detection
algorithms. To address this, two chapters introduce a new data-driven
framework, DeepGRB.
<br />In Chapter 4, a Neural Network (NN) is described for background count rate
estimation for X/gamma-ray detectors, providing a performance evaluation in
different periods, including both solar maxima, solar minima periods, and one
containing an ultra-long GRB. The application of eXplainable Artificial
Intelligence (XAI) is performed for global and local feature importance
analysis to better understand the behavior of the NN.
<br />Chapter 5 employs FOCuS-Poisson for anomaly detection in count rate
observations and estimation from the NN. DeepGRB demonstrates its capability to
process Fermi-GBM data, confirming cataloged events and identifying new ones,
providing further analysis with estimates for localization, duration, and
classification. The chapter concludes with an automated classification method
using Machine Learning techniques that incorporates XAI for eventual bias
identification.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15645" title="Abstract">arXiv:2401.15645</a> (cross-list from stat.CO) [<a href="/pdf/2401.15645" title="Download PDF">pdf</a>, <a href="/format/2401.15645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble-Based Annealed Importance Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+H">Haoxuan Chen</a>, 
<a href="/search/stat?searchtype=author&query=Ying%2C+L">Lexing Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)

</div>
<p class="mathjax">Sampling from a multimodal distribution is a fundamental and challenging
problem in computational science and statistics. Among various approaches
proposed for this task, one popular method is Annealed Importance Sampling
(AIS). In this paper, we propose an ensemble-based version of AIS by combining
it with population-based Monte Carlo methods to improve its efficiency. By
keeping track of an ensemble instead of a single particle along some
continuation path between the starting distribution and the target
distribution, we take advantage of the interaction within the ensemble to
encourage the exploration of undiscovered modes. Specifically, our main idea is
to utilize either the snooker algorithm or the genetic algorithm used in
Evolutionary Monte Carlo. We discuss how the proposed algorithm can be
implemented and derive a partial differential equation governing the evolution
of the ensemble under the continuous time and mean-field limit. We also test
the efficiency of the proposed algorithm on various continuous and discrete
distributions.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15663" title="Abstract">arXiv:2401.15663</a> (cross-list from eess.IV) [<a href="/pdf/2401.15663" title="Download PDF">pdf</a>, <a href="/format/2401.15663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-resolution Prior Equilibrium Network for CT Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yijie Yang</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+Q">Qifeng Gao</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+Y">Yuping Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The unrolling method has been investigated for learning variational models in
X-ray computed tomography. However, it has been observed that directly
unrolling the regularization model through gradient descent does not produce
satisfactory results. In this paper, we present a novel deep learning-based CT
reconstruction model, where the low-resolution image is introduced to obtain an
effective regularization term for improving the network`s robustness. Our
approach involves constructing the backbone network architecture by algorithm
unrolling that is realized using the deep equilibrium architecture. We
theoretically discuss the convergence of the proposed low-resolution prior
equilibrium model and provide the conditions to guarantee convergence.
Experimental results on both sparse-view and limited-angle reconstruction
problems are provided, demonstrating that our end-to-end low-resolution prior
equilibrium model outperforms other state-of-the-art methods in terms of noise
reduction, contrast-to-noise ratio, and preservation of edge details.
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15676" title="Abstract">arXiv:2401.15676</a> (cross-list from eess.AS) [<a href="/pdf/2401.15676" title="Download PDF">pdf</a>, <a href="/format/2401.15676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Speaker Attribution with SURT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Raj%2C+D">Desh Raj</a>, 
<a href="/search/eess?searchtype=author&query=Wiesner%2C+M">Matthew Wiesner</a>, 
<a href="/search/eess?searchtype=author&query=Maciejewski%2C+M">Matthew Maciejewski</a>, 
<a href="/search/eess?searchtype=author&query=Garcia-Perera%2C+L+P">Leibny Paola Garcia-Perera</a>, 
<a href="/search/eess?searchtype=author&query=Povey%2C+D">Daniel Povey</a>, 
<a href="/search/eess?searchtype=author&query=Khudanpur%2C+S">Sanjeev Khudanpur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 6 tables. Submitted to Odyssey 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The Streaming Unmixing and Recognition Transducer (SURT) has recently become
a popular framework for continuous, streaming, multi-talker speech recognition
(ASR). With advances in architecture, objectives, and mixture simulation
methods, it was demonstrated that SURT can be an efficient streaming method for
speaker-agnostic transcription of real meetings. In this work, we push this
framework further by proposing methods to perform speaker-attributed
transcription with SURT, for both short mixtures and long recordings. We
achieve this by adding an auxiliary speaker branch to SURT, and synchronizing
its label prediction with ASR token prediction through HAT-style blank
factorization. In order to ensure consistency in relative speaker labels across
different utterance groups in a recording, we propose "speaker prefixing" --
appending each chunk with high-confidence frames of speakers identified in
previous chunks, to establish the relative order. We perform extensive ablation
experiments on synthetic LibriSpeech mixtures to validate our design choices,
and demonstrate the efficacy of our final model on the AMI corpus.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15692" title="Abstract">arXiv:2401.15692</a> (cross-list from math.CO) [<a href="/pdf/2401.15692" title="Download PDF">pdf</a>, <a href="/format/2401.15692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalisations of Euler&#x27;s Tonnetz on triangulated surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rietsch%2C+K">Konstanze Rietsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 1 table, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Sound (cs.SD); Representation Theory (math.RT)

</div>
<p class="mathjax">We give a definition of a what we call a `tonnetz' on a triangulated surface,
generalising the famous tonnetz of Euler from 1739. In Euler's tonnetz the
vertices of a regular `$A_2$ triangulation' of the plane are labelled with
notes, or pitch-classes. In our generalisation we allow much more general
labellings of triangulated surfaces. In particular, edge labellings turn out to
lead to a rich set of examples. We construct natural examples that are related
to crystallographic reflection groups and live on triangulations of tori.
Underlying these we observe a curious relationship between mathematical
Langlands duality and major/minor duality. We also construct `exotic'
type-$A_2$ examples (different from Euler's Tonnetz), and a tonnetz on a sphere
that encodes all major ninth chords.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15719" title="Abstract">arXiv:2401.15719</a> (cross-list from math.PR) [<a href="/pdf/2401.15719" title="Download PDF">pdf</a>, <a href="/ps/2401.15719" title="Download PostScript">ps</a>, <a href="/format/2401.15719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rates of Convergence in the Central Limit Theorem for Markov Chains,  with an Application to TD Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Srikant%2C+R">R. Srikant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">We prove a non-asymptotic central limit theorem for vector-valued martingale
differences using Stein's method, and use Poisson's equation to extend the
result to functions of Markov Chains. We then show that these results can be
applied to establish a non-asymptotic central limit theorem for Temporal
Difference (TD) learning with averaging.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15743" title="Abstract">arXiv:2401.15743</a> (cross-list from eess.SP) [<a href="/pdf/2401.15743" title="Download PDF">pdf</a>, <a href="/format/2401.15743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time EEG-based Emotion Recognition Model using Principal Component  Analysis and Tree-based Models for Neurohumanities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Blanco-Rios%2C+M+A">Miguel A. Blanco-Rios</a>, 
<a href="/search/eess?searchtype=author&query=Candela-Leal%2C+M+O">Milton O. Candela-Leal</a>, 
<a href="/search/eess?searchtype=author&query=Orozco-Romo%2C+C">Cecilia Orozco-Romo</a>, 
<a href="/search/eess?searchtype=author&query=Remis-Serna%2C+P">Paulina Remis-Serna</a>, 
<a href="/search/eess?searchtype=author&query=Velez-Saboya%2C+C+S">Carol S. Velez-Saboya</a>, 
<a href="/search/eess?searchtype=author&query=Lozoya-Santos%2C+J+D">Jorge De-J. Lozoya-Santos</a>, 
<a href="/search/eess?searchtype=author&query=Cebral-Loureda%2C+M">Manuel Cebral-Loureda</a>, 
<a href="/search/eess?searchtype=author&query=Ramirez-Moreno%2C+M+A">Mauricio A. Ramirez-Moreno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures. Submitted to Frontiers in Human Neuroscience
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Within the field of Humanities, there is a recognized need for educational
innovation, as there are currently no reported tools available that enable
individuals to interact with their environment to create an enhanced learning
experience in the humanities (e.g., immersive spaces). This project proposes a
solution to address this gap by integrating technology and promoting the
development of teaching methodologies in the humanities, specifically by
incorporating emotional monitoring during the learning process of humanistic
context inside an immersive space. In order to achieve this goal, a real-time
emotion detection EEG-based system was developed to interpret and classify
specific emotions. These emotions aligned with the early proposal by Descartes
(Passions), including admiration, love, hate, desire, joy, and sadness. This
system aims to integrate emotional data into the Neurohumanities Lab
interactive platform, creating a comprehensive and immersive learning
environment. This work developed a ML, real-time emotion detection model that
provided Valence, Arousal, and Dominance (VAD) estimations every 5 seconds.
Using PCA, PSD, RF, and Extra-Trees, the best 8 channels and their respective
best band powers were extracted; furthermore, multiple models were evaluated
using shift-based data division and cross-validations. After assessing their
performance, Extra-Trees achieved a general accuracy of 96%, higher than the
reported in the literature (88% accuracy). The proposed model provided
real-time predictions of VAD variables and was adapted to classify Descartes'
six main passions. However, with the VAD values obtained, more than 15 emotions
can be classified (reported in the VAD emotion mapping) and extend the range of
this application.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15745" title="Abstract">arXiv:2401.15745</a> (cross-list from math.OC) [<a href="/pdf/2401.15745" title="Download PDF">pdf</a>, <a href="/format/2401.15745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The computation of approximate feedback Stackelberg equilibria in  multi-player nonlinear constrained dynamic games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jingqi Li</a>, 
<a href="/search/math?searchtype=author&query=Sojoudi%2C+S">Somayeh Sojoudi</a>, 
<a href="/search/math?searchtype=author&query=Tomlin%2C+C">Claire Tomlin</a>, 
<a href="/search/math?searchtype=author&query=Fridovich-Keil%2C+D">David Fridovich-Keil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Solving feedback Stackelberg games with nonlinear dynamics and coupled
constraints, a common scenario in practice, presents significant challenges.
This work introduces an efficient method for computing local feedback
Stackelberg policies in multi-player general-sum dynamic games, with continuous
state and action spaces. Different from existing (approximate) dynamic
programming solutions that are primarily designed for unconstrained problems,
our approach involves reformulating a feedback Stackelberg dynamic game into a
sequence of nested optimization problems, enabling the derivation of
Karush-Kuhn-Tucker (KKT) conditions and the establishment of a second-order
sufficient condition for local feedback Stackelberg policies. We propose a
Newton-style primal-dual interior point method for solving constrained linear
quadratic (LQ) feedback Stackelberg games, offering provable convergence
guarantees. Our method is further extended to compute local feedback
Stackelberg policies for more general nonlinear games by iteratively
approximating them using LQ games, ensuring that their KKT conditions are
locally aligned with those of the original nonlinear games. We prove the
exponential convergence of our algorithm in constrained nonlinear games. In a
feedback Stackelberg game with nonlinear dynamics and (nonconvex) coupled costs
and constraints, our experimental results reveal the algorithm's ability to
handle infeasible initial conditions and achieve exponential convergence
towards an approximate local feedback Stackelberg equilibrium.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15771" title="Abstract">arXiv:2401.15771</a> (cross-list from stat.ML) [<a href="/pdf/2401.15771" title="Download PDF">pdf</a>, <a href="/format/2401.15771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Nonparametrics meets Data-Driven Robust Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bariletto%2C+N">Nicola Bariletto</a> (1), 
<a href="/search/stat?searchtype=author&query=Ho%2C+N">Nhat Ho</a> (1) ((1) The University of Texas at Austin)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Training machine learning and statistical models often involves optimizing a
data-driven risk criterion. The risk is usually computed with respect to the
empirical data distribution, but this may result in poor and unstable
out-of-sample performance due to distributional uncertainty. In the spirit of
distributionally robust optimization, we propose a novel robust criterion by
combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory
and recent decision-theoretic models of smooth ambiguity-averse preferences.
First, we highlight novel connections with standard regularized empirical risk
minimization techniques, among which Ridge and LASSO regressions. Then, we
theoretically demonstrate the existence of favorable finite-sample and
asymptotic statistical guarantees on the performance of the robust optimization
procedure. For practical implementation, we propose and study tractable
approximations of the criterion based on well-known Dirichlet Process
representations. We also show that the smoothness of the criterion naturally
leads to standard gradient-based numerical optimization. Finally, we provide
insights into the workings of our method by applying it to high-dimensional
sparse linear regression and robust location parameter estimation tasks.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15772" title="Abstract">arXiv:2401.15772</a> (cross-list from math.OC) [<a href="/pdf/2401.15772" title="Download PDF">pdf</a>, <a href="/format/2401.15772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effects of Transmission-Rights Pricing on Multi-Stage Electricity  Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=de+Belloy+de+Saint-Lienard%2C+E">Erwann de Belloy de Saint-Lienard</a>, 
<a href="/search/math?searchtype=author&query=Marecek%2C+J">Jakub Marecek</a>, 
<a href="/search/math?searchtype=author&query=Kungurtsev%2C+V">Vyacheslav Kungurtsev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Cross-border transmission infrastructure is pivotal in balancing modern power
systems, but requires fair allocation of cross-border transmission capacity,
possibly via fair pricing thereof. This requirement can be implemented using
multi-stage market mechanisms for Physical Transmission Rights (PTRs). We
analyse the related dynamics, and show prisoner's dilemma arises. Understanding
these dynamics enables the development of novel market-settlement mechanisms to
enhance market efficiency and incentivize renewable energy use.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15791" title="Abstract">arXiv:2401.15791</a> (cross-list from stat.ML) [<a href="/pdf/2401.15791" title="Download PDF">pdf</a>, <a href="/format/2401.15791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Kernel-Based Nonasymptotic Simultaneous Confidence Bands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cs%C3%A1ji%2C+B+C">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>, 
<a href="/search/stat?searchtype=author&query=Horv%C3%A1th%2C+B">B&#xe1;lint Horv&#xe1;th</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 22nd IFAC World Congress, Yokohama, Japan, 2023, 10357-10362
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">The paper studies the problem of constructing nonparametric simultaneous
confidence bands with nonasymptotic and distribition-free guarantees. The
target function is assumed to be band-limited and the approach is based on the
theory of Paley-Wiener reproducing kernel Hilbert spaces. The starting point of
the paper is a recently developed algorithm to which we propose three types of
improvements. First, we relax the assumptions on the noises by replacing the
symmetricity assumption with a weaker distributional invariance principle.
Then, we propose a more efficient way to estimate the norm of the target
function, and finally we enhance the construction of the confidence bands by
tightening the constraints of the underlying convex optimization problems. The
refinements are also illustrated through numerical experiments.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15792" title="Abstract">arXiv:2401.15792</a> (cross-list from stat.ML) [<a href="/pdf/2401.15792" title="Download PDF">pdf</a>, <a href="/format/2401.15792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Complexity of the Sign-Perturbed Sums Identification Method:  Scalar Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Szentp%C3%A9teri%2C+S">Szabolcs Szentp&#xe9;teri</a>, 
<a href="/search/stat?searchtype=author&query=Cs%C3%A1ji%2C+B+C">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 22nd IFAC World Congress, Yokohama, Japan, 2023, 10363-10370
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Statistics Theory (math.ST)

</div>
<p class="mathjax">Sign-Perturbed Sum (SPS) is a powerful finite-sample system identification
algorithm which can construct confidence regions for the true data generating
system with exact coverage probabilities, for any finite sample size. SPS was
developed in a series of papers and it has a wide range of applications, from
general linear systems, even in a closed-loop setup, to nonlinear and
nonparametric approaches. Although several theoretical properties of SPS were
proven in the literature, the sample complexity of the method was not analysed
so far. This paper aims to fill this gap and provides the first results on the
sample complexity of SPS. Here, we focus on scalar linear regression problems,
that is we study the behaviour of SPS confidence intervals. We provide high
probability upper bounds, under three different sets of assumptions, showing
that the sizes of SPS confidence intervals shrink at a geometric rate around
the true parameter, if the observation noises are subgaussian. We also show
that similar bounds hold for the previously proposed outer approximation of the
confidence region. Finally, we present simulation experiments comparing the
theoretical and the empirical convergence rates.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15800" title="Abstract">arXiv:2401.15800</a> (cross-list from stat.ML) [<a href="/pdf/2401.15800" title="Download PDF">pdf</a>, <a href="/format/2401.15800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Stable Feature Rankings with SHAP and LIME
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Goldwasser%2C+J">Jeremy Goldwasser</a>, 
<a href="/search/stat?searchtype=author&query=Hooker%2C+G">Giles Hooker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Feature attributions are ubiquitous tools for understanding the predictions
of machine learning models. However, popular methods for scoring input
variables such as SHAP and LIME suffer from high instability due to random
sampling. Leveraging ideas from multiple hypothesis testing, we devise
attribution methods that correctly rank the most important features with high
probability. Our algorithm RankSHAP guarantees that the $K$ highest Shapley
values have the proper ordering with probability exceeding $1-\alpha$.
Empirical results demonstrate its validity and impressive computational
efficiency. We also build on previous work to yield similar results for LIME,
ensuring the most important features are selected in the right order.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15801" title="Abstract">arXiv:2401.15801</a> (cross-list from stat.ML) [<a href="/pdf/2401.15801" title="Download PDF">pdf</a>, <a href="/ps/2401.15801" title="Download PostScript">ps</a>, <a href="/format/2401.15801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Statistical Properties of Generative Adversarial Models for Low  Intrinsic Data Dimension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chakraborty%2C+S">Saptarshi Chakraborty</a>, 
<a href="/search/stat?searchtype=author&query=Bartlett%2C+P+L">Peter L. Bartlett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">Despite the remarkable empirical successes of Generative Adversarial Networks
(GANs), the theoretical guarantees for their statistical accuracy remain rather
pessimistic. In particular, the data distributions on which GANs are applied,
such as natural images, are often hypothesized to have an intrinsic
low-dimensional structure in a typically high-dimensional feature space, but
this is often not reflected in the derived rates in the state-of-the-art
analyses. In this paper, we attempt to bridge the gap between the theory and
practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs),
by deriving statistical guarantees on the estimated densities in terms of the
intrinsic dimension of the data and the latent space. We analytically show that
if one has access to $n$ samples from the unknown target distribution and the
network architectures are properly chosen, the expected Wasserstein-1 distance
of the estimates from the target scales as $O\left( n^{-1/d_\mu } \right)$ for
GANs and $O\left( n^{-1/(d_\mu+\ell)} \right)$ for BiGANs, where $d_\mu$ and
$\ell$ are the upper Wasserstein-1 dimension of the data-distribution and
latent-space dimension, respectively. The theoretical analyses not only suggest
that these methods successfully avoid the curse of dimensionality, in the sense
that the exponent of $n$ in the error rates does not depend on the data
dimension but also serve to bridge the gap between the theoretical analyses of
GANs and the known sharp rates from optimal transport literature. Additionally,
we demonstrate that GANs can effectively achieve the minimax optimal rate even
for non-smooth underlying distributions, with the use of larger generator
networks.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15811" title="Abstract">arXiv:2401.15811</a> (cross-list from stat.ME) [<a href="/pdf/2401.15811" title="Download PDF">pdf</a>, <a href="/format/2401.15811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seller-Side Experiments under Interference Induced by Feedback Loops in  Two-Sided Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhu%2C+Z">Zhihua Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Cai%2C+Z">Zheng Cai</a>, 
<a href="/search/stat?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>, 
<a href="/search/stat?searchtype=author&query=Si%2C+N">Nian Si</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Two-sided platforms are central to modern commerce and content sharing and
often utilize A/B testing for developing new features. While user-side
experiments are common, seller-side experiments become crucial for specific
interventions and metrics. This paper investigates the effects of interference
caused by feedback loops on seller-side experiments in two-sided platforms,
with a particular focus on the counterfactual interleaving design, proposed in
\citet{ha2020counterfactual,nandy2021b}. These feedback loops, often generated
by pacing algorithms, cause outcomes from earlier sessions to influence
subsequent ones. This paper contributes by creating a mathematical framework to
analyze this interference, theoretically estimating its impact, and conducting
empirical evaluations of the counterfactual interleaving design in real-world
scenarios. Our research shows that feedback loops can result in misleading
conclusions about the treatment effects.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15815" title="Abstract">arXiv:2401.15815</a> (cross-list from eess.SP) [<a href="/pdf/2401.15815" title="Download PDF">pdf</a>, <a href="/ps/2401.15815" title="Download PostScript">ps</a>, <a href="/format/2401.15815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Success probability of the $L_0$-regularized box-constrained Babai point  and column permutation strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chang%2C+X">Xiao-Wen Chang</a>, 
<a href="/search/eess?searchtype=author&query=XU%2C+Y">Yingzi XU</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 1 figure including 2 subfigures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computational Engineering, Finance, and Science (cs.CE); Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider the success probability of the $L_0$-regularized box-constrained
Babai point, which is a suboptimal solution to the $L_0$-regularized
box-constrained integer least squares problem and can be used for MIMO
detection. First, we derive formulas for the success probability of both
$L_0$-regularized and unregularized box-constrained Babai points. Then we
investigate the properties of the $L_0$-regularized box-constrained Babai
point, including the optimality of the regularization parameter, the
monotonicity of its success probability, and the monotonicity of the ratio of
the two success probabilities. A bound on the success probability of the
$L_0$-regularized Babai point is derived. After that, we analyze the effect of
the LLL-P permutation strategy on the success probability of the
$L_0$-regularized Babai point. Then we propose some success probability based
column permutation strategies to increase the success probability of the
$L_0$-regularized box-constrained Babai point. Finally, we present numerical
tests to confirm our theoretical results and to show the advantage of the $L_0$
regularization and the effectiveness of the proposed column permutation
algorithms compared to existing strategies.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15826" title="Abstract">arXiv:2401.15826</a> (cross-list from math.OC) [<a href="/pdf/2401.15826" title="Download PDF">pdf</a>, <a href="/format/2401.15826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Robust Data-driven Predictive Control for Smoothing Mixed  Traffic Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shang%2C+X">Xu Shang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+J">Jiawei Wang</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In a mixed traffic with connected automated vehicles (CAVs) and human-driven
vehicles (HDVs) coexisting, data-driven predictive control of CAVs promises
system-wide traffic performance improvements. Yet, most existing approaches
focus on a centralized setup, which is not computationally scalable while
failing to protect data privacy. The robustness against unknown disturbances
has not been well addressed either, causing safety concerns. In this paper, we
propose a decentralized robust DeeP-LCC (Data-EnablEd Predictive Leading Cruise
Control) approach for CAVs to smooth mixed traffic flow. In particular, each
CAV computes its control input based on locally available data from its
involved subsystem. Meanwhile, the interaction between neighboring subsystems
is modeled as a bounded disturbance, for which appropriate estimation methods
are proposed. Then, we formulate a robust optimization problem and present its
tractable computational solutions. Compared with the centralized formulation,
our method greatly reduces computation burden with better safety performance,
while naturally preserving data privacy. Extensive traffic simulations validate
its wave-dampening ability, safety performance, and computational benefits.
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15838" title="Abstract">arXiv:2401.15838</a> (cross-list from stat.ML) [<a href="/pdf/2401.15838" title="Download PDF">pdf</a>, <a href="/format/2401.15838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Markov Chain Monte Carlo Sampling based on the Alternating  Direction Method of Multipliers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tzikas%2C+A+E">Alexandros E. Tzikas</a>, 
<a href="/search/stat?searchtype=author&query=Romao%2C+L">Licio Romao</a>, 
<a href="/search/stat?searchtype=author&query=Pilanci%2C+M">Mert Pilanci</a>, 
<a href="/search/stat?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>, 
<a href="/search/stat?searchtype=author&query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Optimization and Control (math.OC); Computation (stat.CO)

</div>
<p class="mathjax">Many machine learning applications require operating on a spatially
distributed dataset. Despite technological advances, privacy considerations and
communication constraints may prevent gathering the entire dataset in a central
unit. In this paper, we propose a distributed sampling scheme based on the
alternating direction method of multipliers, which is commonly used in the
optimization literature due to its fast convergence. In contrast to distributed
optimization, distributed sampling allows for uncertainty quantification in
Bayesian inference tasks. We provide both theoretical guarantees of our
algorithm's convergence and experimental evidence of its superiority to the
state-of-the-art. For our theoretical results, we use convex optimization tools
to establish a fundamental inequality on the generated local sample iterates.
This inequality enables us to show convergence of the distribution associated
with these iterates to the underlying target distribution in Wasserstein
distance. In simulation, we deploy our algorithm on linear and logistic
regression tasks and illustrate its fast convergence compared to existing
gradient-based methods.
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15889" title="Abstract">arXiv:2401.15889</a> (cross-list from stat.ML) [<a href="/pdf/2401.15889" title="Download PDF">pdf</a>, <a href="/format/2401.15889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sliced Wasserstein with Random-Path Projecting Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+K">Khai Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+S">Shujian Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Le%2C+T">Tam Le</a>, 
<a href="/search/stat?searchtype=author&query=Ho%2C+N">Nhat Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Slicing distribution selection has been used as an effective technique to
improve the performance of parameter estimators based on minimizing sliced
Wasserstein distance in applications. Previous works either utilize expensive
optimization to select the slicing distribution or use slicing distributions
that require expensive sampling methods. In this work, we propose an
optimization-free slicing distribution that provides a fast sampling for the
Monte Carlo estimation of expectation. In particular, we introduce the
random-path projecting direction (RPD) which is constructed by leveraging the
normalized difference between two random vectors following the two input
measures. From the RPD, we derive the random-path slicing distribution (RPSD)
and two variants of sliced Wasserstein, i.e., the Random-Path Projection Sliced
Wasserstein (RPSW) and the Importance Weighted Random-Path Projection Sliced
Wasserstein (IWRPSW). We then discuss the topological, statistical, and
computational properties of RPSW and IWRPSW. Finally, we showcase the favorable
performance of RPSW and IWRPSW in gradient flow and the training of denoising
diffusion generative models on images.
</p>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15890" title="Abstract">arXiv:2401.15890</a> (cross-list from stat.ML) [<a href="/pdf/2401.15890" title="Download PDF">pdf</a>, <a href="/format/2401.15890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Guarantees of Stochastic Recursive Gradient in Non-Convex  Finite Sum Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhong%2C+Y">Yanjie Zhong</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+J">Jiaqi Li</a>, 
<a href="/search/stat?searchtype=author&query=Lahiri%2C+S">Soumendra Lahiri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 3 figures, accepted to PAKDD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">This paper develops a new dimension-free Azuma-Hoeffding type bound on
summation norm of a martingale difference sequence with random individual
bounds. With this novel result, we provide high-probability bounds for the
gradient norm estimator in the proposed algorithm Prob-SARAH, which is a
modified version of the StochAstic Recursive grAdient algoritHm (SARAH), a
state-of-art variance reduced algorithm that achieves optimal computational
complexity in expectation for the finite sum problem. The in-probability
complexity by Prob-SARAH matches the best in-expectation result up to
logarithmic factors. Empirical experiments demonstrate the superior
probabilistic performance of Prob-SARAH on real datasets compared to other
popular algorithms.
</p>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15905" title="Abstract">arXiv:2401.15905</a> (cross-list from math.PR) [<a href="/pdf/2401.15905" title="Download PDF">pdf</a>, <a href="/ps/2401.15905" title="Download PostScript">ps</a>, <a href="/format/2401.15905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Numerical Truncation Approximation with A Posteriori Error Bounds for  the Solution of Poisson&#x27;s Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mahdian%2C+S">Saied Mahdian</a>, 
<a href="/search/math?searchtype=author&query=Glynn%2C+P+W">Peter W. Glynn</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yuanyuan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The solution to Poisson's equation arise in many Markov chain and Markov jump
process settings, including that of the central limit theorem, value functions
for average reward Markov decision processes, and within the gradient formula
for equilibrium Markovian rewards. In this paper, we consider the problem of
numerically computing the solution to Poisson's equation when the state space
is infinite or very large. In such settings, the state space must be truncated
in order to make the problem computationally tractable. In this paper, we
provide the first truncation approximation solution to Poisson's equation that
comes with provable and computable a posteriori error bounds. Our theory
applies to both discrete-time chains and continuous-time jump processes.
Through numerical experiments, we show our method can provide highly accurate
solutions and tight bounds.
</p>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15913" title="Abstract">arXiv:2401.15913</a> (cross-list from eess.IV) [<a href="/pdf/2401.15913" title="Download PDF">pdf</a>, <a href="/format/2401.15913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Informed Flow Image Super-Resolution with Quaternion Spatial  Modeling and Dynamic Flow Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+Q">Qinglong Cao</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zhengqin Xu</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Fluid Dynamics (physics.flu-dyn); Applications (stat.AP)

</div>
<p class="mathjax">Flow image super-resolution (FISR) aims at recovering high-resolution
turbulent velocity fields from low-resolution flow images. Existing FISR
methods mainly process the flow images in natural image patterns, while the
critical and distinct flow visual properties are rarely considered. This
negligence would cause the significant domain gap between flow and natural
images to severely hamper the accurate perception of flow turbulence, thereby
undermining super-resolution performance. To tackle this dilemma, we
comprehensively consider the flow visual properties, including the unique flow
imaging principle and morphological information, and propose the first flow
visual property-informed FISR algorithm. Particularly, different from natural
images that are constructed by independent RGB channels in the light field,
flow images build on the orthogonal UVW velocities in the flow field. To
empower the FISR network with an awareness of the flow imaging principle, we
propose quaternion spatial modeling to model this orthogonal spatial
relationship for improved FISR. Moreover, due to viscosity and surface tension
characteristics, fluids often exhibit a droplet-like morphology in flow images.
Inspired by this morphological property, we design the dynamic flow convolution
to effectively mine the morphological information to enhance FISR. Extensive
experiments on the newly acquired flow image datasets demonstrate the
state-of-the-art performance of our method. Code and data will be made
available.
</p>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15919" title="Abstract">arXiv:2401.15919</a> (cross-list from eess.SP) [<a href="/pdf/2401.15919" title="Download PDF">pdf</a>, <a href="/format/2401.15919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Imaging and Communication with Reconfigurable Intelligent  Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luo%2C+H">Hao Luo</a>, 
<a href="/search/eess?searchtype=author&query=Alkhateeb%2C+A">Ahmed Alkhateeb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures. To appear in Asilomar 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Reconfigurable intelligent surfaces, with their large number of antennas,
offer an interesting opportunity for high spatial-resolution imaging. In this
paper, we propose a novel RIS-aided integrated imaging and communication system
that can reduce the RIS beam training overhead for communication by leveraging
the imaging of the surrounding environment. In particular, using the RIS as a
wireless imaging device, our system constructs the scene depth map of the
environment, including the mobile user. Then, we develop a user detection
algorithm that subtracts the background and extracts the mobile user attributes
from the depth map. These attributes are then utilized to design the RIS
interaction vector and the beam selection strategy with low overhead.
Simulation results show that the proposed approach can achieve comparable
beamforming gain to the optimal/exhaustive beam selection solution while
requiring 1000 times less beam training overhead.
</p>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15955" title="Abstract">arXiv:2401.15955</a> (cross-list from eess.SP) [<a href="/pdf/2401.15955" title="Download PDF">pdf</a>, <a href="/ps/2401.15955" title="Download PostScript">ps</a>, <a href="/format/2401.15955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Geometric Solution for Moving Target Localization through  Multistatic Sensing in the ISAC System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhuge%2C+S">S. Zhuge</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Y">Y. Ma</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Z">Z. Lin</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+Y">Y. Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper proposes a novel geometric solution for tracking a moving target
through multistatic sensing. In contrast to existing two-step weighted least
square (2SWLS) methods which use the bistatic range (BR) and bistatic range
rate (BRR) measurements, the proposed method incorporates an additional
direction of arrival (DOA) measurement of the target obtained from a
communication receiver in an integrated sensing and communication (ISAC)
system. Unlike the existing 2SWLS methods that require at least three
transmitter-receiver (TX-RX) pairs to operate, the proposed algorithm can
conduct location estimation with a single TX-RX pair and velocity estimation
with two TX-RX pairs. Simulations reveal that the proposed method exhibits
superior performance compared to existing 2SWLS methods, particularly when
dealing with moderate levels of noise in DOA measurements.
</p>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15990" title="Abstract">arXiv:2401.15990</a> (cross-list from eess.IV) [<a href="/pdf/2401.15990" title="Download PDF">pdf</a>, <a href="/format/2401.15990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gland segmentation via dual encoders and boundary-enhanced attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Huadeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jiejiang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Bingbing Li</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+X">Xipeng Pan</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhenbing Liu</a>, 
<a href="/search/eess?searchtype=author&query=Lan%2C+R">Rushi Lan</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+X">Xiaonan Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate and automated gland segmentation on pathological images can assist
pathologists in diagnosing the malignancy of colorectal adenocarcinoma.
However, due to various gland shapes, severe deformation of malignant glands,
and overlapping adhesions between glands. Gland segmentation has always been
very challenging. To address these problems, we propose a DEA model. This model
consists of two branches: the backbone encoding and decoding network and the
local semantic extraction network. The backbone encoding and decoding network
extracts advanced Semantic features, uses the proposed feature decoder to
restore feature space information, and then enhances the boundary features of
the gland through boundary enhancement attention. The local semantic extraction
network uses the pre-trained DeepLabv3+ as a Local semantic-guided encoder to
realize the extraction of edge features. Experimental results on two public
datasets, GlaS and CRAG, confirm that the performance of our method is better
than other gland segmentation methods.
</p>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16016" title="Abstract">arXiv:2401.16016</a> (cross-list from hep-ex) [<a href="/pdf/2401.16016" title="Download PDF">pdf</a>, <a href="/format/2401.16016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combined track finding with GNN &amp; CKF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Heinrich%2C+L">Lukas Heinrich</a>, 
<a href="/search/hep-ex?searchtype=author&query=Huth%2C+B">Benjamin Huth</a>, 
<a href="/search/hep-ex?searchtype=author&query=Salzburger%2C+A">Andreas Salzburger</a>, 
<a href="/search/hep-ex?searchtype=author&query=Wettig%2C+T">Tilo Wettig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, to be published in the Connecting The Dots 2023 conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The application of Graph Neural Networks (GNN) in track reconstruction is a
promising approach to cope with the challenges arising at the High-Luminosity
upgrade of the Large Hadron Collider (HL-LHC). GNNs show good track-finding
performance in high-multiplicity scenarios and are naturally parallelizable on
heterogeneous compute architectures.
<br />Typical high-energy-physics detectors have high resolution in the innermost
layers to support vertex reconstruction but lower resolution in the outer
parts. GNNs mainly rely on 3D space-point information, which can cause reduced
track-finding performance in the outer regions.
<br />In this contribution, we present a novel combination of GNN-based track
finding with the classical Combinatorial Kalman Filter (CKF) algorithm to
circumvent this issue: The GNN resolves the track candidates in the inner pixel
region, where 3D space points can represent measurements very well. These
candidates are then picked up by the CKF in the outer regions, where the CKF
performs well even for 1D measurements.
<br />Using the ACTS infrastructure, we present a proof of concept based on truth
tracking in the pixels as well as a dedicated GNN pipeline trained on
$t\bar{t}$ events with pile-up 200 in the OpenDataDetector.
</p>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16039" title="Abstract">arXiv:2401.16039</a> (cross-list from eess.IV) [<a href="/pdf/2401.16039" title="Download PDF">pdf</a>, <a href="/format/2401.16039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Filter Design in FBP: Transforming CT Reconstruction with  Trainable Fourier Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yipeng Sun</a>, 
<a href="/search/eess?searchtype=author&query=Schneider%2C+L">Linda-Sophie Schneider</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+F">Fuxin Fan</a>, 
<a href="/search/eess?searchtype=author&query=Thies%2C+M">Mareike Thies</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+M">Mingxuan Gu</a>, 
<a href="/search/eess?searchtype=author&query=Mei%2C+S">Siyuan Mei</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yuzhong Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Bayer%2C+S">Siming Bayer</a>, 
<a href="/search/eess?searchtype=author&query=Maier%2C+A">Andreas Maier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we introduce a Fourier series-based trainable filter for
computed tomography (CT) reconstruction within the filtered backprojection
(FBP) framework. This method overcomes the limitation in noise reduction,
inherent in conventional FBP methods, by optimizing Fourier series coefficients
to construct the filter. This method enables robust performance across
different resolution scales and maintains computational efficiency with minimal
increment for the trainable parameters compared to other deep learning
frameworks. Additionally, we propose Gaussian edge-enhanced (GEE) loss function
that prioritizes the $L_1$ norm of high-frequency magnitudes, effectively
countering the blurring problems prevalent in mean squared error (MSE)
approaches. The model's foundation in the FBP algorithm ensures excellent
interpretability, as it relies on a data-driven filter with all other
parameters derived through rigorous mathematical procedures. Designed as a
plug-and-play solution, our Fourier series-based filter can be easily
integrated into existing CT reconstruction models, making it a versatile tool
for a wide range of practical applications. Our research presents a robust and
scalable method that expands the utility of FBP in both medical and scientific
imaging.
</p>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16056" title="Abstract">arXiv:2401.16056</a> (cross-list from math.GT) [<a href="/pdf/2401.16056" title="Download PDF">pdf</a>, <a href="/format/2401.16056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some fast algorithms for curves in surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lackenby%2C+M">Marc Lackenby</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geometric Topology (math.GT)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We present some algorithms that provide useful topological information about
curves in surfaces. One of the main algorithms computes the geometric
intersection number of two properly embedded 1-manifolds $C_1$ and $C_2$ in a
compact orientable surface $S$. The surface $S$ is presented via a
triangulation or a handle structure, and the 1-manifolds are given in normal
form via their normal coordinates. The running time is bounded above by a
polynomial function of the number of triangles in the triangulation (or the
number of handles in the handle structure), and the logarithm of the weight of
$C_1$ and $C_2$. This algorithm represents an improvement over previous work,
since its running time depends polynomially on the size of the triangulation of
$S$ and it can deal with closed surfaces, unlike many earlier algorithms.
Another algorithm, with similar bounds on its running time, can determine
whether $C_1$ and $C_2$ are isotopic. We also present a closely related
algorithm that can be used to place a standard 1-manifold into normal form.
</p>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16085" title="Abstract">arXiv:2401.16085</a> (cross-list from eess.SP) [<a href="/pdf/2401.16085" title="Download PDF">pdf</a>, <a href="/ps/2401.16085" title="Download PostScript">ps</a>, <a href="/format/2401.16085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-BD Symbiotic Radio-Aided 6G IoT Network: Energy Consumption  Optimization with QoS Constraint Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yeganeh%2C+R+S">Rahman Saadat Yeganeh</a>, 
<a href="/search/eess?searchtype=author&query=Omidi%2C+M+J">Mohammad Javad Omidi</a>, 
<a href="/search/eess?searchtype=author&query=Ghavami%2C+M">Mohammad Ghavami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The commensal symbiotic radio (CSR) system is proposed as a novel solution
for connecting systems through green communication networks. This system
enables us to establish secure, ubiquitous, and unlimited connectivity, which
is a goal of 6G. The base station uses MIMO antennas to transmit its signal.
Passive IoT devices, called symbiotic backscatter devices (SBDs), receive the
signal and use it to charge their power supply. When the SBDs have data to
transmit, they modulate the information onto the received ambient RF signal and
send it to the symbiotic user equipment, which is a typical active device. The
main purpose is to enhance energy efficiency in this network by minimizing
energy consumption (EC) while ensuring the minimum required throughput for
SBDs. To achieve this, we propose a new scheduling scheme called Timing-SR that
optimally allocates resources to SBDs. The main optimization problem involves
non-convex objective functions and constraints. To solve this, we use
mathematical techniques and introduce a new approach called sequential
quadratic and conic quadratic representation to relax and discipline the
problem, leading to reducing its complexity and convergence time. The
simulation results demonstrate that the proposed approach outperforms other
outlined schemes in reducing EC.
</p>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16116" title="Abstract">arXiv:2401.16116</a> (cross-list from quant-ph) [<a href="/pdf/2401.16116" title="Download PDF">pdf</a>, <a href="/ps/2401.16116" title="Download PostScript">ps</a>, <a href="/format/2401.16116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Cheques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Barhoush%2C+M">Mohammed Barhoush</a>, 
<a href="/search/quant-ph?searchtype=author&query=Salvail%2C+L">Louis Salvail</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Publicly-verifiable quantum money has been a central focus in quantum
cryptography. To date, no constructions for this primitive exist based on
standard assumptions. In this study, we propose an alternative notion which we
refer to as $\textit{quantum cheques}$ (QCs). A quantum cheque can be verified
using a public-key but only by a single user. Specifically, the payer signs the
quantum cheque for a particular recipient using their ID, and the recipient can
validate it without the assistance of the bank, ensuring that the payer cannot
assign the same cheque to another user with a different ID. Unlike quantum
money, QCs only necessitate quantum communication when a cheque is issued by
the bank, meaning all payments and deposits are entirely classical!
<br />We demonstrate how to construct QCs based on the well-studied
learning-with-errors (LWE) assumption. In the process, we build two novel
primitives which are of independent interest. Firstly, we construct
$\textit{signatures with publicly-verifiable deletion}$ under LWE. This
primitive enables the signing of a message $m$ such that the recipient can
produce a classical string that publicly proves the inability to reproduce a
signature of $m$. We then demonstrate how this primitive can be used to
construct $\textit{2-message signature tokens}$. This primitive enables the
production of a token that can be used to sign a single bit and then
self-destructs. Finally, we show that 2-message signature tokens can be used to
construct QCs.
</p>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16149" title="Abstract">arXiv:2401.16149</a> (cross-list from math.OC) [<a href="/pdf/2401.16149" title="Download PDF">pdf</a>, <a href="/ps/2401.16149" title="Download PostScript">ps</a>, <a href="/format/2401.16149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Speed-up for Helsgaun&#x27;s TSP Heuristic by Relaxing the Positive Gain  Criterion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ammann%2C+S+C+L">Sabrina C.L. Ammann</a>, 
<a href="/search/math?searchtype=author&query=Ostermann%2C+B">Birte Ostermann</a>, 
<a href="/search/math?searchtype=author&query=Stiller%2C+S">Sebastian Stiller</a>, 
<a href="/search/math?searchtype=author&query=de+Wolff%2C+T">Timo de Wolff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 23 pages appendix, 7 figures, 27 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
<p class="mathjax">The Traveling Salesman Problem (TSP) is one of the most extensively
researched and widely applied combinatorial optimization problems. It is
NP-hard even in the symmetric and metric case. Building upon elaborate
research, state-of-the-art exact solvers such as CONCORDE can solve TSP
instances with several ten thousand vertices. A key ingredient for these
integer programming approaches are fast heuristics to find a good initial
solution, in particular the Lin-Kernighan-Helsgaun (LKH) heuristic. For
instances with few hundred vertices heuristics like LKH often find an optimal
solution. In this work we develop variations of LKH that perform significantly
better on large instances. LKH repeatedly improves an initially random tour by
exchanging edges along alternating circles. Thereby, it respects several
criteria designed to quickly find alternating circles that give a feasible
improvement of the tour. Among those criteria, the positive gain criterion
stayed mostly untouched in previous research. It requires that, while
constructing an alternating circle, the total gain has to be positive after
each pair of edges. We relax this criterion carefully leading to improvement
steps hitherto undiscovered by LKH. We confirm this improvement experimentally
via extensive simulations on various benchmark libraries for TSP. Our
computational study shows that for large instances our method is on average 13%
faster than the latest version of LKH.
</p>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16190" title="Abstract">arXiv:2401.16190</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.16190" title="Download PDF">pdf</a>, <a href="/ps/2401.16190" title="Download PostScript">ps</a>, <a href="/format/2401.16190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI prediction of cardiovascular events using opportunistic epicardial  adipose tissue assessments from CT calcium score
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+T">Tao Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Freeze%2C+J">Joshua Freeze</a>, 
<a href="/search/q-bio?searchtype=author&query=Singh%2C+P">Prerna Singh</a>, 
<a href="/search/q-bio?searchtype=author&query=Kim%2C+J">Justin Kim</a>, 
<a href="/search/q-bio?searchtype=author&query=Song%2C+Y">Yingnan Song</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Lee%2C+J">Juhwan Lee</a>, 
<a href="/search/q-bio?searchtype=author&query=Al-Kindi%2C+S">Sadeer Al-Kindi</a>, 
<a href="/search/q-bio?searchtype=author&query=Rajagopalan%2C+S">Sanjay Rajagopalan</a>, 
<a href="/search/q-bio?searchtype=author&query=Wilson%2C+D+L">David L. Wilson</a>, 
<a href="/search/q-bio?searchtype=author&query=Hoori%2C+A">Ammar Hoori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 central illustration, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Background: Recent studies have used basic epicardial adipose tissue (EAT)
assessments (e.g., volume and mean HU) to predict risk of
atherosclerosis-related, major adverse cardiovascular events (MACE).
Objectives: Create novel, hand-crafted EAT features, 'fat-omics', to capture
the pathophysiology of EAT and improve MACE prediction. Methods: We segmented
EAT using a previously-validated deep learning method with optional manual
correction. We extracted 148 radiomic features (morphological, spatial, and
intensity) and used Cox elastic-net for feature reduction and prediction of
MACE. Results: Traditional fat features gave marginal prediction
(EAT-volume/EAT-mean-HU/ BMI gave C-index 0.53/0.55/0.57, respectively).
Significant improvement was obtained with 15 fat-omics features (C-index=0.69,
test set). High-risk features included
volume-of-voxels-having-elevated-HU-[-50, -30-HU] and HU-negative-skewness,
both of which assess high HU, which as been implicated in fat inflammation.
Other high-risk features include kurtosis-of-EAT-thickness, reflecting the
heterogeneity of thicknesses, and EAT-volume-in-the-top-25%-of-the-heart,
emphasizing adipose near the proximal coronary arteries. Kaplan-Meyer plots of
Cox-identified, high- and low-risk patients were well separated with the median
of the fat-omics risk, while high-risk group having HR 2.4 times that of the
low-risk group (P&lt;0.001). Conclusion: Preliminary findings indicate an
opportunity to use more finely tuned, explainable assessments on EAT for
improved cardiovascular risk prediction.
</p>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16210" title="Abstract">arXiv:2401.16210</a> (cross-list from math.CO) [<a href="/pdf/2401.16210" title="Download PDF">pdf</a>, <a href="/ps/2401.16210" title="Download PostScript">ps</a>, <a href="/format/2401.16210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Non-Cancelling Intersections Conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Amarilli%2C+A">Antoine Amarilli</a>, 
<a href="/search/math?searchtype=author&query=Monet%2C+M">Mika&#xeb;l Monet</a>, 
<a href="/search/math?searchtype=author&query=Suciu%2C+D">Dan Suciu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this note, we present a conjecture on intersections of set families, and a
rephrasing of the conjecture in terms of principal downsets of Boolean
lattices. The conjecture informally states that, whenever we can express the
measure of a union of sets in terms of the measure of some of their
intersections using the inclusion-exclusion formula, then we can express the
union as a set from these same intersections via the set operations of disjoint
union and subset complement. We also present a partial result towards
establishing the conjecture.
</p>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16220" title="Abstract">arXiv:2401.16220</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.16220" title="Download PDF">pdf</a>, <a href="/format/2401.16220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic-numeric algorithm for parameter estimation in discrete-time  models with $\exp$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Berman%2C+Y">Yosef Berman</a>, 
<a href="/search/q-bio?searchtype=author&query=Forrest%2C+J">Joshua Forrest</a>, 
<a href="/search/q-bio?searchtype=author&query=Grote%2C+M">Matthew Grote</a>, 
<a href="/search/q-bio?searchtype=author&query=Ovchinnikov%2C+A">Alexey Ovchinnikov</a>, 
<a href="/search/q-bio?searchtype=author&query=Rueda%2C+S">Sonia Rueda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Symbolic Computation (cs.SC); Systems and Control (eess.SY); Commutative Algebra (math.AC); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Determining unknown parameter values in dynamic models is crucial for
accurate analysis of the dynamics across the different scientific disciplines.
Discrete-time dynamic models are widely used to model biological processes, but
it is often difficult to determine these parameters. In this paper, we propose
a robust symbolic-numeric approach for parameter estimation in discrete-time
models that involve non-algebraic functions such as exp. We illustrate the
performance (precision) of our approach by applying our approach to the flour
beetle (LPA) model, an archetypal discrete-time model in biology. Unlike
optimization-based methods, our algorithm guarantees to find all solutions of
the parameter values given time-series data for the measured variables.
</p>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16336" title="Abstract">arXiv:2401.16336</a> (cross-list from math.AT) [<a href="/pdf/2401.16336" title="Download PDF">pdf</a>, <a href="/ps/2401.16336" title="Download PostScript">ps</a>, <a href="/format/2401.16336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Synthetic Cohomology Theory in Homotopy Type Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ljungstr%C3%B6m%2C+A">Axel Ljungstr&#xf6;m</a>, 
<a href="/search/math?searchtype=author&query=M%C3%B6rtberg%2C+A">Anders M&#xf6;rtberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">This paper discusses the development of synthetic cohomology in Homotopy Type
Theory (HoTT), as well as its computer formalisation. The objectives of this
paper are (1) to generalise previous work on integral cohomology in HoTT by the
current authors and Brunerie (2022) to cohomology with arbitrary coefficients
and (2) to provide the mathematical details of, as well as extend, results
underpinning the computer formalisation of cohomology rings by the current
authors and Lamiaux (2023). With respect to objective (1), we provide new
direct definitions of the cohomology group operations and of the cup product,
which, just as in (Brunerie et al., 2022), enable significant simplifications
of many earlier proofs in synthetic cohomology theory. In particular, the new
definition of the cup product allows us to give the first complete
formalisation of the axioms needed to turn the cohomology groups into a graded
commutative ring. We also establish that this cohomology theory satisfies the
HoTT formulation of the Eilenberg-Steenrod axioms for cohomology and study the
classical Mayer-Vietoris and Gysin sequences. With respect to objective (2), we
characterise the cohomology groups and rings of various spaces, including the
spheres, torus, Klein bottle, real/complex projective planes, and infinite real
projective space. All results have been formalised in Cubical Agda and we
obtain multiple new numbers, similar to the famous `Brunerie number', which can
be used as benchmarks for computational implementations of HoTT. Some of these
numbers are infeasible to compute in Cubical Agda and hence provide new
computational challenges and open problems which are much easier to define than
the original Brunerie number.
</p>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16356" title="Abstract">arXiv:2401.16356</a> (cross-list from physics.ins-det) [<a href="/pdf/2401.16356" title="Download PDF">pdf</a>, <a href="/format/2401.16356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> cDVGAN: One Flexible Model for Multi-class Gravitational Wave Signal and  Glitch Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Dooney%2C+T">Tom Dooney</a>, 
<a href="/search/physics?searchtype=author&query=Curier%2C+L">Lyana Curier</a>, 
<a href="/search/physics?searchtype=author&query=Tan%2C+D">Daniel Tan</a>, 
<a href="/search/physics?searchtype=author&query=Lopez%2C+M">Melissa Lopez</a>, 
<a href="/search/physics?searchtype=author&query=Van+Den+Broeck%2C+C">Chris Van Den Broeck</a>, 
<a href="/search/physics?searchtype=author&query=Bromuri%2C+S">Stefano Bromuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 16 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Detectors (physics.ins-det)</span>; Machine Learning (cs.LG); General Relativity and Quantum Cosmology (gr-qc)

</div>
<p class="mathjax">Simulating realistic time-domain observations of gravitational waves (GWs)
and GW detector glitches can help in advancing GW data analysis. Simulated data
can be used in downstream tasks by augmenting datasets for signal searches,
balancing data sets for machine learning, and validating detection schemes. In
this work, we present Conditional Derivative GAN (cDVGAN), a novel conditional
model in the Generative Adversarial Network framework for simulating multiple
classes of time-domain observations that represent gravitational waves (GWs)
and detector glitches. cDVGAN can also generate generalized hybrid samples that
span the variation between classes through interpolation in the conditioned
class vector. cDVGAN introduces an additional player into the typical 2-player
adversarial game of GANs, where an auxiliary discriminator analyzes the
first-order derivative time-series. Our results show that this provides
synthetic data that better captures the features of the original data. cDVGAN
conditions on three classes, two denoised from LIGO blip and tomte glitch
events from its 3rd observing run (O3), and the third representing binary black
hole (BBH) mergers. Our proposed cDVGAN outperforms 4 different baseline GAN
models in replicating the features of the three classes. Specifically, our
experiments show that training convolutional neural networks (CNNs) with our
cDVGAN-generated data improves the detection of samples embedded in detector
noise beyond the synthetic data from other state-of-the-art GAN models. Our
best synthetic dataset yields as much as a 4.2% increase in
area-under-the-curve (AUC) performance compared to synthetic datasets from
baseline GANs. Moreover, training the CNN with hybrid samples from our cDVGAN
outperforms CNNs trained only on the standard classes, when identifying real
samples embedded in LIGO detector background (4% AUC improvement for cDVGAN).
</p>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16363" title="Abstract">arXiv:2401.16363</a> (cross-list from eess.IV) [<a href="/pdf/2401.16363" title="Download PDF">pdf</a>, <a href="/format/2401.16363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of pseudo-healthy image reconstruction for anomaly detection  with deep generative models: Application to brain FDG PET
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hassanaly%2C+R">Ravi Hassanaly</a>, 
<a href="/search/eess?searchtype=author&query=Brianceau%2C+C">Camille Brianceau</a>, 
<a href="/search/eess?searchtype=author&query=Solal%2C+M">Ma&#xeb;lys Solal</a>, 
<a href="/search/eess?searchtype=author&query=Colliot%2C+O">Olivier Colliot</a>, 
<a href="/search/eess?searchtype=author&query=Burgos%2C+N">Ninon Burgos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) <a href="https://melba-journal.org/2024:003">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine.Learning.for.Biomedical.Imaging. 2 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Over the past years, pseudo-healthy reconstruction for unsupervised anomaly
detection has gained in popularity. This approach has the great advantage of
not requiring tedious pixel-wise data annotation and offers possibility to
generalize to any kind of anomalies, including that corresponding to rare
diseases. By training a deep generative model with only images from healthy
subjects, the model will learn to reconstruct pseudo-healthy images. This
pseudo-healthy reconstruction is then compared to the input to detect and
localize anomalies. The evaluation of such methods often relies on a ground
truth lesion mask that is available for test data, which may not exist
depending on the application.
<br />We propose an evaluation procedure based on the simulation of realistic
abnormal images to validate pseudo-healthy reconstruction methods when no
ground truth is available. This allows us to extensively test generative models
on different kinds of anomalies and measuring their performance using the pair
of normal and abnormal images corresponding to the same subject. It can be used
as a preliminary automatic step to validate the capacity of a generative model
to reconstruct pseudo-healthy images, before a more advanced validation step
that would require clinician's expertise. We apply this framework to the
reconstruction of 3D brain FDG PET using a convolutional variational
autoencoder with the aim to detect as early as possible the neurodegeneration
markers that are specific to dementia such as Alzheimer's disease.
</p>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16372" title="Abstract">arXiv:2401.16372</a> (cross-list from math.OC) [<a href="/pdf/2401.16372" title="Download PDF">pdf</a>, <a href="/format/2401.16372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Duality between controllability and observability for target control and  estimation in networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Montanari%2C+A+N">Arthur N. Montanari</a>, 
<a href="/search/math?searchtype=author&query=Duan%2C+C">Chao Duan</a>, 
<a href="/search/math?searchtype=author&query=Motter%2C+A+E">Adilson E. Motter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Systems and Control (eess.SY); Dynamical Systems (math.DS); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Controllability and observability are properties that establish the existence
of full-state controllers and observers, respectively. The notions of output
controllability and functional observability are generalizations that enable
respectively the control and estimation of part of the state vector. These
generalizations are of utmost importance in applications to high-dimensional
systems, such as large-scale networks, in which only a target subset of
variables (nodes) are sought to be controlled or estimated. Although the
duality between controllability and observability is well established, the
characterization of the duality between their generalized counterparts remains
an outstanding problem. Here, we establish both the weak and the strong duality
between output controllability and functional observability. Specifically, we
show that functional observability of a system implies output controllability
of a dual system (weak duality), and that under a certain condition the
converse also holds (strong duality). As an application of the strong duality
principle, we derive a necessary and sufficient condition for target control
via static feedback. This allow us to establish a separation principle between
the design of a feedback target controller and the design of a functional
observer in closed-loop systems. These results generalize the well-known
duality and separation principles in modern control theory.
</p>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16407" title="Abstract">arXiv:2401.16407</a> (cross-list from stat.ML) [<a href="/pdf/2401.16407" title="Download PDF">pdf</a>, <a href="/format/2401.16407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is K-fold cross validation the best model selection method for Machine  Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gorriz%2C+J+M">Juan M Gorriz</a>, 
<a href="/search/stat?searchtype=author&query=Segovia%2C+F">F Segovia</a>, 
<a href="/search/stat?searchtype=author&query=Ramirez%2C+J">J Ramirez</a>, 
<a href="/search/stat?searchtype=author&query=Ortiz%2C+A">A Ortiz</a>, 
<a href="/search/stat?searchtype=author&query=Suckling%2C+J">J. Suckling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
<p class="mathjax">As a technique that can compactly represent complex patterns, machine
learning has significant potential for predictive inference. K-fold
cross-validation (CV) is the most common approach to ascertaining the
likelihood that a machine learning outcome is generated by chance and
frequently outperforms conventional hypothesis testing. This improvement uses
measures directly obtained from machine learning classifications, such as
accuracy, that do not have a parametric description. To approach a frequentist
analysis within machine learning pipelines, a permutation test or simple
statistics from data partitions (i.e. folds) can be added to estimate
confidence intervals. Unfortunately, neither parametric nor non-parametric
tests solve the inherent problems around partitioning small sample-size
datasets and learning from heterogeneous data sources. The fact that machine
learning strongly depends on the learning parameters and the distribution of
data across folds recapitulates familiar difficulties around excess false
positives and replication. The origins of this problem are demonstrated by
simulating common experimental circumstances, including small sample sizes, low
numbers of predictors, and heterogeneous data sources. A novel statistical test
based on K-fold CV and the Upper Bound of the actual error (K-fold CUBV) is
composed, where uncertain predictions of machine learning with CV are bounded
by the \emph{worst case} through the evaluation of concentration inequalities.
Probably Approximately Correct-Bayesian upper bounds for linear classifiers in
combination with K-fold CV is used to estimate the empirical error. The
performance with neuroimaging datasets suggests this is a robust criterion for
detecting effects, validating accuracy values obtained from machine learning
whilst avoiding excess false positives.
</p>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16410" title="Abstract">arXiv:2401.16410</a> (cross-list from stat.ML) [<a href="/pdf/2401.16410" title="Download PDF">pdf</a>, <a href="/format/2401.16410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReTaSA: A Nonparametric Functional Estimation Approach for Addressing  Continuous Target Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kim%2C+H">Hwanwoo Kim</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Zhao%2C+J">Jiwei Zhao</a>, 
<a href="/search/stat?searchtype=author&query=Tian%2C+Q">Qinglong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The presence of distribution shifts poses a significant challenge for
deploying modern machine learning models in real-world applications. This work
focuses on the target shift problem in a regression setting (Zhang et al.,
2013; Nguyen et al., 2016). More specifically, the target variable y (also
known as the response variable), which is continuous, has different marginal
distributions in the training source and testing domain, while the conditional
distribution of features x given y remains the same. While most literature
focuses on classification tasks with finite target space, the regression
problem has an infinite dimensional target space, which makes many of the
existing methods inapplicable. In this work, we show that the continuous target
shift problem can be addressed by estimating the importance weight function
from an ill-posed integral equation. We propose a nonparametric regularized
approach named ReTaSA to solve the ill-posed integral equation and provide
theoretical justification for the estimated importance weight function. The
effectiveness of the proposed method has been demonstrated with extensive
numerical studies on synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16418" title="Abstract">arXiv:2401.16418</a> (cross-list from stat.ML) [<a href="/pdf/2401.16418" title="Download PDF">pdf</a>, <a href="/ps/2401.16418" title="Download PostScript">ps</a>, <a href="/format/2401.16418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boolean Logic as an Error feedback mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Leconte%2C+L">Louis Leconte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The notion of Boolean logic backpropagation was introduced to build neural
networks with weights and activations being Boolean numbers. Most of
computations can be done with Boolean logic instead of real arithmetic, both
during training and inference phases. But the underlying discrete optimization
problem is NP-hard, and the Boolean logic has no guarantee. In this work we
propose the first convergence analysis, under standard non-convex assumptions.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue, 30 Jan 24</h3>
<dl>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1611.06189" title="Abstract">arXiv:1611.06189</a> (replaced) [<a href="/pdf/1611.06189" title="Download PDF">pdf</a>, <a href="/ps/1611.06189" title="Download PostScript">ps</a>, <a href="/format/1611.06189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query Complexity of Tournament Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maiti%2C+A">Arnab Maiti</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+P">Palash Dey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version appeared in AAAI. Full version with new results will appear in Theoretical Computer Science journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1902.08412" title="Abstract">arXiv:1902.08412</a> (replaced) [<a href="/pdf/1902.08412" title="Download PDF">pdf</a>, <a href="/ps/1902.08412" title="Download PostScript">ps</a>, <a href="/format/1902.08412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks on Graph Neural Networks via Meta Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Z%C3%BCgner%2C+D">Daniel Z&#xfc;gner</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR submission
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Learning Representations (ICLR), New
  Orleans, LA, USA, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.05907" title="Abstract">arXiv:2002.05907</a> (replaced) [<a href="/pdf/2002.05907" title="Download PDF">pdf</a>, <a href="/format/2002.05907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on 3D Skeleton-Based Action Recognition Using Learning Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+B">Bin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Runwei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Cyborg and Bionic Systems (CBS), 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2004.13324" title="Abstract">arXiv:2004.13324</a> (replaced) [<a href="/pdf/2004.13324" title="Download PDF">pdf</a>, <a href="/format/2004.13324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Feature Descriptors using Camera Pose Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaowei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hariharan%2C+B">Bharath Hariharan</a>, 
<a href="/search/cs?searchtype=author&query=Snavely%2C+N">Noah Snavely</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ECCV 2020 (oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.00224" title="Abstract">arXiv:2009.00224</a> (replaced) [<a href="/pdf/2009.00224" title="Download PDF">pdf</a>, <a href="/format/2009.00224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Hey Model!&quot; - Natural User Interactions and Agency in Accessible  Interactive 3D Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reinders%2C+S">Samuel Reinders</a>, 
<a href="/search/cs?searchtype=author&query=Butler%2C+M">Matthew Butler</a>, 
<a href="/search/cs?searchtype=author&query=Marriott%2C+K">Kim Marriott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper presented at ACM CHI 2020: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, ACM, New York, April 2020; Replacement: typos corrected, character encoding
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.07497" title="Abstract">arXiv:2009.07497</a> (replaced) [<a href="/pdf/2009.07497" title="Download PDF">pdf</a>, <a href="/ps/2009.07497" title="Download PostScript">ps</a>, <a href="/format/2009.07497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One head is better than two: a polynomial restriction for propositional  definite Horn forgetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liberatore%2C+P">Paolo Liberatore</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.10862" title="Abstract">arXiv:2009.10862</a> (replaced) [<a href="/pdf/2009.10862" title="Download PDF">pdf</a>, <a href="/format/2009.10862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Intuitive Tutorial to Gaussian Process Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+J">Jie Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computing in Science &amp; Engineering, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.16271" title="Abstract">arXiv:2010.16271</a> (replaced) [<a href="/pdf/2010.16271" title="Download PDF">pdf</a>, <a href="/format/2010.16271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> View selection in multi-view stacking: Choosing the meta-learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=van+Loon%2C+W">Wouter van Loon</a>, 
<a href="/search/stat?searchtype=author&query=Fokkema%2C+M">Marjolein Fokkema</a>, 
<a href="/search/stat?searchtype=author&query=Szabo%2C+B">Botond Szabo</a>, 
<a href="/search/stat?searchtype=author&query=de+Rooij%2C+M">Mark de Rooij</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 17 figures. Minor revisions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.06746" title="Abstract">arXiv:2012.06746</a> (replaced) [<a href="/pdf/2012.06746" title="Download PDF">pdf</a>, <a href="/format/2012.06746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Periocular Embedding Learning with Consistent Knowledge Distillation  from Face
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+Y+G">Yoon Gyo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaewoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+C+Y">Cheng Yaw Low</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+J+C+L">Jacky Chen Long Chai</a>, 
<a href="/search/cs?searchtype=author&query=Tiong%2C+L+C+O">Leslie Ching Ow Tiong</a>, 
<a href="/search/cs?searchtype=author&query=Teoh%2C+A+B+J">Andrew Beng Jin Teoh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Neurocomputing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.11116" title="Abstract">arXiv:2101.11116</a> (replaced) [<a href="/pdf/2101.11116" title="Download PDF">pdf</a>, <a href="/format/2101.11116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact and Approximate Heterogeneous Bayesian Decentralized Data Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dagan%2C+O">Ofer Dagan</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N+R">Nisar R. Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures, 2 tables, Published at IEEE Transactions on Robotics (T-RO)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Robotics 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.11768" title="Abstract">arXiv:2102.11768</a> (replaced) [<a href="/pdf/2102.11768" title="Download PDF">pdf</a>, <a href="/format/2102.11768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Granular DeGroot Dynamics -- a Model for Robust Naive Learning in Social  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Amir%2C+G">Gideon Amir</a>, 
<a href="/search/math?searchtype=author&query=Arieli%2C+I">Itai Arieli</a>, 
<a href="/search/math?searchtype=author&query=Ashkenazi-Golan%2C+G">Galit Ashkenazi-Golan</a>, 
<a href="/search/math?searchtype=author&query=Peretz%2C+R">Ron Peretz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.04565" title="Abstract">arXiv:2103.04565</a> (replaced) [<a href="/e-print/2103.04565" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Transformation-based Defenses against Adversarial Examples  with First-order Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haimin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Min Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has technical errors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.06908" title="Abstract">arXiv:2104.06908</a> (replaced) [<a href="/pdf/2104.06908" title="Download PDF">pdf</a>, <a href="/format/2104.06908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UX Debt: Developers Borrow While Users Pay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baltes%2C+S">Sebastian Baltes</a>, 
<a href="/search/cs?searchtype=author&query=Dashuber%2C+V">Veronika Dashuber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, Proceedings of the 17th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.12833" title="Abstract">arXiv:2105.12833</a> (replaced) [<a href="/e-print/2105.12833" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulated Data Generation Through Algorithmic Force Coefficient  Estimation for AI-Based Robotic Projectile Launch Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+S">Sajiv Shah</a>, 
<a href="/search/cs?searchtype=author&query=Haque%2C+A">Ayaan Haque</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> not relevant work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.08824" title="Abstract">arXiv:2107.08824</a> (replaced) [<a href="/pdf/2107.08824" title="Download PDF">pdf</a>, <a href="/ps/2107.08824" title="Download PostScript">ps</a>, <a href="/format/2107.08824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifying a Realistic Mutable Hash Table
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chassot%2C+S">Samuel Chassot</a>, 
<a href="/search/cs?searchtype=author&query=Kun%C4%8Dak%2C+V">Viktor Kun&#x10d;ak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.00783" title="Abstract">arXiv:2109.00783</a> (replaced) [<a href="/pdf/2109.00783" title="Download PDF">pdf</a>, <a href="/format/2109.00783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer Vision Self-supervised Learning Methods on Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Daesoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Aune%2C+E">Erlend Aune</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.06326" title="Abstract">arXiv:2110.06326</a> (replaced) [<a href="/pdf/2110.06326" title="Download PDF">pdf</a>, <a href="/format/2110.06326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Does the Gittins Policy Have Asymptotically Optimal Response Time  Tail?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scully%2C+Z">Ziv Scully</a>, 
<a href="/search/cs?searchtype=author&query=van+Kreveld%2C+L">Lucas van Kreveld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Operations Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.02764" title="Abstract">arXiv:2111.02764</a> (replaced) [<a href="/pdf/2111.02764" title="Download PDF">pdf</a>, <a href="/ps/2111.02764" title="Download PostScript">ps</a>, <a href="/format/2111.02764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilization and Variations to the Adaptive Local Iterative Filtering  Algorithm: the Fast Resampled Iterative Filtering Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Barbarino%2C+G">Giovanni Barbarino</a>, 
<a href="/search/math?searchtype=author&query=Cicone%2C+A">Antonio Cicone</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Barbarino, G., Cicone, A. Stabilization and variations to the
  adaptive local iterative filtering algorithm: the fast resampled iterative
  filtering method. Numer. Math. (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.04870" title="Abstract">arXiv:2112.04870</a> (replaced) [<a href="/pdf/2112.04870" title="Download PDF">pdf</a>, <a href="/format/2112.04870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eigenfunction martingale estimators for interacting particle systems and  their mean field limit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pavliotis%2C+G+A">Grigorios A. Pavliotis</a>, 
<a href="/search/math?searchtype=author&query=Zanoni%2C+A">Andrea Zanoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.01054" title="Abstract">arXiv:2202.01054</a> (replaced) [<a href="/pdf/2202.01054" title="Download PDF">pdf</a>, <a href="/format/2202.01054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved quantum algorithms for linear and nonlinear differential  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Krovi%2C+H">Hari Krovi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the latest version, the use of rescaling in the quantum algorithm for nonlinear differential equations is clarified. The conditions for lemmas 16 and 17 are stated more clearly and a new lemma is added to the appendix
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Quantum 7, 913 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Plasma Physics (physics.plasm-ph)

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.03772" title="Abstract">arXiv:2202.03772</a> (replaced) [<a href="/pdf/2202.03772" title="Download PDF">pdf</a>, <a href="/format/2202.03772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Particle Transformer for Jet Tagging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Qu%2C+H">Huilin Qu</a>, 
<a href="/search/hep-ph?searchtype=author&query=Li%2C+C">Congqiao Li</a>, 
<a href="/search/hep-ph?searchtype=author&query=Qian%2C+S">Sitian Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures. Accepted to the 39th International Conference on Machine Learning (ICML), 2022. v3: fixed a typo on the interaction matrix dimensionality in Sec. 4
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 39th International Conference on Machine
  Learning, PMLR 162:18281-18292, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.08246" title="Abstract">arXiv:2202.08246</a> (replaced) [<a href="/pdf/2202.08246" title="Download PDF">pdf</a>, <a href="/format/2202.08246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Galois connecting call-by-value and call-by-name
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDermott%2C+D">Dylan McDermott</a>, 
<a href="/search/cs?searchtype=author&query=Mycroft%2C+A">Alan Mycroft</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> FSCD 2022 special issue of Logical Methods in Computer Science; minor changes incorporating reviewers' comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.12435" title="Abstract">arXiv:2202.12435</a> (replaced) [<a href="/pdf/2202.12435" title="Download PDF">pdf</a>, <a href="/format/2202.12435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Adversarial Robustness from Feature Maps of Convolutional  Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.00999" title="Abstract">arXiv:2203.00999</a> (replaced) [<a href="/pdf/2203.00999" title="Download PDF">pdf</a>, <a href="/format/2203.00999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepAutoPIN: An automorphism orbits based deep neural network for  characterizing the organizational diversity of protein interactomes across  the tree of life
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Singh%2C+V">Vikram Singh</a>, 
<a href="/search/q-bio?searchtype=author&query=Singh%2C+V">Vikram Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 4 figures, 1 algorithm, 2 supplementary files
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.01327" title="Abstract">arXiv:2203.01327</a> (replaced) [<a href="/pdf/2203.01327" title="Download PDF">pdf</a>, <a href="/format/2203.01327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperspectral Pixel Unmixing with Latent Dirichlet Variational  Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mantripragada%2C+K">Kiran Mantripragada</a>, 
<a href="/search/eess?searchtype=author&query=Qureshi%2C+F+Z">Faisal Z. Qureshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04166" title="Abstract">arXiv:2203.04166</a> (replaced) [<a href="/pdf/2203.04166" title="Download PDF">pdf</a>, <a href="/format/2203.04166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum-based Reinforcement Learning for Distribution System Critical  Load Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Eseye%2C+A+T">Abinet Tesfaye Eseye</a>, 
<a href="/search/eess?searchtype=author&query=Knueven%2C+B">Bernard Knueven</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Weijia Liu</a>, 
<a href="/search/eess?searchtype=author&query=Reynolds%2C+M">Matthew Reynolds</a>, 
<a href="/search/eess?searchtype=author&query=Jones%2C+W">Wesley Jones</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Power Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04228" title="Abstract">arXiv:2203.04228</a> (replaced) [<a href="/pdf/2203.04228" title="Download PDF">pdf</a>, <a href="/format/2203.04228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Engagement with Retracted Articles: Who, When, and How?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dambanemuya%2C+H+K">Henry K. Dambanemuya</a>, 
<a href="/search/cs?searchtype=author&query=Abhari%2C+R">Rod Abhari</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+N">Nicholas Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Horv%C3%A1t%2C+E">Em&#x151;ke-&#xc1;gnes Horv&#xe1;t</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.08565" title="Abstract">arXiv:2203.08565</a> (replaced) [<a href="/pdf/2203.08565" title="Download PDF">pdf</a>, <a href="/format/2203.08565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geographic Adaptation of Pretrained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+V">Valentin Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Glava%C5%A1%2C+G">Goran Glava&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Ljube%C5%A1i%C4%87%2C+N">Nikola Ljube&#x161;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Pierrehumbert%2C+J+B">Janet B. Pierrehumbert</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtze%2C+H">Hinrich Sch&#xfc;tze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TACL 2024 (pre-MIT Press publication version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.12476" title="Abstract">arXiv:2203.12476</a> (replaced) [<a href="/pdf/2203.12476" title="Download PDF">pdf</a>, <a href="/format/2203.12476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Optimization for Large Vision Model Based Deep Image Prior in  Cone-Beam CT Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+M">Minghui Wu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yangdi Xu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yingying Xu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+G">Guangwei Wu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qingqing Chen</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+H">Hongxiang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 1 table. Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.07767" title="Abstract">arXiv:2204.07767</a> (replaced) [<a href="/pdf/2204.07767" title="Download PDF">pdf</a>, <a href="/format/2204.07767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards cost-effective and resource-aware aggregation at Edge for  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+F">Ahmad Faraz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuze Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Haroon%2C+S">Sabaat Haroon</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+H">Haider Ali</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yue Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Butt%2C+A+R">Ali R. Butt</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+A">Ali Anwar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures, 4 tables This paper has been accepted at the 2023 IEEE International Conference on Big Data (BigData)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03056" title="Abstract">arXiv:2205.03056</a> (replaced) [<a href="/pdf/2205.03056" title="Download PDF">pdf</a>, <a href="/format/2205.03056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Evolutionary Strategy For Black-Box Optimizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Changhwi Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11131" title="Abstract">arXiv:2205.11131</a> (replaced) [<a href="/pdf/2205.11131" title="Download PDF">pdf</a>, <a href="/format/2205.11131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous Semantic Transfer for Multi-label Recognition with Partial  Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianshui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+T">Tao Pu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingbo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yukai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhijing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. arXiv admin note: text overlap with <a href="/abs/2112.10941">arXiv:2112.10941</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.13092" title="Abstract">arXiv:2205.13092</a> (replaced) [<a href="/pdf/2205.13092" title="Download PDF">pdf</a>, <a href="/format/2205.13092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Perspective Semantic-Aware Representation Blending for Multi-Label  Image Recognition with Partial Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+T">Tao Pu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianshui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hefeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yukai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhijing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. arXiv admin note: text overlap with <a href="/abs/2203.02172">arXiv:2203.02172</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14570" title="Abstract">arXiv:2205.14570</a> (replaced) [<a href="/pdf/2205.14570" title="Download PDF">pdf</a>, <a href="/format/2205.14570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiniDisc: Minimal Distillation Schedule for Language Model Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawei Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024. Code is available at <a href="https://github.com/GeneZC/MiniDisc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15401" title="Abstract">arXiv:2205.15401</a> (replaced) [<a href="/pdf/2205.15401" title="Download PDF">pdf</a>, <a href="/format/2205.15401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoGE: A Differentiable Volume Renderer using Gaussian Ellipsoids for  Analysis-by-Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Angtian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kortylewski%2C+A">Adam Kortylewski</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02286" title="Abstract">arXiv:2206.02286</a> (replaced) [<a href="/pdf/2206.02286" title="Download PDF">pdf</a>, <a href="/format/2206.02286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AugLoss: A Robust Augmentation-based Fine Tuning Methodology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Otstot%2C+K">Kyle Otstot</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+A">Andrew Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cava%2C+J+K">John Kevin Cava</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+L">Lalitha Sankar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.03183" title="Abstract">arXiv:2206.03183</a> (replaced) [<a href="/pdf/2206.03183" title="Download PDF">pdf</a>, <a href="/format/2206.03183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk Measures and Upper Probabilities: Coherence and Stratification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fr%C3%B6hlich%2C+C">Christian Fr&#xf6;hlich</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+R+C">Robert C. Williamson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05581" title="Abstract">arXiv:2206.05581</a> (replaced) [<a href="/pdf/2206.05581" title="Download PDF">pdf</a>, <a href="/format/2206.05581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhou%2C+D">Doudou Zhou</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Y">Yufeng Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Sonabend-W%2C+A">Aaron Sonabend-W</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>, 
<a href="/search/stat?searchtype=author&query=Lu%2C+J">Junwei Lu</a>, 
<a href="/search/stat?searchtype=author&query=Cai%2C+T">Tianxi Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11396" title="Abstract">arXiv:2206.11396</a> (replaced) [<a href="/pdf/2206.11396" title="Download PDF">pdf</a>, <a href="/format/2206.11396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Horizon Representations with Hierarchical Forward Models for  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McInroe%2C+T">Trevor McInroe</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fer%2C+L">Lukas Sch&#xe4;fer</a>, 
<a href="/search/cs?searchtype=author&query=Albrecht%2C+S+V">Stefano V. Albrecht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.01079" title="Abstract">arXiv:2207.01079</a> (replaced) [<a href="/pdf/2207.01079" title="Download PDF">pdf</a>, <a href="/format/2207.01079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiSCoMaT: Distantly Supervised Composition Extraction from Tables in  Materials Science Articles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+T">Tanishq Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Zaki%2C+M">Mohd Zaki</a>, 
<a href="/search/cs?searchtype=author&query=Khatsuriya%2C+D">Devanshi Khatsuriya</a>, 
<a href="/search/cs?searchtype=author&query=Hira%2C+K">Kausik Hira</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+N+M+A">N. M. Anoop Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Mausam">Mausam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted long paper at ACL 2023 (<a href="https://2023.aclweb.org/program/accepted_main_conference/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Materials Science (cond-mat.mtrl-sci); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.01124" title="Abstract">arXiv:2207.01124</a> (replaced) [<a href="/pdf/2207.01124" title="Download PDF">pdf</a>, <a href="/format/2207.01124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Python Library Migrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M">Mohayeminul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A+K">Ajay Kumar Jha</a>, 
<a href="/search/cs?searchtype=author&query=Akhmetov%2C+I">Ildar Akhmetov</a>, 
<a href="/search/cs?searchtype=author&query=Nadi%2C+S">Sarah Nadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11756" title="Abstract">arXiv:2207.11756</a> (replaced) [<a href="/pdf/2207.11756" title="Download PDF">pdf</a>, <a href="/format/2207.11756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Interplay of Spectral Efficiency, User Density, and Energy in  Grant-based Access Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malak%2C+D">Derya Malak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A short version in WiOpt'22, and this version in TCOM'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13532" title="Abstract">arXiv:2207.13532</a> (replaced) [<a href="/pdf/2207.13532" title="Download PDF">pdf</a>, <a href="/format/2207.13532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Masked Autoencoders are Stronger Vision Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhicheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaojie Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chengze Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Q">Qibin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Dongmei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaohui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07397" title="Abstract">arXiv:2208.07397</a> (replaced) [<a href="/pdf/2208.07397" title="Download PDF">pdf</a>, <a href="/format/2208.07397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling thermal regulation in thin vascular systems: A mathematical  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nakshatrala%2C+K+B">Kalyana B. Nakshatrala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Tissues and Organs (q-bio.TO)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07462" title="Abstract">arXiv:2208.07462</a> (replaced) [<a href="/pdf/2208.07462" title="Download PDF">pdf</a>, <a href="/format/2208.07462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speeding up random walk mixing by starting from a uniform vertex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=D%C3%ADaz%2C+A+E">Alberto Espuny D&#xed;az</a>, 
<a href="/search/math?searchtype=author&query=Morris%2C+P">Patrick Morris</a>, 
<a href="/search/math?searchtype=author&query=Perarnau%2C+G">Guillem Perarnau</a>, 
<a href="/search/math?searchtype=author&query=Serra%2C+O">Oriol Serra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Electronic Journal of Probability
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10469" title="Abstract">arXiv:2208.10469</a> (replaced) [<a href="/pdf/2208.10469" title="Download PDF">pdf</a>, <a href="/format/2208.10469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal Contracts Mitigate Social Dilemmas in Multi-Agent RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haupt%2C+A+A">Andreas A. Haupt</a>, 
<a href="/search/cs?searchtype=author&query=Christoffersen%2C+P+J+K">Phillip J.K. Christoffersen</a>, 
<a href="/search/cs?searchtype=author&query=Damani%2C+M">Mehul Damani</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield-Menell%2C+D">Dylan Hadfield-Menell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00109" title="Abstract">arXiv:2209.00109</a> (replaced) [<a href="/pdf/2209.00109" title="Download PDF">pdf</a>, <a href="/format/2209.00109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A DeepParticle method for learning and generating aggregation patterns  in multi-dimensional Keller-Segel chemotaxis systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+Z">Zhongjian Wang</a>, 
<a href="/search/physics?searchtype=author&query=Xin%2C+J">Jack Xin</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+Z">Zhiwen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02873" title="Abstract">arXiv:2209.02873</a> (replaced) [<a href="/pdf/2209.02873" title="Download PDF">pdf</a>, <a href="/ps/2209.02873" title="Download PostScript">ps</a>, <a href="/format/2209.02873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel difference equation approach for the stability and robustness of  compact schemes for variable coefficient PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goswami%2C+A">Anindya Goswami</a>, 
<a href="/search/math?searchtype=author&query=Patel%2C+K+S">Kuldip Singh Patel</a>, 
<a href="/search/math?searchtype=author&query=Sahu%2C+P+K">Pradeep Kumar Sahu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03563" title="Abstract">arXiv:2209.03563</a> (replaced) [<a href="/pdf/2209.03563" title="Download PDF">pdf</a>, <a href="/format/2209.03563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSL-WM: A Black-Box Watermarking Approach for Encoders Pre-trained by  Self-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+P">Peizhuo Lv</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shenchen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Ruigang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+C">Chang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+F">Fan Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuling Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hualong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+G">Guozhu Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the Network and Distributed System Security (NDSS) Symposium 2024, 26 February - 1 March 2024, San Diego, CA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03622" title="Abstract">arXiv:2209.03622</a> (replaced) [<a href="/pdf/2209.03622" title="Download PDF">pdf</a>, <a href="/format/2209.03622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Models for Detecting Malware Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maniriho%2C+P">Pascal Maniriho</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+A+N">Abdun Naser Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M+J+M">Mohammad Jabed Morshed Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised figures 2 and 3, revised title, remove typos page 17
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07661" title="Abstract">arXiv:2209.07661</a> (replaced) [<a href="/pdf/2209.07661" title="Download PDF">pdf</a>, <a href="/format/2209.07661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Relation between Sensitivity and Accuracy in In-context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>, 
<a href="/search/cs?searchtype=author&query=McKeown%2C+K">Kathleen McKeown</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">He He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 camera-ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03888" title="Abstract">arXiv:2210.03888</a> (replaced) [<a href="/pdf/2210.03888" title="Download PDF">pdf</a>, <a href="/ps/2210.03888" title="Download PostScript">ps</a>, <a href="/format/2210.03888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated and Deep Expectation Maximization for One-Bit MIMO-OFDM  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shao%2C+M">Mingjie Shao</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+W">Wing-Kin Ma</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Junbin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Z">Zihao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04522" title="Abstract">arXiv:2210.04522</a> (replaced) [<a href="/pdf/2210.04522" title="Download PDF">pdf</a>, <a href="/format/2210.04522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HORIZON: High-Resolution Semantically Controlled Panorama Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+L">Lei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenfei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Ming Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shuai Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12273" title="Abstract">arXiv:2210.12273</a> (replaced) [<a href="/pdf/2210.12273" title="Download PDF">pdf</a>, <a href="/ps/2210.12273" title="Download PostScript">ps</a>, <a href="/format/2210.12273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graphemic Normalization of the Perso-Arabic Script
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doctor%2C+R">Raiomond Doctor</a>, 
<a href="/search/cs?searchtype=author&query=Gutkin%2C+A">Alexander Gutkin</a>, 
<a href="/search/cs?searchtype=author&query=Johny%2C+C">Cibu Johny</a>, 
<a href="/search/cs?searchtype=author&query=Roark%2C+B">Brian Roark</a>, 
<a href="/search/cs?searchtype=author&query=Sproat%2C+R">Richard Sproat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print to appear in the Proceedings of Grapholinguistics in the 21st Century (G21C), 2022. Telecom Paris, Palaiseau, France, June 8-10, 2022. 41 pages, 38 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12288" title="Abstract">arXiv:2210.12288</a> (replaced) [<a href="/pdf/2210.12288" title="Download PDF">pdf</a>, <a href="/format/2210.12288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Ultrametric Trees for Optimal Transport Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Samantha Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tabaghi%2C+P">Puoya Tabaghi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13008" title="Abstract">arXiv:2210.13008</a> (replaced) [<a href="/pdf/2210.13008" title="Download PDF">pdf</a>, <a href="/format/2210.13008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent inference for diffusions from low frequency measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nickl%2C+R">Richard Nickl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 5 figures, to appear in the Annals of Statistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14164" title="Abstract">arXiv:2210.14164</a> (replaced) [<a href="/pdf/2210.14164" title="Download PDF">pdf</a>, <a href="/format/2210.14164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No-Box Attacks on 3D Point Cloud Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naderi%2C+H">Hanieh Naderi</a>, 
<a href="/search/cs?searchtype=author&query=Dinesh%2C+C">Chinthaka Dinesh</a>, 
<a href="/search/cs?searchtype=author&query=Bajic%2C+I+V">Ivan V. Bajic</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+S">Shohreh Kasaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06236" title="Abstract">arXiv:2211.06236</a> (replaced) [<a href="/pdf/2211.06236" title="Download PDF">pdf</a>, <a href="/format/2211.06236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Deep Reinforcement Learning with Predictive Processing  Proximal Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%BC%C3%A7%C3%BCko%C4%9Flu%2C+B">Burcu K&#xfc;&#xe7;&#xfc;ko&#x11f;lu</a>, 
<a href="/search/cs?searchtype=author&query=Borkent%2C+W">Walraaf Borkent</a>, 
<a href="/search/cs?searchtype=author&query=Rueckauer%2C+B">Bodo Rueckauer</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+N">Nasir Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BC%C3%A7l%C3%BC%2C+U">Umut G&#xfc;&#xe7;l&#xfc;</a>, 
<a href="/search/cs?searchtype=author&query=van+Gerven%2C+M">Marcel van Gerven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07092" title="Abstract">arXiv:2211.07092</a> (replaced) [<a href="/pdf/2211.07092" title="Download PDF">pdf</a>, <a href="/ps/2211.07092" title="Download PostScript">ps</a>, <a href="/format/2211.07092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Estimation of Controlled Markov Chains: Minimaxity and Sample  Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Banerjee%2C+I">Imon Banerjee</a>, 
<a href="/search/stat?searchtype=author&query=Honnappa%2C+H">Harsha Honnappa</a>, 
<a href="/search/stat?searchtype=author&query=Rao%2C+V">Vinayak Rao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 71 pages, 23 main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09949" title="Abstract">arXiv:2211.09949</a> (replaced) [<a href="/pdf/2211.09949" title="Download PDF">pdf</a>, <a href="/format/2211.09949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressing Transformer-based self-supervised models for speech  processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tzu-Quan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tsung-Huan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chun-Yao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kuang-Ming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tzu-hsun Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Audio, Speech and Language Processing (TASLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15223" title="Abstract">arXiv:2211.15223</a> (replaced) [<a href="/pdf/2211.15223" title="Download PDF">pdf</a>, <a href="/ps/2211.15223" title="Download PostScript">ps</a>, <a href="/format/2211.15223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gamma-convergence of a nonlocal perimeter arising in adversarial machine  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bungert%2C+L">Leon Bungert</a>, 
<a href="/search/math?searchtype=author&query=Stinson%2C+K">Kerrek Stinson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed typos, added new isotropic-anisotropic decomposition formula for limit perimeter
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16384" title="Abstract">arXiv:2211.16384</a> (replaced) [<a href="/pdf/2211.16384" title="Download PDF">pdf</a>, <a href="/format/2211.16384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Estimation with Increased Precision for Elliptic and  Hypo-elliptic Diffusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Iguchi%2C+Y">Yuga Iguchi</a>, 
<a href="/search/stat?searchtype=author&query=Beskos%2C+A">Alexandros Beskos</a>, 
<a href="/search/stat?searchtype=author&query=Graham%2C+M+M">Matthew M. Graham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00403" title="Abstract">arXiv:2212.00403</a> (replaced) [<a href="/pdf/2212.00403" title="Download PDF">pdf</a>, <a href="/format/2212.00403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A method of moments estimator for interacting particle systems and their  mean field limit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pavliotis%2C+G+A">Grigorios A. Pavliotis</a>, 
<a href="/search/math?searchtype=author&query=Zanoni%2C+A">Andrea Zanoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09049" title="Abstract">arXiv:2212.09049</a> (replaced) [<a href="/pdf/2212.09049" title="Download PDF">pdf</a>, <a href="/format/2212.09049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perfectly Covert Communication with a Reflective Panel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elimelech%2C+O">Or Elimelech</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Asaf Cohen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01642" title="Abstract">arXiv:2301.01642</a> (replaced) [<a href="/pdf/2301.01642" title="Download PDF">pdf</a>, <a href="/format/2301.01642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CI-GNN: A Granger Causality-Inspired Graph Neural Network for  Interpretable Brain Network-Based Psychiatric Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zheng%2C+K">Kaizhong Zheng</a>, 
<a href="/search/stat?searchtype=author&query=Yu%2C+S">Shujian Yu</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+B">Badong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript ia accepted by Neural Networks, The source code and implementation details are freely available at GitHub repository (<a href="https://github.com/ZKZ-Brain/CI-GNN/">this https URL</a>). 45 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06166" title="Abstract">arXiv:2301.06166</a> (replaced) [<a href="/pdf/2301.06166" title="Download PDF">pdf</a>, <a href="/ps/2301.06166" title="Download PostScript">ps</a>, <a href="/format/2301.06166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell-Free Massive MIMO in O-RAN: Energy-Aware Joint Orchestration of  Cloud, Fronthaul, and Radio Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Demir%2C+%C3%96+T">&#xd6;zlem Tu&#x11f;fe Demir</a>, 
<a href="/search/eess?searchtype=author&query=Masoudi%2C+M">Meysam Masoudi</a>, 
<a href="/search/eess?searchtype=author&query=Bj%C3%B6rnson%2C+E">Emil Bj&#xf6;rnson</a>, 
<a href="/search/eess?searchtype=author&query=Cavdar%2C+C">Cicek Cavdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures, 3 tables, published in IEEE Journal on Selected Areas in Communications, vol. 42, no. 2, pp. 356-372, Feb. 2024, doi: 10.1109/JSAC.2023.3336187. arXiv admin note: text overlap with <a href="/abs/2202.09254">arXiv:2202.09254</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08897" title="Abstract">arXiv:2301.08897</a> (replaced) [<a href="/pdf/2301.08897" title="Download PDF">pdf</a>, <a href="/format/2301.08897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScaDLES: Scalable Deep Learning over Streaming data at the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+S">Sahil Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Swany%2C+M">Martin Swany</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Tyagi, S., &amp; Swany, M. (2022). ScaDLES: Scalable Deep Learning
  over Streaming data at the Edge. 2022 IEEE International Conference on Big
  Data (Big Data), 2113-2122
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10594" title="Abstract">arXiv:2301.10594</a> (replaced) [<a href="/pdf/2301.10594" title="Download PDF">pdf</a>, <a href="/ps/2301.10594" title="Download PostScript">ps</a>, <a href="/format/2301.10594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Discussion on Nonlinear Quadratic Control and Sontag&#x27;s Formula
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lohmann%2C+B">Boris Lohmann</a>, 
<a href="/search/math?searchtype=author&query=Bongard%2C+J">Joscha Bongard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages; Technical Report TRAC-8, Number 1. Some details added to Appendix 1, results unchanged
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12132" title="Abstract">arXiv:2301.12132</a> (replaced) [<a href="/pdf/2301.12132" title="Download PDF">pdf</a>, <a href="/format/2301.12132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoPEFT: Automatic Configuration Search for Parameter-Efficient  Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Han Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xingchen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Vuli%C4%87%2C+I">Ivan Vuli&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Korhonen%2C+A">Anna Korhonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TACL; pre-MIT Press publication version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13359" title="Abstract">arXiv:2301.13359</a> (replaced) [<a href="/pdf/2301.13359" title="Download PDF">pdf</a>, <a href="/format/2301.13359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Guoyang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinbao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiayi Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+F">Feng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01928" title="Abstract">arXiv:2302.01928</a> (replaced) [<a href="/pdf/2302.01928" title="Download PDF">pdf</a>, <a href="/format/2302.01928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Robot and Human Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bobu%2C+A">Andreea Bobu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+A">Andi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+J">Julie Shah</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A+D">Anca D. Dragan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02759" title="Abstract">arXiv:2302.02759</a> (replaced) [<a href="/pdf/2302.02759" title="Download PDF">pdf</a>, <a href="/ps/2302.02759" title="Download PostScript">ps</a>, <a href="/format/2302.02759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Reddit Users with Depression Using a Hybrid Neural Network  SBERT-CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ren Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Sunyang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+N">Nansu Zong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongfang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Ming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02894" title="Abstract">arXiv:2302.02894</a> (replaced) [<a href="/pdf/2302.02894" title="Download PDF">pdf</a>, <a href="/ps/2302.02894" title="Download PostScript">ps</a>, <a href="/format/2302.02894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral bounds for certain special type of matrix rational functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hadimani%2C+S">Shrinath Hadimani</a>, 
<a href="/search/math?searchtype=author&query=Basavaraju%2C+P">Pallavi Basavaraju</a>, 
<a href="/search/math?searchtype=author&query=Jayaraman%2C+S">Sachindranath Jayaraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Numerical examples section is modified. The order of the authors has been changed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Spectral Theory (math.SP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04914" title="Abstract">arXiv:2302.04914</a> (replaced) [<a href="/pdf/2302.04914" title="Download PDF">pdf</a>, <a href="/format/2302.04914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible, Model-Agnostic Method for Materials Data Extraction from Text  Using General Purpose Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Polak%2C+M+P">Maciej P. Polak</a>, 
<a href="/search/cond-mat?searchtype=author&query=Modi%2C+S">Shrey Modi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Latosinska%2C+A">Anna Latosinska</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+J">Jinming Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+C">Ching-Wen Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+S">Shanonan Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hazra%2C+A+D">Ayan Deep Hazra</a>, 
<a href="/search/cond-mat?searchtype=author&query=Morgan%2C+D">Dane Morgan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06582" title="Abstract">arXiv:2302.06582</a> (replaced) [<a href="/pdf/2302.06582" title="Download PDF">pdf</a>, <a href="/ps/2302.06582" title="Download PostScript">ps</a>, <a href="/format/2302.06582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Convex Hull Cheapest Insertion Heuristic for the Non-Euclidean TSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goutham%2C+M">Mithun Goutham</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+M">Meghna Menon</a>, 
<a href="/search/cs?searchtype=author&query=Garrow%2C+S">Sarah Garrow</a>, 
<a href="/search/cs?searchtype=author&query=Stockar%2C+S">Stephanie Stockar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript submitted 27 January 2024 to the Operations Research Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08957" title="Abstract">arXiv:2302.08957</a> (replaced) [<a href="/pdf/2302.08957" title="Download PDF">pdf</a>, <a href="/format/2302.08957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Like a Good Nearest Neighbor: Practical Content Moderation and Text  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bates%2C+L">Luke Bates</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10096" title="Abstract">arXiv:2302.10096</a> (replaced) [<a href="/pdf/2302.10096" title="Download PDF">pdf</a>, <a href="/ps/2302.10096" title="Download PostScript">ps</a>, <a href="/format/2302.10096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anti%C4%87%2C+C">Christian Anti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11529" title="Abstract">arXiv:2302.11529</a> (replaced) [<a href="/pdf/2302.11529" title="Download PDF">pdf</a>, <a href="/format/2302.11529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pfeiffer%2C+J">Jonas Pfeiffer</a>, 
<a href="/search/cs?searchtype=author&query=Ruder%2C+S">Sebastian Ruder</a>, 
<a href="/search/cs?searchtype=author&query=Vuli%C4%87%2C+I">Ivan Vuli&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Ponti%2C+E+M">Edoardo Maria Ponti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12094" title="Abstract">arXiv:2302.12094</a> (replaced) [<a href="/pdf/2302.12094" title="Download PDF">pdf</a>, <a href="/format/2302.12094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating explainability for machine learning predictions using  model-agnostic metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munoz%2C+C">Cristian Munoz</a>, 
<a href="/search/cs?searchtype=author&query=da+Costa%2C+K">Kleyton da Costa</a>, 
<a href="/search/cs?searchtype=author&query=Modenesi%2C+B">Bernardo Modenesi</a>, 
<a href="/search/cs?searchtype=author&query=Koshiyama%2C+A">Adriano Koshiyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00223" title="Abstract">arXiv:2303.00223</a> (replaced) [<a href="/pdf/2303.00223" title="Download PDF">pdf</a>, <a href="/ps/2303.00223" title="Download PostScript">ps</a>, <a href="/format/2303.00223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meal-time Detection by Means of Long Periods Blood Glucose Level  Monitoring via IoT Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+H+M">Hassan M. Ahmed</a> (1), 
<a href="/search/cs?searchtype=author&query=Maraoui%2C+S">Souhail Maraoui</a> (1), 
<a href="/search/cs?searchtype=author&query=Sadek%2C+M+A+E">Muhammed Abd Elnaby Sadek</a> (1), 
<a href="/search/cs?searchtype=author&query=Abdulrazak%2C+B">Bessam Abdulrazak</a> (1,2), 
<a href="/search/cs?searchtype=author&query=Vandenberghe%2C+C">Camille Vandenberghe</a> (2,3), 
<a href="/search/cs?searchtype=author&query=Cunnane%2C+S+C">Stephen C. Cunnane</a> (2,3), 
<a href="/search/cs?searchtype=author&query=Blanchet%2C+F+G">F. Guillaume Blanchet</a> (2, 4,5,6) ((1) Ambient Intelligence Laboratory (AMI-Lab), Departement d&#x27;informatique, Facult&#x27;e des sciences, Universit&#x27;e de Sherbrooke, Sherbrooke, QC J1K 2R1 (2) Research Centre on Aging, Sherbrooke, QC, J1H 4C4 (3) Brain Research Team, Universit&#x27;e de Sherbrooke, Sherbrooke, QC, J1H4C4 (4) Departement de Biologie, Facult&#x27;e des sciences, Universit&#x27;e de Sherbrooke, Sherbrooke, QC J1K 2R1, Canada (5) Departement de Math&#x27;ematiques, Facult&#x27;e des sciences, Universit&#x27;e de Sherbrooke, Sherbrooke, QC J1K 2R1, Canada (6) Departement des sciences de la sant&#x27;e communautaire, Facult&#x27;e de m&#x27;edecine et des sciences de la sant&#x27;e, Universit&#x27;e de Sherbrooke, Sherbrooke, QC J1K 2R1, Canada)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01310" title="Abstract">arXiv:2303.01310</a> (replaced) [<a href="/pdf/2303.01310" title="Download PDF">pdf</a>, <a href="/format/2303.01310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Language-Conditioned Deformable Object Manipulation with Graph  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yuhong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+K">Kai Mo</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+C">Chongkun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqian Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> has been accepted by ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04488" title="Abstract">arXiv:2303.04488</a> (replaced) [<a href="/pdf/2303.04488" title="Download PDF">pdf</a>, <a href="/format/2303.04488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Magnushammer: A Transformer-based Approach to Premise Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miku%C5%82a%2C+M">Maciej Miku&#x142;a</a>, 
<a href="/search/cs?searchtype=author&query=Antoniak%2C+S">Szymon Antoniak</a>, 
<a href="/search/cs?searchtype=author&query=Tworkowski%2C+S">Szymon Tworkowski</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+A+Q">Albert Qiaochu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+P">Jin Peng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Szegedy%2C+C">Christian Szegedy</a>, 
<a href="/search/cs?searchtype=author&query=Kuci%C5%84ski%2C+%C5%81">&#x141;ukasz Kuci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Mi%C5%82o%C5%9B%2C+P">Piotr Mi&#x142;o&#x15b;</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuhuai Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08583" title="Abstract">arXiv:2303.08583</a> (replaced) [<a href="/pdf/2303.08583" title="Download PDF">pdf</a>, <a href="/format/2303.08583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> F-IVM: Analytics over Relational Databases under Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kara%2C+A">Ahmet Kara</a>, 
<a href="/search/cs?searchtype=author&query=Nikolic%2C+M">Milos Nikolic</a>, 
<a href="/search/cs?searchtype=author&query=Olteanu%2C+D">Dan Olteanu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haozhe Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08895" title="Abstract">arXiv:2303.08895</a> (replaced) [<a href="/pdf/2303.08895" title="Download PDF">pdf</a>, <a href="/format/2303.08895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rollout-Based Charging Strategy for Electric Trucks with  Hours-of-Service Regulations (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bai%2C+T">Ting Bai</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuchao Li</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%A5rtensson%2C+J">Jonas M&#xe5;rtensson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper published in IEEE Control Systems Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12861" title="Abstract">arXiv:2303.12861</a> (replaced) [<a href="/pdf/2303.12861" title="Download PDF">pdf</a>, <a href="/format/2303.12861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Diffusion Model-based Sparse-view Cone-beam Breast CT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xia%2C+W">Wenjun Xia</a>, 
<a href="/search/eess?searchtype=author&query=Tseng%2C+H+W">Hsin Wu Tseng</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+C">Chuang Niu</a>, 
<a href="/search/eess?searchtype=author&query=Cong%2C+W">Wenxiang Cong</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiaohua Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shaohua Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ning%2C+R">Ruola Ning</a>, 
<a href="/search/eess?searchtype=author&query=Vedantham%2C+S">Srinivasan Vedantham</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Ge Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Biological Physics (physics.bio-ph)

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14703" title="Abstract">arXiv:2303.14703</a> (replaced) [<a href="/pdf/2303.14703" title="Download PDF">pdf</a>, <a href="/format/2303.14703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Interplay Between Colorectal Cancer Subtypes Genomic  Variants and Cellular Morphology: A Deep-Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hezi%2C+H">Hadar Hezi</a>, 
<a href="/search/cs?searchtype=author&query=Shats%2C+D">Daniel Shats</a>, 
<a href="/search/cs?searchtype=author&query=Gurevich%2C+D">Daniel Gurevich</a>, 
<a href="/search/cs?searchtype=author&query=Maruvka%2C+Y+E">Yosef E. Maruvka</a>, 
<a href="/search/cs?searchtype=author&query=Freiman%2C+M">Moti Freiman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14897" title="Abstract">arXiv:2303.14897</a> (replaced) [<a href="/pdf/2303.14897" title="Download PDF">pdf</a>, <a href="/format/2303.14897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seer: Language Instructed Video Prediction with Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xianfan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chuan Wen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Weirui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiaming Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15198" title="Abstract">arXiv:2303.15198</a> (replaced) [<a href="/pdf/2303.15198" title="Download PDF">pdf</a>, <a href="/format/2303.15198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Deblurring by Exploring In-depth Properties of Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Pengwei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiayi Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accept by IEEE Transactions on Neural Networks and Learning Systems
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Neural Networks and Learning Systems 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00652" title="Abstract">arXiv:2304.00652</a> (replaced) [<a href="/pdf/2304.00652" title="Download PDF">pdf</a>, <a href="/format/2304.00652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meeting effectiveness and inclusiveness: large-scale measurement,  identification of key features, and prediction in real-world remote meetings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseinkashi%2C+Y">Yasaman Hosseinkashi</a>, 
<a href="/search/cs?searchtype=author&query=Tankelevitch%2C+L">Lev Tankelevitch</a>, 
<a href="/search/cs?searchtype=author&query=Pool%2C+J">Jamie Pool</a>, 
<a href="/search/cs?searchtype=author&query=Cutler%2C+R">Ross Cutler</a>, 
<a href="/search/cs?searchtype=author&query=Madan%2C+C">Chinmaya Madan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01295" title="Abstract">arXiv:2304.01295</a> (replaced) [<a href="/pdf/2304.01295" title="Download PDF">pdf</a>, <a href="/format/2304.01295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Aligned Cross-Lingual Transfer Learning for Conversational  Tasks using Prompt-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+L">Lifu Tu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+J">Jin Qu</a>, 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+S">Semih Yavuz</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yingbo Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Finding of the ACL: EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01385" title="Abstract">arXiv:2304.01385</a> (replaced) [<a href="/pdf/2304.01385" title="Download PDF">pdf</a>, <a href="/ps/2304.01385" title="Download PostScript">ps</a>, <a href="/format/2304.01385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Should the Timing of Inspections be Predictable?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Ball%2C+I">Ian Ball</a>, 
<a href="/search/econ?searchtype=author&query=Knoepfle%2C+J">Jan Knoepfle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03696" title="Abstract">arXiv:2304.03696</a> (replaced) [<a href="/pdf/2304.03696" title="Download PDF">pdf</a>, <a href="/format/2304.03696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOPA: Modular Object Navigation with PointGoal Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raychaudhuri%2C+S">Sonia Raychaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Campari%2C+T">Tommaso Campari</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+U">Unnat Jain</a>, 
<a href="/search/cs?searchtype=author&query=Savva%2C+M">Manolis Savva</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+A+X">Angel X. Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04129" title="Abstract">arXiv:2304.04129</a> (replaced) [<a href="/pdf/2304.04129" title="Download PDF">pdf</a>, <a href="/format/2304.04129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auditing Elon Musk&#x27;s Impact on Hate Speech and Bots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hickey%2C+D">Daniel Hickey</a>, 
<a href="/search/cs?searchtype=author&query=Schmitz%2C+M">Matheus Schmitz</a>, 
<a href="/search/cs?searchtype=author&query=Fessler%2C+D">Daniel Fessler</a>, 
<a href="/search/cs?searchtype=author&query=Smaldino%2C+P">Paul Smaldino</a>, 
<a href="/search/cs?searchtype=author&query=Muric%2C+G">Goran Muric</a>, 
<a href="/search/cs?searchtype=author&query=Burghardt%2C+K">Keith Burghardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 figures, 1 table. In Proceedings of the 17th International AAAI Conference on Web and Social Media (2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Hickey, D., Schmitz, M., Fessler, D., Smaldino, P. E., Muric, G.,
  &amp; Burghardt, K. (2023). Auditing Elon Musk's Impact on Hate Speech and Bots.
  Proceedings of the International AAAI Conference on Web and Social Media,
  17(1), 1133-1137
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04822" title="Abstract">arXiv:2304.04822</a> (replaced) [<a href="/pdf/2304.04822" title="Download PDF">pdf</a>, <a href="/format/2304.04822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Body Exposure (RoBE): A Graph-based Dynamics Modeling Approach to  Manipulating Blankets over People
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puthuveetil%2C+K">Kavya Puthuveetil</a>, 
<a href="/search/cs?searchtype=author&query=Wald%2C+S">Sasha Wald</a>, 
<a href="/search/cs?searchtype=author&query=Pusalkar%2C+A">Atharva Pusalkar</a>, 
<a href="/search/cs?searchtype=author&query=Karnati%2C+P">Pratyusha Karnati</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+Z">Zackory Erickson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published in IEEE Robotics and Automation Letters, 8 pages, 9 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05482" title="Abstract">arXiv:2304.05482</a> (replaced) [<a href="/pdf/2304.05482" title="Download PDF">pdf</a>, <a href="/format/2304.05482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Pathology: A Survey Review and The Way Forward
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hosseini%2C+M+S">Mahdi S. Hosseini</a>, 
<a href="/search/eess?searchtype=author&query=Bejnordi%2C+B+E">Babak Ehteshami Bejnordi</a>, 
<a href="/search/eess?searchtype=author&query=Trinh%2C+V+Q">Vincent Quoc-Huy Trinh</a>, 
<a href="/search/eess?searchtype=author&query=Hasan%2C+D">Danial Hasan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xingwen Li</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+T">Taehyo Kim</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Haochen Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+T">Theodore Wu</a>, 
<a href="/search/eess?searchtype=author&query=Chinniah%2C+K">Kajanan Chinniah</a>, 
<a href="/search/eess?searchtype=author&query=Maghsoudlou%2C+S">Sina Maghsoudlou</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+R">Ryan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+S">Stephen Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+J">Jiadai Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Chan%2C+L">Lyndon Chan</a>, 
<a href="/search/eess?searchtype=author&query=Khaki%2C+S">Samir Khaki</a>, 
<a href="/search/eess?searchtype=author&query=Buin%2C+A">Andrei Buin</a>, 
<a href="/search/eess?searchtype=author&query=Chaji%2C+F">Fatemeh Chaji</a>, 
<a href="/search/eess?searchtype=author&query=Salehi%2C+A">Ala Salehi</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+B+N">Bich Ngoc Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Samaras%2C+D">Dimitris Samaras</a>, 
<a href="/search/eess?searchtype=author&query=Plataniotis%2C+K+N">Konstantinos N. Plataniotis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Elsevier Journal of Pathology Informatics (JPI) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08320" title="Abstract">arXiv:2304.08320</a> (replaced) [<a href="/pdf/2304.08320" title="Download PDF">pdf</a>, <a href="/ps/2304.08320" title="Download PostScript">ps</a>, <a href="/format/2304.08320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Fast-Converged Deep Reinforcement Learning for Optimal Dispatch of  Large-Scale Power Systems under Transient Security Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiao%2C+T">Tannan Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Ying Chen</a>, 
<a href="/search/eess?searchtype=author&query=Diao%2C+H">Han Diao</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+S">Shaowei Huang</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+C">Chen Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08767" title="Abstract">arXiv:2304.08767</a> (replaced) [<a href="/pdf/2304.08767" title="Download PDF">pdf</a>, <a href="/format/2304.08767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Language Model Based Textual Adversarial Example Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaomei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Q">Qi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xufei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengshan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L+Y">Leo Yu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08845" title="Abstract">arXiv:2304.08845</a> (replaced) [<a href="/pdf/2304.08845" title="Download PDF">pdf</a>, <a href="/format/2304.08845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feasible Policy Iteration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhilong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jingliang Duan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingjing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xianyuan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya-Qin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11609" title="Abstract">arXiv:2304.11609</a> (replaced) [<a href="/pdf/2304.11609" title="Download PDF">pdf</a>, <a href="/format/2304.11609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PiClick: Picking the desired mask in click-based interactive  segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Cilin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haochen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaolong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+G">Guoliang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Gavves%2C+E">Efstratios Gavves</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12639" title="Abstract">arXiv:2304.12639</a> (replaced) [<a href="/pdf/2304.12639" title="Download PDF">pdf</a>, <a href="/format/2304.12639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Change detection needs change information: improving deep 3D point cloud  change detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+G%C3%A9lis%2C+I">Iris de G&#xe9;lis</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Corpetti%2C+T">Thomas Corpetti</a> (3), 
<a href="/search/cs?searchtype=author&query=Lef%C3%A8vre%2C+S">S&#xe9;bastien Lef&#xe8;vre</a> (2) ((1) Magellium, (2) Institut de Recherche en Informatique et Syst&#xe8;mes Al&#xe9;atoires IRISA - UMR 6074 - Universit&#xe9; Bretagne Sud, (3) Littoral - Environnement - T&#xe9;l&#xe9;d&#xe9;tection - G&#xe9;omatique LETG - UMR 6554 - Universit&#xe9; Rennes 2)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13383" title="Abstract">arXiv:2304.13383</a> (replaced) [<a href="/pdf/2304.13383" title="Download PDF">pdf</a>, <a href="/format/2304.13383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> N$\text{A}^\text{2}$Q: Neural Attention Additive Model for Interpretable  Multi-Agent Q-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zichuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuanyang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunlin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Conference on Machine Learning (ICML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14402" title="Abstract">arXiv:2304.14402</a> (replaced) [<a href="/pdf/2304.14402" title="Download PDF">pdf</a>, <a href="/format/2304.14402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale  Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Waheed%2C+A">Abdul Waheed</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Abdul-Mageed%2C+M">Muhammad Abdul-Mageed</a>, 
<a href="/search/cs?searchtype=author&query=Aji%2C+A+F">Alham Fikri Aji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures, 17 tables, accepted by EACL2024 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01611" title="Abstract">arXiv:2305.01611</a> (replaced) [<a href="/pdf/2305.01611" title="Download PDF">pdf</a>, <a href="/format/2305.01611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoColor: Learned Light Power Control for Multi-Color Holograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yicheng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Kavakl%C4%B1%2C+K">Koray Kavakl&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Urey%2C+H">Hakan Urey</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ak%C5%9Fit%2C+K">Kaan Ak&#x15f;it</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, SPIE VR|AR|MR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02961" title="Abstract">arXiv:2305.02961</a> (replaced) [<a href="/pdf/2305.02961" title="Download PDF">pdf</a>, <a href="/ps/2305.02961" title="Download PostScript">ps</a>, <a href="/format/2305.02961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FUSegNet: A Deep Convolutional Neural Network for Foot Ulcer  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhar%2C+M+K">Mrinal Kanti Dhar</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Taiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+Y">Yash Patel</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+S">Sandeep Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zeyun Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03686" title="Abstract">arXiv:2305.03686</a> (replaced) [<a href="/pdf/2305.03686" title="Download PDF">pdf</a>, <a href="/format/2305.03686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Preimage Under-Approximation for Neural Networks (Full Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kwiatkowska%2C+M">Marta Kwiatkowska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03939" title="Abstract">arXiv:2305.03939</a> (replaced) [<a href="/pdf/2305.03939" title="Download PDF">pdf</a>, <a href="/ps/2305.03939" title="Download PostScript">ps</a>, <a href="/format/2305.03939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An adaptive ANOVA stochastic Galerkin method for partial differential  equations with high-dimensional random inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+G">Guanjie Wang</a>, 
<a href="/search/math?searchtype=author&query=Sahu%2C+S">Smita Sahu</a>, 
<a href="/search/math?searchtype=author&query=Liao%2C+Q">Qifeng Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05097" title="Abstract">arXiv:2305.05097</a> (replaced) [<a href="/pdf/2305.05097" title="Download PDF">pdf</a>, <a href="/format/2305.05097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Repellent Random Walks on General Graphs -- Achieving Minimal  Sampling Variance via Nonlinear Markov Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Doshi%2C+V">Vishwaraj Doshi</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/math?searchtype=author&query=Eun%2C+D+Y">Do Young Eun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Selected for oral presentation at ICML 2023. Recipient of Outstanding Paper award
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05398" title="Abstract">arXiv:2305.05398</a> (replaced) [<a href="/pdf/2305.05398" title="Download PDF">pdf</a>, <a href="/ps/2305.05398" title="Download PostScript">ps</a>, <a href="/format/2305.05398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach for Approximating 2-Edge-Connected Spanning Subgraph  and 2-Vertex-Connected Spanning Subgraph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87ivril%2C+A">Ali &#xc7;ivril</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, added the two separate improvement operations for 2-VCSS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05499" title="Abstract">arXiv:2305.05499</a> (replaced) [<a href="/pdf/2305.05499" title="Download PDF">pdf</a>, <a href="/format/2305.05499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects of Real-Life Traffic Sign Alteration on YOLOv7- an Object  Recognition Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riya%2C+F+F">Farhin Farhad Riya</a>, 
<a href="/search/cs?searchtype=author&query=Hoque%2C+S">Shahinul Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Onim%2C+M+S+H">Md Saif Hassan Onim</a>, 
<a href="/search/cs?searchtype=author&query=Michaud%2C+E">Edward Michaud</a>, 
<a href="/search/cs?searchtype=author&query=Begoli%2C+E">Edmon Begoli</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J+S">Jinyuan Stella Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05644" title="Abstract">arXiv:2305.05644</a> (replaced) [<a href="/pdf/2305.05644" title="Download PDF">pdf</a>, <a href="/format/2305.05644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Building the Federated GPT: Federated Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Vahidian%2C+S">Saeed Vahidian</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+M">Martin Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yufan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://github.com/JayZhang42/FederatedGPT-Shepherd">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07984" title="Abstract">arXiv:2305.07984</a> (replaced) [<a href="/pdf/2305.07984" title="Download PDF">pdf</a>, <a href="/format/2305.07984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCENE: Self-Labeled Counterfactuals for Extrapolating to Negative  Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Deqing Fu</a>, 
<a href="/search/cs?searchtype=author&query=Godbole%2C+A">Ameya Godbole</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Robin Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09452" title="Abstract">arXiv:2305.09452</a> (replaced) [<a href="/pdf/2305.09452" title="Download PDF">pdf</a>, <a href="/ps/2305.09452" title="Download PostScript">ps</a>, <a href="/format/2305.09452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A sequential transit network design algorithm with optimal learning  under correlated beliefs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+G">Gyugeun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Chow%2C+J+Y+J">Joseph Y. J. Chow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10163" title="Abstract">arXiv:2305.10163</a> (replaced) [<a href="/pdf/2305.10163" title="Download PDF">pdf</a>, <a href="/format/2305.10163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Leverage External Knowledge to Extend Clinical  Insight Beyond Language Boundaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiageng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zhaopeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10565" title="Abstract">arXiv:2305.10565</a> (replaced) [<a href="/pdf/2305.10565" title="Download PDF">pdf</a>, <a href="/format/2305.10565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measurement Based Evaluation and Mitigation of Flood Attacks on a LAN  Test-Bed
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasereddin%2C+M">Mohammed Nasereddin</a>, 
<a href="/search/cs?searchtype=author&query=Nak%C4%B1p%2C+M">Mert Nak&#x131;p</a>, 
<a href="/search/cs?searchtype=author&query=Gelenbe%2C+E">Erol Gelenbe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10857" title="Abstract">arXiv:2305.10857</a> (replaced) [<a href="/pdf/2305.10857" title="Download PDF">pdf</a>, <a href="/format/2305.10857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Space Planning for Multi-Object Manipulation with  Environment-Aware Relational Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+N+C">Nichols Crawford Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Conkey%2C+A">Adam Conkey</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hermans%2C+T">Tucker Hermans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE Transactions on Robotics (T-RO). arXiv admin note: text overlap with <a href="/abs/2209.11943">arXiv:2209.11943</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11467" title="Abstract">arXiv:2305.11467</a> (replaced) [<a href="/pdf/2305.11467" title="Download PDF">pdf</a>, <a href="/format/2305.11467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Sequence Descriptor based on Spatio-Temporal Attention for  Visual Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junqiao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fenglin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yingfeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+G">Gengxuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+W">Wenjie Mu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tiantian Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, published to RA-L
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11789" title="Abstract">arXiv:2305.11789</a> (replaced) [<a href="/pdf/2305.11789" title="Download PDF">pdf</a>, <a href="/format/2305.11789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving NLP Problems through Human-System Collaboration: A  Discussion-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+M">Masahiro Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>, 
<a href="/search/cs?searchtype=author&query=Okazaki%2C+N">Naoaki Okazaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12201" title="Abstract">arXiv:2305.12201</a> (replaced) [<a href="/pdf/2305.12201" title="Download PDF">pdf</a>, <a href="/format/2305.12201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraVAC: Adaptive Compression for Communication-Efficient Distributed DL  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+S">Sahil Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Swany%2C+M">Martin Swany</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Tyagi, S., &amp; Swany, M. (2023). GraVAC: Adaptive Compression for
  Communication-Efficient Distributed DL Training. 2023 IEEE 16th International
  Conference on Cloud Computing (CLOUD), 319-329
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12924" title="Abstract">arXiv:2305.12924</a> (replaced) [<a href="/pdf/2305.12924" title="Download PDF">pdf</a>, <a href="/format/2305.12924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EnCore: Fine-Grained Entity Typing by Pre-Training Entity Encoders on  Coreference Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mtumbuka%2C+F">Frank Mtumbuka</a>, 
<a href="/search/cs?searchtype=author&query=Schockaert%2C+S">Steven Schockaert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12971" title="Abstract">arXiv:2305.12971</a> (replaced) [<a href="/pdf/2305.12971" title="Download PDF">pdf</a>, <a href="/format/2305.12971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Cellular Automata Can Respond to Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stovold%2C+J">James Stovold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to main track at ALIFE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13521" title="Abstract">arXiv:2305.13521</a> (replaced) [<a href="/pdf/2305.13521" title="Download PDF">pdf</a>, <a href="/format/2305.13521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CEO: Corpus-based Open-Domain Event Ontology Induction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianshu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13684" title="Abstract">arXiv:2305.13684</a> (replaced) [<a href="/pdf/2305.13684" title="Download PDF">pdf</a>, <a href="/format/2305.13684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mPLM-Sim: Better Cross-Lingual Similarity and Transfer in Multilingual  Pretrained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Peiqin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chengzhi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+A+F+T">Andr&#xe9; F. T. Martins</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtze%2C+H">Hinrich Sch&#xfc;tze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15645" title="Abstract">arXiv:2305.15645</a> (replaced) [<a href="/pdf/2305.15645" title="Download PDF">pdf</a>, <a href="/format/2305.15645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConvGQR: Generative Query Reformulation for Conversational Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+F">Fengran Mo</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+K">Kelong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yutao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yihong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaiyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jian-Yun Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16128" title="Abstract">arXiv:2305.16128</a> (replaced) [<a href="/pdf/2305.16128" title="Download PDF">pdf</a>, <a href="/format/2305.16128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Give Me More Details: Improving Fact-Checking with Latent Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junzhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhijiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed minor issues, 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16304" title="Abstract">arXiv:2305.16304</a> (replaced) [<a href="/pdf/2305.16304" title="Download PDF">pdf</a>, <a href="/format/2305.16304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Candidate Set Re-ranking for Composed Image Retrieval with Dual  Multi-modal Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Teney%2C+D">Damien Teney</a>, 
<a href="/search/cs?searchtype=author&query=Gould%2C+S">Stephen Gould</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at TMLR, 19 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17891" title="Abstract">arXiv:2305.17891</a> (replaced) [<a href="/pdf/2305.17891" title="Download PDF">pdf</a>, <a href="/format/2305.17891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Rise of AI Language Pathologists: Exploring Two-level Prompt  Learning for Few-shot Weakly-supervised Whole Slide Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Linhao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaoyuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+K">Kexue Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Manning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhijian Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19128" title="Abstract">arXiv:2305.19128</a> (replaced) [<a href="/pdf/2305.19128" title="Download PDF">pdf</a>, <a href="/ps/2305.19128" title="Download PostScript">ps</a>, <a href="/format/2305.19128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniform relations between the Gauss-Legendre nodes and weights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pouso%2C+%C3%93+L">&#xd3;scar L&#xf3;pez Pouso</a>, 
<a href="/search/math?searchtype=author&query=Segura%2C+J">Javier Segura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Section 3.1 has been added to this new version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Classical Analysis and ODEs (math.CA)

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19659" title="Abstract">arXiv:2305.19659</a> (replaced) [<a href="/pdf/2305.19659" title="Download PDF">pdf</a>, <a href="/format/2305.19659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Expressivity of Graph Neural Networks using Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Anant Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Shrutimoy Das</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Shubhajit Roy</a>, 
<a href="/search/cs?searchtype=author&query=Maity%2C+B">Binita Maity</a>, 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+A">Anirban Dasgupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00168" title="Abstract">arXiv:2306.00168</a> (replaced) [<a href="/pdf/2306.00168" title="Download PDF">pdf</a>, <a href="/format/2306.00168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the Robustness of NLP Models to Domain Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calderon%2C+N">Nitay Calderon</a>, 
<a href="/search/cs?searchtype=author&query=Porat%2C+N">Naveh Porat</a>, 
<a href="/search/cs?searchtype=author&query=Ben-David%2C+E">Eyal Ben-David</a>, 
<a href="/search/cs?searchtype=author&query=Chapanin%2C+A">Alexander Chapanin</a>, 
<a href="/search/cs?searchtype=author&query=Gekhman%2C+Z">Zorik Gekhman</a>, 
<a href="/search/cs?searchtype=author&query=Oved%2C+N">Nadav Oved</a>, 
<a href="/search/cs?searchtype=author&query=Shalumov%2C+V">Vitaly Shalumov</a>, 
<a href="/search/cs?searchtype=author&query=Reichart%2C+R">Roi Reichart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01875" title="Abstract">arXiv:2306.01875</a> (replaced) [<a href="/pdf/2306.01875" title="Download PDF">pdf</a>, <a href="/format/2306.01875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffECG: A Versatile Probabilistic Diffusion Model for ECG Signals  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neifar%2C+N">Nour Neifar</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Hamadou%2C+A">Achraf Ben-Hamadou</a>, 
<a href="/search/cs?searchtype=author&query=Mdhaffar%2C+A">Afef Mdhaffar</a>, 
<a href="/search/cs?searchtype=author&query=Jmaiel%2C+M">Mohamed Jmaiel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Pattern Recognition Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02195" title="Abstract">arXiv:2306.02195</a> (replaced) [<a href="/pdf/2306.02195" title="Download PDF">pdf</a>, <a href="/format/2306.02195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subchromatic numbers of powers of graphs with excluded minors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cort%C3%A9s%2C+P+P">Pedro P. Cort&#xe9;s</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+P">Pankaj Kumar</a>, 
<a href="/search/math?searchtype=author&query=Moore%2C+B">Benjamin Moore</a>, 
<a href="/search/math?searchtype=author&query=de+Mendez%2C+P+O">Patrice Ossona de Mendez</a>, 
<a href="/search/math?searchtype=author&query=Quiroz%2C+D+A">Daniel A. Quiroz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 2 figures, version 2 incorporates referee comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02245" title="Abstract">arXiv:2306.02245</a> (replaced) [<a href="/pdf/2306.02245" title="Download PDF">pdf</a>, <a href="/format/2306.02245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM3D: Zero-Shot 3D Object Detection via Segment Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Dingkang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongcheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhikang Zou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xiaoqing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Science China Information Sciences (SCIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06137" title="Abstract">arXiv:2306.06137</a> (replaced) [<a href="/pdf/2306.06137" title="Download PDF">pdf</a>, <a href="/ps/2306.06137" title="Download PostScript">ps</a>, <a href="/format/2306.06137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensing-Aided Peer-to-Peer Millimeter-Wave Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiangyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+S">Sidong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Malik%2C+S">Shez Malik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06201" title="Abstract">arXiv:2306.06201</a> (replaced) [<a href="/pdf/2306.06201" title="Download PDF">pdf</a>, <a href="/format/2306.06201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Dynamic Programming with Feasibility Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Engelmann%2C+A">Alexander Engelmann</a>, 
<a href="/search/math?searchtype=author&query=Bandeira%2C+M+B">Maisa B. Bandeira</a>, 
<a href="/search/math?searchtype=author&query=Faulwasser%2C+T">Timm Faulwasser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06230" title="Abstract">arXiv:2306.06230</a> (replaced) [<a href="/pdf/2306.06230" title="Download PDF">pdf</a>, <a href="/format/2306.06230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Frameworks for Hyper-Connected Social XRI Immersive Metaverse  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Jie Guan</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+A">Alexis Morris</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Network ( Volume: 37, Issue: 4, July/August 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06397" title="Abstract">arXiv:2306.06397</a> (replaced) [<a href="/pdf/2306.06397" title="Download PDF">pdf</a>, <a href="/format/2306.06397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower-depth programmable linear optical processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Tang%2C+R">Rui Tang</a>, 
<a href="/search/physics?searchtype=author&query=Tanomura%2C+R">Ryota Tanomura</a>, 
<a href="/search/physics?searchtype=author&query=Tanemura%2C+T">Takuo Tanemura</a>, 
<a href="/search/physics?searchtype=author&query=Nakano%2C+Y">Yoshiaki Nakano</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Physical Review Applied 21, 014054 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09189" title="Abstract">arXiv:2306.09189</a> (replaced) [<a href="/pdf/2306.09189" title="Download PDF">pdf</a>, <a href="/format/2306.09189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Resolution Convolutional Neural Networks on Homomorphically  Encrypted Data via Sharding Ciphertexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maloney%2C+V">Vivian Maloney</a>, 
<a href="/search/cs?searchtype=author&query=Obrecht%2C+R+F">Richard F. Obrecht</a>, 
<a href="/search/cs?searchtype=author&query=Saraph%2C+V">Vikram Saraph</a>, 
<a href="/search/cs?searchtype=author&query=Rama%2C+P">Prathibha Rama</a>, 
<a href="/search/cs?searchtype=author&query=Tallaksen%2C+K">Kate Tallaksen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10882" title="Abstract">arXiv:2306.10882</a> (replaced) [<a href="/pdf/2306.10882" title="Download PDF">pdf</a>, <a href="/format/2306.10882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaStop: adaptive statistical testing for sound comparisons of Deep RL  agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+T">Timoth&#xe9;e Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Della+Vecchia%2C+R">Riccardo Della Vecchia</a>, 
<a href="/search/cs?searchtype=author&query=Shilova%2C+A">Alena Shilova</a>, 
<a href="/search/cs?searchtype=author&query=Centa%2C+M+M">Matheus Medeiros Centa</a>, 
<a href="/search/cs?searchtype=author&query=Kohler%2C+H">Hector Kohler</a>, 
<a href="/search/cs?searchtype=author&query=Maillard%2C+O">Odalric-Ambrym Maillard</a>, 
<a href="/search/cs?searchtype=author&query=Preux%2C+P">Philippe Preux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11886" title="Abstract">arXiv:2306.11886</a> (replaced) [<a href="/pdf/2306.11886" title="Download PDF">pdf</a>, <a href="/format/2306.11886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPRINT: Scalable Policy Pre-Training via Language Instruction Relabeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jesse Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pertsch%2C+K">Karl Pertsch</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J+J">Joseph J. Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 18 figures. Published at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12681" title="Abstract">arXiv:2306.12681</a> (replaced) [<a href="/pdf/2306.12681" title="Download PDF">pdf</a>, <a href="/format/2306.12681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One at a Time: Progressive Multi-step Volumetric Probability Learning  for Reliable 3D Scene Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yasheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jingxin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenjun Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15516" title="Abstract">arXiv:2306.15516</a> (replaced) [<a href="/pdf/2306.15516" title="Download PDF">pdf</a>, <a href="/format/2306.15516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A logic-based framework for database repairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fr%C3%B6hlich%2C+N">Nicolas Fr&#xf6;hlich</a>, 
<a href="/search/cs?searchtype=author&query=Meier%2C+A">Arne Meier</a>, 
<a href="/search/cs?searchtype=author&query=Pardal%2C+N">Nina Pardal</a>, 
<a href="/search/cs?searchtype=author&query=Virtema%2C+J">Jonni Virtema</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages + 1 page references + 1 page Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15749" title="Abstract">arXiv:2306.15749</a> (replaced) [<a href="/pdf/2306.15749" title="Download PDF">pdf</a>, <a href="/format/2306.15749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Spike or Not To Spike: A Digital Hardware Perspective on Deep  Learning Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ottati%2C+F">Fabrizio Ottati</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qinyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Brignone%2C+G">Giovanni Brignone</a>, 
<a href="/search/cs?searchtype=author&query=Casu%2C+M+R">Mario R. Casu</a>, 
<a href="/search/cs?searchtype=author&query=Eshraghian%2C+J+K">Jason K. Eshraghian</a>, 
<a href="/search/cs?searchtype=author&query=Lavagno%2C+L">Luciano Lavagno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed error in bio
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16048" title="Abstract">arXiv:2306.16048</a> (replaced) [<a href="/pdf/2306.16048" title="Download PDF">pdf</a>, <a href="/format/2306.16048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Zero-Shot Recognition with Vision-Language Models:  Challenges on Granularity and Specificity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenlin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+T">Tiffany Deng</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+A">Abhay Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanbei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Manchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Favaro%2C+P">Paolo Favaro</a>, 
<a href="/search/cs?searchtype=author&query=Tighe%2C+J">Joseph Tighe</a>, 
<a href="/search/cs?searchtype=author&query=Modolo%2C+D">Davide Modolo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Additional experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00012" title="Abstract">arXiv:2307.00012</a> (replaced) [<a href="/pdf/2307.00012" title="Download PDF">pdf</a>, <a href="/format/2307.00012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlakyFix: Using Large Language Models for Predicting Flaky Test Fix  Categories and Test Code Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fatima%2C+S">Sakina Fatima</a>, 
<a href="/search/cs?searchtype=author&query=Hemmati%2C+H">Hadi Hemmati</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L">Lionel Briand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 16 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00238" title="Abstract">arXiv:2307.00238</a> (replaced) [<a href="/pdf/2307.00238" title="Download PDF">pdf</a>, <a href="/format/2307.00238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Transfer Learning Models in High-Dimensional Linear Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Liu%2C+S+S">Shuo Shuo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01926" title="Abstract">arXiv:2307.01926</a> (replaced) [<a href="/pdf/2307.01926" title="Download PDF">pdf</a>, <a href="/format/2307.01926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Equations of Motion from Superconducting Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Pratt%2C+C+Z">Christian Z. Pratt</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ray%2C+K+J">Kyle J. Ray</a>, 
<a href="/search/cond-mat?searchtype=author&query=Crutchfield%2C+J+P">James P. Crutchfield</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures; <a href="https://csc.ucdavis.edu/~cmg/compmech/pubs/nds.htm">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Emerging Technologies (cs.ET); Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02180" title="Abstract">arXiv:2307.02180</a> (replaced) [<a href="/pdf/2307.02180" title="Download PDF">pdf</a>, <a href="/ps/2307.02180" title="Download PostScript">ps</a>, <a href="/format/2307.02180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Runtime Repeated Recursion Unfolding in CHR: A Just-In-Time Online  Program Optimization Strategy That Can Achieve Super-Linear Speedup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fruehwirth%2C+T">Thom Fruehwirth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Major revision of submission to Journal Fundamenta Informaticae
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Computational Complexity (cs.CC); Performance (cs.PF); Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07788" title="Abstract">arXiv:2307.07788</a> (replaced) [<a href="/e-print/2307.07788" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciding One to One property of Boolean maps: Condition and algorithm in  terms of implicants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sule%2C+V">Virendra Sule</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I need to fix some errors in proofs of theorems that I have noticed. Paper will be replaced as version 2 shortly
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07950" title="Abstract">arXiv:2307.07950</a> (replaced) [<a href="/pdf/2307.07950" title="Download PDF">pdf</a>, <a href="/format/2307.07950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Distributed ML Training via Selective Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+S">Sahil Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Swany%2C+M">Martin Swany</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Tyagi, S., &amp; Swany, M. (2023). Accelerating Distributed ML
  Training via Selective Synchronization. 2023 IEEE International Conference on
  Cluster Computing (CLUSTER), 1-12
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08962" title="Abstract">arXiv:2307.08962</a> (replaced) [<a href="/pdf/2307.08962" title="Download PDF">pdf</a>, <a href="/format/2307.08962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REX: Rapid Exploration and eXploitation for AI Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murthy%2C+R">Rithesh Murthy</a>, 
<a href="/search/cs?searchtype=author&query=Heinecke%2C+S">Shelby Heinecke</a>, 
<a href="/search/cs?searchtype=author&query=Niebles%2C+J+C">Juan Carlos Niebles</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Le Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Weiran Yao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yihao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gokul%2C+A">Akash Gokul</a>, 
<a href="/search/cs?searchtype=author&query=Arpit%2C+D">Devansh Arpit</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mui%2C+P">Phil Mui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Savarese%2C+S">Silvio Savarese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09754" title="Abstract">arXiv:2307.09754</a> (replaced) [<a href="/pdf/2307.09754" title="Download PDF">pdf</a>, <a href="/format/2307.09754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProNav: Proprioceptive Traversability Estimation for Legged Robot  Navigation in Outdoor Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elnoor%2C+M">Mohamed Elnoor</a>, 
<a href="/search/cs?searchtype=author&query=Sathyamoorthy%2C+A+J">Adarsh Jagan Sathyamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Weerakoon%2C+K">Kasun Weerakoon</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12896" title="Abstract">arXiv:2307.12896</a> (replaced) [<a href="/pdf/2307.12896" title="Download PDF">pdf</a>, <a href="/format/2307.12896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corrections of Zipf&#x27;s and Heaps&#x27; Laws Derived from Hapax Rate Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C4%99bowski%2C+%C5%81">&#x141;ukasz D&#x119;bowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 61 pages, 29 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13637" title="Abstract">arXiv:2307.13637</a> (replaced) [<a href="/pdf/2307.13637" title="Download PDF">pdf</a>, <a href="/format/2307.13637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insights into Cognitive Engagement: Comparing the Effectiveness of  Game-Based and Video-Based Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharmin%2C+S">Shayla Sharmin</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+A">Arpan Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Sadik%2C+R">Rifat Sadik</a>, 
<a href="/search/cs?searchtype=author&query=Patre%2C+P+R">Priyanka Raju Patre</a>, 
<a href="/search/cs?searchtype=author&query=Koiler%2C+R">Reza Koiler</a>, 
<a href="/search/cs?searchtype=author&query=Getchell%2C+N">Nancy Getchell</a>, 
<a href="/search/cs?searchtype=author&query=Barmaki%2C+R+L">Roghayeh Leila Barmaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14023" title="Abstract">arXiv:2307.14023</a> (replaced) [<a href="/pdf/2307.14023" title="Download PDF">pdf</a>, <a href="/format/2307.14023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Transformers with One Layer Self-Attention Using Low-Rank Weight  Matrices Universal Approximators?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kajitsuka%2C+T">Tokio Kajitsuka</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+I">Issei Sato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14223" title="Abstract">arXiv:2307.14223</a> (replaced) [<a href="/pdf/2307.14223" title="Download PDF">pdf</a>, <a href="/ps/2307.14223" title="Download PostScript">ps</a>, <a href="/format/2307.14223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rewriting and Completeness of Sum-Over-Paths in Dyadic Fragments of  Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vilmart%2C+R">Renaud Vilmart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2205.02600">arXiv:2205.02600</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14385" title="Abstract">arXiv:2307.14385</a> (replaced) [<a href="/pdf/2307.14385" title="Download PDF">pdf</a>, <a href="/format/2307.14385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mental-LLM: Leveraging Large Language Models for Mental Health  Prediction via Online Text Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuhai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+B">Bingsheng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuanzhe Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+S">Saadia Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hendler%2C+J">James Hendler</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M">Marzyeh Ghassemi</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+A+K">Anind K. Dey</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dakuo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14927" title="Abstract">arXiv:2307.14927</a> (replaced) [<a href="/pdf/2307.14927" title="Download PDF">pdf</a>, <a href="/format/2307.14927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascaded Code Distributed Computing With Low Complexity and Improved  Flexibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Youlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Minquan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dianhua Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16348" title="Abstract">arXiv:2307.16348</a> (replaced) [<a href="/pdf/2307.16348" title="Download PDF">pdf</a>, <a href="/format/2307.16348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rating-based Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=White%2C+D">Devin White</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mingkang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Novoseller%2C+E">Ellen Novoseller</a>, 
<a href="/search/cs?searchtype=author&query=Lawhern%2C+V+J">Vernon J. Lawhern</a>, 
<a href="/search/cs?searchtype=author&query=Waytowich%2C+N">Nicholas Waytowich</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yongcan Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of the paper "Rating-based Reinforcement Learning" accepted to the 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04065" title="Abstract">arXiv:2308.04065</a> (replaced) [<a href="/pdf/2308.04065" title="Download PDF">pdf</a>, <a href="/format/2308.04065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A space-time high-order implicit shock tracking method for  shock-dominated unsteady flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Naudet%2C+C+J">Charles J. Naudet</a>, 
<a href="/search/math?searchtype=author&query=Zahr%2C+M+J">Matthew J. Zahr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07187" title="Abstract">arXiv:2308.07187</a> (replaced) [<a href="/pdf/2308.07187" title="Download PDF">pdf</a>, <a href="/ps/2308.07187" title="Download PostScript">ps</a>, <a href="/format/2308.07187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Asymptotic Nonnegative Rank of Matrices and its Applications in  Information Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chee%2C+Y+M">Yeow Meng Chee</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+Q+T">Quoc Tung Le</a>, 
<a href="/search/cs?searchtype=author&query=Ta%2C+H">Hoang Ta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computational Complexity (cs.CC); Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07491" title="Abstract">arXiv:2308.07491</a> (replaced) [<a href="/pdf/2308.07491" title="Download PDF">pdf</a>, <a href="/format/2308.07491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Tracking of a Single-Rigid-Body Character in Various  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+T">Taesoo Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Taehong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J">Jaewon Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yoonsang Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023 Conference Papers
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SA '23: SIGGRAPH Asia 2023 Conference Papers, December 2023,
  Article No.: 118, Pages 1-11
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08334" title="Abstract">arXiv:2308.08334</a> (replaced) [<a href="/pdf/2308.08334" title="Download PDF">pdf</a>, <a href="/ps/2308.08334" title="Download PostScript">ps</a>, <a href="/format/2308.08334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning logic programs by discovering higher-order abstractions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hocquette%2C+C">C&#xe9;line Hocquette</a>, 
<a href="/search/cs?searchtype=author&query=Duman%C4%8Di%C4%87%2C+S">Sebastijan Duman&#x10d;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Cropper%2C+A">Andrew Cropper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08628" title="Abstract">arXiv:2308.08628</a> (replaced) [<a href="/pdf/2308.08628" title="Download PDF">pdf</a>, <a href="/format/2308.08628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the meanings of function words from grounded language using a  visual question answering model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Portelance%2C+E">Eva Portelance</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+M+C">Michael C. Frank</a>, 
<a href="/search/cs?searchtype=author&query=Jurafsky%2C+D">Dan Jurafsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09959" title="Abstract">arXiv:2308.09959</a> (replaced) [<a href="/pdf/2308.09959" title="Download PDF">pdf</a>, <a href="/format/2308.09959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hummingbird: Fast, Flexible, and Fair Inter-Domain Bandwidth  Reservations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=W%C3%BCst%2C+K">Karl W&#xfc;st</a>, 
<a href="/search/cs?searchtype=author&query=Giuliari%2C+G">Giacomo Giuliari</a>, 
<a href="/search/cs?searchtype=author&query=Legner%2C+M">Markus Legner</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J">Jean-Pierre Smith</a>, 
<a href="/search/cs?searchtype=author&query=Wyss%2C+M">Marc Wyss</a>, 
<a href="/search/cs?searchtype=author&query=Bachmann%2C+J">Jules Bachmann</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Pardo%2C+J+A">Juan A. Garcia-Pardo</a>, 
<a href="/search/cs?searchtype=author&query=Perrig%2C+A">Adrian Perrig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10335" title="Abstract">arXiv:2308.10335</a> (replaced) [<a href="/pdf/2308.10335" title="Download PDF">pdf</a>, <a href="/format/2308.10335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT replace StackOverflow? A Study on Robustness and Reliability  of Large Language Model Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Li Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11787" title="Abstract">arXiv:2308.11787</a> (replaced) [<a href="/pdf/2308.11787" title="Download PDF">pdf</a>, <a href="/format/2308.11787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HypBO: Accelerating Black-Box Scientific Experiments Using Experts&#x27;  Hypotheses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cisse%2C+A">Abdoulatif Cisse</a>, 
<a href="/search/cs?searchtype=author&query=Evangelopoulos%2C+X">Xenophon Evangelopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Carruthers%2C+S">Sam Carruthers</a>, 
<a href="/search/cs?searchtype=author&query=Gusev%2C+V+V">Vladimir V. Gusev</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+I">Andrew I. Cooper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12017" title="Abstract">arXiv:2308.12017</a> (replaced) [<a href="/pdf/2308.12017" title="Download PDF">pdf</a>, <a href="/format/2308.12017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DISCO: Distribution-Aware Calibration for Object Detection with Noisy  Bounding Boxes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Donghao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiancheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Q">Qiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bin-Bin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P">Pheng-Ann Heng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12608" title="Abstract">arXiv:2308.12608</a> (replaced) [<a href="/pdf/2308.12608" title="Download PDF">pdf</a>, <a href="/format/2308.12608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HR-Pro: Point-supervised Temporal Action Localization via Hierarchical  Reliability Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qing%2C+Z">Zhiwu Qing</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+N">Nong Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13111" title="Abstract">arXiv:2308.13111</a> (replaced) [<a href="/pdf/2308.13111" title="Download PDF">pdf</a>, <a href="/format/2308.13111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Low-rank Adaptation for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+A+X">Adam X. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Robeyns%2C+M">Maxime Robeyns</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Aitchison%2C+L">Laurence Aitchison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13420" title="Abstract">arXiv:2308.13420</a> (replaced) [<a href="/pdf/2308.13420" title="Download PDF">pdf</a>, <a href="/format/2308.13420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning-assisted Evolutionary Algorithm: A Survey and  Research Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yanjie Song</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yutong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yangyang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Ran Yan</a>, 
<a href="/search/cs?searchtype=author&query=Suganthan%2C+P+N">P. N. Suganthan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pedrycz%2C+W">Witold Pedrycz</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Swagatam Das</a>, 
<a href="/search/cs?searchtype=author&query=Mallipeddi%2C+R">Rammohan Mallipeddi</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+O+S+A+Q">Oladayo Solomon Ajani. Qiang Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14222" title="Abstract">arXiv:2308.14222</a> (replaced) [<a href="/pdf/2308.14222" title="Download PDF">pdf</a>, <a href="/format/2308.14222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate complex Jacobi rotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Novakovi%C4%87%2C+V">Vedran Novakovi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Supplementary material is available in <a href="https://github.com/venovako/AccJac">this https URL</a> and <a href="https://github.com/venovako/libpvn">this https URL</a> repositories
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14636" title="Abstract">arXiv:2308.14636</a> (replaced) [<a href="/pdf/2308.14636" title="Download PDF">pdf</a>, <a href="/format/2308.14636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Standardized Disturbance Rejection Testing of Legged Robot  Locomotion with Linear Impactor: A Preliminary Study, Observations, and  Implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+B">Bowen Weng</a>, 
<a href="/search/cs?searchtype=author&query=Castillo%2C+G+A">Guillermo A. Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yun-Seok Kang</a>, 
<a href="/search/cs?searchtype=author&query=Hereid%2C+A">Ayonga Hereid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A modified version of this preprint has been accepted at IEEE International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14993" title="Abstract">arXiv:2308.14993</a> (replaced) [<a href="/pdf/2308.14993" title="Download PDF">pdf</a>, <a href="/ps/2308.14993" title="Download PostScript">ps</a>, <a href="/format/2308.14993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On k-Mer-Based and Maximum Likelihood Estimation Algorithms for Trace  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Grigorescu%2C+E">Elena Grigorescu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Sudan%2C+M">Madhu Sudan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minshen Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15715" title="Abstract">arXiv:2308.15715</a> (replaced) [<a href="/pdf/2308.15715" title="Download PDF">pdf</a>, <a href="/format/2308.15715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic properties of double porosity/permeability model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nakshatrala%2C+K+B">K. B. Nakshatrala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Analysis of PDEs (math.AP); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03160" title="Abstract">arXiv:2309.03160</a> (replaced) [<a href="/pdf/2309.03160" title="Download PDF">pdf</a>, <a href="/format/2309.03160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResFields: Residual Neural Fields for Spatiotemporal Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mihajlovic%2C+M">Marko Mihajlovic</a>, 
<a href="/search/cs?searchtype=author&query=Prokudin%2C+S">Sergey Prokudin</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siyu Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> [ICLR 2024 Spotlight] Project and code at: <a href="https://markomih.github.io/ResFields/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04036" title="Abstract">arXiv:2309.04036</a> (replaced) [<a href="/pdf/2309.04036" title="Download PDF">pdf</a>, <a href="/format/2309.04036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-to-Multiple Clean-Label Image Camouflage (OmClic) based Backdoor  Attack on Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guohong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yansong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Abuadbba%2C+A">Alsharif Abuadbba</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wei Kang</a>, 
<a href="/search/cs?searchtype=author&query=Al-Sarawib%2C+S+F">Said F. Al-Sarawib</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gongxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Abbott%2C+D">Derek Abbott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04174" title="Abstract">arXiv:2309.04174</a> (replaced) [<a href="/pdf/2309.04174" title="Download PDF">pdf</a>, <a href="/format/2309.04174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manifold-based Verbalizer Space Re-embedding for Tuning-free  Prompt-based Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haochun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sendong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+N">Nuwa Xi</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Muzhen Cai</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024, 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04624" title="Abstract">arXiv:2309.04624</a> (replaced) [<a href="/pdf/2309.04624" title="Download PDF">pdf</a>, <a href="/ps/2309.04624" title="Download PostScript">ps</a>, <a href="/format/2309.04624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Probabilistic Framework in IMALL: A Concrete Categorical  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Caro%2C+A">Alejandro D&#xed;az-Caro</a>, 
<a href="/search/cs?searchtype=author&query=Malherbe%2C+O">Octavio Malherbe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06054" title="Abstract">arXiv:2309.06054</a> (replaced) [<a href="/pdf/2309.06054" title="Download PDF">pdf</a>, <a href="/format/2309.06054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking through the learning plateaus of in-context learning in  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jingwen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06252" title="Abstract">arXiv:2309.06252</a> (replaced) [<a href="/pdf/2309.06252" title="Download PDF">pdf</a>, <a href="/format/2309.06252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Routine Object Usage for Proactive Robot Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+M">Maithili Patel</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+A">Aswin Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Chernova%2C+S">Sonia Chernova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06782" title="Abstract">arXiv:2309.06782</a> (replaced) [<a href="/pdf/2309.06782" title="Download PDF">pdf</a>, <a href="/format/2309.06782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved particle-flow event reconstruction with scalable neural  networks for current and future particle detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pata%2C+J">Joosep Pata</a>, 
<a href="/search/physics?searchtype=author&query=Wulff%2C+E">Eric Wulff</a>, 
<a href="/search/physics?searchtype=author&query=Mokhtar%2C+F">Farouk Mokhtar</a>, 
<a href="/search/physics?searchtype=author&query=Southwick%2C+D">David Southwick</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+M">Mengke Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Girone%2C+M">Maria Girone</a>, 
<a href="/search/physics?searchtype=author&query=Duarte%2C+J">Javier Duarte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Instrumentation and Detectors (physics.ins-det); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07098" title="Abstract">arXiv:2309.07098</a> (replaced) [<a href="/pdf/2309.07098" title="Download PDF">pdf</a>, <a href="/format/2309.07098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Hallucinations and Off-target Machine Translation with  Source-Contrastive and Language-Contrastive Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sennrich%2C+R">Rico Sennrich</a>, 
<a href="/search/cs?searchtype=author&query=Vamvas%2C+J">Jannis Vamvas</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadshahi%2C+A">Alireza Mohammadshahi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07202" title="Abstract">arXiv:2309.07202</a> (replaced) [<a href="/pdf/2309.07202" title="Download PDF">pdf</a>, <a href="/format/2309.07202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Deep Decarbonization Pathways in California with Power System  Planning Using Surrogate Level-based Lagrangian Relaxation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Anderson%2C+O">Osten Anderson</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+N">Nanpeng Yu</a>, 
<a href="/search/eess?searchtype=author&query=Bragin%2C+M">Mikhail Bragin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08609" title="Abstract">arXiv:2309.08609</a> (replaced) [<a href="/pdf/2309.08609" title="Download PDF">pdf</a>, <a href="/format/2309.08609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Media of Langue: The dictionary that visualizes Inter-Lingual Semantic  Network/Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muramoto%2C+G">Goki Muramoto</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+A">Atsuki Sato</a>, 
<a href="/search/cs?searchtype=author&query=Koyama%2C+T">Takayoshi Koyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09212" title="Abstract">arXiv:2309.09212</a> (replaced) [<a href="/pdf/2309.09212" title="Download PDF">pdf</a>, <a href="/format/2309.09212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RobotPerf: An Open-Source, Vendor-Agnostic, Benchmarking Suite for  Evaluating Robotics Computing System Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mayoral-Vilches%2C+V">V&#xed;ctor Mayoral-Vilches</a>, 
<a href="/search/cs?searchtype=author&query=Jabbour%2C+J">Jason Jabbour</a>, 
<a href="/search/cs?searchtype=author&query=Hsiao%2C+Y">Yu-Shun Hsiao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zishen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Crespo-%C3%81lvarez%2C+M">Marti&#xf1;o Crespo-&#xc1;lvarez</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+M">Matthew Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Reina-Mu%C3%B1oz%2C+J+M">Juan Manuel Reina-Mu&#xf1;oz</a>, 
<a href="/search/cs?searchtype=author&query=Nagras%2C+P">Prateek Nagras</a>, 
<a href="/search/cs?searchtype=author&query=Vikhe%2C+G">Gaurav Vikhe</a>, 
<a href="/search/cs?searchtype=author&query=Bakhshalipour%2C+M">Mohammad Bakhshalipour</a>, 
<a href="/search/cs?searchtype=author&query=Pinzger%2C+M">Martin Pinzger</a>, 
<a href="/search/cs?searchtype=author&query=Rass%2C+S">Stefan Rass</a>, 
<a href="/search/cs?searchtype=author&query=Panigrahi%2C+S">Smruti Panigrahi</a>, 
<a href="/search/cs?searchtype=author&query=Corradi%2C+G">Giulio Corradi</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Niladri Roy</a>, 
<a href="/search/cs?searchtype=author&query=Gibbons%2C+P+B">Phillip B. Gibbons</a>, 
<a href="/search/cs?searchtype=author&query=Neuman%2C+S+M">Sabrina M. Neuman</a>, 
<a href="/search/cs?searchtype=author&query=Plancher%2C+B">Brian Plancher</a>, 
<a href="/search/cs?searchtype=author&query=Reddi%2C+V+J">Vijay Janapa Reddi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11765" title="Abstract">arXiv:2309.11765</a> (replaced) [<a href="/pdf/2309.11765" title="Download PDF">pdf</a>, <a href="/format/2309.11765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving In-Context Learning with Differentially Private  Few-Shot Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xinyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+R">Richard Shin</a>, 
<a href="/search/cs?searchtype=author&query=Inan%2C+H+A">Huseyin A. Inan</a>, 
<a href="/search/cs?searchtype=author&query=Manoel%2C+A">Andre Manoel</a>, 
<a href="/search/cs?searchtype=author&query=Mireshghallah%2C+F">Fatemehsadat Mireshghallah</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zinan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gopi%2C+S">Sivakanth Gopi</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+J">Janardhan Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+R">Robert Sim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12291" title="Abstract">arXiv:2309.12291</a> (replaced) [<a href="/pdf/2309.12291" title="Download PDF">pdf</a>, <a href="/format/2309.12291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linearity of $\mathbb{Z}_{2^L}$-Linear Codes via Schur Product
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bastos%2C+G+T">Gustavo T. Bastos</a>, 
<a href="/search/cs?searchtype=author&query=Bollauf%2C+M+F">Maiara F. Bollauf</a>, 
<a href="/search/cs?searchtype=author&query=Ferrari%2C+A+J">Agnaldo J. Ferrari</a>, 
<a href="/search/cs?searchtype=author&query=Ytrehus%2C+%C3%98">&#xd8;yvind Ytrehus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12953" title="Abstract">arXiv:2309.12953</a> (replaced) [<a href="/pdf/2309.12953" title="Download PDF">pdf</a>, <a href="/ps/2309.12953" title="Download PostScript">ps</a>, <a href="/format/2309.12953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inter-vendor harmonization of Computed Tomography (CT) reconstruction  kernels using unpaired image translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Krishnan%2C+A+R">Aravind R. Krishnan</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+K">Kaiwen Xu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Thomas Li</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+C">Chenyu Gao</a>, 
<a href="/search/eess?searchtype=author&query=Remedios%2C+L+W">Lucas W. Remedios</a>, 
<a href="/search/eess?searchtype=author&query=Kanakaraj%2C+P">Praitayini Kanakaraj</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H+H">Ho Hin Lee</a>, 
<a href="/search/eess?searchtype=author&query=Bao%2C+S">Shunxing Bao</a>, 
<a href="/search/eess?searchtype=author&query=Sandler%2C+K+L">Kim L. Sandler</a>, 
<a href="/search/eess?searchtype=author&query=Maldonado%2C+F">Fabien Maldonado</a>, 
<a href="/search/eess?searchtype=author&query=Isgum%2C+I">Ivana Isgum</a>, 
<a href="/search/eess?searchtype=author&query=Landman%2C+B+A">Bennett A. Landman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 1 table, Submitted to SPIE Medical Imaging : Image Processing. San Diego, CA. February 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13043" title="Abstract">arXiv:2309.13043</a> (replaced) [<a href="/pdf/2309.13043" title="Download PDF">pdf</a>, <a href="/format/2309.13043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E(2)-Equivariant Graph Planning for Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Linfeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Padir%2C+T">Taskin Padir</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Huaizu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+L+L+S">Lawson L.S. Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by RA-L
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13340" title="Abstract">arXiv:2309.13340</a> (replaced) [<a href="/pdf/2309.13340" title="Download PDF">pdf</a>, <a href="/format/2309.13340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards LLM-guided Causal Explainability for Black-box Text Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+A">Amrita Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Moraffah%2C+R">Raha Moraffah</a>, 
<a href="/search/cs?searchtype=author&query=Garland%2C+J">Joshua Garland</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready for AAAI ReLM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13349" title="Abstract">arXiv:2309.13349</a> (replaced) [<a href="/pdf/2309.13349" title="Download PDF">pdf</a>, <a href="/format/2309.13349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speeding-up Evolutionary Algorithms to solve Black-Box Optimization  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Echevarrieta%2C+J">Judith Echevarrieta</a>, 
<a href="/search/cs?searchtype=author&query=Arza%2C+E">Etor Arza</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+A">Aritz P&#xe9;rez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13500" title="Abstract">arXiv:2309.13500</a> (replaced) [<a href="/pdf/2309.13500" title="Download PDF">pdf</a>, <a href="/format/2309.13500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Student Performance Prediction on Learnersourced Questions  with SGNN-LLM Synergy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+L">Lin Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xianda Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Paul Denny</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamou Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13920" title="Abstract">arXiv:2309.13920</a> (replaced) [<a href="/pdf/2309.13920" title="Download PDF">pdf</a>, <a href="/ps/2309.13920" title="Download PostScript">ps</a>, <a href="/format/2309.13920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Emergency Vehicle Detection using Mel Spectrograms and Regular  Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pacheco-Gonzalez%2C+A">Alberto Pacheco-Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+R">Raymundo Torres</a>, 
<a href="/search/cs?searchtype=author&query=Chacon%2C+R">Raul Chacon</a>, 
<a href="/search/cs?searchtype=author&query=Robledo%2C+I">Isidro Robledo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Spanish language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Formal Languages and Automata Theory (cs.FL); Symbolic Computation (cs.SC); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14053" title="Abstract">arXiv:2309.14053</a> (replaced) [<a href="/pdf/2309.14053" title="Download PDF">pdf</a>, <a href="/format/2309.14053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting LARS for Large Batch Training Generalization of Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+K">Khoi Do</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hoa Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tran-Thanh%2C+L">Long Tran-Thanh</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quoc-Viet Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14630" title="Abstract">arXiv:2309.14630</a> (replaced) [<a href="/pdf/2309.14630" title="Download PDF">pdf</a>, <a href="/format/2309.14630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free Discontinuity Regression: With an Application to the Economic  Effects of Internet Shutdowns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Gunsilius%2C+F">Florian Gunsilius</a>, 
<a href="/search/econ?searchtype=author&query=Van+Dijcke%2C+D">David Van Dijcke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures; authors listed alphabetically; code available at <a href="https://github.com/Davidvandijcke/fdr">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Computer Vision and Pattern Recognition (cs.CV); Statistics Theory (math.ST); Applications (stat.AP); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15560" title="Abstract">arXiv:2309.15560</a> (replaced) [<a href="/pdf/2309.15560" title="Download PDF">pdf</a>, <a href="/format/2309.15560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifiability Matters: Revealing the Hidden Recoverable Condition in  Unbiased Learning to Rank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mouxiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianling Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Improve the experiments and theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16742" title="Abstract">arXiv:2309.16742</a> (replaced) [<a href="/pdf/2309.16742" title="Download PDF">pdf</a>, <a href="/format/2309.16742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervised Learning Models for Early Detection of Albuminuria Risk in  Type-2 Diabetes Mellitus Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muharram%2C+A+P">Arief Purnama Muharram</a>, 
<a href="/search/cs?searchtype=author&query=Tahapary%2C+D+L">Dicky Levenus Tahapary</a>, 
<a href="/search/cs?searchtype=author&query=Lestari%2C+Y+D">Yeni Dwi Lestari</a>, 
<a href="/search/cs?searchtype=author&query=Sarayar%2C+R">Randy Sarayar</a>, 
<a href="/search/cs?searchtype=author&query=Dirjayanto%2C+V+J">Valerie Josephine Dirjayanto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the 2023 10th International Conference on Advanced Informatics: Concept, Theory and Application (ICAICTA)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 10th International Conference on Advanced Informatics:
  Concept, Theory and Application (2023) 1-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17096" title="Abstract">arXiv:2309.17096</a> (replaced) [<a href="/pdf/2309.17096" title="Download PDF">pdf</a>, <a href="/format/2309.17096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Obtaining Pseudo-inverse Solutions With MINRES
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/math?searchtype=author&query=Milzarek%2C+A">Andre Milzarek</a>, 
<a href="/search/math?searchtype=author&query=Roosta%2C+F">Fred Roosta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17194" title="Abstract">arXiv:2309.17194</a> (replaced) [<a href="/pdf/2309.17194" title="Download PDF">pdf</a>, <a href="/format/2309.17194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Activation via Multivariate Projection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayun Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuxiao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yiwen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhuofan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yilin Mo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00863" title="Abstract">arXiv:2310.00863</a> (replaced) [<a href="/pdf/2310.00863" title="Download PDF">pdf</a>, <a href="/format/2310.00863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syllable-level lyrics generation from melody exploiting character-level  language model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lasocki%2C+K">Karol Lasocki</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Takasu%2C+A">Atsuhiro Takasu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01040" title="Abstract">arXiv:2310.01040</a> (replaced) [<a href="/pdf/2310.01040" title="Download PDF">pdf</a>, <a href="/format/2310.01040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised motion segmentation in one go: Smooth long-term model over  a video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meunier%2C+E">Etienne Meunier</a>, 
<a href="/search/cs?searchtype=author&query=Bouthemy%2C+P">Patrick Bouthemy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01728" title="Abstract">arXiv:2310.01728</a> (replaced) [<a href="/pdf/2310.01728" title="Download PDF">pdf</a>, <a href="/format/2310.01728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-LLM: Time Series Forecasting by Reprogramming Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lintao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+Y">James Y. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Fang Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 12th International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01801" title="Abstract">arXiv:2310.01801</a> (replaced) [<a href="/pdf/2310.01801" title="Download PDF">pdf</a>, <a href="/format/2310.01801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+S">Suyu Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02161" title="Abstract">arXiv:2310.02161</a> (replaced) [<a href="/pdf/2310.02161" title="Download PDF">pdf</a>, <a href="/format/2310.02161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews  Elicited from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M+X">Michael Xieyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tongshuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F+M">Franklin Mingzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Kittur%2C+A">Aniket Kittur</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+B+A">Brad A. Myers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02446" title="Abstract">arXiv:2310.02446</a> (replaced) [<a href="/pdf/2310.02446" title="Download PDF">pdf</a>, <a href="/format/2310.02446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Resource Languages Jailbreak GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yong%2C+Z">Zheng-Xin Yong</a>, 
<a href="/search/cs?searchtype=author&query=Menghini%2C+C">Cristina Menghini</a>, 
<a href="/search/cs?searchtype=author&query=Bach%2C+S+H">Stephen H. Bach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS Workshop on Socially Responsible Language Modelling Research (SoLaR) 2023. Best Paper Award
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03337" title="Abstract">arXiv:2310.03337</a> (replaced) [<a href="/pdf/2310.03337" title="Download PDF">pdf</a>, <a href="/format/2310.03337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Diffusion Step-aware Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yukang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Luozhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingcong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03480" title="Abstract">arXiv:2310.03480</a> (replaced) [<a href="/pdf/2310.03480" title="Download PDF">pdf</a>, <a href="/format/2310.03480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The ICASSP SP Cadenza Challenge: Music Demixing/Remixing for Hearing  Aids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dabike%2C+G+R">Gerardo Roa Dabike</a>, 
<a href="/search/eess?searchtype=author&query=Akeroyd%2C+M+A">Michael A. Akeroyd</a>, 
<a href="/search/eess?searchtype=author&query=Bannister%2C+S">Scott Bannister</a>, 
<a href="/search/eess?searchtype=author&query=Barker%2C+J">Jon Barker</a>, 
<a href="/search/eess?searchtype=author&query=Cox%2C+T+J">Trevor J. Cox</a>, 
<a href="/search/eess?searchtype=author&query=Fazenda%2C+B">Bruno Fazenda</a>, 
<a href="/search/eess?searchtype=author&query=Firth%2C+J">Jennifer Firth</a>, 
<a href="/search/eess?searchtype=author&query=Graetzer%2C+S">Simone Graetzer</a>, 
<a href="/search/eess?searchtype=author&query=Greasley%2C+A">Alinka Greasley</a>, 
<a href="/search/eess?searchtype=author&query=Vos%2C+R+R">Rebecca R. Vos</a>, 
<a href="/search/eess?searchtype=author&query=Whitmer%2C+W+M">William M. Whitmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2-page paper for ICASSP 2024 SP Grand Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04676" title="Abstract">arXiv:2310.04676</a> (replaced) [<a href="/pdf/2310.04676" title="Download PDF">pdf</a>, <a href="/format/2310.04676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surgical Gym: A high-performance GPU-based platform for reinforcement  learning with surgical robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidgall%2C+S">Samuel Schmidgall</a>, 
<a href="/search/cs?searchtype=author&query=Krieger%2C+A">Axel Krieger</a>, 
<a href="/search/cs?searchtype=author&query=Eshraghian%2C+J">Jason Eshraghian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05668" title="Abstract">arXiv:2310.05668</a> (replaced) [<a href="/pdf/2310.05668" title="Download PDF">pdf</a>, <a href="/format/2310.05668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LARA: A Light and Anti-overfitting Retraining Approach for Unsupervised  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shuiguang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Web Conference 2024 (WWW 24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05969" title="Abstract">arXiv:2310.05969</a> (replaced) [<a href="/pdf/2310.05969" title="Download PDF">pdf</a>, <a href="/format/2310.05969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Chest X-Ray Report Generator Using Multi-Model Deep Learning  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Muharram%2C+A+P">Arief Purnama Muharram</a>, 
<a href="/search/eess?searchtype=author&query=Haryono%2C+H+P">Hollyana Puteri Haryono</a>, 
<a href="/search/eess?searchtype=author&query=Juma%2C+A+H">Abassi Haji Juma</a>, 
<a href="/search/eess?searchtype=author&query=Puspasari%2C+I">Ira Puspasari</a>, 
<a href="/search/eess?searchtype=author&query=Utama%2C+N+P">Nugraha Priya Utama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the 2023 IEEE International Conference on Data and Software Engineering (ICoDSE)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Data and Software
  Engineering (2023) 25-30
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06639" title="Abstract">arXiv:2310.06639</a> (replaced) [<a href="/pdf/2310.06639" title="Download PDF">pdf</a>, <a href="/format/2310.06639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Lattice Overparametrization Paradigm for the Machine Learning of  Lattice Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marcondes%2C+D">Diego Marcondes</a>, 
<a href="/search/cs?searchtype=author&query=Barrera%2C+J">Junior Barrera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06690" title="Abstract">arXiv:2310.06690</a> (replaced) [<a href="/pdf/2310.06690" title="Download PDF">pdf</a>, <a href="/format/2310.06690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Coding-Modulation for Digital Semantic Communications via  Variational Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bo%2C+Y">Yufei Bo</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yiheng Duan</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuo Shao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+M">Meixia Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07276" title="Abstract">arXiv:2310.07276</a> (replaced) [<a href="/pdf/2310.07276" title="Download PDF">pdf</a>, <a href="/format/2310.07276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioT5: Enriching Cross-modal Integration in Biology with Chemical  Knowledge and Natural Language Associations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+Q">Qizhi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kehan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kaiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lijun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yingce Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Empirical Methods in Natural Language Processing 2023 (EMNLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07736" title="Abstract">arXiv:2310.07736</a> (replaced) [<a href="/pdf/2310.07736" title="Download PDF">pdf</a>, <a href="/format/2310.07736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Observatory: Characterizing Embeddings of Relational Tables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cong%2C+T">Tianji Cong</a>, 
<a href="/search/cs?searchtype=author&query=Hulsebos%2C+M">Madelon Hulsebos</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhenjie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Groth%2C+P">Paul Groth</a>, 
<a href="/search/cs?searchtype=author&query=Jagadish%2C+H+V">H. V. Jagadish</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready of VLDB 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08383" title="Abstract">arXiv:2310.08383</a> (replaced) [<a href="/pdf/2310.08383" title="Download PDF">pdf</a>, <a href="/format/2310.08383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing Materials Tetrahedron: Challenges in Materials  Information Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hira%2C+K">Kausik Hira</a>, 
<a href="/search/cs?searchtype=author&query=Zaki%2C+M">Mohd Zaki</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+D">Dhruvil Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Mausam">Mausam</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+N+M+A">N M Anoop Krishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09395" title="Abstract">arXiv:2310.09395</a> (replaced) [<a href="/pdf/2310.09395" title="Download PDF">pdf</a>, <a href="/format/2310.09395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medial Skeletal Diagram: A Generalized Medial Axis Approach for Compact  3D Shape Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Minghao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Matusik%2C+W">Wojciech Matusik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 28 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09663" title="Abstract">arXiv:2310.09663</a> (replaced) [<a href="/pdf/2310.09663" title="Download PDF">pdf</a>, <a href="/format/2310.09663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VBFT: Veloce Byzantine Fault Tolerant Consensus for Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jalalzai%2C+M+M">Mohammad M. Jalalzai</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lemieux%2C+V">Victoria Lemieux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2109.14604">arXiv:2109.14604</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10443" title="Abstract">arXiv:2310.10443</a> (replaced) [<a href="/pdf/2310.10443" title="Download PDF">pdf</a>, <a href="/format/2310.10443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming the Sigmoid Bottleneck: Provably Argmaxable Sparse Multi-Label  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grivas%2C+A">Andreas Grivas</a>, 
<a href="/search/cs?searchtype=author&query=Vergari%2C+A">Antonio Vergari</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+A">Adam Lopez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10483" title="Abstract">arXiv:2310.10483</a> (replaced) [<a href="/pdf/2310.10483" title="Download PDF">pdf</a>, <a href="/format/2310.10483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passive Inference Attacks on Split Learning via Adversarial  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaochen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xinjian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuncheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yangfan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiaokui Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ooi%2C+B+C">Beng Chin Ooi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10705" title="Abstract">arXiv:2310.10705</a> (replaced) [<a href="/pdf/2310.10705" title="Download PDF">pdf</a>, <a href="/ps/2310.10705" title="Download PostScript">ps</a>, <a href="/format/2310.10705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical and Experimental Insights into Machine Learning-Based Defect  Classification in Semiconductor Wafers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taha%2C+K">Kamal Taha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10818" title="Abstract">arXiv:2310.10818</a> (replaced) [<a href="/pdf/2310.10818" title="Download PDF">pdf</a>, <a href="/format/2310.10818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware transfer across tasks using hybrid model-based  successor feature reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malekzadeh%2C+P">Parvin Malekzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+M">Ming Hou</a>, 
<a href="/search/cs?searchtype=author&query=Plataniotis%2C+K+N">Konstantinos N. Plataniotis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neurocomputing 530 (2023): 165-187
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11288" title="Abstract">arXiv:2310.11288</a> (replaced) [<a href="/pdf/2310.11288" title="Download PDF">pdf</a>, <a href="/ps/2310.11288" title="Download PostScript">ps</a>, <a href="/format/2310.11288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enriching Diagrams with Algebraic Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villoria%2C+A">Alejandro Villoria</a>, 
<a href="/search/cs?searchtype=author&query=Basold%2C+H">Henning Basold</a>, 
<a href="/search/cs?searchtype=author&query=Laarman%2C+A">Alfons Laarman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 appendix pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11373" title="Abstract">arXiv:2310.11373</a> (replaced) [<a href="/pdf/2310.11373" title="Download PDF">pdf</a>, <a href="/format/2310.11373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Layer Blockchain Sharding Protocol Leveraging Safety and Liveness  for Enhanced Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yibin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jingyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%BCdder%2C+B">Boris D&#xfc;dder</a>, 
<a href="/search/cs?searchtype=author&query=Slaats%2C+T">Tijs Slaats</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yongluan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted to Network and Distributed System Security (NDSS) Symposium 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Network and Distributed System Security (NDSS) Symposium 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11526" title="Abstract">arXiv:2310.11526</a> (replaced) [<a href="/pdf/2310.11526" title="Download PDF">pdf</a>, <a href="/ps/2310.11526" title="Download PostScript">ps</a>, <a href="/format/2310.11526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commitments from Quantum One-Wayness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Khurana%2C+D">Dakshita Khurana</a> (UIUC), 
<a href="/search/quant-ph?searchtype=author&query=Tomer%2C+K">Kabir Tomer</a> (UIUC)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages; Minor edits to the proof of Claim 4.2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12279" title="Abstract">arXiv:2310.12279</a> (replaced) [<a href="/pdf/2310.12279" title="Download PDF">pdf</a>, <a href="/ps/2310.12279" title="Download PostScript">ps</a>, <a href="/format/2310.12279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adjoint-based inversion for stress and frictional parameters in  earthquake modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Stiernstr%C3%B6m%2C+V">Vidar Stiernstr&#xf6;m</a>, 
<a href="/search/math?searchtype=author&query=Almquist%2C+M">Martin Almquist</a>, 
<a href="/search/math?searchtype=author&query=Dunham%2C+E+M">Eric M. Dunham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor edits, updated figures in section 6.5.2 and 6.5.3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12701" title="Abstract">arXiv:2310.12701</a> (replaced) [<a href="/pdf/2310.12701" title="Download PDF">pdf</a>, <a href="/ps/2310.12701" title="Download PostScript">ps</a>, <a href="/format/2310.12701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parity Games on Temporal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Austin%2C+P">Pete Austin</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+S">Sougata Bose</a>, 
<a href="/search/cs?searchtype=author&query=Totzke%2C+P">Patrick Totzke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13833" title="Abstract">arXiv:2310.13833</a> (replaced) [<a href="/pdf/2310.13833" title="Download PDF">pdf</a>, <a href="/format/2310.13833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mufei Li</a>, 
<a href="/search/cs?searchtype=author&query=Krea%C4%8Di%C4%87%2C+E">Eleonora Krea&#x10d;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Potluru%2C+V+K">Vamsi K. Potluru</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/Graph-COM/GraphMaker">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13889" title="Abstract">arXiv:2310.13889</a> (replaced) [<a href="/pdf/2310.13889" title="Download PDF">pdf</a>, <a href="/format/2310.13889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Experimental Study of Model-based Control for Planar Handed Shearing  Auxetics Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=St%C3%B6lzle%2C+M">Maximilian St&#xf6;lzle</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>, 
<a href="/search/cs?searchtype=author&query=Della+Santina%2C+C">Cosimo Della Santina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14526" title="Abstract">arXiv:2310.14526</a> (replaced) [<a href="/pdf/2310.14526" title="Download PDF">pdf</a>, <a href="/format/2310.14526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Zero Shot Learning in Restless Multi-armed Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunfan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Behari%2C+N">Nikhil Behari</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+E">Edward Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Edwin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nagaraj%2C+D">Dheeraj Nagaraj</a>, 
<a href="/search/cs?searchtype=author&query=Tuyls%2C+K">Karl Tuyls</a>, 
<a href="/search/cs?searchtype=author&query=Taneja%2C+A">Aparna Taneja</a>, 
<a href="/search/cs?searchtype=author&query=Tambe%2C+M">Milind Tambe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14703" title="Abstract">arXiv:2310.14703</a> (replaced) [<a href="/pdf/2310.14703" title="Download PDF">pdf</a>, <a href="/ps/2310.14703" title="Download PostScript">ps</a>, <a href="/format/2310.14703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Establishing Vocabulary Tests as a Benchmark for Evaluating Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez%2C+G">Gonzalo Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Conde%2C+J">Javier Conde</a>, 
<a href="/search/cs?searchtype=author&query=Merino-G%C3%B3mez%2C+E">Elena Merino-G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Berm%C3%BAdez-Margaretto%2C+B">Beatriz Berm&#xfa;dez-Margaretto</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez%2C+J+A">Jos&#xe9; Alberto Hern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Reviriego%2C+P">Pedro Reviriego</a>, 
<a href="/search/cs?searchtype=author&query=Brysbaert%2C+M">Marc Brysbaert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16507" title="Abstract">arXiv:2310.16507</a> (replaced) [<a href="/pdf/2310.16507" title="Download PDF">pdf</a>, <a href="/ps/2310.16507" title="Download PostScript">ps</a>, <a href="/format/2310.16507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification Capacity of the Discrete-Time Poisson Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Labidi%2C+W">Wafa Labidi</a>, 
<a href="/search/cs?searchtype=author&query=Deppe%2C+C">Christian Deppe</a>, 
<a href="/search/cs?searchtype=author&query=Boche%2C+H">Holger Boche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17589" title="Abstract">arXiv:2310.17589</a> (replaced) [<a href="/pdf/2310.17589" title="Download PDF">pdf</a>, <a href="/format/2310.17589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Open Source Data Contamination Report for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yucheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Guerin%2C+F">Frank Guerin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18446" title="Abstract">arXiv:2310.18446</a> (replaced) [<a href="/pdf/2310.18446" title="Download PDF">pdf</a>, <a href="/format/2310.18446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hu Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19063" title="Abstract">arXiv:2310.19063</a> (replaced) [<a href="/pdf/2310.19063" title="Download PDF">pdf</a>, <a href="/format/2310.19063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Aggregation in Joint Sound Classification and Localization  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Healy%2C+B">Brendan Healy</a>, 
<a href="/search/cs?searchtype=author&query=McNamee%2C+P">Patrick McNamee</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadabadi%2C+Z+N">Zahra Nili Ahmadabadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20025" title="Abstract">arXiv:2310.20025</a> (replaced) [<a href="/pdf/2310.20025" title="Download PDF">pdf</a>, <a href="/format/2310.20025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with  Learned Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mianchu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Montana%2C+G">Giovanni Montana</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Spotlight Presentation at Goal-conditioned Reinforcement Learning Workshop at NeurIPS, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20448" title="Abstract">arXiv:2310.20448</a> (replaced) [<a href="/pdf/2310.20448" title="Download PDF">pdf</a>, <a href="/format/2310.20448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Federated Unlearning: Challenges, Methods, and Future  Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiyuan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+M">Minyi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kwok-Yan Lam</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xingliang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoning Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00604" title="Abstract">arXiv:2311.00604</a> (replaced) [<a href="/pdf/2311.00604" title="Download PDF">pdf</a>, <a href="/format/2311.00604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Review of Approximability Results for Traveling Salesman  Problems leveraging the TSP-T3CO Definition Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saller%2C+S">Sophia Saller</a>, 
<a href="/search/cs?searchtype=author&query=Koehler%2C+J">Jana Koehler</a>, 
<a href="/search/cs?searchtype=author&query=Karrenbauer%2C+A">Andreas Karrenbauer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00689" title="Abstract">arXiv:2311.00689</a> (replaced) [<a href="/pdf/2311.00689" title="Download PDF">pdf</a>, <a href="/format/2311.00689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaboration in Immersive Environments: Challenges and Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doroudian%2C+S">Shahin Doroudian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01927" title="Abstract">arXiv:2311.01927</a> (replaced) [<a href="/pdf/2311.01927" title="Download PDF">pdf</a>, <a href="/format/2311.01927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katsch%2C+T">Tobias Katsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor updates: Clarified tensor shapes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02340" title="Abstract">arXiv:2311.02340</a> (replaced) [<a href="/pdf/2311.02340" title="Download PDF">pdf</a>, <a href="/format/2311.02340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MC-Stereo: Multi-peak Lookup and Cascade Search Range for Stereo  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Miaojie Feng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Junda Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+H">Hao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Longliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Gangwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qingyong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 3DV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04507" title="Abstract">arXiv:2311.04507</a> (replaced) [<a href="/pdf/2311.04507" title="Download PDF">pdf</a>, <a href="/format/2311.04507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversation Understanding using Relational Temporal Graph Neural  Networks with Auxiliary Cross-Modality Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C+T">Cam-Van Thi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+A">Anh-Tuan Mai</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">The-Son Le</a>, 
<a href="/search/cs?searchtype=author&query=Kieu%2C+H">Hai-Dang Kieu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D">Duc-Trong Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 2023 Conference on Empirical Methods in Natural Language
  Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04892" title="Abstract">arXiv:2311.04892</a> (replaced) [<a href="/pdf/2311.04892" title="Download PDF">pdf</a>, <a href="/format/2311.04892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shashank Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+V">Vaishnavi Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A">Ameet Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Kalyan%2C+A">Ashwin Kalyan</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+P">Peter Clark</a>, 
<a href="/search/cs?searchtype=author&query=Sabharwal%2C+A">Ashish Sabharwal</a>, 
<a href="/search/cs?searchtype=author&query=Khot%2C+T">Tushar Khot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://allenai.github.io/persona-bias.">this https URL</a> Paper to appear at ICLR 2024. Added results for other LLMs in v2 (similar findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04997" title="Abstract">arXiv:2311.04997</a> (replaced) [<a href="/pdf/2311.04997" title="Download PDF">pdf</a>, <a href="/format/2311.04997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twin-based 3D Map Management for Edge-assisted Device Pose  Tracking in Mobile AR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Conghao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mushu Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Nan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuemin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+W">Weihua Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Internet of Things Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05028" title="Abstract">arXiv:2311.05028</a> (replaced) [<a href="/pdf/2311.05028" title="Download PDF">pdf</a>, <a href="/ps/2311.05028" title="Download PostScript">ps</a>, <a href="/format/2311.05028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Changes to Daylight Illumination level on Architectural  experience in Offices Based on VR and EEG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Payedar-Ardakani%2C+P">Pegah Payedar-Ardakani</a>, 
<a href="/search/cs?searchtype=author&query=Gorji-Mahlabani%2C+Y">Yousef Gorji-Mahlabani</a>, 
<a href="/search/cs?searchtype=author&query=Ghanbaran%2C+A">Abdolhamid Ghanbaran</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimpour%2C+R">Reza Ebrahimpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05181" title="Abstract">arXiv:2311.05181</a> (replaced) [<a href="/pdf/2311.05181" title="Download PDF">pdf</a>, <a href="/format/2311.05181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-efficient flocking with nonlinear navigational feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dykhovychnyi%2C+O">Oleksandr Dykhovychnyi</a>, 
<a href="/search/math?searchtype=author&query=Panchenko%2C+A">Alexander Panchenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06205" title="Abstract">arXiv:2311.06205</a> (replaced) [<a href="/pdf/2311.06205" title="Download PDF">pdf</a>, <a href="/format/2311.06205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRAFS: A Nonsmooth Convex Optimization Algorithm with  $\mathcal{O}\left(\frac{1}&#x3b5;\right)$ Iteration Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jia%2C+K">Kai Jia</a>, 
<a href="/search/math?searchtype=author&query=Rinard%2C+M">Martin Rinard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06780" title="Abstract">arXiv:2311.06780</a> (replaced) [<a href="/pdf/2311.06780" title="Download PDF">pdf</a>, <a href="/ps/2311.06780" title="Download PostScript">ps</a>, <a href="/format/2311.06780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Strategyproof Mechanism for Ownership Restructuring in Privately Owned  Assets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Danino%2C+G">Gal Danino</a>, 
<a href="/search/econ?searchtype=author&query=Koren%2C+M">Moran Koren</a>, 
<a href="/search/econ?searchtype=author&query=Madmon%2C+O">Omer Madmon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07536" title="Abstract">arXiv:2311.07536</a> (replaced) [<a href="/pdf/2311.07536" title="Download PDF">pdf</a>, <a href="/format/2311.07536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Baotian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanqi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chenyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 13pages; working in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07550" title="Abstract">arXiv:2311.07550</a> (replaced) [<a href="/pdf/2311.07550" title="Download PDF">pdf</a>, <a href="/format/2311.07550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks  for Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pleiter%2C+B">Bart Pleiter</a>, 
<a href="/search/cs?searchtype=author&query=Tajalli%2C+B">Behrad Tajalli</a>, 
<a href="/search/cs?searchtype=author&query=Koffas%2C+S">Stefanos Koffas</a>, 
<a href="/search/cs?searchtype=author&query=Abad%2C+G">Gorka Abad</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+M">Martha Larson</a>, 
<a href="/search/cs?searchtype=author&query=Picek%2C+S">Stjepan Picek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07745" title="Abstract">arXiv:2311.07745</a> (replaced) [<a href="/pdf/2311.07745" title="Download PDF">pdf</a>, <a href="/format/2311.07745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplifying Complex Observation Models in Continuous POMDP Planning with  Probabilistic Guarantees and Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lev-Yehudi%2C+I">Idan Lev-Yehudi</a>, 
<a href="/search/cs?searchtype=author&query=Barenboim%2C+M">Moran Barenboim</a>, 
<a href="/search/cs?searchtype=author&query=Indelman%2C+V">Vadim Indelman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07957" title="Abstract">arXiv:2311.07957</a> (replaced) [<a href="/pdf/2311.07957" title="Download PDF">pdf</a>, <a href="/format/2311.07957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models are Better Bug Detector Through Code-Pair Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alrashedy%2C+K">Kamel Alrashedy</a>, 
<a href="/search/cs?searchtype=author&query=Binjahlan%2C+A">Ahmed Binjahlan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08053" title="Abstract">arXiv:2311.08053</a> (replaced) [<a href="/pdf/2311.08053" title="Download PDF">pdf</a>, <a href="/format/2311.08053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARQ for Active Learning at the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Croisfelt%2C+V">Victor Croisfelt</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+S+R">Shashi Raj Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Simeone%2C+O">Osvaldo Simeone</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, conference version, submitted to IEEE ICC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08149" title="Abstract">arXiv:2311.08149</a> (replaced) [<a href="/pdf/2311.08149" title="Download PDF">pdf</a>, <a href="/format/2311.08149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Complex Disease Trajectories using Deep Generative Models with  Semi-Supervised Latent Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trottet%2C+C">C&#xe9;cile Trottet</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCrch%2C+M">Manuel Sch&#xfc;rch</a>, 
<a href="/search/cs?searchtype=author&query=Allam%2C+A">Ahmed Allam</a>, 
<a href="/search/cs?searchtype=author&query=Barua%2C+I">Imon Barua</a>, 
<a href="/search/cs?searchtype=author&query=Petelytska%2C+L">Liubov Petelytska</a>, 
<a href="/search/cs?searchtype=author&query=Distler%2C+O">Oliver Distler</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann-Vold%2C+A">Anna-Maria Hoffmann-Vold</a>, 
<a href="/search/cs?searchtype=author&query=Krauthammer%2C+M">Michael Krauthammer</a>, 
the <a href="/search/cs?searchtype=author&query=collaborators%2C+E">EUSTAR collaborators</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08724" title="Abstract">arXiv:2311.08724</a> (replaced) [<a href="/pdf/2311.08724" title="Download PDF">pdf</a>, <a href="/ps/2311.08724" title="Download PostScript">ps</a>, <a href="/format/2311.08724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Construction in Power Distribution Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Che Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09335" title="Abstract">arXiv:2311.09335</a> (replaced) [<a href="/pdf/2311.09335" title="Download PDF">pdf</a>, <a href="/format/2311.09335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Hallucinations in Pruned Large Language Models for  Abstractive Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chrysostomou%2C+G">George Chrysostomou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhixue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+M">Miles Williams</a>, 
<a href="/search/cs?searchtype=author&query=Aletras%2C+N">Nikolaos Aletras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12076" title="Abstract">arXiv:2311.12076</a> (replaced) [<a href="/pdf/2311.12076" title="Download PDF">pdf</a>, <a href="/format/2311.12076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Few-shot Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jiuqing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yongbin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Heng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cen%2C+J">Jun Cen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yifan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sook Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P+D">Park Dong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12265" title="Abstract">arXiv:2311.12265</a> (replaced) [<a href="/pdf/2311.12265" title="Download PDF">pdf</a>, <a href="/format/2311.12265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Home Staging: Inverse Rendering and Editing an Indoor Panorama  under Natural Illumination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+G">Guanzhou Ji</a>, 
<a href="/search/cs?searchtype=author&query=Sawyer%2C+A+O">Azadeh O. Sawyer</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+S+G">Srinivasa G. Narasimhan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Symposium on Visual Computing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13708" title="Abstract">arXiv:2311.13708</a> (replaced) [<a href="/pdf/2311.13708" title="Download PDF">pdf</a>, <a href="/ps/2311.13708" title="Download PostScript">ps</a>, <a href="/format/2311.13708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Fault Analysis in Substations Based on Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hui Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14045" title="Abstract">arXiv:2311.14045</a> (replaced) [<a href="/pdf/2311.14045" title="Download PDF">pdf</a>, <a href="/format/2311.14045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics Informed Neural Network Framework for Unsteady Discretized  Reduced Order System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Halder%2C+R">Rahul Halder</a>, 
<a href="/search/math?searchtype=author&query=Stabile%2C+G">Giovanni Stabile</a>, 
<a href="/search/math?searchtype=author&query=Rozza%2C+G">Gianluigi Rozza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14387" title="Abstract">arXiv:2311.14387</a> (replaced) [<a href="/pdf/2311.14387" title="Download PDF">pdf</a>, <a href="/format/2311.14387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving Margin Maximization Exponentially Fast via Progressive Norm  Rescaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+Z">Zeping Min</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15480" title="Abstract">arXiv:2311.15480</a> (replaced) [<a href="/pdf/2311.15480" title="Download PDF">pdf</a>, <a href="/ps/2311.15480" title="Download PostScript">ps</a>, <a href="/format/2311.15480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Time Signature Determination for New Scores Using Lyrics for  Latent Rhythmic Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+C+C">Callie C. Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+D">Duoduo Liao</a>, 
<a href="/search/cs?searchtype=author&query=Guessford%2C+J">Jesse Guessford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2023 IEEE International Conference on Big Data (IEEE BigData 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15738" title="Abstract">arXiv:2311.15738</a> (replaced) [<a href="/pdf/2311.15738" title="Download PDF">pdf</a>, <a href="/format/2311.15738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On full linear convergence and optimal complexity of adaptive FEM with  inexact solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bringmann%2C+P">Philipp Bringmann</a>, 
<a href="/search/math?searchtype=author&query=Feischl%2C+M">Michael Feischl</a>, 
<a href="/search/math?searchtype=author&query=Miraci%2C+A">Ani Miraci</a>, 
<a href="/search/math?searchtype=author&query=Praetorius%2C+D">Dirk Praetorius</a>, 
<a href="/search/math?searchtype=author&query=Streitberger%2C+J">Julian Streitberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16522" title="Abstract">arXiv:2311.16522</a> (replaced) [<a href="/pdf/2311.16522" title="Download PDF">pdf</a>, <a href="/ps/2311.16522" title="Download PostScript">ps</a>, <a href="/format/2311.16522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Fault Characteristics Evaluation in Power Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+H">Hao Pei</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Si Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanfu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Che Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16826" title="Abstract">arXiv:2311.16826</a> (replaced) [<a href="/pdf/2311.16826" title="Download PDF">pdf</a>, <a href="/format/2311.16826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative analysis of phase-field and intrinsic cohesive zone models  for fracture simulations in multiphase materials with interfaces:  Investigation of the influence of the microstructure on the fracture  properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koopas%2C+R+N">Rasoul Najafi Koopas</a>, 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+S">Shahed Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=Rauter%2C+N">Natalie Rauter</a>, 
<a href="/search/cs?searchtype=author&query=Ostwald%2C+R">Richard Ostwald</a>, 
<a href="/search/cs?searchtype=author&query=Lammering%2C+R">Rolf Lammering</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16877" title="Abstract">arXiv:2311.16877</a> (replaced) [<a href="/pdf/2311.16877" title="Download PDF">pdf</a>, <a href="/format/2311.16877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imputation using training labels and classification via label imputation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+T+L">Tuan L. Vo</a>, 
<a href="/search/cs?searchtype=author&query=Halvorsen%2C+P">P&#xe5;l Halvorsen</a>, 
<a href="/search/cs?searchtype=author&query=Riegler%2C+M+A">Michael A. Riegler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18727" title="Abstract">arXiv:2311.18727</a> (replaced) [<a href="/pdf/2311.18727" title="Download PDF">pdf</a>, <a href="/format/2311.18727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Functional Differentiation in JAX
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Min Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The Twelfth International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01709" title="Abstract">arXiv:2312.01709</a> (replaced) [<a href="/pdf/2312.01709" title="Download PDF">pdf</a>, <a href="/ps/2312.01709" title="Download PostScript">ps</a>, <a href="/format/2312.01709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Challenging Curve Fitting Benchmark Test Set for Global  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cheng%2C+P">Peicong Cheng</a>, 
<a href="/search/math?searchtype=author&query=Cheng%2C+P">Peicheng Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Mathematical Software (cs.MS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02493" title="Abstract">arXiv:2312.02493</a> (replaced) [<a href="/pdf/2312.02493" title="Download PDF">pdf</a>, <a href="/format/2312.02493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Communication for Optimal Distributed Learning over  Unpredictable Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+S">Sahil Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Swany%2C+M">Martin Swany</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE International Conference on Big Data (BigData)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Big Data (BigData), 925-935
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03687" title="Abstract">arXiv:2312.03687</a> (replaced) [<a href="/pdf/2312.03687" title="Download PDF">pdf</a>, <a href="/format/2312.03687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatterGen: a generative model for inorganic materials design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Zeni%2C+C">Claudio Zeni</a>, 
<a href="/search/cond-mat?searchtype=author&query=Pinsler%2C+R">Robert Pinsler</a>, 
<a href="/search/cond-mat?searchtype=author&query=Z%C3%BCgner%2C+D">Daniel Z&#xfc;gner</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fowler%2C+A">Andrew Fowler</a>, 
<a href="/search/cond-mat?searchtype=author&query=Horton%2C+M">Matthew Horton</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fu%2C+X">Xiang Fu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Shysheya%2C+S">Sasha Shysheya</a>, 
<a href="/search/cond-mat?searchtype=author&query=Crabb%C3%A9%2C+J">Jonathan Crabb&#xe9;</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+L">Lixin Sun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Smith%2C+J">Jake Smith</a>, 
<a href="/search/cond-mat?searchtype=author&query=Nguyen%2C+B">Bichlien Nguyen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Schulz%2C+H">Hannes Schulz</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lewis%2C+S">Sarah Lewis</a>, 
<a href="/search/cond-mat?searchtype=author&query=Huang%2C+C">Chin-Wei Huang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lu%2C+Z">Ziheng Lu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhou%2C+Y">Yichi Zhou</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yang%2C+H">Han Yang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hao%2C+H">Hongxia Hao</a>, 
<a href="/search/cond-mat?searchtype=author&query=Li%2C+J">Jielan Li</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tomioka%2C+R">Ryota Tomioka</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xie%2C+T">Tian Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages main text, 35 pages supplementary information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03731" title="Abstract">arXiv:2312.03731</a> (replaced) [<a href="/pdf/2312.03731" title="Download PDF">pdf</a>, <a href="/format/2312.03731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03905" title="Abstract">arXiv:2312.03905</a> (replaced) [<a href="/pdf/2312.03905" title="Download PDF">pdf</a>, <a href="/format/2312.03905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Pseudo-Semantic Loss for Autoregressive Models with Logical  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+K">Kareem Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Van+den+Broeck%2C+G">Guy Van den Broeck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated detoxification experiments; moved example toxic generations to Github and added link
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04027" title="Abstract">arXiv:2312.04027</a> (replaced) [<a href="/pdf/2312.04027" title="Download PDF">pdf</a>, <a href="/ps/2312.04027" title="Download PostScript">ps</a>, <a href="/format/2312.04027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The sample complexity of multi-distribution learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Binghui Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05670" title="Abstract">arXiv:2312.05670</a> (replaced) [<a href="/pdf/2312.05670" title="Download PDF">pdf</a>, <a href="/ps/2312.05670" title="Download PostScript">ps</a>, <a href="/format/2312.05670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounds for the sampling discretization error and their applications to  universal sampling discretization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kosov%2C+E+D">E.D. Kosov</a>, 
<a href="/search/math?searchtype=author&query=Temlyakov%2C+V+N">V.N. Temlyakov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05778" title="Abstract">arXiv:2312.05778</a> (replaced) [<a href="/pdf/2312.05778" title="Download PDF">pdf</a>, <a href="/format/2312.05778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guiding ChatGPT to Fix Web UI Tests via Explanation-Consistency Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhuolin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiushi Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S+H">Shin Hwei Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05928" title="Abstract">arXiv:2312.05928</a> (replaced) [<a href="/pdf/2312.05928" title="Download PDF">pdf</a>, <a href="/format/2312.05928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+J">Joonwoo Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sooyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuewei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shinjae Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+J">Jiook Cha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06395" title="Abstract">arXiv:2312.06395</a> (replaced) [<a href="/pdf/2312.06395" title="Download PDF">pdf</a>, <a href="/format/2312.06395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Threshold Decision-Making Dynamics Adaptive to Physical Constraints and  Changing Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amorim%2C+G">Giovanna Amorim</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+M">Mar&#xed;a Santos</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Shinkyu Park</a>, 
<a href="/search/cs?searchtype=author&query=Franci%2C+A">Alessio Franci</a>, 
<a href="/search/cs?searchtype=author&query=Leonard%2C+N+E">Naomi Ehrich Leonard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06695" title="Abstract">arXiv:2312.06695</a> (replaced) [<a href="/pdf/2312.06695" title="Download PDF">pdf</a>, <a href="/format/2312.06695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving Reservoirs for Meta Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%A9ger%2C+C">Corentin L&#xe9;ger</a>, 
<a href="/search/cs?searchtype=author&query=Hamon%2C+G">Gautier Hamon</a>, 
<a href="/search/cs?searchtype=author&query=Nisioti%2C+E">Eleni Nisioti</a>, 
<a href="/search/cs?searchtype=author&query=Hinaut%2C+X">Xavier Hinaut</a>, 
<a href="/search/cs?searchtype=author&query=Moulin-Frier%2C+C">Cl&#xe9;ment Moulin-Frier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08557" title="Abstract">arXiv:2312.08557</a> (replaced) [<a href="/pdf/2312.08557" title="Download PDF">pdf</a>, <a href="/format/2312.08557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating and Querying Data Cubes in Python using pyCube
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vang%2C+S">Sigmundur Vang</a>, 
<a href="/search/cs?searchtype=author&query=Thomsen%2C+C">Christian Thomsen</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+T+B">Torben Bach Pedersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of DOLAP2024 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08616" title="Abstract">arXiv:2312.08616</a> (replaced) [<a href="/pdf/2312.08616" title="Download PDF">pdf</a>, <a href="/format/2312.08616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Neural Diffusion Framework on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongrui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09486" title="Abstract">arXiv:2312.09486</a> (replaced) [<a href="/pdf/2312.09486" title="Download PDF">pdf</a>, <a href="/format/2312.09486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Batch Normalization for Realistic Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zixian Su</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiufeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10048" title="Abstract">arXiv:2312.10048</a> (replaced) [<a href="/pdf/2312.10048" title="Download PDF">pdf</a>, <a href="/ps/2312.10048" title="Download PostScript">ps</a>, <a href="/format/2312.10048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Enhanced Aspect-Level Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+K">Kavita Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Ritu Patel</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+S">Sunita Iyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10049" title="Abstract">arXiv:2312.10049</a> (replaced) [<a href="/pdf/2312.10049" title="Download PDF">pdf</a>, <a href="/ps/2312.10049" title="Download PostScript">ps</a>, <a href="/format/2312.10049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Reasoning Based on Attention GCN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Meera Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Khanna%2C+R">Ravi Khanna</a>, 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+D">Divya Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+N">Nandini Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10572" title="Abstract">arXiv:2312.10572</a> (replaced) [<a href="/pdf/2312.10572" title="Download PDF">pdf</a>, <a href="/format/2312.10572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Anonymous Multi-Agent Path Finding Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+Z+A">Zain Alabedeen Ali</a>, 
<a href="/search/cs?searchtype=author&query=Yakovlev%2C+K">Konstantin Yakovlev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10623" title="Abstract">arXiv:2312.10623</a> (replaced) [<a href="/pdf/2312.10623" title="Download PDF">pdf</a>, <a href="/format/2312.10623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Query-based API Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Moshi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Harzevili%2C+N+S">Nima Shiri Harzevili</a>, 
<a href="/search/cs?searchtype=author&query=Belle%2C+A+B">Alvine Boaye Belle</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinqiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+M">Ming Zhen</a> (Jack)
<a href="/search/cs?searchtype=author&query=Jiang">Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11456" title="Abstract">arXiv:2312.11456</a> (replaced) [<a href="/pdf/2312.11456" title="Download PDF">pdf</a>, <a href="/format/2312.11456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Preference Learning from Human Feedback: Bridging Theory and  Practice for RLHF under KL-Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hanze Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chenlu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Han Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages; mathematical foundation and practical algorithms of RLHF
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11714" title="Abstract">arXiv:2312.11714</a> (replaced) [<a href="/pdf/2312.11714" title="Download PDF">pdf</a>, <a href="/format/2312.11714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Transformer: Integrating Local and Global Features for Better Time  Series Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuansan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wijewickrema%2C+S">Sudanthi Wijewickrema</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Bester%2C+C">Christofer Bester</a>, 
<a href="/search/cs?searchtype=author&query=O%27Leary%2C+S">Stephen O&#x27;Leary</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+J">James Bailey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures and 16 tables. SDM24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11730" title="Abstract">arXiv:2312.11730</a> (replaced) [<a href="/pdf/2312.11730" title="Download PDF">pdf</a>, <a href="/format/2312.11730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stronger Graph Transformer with Regularized Attention Scores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ku%2C+E">Eugene Ku</a>, 
<a href="/search/cs?searchtype=author&query=Arunraj%2C+S">Swetha Arunraj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12964" title="Abstract">arXiv:2312.12964</a> (replaced) [<a href="/pdf/2312.12964" title="Download PDF">pdf</a>, <a href="/format/2312.12964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Far- and Near-Field Channel Measurements and Characterization in the  Terahertz Band Using a Virtual Antenna Array
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Ziming Yu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chong Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13250" title="Abstract">arXiv:2312.13250</a> (replaced) [<a href="/pdf/2312.13250" title="Download PDF">pdf</a>, <a href="/format/2312.13250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The role of data embedding in equivariant quantum convolutional neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Das%2C+S">Sreetama Das</a>, 
<a href="/search/quant-ph?searchtype=author&query=Martina%2C+S">Stefano Martina</a>, 
<a href="/search/quant-ph?searchtype=author&query=Caruso%2C+F">Filippo Caruso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures. Significant changes compared to previous version. New results added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13470" title="Abstract">arXiv:2312.13470</a> (replaced) [<a href="/pdf/2312.13470" title="Download PDF">pdf</a>, <a href="/ps/2312.13470" title="Download PostScript">ps</a>, <a href="/format/2312.13470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coffee: Cost-Effective Edge Caching for 360 Degree Live Video Streaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tingwei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+T">Tongyu Zong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Liyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Houwei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13778" title="Abstract">arXiv:2312.13778</a> (replaced) [<a href="/e-print/2312.13778" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Evolution from Single-Point to Polygon for Scene Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+L">Linger Deng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xudong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper lacks innovation and has insufficient rigor in experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15600" title="Abstract">arXiv:2312.15600</a> (replaced) [<a href="/pdf/2312.15600" title="Download PDF">pdf</a>, <a href="/format/2312.15600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-aware Communication for Multi-agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinran Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 23nd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15816" title="Abstract">arXiv:2312.15816</a> (replaced) [<a href="/pdf/2312.15816" title="Download PDF">pdf</a>, <a href="/format/2312.15816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEILP: Time Prediction over Knowledge Graphs via Logical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+S">Siheng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Payani%2C+A">Ali Payani</a>, 
<a href="/search/cs?searchtype=author&query=Kerce%2C+J+C">James C Kerce</a>, 
<a href="/search/cs?searchtype=author&query=Fekri%2C+F">Faramarz Fekri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI24 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15915" title="Abstract">arXiv:2312.15915</a> (replaced) [<a href="/pdf/2312.15915" title="Download PDF">pdf</a>, <a href="/format/2312.15915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChartBench: A Benchmark for Complex Visual Reasoning in Charts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengzhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Sinan Du</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yiyan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengjin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jian Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16129" title="Abstract">arXiv:2312.16129</a> (replaced) [<a href="/pdf/2312.16129" title="Download PDF">pdf</a>, <a href="/format/2312.16129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Shape Sonification for Tumor Localization in Breast Cancer  Surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtz%2C+L">Laura Sch&#xfc;tz</a>, 
<a href="/search/cs?searchtype=author&query=Chemaly%2C+T+E">Trishia El Chemaly</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+E">Emmanuelle Weber</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+A+T">Anh Thien Doan</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+J">Jacqueline Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Leuze%2C+C">Christoph Leuze</a>, 
<a href="/search/cs?searchtype=author&query=Daniel%2C+B">Bruce Daniel</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the CHI Conference on Human Factors in Computing
  Systems (CHI '24), May 11-16, 2024, Honolulu, HI, USA. ACM, New York, NY, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16377" title="Abstract">arXiv:2312.16377</a> (replaced) [<a href="/pdf/2312.16377" title="Download PDF">pdf</a>, <a href="/format/2312.16377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heavy-Traffic Optimal Size- and State-Aware Dispatching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Runhan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Grosof%2C+I">Isaac Grosof</a>, 
<a href="/search/cs?searchtype=author&query=Scully%2C+Z">Ziv Scully</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM SIGMETRICS / IFIP Performance 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16554" title="Abstract">arXiv:2312.16554</a> (replaced) [<a href="/pdf/2312.16554" title="Download PDF">pdf</a>, <a href="/format/2312.16554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theoretical Analysis of Efficiency Constrained Utility-Privacy  Bi-Objective Optimization in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanlin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Gongxi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuxing Han</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16652" title="Abstract">arXiv:2312.16652</a> (replaced) [<a href="/pdf/2312.16652" title="Download PDF">pdf</a>, <a href="/ps/2312.16652" title="Download PostScript">ps</a>, <a href="/format/2312.16652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant-based Program Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Bataineh%2C+O+I">Omar I. Al-Bataineh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the 27th International Conference on Fundamental Approaches to Software Engineering (FASE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16762" title="Abstract">arXiv:2312.16762</a> (replaced) [<a href="/pdf/2312.16762" title="Download PDF">pdf</a>, <a href="/format/2312.16762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backstepping Neural Operators for $2\times 2$ Hyperbolic PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+S">Shanshan Wang</a>, 
<a href="/search/math?searchtype=author&query=Diagne%2C+M">Mamadou Diagne</a>, 
<a href="/search/math?searchtype=author&query=Krsti%C4%87%2C+M">Miroslav Krsti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17560" title="Abstract">arXiv:2312.17560</a> (replaced) [<a href="/pdf/2312.17560" title="Download PDF">pdf</a>, <a href="/ps/2312.17560" title="Download PostScript">ps</a>, <a href="/format/2312.17560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertain research country rankings. Should we continue producing  uncertain rankings?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodriguez-Navarro%2C+A">Alonso Rodriguez-Navarro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Information Retrieval (cs.IR); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01577" title="Abstract">arXiv:2401.01577</a> (replaced) [<a href="/pdf/2401.01577" title="Download PDF">pdf</a>, <a href="/format/2401.01577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Time Personalization with Meta Prompt for Gaze Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Julia Qi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+M">Mohammad Hassanpour</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Plataniotis%2C+K">Konstantinos Plataniotis</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yuanhao Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01722" title="Abstract">arXiv:2401.01722</a> (replaced) [<a href="/pdf/2401.01722" title="Download PDF">pdf</a>, <a href="/format/2401.01722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Splitting Methods for differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Blanes%2C+S">Sergio Blanes</a>, 
<a href="/search/math?searchtype=author&query=Casas%2C+F">Fernando Casas</a>, 
<a href="/search/math?searchtype=author&query=Murua%2C+A">Ander Murua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Review paper to be published in Acta Numerica 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01801" title="Abstract">arXiv:2401.01801</a> (replaced) [<a href="/pdf/2401.01801" title="Download PDF">pdf</a>, <a href="/format/2401.01801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quatum inspired neural network for geometric modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weitao Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuecang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01836" title="Abstract">arXiv:2401.01836</a> (replaced) [<a href="/pdf/2401.01836" title="Download PDF">pdf</a>, <a href="/format/2401.01836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Optimal Control: Concurrent System Identification and Control  Learning with Neural ODE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chi%2C+C">Cheng Chi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, code open sourced in format of Google Colab notebooks; Resubmitted for adding missed references in the first submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02968" title="Abstract">arXiv:2401.02968</a> (replaced) [<a href="/pdf/2401.02968" title="Download PDF">pdf</a>, <a href="/ps/2401.02968" title="Download PostScript">ps</a>, <a href="/format/2401.02968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rule-Guided Joint Embedding Learning over Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qisong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Ji Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Sijia Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Neng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03343" title="Abstract">arXiv:2401.03343</a> (replaced) [<a href="/pdf/2401.03343" title="Download PDF">pdf</a>, <a href="/ps/2401.03343" title="Download PostScript">ps</a>, <a href="/format/2401.03343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rediscovering Ranganathan: A Prismatic View of His Life through the  Knowledge Graph Spectrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+B">B. Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Arzoo%2C+S">S. Arzoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03451" title="Abstract">arXiv:2401.03451</a> (replaced) [<a href="/pdf/2401.03451" title="Download PDF">pdf</a>, <a href="/format/2401.03451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization Over Trained Neural Networks: Taking a Relaxing Walk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tong%2C+J">Jiatai Tong</a>, 
<a href="/search/math?searchtype=author&query=Cai%2C+J">Junyang Cai</a>, 
<a href="/search/math?searchtype=author&query=Serra%2C+T">Thiago Serra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03591" title="Abstract">arXiv:2401.03591</a> (replaced) [<a href="/pdf/2401.03591" title="Download PDF">pdf</a>, <a href="/ps/2401.03591" title="Download PostScript">ps</a>, <a href="/format/2401.03591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text Classification Based on Knowledge Graphs and Improved Attention  Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chenwei Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinyi Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04856" title="Abstract">arXiv:2401.04856</a> (replaced) [<a href="/pdf/2401.04856" title="Download PDF">pdf</a>, <a href="/format/2401.04856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Good Score Does not Lead to A Good Generative Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sixu Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05363" title="Abstract">arXiv:2401.05363</a> (replaced) [<a href="/pdf/2401.05363" title="Download PDF">pdf</a>, <a href="/format/2401.05363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Sleep Staging via Multi-Level Domain Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiquan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Sha Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+H">Haiteng Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shijian Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+G">Gang Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05382" title="Abstract">arXiv:2401.05382</a> (replaced) [<a href="/pdf/2401.05382" title="Download PDF">pdf</a>, <a href="/ps/2401.05382" title="Download PostScript">ps</a>, <a href="/format/2401.05382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Genetic Programming Models with Multiple Equations for Accurate  Semi-Autogenous Grinding Mill Throughput Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghasemi%2C+Z">Zahra Ghasemi</a>, 
<a href="/search/cs?searchtype=author&query=Nesht%2C+M">Mehdi Nesht</a>, 
<a href="/search/cs?searchtype=author&query=Aldrich%2C+C">Chris Aldrich</a>, 
<a href="/search/cs?searchtype=author&query=Karageorgos%2C+J">John Karageorgos</a>, 
<a href="/search/cs?searchtype=author&query=Zanin%2C+M">Max Zanin</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+F">Frank Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05578" title="Abstract">arXiv:2401.05578</a> (replaced) [<a href="/pdf/2401.05578" title="Download PDF">pdf</a>, <a href="/ps/2401.05578" title="Download PostScript">ps</a>, <a href="/format/2401.05578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Cerebral Blood Flow Analysis via Extreme Learning Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Z">Zhenya Zang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingda Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05580" title="Abstract">arXiv:2401.05580</a> (replaced) [<a href="/pdf/2401.05580" title="Download PDF">pdf</a>, <a href="/ps/2401.05580" title="Download PostScript">ps</a>, <a href="/format/2401.05580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Blood Flow Assessment in Diffuse Correlation Spectroscopy: A  Transfer Learning Approach with Noise Robustness Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingda Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05602" title="Abstract">arXiv:2401.05602</a> (replaced) [<a href="/pdf/2401.05602" title="Download PDF">pdf</a>, <a href="/ps/2401.05602" title="Download PostScript">ps</a>, <a href="/format/2401.05602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nucleus subtype classification using inter-modality learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Remedios%2C+L+W">Lucas W. Remedios</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+S">Shunxing Bao</a>, 
<a href="/search/cs?searchtype=author&query=Remedios%2C+S+W">Samuel W. Remedios</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H+H">Ho Hin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L+Y">Leon Y. Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Thomas Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+R">Ruining Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Can Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+K+S">Ken S. Lau</a>, 
<a href="/search/cs?searchtype=author&query=Roland%2C+J+T">Joseph T. Roland</a>, 
<a href="/search/cs?searchtype=author&query=Washington%2C+M+K">Mary K. Washington</a>, 
<a href="/search/cs?searchtype=author&query=Coburn%2C+L+A">Lori A. Coburn</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+K+T">Keith T. Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuankai Huo</a>, 
<a href="/search/cs?searchtype=author&query=Landman%2C+B+A">Bennett A. Landman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06256" title="Abstract">arXiv:2401.06256</a> (replaced) [<a href="/pdf/2401.06256" title="Download PDF">pdf</a>, <a href="/ps/2401.06256" title="Download PostScript">ps</a>, <a href="/format/2401.06256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Universal Knowledge Model and Cognitive Architecture for Prototyping  AGI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sukhobokov%2C+A">Artem Sukhobokov</a>, 
<a href="/search/cs?searchtype=author&query=Belousov%2C+E">Evgeny Belousov</a>, 
<a href="/search/cs?searchtype=author&query=Gromozdov%2C+D">Danila Gromozdov</a>, 
<a href="/search/cs?searchtype=author&query=Zenger%2C+A">Anna Zenger</a>, 
<a href="/search/cs?searchtype=author&query=Popov%2C+I">Ilya Popov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06574" title="Abstract">arXiv:2401.06574</a> (replaced) [<a href="/pdf/2401.06574" title="Download PDF">pdf</a>, <a href="/format/2401.06574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CTMCs with Imprecisely Timed Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badings%2C+T">Thom Badings</a>, 
<a href="/search/cs?searchtype=author&query=Volk%2C+M">Matthias Volk</a>, 
<a href="/search/cs?searchtype=author&query=Junges%2C+S">Sebastian Junges</a>, 
<a href="/search/cs?searchtype=author&query=Stoelinga%2C+M">Marielle Stoelinga</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+N">Nils Jansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version (with appendix) of the paper accepted at TACAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06650" title="Abstract">arXiv:2401.06650</a> (replaced) [<a href="/pdf/2401.06650" title="Download PDF">pdf</a>, <a href="/ps/2401.06650" title="Download PostScript">ps</a>, <a href="/format/2401.06650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMI-based robust model predictive control for a quarter car with series  active variable geometry suspension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+Z">Zilin Feng</a>, 
<a href="/search/eess?searchtype=author&query=Georgiou%2C+A">Anastasis Georgiou</a>, 
<a href="/search/eess?searchtype=author&query=Evangelou%2C+S+A">Simos A. Evangelou</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+M">Min Yu</a>, 
<a href="/search/eess?searchtype=author&query=Jaimoukha%2C+I+M">Imad M Jaimoukha</a>, 
<a href="/search/eess?searchtype=author&query=Dini%2C+D">Daniele Dini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, 2 tables, IEEE Transactions on Control Systems Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06772" title="Abstract">arXiv:2401.06772</a> (replaced) [<a href="/pdf/2401.06772" title="Download PDF">pdf</a>, <a href="/ps/2401.06772" title="Download PostScript">ps</a>, <a href="/format/2401.06772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Parsing for Question Answering over Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Sijia Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qisong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2401.02968">arXiv:2401.02968</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06982" title="Abstract">arXiv:2401.06982</a> (replaced) [<a href="/pdf/2401.06982" title="Download PDF">pdf</a>, <a href="/format/2401.06982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plug-In Diffusion Model for Embedding Denoising in Recommendation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jujia Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Teng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07548" title="Abstract">arXiv:2401.07548</a> (replaced) [<a href="/pdf/2401.07548" title="Download PDF">pdf</a>, <a href="/format/2401.07548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rabin Games and Colourful Universal Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+R">Rupak Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Saglam%2C+I">Irmak Saglam</a>, 
<a href="/search/cs?searchtype=author&query=Thejaswini%2C+K+S">K. S. Thejaswini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 4 figures. Accepted at TACAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Data Structures and Algorithms (cs.DS); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07841" title="Abstract">arXiv:2401.07841</a> (replaced) [<a href="/pdf/2401.07841" title="Download PDF">pdf</a>, <a href="/format/2401.07841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Simulation at Machine Level: A Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deubert%2C+D">Darius Deubert</a>, 
<a href="/search/eess?searchtype=author&query=Klingel%2C+L">Lars Klingel</a>, 
<a href="/search/eess?searchtype=author&query=Selig%2C+A">Andreas Selig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 12 figures, submitted to Springer - The International Journal on Advanced Manufacturing Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08552" title="Abstract">arXiv:2401.08552</a> (replaced) [<a href="/pdf/2401.08552" title="Download PDF">pdf</a>, <a href="/format/2401.08552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining Time Series via Contrastive and Locally Sparse Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zichuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianchun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zefan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dongsheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunlin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lunting Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09720" title="Abstract">arXiv:2401.09720</a> (replaced) [<a href="/pdf/2401.09720" title="Download PDF">pdf</a>, <a href="/format/2401.09720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianBody: Clothed Human Reconstruction via 3d Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengtian Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shengxiang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhifeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keyu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10124" title="Abstract">arXiv:2401.10124</a> (replaced) [<a href="/pdf/2401.10124" title="Download PDF">pdf</a>, <a href="/format/2401.10124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower Ricci Curvature for Efficient Community Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Park%2C+Y+J">Yun Jin Park</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+D">Didong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10244" title="Abstract">arXiv:2401.10244</a> (replaced) [<a href="/pdf/2401.10244" title="Download PDF">pdf</a>, <a href="/ps/2401.10244" title="Download PostScript">ps</a>, <a href="/format/2401.10244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Driven Recommendation System Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Siwei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10282" title="Abstract">arXiv:2401.10282</a> (replaced) [<a href="/pdf/2401.10282" title="Download PDF">pdf</a>, <a href="/format/2401.10282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioDiffusion: A Versatile Diffusion Model for Biomedical Signal  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaomin Li</a>, 
<a href="/search/eess?searchtype=author&query=Sakevych%2C+M">Mykhailo Sakevych</a>, 
<a href="/search/eess?searchtype=author&query=Atkinson%2C+G">Gentry Atkinson</a>, 
<a href="/search/eess?searchtype=author&query=Metsis%2C+V">Vangelis Metsis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10711" title="Abstract">arXiv:2401.10711</a> (replaced) [<a href="/pdf/2401.10711" title="Download PDF">pdf</a>, <a href="/format/2401.10711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal  Models for Video Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+C">Chenghang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+W">Weifeng Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10768" title="Abstract">arXiv:2401.10768</a> (replaced) [<a href="/pdf/2401.10768" title="Download PDF">pdf</a>, <a href="/format/2401.10768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Hallucinations of Large Language Models via Knowledge  Consistent Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fanqi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10800" title="Abstract">arXiv:2401.10800</a> (replaced) [<a href="/pdf/2401.10800" title="Download PDF">pdf</a>, <a href="/format/2401.10800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of AMOC transition probabilities using a machine learning  based rare-event algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Jacques-Dumas%2C+V">Val&#xe9;rian Jacques-Dumas</a>, 
<a href="/search/physics?searchtype=author&query=van+Westen%2C+R+M">Ren&#xe9; M. van Westen</a>, 
<a href="/search/physics?searchtype=author&query=Dijkstra%2C+H+A">Henk A. Dijkstra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10893" title="Abstract">arXiv:2401.10893</a> (replaced) [<a href="/pdf/2401.10893" title="Download PDF">pdf</a>, <a href="/ps/2401.10893" title="Download PostScript">ps</a>, <a href="/format/2401.10893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Location Sensitive Embedding for Knowledge Graph Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+D">Deepak Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Ishaan%2C+A">Anjali Ishaan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11113" title="Abstract">arXiv:2401.11113</a> (replaced) [<a href="/pdf/2401.11113" title="Download PDF">pdf</a>, <a href="/format/2401.11113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SleepNet: Attention-Enhanced Robust Sleep Prediction using Dynamic  Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalid%2C+M">Maryam Khalid</a>, 
<a href="/search/cs?searchtype=author&query=Klerman%2C+E+B">Elizabeth B. Klerman</a>, 
<a href="/search/cs?searchtype=author&query=Mchill%2C+A+W">Andrew W. Mchill</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+A+J+K">Andrew J. K. Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Sano%2C+A">Akane Sano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 8 (March 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11156" title="Abstract">arXiv:2401.11156</a> (replaced) [<a href="/pdf/2401.11156" title="Download PDF">pdf</a>, <a href="/format/2401.11156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Speaker Verification for Spoof Awareness in the Embedding  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuechen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sahidullah%2C+M">Md Sahidullah</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+A">Kong Aik Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kinnunen%2C+T">Tomi Kinnunen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE/ACM Transactions on Audio, Speech, and Language Processing (doi updated)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11160" title="Abstract">arXiv:2401.11160</a> (replaced) [<a href="/pdf/2401.11160" title="Download PDF">pdf</a>, <a href="/ps/2401.11160" title="Download PostScript">ps</a>, <a href="/format/2401.11160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quasi-Perfect and Distance-Optimal Codes in the Sum-Rank Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, only quasi-perfect sum codes constructed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11257" title="Abstract">arXiv:2401.11257</a> (replaced) [<a href="/pdf/2401.11257" title="Download PDF">pdf</a>, <a href="/format/2401.11257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Policy Distance for Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tianyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Z">Zhiqiang Pu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+X">Xiaolin Ai</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+T">Tenghai Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jianqiang Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11414" title="Abstract">arXiv:2401.11414</a> (replaced) [<a href="/pdf/2401.11414" title="Download PDF">pdf</a>, <a href="/format/2401.11414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S$^3$M-Net: Joint Learning of Semantic Segmentation and Stereo Matching  for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chuang-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fisher Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to IEEE Trans. on Intelligent Vehicles (T-IV)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11648" title="Abstract">arXiv:2401.11648</a> (replaced) [<a href="/pdf/2401.11648" title="Download PDF">pdf</a>, <a href="/format/2401.11648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal  Contrastive EHR Modelling with Hierarchical Regularisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koo%2C+H">Heejoon Koo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024 (The 18th Conference of the European Chapter of the Association for Computational Linguistics)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11723" title="Abstract">arXiv:2401.11723</a> (replaced) [<a href="/pdf/2401.11723" title="Download PDF">pdf</a>, <a href="/format/2401.11723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Attacks in Machine Learning-based IoT Ecosystems: A Survey  and the Open Libraries Behind Them
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chris Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kelvin Wong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11742" title="Abstract">arXiv:2401.11742</a> (replaced) [<a href="/pdf/2401.11742" title="Download PDF">pdf</a>, <a href="/ps/2401.11742" title="Download PostScript">ps</a>, <a href="/format/2401.11742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Navigation: Inferring the Interlocking Map of Knowledge from  Research Trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Shibing Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yurui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chaolin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yifang Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 9 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Digital Libraries (cs.DL); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11792" title="Abstract">arXiv:2401.11792</a> (replaced) [<a href="/pdf/2401.11792" title="Download PDF">pdf</a>, <a href="/format/2401.11792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Generalized end-to-end Autonomous Driving System with  Reinforcement Learning and Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zuojin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">YongQiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianyu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11798" title="Abstract">arXiv:2401.11798</a> (replaced) [<a href="/pdf/2401.11798" title="Download PDF">pdf</a>, <a href="/format/2401.11798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation on Spatial-Temporal Graph Convolutional Network  for Traffic Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izadi%2C+M">Mohammad Izadi</a>, 
<a href="/search/cs?searchtype=author&query=Safayani%2C+M">Mehran Safayani</a>, 
<a href="/search/cs?searchtype=author&query=Mirzaei%2C+A">Abdolreza Mirzaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11864" title="Abstract">arXiv:2401.11864</a> (replaced) [<a href="/pdf/2401.11864" title="Download PDF">pdf</a>, <a href="/format/2401.11864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Small Language Models&#x27; Mathematical Reasoning via  Equation-of-Thought Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xunyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Can Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12007" title="Abstract">arXiv:2401.12007</a> (replaced) [<a href="/pdf/2401.12007" title="Download PDF">pdf</a>, <a href="/format/2401.12007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor-view Topological Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+T">Tao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Elynn Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuzhou Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12012" title="Abstract">arXiv:2401.12012</a> (replaced) [<a href="/pdf/2401.12012" title="Download PDF">pdf</a>, <a href="/format/2401.12012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for  Lazy Clients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengdi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bodonhelyi%2C+A">Anna Bodonhelyi</a>, 
<a href="/search/cs?searchtype=author&query=Bozkir%2C+E">Efe Bozkir</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+E">Enkelejda Kasneci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the AAAI Conference on Artificial Intelligence 2024 (AAAI'24)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the AAAI Conference on Artificial Intelligence 2024
  (AAAI'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12125" title="Abstract">arXiv:2401.12125</a> (replaced) [<a href="/pdf/2401.12125" title="Download PDF">pdf</a>, <a href="/format/2401.12125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodeTailor: Personalized Parsons Puzzles are Preferred Over AI-Generated  Solutions to Support Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinying Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ericson%2C+B+J">Barbara J. Ericson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12131" title="Abstract">arXiv:2401.12131</a> (replaced) [<a href="/pdf/2401.12131" title="Download PDF">pdf</a>, <a href="/format/2401.12131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroSynt: A Neuro-symbolic Portfolio Solver for Reactive Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cosler%2C+M">Matthias Cosler</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+C">Christopher Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Omar%2C+A">Ayham Omar</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+F">Frederik Schmitt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12586" title="Abstract">arXiv:2401.12586</a> (replaced) [<a href="/pdf/2401.12586" title="Download PDF">pdf</a>, <a href="/format/2401.12586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C2Ideas: Supporting Creative Interior Color Design Ideation with Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yihan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Manling Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wei Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12590" title="Abstract">arXiv:2401.12590</a> (replaced) [<a href="/pdf/2401.12590" title="Download PDF">pdf</a>, <a href="/format/2401.12590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyCF: Towards the Optimal Spectral Graph Filters for Collaborative  Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yifang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yiyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhiping Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12665" title="Abstract">arXiv:2401.12665</a> (replaced) [<a href="/pdf/2401.12665" title="Download PDF">pdf</a>, <a href="/format/2401.12665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClipSAM: CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengze Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jianjian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuhan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Chongjun Tu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages,17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12729" title="Abstract">arXiv:2401.12729</a> (replaced) [<a href="/pdf/2401.12729" title="Download PDF">pdf</a>, <a href="/format/2401.12729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Object Detection Performance for Small Objects through  Synthetic Data Generation and Proportional Class-Balancing Technique: A  Comparative Study in Industrial Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antony%2C+J">Jibinraj Antony</a>, 
<a href="/search/cs?searchtype=author&query=Hegiste%2C+V">Vinit Hegiste</a>, 
<a href="/search/cs?searchtype=author&query=Nazeri%2C+A">Ali Nazeri</a>, 
<a href="/search/cs?searchtype=author&query=Tavakoli%2C+H">Hooman Tavakoli</a>, 
<a href="/search/cs?searchtype=author&query=Walunj%2C+S">Snehal Walunj</a>, 
<a href="/search/cs?searchtype=author&query=Plociennik%2C+C">Christiane Plociennik</a>, 
<a href="/search/cs?searchtype=author&query=Ruskowski%2C+M">Martin Ruskowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented in conference ESAIM23 1st European Symposium on Artificial Intelligence in Manufacturing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12900" title="Abstract">arXiv:2401.12900</a> (replaced) [<a href="/pdf/2401.12900" title="Download PDF">pdf</a>, <a href="/format/2401.12900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PSAvatar: A Point-based Morphable Shape Model for Real-Time Head Avatar  Animation with 3D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhongyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Z">Zhenyu Bao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+G">Guoping Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kanglin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12923" title="Abstract">arXiv:2401.12923</a> (replaced) [<a href="/pdf/2401.12923" title="Download PDF">pdf</a>, <a href="/format/2401.12923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep multitask neural networks for solving some stochastic optimal  control problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yeo%2C+C">Christian Yeo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12946" title="Abstract">arXiv:2401.12946</a> (replaced) [<a href="/pdf/2401.12946" title="Download PDF">pdf</a>, <a href="/format/2401.12946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coverage Axis++: Efficient Inner Point Selection for 3D Shape  Skeletonization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zimeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Cheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xiaoxiao Long</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+S">Shiqing Xin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaoming Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Geometry (cs.CG); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13034" title="Abstract">arXiv:2401.13034</a> (replaced) [<a href="/pdf/2401.13034" title="Download PDF">pdf</a>, <a href="/format/2401.13034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locality Sensitive Sparse Encoding for Learning World Models Online
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zichen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chao Du</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W+S">Wee Sun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Min Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13098" title="Abstract">arXiv:2401.13098</a> (replaced) [<a href="/pdf/2401.13098" title="Download PDF">pdf</a>, <a href="/format/2401.13098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gravity-Informed Deep Learning Framework for Predicting Ship Traffic  Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruixin Song</a>, 
<a href="/search/cs?searchtype=author&query=Spadon%2C+G">Gabriel Spadon</a>, 
<a href="/search/cs?searchtype=author&query=Pelot%2C+R">Ronald Pelot</a>, 
<a href="/search/cs?searchtype=author&query=Matwin%2C+S">Stan Matwin</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+A">Amilcar Soares</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 7 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13112" title="Abstract">arXiv:2401.13112</a> (replaced) [<a href="/pdf/2401.13112" title="Download PDF">pdf</a>, <a href="/format/2401.13112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DISCOUNT: Distributional Counterfactual Explanation With Optimal  Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+L">Lei You</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lele Cao</a>, 
<a href="/search/cs?searchtype=author&query=Nilsson%2C+M">Mattias Nilsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in ICML 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13165" title="Abstract">arXiv:2401.13165</a> (replaced) [<a href="/pdf/2401.13165" title="Download PDF">pdf</a>, <a href="/ps/2401.13165" title="Download PostScript">ps</a>, <a href="/format/2401.13165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misgendering and Assuming Gender in Machine Translation when Working  with Low-Resource Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Sourojit Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+S">Srishti Chatterjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Upcoming Publication, Gendered Technology in Translation and Interpreting Centering Rights in the Development of Language Technology, Routledge 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13231" title="Abstract">arXiv:2401.13231</a> (replaced) [<a href="/pdf/2401.13231" title="Download PDF">pdf</a>, <a href="/format/2401.13231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DittoGym: Learning to Control Soft Shape-Shifting Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Suning Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sitzmann%2C+V">Vincent Sitzmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13232" title="Abstract">arXiv:2401.13232</a> (replaced) [<a href="/pdf/2401.13232" title="Download PDF">pdf</a>, <a href="/ps/2401.13232" title="Download PostScript">ps</a>, <a href="/format/2401.13232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Source Coding Using Constrained-Random-Number Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muramatsu%2C+J">Jun Muramatsu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, this is the extended version of the paper submitted to ISIT2024, appendices are the revision of <a href="/abs/2206.00792">arXiv:2206.00792</a>, (v2) add Refs. [10][31]. arXiv admin note: text overlap with <a href="/abs/2206.00792">arXiv:2206.00792</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13255" title="Abstract">arXiv:2401.13255</a> (replaced) [<a href="/pdf/2401.13255" title="Download PDF">pdf</a>, <a href="/ps/2401.13255" title="Download PostScript">ps</a>, <a href="/format/2401.13255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructing a fully homomorphic encryption scheme with the Yoneda Lemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuy%C3%A9ras%2C+R">R&#xe9;my Tuy&#xe9;ras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages; improved phrasing, corrected typos, added clarifications; removed unused assumptions and changed the construction of section 5 (to address a type of attacks)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Category Theory (math.CT)

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13275" title="Abstract">arXiv:2401.13275</a> (replaced) [<a href="/pdf/2401.13275" title="Download PDF">pdf</a>, <a href="/format/2401.13275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can AI Assistants Know What They Don&#x27;t Know?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qinyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tianxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shimin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyang Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhengfu He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13324" title="Abstract">arXiv:2401.13324</a> (replaced) [<a href="/pdf/2401.13324" title="Download PDF">pdf</a>, <a href="/ps/2401.13324" title="Download PostScript">ps</a>, <a href="/format/2401.13324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information That Matters: Exploring Information Needs of People Affected  by Algorithmic Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmude%2C+T">Timoth&#xe9;e Schmude</a>, 
<a href="/search/cs?searchtype=author&query=Koesten%2C+L">Laura Koesten</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B6ller%2C+T">Torsten M&#xf6;ller</a>, 
<a href="/search/cs?searchtype=author&query=Tschiatschek%2C+S">Sebastian Tschiatschek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main text: 21 pages, 3 figures. Supplementary material is provided. Manuscript submitted for review to IJHCS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13329" title="Abstract">arXiv:2401.13329</a> (replaced) [<a href="/pdf/2401.13329" title="Download PDF">pdf</a>, <a href="/format/2401.13329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Video Diffusion for Unseen Cross-Domain Video Moment  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dezhao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shaogang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiabo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hailin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13429" title="Abstract">arXiv:2401.13429</a> (replaced) [<a href="/pdf/2401.13429" title="Download PDF">pdf</a>, <a href="/ps/2401.13429" title="Download PostScript">ps</a>, <a href="/format/2401.13429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of Correlated Random Vectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elimelech%2C+D">Dor Elimelech</a>, 
<a href="/search/cs?searchtype=author&query=Huleihel%2C+W">Wasim Huleihel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13565" title="Abstract">arXiv:2401.13565</a> (replaced) [<a href="/pdf/2401.13565" title="Download PDF">pdf</a>, <a href="/format/2401.13565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Malaysian Language Model Based on Mistral for Enhanced Local  Language Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zolkepli%2C+H">Husein Zolkepli</a>, 
<a href="/search/cs?searchtype=author&query=Razak%2C+A">Aisyah Razak</a>, 
<a href="/search/cs?searchtype=author&query=Adha%2C+K">Kamarul Adha</a>, 
<a href="/search/cs?searchtype=author&query=Nazhan%2C+A">Ariff Nazhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13802" title="Abstract">arXiv:2401.13802</a> (replaced) [<a href="/pdf/2401.13802" title="Download PDF">pdf</a>, <a href="/format/2401.13802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Efficacy of Large Language Models for Code Clone  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khajezade%2C+M">Mohamad Khajezade</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+J">Jie JW Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fard%2C+F+H">Fatemeh Hendijani Fard</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-P%C3%A9rez%2C+G">Gema Rodr&#xed;guez-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Shehata%2C+M+S">Mohamed Sami Shehata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13851" title="Abstract">arXiv:2401.13851</a> (replaced) [<a href="/pdf/2401.13851" title="Download PDF">pdf</a>, <a href="/ps/2401.13851" title="Download PostScript">ps</a>, <a href="/format/2401.13851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling NVIDIA&#x27;s Multi-speaker Multi-lingual TTS Systems with Zero-Shot  TTS to Indic Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+A">Akshit Arora</a>, 
<a href="/search/cs?searchtype=author&query=Badlani%2C+R">Rohan Badlani</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungwon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Valle%2C+R">Rafael Valle</a>, 
<a href="/search/cs?searchtype=author&query=Catanzaro%2C+B">Bryan Catanzaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presentation accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13919" title="Abstract">arXiv:2401.13919</a> (replaced) [<a href="/pdf/2401.13919" title="Download PDF">pdf</a>, <a href="/format/2401.13919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WebVoyager: Building an End-to-End Web Agent with Large Multimodal  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hongliang He</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wenlin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaixin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Z">Zhenzhong Lan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13922" title="Abstract">arXiv:2401.13922</a> (replaced) [<a href="/pdf/2401.13922" title="Download PDF">pdf</a>, <a href="/format/2401.13922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplified Successive Cancellation List Decoding of PAC Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saber%2C+H">Hamid Saber</a>, 
<a href="/search/cs?searchtype=author&query=Hatami%2C+H">Homayoon Hatami</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+J+H">Jung Hyun Bae</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13947" title="Abstract">arXiv:2401.13947</a> (replaced) [<a href="/pdf/2401.13947" title="Download PDF">pdf</a>, <a href="/format/2401.13947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Networked Multiagent Reinforcement Learning for Peer-to-Peer Energy  Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+C">Chen Feng</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+A+L">Andrew L. Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13956" title="Abstract">arXiv:2401.13956</a> (replaced) [<a href="/pdf/2401.13956" title="Download PDF">pdf</a>, <a href="/format/2401.13956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Image Quality Database for Multiple Industrial Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xuanchao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yanlin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chengxu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+K">Ke Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13998" title="Abstract">arXiv:2401.13998</a> (replaced) [<a href="/pdf/2401.13998" title="Download PDF">pdf</a>, <a href="/format/2401.13998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WAL-Net: Weakly supervised auxiliary task learning network for carotid  plaques classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gan%2C+H">Haitao Gan</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+L">Lingchao Fu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+R">Ran Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Gan%2C+W">Weiyan Gan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Furong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xiaoyan Wu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Zhi Yang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Z">Zhongwei Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14132" title="Abstract">arXiv:2401.14132</a> (replaced) [<a href="/pdf/2401.14132" title="Download PDF">pdf</a>, <a href="/format/2401.14132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Cross-Camera Collaboration for Video Analytics on Distributed  Smart Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+C">Chulhong Min</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Juheon Yi</a>, 
<a href="/search/cs?searchtype=author&query=Acer%2C+U+G">Utku Gunay Acer</a>, 
<a href="/search/cs?searchtype=author&query=Kawsar%2C+F">Fahim Kawsar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14166" title="Abstract">arXiv:2401.14166</a> (replaced) [<a href="/pdf/2401.14166" title="Download PDF">pdf</a>, <a href="/format/2401.14166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on  Few-shot Inference via Debiased Domain Abstraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangmeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+F">Fei Song</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yifan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+W">Wenwen Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Changwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14211" title="Abstract">arXiv:2401.14211</a> (replaced) [<a href="/pdf/2401.14211" title="Download PDF">pdf</a>, <a href="/format/2401.14211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Federated Learning through Adaptive Weight  Clustering and Server-Side Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsouvalas%2C+V">Vasileios Tsouvalas</a>, 
<a href="/search/cs?searchtype=author&query=Saeed%2C+A">Aaqib Saeed</a>, 
<a href="/search/cs?searchtype=author&query=Ozcelebi%2C+T">Tanir Ozcelebi</a>, 
<a href="/search/cs?searchtype=author&query=Meratnia%2C+N">Nirvana Meratnia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, Accepted on ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14215" title="Abstract">arXiv:2401.14215</a> (replaced) [<a href="/pdf/2401.14215" title="Download PDF">pdf</a>, <a href="/format/2401.14215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commonsense-augmented Memory Construction and Management in Long-term  Conversations via Context-aware Persona Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hana Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+K+T">Kai Tzu-iunn Ong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seoyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongha Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J">Jinyoung Yeo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1036">[1036]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14241" title="Abstract">arXiv:2401.14241</a> (replaced) [<a href="/pdf/2401.14241" title="Download PDF">pdf</a>, <a href="/format/2401.14241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Algorithms for Computing Sibson Capacity and Arimoto Capacity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamatsuka%2C+A">Akira Kamatsuka</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+Y">Yuki Ishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Kazama%2C+K">Koki Kazama</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+T">Takahiro Yoshida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1037">[1037]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14257" title="Abstract">arXiv:2401.14257</a> (replaced) [<a href="/pdf/2401.14257" title="Download PDF">pdf</a>, <a href="/format/2401.14257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minglin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weihao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yukun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Z">Zhe Sheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yisheng He</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zilong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yulan Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1038">[1038]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14265" title="Abstract">arXiv:2401.14265</a> (replaced) [<a href="/pdf/2401.14265" title="Download PDF">pdf</a>, <a href="/format/2401.14265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Worst-Case Per-User Error Bound for Asynchronous Unsourced Multiple  Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jyun-Sian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pin-Hsun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Mross%2C+M+A">Marcel A. Mross</a>, 
<a href="/search/cs?searchtype=author&query=Jorswieck%2C+E+A">Eduard A. Jorswieck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1039">[1039]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14319" title="Abstract">arXiv:2401.14319</a> (replaced) [<a href="/pdf/2401.14319" title="Download PDF">pdf</a>, <a href="/ps/2401.14319" title="Download PostScript">ps</a>, <a href="/format/2401.14319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantum &quot;Lifting Theorem&quot; for Constructions of Pseudorandom Generators  from Random Oracles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katz%2C+J">Jonathan Katz</a>, 
<a href="/search/cs?searchtype=author&query=Sela%2C+B">Ben Sela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1040">[1040]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14321" title="Abstract">arXiv:2401.14321</a> (replaced) [<a href="/pdf/2401.14321" title="Download PDF">pdf</a>, <a href="/format/2401.14321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VALL-T: Decoder-Only Generative Transducer for Robust and  Decoding-Controllable Text-to-Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hankun Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+Z">Zhikang Niu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1041">[1041]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14340" title="Abstract">arXiv:2401.14340</a> (replaced) [<a href="/pdf/2401.14340" title="Download PDF">pdf</a>, <a href="/format/2401.14340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of partially known Gaussian graphical models with score-based  structural priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sevilla%2C+M">Mart&#xed;n Sevilla</a>, 
<a href="/search/stat?searchtype=author&query=Marques%2C+A+G">Antonio Garc&#xed;a Marques</a>, 
<a href="/search/stat?searchtype=author&query=Segarra%2C+S">Santiago Segarra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1042">[1042]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14347" title="Abstract">arXiv:2401.14347</a> (replaced) [<a href="/pdf/2401.14347" title="Download PDF">pdf</a>, <a href="/format/2401.14347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving higher-order synergies reveals a trade-off between stability  and information integration capacity in complex systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varley%2C+T+F">Thomas F. Varley</a>, 
<a href="/search/cs?searchtype=author&query=Bongard%2C+J">Joshua Bongard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Dynamical Systems (math.DS); Chaotic Dynamics (nlin.CD); Cellular Automata and Lattice Gases (nlin.CG)

</div>
</div>
</dd>
<dt><a name="item1043">[1043]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14403" title="Abstract">arXiv:2401.14403</a> (replaced) [<a href="/pdf/2401.14403" title="Download PDF">pdf</a>, <a href="/format/2401.14403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Mobile Manipulation for Articulated Objects In the Open World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Haoyu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Mendonca%2C+R">Russell Mendonca</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+K">Kenneth Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website at <a href="https://open-world-mobilemanip.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1044">[1044]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14424" title="Abstract">arXiv:2401.14424</a> (replaced) [<a href="/pdf/2401.14424" title="Download PDF">pdf</a>, <a href="/format/2401.14424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Mathematical Formulas from Data via GPT-guided Monte Carlo  Tree Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lina Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+M">Meilan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yusong Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1045">[1045]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14521" title="Abstract">arXiv:2401.14521</a> (replaced) [<a href="/pdf/2401.14521" title="Download PDF">pdf</a>, <a href="/ps/2401.14521" title="Download PostScript">ps</a>, <a href="/format/2401.14521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Interpretable Physical-Conceptual Catchment-Scale Hydrological  Modeling using the Mass-Conserving-Perceptron
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan-Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+H+V">Hoshin V. Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 7 Figures, 2 Tables, 1 Supplementary Material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1046">[1046]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14581" title="Abstract">arXiv:2401.14581</a> (replaced) [<a href="/pdf/2401.14581" title="Download PDF">pdf</a>, <a href="/format/2401.14581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVELA - A Vision for Engineering Literacy &amp; Access: Understanding Why  Technology Alone Is Not Enough
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnson%2C+K">Kyle Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Arroyos%2C+V">Vicente Arroyos</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+C">Celeste Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Hussein%2C+L">Liban Hussein</a>, 
<a href="/search/cs?searchtype=author&query=Cora%2C+A">Aisha Cora</a>, 
<a href="/search/cs?searchtype=author&query=Melaku%2C+T">Tsewone Melaku</a>, 
<a href="/search/cs?searchtype=author&query=Cunningham%2C+J+L">Jay L. Cunningham</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+R+B">R. Benjamin Shapiro</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+V">Vikram Iyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the author's version of the work. It is posted here for personal use, not for redistribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1047">[1047]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14680" title="Abstract">arXiv:2401.14680</a> (replaced) [<a href="/pdf/2401.14680" title="Download PDF">pdf</a>, <a href="/format/2401.14680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaLLaM -- Malaysia Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zolkepli%2C+H">Husein Zolkepli</a>, 
<a href="/search/cs?searchtype=author&query=Razak%2C+A">Aisyah Razak</a>, 
<a href="/search/cs?searchtype=author&query=Adha%2C+K">Kamarul Adha</a>, 
<a href="/search/cs?searchtype=author&query=Nazhan%2C+A">Ariff Nazhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1048">[1048]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14780" title="Abstract">arXiv:2401.14780</a> (replaced) [<a href="/pdf/2401.14780" title="Download PDF">pdf</a>, <a href="/format/2401.14780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks and Defenses in 6G Network-Assisted IoT Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Son%2C+B+D">Bui Duc Son</a>, 
<a href="/search/cs?searchtype=author&query=Hoa%2C+N+T">Nguyen Tien Hoa</a>, 
<a href="/search/cs?searchtype=author&query=Van+Chien%2C+T">Trinh Van Chien</a>, 
<a href="/search/cs?searchtype=author&query=Khalid%2C+W">Waqas Khalid</a>, 
<a href="/search/cs?searchtype=author&query=Ferrag%2C+M+A">Mohamed Amine Ferrag</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+W">Wan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures, and 4 tables. Submitted for publications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1049">[1049]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14887" title="Abstract">arXiv:2401.14887</a> (replaced) [<a href="/pdf/2401.14887" title="Download PDF">pdf</a>, <a href="/format/2401.14887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Noise: Redefining Retrieval for RAG Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cuconasu%2C+F">Florin Cuconasu</a>, 
<a href="/search/cs?searchtype=author&query=Trappolini%2C+G">Giovanni Trappolini</a>, 
<a href="/search/cs?searchtype=author&query=Siciliano%2C+F">Federico Siciliano</a>, 
<a href="/search/cs?searchtype=author&query=Filice%2C+S">Simone Filice</a>, 
<a href="/search/cs?searchtype=author&query=Campagnano%2C+C">Cesare Campagnano</a>, 
<a href="/search/cs?searchtype=author&query=Maarek%2C+Y">Yoelle Maarek</a>, 
<a href="/search/cs?searchtype=author&query=Tonellotto%2C+N">Nicola Tonellotto</a>, 
<a href="/search/cs?searchtype=author&query=Silvestri%2C+F">Fabrizio Silvestri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1050">[1050]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14915" title="Abstract">arXiv:2401.14915</a> (replaced) [<a href="/pdf/2401.14915" title="Download PDF">pdf</a>, <a href="/format/2401.14915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Charting the Future of AI in Project-Based Learning: A Co-Design  Exploration with Students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chengbo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Kangyu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Bingcan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mogavi%2C+R+H">Reza Hadi Mogavi</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhenhui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shuai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojuan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conditionally accepted by CHI '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1051">[1051]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14920" title="Abstract">arXiv:2401.14920</a> (replaced) [<a href="/pdf/2401.14920" title="Download PDF">pdf</a>, <a href="/format/2401.14920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hold Tight: Identifying Behavioral Patterns During Prolonged Work in VR  through Video Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biener%2C+V">Verena Biener</a>, 
<a href="/search/cs?searchtype=author&query=Farzinnejad%2C+F">Forouzan Farzinnejad</a>, 
<a href="/search/cs?searchtype=author&query=Schuster%2C+R">Rinaldo Schuster</a>, 
<a href="/search/cs?searchtype=author&query=Tabaei%2C+S">Seyedmasih Tabaei</a>, 
<a href="/search/cs?searchtype=author&query=Lindlein%2C+L">Leon Lindlein</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jinghui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Nouri%2C+N">Negar Nouri</a>, 
<a href="/search/cs?searchtype=author&query=Dudley%2C+J+J">John J. Dudley</a>, 
<a href="/search/cs?searchtype=author&query=Kristensson%2C+P+O">Per Ola Kristensson</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J">J&#xf6;rg M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Grubert%2C+J">Jens Grubert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1052">[1052]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15071" title="Abstract">arXiv:2401.15071</a> (replaced) [<a href="/pdf/2401.15071" title="Download PDF">pdf</a>, <a href="/format/2401.15071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From GPT-4 to Gemini and Beyond: Assessing the Landscape of MLLMs on  Generalizability, Trustworthiness and Causality through Four Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chaochao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guodong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hongxing Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hongzhi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jingyi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jinlan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kexin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kunchang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Meiqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Q">Qibing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sirui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yali Wang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yan Teng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yinan He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingchun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujiong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+Y">Yurong Mou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zaibin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhelun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhenfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhipin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item589">Cross-lists</a></li>
<li><a href="#item661">Replacements</a></li>
</ul>
<small>[ total of 1052 entries:  <b>1-1052</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2401">2401</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
